{"id": "2508.00031", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00031", "abs": "https://arxiv.org/abs/2508.00031", "authors": ["Junde Wu"], "title": "Git Context Controller: Manage the Context of LLM-based Agents like Git", "comment": "in updating", "summary": "Large language model (LLM) based agents have shown impressive capabilities by\ninterleaving internal reasoning with external tool use. However, as these\nagents are deployed in long-horizon workflows, such as coding for a big,\nlong-term project, context management becomes a critical bottleneck. We\nintroduce Git-Context-Controller (GCC), a structured context management\nframework inspired by software version control systems. GCC elevates context as\nversioned memory hierarchy like Git. It structures agent memory as a persistent\nfile system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,\nenabling milestone-based checkpointing, exploration of alternative plans, and\nstructured reflection. Our approach empowers agents to manage long-term goals,\nisolate architectural experiments, and recover or hand off memory across\nsessions and agents. Empirically, agents equipped with GCC achieve\nstate-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00\nof software bugs, outperforming 26 competitive systems. In a self-replication\ncase study, a GCC-augmented agent builds a new CLI agent from scratch,\nachieving 40.7 task resolution, compared to only 11.7 without GCC. The code is\nreleased at: https://github.com/theworldofagents/GCC", "AI": {"tldr": "GCC\u662f\u4e00\u4e2a\u57fa\u4e8eGit\u542f\u53d1\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u6846\u67b6\uff0c\u5e2e\u52a9LLM\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u9ad8\u6548\u7ba1\u7406\u4e0a\u4e0b\u6587\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7ba1\u7406\u7684\u74f6\u9888\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u7ba1\u7406\u8bb0\u5fc6\u548c\u4efb\u52a1\u72b6\u6001\u3002", "method": "GCC\u5c06\u4ee3\u7406\u8bb0\u5fc6\u7ed3\u6784\u5316\u4e3a\u7c7b\u4f3cGit\u7684\u7248\u672c\u63a7\u5236\u7cfb\u7edf\uff0c\u652f\u6301COMMIT\u3001BRANCH\u3001MERGE\u7b49\u64cd\u4f5c\uff0c\u5b9e\u73b0\u91cc\u7a0b\u7891\u68c0\u67e5\u70b9\u548c\u7ed3\u6784\u5316\u53cd\u601d\u3002", "result": "\u5728SWE-Bench-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGCC\u4ee3\u7406\u89e3\u51b3\u4e8648.00%\u7684\u8f6f\u4ef6\u9519\u8bef\uff0c\u4f18\u4e8e26\u4e2a\u7ade\u4e89\u7cfb\u7edf\uff1b\u5728\u81ea\u590d\u5236\u6848\u4f8b\u4e2d\uff0c\u4efb\u52a1\u89e3\u51b3\u7387\u4ece11.7%\u63d0\u5347\u81f340.7%\u3002", "conclusion": "GCC\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.00005", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00005", "abs": "https://arxiv.org/abs/2508.00005", "authors": ["Tilman Hinnerichs", "Bart Swinkels", "Jaap de Jong", "Reuben Gardos Reid", "Tudor Magirescu", "Neil Yorke-Smith", "Sebastijan Dumancic"], "title": "Modelling Program Spaces in Program Synthesis with Constraints", "comment": null, "summary": "A core challenge in program synthesis is taming the large space of possible\nprograms. Since program synthesis is essentially a combinatorial search, the\ncommunity has sought to leverage powerful combinatorial constraint solvers.\nHere, constraints are used to express the program semantics, but not as a\npotentially potent tool to remove unwanted programs. Recent inductive logic\nprogramming approaches introduce constraints on the program's syntax to be\nsynthesized. These syntactic constraints allow for checking and propagating a\nconstraint without executing the program, and thus for arbitrary operators. In\nthis work, we leverage syntactic constraints to model program spaces, defining\nnot just solutions that are feasible, but also ones that are likely useful. To\ndemonstrate this idea, we introduce BART, a solver that efficiently propagates\nand solves these constraints. We evaluate BART on program space enumeration\ntasks, finding that the constraints eliminate up to 99 percent of the program\nspace, and that modeling program spaces significantly reduces enumeration time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8bed\u6cd5\u7ea6\u675f\u6765\u4f18\u5316\u7a0b\u5e8f\u5408\u6210\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7BART\u6c42\u89e3\u5668\u9ad8\u6548\u4f20\u64ad\u548c\u89e3\u51b3\u8fd9\u4e9b\u7ea6\u675f\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7a0b\u5e8f\u7a7a\u95f4\u7684\u679a\u4e3e\u65f6\u95f4\u548c\u89c4\u6a21\u3002", "motivation": "\u7a0b\u5e8f\u5408\u6210\u7684\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5904\u7406\u5e9e\u5927\u7684\u53ef\u80fd\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7ec4\u5408\u7ea6\u675f\u6c42\u89e3\u5668\u8868\u8fbe\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4f46\u672a\u5145\u5206\u5229\u7528\u7ea6\u675f\u53bb\u9664\u65e0\u7528\u7a0b\u5e8f\u3002", "method": "\u5f15\u5165\u8bed\u6cd5\u7ea6\u675f\u6765\u5efa\u6a21\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u5b9a\u4e49\u53ef\u884c\u4e14\u53ef\u80fd\u6709\u7528\u7684\u89e3\uff0c\u5f00\u53d1BART\u6c42\u89e3\u5668\u9ad8\u6548\u4f20\u64ad\u548c\u89e3\u51b3\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bed\u6cd5\u7ea6\u675f\u80fd\u6d88\u9664\u9ad8\u8fbe99%\u7684\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u663e\u8457\u51cf\u5c11\u679a\u4e3e\u65f6\u95f4\u3002", "conclusion": "\u8bed\u6cd5\u7ea6\u675f\u662f\u4f18\u5316\u7a0b\u5e8f\u5408\u6210\u7684\u6709\u6548\u5de5\u5177\uff0cBART\u6c42\u89e3\u5668\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00033", "categories": ["cs.SE", "cs.AI", "cs.CL", "68T50", "I.2.2; I.2.7; D.2.3"], "pdf": "https://arxiv.org/pdf/2508.00033", "abs": "https://arxiv.org/abs/2508.00033", "authors": ["Nuno Fachada", "Daniel Fernandes", "Carlos M. Fernandes", "Bruno D. Ferreira-Saraiva", "Jo\u00e3o P. Matos-Carvalho"], "title": "GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries", "comment": null, "summary": "Large Language Models (LLMs) have advanced rapidly as tools for automating\ncode generation in scientific research, yet their ability to interpret and use\nunfamiliar Python APIs for complex computational experiments remains poorly\ncharacterized. This study systematically benchmarks a selection of\nstate-of-the-art LLMs in generating functional Python code for two increasingly\nchallenging scenarios: conversational data analysis with the \\textit{ParShift}\nlibrary, and synthetic data generation and clustering using \\textit{pyclugen}\nand \\textit{scikit-learn}. Both experiments use structured, zero-shot prompts\nspecifying detailed requirements but omitting in-context examples. Model\noutputs are evaluated quantitatively for functional correctness and prompt\ncompliance over multiple runs, and qualitatively by analyzing the errors\nproduced when code execution fails. Results show that only a small subset of\nmodels consistently generate correct, executable code, with GPT-4.1 standing\nout as the only model to always succeed in both tasks. In addition to\nbenchmarking LLM performance, this approach helps identify shortcomings in\nthird-party libraries, such as unclear documentation or obscure implementation\nbugs. Overall, these findings highlight current limitations of LLMs for\nend-to-end scientific automation and emphasize the need for careful prompt\ndesign, comprehensive library documentation, and continued advances in language\nmodel capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u590d\u6742Python\u4ee3\u7801\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4ec5\u6709\u5c11\u6570\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u80fd\u7a33\u5b9a\u751f\u6210\u6b63\u786e\u4ee3\u7801\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u7b2c\u4e09\u65b9\u5e93\u6587\u6863\u548c\u5b9e\u73b0\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u751f\u6210\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5bf9\u4e0d\u719f\u6089API\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u4ee5\u63a8\u52a8\u79d1\u5b66\u81ea\u52a8\u5316\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u96f6\u6837\u672c\u63d0\u793a\uff0c\u6d4b\u8bd5LLMs\u5728\u4e24\u79cd\u590d\u6742\u4efb\u52a1\uff08\u6570\u636e\u5206\u6790\u548c\u5408\u6210\u6570\u636e\u751f\u6210\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u9519\u8bef\u3002", "result": "\u4ec5\u5c11\u6570\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u80fd\u7a33\u5b9a\u751f\u6210\u6b63\u786e\u4ee3\u7801\uff0c\u540c\u65f6\u53d1\u73b0\u7b2c\u4e09\u65b9\u5e93\u6587\u6863\u548c\u5b9e\u73b0\u4e2d\u7684\u95ee\u9898\u3002", "conclusion": "LLMs\u5728\u79d1\u5b66\u81ea\u52a8\u5316\u4e2d\u4ecd\u6709\u5c40\u9650\uff0c\u9700\u6539\u8fdb\u63d0\u793a\u8bbe\u8ba1\u3001\u5e93\u6587\u6863\u548c\u6a21\u578b\u80fd\u529b\u3002"}}
{"id": "2508.00013", "categories": ["cs.PL", "I.2.6; F.1.1"], "pdf": "https://arxiv.org/pdf/2508.00013", "abs": "https://arxiv.org/abs/2508.00013", "authors": ["Zurabi Kobaladze", "Anna Arnania", "Tamar Sanikidze"], "title": "From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms", "comment": "78 pages. Undergraduate thesis project submitted in partial\n  fulfillment of the requirements for the Bachelor's degree in Computer Science\n  at Kutaisi International University", "summary": "Program synthesis--the automated generation of executable code from\nhigh-level specifications--has been a central goal of computer science for over\nfifty years. This thesis provides a comparative literature review of the main\nparadigms that have shaped the field, tracing its evolution from formal logic\nbased methods to recent advances using large scale neural models. We examine\nfive key approaches: logic based (deductive) synthesis, inductive (example\nbased) synthesis, sketch/schema based synthesis, large language model based\nsynthesis, and neuro-symbolic hybrids. For each, we analyze foundational\nprinciples, notable systems, and practical applications, highlighting trade\noffs between correctness guarantees, specification requirements, search\ncomplexity, and expressive power. By reviewing developments from formally\nverified synthesis tools such as KIDS and Coq to data driven models generating\nprobabilistic code from natural language like Codex, we present a comprehensive\nnarrative of progress and ongoing challenges. This work emphasizes the\ntransition from symbolic to hybrid neuro-symbolic methods and outlines future\ndirections for reliable and scalable program synthesis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u7a0b\u5e8f\u5408\u6210\u7684\u4e94\u79cd\u4e3b\u8981\u65b9\u6cd5\uff0c\u4ece\u903b\u8f91\u57fa\u7840\u5230\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5176\u53d1\u5c55\u5386\u7a0b\u3001\u4f18\u7f3a\u70b9\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u7a0b\u5e8f\u5408\u6210\u9886\u57df\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u4e94\u79cd\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\uff1a\u903b\u8f91\u57fa\u7840\u3001\u5f52\u7eb3\u57fa\u7840\u3001\u8349\u56fe/\u6a21\u5f0f\u57fa\u7840\u3001\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u7840\u548c\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u539f\u7406\u3001\u7cfb\u7edf\u3001\u5e94\u7528\u53ca\u6743\u8861\uff0c\u7a81\u51fa\u4e86\u4ece\u7b26\u53f7\u65b9\u6cd5\u5230\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u7684\u8f6c\u53d8\u3002", "conclusion": "\u672a\u6765\u7a0b\u5e8f\u5408\u6210\u9700\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u53ef\u9760\u548c\u53ef\u6269\u5c55\u7684\u5408\u6210\u6280\u672f\u3002"}}
{"id": "2508.00045", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00045", "abs": "https://arxiv.org/abs/2508.00045", "authors": ["Samah Kansab"], "title": "Machine Learning Pipeline for Software Engineering: A Systematic Literature Review", "comment": null, "summary": "The rapid advancement of software development practices has introduced\nchallenges in ensuring quality and efficiency across the software engineering\n(SE) lifecycle. As SE systems grow in complexity, traditional approaches often\nfail to scale, resulting in longer debugging times, inefficient defect\ndetection, and resource-heavy development cycles. Machine Learning (ML) has\nemerged as a key solution, enabling automation in tasks such as defect\nprediction, code review, and release quality estimation. However, the\neffectiveness of ML in SE depends on the robustness of its pipeline, including\ndata collection, preprocessing, feature engineering, algorithm selection,\nvalidation, and evaluation.\n  This systematic literature review (SLR) examines state-of-the-art ML\npipelines designed for SE, consolidating best practices, challenges, and gaps.\nOur findings show that robust preprocessing, such as SMOTE for data balancing\nand SZZ-based algorithms for feature selection, improves model reliability.\nEnsemble methods like Random Forest and Gradient Boosting dominate performance\nacross tasks, while simpler models such as Naive Bayes remain valuable for\nefficiency and interpretability. Evaluation metrics including AUC, F1-score,\nand precision are most common, with new metrics like Best Arithmetic Mean (BAM)\nemerging in niche applications. Validation techniques such as bootstrapping are\nwidely used to ensure model stability and generalizability.\n  This SLR highlights the importance of well-designed ML pipelines for\naddressing SE challenges and provides actionable insights for researchers and\npractitioners seeking to optimize software quality and efficiency. By\nidentifying gaps and trends, this study sets a foundation for advancing ML\nadoption and fostering innovation in increasingly complex development\nenvironments.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u6700\u4f73\u5b9e\u8df5\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u8d28\u91cf\u548c\u6548\u7387\u9700\u6c42\uff0cML\u6210\u4e3a\u89e3\u51b3SE\u95ee\u9898\u7684\u5173\u952e\u5de5\u5177\u3002", "method": "\u901a\u8fc7SLR\u5206\u6790ML\u5728SE\u4e2d\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u7b97\u6cd5\u9009\u62e9\u548c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u636e\u5e73\u8861\uff08\u5982SMOTE\uff09\u3001\u7279\u5f81\u9009\u62e9\uff08\u5982SZZ\uff09\u548c\u96c6\u6210\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8bbe\u8ba1\u826f\u597d\u7684ML\u6d41\u7a0b\u5bf9\u4f18\u5316SE\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.00016", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00016", "abs": "https://arxiv.org/abs/2508.00016", "authors": ["Matt Kaufmann", "Yahya Sohail", "Warren A. Hunt Jr"], "title": "Extended Abstract: Mutable Objects with Several Implementations", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "This extended abstract outlines an ACL2 feature, attach-stobj, that first\nappeared in ACL2 Version 8.6 (October, 2024). This feature supports different\nexecutable operations for a given abstract stobj, without requiring\nrecertification of the book that introduces that stobj or theorems about it.\nThe paper provides background as well as a user-level overview and some\nimplementation notes.", "AI": {"tldr": "ACL2\u7684attach-stobj\u529f\u80fd\u652f\u6301\u5bf9\u62bd\u8c61stobj\u7684\u4e0d\u540c\u53ef\u6267\u884c\u64cd\u4f5c\uff0c\u65e0\u9700\u91cd\u65b0\u8ba4\u8bc1\u76f8\u5173\u4e66\u7c4d\u6216\u5b9a\u7406\u3002", "motivation": "\u63d0\u4f9b\u4e00\u79cd\u7075\u6d3b\u7684\u65b9\u5f0f\uff0c\u5141\u8bb8\u7528\u6237\u5728\u4e0d\u91cd\u65b0\u8ba4\u8bc1\u4e66\u7c4d\u6216\u5b9a\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u62bd\u8c61stobj\u5b9a\u4e49\u4e0d\u540c\u7684\u53ef\u6267\u884c\u64cd\u4f5c\u3002", "method": "\u4ecb\u7ecd\u4e86attach-stobj\u529f\u80fd\uff0c\u5305\u62ec\u80cc\u666f\u3001\u7528\u6237\u7ea7\u6982\u8ff0\u548c\u5b9e\u73b0\u7ec6\u8282\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u62bd\u8c61stobj\u7684\u591a\u64cd\u4f5c\u652f\u6301\uff0c\u63d0\u5347\u4e86ACL2\u7684\u7075\u6d3b\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "attach-stobj\u529f\u80fd\u4e3aACL2\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u7b80\u5316\u4e86\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2508.00083", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00083", "abs": "https://arxiv.org/abs/2508.00083", "authors": ["Yihong Dong", "Xue Jiang", "Jiaru Qian", "Tian Wang", "Kechi Zhang", "Zhi Jin", "Ge Li"], "title": "A Survey on Code Generation with LLM-based Agents", "comment": "Work in progress", "summary": "Code generation agents powered by large language models (LLMs) are\nrevolutionizing the software development paradigm. Distinct from previous code\ngeneration techniques, code generation agents are characterized by three core\nfeatures. 1) Autonomy: the ability to independently manage the entire workflow,\nfrom task decomposition to coding and debugging. 2) Expanded task scope:\ncapabilities that extend beyond generating code snippets to encompass the full\nsoftware development lifecycle (SDLC). 3) Enhancement of engineering\npracticality: a shift in research emphasis from algorithmic innovation toward\npractical engineering challenges, such as system reliability, process\nmanagement, and tool integration. This domain has recently witnessed rapid\ndevelopment and an explosion in research, demonstrating significant application\npotential. This paper presents a systematic survey of the field of LLM-based\ncode generation agents. We trace the technology's developmental trajectory from\nits inception and systematically categorize its core techniques, including both\nsingle-agent and multi-agent architectures. Furthermore, this survey details\nthe applications of LLM-based agents across the full SDLC, summarizes\nmainstream evaluation benchmarks and metrics, and catalogs representative\ntools. Finally, by analyzing the primary challenges, we identify and propose\nseveral foundational, long-term research directions for the future work of the\nfield.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u751f\u6210\u4ee3\u7406\uff0c\u603b\u7ed3\u4e86\u5176\u6838\u5fc3\u7279\u5f81\u3001\u6280\u672f\u5206\u7c7b\u3001\u5e94\u7528\u573a\u666f\u3001\u8bc4\u4f30\u5de5\u5177\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u4ee3\u7801\u751f\u6210\u4ee3\u7406\u5982\u4f55\u901a\u8fc7\u81ea\u4e3b\u6027\u3001\u4efb\u52a1\u8303\u56f4\u6269\u5c55\u548c\u5de5\u7a0b\u5b9e\u7528\u6027\u63d0\u5347\uff0c\u9769\u65b0\u8f6f\u4ef6\u5f00\u53d1\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u8c03\u67e5\uff0c\u5206\u7c7b\u5355\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u5e76\u5206\u6790\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u603b\u7ed3\u4e86\u4e3b\u6d41\u8bc4\u4f30\u57fa\u51c6\u548c\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u8be5\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\u548c\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8be5\u9886\u57df\u7684\u57fa\u7840\u6027\u3001\u957f\u671f\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u5e94\u5bf9\u5f53\u524d\u6311\u6218\u3002"}}
{"id": "2508.00422", "categories": ["cs.PL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00422", "abs": "https://arxiv.org/abs/2508.00422", "authors": ["Varun Bharti", "Shashwat Jha", "Dhruv Kumar", "Pankaj Jalote"], "title": "Automated Type Annotation in Python Using Large Language Models", "comment": "Under Review", "summary": "Type annotations in Python enhance maintainability and error detection.\nHowever, generating these annotations manually is error prone and requires\nextra effort. Traditional automation approaches like static analysis, machine\nlearning, and deep learning struggle with limited type vocabularies, behavioral\nover approximation, and reliance on large labeled datasets. In this work, we\nexplore the use of LLMs for generating type annotations in Python. We develop a\ngenerate check repair pipeline: the LLM proposes annotations guided by a\nConcrete Syntax Tree representation, a static type checker (Mypy) verifies\nthem, and any errors are fed back for iterative refinement. We evaluate four\nLLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini\n(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.\nWe first measure the proportion of code snippets annotated by LLMs for which\nMyPy reported no errors (i.e., consistent results): GPT 4oMini achieved\nconsistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,\nand O4Mini each reached approximately 88.6% consistency (around 11.4%\nfailures). To measure annotation quality, we then compute exact-match and\nbase-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini\nperform the best, achieving up to 70.5% exact match and 79.1% base type\naccuracy, requiring under one repair iteration on average. Our results\ndemonstrate that general-purpose and reasoning optimized LLMs, without any task\nspecific fine tuning or additional training can be effective in generating\nconsistent type annotations.They perform competitively with traditional deep\nlearning techniques which require large labeled dataset for training. While our\nwork focuses on Python, the pipeline can be extended to other optionally typed\nimperative languages like Ruby", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u4f7f\u7528LLMs\uff08\u5982GPT 4oMini\u3001GPT 4.1mini\u7b49\uff09\u81ea\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210-\u68c0\u67e5-\u4fee\u590d\u6d41\u7a0b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u624b\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\u5bb9\u6613\u51fa\u9519\u4e14\u8017\u65f6\uff0c\u4f20\u7edf\u81ea\u52a8\u5316\u65b9\u6cd5\uff08\u5982\u9759\u6001\u5206\u6790\u3001\u673a\u5668\u5b66\u4e60\uff09\u5b58\u5728\u7c7b\u578b\u8bcd\u6c47\u6709\u9650\u3001\u884c\u4e3a\u8fc7\u5ea6\u8fd1\u4f3c\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u751f\u6210-\u68c0\u67e5-\u4fee\u590d\u6d41\u7a0b\uff1aLLM\u57fa\u4e8e\u8bed\u6cd5\u6811\u751f\u6210\u6ce8\u91ca\uff0c\u9759\u6001\u68c0\u67e5\u5668\u9a8c\u8bc1\uff0c\u9519\u8bef\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u3002", "result": "GPT 4.1mini\u548cO3Mini\u8868\u73b0\u6700\u4f73\uff0c\u4e00\u81f4\u6027\u8fbe88.6%\uff0c\u51c6\u786e\u7387\u6700\u9ad870.5%\uff08\u7cbe\u786e\u5339\u914d\uff09\u548c79.1%\uff08\u57fa\u7840\u7c7b\u578b\u5339\u914d\uff09\u3002", "conclusion": "\u901a\u7528\u548c\u63a8\u7406\u4f18\u5316\u7684LLMs\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u6709\u6548\u751f\u6210\u7c7b\u578b\u6ce8\u91ca\uff0c\u6027\u80fd\u4e0e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u76f8\u5f53\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u53ef\u9009\u7c7b\u578b\u8bed\u8a00\u3002"}}
{"id": "2508.00738", "categories": ["cs.SE", "cs.FL", "68N30", "D.2.4"], "pdf": "https://arxiv.org/pdf/2508.00738", "abs": "https://arxiv.org/abs/2508.00738", "authors": ["Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber", "Valdes Voufo"], "title": "Tool-Assisted Conformance Checking to Reference Process Models", "comment": null, "summary": "Reference models convey best practices and standards. The reference\nframeworks necessitate conformance checks to ensure adherence to established\nguidelines and principles, which is crucial for maintaining quality and\nconsistency in various processes. This paper explores automated conformance\nchecks for concrete process models against reference models using causal\ndependency analysis of tasks and events. Existing notions of conformance\nchecking for process models focus on verifying process execution traces and\nlack the expressiveness and automation needed for semantic model comparison,\nleaving this question unresolved. We integrate our approach into a broader\nsemantic framework for defining reference model conformance. We outline an\nalgorithm for reference process model conformance checking, evaluate it through\na case study, and discuss its strengths and limitations. Our research provides\na tool-assisted solution enhancing accuracy and flexibility in process model\nconformance verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u4f9d\u8d56\u5206\u6790\u7684\u81ea\u52a8\u5316\u4e00\u81f4\u6027\u68c0\u67e5\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5177\u4f53\u6d41\u7a0b\u6a21\u578b\u4e0e\u53c2\u8003\u6a21\u578b\u7684\u4e00\u81f4\u6027\uff0c\u586b\u8865\u4e86\u8bed\u4e49\u6a21\u578b\u6bd4\u8f83\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u6a21\u578b\u6bd4\u8f83\u7684\u8868\u8fbe\u80fd\u529b\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u91c7\u7528\u56e0\u679c\u4f9d\u8d56\u5206\u6790\u4efb\u52a1\u548c\u4e8b\u4ef6\uff0c\u63d0\u51fa\u7b97\u6cd5\u5e76\u96c6\u6210\u5230\u8bed\u4e49\u6846\u67b6\u4e2d\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5de5\u5177\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u6d41\u7a0b\u6a21\u578b\u4e00\u81f4\u6027\u9a8c\u8bc1\u7684\u80fd\u529b\u3002"}}
{"id": "2508.00003", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00003", "abs": "https://arxiv.org/abs/2508.00003", "authors": ["Kang Rong Roy Ang"], "title": "Building Bigraphs of the real world", "comment": "Submitted in partial fulfilment of the requirements for Part II of\n  the Computer Science Tripos at the University of Cambridge", "summary": "This report proposes a formal specification for organising all buildings,\nstreets and administrative areas in the world into a hierarchical\nspace-partitioning tree using data from OpenStreetMap. This hierarchical\nstructure is encoded into a bigraph, serving as a digital twin of the world and\ncapturing complete street connectivity. It presents a tool implemented in OCaml\n(source code at https://github.com/royangkr/bigraph-of-the-world ) that\nconstructs bigraphs for regions from any part of the world. In addition, it\ncontributes algorithmic improvements to open-source bigraph-building tools that\nenable them to efficiently construct and transform extremely large bigraphs,\nachieving up to a 97x speedup among other gains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eOpenStreetMap\u6570\u636e\u7684\u5168\u7403\u5efa\u7b51\u3001\u8857\u9053\u548c\u884c\u653f\u533a\u57df\u7684\u5c42\u6b21\u5316\u7a7a\u95f4\u5206\u533a\u6811\u89c4\u8303\uff0c\u5e76\u5c06\u5176\u7f16\u7801\u4e3a\u5927\u56fe\uff08bigraph\uff09\uff0c\u4f5c\u4e3a\u4e16\u754c\u7684\u6570\u5b57\u5b6a\u751f\u3002", "motivation": "\u4e3a\u4e86\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u5b8c\u6574\u6355\u6349\u8857\u9053\u8fde\u901a\u6027\u7684\u5168\u7403\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u3002", "method": "\u4f7f\u7528OCaml\u5b9e\u73b0\u5de5\u5177\uff0c\u4eceOpenStreetMap\u6570\u636e\u6784\u5efa\u5927\u56fe\uff0c\u5e76\u6539\u8fdb\u5f00\u6e90\u5de5\u5177\u4ee5\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u8fbe97\u500d\u7684\u52a0\u901f\uff0c\u5e76\u80fd\u9ad8\u6548\u6784\u5efa\u548c\u8f6c\u6362\u6781\u5927\u5c3a\u5bf8\u7684\u5927\u56fe\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5168\u7403\u7a7a\u95f4\u6570\u636e\u7684\u5c42\u6b21\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2508.00128", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00128", "abs": "https://arxiv.org/abs/2508.00128", "authors": ["Md Nazmul Haque", "Hua Yang", "Zhou Yang", "Bowen Xu"], "title": "How Quantization Impacts Privacy Risk on LLMs for Code?", "comment": null, "summary": "Large language models for code (LLMs4Code) rely heavily on massive training\ndata, including sensitive data, such as cloud service credentials of the\nprojects and personal identifiable information of the developers, raising\nserious privacy concerns. Membership inference (MI) has recently emerged as an\neffective tool for assessing privacy risk by identifying whether specific data\nbelong to a model's training set. In parallel, model compression techniques,\nespecially quantization, have gained traction for reducing computational costs\nand enabling the deployment of large models. However, while quantized models\nstill retain knowledge learned from the original training data, it remains\nunclear whether quantization affects their ability to retain and expose privacy\ninformation. Answering this question is of great importance to understanding\nprivacy risks in real-world deployments. In this work, we conduct the first\nempirical study on how quantization influences task performance and privacy\nrisk simultaneously in LLMs4Code. To do this, we implement widely used\nquantization techniques (static and dynamic) to three representative model\nfamilies, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that\nquantization has a significant impact on reducing the privacy risk relative to\nthe original model. We also uncover a positive correlation between task\nperformance and privacy risk, indicating an underlying tradeoff. Moreover, we\nreveal the possibility that quantizing larger models could yield better balance\nthan using full-precision small models. Finally, we demonstrate that these\nfindings generalize across different architectures, model sizes and MI methods,\noffering practical guidance for safeguarding privacy when deploying compressed\nLLMs4Code.", "AI": {"tldr": "\u91cf\u5316\u6280\u672f\u663e\u8457\u964d\u4f4e\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4efb\u52a1\u6027\u80fd\u4e0e\u9690\u79c1\u98ce\u9669\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u91cf\u5316\u6280\u672f\u5bf9\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs4Code\uff09\u4efb\u52a1\u6027\u80fd\u548c\u9690\u79c1\u98ce\u9669\u7684\u5f71\u54cd\uff0c\u4ee5\u6307\u5bfc\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u5bf9Pythia\u3001CodeGen\u548cGPTNeo\u4e09\u79cd\u6a21\u578b\u5bb6\u65cf\u5e94\u7528\u9759\u6001\u548c\u52a8\u6001\u91cf\u5316\u6280\u672f\uff0c\u5206\u6790\u91cf\u5316\u5bf9\u9690\u79c1\u98ce\u9669\u548c\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u91cf\u5316\u663e\u8457\u964d\u4f4e\u9690\u79c1\u98ce\u9669\uff0c\u5e76\u53d1\u73b0\u4efb\u52a1\u6027\u80fd\u4e0e\u9690\u79c1\u98ce\u9669\u6b63\u76f8\u5173\uff1b\u91cf\u5316\u5927\u6a21\u578b\u53ef\u80fd\u6bd4\u5c0f\u6a21\u578b\u66f4\u4f18\u3002", "conclusion": "\u91cf\u5316\u662f\u964d\u4f4eLLMs4Code\u9690\u79c1\u98ce\u9669\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u90e8\u7f72\u538b\u7f29\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2508.00482", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00482", "abs": "https://arxiv.org/abs/2508.00482", "authors": ["Erdem Yildirim", "Albert Schimpf", "Stefan Wehr", "Annette Bieniusa"], "title": "Semantic Subtyping for Maps in Erlang", "comment": null, "summary": "In this paper we will construct a set-theoretic model of types featuring type\nvariables, base types, set-theoretic types and map types. Syntax of map types\nspans all the map types available in Erlang. The model of types is used to\ndefine a semantic subtyping relation based on set containment. The novelty of\nthis work is the definition of subtyping over parameteric map types.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7c7b\u578b\u53d8\u91cf\u3001\u57fa\u7840\u7c7b\u578b\u3001\u96c6\u5408\u7c7b\u578b\u548c\u6620\u5c04\u7c7b\u578b\u7684\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5b9a\u4e49\u4e86\u57fa\u4e8e\u96c6\u5408\u5305\u542b\u7684\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u3002", "motivation": "\u7814\u7a76\u7c7b\u578b\u7cfb\u7edf\u4e2d\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u7279\u522b\u662f\u9488\u5bf9Erlang\u4e2d\u7684\u6620\u5c04\u7c7b\u578b\uff0c\u586b\u8865\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u5b50\u7c7b\u578b\u5b9a\u4e49\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u6db5\u76d6\u591a\u79cd\u7c7b\u578b\uff0c\u5e76\u57fa\u4e8e\u96c6\u5408\u5305\u542b\u5b9a\u4e49\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u6269\u5c55\u4e86\u7c7b\u578b\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7c7b\u578b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c24\u5176\u5728\u5904\u7406\u590d\u6742\u6620\u5c04\u7c7b\u578b\u65f6\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2508.00749", "categories": ["cs.SE", "cs.FL", "cs.SC", "68N30", "D.2.4"], "pdf": "https://arxiv.org/pdf/2508.00749", "abs": "https://arxiv.org/abs/2508.00749", "authors": ["Johanna Grahl", "Bernhard Rumpe", "Max Stachon", "Sebastian St\u00fcber"], "title": "Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures", "comment": null, "summary": "In the context of model-driven development, ensuring the correctness and\nconsistency of evolving models is paramount. This paper investigates the\napplication of Dynamic Symbolic Execution (DSE) for semantic difference\nanalysis of component-and-connector architectures, specifically utilizing\nMontiArc models. We have enhanced the existing MontiArc-to-Java generator to\ngather both symbolic and concrete execution data at runtime, encompassing\ntransition conditions, visited states, and internal variables of automata. This\ndata facilitates the identification of significant execution traces that\nprovide critical insights into system behavior. We evaluate various execution\nstrategies based on the criteria of runtime efficiency, minimality, and\ncompleteness, establishing a framework for assessing the applicability of DSE\nin semantic difference analysis. Our findings indicate that while DSE shows\npromise for analyzing component and connector architectures, scalability\nremains a primary limitation, suggesting further research is needed to enhance\nits practical utility in larger systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u52a8\u6001\u7b26\u53f7\u6267\u884c\uff08DSE\uff09\u5728\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u8bed\u4e49\u5dee\u5f02\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u589e\u5f3aMontiArc\u6a21\u578b\u751f\u6210\u5668\uff0c\u6536\u96c6\u8fd0\u884c\u65f6\u6570\u636e\u4ee5\u8bc6\u522b\u5173\u952e\u6267\u884c\u8f68\u8ff9\u3002\u8bc4\u4f30\u4e86\u4e0d\u540c\u6267\u884c\u7b56\u7565\uff0c\u53d1\u73b0DSE\u6f5c\u529b\u663e\u8457\u4f46\u53ef\u6269\u5c55\u6027\u53d7\u9650\u3002", "motivation": "\u5728\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u4e2d\uff0c\u786e\u4fdd\u6a21\u578b\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u6709\u6548\u7684\u8bed\u4e49\u5dee\u5f02\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u589e\u5f3aMontiArc-to-Java\u751f\u6210\u5668\uff0c\u6536\u96c6\u7b26\u53f7\u548c\u5177\u4f53\u6267\u884c\u6570\u636e\uff0c\u5206\u6790\u6267\u884c\u8f68\u8ff9\uff0c\u8bc4\u4f30\u4e0d\u540c\u6267\u884c\u7b56\u7565\u7684\u6548\u7387\u3001\u6700\u5c0f\u6027\u548c\u5b8c\u6574\u6027\u3002", "result": "DSE\u5728\u7ec4\u4ef6-\u8fde\u63a5\u5668\u67b6\u6784\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u53ef\u6269\u5c55\u6027\u662f\u5176\u4e3b\u8981\u9650\u5236\u3002", "conclusion": "DSE\u5728\u8bed\u4e49\u5dee\u5f02\u5206\u6790\u4e2d\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u5347\u5176\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00004", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2508.00004", "abs": "https://arxiv.org/abs/2508.00004", "authors": ["Dazhu Li", "Sujata Ghosh", "Fenrong Liu"], "title": "Reasoning under uncertainty in the game of Cops and Robbers", "comment": null, "summary": "The game of Cops and Robbers is an important model for studying computational\nqueries in pursuit-evasion environments, among others. As recent logical\nexplorations have shown, its structure exhibits appealing analogies with modal\nlogic. In this paper, we enrich the game with a setting in which players may\nhave imperfect information. We propose a new formal framework, Epistemic Logic\nof Cops and Robbers (ELCR), to make the core notions of the game precise, for\ninstance, players' positions, observational power and inference. Applying ELCR\nto analyze the game, we obtain an automated way to track interactions between\nplayers and characterize their information updates during the game. The update\nmechanism is defined by a novel dynamic operator, and we compare it with some\nrelevant paradigms from the game and logic perspectives. We study various\nproperties of ELCR including axiomatization and decidability. To our knowledge,\nthis is the first attempt to explore these games from a formal point of view\nwhere (partial) information available to players is taken into account.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u5316\u6846\u67b6ELCR\uff0c\u7528\u4e8e\u7814\u7a76\u5177\u6709\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684Cops and Robbers\u6e38\u620f\uff0c\u901a\u8fc7\u6a21\u6001\u903b\u8f91\u548c\u52a8\u6001\u64cd\u4f5c\u7b26\u5206\u6790\u73a9\u5bb6\u4e92\u52a8\u548c\u4fe1\u606f\u66f4\u65b0\u3002", "motivation": "\u7814\u7a76\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u73af\u5883\u4e0bCops and Robbers\u6e38\u620f\u7684\u8ba1\u7b97\u67e5\u8be2\u548c\u73a9\u5bb6\u4e92\u52a8\u3002", "method": "\u63d0\u51faEpistemic Logic of Cops and Robbers (ELCR)\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u6001\u903b\u8f91\u548c\u52a8\u6001\u64cd\u4f5c\u7b26\u5206\u6790\u6e38\u620f\u4e2d\u7684\u4fe1\u606f\u66f4\u65b0\u3002", "result": "\u5b9e\u73b0\u4e86\u73a9\u5bb6\u4e92\u52a8\u7684\u81ea\u52a8\u5316\u8ddf\u8e2a\u548c\u4fe1\u606f\u66f4\u65b0\u673a\u5236\uff0c\u7814\u7a76\u4e86ELCR\u7684\u516c\u7406\u5316\u548c\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "ELCR\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684Cops and Robbers\u6e38\u620f\u63d0\u4f9b\u4e86\u9996\u4e2a\u5f62\u5f0f\u5316\u5206\u6790\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.00198", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00198", "abs": "https://arxiv.org/abs/2508.00198", "authors": ["Cleyton Magalhaes", "Italo Santos", "Brody Stuart-Verner", "Ronnie de Souza Santos"], "title": "Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems", "comment": null, "summary": "Background: Software systems powered by large language models are becoming a\nroutine part of everyday technologies, supporting applications across a wide\nrange of domains. In software engineering, many studies have focused on how\nLLMs support tasks such as code generation, debugging, and documentation.\nHowever, there has been limited focus on how full systems that integrate LLMs\nare tested during development. Aims: This study explores how LLM-powered\nsystems are tested in the context of real-world application development.\nMethod: We conducted an exploratory case study using 99 individual reports\nwritten by students who built and deployed LLM-powered applications as part of\na university course. Each report was independently analyzed using thematic\nanalysis, supported by a structured coding process. Results: Testing strategies\ncombined manual and automated methods to evaluate both system logic and model\nbehavior. Common practices included exploratory testing, unit testing, and\nprompt iteration. Reported challenges included integration failures,\nunpredictable outputs, prompt sensitivity, hallucinations, and uncertainty\nabout correctness. Conclusions: Testing LLM-powered systems required\nadaptations to traditional verification methods, blending source-level\nreasoning with behavior-aware evaluations. These findings provide evidence on\nthe practical context of testing generative components in software systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u73b0\u5b9e\u5e94\u7528\u5f00\u53d1\u4e2d\u5982\u4f55\u6d4b\u8bd5\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7cfb\u7edf\uff0c\u53d1\u73b0\u6d4b\u8bd5\u7b56\u7565\u7ed3\u5408\u4e86\u624b\u52a8\u548c\u81ea\u52a8\u65b9\u6cd5\uff0c\u5e76\u9762\u4e34\u96c6\u6210\u5931\u8d25\u3001\u8f93\u51fa\u4e0d\u53ef\u9884\u6d4b\u7b49\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u80cc\u666f\u662fLLM\u7cfb\u7edf\u5728\u65e5\u5e38\u6280\u672f\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5bf9\u5176\u6d4b\u8bd5\u65b9\u6cd5\u7684\u5173\u6ce8\u6709\u9650\u3002\u76ee\u6807\u662f\u63a2\u7d22\u5b9e\u9645\u5f00\u53d1\u4e2dLLM\u7cfb\u7edf\u7684\u6d4b\u8bd5\u5b9e\u8df5\u3002", "method": "\u901a\u8fc7\u5206\u679099\u4efd\u5b66\u751f\u62a5\u544a\uff0c\u91c7\u7528\u4e3b\u9898\u5206\u6790\u548c\u7ed3\u6784\u5316\u7f16\u7801\u8fdb\u884c\u63a2\u7d22\u6027\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6d4b\u8bd5\u7b56\u7565\u7ed3\u5408\u624b\u52a8\u4e0e\u81ea\u52a8\u65b9\u6cd5\uff0c\u5e38\u89c1\u5b9e\u8df5\u5305\u62ec\u63a2\u7d22\u6027\u6d4b\u8bd5\u3001\u5355\u5143\u6d4b\u8bd5\u548c\u63d0\u793a\u8fed\u4ee3\u3002\u6311\u6218\u5305\u62ec\u96c6\u6210\u5931\u8d25\u3001\u8f93\u51fa\u4e0d\u53ef\u9884\u6d4b\u7b49\u3002", "conclusion": "\u6d4b\u8bd5LLM\u7cfb\u7edf\u9700\u8c03\u6574\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7ed3\u5408\u6e90\u4ee3\u7801\u63a8\u7406\u548c\u884c\u4e3a\u611f\u77e5\u8bc4\u4f30\uff0c\u4e3a\u751f\u6210\u7ec4\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u5b9e\u8df5\u53c2\u8003\u3002"}}
{"id": "2508.00534", "categories": ["cs.PL", "cs.CL", "D.3.2; F.3.2; D.3.1"], "pdf": "https://arxiv.org/pdf/2508.00534", "abs": "https://arxiv.org/abs/2508.00534", "authors": ["Mikel Vandeloise"], "title": "Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations", "comment": "Preprint submitted to the Journal of Object Technology on July 29,\n  2025. Data available upon request until peer-review is completed", "summary": "The rise of multi-paradigm languages challenges traditional classification\nmethods, leading to practical software engineering issues like interoperability\ndefects. This systematic literature review (SLR) maps the formal foundations of\nprogramming paradigms. Our objective is twofold: (1) to assess the state of the\nart of classification formalisms and their limitations, and (2) to identify the\nconceptual primitives and mathematical frameworks for a more powerful,\nreconstructive approach.\n  Based on a synthesis of 74 primary studies, we find that existing taxonomies\nlack conceptual granularity, a unified formal basis, and struggle with hybrid\nlanguages. In response, our analysis reveals a strong convergence toward a\ncompositional reconstruction of paradigms. This approach identifies a minimal\nset of orthogonal, atomic primitives and leverages mathematical frameworks,\npredominantly Type theory, Category theory and Unifying Theories of Programming\n(UTP), to formally guarantee their compositional properties.\n  We conclude that the literature reflects a significant intellectual shift\naway from classification towards these promising formal, reconstructive\nframeworks. This review provides a map of this evolution and proposes a\nresearch agenda for their unification.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u591a\u8303\u5f0f\u8bed\u8a00\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u5b50\u539f\u8bed\u548c\u6570\u5b66\u6846\u67b6\u7684\u91cd\u6784\u65b9\u6cd5\u3002", "motivation": "\u591a\u8303\u5f0f\u8bed\u8a00\u7684\u5174\u8d77\u6311\u6218\u4e86\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\uff0c\u5bfc\u81f4\u4e92\u64cd\u4f5c\u6027\u7f3a\u9677\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u57fa\u4e8e74\u9879\u4e3b\u8981\u7814\u7a76\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u73b0\u6709\u5206\u7c7b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u7c7b\u578b\u7406\u8bba\u3001\u8303\u7574\u7406\u8bba\u548c\u7edf\u4e00\u7f16\u7a0b\u7406\u8bba\u7684\u91cd\u6784\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u5206\u7c7b\u65b9\u6cd5\u7f3a\u4e4f\u6982\u5ff5\u7c92\u5ea6\uff0c\u800c\u91cd\u6784\u65b9\u6cd5\u901a\u8fc7\u6b63\u4ea4\u539f\u5b50\u539f\u8bed\u548c\u6570\u5b66\u6846\u67b6\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "conclusion": "\u6587\u732e\u8868\u660e\uff0c\u7814\u7a76\u8d8b\u52bf\u6b63\u4ece\u5206\u7c7b\u8f6c\u5411\u91cd\u6784\u6846\u67b6\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u4e00\u8fd9\u4e9b\u6846\u67b6\u7684\u7814\u7a76\u8bae\u7a0b\u3002"}}
{"id": "2508.00014", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00014", "abs": "https://arxiv.org/abs/2508.00014", "authors": ["Isa Vialard"], "title": "Deciding the Value of Two-Clock Almost Non-Zeno Weighted Timed Games", "comment": null, "summary": "The Value Problem for weighted timed games (wtgs) consists in determining,\ngiven a two-player weighted timed game with a reachability objective and a\nrational threshold, whether or not the value of the game exceeds the threshold.\nWhen restrained to wtgs with non-negative weight, this problem is known to be\nundecidable for weighted timed games with three or more clocks, and decidable\nfor one-clock wtgs. The Value Problem for two-clock non-negative wtgs, which\nremained stubbornly open for a decade, was recently shown to be undecidable. In\nthis article, we show that the Value Problem is decidable when considering\ntwo-clock almost non-Zeno wtgs.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\uff08wtgs\uff09\u7684\u503c\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u4e24\u65f6\u949f\u51e0\u4e4e\u975eZeno wtgs\u7684\u53ef\u5224\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\u7684\u503c\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4e24\u65f6\u949f\u975e\u8d1fwtgs\u7684\u672a\u89e3\u95ee\u9898\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e24\u65f6\u949f\u51e0\u4e4e\u975eZeno wtgs\u7684\u7279\u6027\uff0c\u5e76\u8bc1\u660e\u5176\u503c\u95ee\u9898\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u65f6\u949f\u51e0\u4e4e\u975eZeno wtgs\u7684\u503c\u95ee\u9898\u662f\u53ef\u5224\u5b9a\u7684\u3002", "conclusion": "\u4e3a\u52a0\u6743\u5b9a\u65f6\u6e38\u620f\u7684\u503c\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u6269\u5c55\u4e86\u53ef\u5224\u5b9a\u6027\u7684\u8303\u56f4\u3002"}}
{"id": "2508.00244", "categories": ["cs.SE", "cs.PL", "D.3.2; D.2.11; D.2.13"], "pdf": "https://arxiv.org/pdf/2508.00244", "abs": "https://arxiv.org/abs/2508.00244", "authors": ["Briza Mel Dias de Sousa", "Renato Cordeiro Ferreira", "Alfredo Goldman"], "title": "Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems", "comment": "11 pages, 16 figures (1 table, 3 diagrams, 5 graphics, 7 listings),\n  submitted to CTICQS capstone project competition at SBQS 2025", "summary": "After decades of dominance by object-oriented programming (OOP), functional\nprogramming (FP) is gaining increasing attention in the software industry. This\nstudy compares the impact of OOP and FP on the architectural characteristics of\nsoftware systems. For that, it examines the design and implementation of a\nDigital Wallet system, developed in Kotlin (representing OOP) and Scala\n(representing FP). The comparison is made through both qualitative and\nquantitative analyses to explore how each paradigm influences the system's\narchitectural characteristics. The self-ethnographic qualitative analysis\nprovides a side-by-side comparison of both implementations, revealing the\nperspective of those writing such code. The survey-based quantitative analysis\ngathers feedback from developers with diverse backgrounds, showing their\nimpressions of those reading this code. Hopefully, these results may be useful\nfor developers or organizations seeking to make more informed decisions about\nwhich paradigm is best suited for their next project.", "AI": {"tldr": "\u6bd4\u8f83\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\uff08FP\uff09\u5bf9\u8f6f\u4ef6\u7cfb\u7edf\u67b6\u6784\u7279\u6027\u7684\u5f71\u54cd\uff0c\u901a\u8fc7Kotlin\uff08OOP\uff09\u548cScala\uff08FP\uff09\u5b9e\u73b0\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\uff0c\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u3002", "motivation": "\u7814\u7a76OOP\u548cFP\u5728\u8f6f\u4ef6\u67b6\u6784\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u9009\u62e9\u66f4\u9002\u5408\u7684\u7f16\u7a0b\u8303\u5f0f\u3002", "method": "\u901a\u8fc7Kotlin\u548cScala\u5b9e\u73b0\u6570\u5b57\u94b1\u5305\u7cfb\u7edf\uff0c\u8fdb\u884c\u5b9a\u6027\uff08\u81ea\u6c11\u65cf\u5fd7\uff09\u548c\u5b9a\u91cf\uff08\u5f00\u53d1\u8005\u8c03\u67e5\uff09\u5206\u6790\u3002", "result": "\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u7f16\u5199\u4ee3\u7801\u7684\u89c6\u89d2\uff0c\u5b9a\u91cf\u5206\u6790\u5c55\u793a\u4e86\u5f00\u53d1\u8005\u5bf9\u4ee3\u7801\u7684\u9605\u8bfb\u4f53\u9a8c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u5728\u9009\u62e9\u7f16\u7a0b\u8303\u5f0f\u65f6\u63d0\u4f9b\u4e86\u53c2\u8003\u4f9d\u636e\u3002"}}
{"id": "2508.00015", "categories": ["cs.LO", "cs.MS"], "pdf": "https://arxiv.org/pdf/2508.00015", "abs": "https://arxiv.org/abs/2508.00015", "authors": ["Matt Kaufmann", "J Strother Moore"], "title": "Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We illustrate the power of partial-encapsulate, showing how it is used in the\nimplementation of floating-point operations in ACL2.", "AI": {"tldr": "\u5c55\u793a\u4e86partial-encapsulate\u5728ACL2\u4e2d\u5b9e\u73b0\u6d6e\u70b9\u8fd0\u7b97\u7684\u5f3a\u5927\u529f\u80fd\u3002", "motivation": "\u63a2\u8ba8partial-encapsulate\u5728ACL2\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u9a8c\u8bc1\u5176\u5728\u5b9e\u73b0\u590d\u6742\u8fd0\u7b97\uff08\u5982\u6d6e\u70b9\u8fd0\u7b97\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528partial-encapsulate\u6280\u672f\uff0c\u5728ACL2\u4e2d\u5b9e\u73b0\u6d6e\u70b9\u8fd0\u7b97\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86partial-encapsulate\u5728\u6d6e\u70b9\u8fd0\u7b97\u5b9e\u73b0\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "partial-encapsulate\u662fACL2\u4e2d\u5b9e\u73b0\u590d\u6742\u8fd0\u7b97\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2508.00253", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00253", "abs": "https://arxiv.org/abs/2508.00253", "authors": ["Moumita Asad", "Rafed Muhammad Yasir", "Armin Geramirad", "Sam Malek"], "title": "Leveraging Large Language Model for Information Retrieval-based Bug Localization", "comment": null, "summary": "Information Retrieval-based Bug Localization aims to identify buggy source\nfiles for a given bug report. While existing approaches -- ranging from vector\nspace models to deep learning models -- have shown potential in this domain,\ntheir effectiveness is often limited by the vocabulary mismatch between bug\nreports and source code. To address this issue, we propose a novel Large\nLanguage Model (LLM) based bug localization approach, called GenLoc. Given a\nbug report, GenLoc leverages an LLM equipped with code-exploration functions to\niteratively analyze the code base and identify potential buggy files. To gather\nbetter context, GenLoc may optionally retrieve semantically relevant files\nusing vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug\nreports from six large-scale Java projects. Experimental results show that\nGenLoc outperforms five state-of-the-art bug localization techniques across\nmultiple metrics, achieving an average improvement of more than 60\\% in\nAccuracy@1.", "AI": {"tldr": "GenLoc\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u8fed\u4ee3\u5206\u6790\u4ee3\u7801\u5e93\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7f3a\u9677\u62a5\u544a\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5\uff08\u4ece\u5411\u91cf\u7a7a\u95f4\u6a21\u578b\u5230\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff09\u7684\u6709\u6548\u6027\u53d7\u9650\u4e8e\u7f3a\u9677\u62a5\u544a\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u8bcd\u6c47\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "GenLoc\u5229\u7528\u914d\u5907\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u7684LLM\uff0c\u8fed\u4ee3\u5206\u6790\u4ee3\u7801\u5e93\u5e76\u8bc6\u522b\u6f5c\u5728\u7f3a\u9677\u6587\u4ef6\uff0c\u8fd8\u53ef\u901a\u8fc7\u5411\u91cf\u5d4c\u5165\u68c0\u7d22\u8bed\u4e49\u76f8\u5173\u6587\u4ef6\u4ee5\u83b7\u53d6\u66f4\u597d\u7684\u4e0a\u4e0b\u6587\u3002", "result": "\u57286\u4e2a\u5927\u578bJava\u9879\u76ee\u76849,000\u591a\u4e2a\u771f\u5b9e\u7f3a\u9677\u62a5\u544a\u4e0a\u6d4b\u8bd5\uff0cGenLoc\u5728\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8e5\u79cd\u6700\u5148\u8fdb\u7684\u7f3a\u9677\u5b9a\u4f4d\u6280\u672f\uff0cAccuracy@1\u5e73\u5747\u63d0\u5347\u8d85\u8fc760%\u3002", "conclusion": "GenLoc\u901a\u8fc7LLM\u548c\u4ee3\u7801\u63a2\u7d22\u529f\u80fd\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.00419", "categories": ["cs.LO", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00419", "abs": "https://arxiv.org/abs/2508.00419", "authors": ["Varun Bharti", "Shashwat Jha", "Dhruv Kumar", "Pankaj Jalote"], "title": "Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers", "comment": "Under Review", "summary": "Loop invariants are essential for proving the correctness of programs with\nloops. Developing loop invariants is challenging, and fully automatic synthesis\ncannot be guaranteed for arbitrary programs. Some approaches have been proposed\nto synthesize loop invariants using symbolic techniques and more recently using\nneural approaches. These approaches are able to correctly synthesize loop\ninvariants only for subsets of standard benchmarks. In this work, we\ninvestigate whether modern, reasoning-optimized large language models can do\nbetter. We integrate OpenAI's O1, O1-mini, and O3-mini into a tightly coupled\ngenerate-and-check pipeline with the Z3 SMT solver, using solver\ncounterexamples to iteratively guide invariant refinement. We use Code2Inv\nbenchmark, which provides C programs along with their formal preconditions and\npostconditions. On this benchmark of 133 tasks, our framework achieves 100%\ncoverage (133 out of 133), outperforming the previous best of 107 out of 133,\nwhile requiring only 1-2 model proposals per instance and 14-55 seconds of\nwall-clock time. These results demonstrate that LLMs possess latent logical\nreasoning capabilities which can help automate loop invariant synthesis. While\nour experiments target C-specific programs, this approach should be\ngeneralizable to other imperative languages.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408Z3\u6c42\u89e3\u5668\u81ea\u52a8\u5408\u6210\u5faa\u73af\u4e0d\u53d8\u5f0f\u7684\u65b9\u6cd5\uff0c\u5728Code2Inv\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u8986\u76d6\u7387\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u4f73\u7ed3\u679c\u3002", "motivation": "\u5faa\u73af\u4e0d\u53d8\u5f0f\u5bf9\u7a0b\u5e8f\u9a8c\u8bc1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u81ea\u52a8\u5408\u6210\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u90e8\u5206\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u56e0\u6b64\u7814\u7a76\u73b0\u4ee3LLM\u662f\u5426\u80fd\u6539\u8fdb\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u5c06OpenAI\u7684O1\u3001O1-mini\u548cO3-mini\u6a21\u578b\u4e0eZ3\u6c42\u89e3\u5668\u7ed3\u5408\uff0c\u901a\u8fc7\u751f\u6210-\u68c0\u67e5\u8fed\u4ee3\u4f18\u5316\u4e0d\u53d8\u5f0f\u3002", "result": "\u5728133\u4e2a\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u8986\u76d6\u7387\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684107/133\uff0c\u4e14\u6bcf\u6b21\u4ec5\u97001-2\u6b21\u6a21\u578b\u63d0\u8bae\u548c14-55\u79d2\u65f6\u95f4\u3002", "conclusion": "LLM\u5177\u6709\u6f5c\u5728\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u81ea\u52a8\u5316\u5faa\u73af\u4e0d\u53d8\u5f0f\u5408\u6210\uff0c\u4e14\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u547d\u4ee4\u5f0f\u8bed\u8a00\u3002"}}
{"id": "2508.00017", "categories": ["cs.LO", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2508.00017", "abs": "https://arxiv.org/abs/2508.00017", "authors": ["Nikolai Sergeev"], "title": "Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation", "comment": "19 pages, 5 figures. Code and interactive HTML proof graphs\n  permanently archived on Zenodo (DOI: 10.5281/zenodo.16408441)", "summary": "We present Generative Logic (GL), a deterministic architecture that begins\nfrom user-supplied axiomatic definitions -- written in a minimalist\nMathematical Programming Language (MPL) -- and systematically explores their\ndeductive neighborhood. Definitions are compiled into a distributed grid of\nsimple Logic Blocks (LBs) that exchange messages; any time several expressions\nunify under an inference rule, a new fact is emitted with full provenance to\nits sources, yielding replayable, auditable proof graphs.\n  A prototype software implementation instantiates the workflow on first-order\nPeano arithmetic. Starting only from the Peano axioms, GL enumerates candidate\nimplications, applies normalization and type filters, and automatically\nreconstructs machine-checkable proofs of foundational arithmetic laws including\nassociativity and commutativity of addition, associativity and commutativity of\nmultiplication, and distributivity. Generated proofs export to navigable HTML\nso that every inference step can be inspected independently.\n  We outline a hardware-software co-design path toward massively parallel\nrealizations and describe prospective integration with probabilistic models\n(e.g., Large Language Models (LLMs)) for autoformalization and conjecture\nseeding. The Python and MPL code to reproduce the Peano experiments, along with\nthe full HTML proof graphs, are available in the project's GitHub repository at\nhttps://github.com/Generative-Logic/GL/tree/35a111ea9ba53afe051703d6050be0c3923e9724\nand are permanently archived at https://doi.org/10.5281/zenodo.16408441. We\ninvite community feedback and collaboration.", "AI": {"tldr": "Generative Logic (GL) \u662f\u4e00\u79cd\u786e\u5b9a\u6027\u67b6\u6784\uff0c\u901a\u8fc7\u7528\u6237\u63d0\u4f9b\u7684\u516c\u7406\u5316\u5b9a\u4e49\uff0c\u7cfb\u7edf\u5730\u63a2\u7d22\u5176\u6f14\u7ece\u90bb\u57df\uff0c\u751f\u6210\u53ef\u91cd\u653e\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc1\u660e\u56fe\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u5f0f\u4ece\u516c\u7406\u51fa\u53d1\uff0c\u91cd\u5efa\u7b97\u672f\u5b9a\u5f8b\u7684\u673a\u5668\u53ef\u68c0\u67e5\u8bc1\u660e\uff0c\u5e76\u63a2\u7d22\u4e0e\u6982\u7387\u6a21\u578b\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u7684\u6f5c\u5728\u96c6\u6210\u3002", "method": "\u5c06\u5b9a\u4e49\u7f16\u8bd1\u4e3a\u5206\u5e03\u5f0f\u903b\u8f91\u5757\u7f51\u683c\uff0c\u901a\u8fc7\u6d88\u606f\u4ea4\u6362\u548c\u7edf\u4e00\u89c4\u5219\u751f\u6210\u65b0\u4e8b\u5b9e\uff0c\u5e76\u5bfc\u51fa\u4e3a\u53ef\u5bfc\u822a\u7684HTML\u8bc1\u660e\u56fe\u3002", "result": "\u6210\u529f\u4ecePeano\u516c\u7406\u51fa\u53d1\uff0c\u81ea\u52a8\u91cd\u5efa\u4e86\u52a0\u6cd5\u3001\u4e58\u6cd5\u7684\u7ed3\u5408\u5f8b\u3001\u4ea4\u6362\u5f8b\u53ca\u5206\u914d\u5f8b\u7684\u8bc1\u660e\u3002", "conclusion": "GL\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u8bc1\u660e\u751f\u6210\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u672a\u6765\u65b9\u5411\uff0c\u9f13\u52b1\u793e\u533a\u53cd\u9988\u4e0e\u5408\u4f5c\u3002"}}
{"id": "2508.00255", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00255", "abs": "https://arxiv.org/abs/2508.00255", "authors": ["Boqi Chen", "Ou Wei", "Bingzhou Zheng", "Gunter Mussbacher"], "title": "Accurate and Consistent Graph Model Generation from Text with Large Language Models", "comment": "Accepted at ACM / IEEE 28th International Conference on Model Driven\n  Engineering Languages and Systems (MODELS 2025)", "summary": "Graph model generation from natural language description is an important task\nwith many applications in software engineering. With the rise of large language\nmodels (LLMs), there is a growing interest in using LLMs for graph model\ngeneration. Nevertheless, LLM-based graph model generation typically produces\npartially correct models that suffer from three main issues: (1) syntax\nviolations: the generated model may not adhere to the syntax defined by its\nmetamodel, (2) constraint inconsistencies: the structure of the model might not\nconform to some domain-specific constraints, and (3) inaccuracy: due to the\ninherent uncertainty in LLMs, the models can include inaccurate, hallucinated\nelements. While the first issue is often addressed through techniques such as\nconstraint decoding or filtering, the latter two remain largely unaddressed.\nMotivated by recent self-consistency approaches in LLMs, we propose a novel\nabstraction-concretization framework that enhances the consistency and quality\nof generated graph models by considering multiple outputs from an LLM. Our\napproach first constructs a probabilistic partial model that aggregates all\ncandidate outputs and then refines this partial model into the most appropriate\nconcrete model that satisfies all constraints. We evaluate our framework on\nseveral popular open-source and closed-source LLMs using diverse datasets for\nmodel generation tasks. The results demonstrate that our approach significantly\nimproves both the consistency and quality of the generated graph models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2aLLM\u8f93\u51fa\u751f\u6210\u66f4\u4e00\u81f4\u548c\u9ad8\u8d28\u91cf\u7684\u56fe\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u56fe\u6a21\u578b\u65f6\u7684\u8bed\u6cd5\u8fdd\u89c4\u3001\u7ea6\u675f\u4e0d\u4e00\u81f4\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u91c7\u7528\u62bd\u8c61-\u5177\u4f53\u5316\u6846\u67b6\uff0c\u805a\u5408\u591a\u4e2aLLM\u8f93\u51fa\u5e76\u4f18\u5316\u4e3a\u6ee1\u8db3\u7ea6\u675f\u7684\u5177\u4f53\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u56fe\u6a21\u578b\u7684\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u751f\u6210\u56fe\u6a21\u578b\u7684\u4e09\u5927\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.00508", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00508", "abs": "https://arxiv.org/abs/2508.00508", "authors": ["Panagiotis Diamantakis", "Thanassis Avgerinos", "Yannis Smaragdakis"], "title": "Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis", "comment": null, "summary": "Over the past two decades, two different types of static analyses have\nemerged as dominant paradigms both in academia and industry: value-flow\nanalysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis\n(e.g., symbolic execution). Despite their individual successes in numerous\napplication fields, the two approaches have remained largely separate; an\nartifact of the simple reality that there is no broadly adopted unifying\nplatform for effortless and efficient integration of symbolic techniques with\nhigh-performance data-flow reasoning.\n  To bridge this gap, we introduce Desyan: a platform for writing program\nanalyses with seamless integration of value-flow and symbolic reasoning. Desyan\nexpands a production-ready Datalog fixpoint engine (Souffl\\'e) with\nfull-fledged SMT solving invoking industry-leading SMT engines. Desyan provides\nconstructs for automatically (and efficiently!) handling typical patterns that\ncome up in program analysis. At the same time, the integration is agnostic with\nrespect to the solving technology, and supports Datalog-native symbolic\nreasoning, via a bottom-up algebraic reasoning module.\n  The result is an engine that allows blending different kinds of reasoning, as\nneeded for the underlying analysis. For value-flow analysis, the engine is the\nbest-in-class Datalog evaluator (often by a factor of over 20x in execution\ntime); for applications that require full SMT (e.g., a concolic execution\nengine or other symbolic evaluator that needs to solve arbitrarily complex\nconditions), the engine is leveraging the leading SMT solvers; for lightweight\nsymbolic evaluation (e.g., solving simple conditionals in the context of a\npath-sensitive analysis), the engine can use Datalog-native symbolic reasoning,\nachieving large speedups (often of over 2x) compared to eagerly appealing to an\nSMT solver.", "AI": {"tldr": "Desyan\u5e73\u53f0\u65e0\u7f1d\u6574\u5408\u4e86\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u3002", "motivation": "\u89e3\u51b3\u503c\u6d41\u5206\u6790\u548c\u7b26\u53f7\u5206\u6790\u957f\u671f\u5206\u79bb\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u5e73\u53f0\u3002", "method": "\u6269\u5c55Souffl\u00e9 Datalog\u5f15\u64ce\uff0c\u96c6\u6210SMT\u6c42\u89e3\u5668\uff0c\u652f\u6301\u591a\u79cd\u63a8\u7406\u6a21\u5f0f\u3002", "result": "Desyan\u5728\u503c\u6d41\u5206\u6790\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u7b26\u53f7\u63a8\u7406\u65f6\u901f\u5ea6\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Desyan\u4e3a\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u7edf\u4e00\u5e73\u53f0\u3002"}}
{"id": "2508.00021", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00021", "abs": "https://arxiv.org/abs/2508.00021", "authors": ["Thomas A. Henzinger", "Konstantin Kueffner", "Vasu Singh", "I Sun"], "title": "Alignment Monitoring", "comment": null, "summary": "Formal verification provides assurances that a probabilistic system satisfies\nits specification--conditioned on the system model being aligned with reality.\nWe propose alignment monitoring to watch that this assumption is justified. We\nconsider a probabilistic model well aligned if it accurately predicts the\nbehaviour of an uncertain system in advance. An alignment score measures this\nby quantifying the similarity between the model's predicted and the system's\n(unknown) actual distributions. An alignment monitor observes the system at\nruntime; at each point in time it uses the current state and the model to\npredict the next state. After the next state is observed, the monitor updates\nthe verdict, which is a high-probability interval estimate for the true\nalignment score. We utilize tools from sequential forecasting to construct our\nalignment monitors. Besides a monitor for measuring the expected alignment\nscore, we introduce a differential alignment monitor, designed for comparing\ntwo models, and a weighted alignment monitor, which permits task-specific\nalignment monitoring. We evaluate our monitors experimentally on the PRISM\nbenchmark suite. They are fast, memory-efficient, and detect misalignment\nearly.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u9f50\u76d1\u63a7\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u6982\u7387\u6a21\u578b\u662f\u5426\u4e0e\u5b9e\u9645\u60c5\u51b5\u4e00\u81f4\uff0c\u901a\u8fc7\u9884\u6d4b\u4e0e\u5b9e\u9645\u884c\u4e3a\u7684\u76f8\u4f3c\u6027\u8bc4\u5206\u6765\u8bc4\u4f30\u6a21\u578b\u5bf9\u9f50\u6027\u3002", "motivation": "\u786e\u4fdd\u6982\u7387\u6a21\u578b\u4e0e\u5b9e\u9645\u60c5\u51b5\u4e00\u81f4\uff0c\u4ee5\u63d0\u4f9b\u53ef\u9760\u7684\u9a8c\u8bc1\u7ed3\u679c\u3002", "method": "\u5229\u7528\u987a\u5e8f\u9884\u6d4b\u5de5\u5177\u6784\u5efa\u5bf9\u9f50\u76d1\u63a7\u5668\uff0c\u5305\u62ec\u9884\u671f\u5bf9\u9f50\u8bc4\u5206\u3001\u5dee\u5f02\u5bf9\u9f50\u76d1\u63a7\u548c\u52a0\u6743\u5bf9\u9f50\u76d1\u63a7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u76d1\u63a7\u5668\u5feb\u901f\u3001\u5185\u5b58\u9ad8\u6548\uff0c\u5e76\u80fd\u65e9\u671f\u68c0\u6d4b\u5230\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u5bf9\u9f50\u76d1\u63a7\u5668\u6709\u6548\u9a8c\u8bc1\u6a21\u578b\u4e0e\u5b9e\u9645\u884c\u4e3a\u7684\u4e00\u81f4\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u573a\u666f\u3002"}}
{"id": "2508.00408", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.00408", "abs": "https://arxiv.org/abs/2508.00408", "authors": ["Dong Huang", "Jie M. Zhang", "Mark Harman", "Qianru Zhang", "Mingzhe Du", "See-Kiong Ng"], "title": "Benchmarking LLMs for Unit Test Generation from Real-World Functions", "comment": "Under Review", "summary": "Recently, large language models (LLMs) have shown great promise in automating\nunit test generation, significantly reducing the manual effort required by\ndevelopers. To effectively evaluate the capabilities of LLMs in this domain, it\nis crucial to have a well-designed benchmark that accurately reflects\nreal-world scenarios and mitigates common pitfalls. Existing LLM test\ngeneration benchmarks are limited by two critical drawbacks: data contamination\nand structurally simple function code. As a result, we often cannot rely on the\nvalidity of scientific conclusions drawn from empirical studies using these\nlimited benchmarks. The empirical evidence presented may be biased due to\ncontamination and may fail to generalize beyond toy programs due to structural\nsimplicity.\n  To address these problems, we introduce ULT (UnLeakedTestbench), a new\nbenchmark specifically designed for function-level unit test generation from\nreal-world Python functions. ULT is constructed through a multi-stage curation\nprocess that ensures high cyclomatic complexity and mitigates test case\ncontamination. With 3,909 carefully selected function-level tasks, ULT provides\na more realistic and challenging evaluation of LLMs' test generation\ncapabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT\nwith leaked tests designed to enable a controlled analysis of memorization\nversus reasoning in test generation. Our evaluation results demonstrate that\nULT is significantly more challenging. For example, test cases generated by\nLLMs only achieve 41.32\\%, 45.10\\%, 30.22\\%, and 40.21\\% for accuracy,\nstatement coverage, branch coverage, and mutation score on average for all\nLLMs, respectively. These results are substantially lower than the\ncorresponding metrics on TestEval (91.79\\%, 92.18\\%, 82.04\\%, and 49.69\\%) and\nPLT (47.07\\%, 55.13\\%, 40.07\\%, and 50.80\\%).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ULT\uff08UnLeakedTestbench\uff09\u57fa\u51c6\uff0c\u7528\u4e8e\u66f4\u771f\u5b9e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u7b80\u5355\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u6d4b\u8bd5\u751f\u6210\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u7ed3\u6784\u8fc7\u4e8e\u7b80\u5355\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u79d1\u5b66\u7ed3\u8bba\u7684\u53ef\u9760\u6027\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u591a\u9636\u6bb5\u7b5b\u9009\u8fc7\u7a0b\u6784\u5efaULT\u57fa\u51c6\uff0c\u5305\u542b3,909\u4e2a\u9ad8\u590d\u6742\u5ea6\u7684\u771f\u5b9ePython\u51fd\u6570\u4efb\u52a1\uff0c\u5e76\u5f15\u5165PLT\u57fa\u51c6\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "ULT\u57fa\u51c6\u663e\u8457\u66f4\u5177\u6311\u6218\u6027\uff0cLLM\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u5728\u51c6\u786e\u7387\u3001\u8bed\u53e5\u8986\u76d6\u7387\u3001\u5206\u652f\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5206\u6570\u4e0a\u8868\u73b0\u660e\u663e\u4f4e\u4e8e\u5176\u4ed6\u57fa\u51c6\u3002", "conclusion": "ULT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u771f\u5b9e\u548c\u4e25\u683c\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8861\u91cfLLM\u5728\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\u3002"}}
{"id": "2508.00772", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00772", "abs": "https://arxiv.org/abs/2508.00772", "authors": ["Md Imranur Rahman Akib", "Fathima Binthe Muhammed", "Umit Saha", "Md Fazlul Karim Patwary", "Mehrin Anannya", "Md Alomgeer Hussein", "Md Biplob Hosen"], "title": "From Code to Career: Assessing Competitive Programmers for Industry Placement", "comment": null, "summary": "In today's fast-paced tech industry, there is a growing need for tools that\nevaluate a programmer's job readiness based on their coding performance. This\nstudy focuses on predicting the potential of Codeforces users to secure various\nlevels of software engineering jobs. The primary objective is to analyze how a\nuser's competitive programming activity correlates with their chances of\nobtaining positions, ranging from entry-level roles to jobs at major tech\ncompanies. We collect user data using the Codeforces API, process key\nperformance metrics, and build a prediction model using a Random Forest\nclassifier. The model categorizes users into four levels of employability,\nranging from those needing further development to those ready for top-tier tech\njobs. The system is implemented using Flask and deployed on Render for\nreal-time predictions. Our evaluation demonstrates that the approach\neffectively distinguishes between different skill levels based on coding\nproficiency and participation. This work lays a foundation for the use of\nmachine learning in career assessment and could be extended to predict job\nreadiness in broader technical fields.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790Codeforces\u7528\u6237\u7684\u7f16\u7a0b\u7ade\u8d5b\u8868\u73b0\uff0c\u9884\u6d4b\u5176\u5728\u4e0d\u540c\u7ea7\u522b\u8f6f\u4ef6\u5de5\u7a0b\u804c\u4f4d\u4e2d\u7684\u5c31\u4e1a\u6f5c\u529b\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u5206\u7c7b\u6a21\u578b\u3002", "motivation": "\u5feb\u901f\u53d1\u5c55\u7684\u79d1\u6280\u884c\u4e1a\u9700\u8981\u8bc4\u4f30\u7a0b\u5e8f\u5458\u5c31\u4e1a\u6f5c\u529b\u7684\u5de5\u5177\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u7f16\u7a0b\u7ade\u8d5b\u8868\u73b0\u4e0e\u5c31\u4e1a\u673a\u4f1a\u4e4b\u95f4\u7684\u5173\u8054\u3002", "method": "\u4f7f\u7528Codeforces API\u6536\u96c6\u7528\u6237\u6570\u636e\uff0c\u5904\u7406\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u5e76\u5229\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u6784\u5efa\u9884\u6d4b\u6a21\u578b\uff0c\u5c06\u7528\u6237\u5206\u4e3a\u56db\u4e2a\u5c31\u4e1a\u80fd\u529b\u7b49\u7ea7\u3002", "result": "\u6a21\u578b\u80fd\u6709\u6548\u533a\u5206\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\uff0c\u7cfb\u7edf\u901a\u8fc7Flask\u5b9e\u73b0\u5e76\u90e8\u7f72\u5728Render\u4e0a\uff0c\u652f\u6301\u5b9e\u65f6\u9884\u6d4b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u673a\u5668\u5b66\u4e60\u5728\u804c\u4e1a\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f3\u66f4\u5e7f\u6cdb\u7684\u6280\u672f\u9886\u57df\u3002"}}
{"id": "2508.00151", "categories": ["cs.LO", "cs.GT", "03B70, 91A44, 91A05, 68Q10", "F.1.1; F.4.1; F.3.1; I.2.3"], "pdf": "https://arxiv.org/pdf/2508.00151", "abs": "https://arxiv.org/abs/2508.00151", "authors": ["Faruk Alpay", "Hamdi Al Alakkad"], "title": "Ordinal Folding Index: A Computable Metric for Self-Referential Semantics", "comment": "13 pages, 2 figures. Introduces the Ordinal Folding Index, a\n  computable ordinal depth metric for self referential statements that unifies\n  fixed point logic with infinite game theory", "summary": "The Ordinal Folding Index (OFI) is a new, fully computable yard-stick that\nmeasures how many rounds of self-reference a statement, protocol or position\nmust unfold before its truth or outcome stabilises. By turning this abstract\n'fold-back' depth into a single ordinal number, OFI forges a direct link\nbetween areas that are usually studied in isolation: the closure stages of\nfixed-point logics, the time-to-win values of infinite parity games, and the\nordinal progressions that calibrate the strength of formal theories. We prove\nthat OFI refines all classical game-theoretic and logical metrics while\nremaining algorithmically enumerable, supply a polynomial-time approximation\nscheme on finite arenas, and show how the index coincides exactly with the\nlength of the shortest winning strategy in the associated evaluation game.\nAlongside the theory we outline five open problems from the completeness of the\ncomputable-ordinal spectrum to the possibility of 'compressing' deep\nself-reference that chart a research programme at the intersection of\ncomputer-aided logic, algorithmic game theory and ordinal analysis. OFI thus\ninvites game theorists and logicians alike to view infinite play, transfinite\ninduction and reflective reasoning through a single, intuitive lens, opening\ncommon ground for techniques.", "AI": {"tldr": "OFI\u662f\u4e00\u79cd\u65b0\u7684\u53ef\u8ba1\u7b97\u5ea6\u91cf\uff0c\u7528\u4e8e\u8861\u91cf\u8bed\u53e5\u3001\u534f\u8bae\u6216\u7acb\u573a\u5728\u81ea\u5f15\u7528\u5c55\u5f00\u540e\u5176\u771f\u503c\u6216\u7ed3\u679c\u7a33\u5b9a\u7684\u8f6e\u6570\uff0c\u5c06\u62bd\u8c61\u7684\u201c\u6298\u53e0\u201d\u6df1\u5ea6\u8f6c\u5316\u4e3a\u5e8f\u6570\u3002\u5b83\u8fde\u63a5\u4e86\u56fa\u5b9a\u70b9\u903b\u8f91\u3001\u65e0\u9650\u5947\u5076\u535a\u5f08\u548c\u5f62\u5f0f\u7406\u8bba\u7684\u5e8f\u6570\u5f3a\u5ea6\u6821\u51c6\uff0c\u5e76\u8bc1\u660eOFI\u7ec6\u5316\u7ecf\u5178\u5ea6\u91cf\u4e14\u53ef\u7b97\u6cd5\u679a\u4e3e\u3002", "motivation": "\u7814\u7a76\u81ea\u5f15\u7528\u5c55\u5f00\u7684\u6df1\u5ea6\u5982\u4f55\u5f71\u54cd\u903b\u8f91\u3001\u535a\u5f08\u8bba\u548c\u5f62\u5f0f\u7406\u8bba\u7684\u7a33\u5b9a\u6027\uff0c\u4ee5\u63d0\u4f9b\u7edf\u4e00\u7684\u5ea6\u91cf\u5de5\u5177\u3002", "method": "\u63d0\u51faOrdinal Folding Index\uff08OFI\uff09\uff0c\u5c06\u5176\u4e0e\u56fa\u5b9a\u70b9\u903b\u8f91\u3001\u65e0\u9650\u5947\u5076\u535a\u5f08\u548c\u5f62\u5f0f\u7406\u8bba\u7684\u5e8f\u6570\u5f3a\u5ea6\u6821\u51c6\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u8bc1\u660e\u5176\u7b97\u6cd5\u53ef\u679a\u4e3e\u6027\u548c\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u6027\u3002", "result": "OFI\u7ec6\u5316\u7ecf\u5178\u5ea6\u91cf\uff0c\u7b97\u6cd5\u53ef\u679a\u4e3e\uff0c\u4e14\u5728\u6709\u9650\u7ade\u6280\u573a\u4e0a\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff0c\u4e0e\u8bc4\u4f30\u535a\u5f08\u7684\u6700\u77ed\u83b7\u80dc\u7b56\u7565\u957f\u5ea6\u4e00\u81f4\u3002", "conclusion": "OFI\u4e3a\u65e0\u9650\u535a\u5f08\u3001\u8d85\u9650\u5f52\u7eb3\u548c\u81ea\u53cd\u63a8\u7406\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c6\u89d2\uff0c\u5e76\u63d0\u51fa\u4e86\u4e94\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u4e3a\u8ba1\u7b97\u673a\u8f85\u52a9\u903b\u8f91\u3001\u7b97\u6cd5\u535a\u5f08\u8bba\u548c\u5e8f\u6570\u5206\u6790\u7684\u4ea4\u53c9\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.00462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00462", "abs": "https://arxiv.org/abs/2508.00462", "authors": ["Linus Ververs", "Lutz Prechelt"], "title": "Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory", "comment": null, "summary": "Context: Pair Programming as a work mode is used (occasionally or frequently)\nthroughout professional software development. Objective: Understand what\npower-related phenomena occur in pair programming as it is used in industry;\ngive advice to practitioners on how to do better pair programming. Method:\nAnalyze 22 industrial pair programming sessions using Grounded Theory\nMethodology. Formulate a Grounded Theory on power-related behaviors. Run a\nsurvey with 292 participants about that theory. Use it to demonstrate that the\nphenomena are common. Results: Our theory describes the phenomenon of Power\nGap: a perceived difference in participation opportunities. The theory shows\nthe behaviors that create a Power Gap or result from it. Power Gaps tend to\ndamage knowledge transfer, code quality, and process effi ciency. The survey\nresults show that all concepts from our theory are frequent in practice. They\nalso provide more grounding for concepts that are observable only indirectly.\nConclusions: It is a valuable component of pair programming skill to be able to\navoid Power Gaps. Specifically, pair partners need to avoid Hierarchical\nBehavior (which tends to create or increase a Power Gap) and should perform\nenough Equalizing Behavior (which prevents or reduces a Power Gap).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5de5\u4e1a\u4e2d\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u7684\u6743\u529b\u5dee\u8ddd\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u907f\u514d\u6743\u529b\u5dee\u8ddd\u7684\u5efa\u8bae\u3002", "motivation": "\u7406\u89e3\u5de5\u4e1a\u4e2d\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u6743\u529b\u76f8\u5173\u73b0\u8c61\uff0c\u5e76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u624e\u6839\u7406\u8bba\u5206\u679022\u4e2a\u5de5\u4e1a\u7ed3\u5bf9\u7f16\u7a0b\u4f1a\u8bdd\uff0c\u5e76\u8c03\u67e5292\u540d\u53c2\u4e0e\u8005\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u63d0\u51fa\u4e86\u6743\u529b\u5dee\u8ddd\u7406\u8bba\uff0c\u663e\u793a\u5176\u666e\u904d\u6027\u53ca\u5bf9\u77e5\u8bc6\u4f20\u9012\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u907f\u514d\u6743\u529b\u5dee\u8ddd\u662f\u7ed3\u5bf9\u7f16\u7a0b\u7684\u91cd\u8981\u6280\u80fd\uff0c\u9700\u51cf\u5c11\u7b49\u7ea7\u884c\u4e3a\uff0c\u589e\u52a0\u5e73\u7b49\u884c\u4e3a\u3002"}}
{"id": "2508.00575", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00575", "abs": "https://arxiv.org/abs/2508.00575", "authors": ["Camille Bourgaux", "Anton Gnatenko", "Micha\u00ebl Thomazo"], "title": "Analysing Temporal Reasoning in Description Logics Using Formal Grammars", "comment": "This is an extended version of a paper appearing at the 28th European\n  Conference on Artificial Intelligence (ECAI 2025). 20 pages", "summary": "We establish a correspondence between (fragments of)\n$\\mathcal{TEL}^\\bigcirc$, a temporal extension of the $\\mathcal{EL}$\ndescription logic with the LTL operator $\\bigcirc^k$, and some specific kinds\nof formal grammars, in particular, conjunctive grammars (context-free grammars\nequipped with the operation of intersection). This connection implies that\n$\\mathcal{TEL}^\\bigcirc$ does not possess the property of ultimate periodicity\nof models, and further leads to undecidability of query answering in\n$\\mathcal{TEL}^\\bigcirc$, closing a question left open since the introduction\nof $\\mathcal{TEL}^\\bigcirc$. Moreover, it also allows to establish decidability\nof query answering for some new interesting fragments of\n$\\mathcal{TEL}^\\bigcirc$, and to reuse for this purpose existing tools and\nalgorithms for conjunctive grammars.", "AI": {"tldr": "\u8bba\u6587\u5efa\u7acb\u4e86$\\mathcal{TEL}^\\bigcirc$\uff08\u4e00\u79cd\u5e26\u6709LTL\u64cd\u4f5c\u7b26$\\bigcirc^k$\u7684$\\mathcal{EL}$\u63cf\u8ff0\u903b\u8f91\u7684\u65f6\u95f4\u6269\u5c55\uff09\u4e0e\u67d0\u4e9b\u5f62\u5f0f\u6587\u6cd5\uff08\u5982\u5408\u53d6\u6587\u6cd5\uff09\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u5176\u6a21\u578b\u4e0d\u5177\u5907\u6700\u7ec8\u5468\u671f\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u67e5\u8be2\u56de\u7b54\u7684\u4e0d\u53ef\u5224\u5b9a\u6027\u3002\u540c\u65f6\uff0c\u8be5\u7814\u7a76\u4e5f\u4e3a$\\mathcal{TEL}^\\bigcirc$\u7684\u67d0\u4e9b\u7247\u6bb5\u63d0\u4f9b\u4e86\u67e5\u8be2\u56de\u7b54\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u5e76\u5229\u7528\u5408\u53d6\u6587\u6cd5\u7684\u5de5\u5177\u548c\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76$\\mathcal{TEL}^\\bigcirc$\u7684\u6027\u8d28\uff0c\u7279\u522b\u662f\u5176\u6a21\u578b\u7684\u5468\u671f\u6027\u548c\u67e5\u8be2\u56de\u7b54\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u586b\u8865\u4e86\u81ea$\\mathcal{TEL}^\\bigcirc$\u63d0\u51fa\u4ee5\u6765\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5efa\u7acb$\\mathcal{TEL}^\\bigcirc$\u4e0e\u5408\u53d6\u6587\u6cd5\u7b49\u7279\u5b9a\u5f62\u5f0f\u6587\u6cd5\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5206\u6790\u5176\u6a21\u578b\u6027\u8d28\u548c\u67e5\u8be2\u56de\u7b54\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u8bc1\u660e\u4e86$\\mathcal{TEL}^\\bigcirc$\u6a21\u578b\u4e0d\u5177\u5907\u6700\u7ec8\u5468\u671f\u6027\uff0c\u67e5\u8be2\u56de\u7b54\u5728\u8be5\u903b\u8f91\u4e2d\u4e0d\u53ef\u5224\u5b9a\uff0c\u4f46\u67d0\u4e9b\u7247\u6bb5\u5177\u6709\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u89e3\u51b3\u4e86$\\mathcal{TEL}^\\bigcirc$\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u8fd8\u4e3a\u5176\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u7b97\u6cd5\u3002"}}
{"id": "2508.00546", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00546", "abs": "https://arxiv.org/abs/2508.00546", "authors": ["Wenchao Gu", "Zongyi Lyu", "Yanlin Wang", "Hongyu Zhang", "Cuiyun Gao", "Michael R. Lyu"], "title": "SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval", "comment": null, "summary": "Code retrieval aims to provide users with desired code snippets based on\nusers' natural language queries. With the development of deep learning\ntechnologies, adopting pre-trained models for this task has become mainstream.\nConsidering the retrieval efficiency, most of the previous approaches adopt a\ndual-encoder for this task, which encodes the description and code snippet into\nrepresentation vectors, respectively. However, the model structure of the\ndual-encoder tends to limit the model's performance, since it lacks the\ninteraction between the code snippet and description at the bottom layer of the\nmodel during training. To improve the model's effectiveness while preserving\nits efficiency, we propose a framework, which adopts Self-AdaPtive Model\nDistillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts\nthe dual-encoder to narrow the search space and then adopts the cross-encoder\nto improve accuracy. To improve the efficiency of SPENCER, we propose a novel\nmodel distillation technique, which can greatly reduce the inference time of\nthe dual-encoder while maintaining the overall performance. We also propose a\nteaching assistant selection strategy for our model distillation, which can\nadaptively select the suitable teaching assistant models for different\npre-trained models during the model distillation to ensure the model\nperformance. Extensive experiments demonstrate that the combination of\ndual-encoder and cross-encoder improves overall performance compared to solely\ndual-encoder-based models for code retrieval. Besides, our model distillation\ntechnique retains over 98% of the overall performance while reducing the\ninference time of the dual-encoder by 70%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPENCER\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u4ee5\u63d0\u9ad8\u4ee3\u7801\u68c0\u7d22\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u53cc\u7f16\u7801\u5668\u6a21\u578b\u5728\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u5e95\u5c42\u4ea4\u4e92\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "SPENCER\u6846\u67b6\u5148\u4f7f\u7528\u53cc\u7f16\u7801\u5668\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u518d\u7528\u4ea4\u53c9\u7f16\u7801\u5668\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u6a21\u578b\u84b8\u998f\u6280\u672f\u4f18\u5316\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u53cc\u7f16\u7801\u5668\u4e0e\u4ea4\u53c9\u7f16\u7801\u5668\u7684\u7ec4\u5408\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u6a21\u578b\u84b8\u998f\u6280\u672f\u51cf\u5c1170%\u63a8\u7406\u65f6\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u4e8698%\u7684\u6027\u80fd\u3002", "conclusion": "SPENCER\u6846\u67b6\u5728\u4ee3\u7801\u68c0\u7d22\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e0e\u9ad8\u51c6\u786e\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2508.00613", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00613", "abs": "https://arxiv.org/abs/2508.00613", "authors": ["Benedikt Maderbacher", "Roderick Bloem"], "title": "Parameterized Infinite-State Reactive Synthesis", "comment": null, "summary": "We propose a method to synthesize a parameterized infinite-state systems that\ncan be instantiated for different parameter values. The specification is given\nin a parameterized temporal logic that allows for data variables as well as\nparameter variables that encode properties of the environment. Our synthesis\nmethod runs in a counterexample-guided loop consisting of four main steps:\nFirst, we use existing techniques to synthesize concrete systems for some small\nparameter instantiations. Second, we generalize the concrete systems into a\nparameterized program. Third, we create a proof candidate consisting of an\ninvariant and a ranking function. Fourth, we check the proof candidate for\nconsistency with the program. If the proof succeeds, the parameterized program\nis valid. Otherwise, we identify a parameter value for which the proof fails\nand add a new concrete instance to step one. To generalize programs and create\nproof candidates, we use a combination of anti-unification and syntax-guided\nsynthesis to express syntactic differences between programs as functions of the\nparameters. We evaluate our approach on examples from the literature that have\nbeen extended with parameters as well as new problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u53c2\u6570\u5316\u65e0\u9650\u72b6\u6001\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u4f8b\u5f15\u5bfc\u5faa\u73af\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u53c2\u6570\u5316\u7cfb\u7edf\u7684\u5408\u6210\u95ee\u9898\uff0c\u4f7f\u5176\u80fd\u9002\u5e94\u4e0d\u540c\u53c2\u6570\u503c\uff0c\u5e76\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002", "method": "\u91c7\u7528\u53cd\u4f8b\u5f15\u5bfc\u5faa\u73af\uff0c\u5305\u62ec\u5177\u4f53\u7cfb\u7edf\u5408\u6210\u3001\u53c2\u6570\u5316\u7a0b\u5e8f\u6cdb\u5316\u3001\u8bc1\u660e\u5019\u9009\u751f\u6210\u53ca\u9a8c\u8bc1\u56db\u4e2a\u6b65\u9aa4\u3002", "result": "\u65b9\u6cd5\u5728\u6587\u732e\u6848\u4f8b\u548c\u65b0\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6210\u529f\u5408\u6210\u5e76\u9a8c\u8bc1\u53c2\u6570\u5316\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\u3002"}}
{"id": "2508.00593", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00593", "abs": "https://arxiv.org/abs/2508.00593", "authors": ["Shuyao Jiang", "Jiazhen Gu", "Wujie Zheng", "Yangfan Zhou", "Michael R. Lyu"], "title": "Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System", "comment": "Accepted by the 19th ACM/IEEE International Symposium on Empirical\n  Software Engineering and Measurement (ESEM 2025)", "summary": "Background: It has long been suggested that user feedback, typically written\nin natural language by end-users, can help issue detection. However, for\nlarge-scale online service systems that receive a tremendous amount of\nfeedback, it remains a challenging task to identify severe issues from user\nfeedback. Aims: To develop a better feedback-based issue detection approach, it\nis crucial first to gain a comprehensive understanding of the characteristics\nof user feedback in real production systems. Method: In this paper, we conduct\nan empirical study on 50,378,766 user feedback items from six real-world\nservices in a one-billion-user online service system. We first study what users\nprovide in their feedback. We then examine whether certain features of feedback\nitems can be good indicators of severe issues. Finally, we investigate whether\nadopting machine learning techniques to analyze user feedback is reasonable.\nResults: Our results show that a large proportion of user feedback provides\nirrelevant information about system issues. As a result, it is crucial to\nfilter out issue-irrelevant information when processing user feedback.\nMoreover, we find severe issues that cannot be easily detected based solely on\nuser feedback characteristics. Finally, we find that the distributions of the\nfeedback topics in different time intervals are similar. This confirms that\ndesigning machine learning-based approaches is a viable direction for better\nanalyzing user feedback. Conclusions: We consider that our findings can serve\nas an empirical foundation for feedback-based issue detection in large-scale\nservice systems, which sheds light on the design and implementation of\npractical issue detection approaches.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u89c4\u6a21\u7528\u6237\u53cd\u9988\u6570\u636e\uff0c\u53d1\u73b0\u8fc7\u6ee4\u65e0\u5173\u4fe1\u606f\u5bf9\u95ee\u9898\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u9a8c\u8bc1\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u7406\u89e3\u7528\u6237\u53cd\u9988\u5728\u5927\u578b\u5728\u7ebf\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u7279\u6027\uff0c\u4ee5\u6539\u8fdb\u57fa\u4e8e\u53cd\u9988\u7684\u95ee\u9898\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5bf9\u6765\u81ea6\u4e2a\u5b9e\u9645\u670d\u52a1\u768450,378,766\u6761\u7528\u6237\u53cd\u9988\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u5185\u5bb9\u3001\u7279\u5f81\u4e0e\u95ee\u9898\u5173\u8054\u6027\u3002", "result": "\u5927\u90e8\u5206\u53cd\u9988\u4e0e\u7cfb\u7edf\u95ee\u9898\u65e0\u5173\uff0c\u67d0\u4e9b\u95ee\u9898\u96be\u4ee5\u901a\u8fc7\u53cd\u9988\u7279\u5f81\u76f4\u63a5\u68c0\u6d4b\uff0c\u53cd\u9988\u4e3b\u9898\u5206\u5e03\u7a33\u5b9a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5927\u89c4\u6a21\u670d\u52a1\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u53cd\u9988\u7684\u95ee\u9898\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u652f\u6301\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.00653", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00653", "abs": "https://arxiv.org/abs/2508.00653", "authors": ["Luc\u00eda G\u00f3mez \u00c1lvarez", "Sebastian Rudolph"], "title": "Putting Perspective into OWL [sic]: Complexity-Neutral Standpoint Reasoning for Ontology Languages via Monodic S5 over Counting Two-Variable First-Order Logic (Extended Version with Appendix)", "comment": null, "summary": "Standpoint extensions of knowledge representation formalisms have been\nrecently introduced as a means to incorporate multi-perspective modelling and\nreasoning through modal operators that attribute pieces of knowledge to\nspecific entities or agents. In these extensions, the integration between\nconceptual modelling and perspective annotations can vary in strength, with\nmonodic standpoint extensions offering a well-balanced approach. They allow for\nadvanced modelling features, such as the expression of rigid concepts, while\nmaintaining desirable reasoning complexity.\n  We consider the extension of C2--the counting two-variable fragment of\nfirst-order logic--by monodic standpoints. At the heart of our work is a\npolynomial-time translation of formulas in this extended formalism into\nstandard, standpoint-free C2, a result that relies on intricate model-theoretic\narguments. Thanks to this translation, the satisfiability problem remains at\nthe same complexity level: NExpTime-complete, as in plain C2. Since our\nformalism subsumes monodic S5 over C2, this result also marks a substantial\nadvancement in the study of first-order modal logics.\n  From a practical standpoint, this means that highly expressive description\nlogics such as SHOIQBs and SROIQBs--which underpin the widely adopted OWL 1 and\nOWL 2 ontology languages standardised by the W3C--can be extended with monodic\nstandpoints without increasing the standard reasoning complexity.\n  We further prove that NExpTime-hardness arises even in significantly less\nexpressive description logics, as long as they include both nominals and\nmonodic standpoints. Moreover, we show that if the monodicity restriction is\nrelaxed even slightly in the presence of inverse roles, functionality, and\nnominals, the satisfiability problem becomes undecidable.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u77e5\u8bc6\u8868\u793a\u5f62\u5f0f\u7684\u591a\u89c6\u89d2\u6269\u5c55\uff0c\u7279\u522b\u662f\u5355\u5b50\u89c6\u89d2\u6269\u5c55\u5728C2\u903b\u8f91\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u590d\u6742\u5ea6\u4e0d\u53d8\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u95ee\u9898\u4f1a\u53d8\u5f97\u4e0d\u53ef\u5224\u5b9a\u3002", "motivation": "\u7814\u7a76\u591a\u89c6\u89d2\u5efa\u6a21\u548c\u63a8\u7406\u7684\u9700\u6c42\uff0c\u901a\u8fc7\u6a21\u6001\u7b97\u5b50\u5c06\u77e5\u8bc6\u5f52\u56e0\u4e8e\u7279\u5b9a\u5b9e\u4f53\u6216\u4ee3\u7406\uff0c\u4ee5\u589e\u5f3a\u77e5\u8bc6\u8868\u793a\u7684\u7075\u6d3b\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u591a\u9879\u5f0f\u65f6\u95f4\u7ffb\u8bd1\u5c06\u5355\u5b50\u89c6\u89d2\u6269\u5c55\u7684C2\u903b\u8f91\u516c\u5f0f\u8f6c\u6362\u4e3a\u6807\u51c6C2\u903b\u8f91\uff0c\u5229\u7528\u6a21\u578b\u8bba\u8bba\u8bc1\u4fdd\u6301\u590d\u6742\u5ea6\u4e0d\u53d8\u3002", "result": "\u6269\u5c55\u540e\u7684\u903b\u8f91\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u590d\u6742\u5ea6\u4ecd\u4e3aNExpTime\u5b8c\u5168\uff0c\u4e14\u9002\u7528\u4e8e\u9ad8\u8868\u8fbe\u63cf\u8ff0\u903b\u8f91\u5982SHOIQBs\u548cSROIQBs\u3002", "conclusion": "\u5355\u5b50\u89c6\u89d2\u6269\u5c55\u5728\u4fdd\u6301\u63a8\u7406\u590d\u6742\u5ea6\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u653e\u677e\u5355\u5b50\u6027\u9650\u5236\u4f1a\u5bfc\u81f4\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u3002"}}
{"id": "2508.00630", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00630", "abs": "https://arxiv.org/abs/2508.00630", "authors": ["Khaled Ahmed", "Jialing Song", "Boqi Chen", "Ou Wei", "Bingzhou Zheng"], "title": "MCeT: Behavioral Model Correctness Evaluation using Large Language Models", "comment": "MODELS 2025", "summary": "Behavioral model diagrams, e.g., sequence diagrams, are an essential form of\ndocumentation that are typically designed by system engineers from requirements\ndocumentation, either fully manually or assisted by design tools. With the\ngrowing use of Large Language Models (LLM) as AI modeling assistants, more\nautomation will be involved in generating diagrams. This necessitates the\nadvancement of automatic model correctness evaluation tools. Such a tool can be\nused to evaluate both manually and AI automatically generated models; to\nprovide feedback to system engineers, and enable AI assistants to self-evaluate\nand self-enhance their generated models.\n  In this paper, we propose MCeT, the first fully automated tool to evaluate\nthe correctness of a behavioral model, sequence diagrams in particular, against\nits corresponding requirements text and produce a list of issues that the model\nhas. We utilize LLMs for the correctness evaluation tasks as they have shown\noutstanding natural language understanding ability. However, we show that\ndirectly asking an LLM to compare a diagram to requirements finds less than 35%\nof issues that experienced engineers can find. We propose to supplement the\ndirect check with a fine-grained, multi-perspective approach; we split the\ndiagram into atomic, non-divisible interactions, and split the requirements\ntext into atomic, self-contained items. We compare the diagram with atomic\nrequirements and each diagram-atom with the requirements. We also propose a\nself-consistency checking approach that combines perspectives to mitigate LLM\nhallucinated issues. Our combined approach improves upon the precision of the\ndirect approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,\nthe approach finds 90% more issues that the experienced engineers found than\nthe direct approach, and reports an average of 6 new issues per diagram.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMCeT\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30\u884c\u4e3a\u6a21\u578b\uff08\u5982\u987a\u5e8f\u56fe\uff09\u7684\u6b63\u786e\u6027\uff0c\u5e76\u751f\u6210\u95ee\u9898\u5217\u8868\u3002\u901a\u8fc7\u7ed3\u5408\u7ec6\u7c92\u5ea6\u591a\u89c6\u89d2\u65b9\u6cd5\u548c\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u95ee\u9898\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728AI\u5efa\u6a21\u8f85\u52a9\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u6a21\u578b\u6b63\u786e\u6027\u8bc4\u4f30\u5de5\u5177\u6765\u652f\u6301\u5de5\u7a0b\u5e08\u548cAI\u52a9\u624b\u3002", "method": "MCeT\u5c06\u56fe\u8868\u548c\u9700\u6c42\u6587\u672c\u5206\u89e3\u4e3a\u539f\u5b50\u7ea7\u5143\u7d20\uff0c\u91c7\u7528\u591a\u89c6\u89d2\u6bd4\u8f83\u548c\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u7ed3\u5408LLM\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06\u76f4\u63a5\u68c0\u67e5\u7684\u7cbe\u5ea6\u4ece0.58\u63d0\u5347\u81f30.81\uff0c\u5e76\u68c0\u6d4b\u5230\u6bd4\u76f4\u63a5\u65b9\u6cd5\u591a90%\u7684\u95ee\u9898\uff0c\u5e73\u5747\u6bcf\u4e2a\u56fe\u8868\u62a5\u544a6\u4e2a\u65b0\u95ee\u9898\u3002", "conclusion": "MCeT\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5206\u6790\u548c\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u884c\u4e3a\u6a21\u578b\u6b63\u786e\u6027\u8bc4\u4f30\u7684\u6548\u679c\uff0c\u4e3a\u5de5\u7a0b\u5e08\u548cAI\u52a9\u624b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2508.00700", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.00700", "abs": "https://arxiv.org/abs/2508.00700", "authors": ["Alfred Santa Molison", "Marcia Moraes", "Glaucia Melo", "Fabio Santos", "Wesley K. G. Assuncao"], "title": "Is LLM-Generated Code More Maintainable \\& Reliable than Human-Written Code?", "comment": "Accepted ESEM2025", "summary": "Background: The rise of Large Language Models (LLMs) in software development\nhas opened new possibilities for code generation. Despite the widespread use of\nthis technology, it remains unclear how well LLMs generate code solutions in\nterms of software quality and how they compare to human-written code. Aims:\nThis study compares the internal quality attributes of LLM-generated and\nhuman-written code. Method: Our empirical study integrates datasets of coding\ntasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and\nSonarQube to assess software quality. The dataset comprises Python code\nsolutions across three difficulty levels: introductory, interview, and\ncompetition. We analyzed key code quality metrics, including maintainability\nand reliability, and the estimated effort required to resolve code issues.\nResults: Our analysis shows that LLM-generated code has fewer bugs and requires\nless effort to fix them overall. Interestingly, fine-tuned models reduced the\nprevalence of high-severity issues, such as blocker and critical bugs, and\nshifted them to lower-severity categories, but decreased the model's\nperformance. In competition-level problems, the LLM solutions sometimes\nintroduce structural issues that are not present in human-written code.\nConclusion: Our findings provide valuable insights into the quality of\nLLM-generated code; however, the introduction of critical issues in more\ncomplex scenarios highlights the need for a systematic evaluation and\nvalidation of LLM solutions. Our work deepens the understanding of the\nstrengths and limitations of LLMs for code generation.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86LLM\u751f\u6210\u4ee3\u7801\u4e0e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u7684\u5185\u90e8\u8d28\u91cf\u5c5e\u6027\uff0c\u53d1\u73b0LLM\u751f\u6210\u7684\u4ee3\u7801\u6574\u4f53\u4e0a\u7f3a\u9677\u66f4\u5c11\u4e14\u4fee\u590d\u6210\u672c\u66f4\u4f4e\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u4e0b\u53ef\u80fd\u5f15\u5165\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u63a2\u8ba8LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8f6f\u4ef6\u8d28\u91cf\u8868\u73b0\uff0c\u5e76\u4e0e\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u8fdb\u884c\u5bf9\u6bd4\u3002", "method": "\u6574\u5408\u7f16\u7801\u4efb\u52a1\u6570\u636e\u96c6\u3001\u4e09\u79cdLLM\u914d\u7f6e\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\uff09\u53caSonarQube\u5de5\u5177\uff0c\u5206\u6790Python\u4ee3\u7801\u8d28\u91cf\u6307\u6807\u3002", "result": "LLM\u751f\u6210\u7684\u4ee3\u7801\u7f3a\u9677\u8f83\u5c11\u4e14\u4fee\u590d\u6210\u672c\u4f4e\uff0c\u4f46\u5fae\u8c03\u6a21\u578b\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u5e76\u5728\u590d\u6742\u573a\u666f\u4e2d\u5f15\u5165\u7ed3\u6784\u6027\u95ee\u9898\u3002", "conclusion": "LLM\u751f\u6210\u4ee3\u7801\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u590d\u6742\u573a\u666f\u9700\u7cfb\u7edf\u8bc4\u4f30\u548c\u9a8c\u8bc1\uff0c\u4ee5\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002"}}
