<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.LO](#cs.LO) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM](https://arxiv.org/abs/2512.05224)
*Miguel de Oliveira Guerreiro*

Main category: cs.PL

TL;DR: NVLang是一个静态类型函数式语言，为BEAM虚拟机提供全面的类型安全，通过代数数据类型编码actor消息协议，在编译时强制执行协议一致性。


<details>
  <summary>Details</summary>
Motivation: Erlang/OTP等基于actor的系统虽然具有高可靠性和并发处理能力，但缺乏静态类型保证，消息协议只能在运行时通过模式匹配检查，导致协议违规只能在生产环境中发现。

Method: NVLang使用代数数据类型编码actor消息协议，每个actor声明其消息词汇表的和类型，类型系统在编译时强制执行协议一致性。引入类型化进程标识符(Pid[T])编码actor期望的协议，以及类型化future(Future[T])提供类型安全的请求-回复模式。扩展Hindley-Milner类型推断来跟踪消息协议。

Result: NVLang消除了整个消息传递错误类别，同时保持了与动态类型替代方案相媲美的简洁语法。实现编译到Core Erlang，可与现有Erlang生态系统无缝互操作。形式化类型系统并提供类型健全性证明草图。

Conclusion: NVLang成功地将全面的类型安全引入BEAM虚拟机，同时保留了actor模型的简单性和强大功能，证明了代数数据类型可以自然地编码actor消息协议，为关键基础设施提供更强的可靠性保证。

Abstract: Actor-based systems like Erlang/OTP power critical infrastructure -- from telecommunications to messaging platforms -- handling millions of concurrent connections with legendary reliability. Yet these systems lack static guarantees about message protocols: processes communicate by sending arbitrary messages that pattern-matched at runtime, deferring protocol violations to production failures.
  We present NVLang, a statically typed functional language that brings comprehensive type safety to the BEAM virtual machine while preserving actor model's simplicity and power. NVLang's central contribution that algebraic data types (ADTs) naturally encode actor message protocols: each actor declares the sum type representing its message vocabulary, and the type system enforces protocol conformance at compile time. We introduce typed process identifiers (Pid[T]) that encode the protocol an actor expects, and typed futures (Future[T]) that provide type-safe request-reply patterns.
  By extending Hindley-Milner type inference to track message protocols, NVLang eliminates an entire class of message-passing errors while maintaining clean syntax that rivals dynamically typed alternatives. Our implementation compiles to Core Erlang, enabling seamless interoperability with the existing Erlang ecosystem. We formalize the type system and provide proof sketches for type soundness, demonstrating that well-typed NVLang programs cannot send messages that violate actor protocols.

</details>


### [2] [Verified VCG and Verified Compiler for Dafny](https://arxiv.org/abs/2512.05262)
*Daniel Nezamabadi,Magnus O. Myreen,Yong Kiam Tan*

Main category: cs.PL

TL;DR: 为Dafny语言开发了经过验证的验证条件生成器和编译器，确保从源代码到机器代码的完整正确性证明链


<details>
  <summary>Details</summary>
Motivation: Dafny语言现有的编译器和验证器存在正确性缺陷，需要建立具有基础正确性保证的工具链

Method: 为Dafny子集定义函数式大步语义，基于此语义在HOL4定理证明器中实现经过验证的验证条件生成器和编译器

Result: 成功开发了能够处理递归方法调用、while循环和数组等复杂特性的验证工具链，可编译到CakeML并最终生成机器代码

Conclusion: 实现了从Dafny程序到机器代码的完整验证链，为Dafny工具提供了基础正确性保证

Abstract: Dafny is a verification-aware programming language that comes with a compiler and static program verifier. However, neither the compiler nor the verifier is proved correct; in fact, soundness bugs have been found in both tools. This paper shows that the aforementioned Dafny tools can be developed with foundational correctness guarantees. We present a functional big-step semantics for an imperative subset of Dafny and, based on this semantics, a verified verification condition generator (VCG) and a verified compiler for Dafny. The subset of Dafny we have formalized includes mutually recursive method calls, while loops, and arrays -- these language features are significant enough to cover challenging examples such as McCarthy's 91 function and array-based programs that are used when teaching Dafny. The verified VCG allows one to prove functional correctness of annotated Dafny programs, while the verified compiler can be used to compile verified Dafny programs to CakeML programs. From there, one can obtain executable machine code via the (already verified) CakeML compiler, all while provably maintaining the functional correctness guarantees that were proved for the source-level Dafny programs. Our work has been mechanized in the HOL4 theorem prover.

</details>


### [3] [Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware](https://arxiv.org/abs/2512.05516)
*Pawel K. Radtke,Tobias Weinzierl*

Main category: cs.PL

TL;DR: 论文评估了在GPU平台上对粒子模拟代码进行AoS到SoA转换与降低精度数据布局的性能，发现不同GPU平台有不同表现，并提出编译器注解来协调转换与GPU卸载。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决粒子模拟中AoS（数组结构）与SoA（结构数组）数据布局在GPU SIMT架构下的性能优化问题，特别是在降低精度和CPU/GPU转换协调方面的挑战。

Method: 引入编译器注解来协调AoS到SoA的转换和精度降低操作，允许程序员控制这些转换与GPU卸载的协调方式，并在多个GPU平台上进行性能评估。

Result: 在Nvidia G200平台上获得了约2.6倍的加速，而AMD MI300A平台表现出更稳健的性能但收益较小，表明不同GPU架构对数据布局转换的响应不同。

Conclusion: 编译器驱动的数据布局转换和精度降低技术适用于广泛的拉格朗日代码，为GPU加速提供了有效的优化方法，但需要针对不同硬件平台进行调优。

Abstract: This study evaluates AoS-to-SoA transformations over reduced-precision data layouts for a particle simulation code on several GPU platforms: We hypothesize that SoA fits particularly well to SIMT, while AoS is the preferred storage format for many Lagrangian codes. Reduced-precision (below IEEE accuracy) is an established tool to address bandwidth constraints, although it remains unclear whether AoS and precision conversions should execute on a CPU or be deployed to a GPU if the compute kernel itself must run on an accelerator. On modern superchips where CPUs and GPUs share (logically) one data space, it is also unclear whether it is advantageous to stream data to the accelerator prior to the calculation, or whether we should let the accelerator transform data on demand, i.e.~work in-place logically. We therefore introduce compiler annotations to facilitate such conversions and to give the programmer the option to orchestrate the conversions in combination with GPU offloading. For some of our compute kernels of interest, Nvidia's G200 platforms yield a speedup of around 2.6 while AMD's MI300A exhibits more robust performance yet profits less. We assume that our compiler-based techniques are applicable to a wide variety of Lagrangian codes and beyond.

</details>


### [4] [Compiling Away the Overhead of Race Detection](https://arxiv.org/abs/2512.05555)
*Alexey Paznikov,Andrey Kogutenko,Yaroslav Osipov,Michael Schwarz,Umang Mathur*

Main category: cs.PL

TL;DR: 通过静态分析消除动态数据竞争检测中的冗余检测点，显著降低运行时开销，平均加速1.34倍


<details>
  <summary>Details</summary>
Motivation: 动态数据竞争检测器的高运行时开销限制了其广泛应用，主要原因是大量内存访问检测中存在冗余检测点

Method: 提出五种静态分析方法：1) 基于内存访问模式、同步和线程创建的跨过程分析，消除可证明无竞争的访问检测；2) 基于支配关系的消除分析，识别并消除报告等价竞争的多余检测点；在LLVM中实现并与ThreadSanitizer集成

Result: 在真实应用测试中，平均获得1.34倍加速，高线程竞争下峰值加速达2.5倍，编译时间增加可忽略，已获ThreadSanitizer维护者接受并正在上游化

Conclusion: 通过静态分析消除冗余检测点能显著降低动态数据竞争检测器的运行时开销，实现完全自动化且不增加开发者负担，已证明在实际应用中有效

Abstract: Dynamic data race detectors are indispensable for flagging concurrency errors in software, but their high runtime overhead limits their adoption. This overhead stems primarily from pervasive instrumentation of memory accesses - a significant fraction of which is redundant. We addresses this inefficiency through a static, compiler-integrated approach that identifies and eliminates redundant instrumentation, drastically reducing the runtime cost of dynamic data race detectors. We introduce a suite of interprocedural static analyses reasoning about memory access patterns, synchronization, and thread creation to eliminate instrumentation for provably race-free accesses and show that the completeness properties of the data race detector are preserved. We further observe that many inserted checks flag a race if and only if a preceding check has already flagged an equivalent race for the same memory location - albeit potentially at a different access. We characterize this notion of equivalence and show that, when limiting reporting to at least one representative for each equivalence class, a further class of redundant checks can be eliminated. We identify such accesses using a novel dominance-based elimination analysis. Based on these two insights, we have implemented five static analyses within the LLVM, integrated with the instrumentation pass of the race detector ThreadSanitizer. Our experimental evaluation on a diverse suite of real-world applications demonstrates that our approach significantly reduces race detection overhead, achieving a geomean speedup of 1.34x, with peak speedups reaching 2.5x under high thread contention. This performance is achieved with a negligible increase in compilation time and, being fully automatic, places no additional burden on developers. Our optimizations have been accepted by the ThreadSanitizer maintainers and are in the process of being upstreamed.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [5] [On the Impact of the Communication Model on Realisability](https://arxiv.org/abs/2512.05609)
*Cinzia Di Giusto,Etienne Lozes,Pascal Urso*

Main category: cs.FL

TL;DR: 该论文为多会话类型(MPST)在不同通信模型下的可实现性和子类型检查提供了统一框架，证明了通信模型影响可实现性但不影响子类型概念。


<details>
  <summary>Details</summary>
Motivation: MPST为分布式系统中的通信协议提供了类型理论基础，但现有的可实现性研究主要集中在点对点语义下，对于基于包、因果有序或同步通信等替代通信模型的理解不足。

Method: 开发了一个统一的框架来推理不同通信模型下的可实现性和子类型，引入了多种决策程序用于子类型检查和可实现性检查。

Result: 证明了通信模型不影响子类型概念但影响可实现性概念，提出的决策程序复杂度从NLOGSPACE到EXPSPACE不等，具体取决于全局类型的可补性和补集大小等假设。

Conclusion: 该研究为MPST在不同通信模型下的可实现性和子类型检查提供了系统化的理论框架和算法工具，填补了现有研究的空白。

Abstract: Multiparty Session Types (MPST) provide a type-theoretic foundation for specifying and verifying communication protocols in distributed systems. MPST rely on the notion of global type which specifies the global behaviour and local types, which are the projections of the global behaviour onto each local participant. A central notion in MPST is realisability - whether local implementations derived from a global specification correctly realise the intended protocol under a given communication model. While realisability has been extensively studied under peer-to-peer semantics, it remains poorly understood in alternative communication models such as bag-based, causally ordered, or synchronous communications. In this paper, we develop a unified framework for reasoning about realisability and subtyping across a spectrum of communication models. We show that the communication model does not impact the notion of subtyping, but that it impacts the notion of realisability. We introduce several decision procedures for subtyping checking and realisability checking with complexities ranging from NLOGSPACE to EXPSPACE depending on the assumptions made on the global types, in particular depending on their complementability and the size of a given complement.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Stellis: A Strategy Language for Purifying Separation Logic Entailments](https://arxiv.org/abs/2512.05159)
*Zhiyi Wang,Xiwei Wu,Yi Fang,Chengtao Li,Hongyi Zhong,Lihan Xie,Qinxiang Cao,Zhenjiang Hu*

Main category: cs.SE

TL;DR: Stellis：一种用于纯化分离逻辑蕴含的策略语言，通过移除空间公式将蕴含简化为纯蕴含，提供强大的匹配机制和灵活的动作描述，自动生成正确性证明。


<details>
  <summary>Details</summary>
Motivation: 自动证明分离逻辑蕴含是验证中的基本挑战。基于规则的方法依赖分离逻辑规则进行自动化，但这些规则语句不足以描述自动化策略，特别是特定场景中内存布局的对齐和消除。

Method: 提出Stellis策略语言，具有强大的匹配机制和灵活的动作描述，能够编码各种策略。引入算法为每个策略生成正确性条件，将策略的正确性简化为其正确性条件的验证。基于机械化的归约正确性定理，原型实现生成整体自动化的正确性证明。

Result: 在229个蕴含的基准测试中（来自标准链表数据结构和微内核内存模块的验证），系统自动纯化了95.6%（219/229）的蕴含，使用了5个库中的98个策略。

Conclusion: Stellis在提供灵活性和便利性的同时，也保持了高效性，能够自动纯化大多数分离逻辑蕴含，并通过生成正确性证明确保策略的正确性。

Abstract: Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.

</details>


### [7] [Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge](https://arxiv.org/abs/2512.05176)
*Brittany Johnson,Erin Reddick,Angela D. R. Smith*

Main category: cs.SE

TL;DR: 该论文提出CIVIQ基准测试，用于评估LLM与社区社会价值观和常识的文化对齐，填补了美国多元文化背景下文化对齐评估的空白。


<details>
  <summary>Details</summary>
Motivation: 当前LLM主要与西方白人叙事对齐，与边缘化文化群体存在错位。虽然已有国家对齐基准（如KorNAT），但美国文化多样性使得国家基准无法实现广泛代表性，需要社区层面的文化对齐评估工具。

Method: 采用复制研究方法，将韩国国家LLM对齐基准KorNAT的开发流程转化为美国语境，开发CIVIQ基准测试，专注于社区社会价值观和常识的对齐评估。

Result: 成功开发了CIVIQ基准测试，为评估LLM与不同社区文化价值观的对齐提供了工具基础，支持文化对齐AI技术的研发。

Conclusion: CIVIQ基准为AI技术文化对齐的研究和实践提供了关键基础，有助于解决LLM与多元文化群体错位的问题，促进更具包容性的人工智能发展。

Abstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as "general purpose" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of "culturally-informed" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.

</details>


### [8] [A Survey of Bugs in AI-Generated Code](https://arxiv.org/abs/2512.05239)
*Ruofan Gao,Amjed Tahir,Peng Liang,Teo Susnjak,Foutse Khomh*

Main category: cs.SE

TL;DR: 该论文系统分析了AI生成代码中的缺陷类型、分布模式及修复策略，为模型改进和质量评估提供参考


<details>
  <summary>Details</summary>
Motivation: AI代码生成模型被广泛使用以提高生产力，但生成的代码存在质量问题和缺陷，这些缺陷可能源自训练数据中的bug，导致开发过程中的信任和维护挑战。目前相关发现分散且缺乏系统性总结，需要全面分析AI生成代码中的错误类型、分布、修复策略及其与特定模型的关联。

Method: 系统性地分析现有AI生成代码文献，建立对生成代码中缺陷和bug的整体理解，提供bug类型和模式的分类，并讨论不同模型生成的代码中的缺陷模式

Result: 建立了AI生成代码中bug的整体理解框架，提供了bug类型和模式的分类体系，分析了不同模型生成的代码中的缺陷分布，并总结了可能的修复和缓解策略

Conclusion: 该研究为未来AI代码生成模型的改进和质量评估提供了系统性的参考框架，有助于理解AI生成代码中缺陷的本质和范围，并为消除生成代码中的bug提供了策略指导

Abstract: Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.

</details>


### [9] [Executing Discrete/Continuous Declarative Process Specifications via Complex Event Processing](https://arxiv.org/abs/2512.05653)
*Stefan Schönig,Leo Poss,Fabrizio Maria Maggi*

Main category: cs.SE

TL;DR: 提出基于复杂事件处理的混合声明式流程执行架构，实现实时执行和强制执行，解决传统BPM无法处理连续传感器数据的问题


<details>
  <summary>Details</summary>
Motivation: 传统业务流程管理（BPM）专注于离散事件，无法有效整合网络物理环境中的连续传感器数据。现有的混合声明式规范虽然使用信号时序逻辑（STL）解决了部分问题，但仅限于监控和事后一致性检查，缺乏实时执行和强制执行能力。

Method: 提出基于复杂事件处理（CEP）的三层执行架构，将STL启发的谓词集成到执行流程中，使系统能够基于连续传感器行为主动触发活动并强制执行流程边界。

Result: 该架构实现了混合声明式模型的实时执行和强制执行，填补了混合规范与操作控制之间的空白，使系统能够主动响应连续传感器数据。

Conclusion: 提出的CEP-based执行架构成功解决了传统BPM在处理网络物理环境中的局限性，实现了混合声明式规范的实时操作控制，为业务流程管理在物联网和工业4.0环境中的应用提供了新的解决方案。

Abstract: Traditional Business Process Management (BPM) focuses on discrete events and fails to incorporate critical continuous sensor data in cyber-physical environments. Hybrid declarative specifications, utilizing Signal Temporal Logic (STL), address this limitation by allowing constraints over both discrete events and real-valued signals. However, existing work has been limited to monitoring and post-hoc conformance checking. This paper introduces a novel Complex Event Processing (CEP)-based execution architecture that enables the real-time execution and enforcement of hybrid declarative models. Our three-layer approach integrates STL-inspired predicates into the execution flow, allowing the system to actively trigger activities and enforce process boundaries based on continuous sensor behavior. This approach bridges the gap between hybrid specification and operational control.

</details>


### [10] [Learning to Code with Context: A Study-Based Approach](https://arxiv.org/abs/2512.05242)
*Uwe M. Borghoff,Mark Minas,Jannis Schopp*

Main category: cs.SE

TL;DR: 该研究探讨了在软件工程教育中整合生成式AI工具的方法，通过在大学游戏开发项目中开展用户研究，分析了学生使用AI工具的模式、效果和挑战，并评估了基于RAG的本地部署LLM助手在项目上下文支持中的表现。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具的快速发展正在改变软件开发方式，软件工程教育需要适应这一变化，确保学生不仅掌握传统开发方法，还能有意义且负责任地使用这些新技术。项目式课程为探索AI辅助工具在实际开发实践中的整合提供了有效环境。

Method: 在大学编程项目中开展用户研究，学生在协作开发电脑游戏过程中使用生成式AI工具。研究分析学生在软件开发各阶段如何使用这些工具，识别最有效的任务类型，并分析遇到的挑战。进一步研究基于检索增强生成(RAG)的本地部署大语言模型助手，该系统通过检索相关文档和源代码来提供项目上下文支持。

Result: 研究深入了解了学生在软件项目中使用生成式AI工具的模式，识别了AI工具最有效的任务类型和常见挑战。对基于RAG的本地LLM助手进行了定性分析，包括模型行为、参数敏感性和常见失败模式，为教育环境中的上下文感知AI支持提供了实证见解。

Conclusion: 研究结果加深了对教育软件项目中上下文感知AI支持的理解，为未来将基于AI的辅助工具整合到软件工程课程中提供了重要参考，有助于设计更有效的AI辅助软件工程教育方案。

Abstract: The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.

</details>


### [11] [Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions](https://arxiv.org/abs/2512.05309)
*Adam Alami,Nathan Cassee,Thiago Rocha Silva,Elda Paja,Neil A. Ernst*

Main category: cs.SE

TL;DR: 研究比较了人类同行评审与LLM辅助代码评审中软件工程师的情感反应、自我调节策略和参与行为，发现LLM辅助评审将重点从情绪管理转向认知负荷管理，建议AI作为支持伙伴减少认知和情感负担。


<details>
  <summary>Details</summary>
Motivation: 代码评审是社交技术实践，但工程师在LLM辅助评审与人类同行评审中的参与方式差异尚不清楚。研究旨在理解工程师在这两种评审模式中的情感反应、参与决策和反馈采纳过程。

Method: 采用两阶段定性研究，涉及20名软件工程师。第一阶段：参与者交换同行评审并访谈情感反应和参与决策。第二阶段：引入符合工程师偏好的提示，探究特征如何影响反应。开发了连接情感自我调节与行为参与和解决的整合模型。

Result: 识别了工程师应对负面反馈的情感自我调节策略：重构、对话调节、回避和防御性。参与通过社会校准进行。在同行评审中，解决轨迹因焦点（个人/双人/团队）和内部意义建构过程而异。LLM辅助评审中情感成本和自我调节需求较低，当LLM反馈符合认知期望时，处理努力减少，采纳倾向更高。

Conclusion: LLM辅助评审将参与重点从情绪管理转向认知负荷管理。AI最适合作为支持伙伴，减少认知和情感负担，同时保留人类责任和同行评审等社交技术活动的社会意义。

Abstract: Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.

</details>


### [12] [WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp](https://arxiv.org/abs/2512.05314)
*Ke Mao,Timotej Kapus,Cons T Åhs,Matteo Marescotti,Daniel Ip,Ákos Hajdu,Sopot Cela,Aparup Banerjee*

Main category: cs.SE

TL;DR: WhatsCode是WhatsApp的领域特定AI开发系统，在25个月部署中显著提升隐私验证覆盖率3.5倍，生成3000+代码变更，识别出两种稳定的人机协作模式，证明组织因素与技术能力同等重要。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助开发工具在工业环境中日益普及，但在合规相关的大规模工业部署方面存在显著研究空白。本研究旨在填补这一空白，通过WhatsApp的实际部署案例提供实证指导。

Method: WhatsCode是一个领域特定的AI开发系统，支持WhatsApp服务（20亿+用户），处理数百万行跨平台代码。系统从针对性隐私自动化演变为集成端到端功能开发和DevOps流程的自主代理工作流，部署周期25个月（2023-2025）。

Result: 自动化隐私验证覆盖率从15%提升至53%（3.5倍增长）；生成3000+个被接受的代码变更，接受率在9%-100%之间；提交692个自动化重构/修复变更，711个框架采用，141个功能开发辅助；bug分类保持86%精确度。识别出两种稳定的人机协作模式：一键部署（60%高置信度变更）和接管-修订（40%复杂决策）。

Conclusion: 组织因素（所有权模型、采用动态、风险管理）与技术能力同样关键；有效的人机协作而非完全自动化驱动可持续业务影响；为合规相关环境中大规模AI工具部署提供实证指导。

Abstract: The deployment of AI-assisted development tools in compliance-relevant, large-scale industrial environments represents significant gaps in academic literature, despite growing industry adoption. We report on the industrial deployment of WhatsCode, a domain-specific AI development system that supports WhatsApp (serving over 2 billion users) and processes millions of lines of code across multiple platforms. Over 25 months (2023-2025), WhatsCode evolved from targeted privacy automation to autonomous agentic workflows integrated with end-to-end feature development and DevOps processes.
  WhatsCode achieved substantial quantifiable impact, improving automated privacy verification coverage 3.5x from 15% to 53%, identifying privacy requirements, and generating over 3,000 accepted code changes with acceptance rates ranging from 9% to 100% across different automation domains. The system committed 692 automated refactor/fix changes, 711 framework adoptions, 141 feature development assists and maintained 86% precision in bug triage. Our study identifies two stable human-AI collaboration patterns that emerged from production deployment: one-click rollout for high-confidence changes (60% of cases) and commandeer-revise for complex decisions (40%). We demonstrate that organizational factors, such as ownership models, adoption dynamics, and risk management, are as decisive as technical capabilities for enterprise-scale AI success. The findings provide evidence-based guidance for large-scale AI tool deployment in compliance-relevant environments, showing that effective human-AI collaboration, not full automation, drives sustainable business impact.

</details>


### [13] [Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models](https://arxiv.org/abs/2512.05887)
*Sairam Vaidya,Marcel Böhme,Loris D'Antoni*

Main category: cs.SE

TL;DR: Germinator：一种基于语法和覆盖引导的模糊测试方法，用于可扩展编译器，能自动从方言规范中提取语法，结合大语言模型生成种子输入，提高测试覆盖率和发现bug


<details>
  <summary>Details</summary>
Motivation: 现代可扩展编译器框架（如MLIR）虽然支持快速创建领域特定语言方言，但扩展性也使得正确性验证更加困难。现有测试方法要么需要为每个方言手动构建种子语料库，要么无法有效针对方言特定功能发现bug

Method: 提出一种方言无关且方言有效的基于语法和覆盖引导的模糊测试方法：1）自动从方言规范中提取语法；2）结合预训练大语言模型自动生成代表性且多样化的种子输入；3）用这些种子引导覆盖引导的模糊测试器

Result: 在6个MLIR项目的91个方言上评估，Germinator生成的种子相比基于语法的基线方法提高行覆盖率10-120%，发现88个先前未知的bug（40个已确认），其中23个在之前没有自动化测试生成器的方言中

Conclusion: Germinator实现了对低资源方言的有效且可控的大规模测试，解决了可扩展编译器测试中方言无关性和方言有效性之间的权衡问题

Abstract: Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.

</details>


### [14] [Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering](https://arxiv.org/abs/2512.05350)
*Munazza Zaib,Wei Wang,Dulaji Hidellaarachchi,Isma Farah Siddiqui*

Main category: cs.SE

TL;DR: 该研究首次系统性地探讨了软件工程中神经多样性女性面临的独特挑战，提出了结合InclusiveMag框架和GenderMag方法的混合方法，旨在通过三阶段设计开发包容性分析方法。


<details>
  <summary>Details</summary>
Motivation: 神经多样性女性在软件工程领域面临性别偏见和神经差异的双重挑战，但现有研究尚未系统性地关注这一群体。误诊、伪装和男性中心的工作文化加剧了她们的压力、倦怠和流失问题。

Method: 提出混合方法：整合InclusiveMag包容性框架和GenderMag walkthrough过程，专门针对神经多样性女性在SE中的情境。采用三阶段设计：1)文献综述确定挑战范围；2)开发人物角色和分析流程；3)在协作工作坊中应用方法。

Result: 通过文献综述将神经多样性女性在SE中的挑战归纳为认知、社交、组织、结构和职业发展五大类，揭示了误诊/延迟诊断和伪装如何加剧排斥问题，为后续开发包容性分析方法奠定了基础。

Conclusion: 该研究填补了SE领域对神经多样性女性系统性研究的空白，提出的混合方法框架为开发支持实际变革的包容性分析方法提供了基础，有助于缓解该群体面临的独特挑战。

Abstract: Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.

</details>


### [15] [BGPFuzz: Automated Configuration Fuzzing of the Border Gateway Protocol](https://arxiv.org/abs/2512.05358)
*Chenlu Zhang,Amirmohammad Pasdar,Van-Thuan Pham*

Main category: cs.SE

TL;DR: BGPFuzz：一种结构感知、有状态的模糊测试框架，用于检测BGP配置错误，无需预定义正确性属性，通过运行时预言机捕获实际异常症状。


<details>
  <summary>Details</summary>
Motivation: 电信网络依赖配置定义路由行为，BGP中的错误配置可能导致严重中断和安全漏洞（如2021年Facebook中断）。现有方法依赖合成或验证，缺乏针对BGP固有复杂性或厂商特定实现的经济有效方法。

Method: 提出BGPFuzz框架：结构感知、有状态的模糊测试方法，系统性地变异BGP配置并在虚拟化网络中评估其效果。使用运行时预言机捕获实际症状（会话重置、黑洞、流量重定向），无需静态分析中的预定义正确性属性。

Result: 实验表明BGPFuzz能够可靠地复现和检测已知故障，包括最大前缀违规和子前缀劫持。

Conclusion: BGPFuzz提供了一种经济有效的BGP配置错误检测方法，通过运行时异常检测而非静态验证，能够处理BGP复杂性和厂商特定实现问题。

Abstract: Telecommunications networks rely on configurations to define routing behavior, especially in the Border Gateway Protocol (BGP), where misconfigurations can lead to severe outages and security breaches, as demonstrated by the 2021 Facebook outage. Unlike existing approaches that rely on synthesis or verification, our work offers a cost-effective method for identifying misconfigurations resulting from BGP's inherent complexity or vendor-specific implementations. We present BGPFuzz, a structure-aware and stateful fuzzing framework that systematically mutates BGP configurations and evaluates their effects in virtualized network. Without requiring predefined correctness properties as in static analysis, BGPFuzz detects anomalies through runtime oracles that capture practical symptoms such as session resets, blackholing, and traffic redirection. Our experiments show that BGPFuzz can reliably reproduce and detect known failures, including max-prefix violations and sub-prefix hijacks.

</details>


### [16] [Legacy Modernization with AI -- Mainframe modernization](https://arxiv.org/abs/2512.05375)
*Sunil Khemka,Arunava Majumdar*

Main category: cs.SE

TL;DR: AI辅助的遗留系统现代化将传统大型机系统转变为灵活、可扩展的智能架构，通过自动化代码重构、智能数据迁移和预测性维护等技术，帮助企业迁移到微服务、容器化和混合云平台。


<details>
  <summary>Details</summary>
Motivation: 传统大型机系统虽然可靠，但面临维护成本高、技能短缺、与云系统集成困难等问题，需要通过现代化改造来提高灵活性、可扩展性和智能化水平。

Method: 采用AI驱动的现代化策略，包括：1) 自动化代码重构；2) 智能工具进行数据迁移；3) 预测性维护；4) 机器学习模型分析遗留代码库；5) 自动化测试和部署；6) AI生成洞察用于负载均衡和异常检测。

Result: 企业能够顺利迁移到微服务、容器化环境和混合云平台，不仅保留核心业务逻辑，还能实现更快的创新、减少停机时间、增强系统弹性，提高运营效率。

Conclusion: AI在大型机现代化中的应用是数字化转型和企业可持续发展的催化剂，能够推动业务增长和技术创新。

Abstract: Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.

</details>


### [17] [Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation](https://arxiv.org/abs/2512.05383)
*Mara Downing,Matthew Peng,Jacob Granley,Michael Beyeler,Tevfik Bultan*

Main category: cs.SE

TL;DR: 论文提出了一种基于覆盖引导模糊测试的方法，用于检测和表征机器学习驱动的神经刺激系统中的不安全刺激模式。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型越来越多地用于神经假体设备（如视觉假体）中生成电刺激模式。虽然这些模型提供了精确和个性化的控制，但当模型输出直接传递到神经组织时，也引入了新的安全风险。需要系统化的定量方法来检测和表征ML驱动神经刺激系统中的不安全刺激模式。

Method: 将自动化软件测试技术——覆盖引导模糊测试——应用于神经刺激领域。该方法将编码器视为黑盒，通过扰动模型输入并跟踪产生的刺激是否违反电荷密度、瞬时电流或电极共激活等生物物理限制。使用覆盖度量来引导探索，量化测试用例在可能输出空间和违规类型上的覆盖广度。

Result: 应用于视网膜和皮层的深度刺激编码器时，该方法系统地揭示了超出既定安全限制的多样化刺激机制。两种违规输出覆盖度量识别了最高数量和最多样化的不安全输出，使得能够对架构和训练策略进行可解释的比较。

Conclusion: 违规聚焦的模糊测试将安全评估重新定义为经验性、可重复的过程。通过将安全从训练启发式转变为已部署模型的可测量属性，为下一代神经接口的基于证据的基准测试、监管准备和伦理保证奠定了基础。

Abstract: Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.

</details>


### [18] [Bita: A Conversational Assistant for Fairness Testing](https://arxiv.org/abs/2512.05428)
*Keeryn Johnson,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: Bita是一个基于对话的AI助手，帮助软件测试人员检测AI系统中的偏见，评估测试计划，并生成公平性导向的探索性测试章程。


<details>
  <summary>Details</summary>
Motivation: AI系统中的偏见可能导致不公平和歧视性结果，而现有的公平性测试工具通常难以使用，需要高级专业知识，并且对实际工作流程支持有限。

Method: 开发了Bita对话助手，将大型语言模型与检索增强生成技术结合，基于精选的公平性文献提供响应，支持偏见检测、测试计划评估和测试章程生成。

Result: 验证表明Bita能够有效支持真实世界AI系统的公平性测试任务，提供结构化、可复现的证据，证明其实用性。

Conclusion: Bita为工业实践提供了一个实用工具，使公平性测试变得可访问、系统化，并可直接应用于实际工作中。

Abstract: Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.

</details>


### [19] [Model Gateway: Model Management Platform for Model-Driven Drug Discovery](https://arxiv.org/abs/2512.05462)
*Yan-Shiun Wu,Nathan A. Morin*

Main category: cs.SE

TL;DR: Model Gateway是一个用于药物发现流程中管理和集成机器学习与科学计算模型的平台，支持LLM代理和生成式AI工具，实现模型注册、管理、异步执行等功能，在10k+并发客户端测试中达到0%失败率。


<details>
  <summary>Details</summary>
Motivation: 药物发现流程中需要管理大量机器学习模型和科学计算模型，传统方法难以有效集成和管理这些模型，缺乏统一的平台来支持LLM代理和生成式AI工具在MLOps管道中的应用。

Method: 开发了Model Gateway平台，包含模型所有者控制面板、平台管理工具和API服务，支持动态共识模型（聚合多个科学计算模型）、模型注册管理、信息检索、异步提交执行和结果接收等功能。

Result: 平台在超过10k个同时应用客户端测试中实现了0%的失败率，成功集成了LLM代理和生成式AI工具，成为模型驱动药物发现流程的基础组成部分。

Conclusion: Model Gateway平台通过成熟的MLOps基础设施和LLM代理与生成式AI工具的集成，有望显著加速新药开发进程，是药物发现领域的重要技术基础设施。

Abstract: This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.

</details>


### [20] [Everything is Context: Agentic File System Abstraction for Context Engineering](https://arxiv.org/abs/2512.05470)
*Xiwei Xu,Robert Mao,Quan Bai,Xuewu Gu,Yechao Li,Liming Zhu*

Main category: cs.SE

TL;DR: 提出基于文件系统抽象的统一上下文工程架构，解决生成式AI系统中上下文管理的碎片化问题，实现可验证、可追溯的AI协作系统。


<details>
  <summary>Details</summary>
Motivation: 生成式AI重塑了软件系统设计，但现有的上下文工程实践（如提示工程、RAG、工具集成）存在碎片化问题，产生临时性产物，限制了可追溯性和问责性。

Method: 提出受Unix"一切皆文件"理念启发的文件系统抽象，提供持久化、受治理的基础设施来管理异构上下文产物。在开源AIGNE框架中实现包含上下文构造器、加载器和评估器的可验证上下文工程管道。

Result: 实现了两个示例：具有记忆功能的智能体和基于MCP的GitHub助手。该架构在AIGNE框架中可操作化，支持可验证、可维护、工业就绪的生成式AI系统。

Conclusion: 该文件系统抽象架构为负责任、以人为本的AI协作建立了可重用的基础，使人类能够作为策展人、验证者和共同推理者参与决策支持过程。

Abstract: Generative AI (GenAI) has reshaped software system design by introducing foundation models as pre-trained subsystems that redefine architectures and operations. The emerging challenge is no longer model fine-tuning but context engineering-how systems capture, structure, and govern external knowledge, memory, tools, and human input to enable trustworthy reasoning. Existing practices such as prompt engineering, retrieval-augmented generation (RAG), and tool integration remain fragmented, producing transient artefacts that limit traceability and accountability. This paper proposes a file-system abstraction for context engineering, inspired by the Unix notion that 'everything is a file'. The abstraction offers a persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting, metadata, and access control. Implemented within the open-source AIGNE framework, the architecture realises a verifiable context-engineering pipeline, comprising the Context Constructor, Loader, and Evaluator, that assembles, delivers, and validates context under token constraints. As GenAI becomes an active collaborator in decision support, humans play a central role as curators, verifiers, and co-reasoners. The proposed architecture establishes a reusable foundation for accountable and human-centred AI co-work, demonstrated through two exemplars: an agent with memory and an MCP-based GitHub assistant. The implementation within the AIGNE framework demonstrates how the architecture can be operationalised in developer and industrial settings, supporting verifiable, maintainable, and industry-ready GenAI systems.

</details>


### [21] [A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models](https://arxiv.org/abs/2512.05498)
*Xiao He,Ru Chen,Zeqing Zhang,Yanling Wang,Qiuyan Dong*

Main category: cs.SE

TL;DR: iEcoreGen结合EMF建模框架和LLMs，通过模型驱动开发生成代码，在保证正确性的同时提高灵活性


<details>
  <summary>Details</summary>
Motivation: 模板驱动代码生成具有正确性保证但灵活性不足，而LLMs生成代码灵活但可能产生错误代码。需要结合两者优势，实现既可靠又灵活的代码生成方法。

Method: iEcoreGen使用EMF的Ecore模型定义系统结构，分解需求生成操作规范，用模板生成初始Java代码，将规范序列化为文档字符串，然后调用LLMs完成和修复未实现的方法。

Result: 在20个代码生成任务和5个LLMs上的评估显示，iEcoreGen在pass@k指标上优于纯LLM基线，在compilation@k指标上与基线相当。消融研究阐明了各组件贡献。

Conclusion: LLM增强的模型驱动开发是实现更高效软件自动化的有前景路径，结合了模板驱动方法的正确性保证和LLMs的灵活性。

Abstract: Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.

</details>


### [22] [Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study](https://arxiv.org/abs/2512.05507)
*Masoud Sadrnezhaad,José Antonio Hernández López,Torvald Mårtensson,Daniel Varro*

Main category: cs.SE

TL;DR: 本文通过跨公司研讨会收集了从业者对生成式AI在大型信息物理系统仿真测试中应用的观点，识别了挑战并提出了包含三个优先方向的研究议程。


<details>
  <summary>Details</summary>
Motivation: 大型信息物理系统的质量保证依赖复杂的仿真测试环境，但开发和维护这些仿真模型需要大量资源。虽然生成式AI已能生成软件测试用例，但在信息物理系统仿真测试中的应用仍未被充分探索，需要了解从业者的观点来填补这一空白。

Method: 本研究基于与六家组织的跨公司研讨会，收集从业者对生成式AI在仿真测试中应用的观点和经验，通过定性分析获得实践见解。

Result: 研究获得了详细的工程师经验见解，识别了实际挑战，并提出了包含三个高优先级方向的研究议程：AI生成的场景和环境模型、CI/CD管道中的仿真器和AI、以及生成式AI在仿真中的可信度。

Conclusion: 从业者认可生成式AI的巨大潜力，但也指出了未解决的挑战。通过详细阐述这些问题，本文旨在指导未来学术界与工业界的合作，促进生成式AI在仿真测试中的负责任应用。

Abstract: Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.

</details>


### [23] [From Challenge to Change: Design Principles for AI Transformations](https://arxiv.org/abs/2512.05533)
*Theocharis Tavantzis,Stefano Lambiase,Daniel Russo,Robert Feldt*

Main category: cs.SE

TL;DR: 提出基于行为软件工程学的以人为本框架，帮助软件工程组织在早期AI采用阶段应对社会技术复杂性，包含9个维度的具体指导原则和行动步骤。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展正在重塑软件工程，虽然现有研究注意到行为和非技术因素，但大多仍强调技术问题，缺乏对团队如何适应和信任AI的深入理解。需要解决AI集成中的人类中心挑战。

Method: 采用混合方法：通过文献综述分析组织变革模型，通过访谈数据的主题分析构建框架，然后通过调查（N=105）和专家研讨会（N=4）收集初步实践者反馈。

Result: 开发出包含9个维度的框架：AI战略设计、AI战略评估、协作、沟通、治理与伦理、领导力、组织文化、组织动态、技能提升。调查显示技能提升（15.2%）和AI战略设计（15.1%）被认为最重要，组织当前优先程序性元素，而人类中心护栏发展不足。

Conclusion: 该框架为早期AI采用提供了实用的路线图，识别了关键行为维度并提供可操作指导，强调了将框架扎根于实际实践的重要性，为SE中以人为本的AI研究指明了未来方向。

Abstract: The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.

</details>


### [24] [Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub](https://arxiv.org/abs/2512.05551)
*Jai Lal Lulla,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: GitHub的CODEOWNERS功能通过自动指定代码审查者来增强问责制，但实际采用情况未知。本研究首次大规模实证分析发现，代码所有者遵守规则、行为与传统所有权指标相似，能促进更顺畅的PR流程，并将审查责任从核心开发者转移。


<details>
  <summary>Details</summary>
Motivation: 随着软件供应链攻击等外部威胁增加，确保代码所有权和问责制变得至关重要。GitHub于2017年引入CODEOWNERS功能来自动指定文件审查者，但其实际采用和实践情况尚不清楚，需要实证研究来了解其效果和影响。

Method: 对超过844,000个拉取请求、190万条评论和200万次审查进行大规模实证研究，识别10,287名代码所有者并追踪其审查活动。使用回归断点设计（RDD）分析CODEOWNERS采用对审查动态的影响。

Result: 代码所有者倾向于遵守CODEOWNERS文件规则，行为与传统所有权指标相似，但能促进更顺畅、更快的PR工作流程。RDD分析显示，采用CODEOWNERS的仓库审查动态发生变化，审查责任从核心开发者重新分配。

Conclusion: CODEOWNERS是一种有前景但未充分利用的软件治理机制，能够增强安全性、问责制和工作流程效率。项目可以利用这种替代所有权方法来改善开源开发的治理和韧性。

Abstract: Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.

</details>


### [25] [Metronome: Differentiated Delay Scheduling for Serverless Functions](https://arxiv.org/abs/2512.05703)
*Zhuangbin Chen,Juzheng Zheng,Zibin Zheng*

Main category: cs.SE

TL;DR: Metronome：一个针对无服务器函数计算的差异化延迟调度框架，通过预测机制优化数据本地性和基础设施本地性，显著减少函数执行时间。


<details>
  <summary>Details</summary>
Motivation: 无服务器函数计算（FaaS）因其易管理性和弹性而兴起，但动态和事件驱动的特性使得调度优化具有挑战性。数据本地性在传统集群计算中通过延迟调度已被证明有效，但在无服务器平台中的应用尚未充分探索。

Method: 提出Metronome框架，采用差异化延迟调度策略。使用在线随机森林回归模型预测函数在不同节点上的执行时间，识别最优的本地性感知节点，做出明智的延迟决策同时防止SLA违规。

Result: 在OpenLambda上的实现表明，Metronome显著优于基线方法，将函数的平均执行时间减少了64.88%-95.83%，在高并发水平下保持性能优势，并确保SLA合规性。

Conclusion: Metronome通过预测性差异化延迟调度，有效解决了无服务器环境中复杂的本地性模式问题，为FaaS平台提供了高效的调度解决方案。

Abstract: Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.

</details>


### [26] [MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems](https://arxiv.org/abs/2512.05716)
*Zhiling Deng,Juepeng Wang,Zhuangbin Chen*

Main category: cs.SE

TL;DR: MicroRacer：一种用于微服务环境中并发bug检测的非侵入式自动化框架，通过动态插桩收集追踪数据，分析happened-before关系和资源访问模式，采用三阶段验证过程检测并发问题。


<details>
  <summary>Details</summary>
Motivation: 现代云应用基于微服务架构的分布式系统构建，端到端用户请求穿越多个不同服务和机器，表现出复杂的交互。因此，云服务系统容易受到并发bug的影响，对其可靠性构成重大挑战。现有并发bug检测方法往往因其侵入性且无法处理微服务的架构复杂性而不足。

Method: MicroRacer通过在运行时动态插桩广泛使用的库来收集详细的追踪数据，无需修改应用代码。利用这些数据分析服务系统中常见操作的happened-before关系和资源访问模式。基于这些信息，识别可疑的并发操作，并采用三阶段验证过程来测试和确认并发bug。

Result: 在开源微服务基准测试中复现工业级bug的实验表明，MicroRacer在准确检测和定位并发问题方面具有有效性和高效性。

Conclusion: MicroRacer为非侵入式、自动化的微服务并发bug检测提供了一种有效解决方案，能够处理微服务架构的复杂性，提高云服务系统的可靠性。

Abstract: Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.

</details>


### [27] [Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures](https://arxiv.org/abs/2512.05908)
*Amirkia Rafiei Oskooei,S. Selcan Yukcu,Mehmet Cevheri Bozoglan,Mehmet S. Aktas*

Main category: cs.SE

TL;DR: 将多仓库微服务架构中的bug定位重新定义为自然语言推理任务，通过将代码库转换为分层NL摘要，使用NL-to-NL搜索替代跨模态检索，显著提升定位效果。


<details>
  <summary>Details</summary>
Motivation: 多仓库微服务架构中的bug定位面临三大挑战：自然语言bug报告与代码之间的语义鸿沟、LLM上下文限制、以及需要首先确定正确的仓库。现有方法效果有限。

Method: 将代码库转换为分层自然语言摘要（文件、目录、仓库级别），采用两阶段搜索：首先将bug报告路由到相关仓库，然后在仓库内进行自上而下的定位。

Result: 在包含46个仓库和110万行代码的工业系统DNext上评估，Pass@10达到0.82，MRR达到0.50，显著优于检索基线和GitHub Copilot、Cursor等代理RAG系统。

Conclusion: 工程化的自然语言表示比原始源代码更有效于可扩展的bug定位，提供可解释的仓库->目录->文件搜索路径，这对构建企业AI工具的信任至关重要。

Abstract: Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [28] [Computing Supported Models via Transformation to Stable Models](https://arxiv.org/abs/2512.05437)
*Fang Li,Gopal Gupta*

Main category: cs.LO

TL;DR: 提出一种基于转换的方法，使用标准ASP求解器计算支持模型，填补了ASP中支持模型缺乏实用计算工具的空白。


<details>
  <summary>Details</summary>
Motivation: 稳定模型的极小性要求在某些应用中可能过于严格，需要探索非极小但逻辑一致的解空间。支持模型放松了极小性约束，但缺乏与现代ASP求解器集成的实用计算工具。

Method: 提出一种基于转换的方法：将任何基础逻辑程序转换为等价程序，使得新程序的稳定模型恰好对应原程序的支持模型。该方法在Clingo中实现，兼容标准ASP语法。

Result: 实现了第一个使用最先进ASP求解器计算支持模型的实用工具，在软件验证、医疗诊断和规划等应用中展示了支持模型的探索推理能力，并通过实证评估验证了方法的实用性。

Conclusion: 该方法填补了ASP中支持模型计算工具的空白，为需要非极小但逻辑一致解空间的应用提供了有价值的探索推理能力，同时保持了与现有ASP基础设施的兼容性。

Abstract: Answer Set Programming (ASP) with stable model semantics has proven highly effective for knowledge representation and reasoning. However, the minimality requirement of stable models can be restrictive for applications requiring exploration of non-minimal but logically consistent solution spaces. Supported models, introduced by Apt, Blair, and Walker in 1988, relax this minimality constraint while maintaining a support condition ensuring every true atom is justified by some rule.
  Despite their theoretical significance, supported models lack practical computational tools integrated with modern ASP solvers. We present a novel transformation-based method enabling computation of supported models using standard ASP infrastructure. Our approach transforms any ground logic program into an equivalent program whose stable models correspond exactly to the supported models of the original program. We implement this transformation for Clingo, providing the first practical tool for computing supported models with state-of-the-art ASP solvers.
  We demonstrate applications in software verification, medical diagnosis, and planning where supported models enable valuable exploratory reasoning capabilities beyond those provided by stable models. We also provide an empirical evaluation to justify the practical utility of our approach compared to established methods. Our implementation is publicly available and compatible with standard ASP syntax.

</details>


### [29] [Formalizing Polynomial Laws and the Universal Divided Power Algebra](https://arxiv.org/abs/2512.05750)
*Antoine Chambert-Loir,María Inés de Frutos-Fernández*

Main category: cs.LO

TL;DR: 本文在Lean/Mathlib数学库中形式化Roby(1965)的通用分次幂代数构造，这是分次幂理论中类似多项式代数的结构，在晶体上同调和p-adic Hodge理论中有重要应用。


<details>
  <summary>Details</summary>
Motivation: 通用分次幂代数是晶体上同调发展的关键工具，也在p-adic Hodge理论中用于定义晶体周期环。该代数在分次幂理论中类似于经典的多项式代数，具有重要的数学意义。

Method: 使用Lean/Mathlib数学库进行形式化，重点关注Roby定理中在增广理想上构造分次幂结构的主要难点。通过将分次分量与齐次多项式律这一通用结构联系起来，并形式化多项式律理论的初步步骤。

Result: 成功形式化了多项式律理论的初步步骤，展示了未来工作如何完成上述分次幂结构的完整形式化。报告了形式化过程中遇到的各种困难，包括宇宙处理、将Mathlib库扩展到半环、以及处理多个"不可见数学"实例。

Conclusion: 本文展示了在Lean/Mathlib中形式化Roby通用分次幂代数构造的进展，为完成完整的分次幂结构形式化奠定了基础，同时解决了形式化过程中的技术挑战。

Abstract: The goal of this paper is to present an ongoing formalization, in the framework provided by the Lean/Mathlib mathematical library, of the construction by Roby (1965) of the universal divided power algebra. This is an analogue, in the theory of divided powers, of the classical algebra of polynomials. It is a crucial tool in the development of crystalline cohomology; it is also used in $p$-adic Hodge theory to define the crystalline period ring. As an algebra, this universal divided power algebra has a fairly simple definition that shows that it is a graded algebra. The main difficulty in Roby's theorem lies in constructing a divided power structure on its augmentation ideal. To that aim, Roby identified the graded pieces with another universal structure: homogeneous polynomial laws.We formalize the first steps of the theory of polynomial laws and show how future work will allow to complete the formalization of the above-mentioned divided power structure. We report on various difficulties that appeared in this formalization: taking care of universes, extending to semirings some aspects of the Mathlib library, and coping with several instances of "invisible mathematics".

</details>


### [30] [Skolemization and Decidability of the Bernays-Schoenfinkel Class in Goedel Logics](https://arxiv.org/abs/2512.05772)
*Mariami Gamsakhurdia,Matthias Baaz,Anela Lolic*

Main category: cs.LO

TL;DR: 研究Bernays-Schoenfinkel类在所有哥德尔逻辑中的可判定性，证明其有效性和1-可满足性在所有哥德尔逻辑中都是可判定的


<details>
  <summary>Details</summary>
Motivation: Bernays和Schoenfinkel在1928年证明了不含函数符号的前束句子的可判定性（BS类）。本文旨在研究BS类在所有哥德尔逻辑中的可判定性，扩展经典逻辑的结果到多值逻辑框架

Method: 利用前束哥德尔逻辑的Skolem化有效性，以及前束公式的结构性质来证明1-可满足性。通过分析BS类在哥德尔逻辑中的特性来建立可判定性结果

Result: 证明BS类在所有哥德尔逻辑中，有效性和1-可满足性都是可判定的。这些性质在所有无限哥德尔逻辑中保持一致

Conclusion: Bernays-Schoenfinkel类在所有哥德尔逻辑中保持可判定性，将经典逻辑的重要结果成功扩展到多值逻辑框架，为哥德尔逻辑中的量化理论提供了基础性结果

Abstract: In 1928, Bernays and Schoenfinkel proved the decidability of prenex sentences whose matrices contain no function symbols, now known as the Bernays-Schoenfinkel (BS) class. We investigate the decidability of the BS class for all Goedel logics. Our validity argument relies on the fact that Skolemization works for prenex Goedel logics, while 1-satisfiability follows from structural properties of prenex formulas. We show that validity and 1-satisfiability for the BS class are decidable in every Goedel logic, and that these properties persist across all infinite Goedel logics.

</details>


### [31] [Complex Bounded Operators in Isabelle/HOL](https://arxiv.org/abs/2512.05878)
*Dominique Unruh,José Manuel Rodríguez Caballero*

Main category: cs.LO

TL;DR: 在Isabelle/HOL中形式化复希尔伯特空间和有界算子理论的综合库


<details>
  <summary>Details</summary>
Motivation: 希尔伯特空间和算子理论是数学中的重要领域，需要建立形式化验证的库来支持相关定理的机器验证

Method: 在Isabelle/HOL中开发Complex_Bounded_Operators库，形式化复向量空间、内积空间、希尔伯特空间、有界算子、伴随算子、酉算子、投影算子等概念

Result: 成功构建了包含大量定理的形式化库，涵盖复希尔伯特空间和有界算子的核心理论，并提供有限维情况下的代码生成支持

Conclusion: 该工作为希尔伯特空间和算子理论的形式化验证提供了坚实基础，支持数学定理的机器验证和代码生成

Abstract: Functional analysis, especially the theory of Hilbert spaces and of operators on these, form an important area in mathematics. We formalized the Isabelle/HOL library Complex_Bounded_Operators containing a large amount of theorems about complex Hilbert spaces and (bounded) operators on these.
  Specifically, we formalize the properties complex vector spaces, inner product (and Hilbert) spaces, one-dimensional spaces, bounded operators, adjoints, unitaries, projections, extensions of bounded operators (BLT-theorem), positive operators, square-summable sequences and much more.
  Additionally, we provide support for code generation in the finite-dimensional case.

</details>
