<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.FL](#cs.FL) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Compositional Quantum Control Flow with Efficient Compilation in Qunity](https://arxiv.org/abs/2508.02857)
*Mikhail Mints,Finn Voichick,Leonidas Lampropoulos,Robert Rand*

Main category: cs.PL

TL;DR: 本文提出了一种高效的量子控制流构造编译方法，基于Qunity语言，优化了编译过程并减少了量子比特和门的使用。


<details>
  <summary>Details</summary>
Motivation: 现有量子编程语言在实现高级抽象（尤其是量子控制流）时效率低下，Qunity语言虽提出解决方案但缺乏实现且编译效率低。

Method: 在Qunity基础上引入更广泛的抽象，开发完整的Qunity编译器，优化编译过程，包括低层电路优化和高层程序结构优化。

Result: 实现了高效的编译方法，显著减少了量子比特和门的数量，生成OpenQASM 3代码。

Conclusion: 通过优化编译过程，Qunity语言的高效实现成为可能，为量子编程提供了更实用的工具。

Abstract: Most existing quantum programming languages are based on the quantum circuit
model of computation, as higher-level abstractions are particularly challenging
to implement - especially ones relating to quantum control flow. The Qunity
language, proposed by Voichick et al., offered such an abstraction in the form
of a quantum control construct, with great care taken to ensure that the
resulting language is still realizable. However, Qunity lacked a working
implementation, and the originally proposed compilation procedure was very
inefficient, with even simple quantum algorithms compiling to unreasonably
large circuits.
  In this work, we focus on the efficient compilation of high-level quantum
control flow constructs, using Qunity as our starting point. We introduce a
wider range of abstractions on top of Qunity's core language that offer
compelling trade-offs compared to its existing control construct. We create a
complete implementation of a Qunity compiler, which converts high-level Qunity
code into the quantum assembly language OpenQASM 3. We develop optimization
techniques for multiple stages of the Qunity compilation procedure, including
both low-level circuit optimizations as well as methods that consider the
high-level structure of a Qunity program, greatly reducing the number of qubits
and gates used by the compiler.

</details>


### [2] [SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation](https://arxiv.org/abs/2508.03558)
*M Zafir Sadik Khan,Nowfel Mashnoor,Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 本文介绍了SAGE-HLS，一种专为HLS代码生成设计的微调LLM，通过Verilog-to-C/C++转换创建数据集，并结合AST指导的微调策略，显著提升了HLS代码的生成质量。


<details>
  <summary>Details</summary>
Motivation: 由于公开可用的HLS代码数据集稀缺，现有LLM在HLS代码生成中的应用受限，本文旨在解决这一问题。

Method: 通过Verilog-to-C/C++转换创建16.7K HLS代码数据集，采用基于AST的指令提示微调策略，并开发半自动化评估框架VerilogEval。

Result: SAGE-HLS在QwenCoder 7B模型上微调后，代码可合成率接近100%，功能正确率达75%。

Conclusion: SAGE-HLS为HLS代码生成提供了高效解决方案，填补了LLM在该领域的应用空白。

Abstract: In today's rapidly evolving field of electronic design automation (EDA), the
complexity of hardware designs is increasing, necessitating more sophisticated
automation solutions. High-level synthesis (HLS), as a pivotal solution,
automates hardware designs from high-level abstractions (e.g., C/C++). However,
it faces significant challenges, particularly in design space exploration and
optimization. While large language models (LLMs) have shown notable
capabilities in code generation, their application to HLS has been limited due
to the scarcity of (publicly) available HLS code datasets. Hence, research in
this domain has primarily focused on techniques such as prompt engineering and
retrieval-augmented generation (RAG). To overcome this limitation, this paper
introduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS
code generation. Our method includes three key advancements: (i) We implement
Verilog-to-C/C++ porting, converting verified and synthesizable Verilog codes
into corresponding C, creating a dataset of 16.7K HLS codes; (ii) We implement
a fine-tuning strategy, which is based on instruction prompting to code
generation guided by abstract syntax tree (AST); (iii) We develop a
semi-automated evaluation framework using VerilogEval to assess the
functionality of the generated HLS code. Our experiments show that SAGE-HLS,
fined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100% success rate
in code synthesizability and a 75% success rate in functional correctness.

</details>


### [3] [Teaching Introductory Functional Programming Using Haskelite](https://arxiv.org/abs/2508.03640)
*Pedro Vasconcelos*

Main category: cs.PL

TL;DR: 论文探讨了在教授函数式编程时使用逐步追踪解释器的经验，展示了其对学生理解递归定义、代数数据类型和高阶函数等概念的帮助。


<details>
  <summary>Details</summary>
Motivation: 学生在学习函数式编程时，对基于替换的计算模型（如递归定义、代数数据类型和高阶函数）存在理解困难，逐步解释器被证明能有效澄清误解并提升理解。

Method: 在波尔图大学的函数式编程入门课程中，使用了一个针对Haskell子集的逐步追踪解释器，并收集了学生的反馈。

Result: 学生反馈表明逐步解释器有助于理解复杂概念，课程经验也提供了改进方向。

Conclusion: 逐步追踪解释器是教授函数式编程的有效工具，未来可进一步优化和扩展其应用。

Abstract: Learning functional programming requires learning a substitution-based
computational model. While substitution should be a familiar concept from
high-school algebra, students often have difficulty applying it to new
settings, such as recursive definitions, algebraic data types and higher-order
functions. Step-by-step interpreters have been shown to help beginners by
clarifying misconceptions and improving understanding.
  This paper reports on the experience of using a step-by-step tracing
interpreter for a subset of Haskell while teaching an introductory functional
programming course at the University of Porto. We describe the use of the
interpreter, present some feedback obtained from students, reflect on the
lessons learned and point directions for further work.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](https://arxiv.org/abs/2508.02721)
*Libin Qiu,Yuhang Ye,Zhirong Gao,Xide Zou,Junfu Chen,Ziming Gui,Weizhi Huang,Xiaobo Xue,Wenkai Qiu,Kun Zhao*

Main category: cs.SE

TL;DR: 论文提出了一种名为Source Code Agent的新框架，通过将工作流逻辑与生成模型解耦，解决了LLM代理在结构化操作环境中的非确定性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理的非确定性限制了其在需要严格程序保真度和可预测执行的结构化环境中的应用。

Method: 采用‘Blueprint First, Model Second’哲学，将专家定义的操作程序编码为基于源代码的执行蓝图，并由确定性引擎执行，LLM仅用于处理有限复杂子任务。

Result: 在tau-bench基准测试中，Source Code Agent表现优异，平均Pass^1得分比最强基线高出10.1个百分点，同时显著提高了执行效率。

Conclusion: 该框架实现了在严格程序逻辑应用中的可验证和可靠部署。

Abstract: While powerful, the inherent non-determinism of large language model (LLM)
agents limits their application in structured operational environments where
procedural fidelity and predictable execution are strict requirements. This
limitation stems from current architectures that conflate probabilistic,
high-level planning with low-level action execution within a single generative
process. To address this, we introduce the Source Code Agent framework, a new
paradigm built on the "Blueprint First, Model Second" philosophy. Our framework
decouples the workflow logic from the generative model. An expert-defined
operational procedure is first codified into a source code-based Execution
Blueprint, which is then executed by a deterministic engine. The LLM is
strategically invoked as a specialized tool to handle bounded, complex
sub-tasks within the workflow, but never to decide the workflow's path. We
conduct a comprehensive evaluation on the challenging tau-bench benchmark,
designed for complex user-tool-rule scenarios. Our results demonstrate that the
Source Code Agent establishes a new state-of-the-art, outperforming the
strongest baseline by 10.1 percentage points on the average Pass^1 score while
dramatically improving execution efficiency. Our work enables the verifiable
and reliable deployment of autonomous agents in applications governed by strict
procedural logic.

</details>


### [5] [Automated Code Repair for C/C++ Static Analysis Alerts](https://arxiv.org/abs/2508.02820)
*David Svoboda,Lori Flynn,William Klieber,Michael Duggan,Nicholas Reimer,Joseph Sible*

Main category: cs.SE

TL;DR: 本文探讨了静态分析（SA）工具在C/C++代码中产生的诊断警报问题，提出了一种自动程序修复（APR）工具，显著减少了警报数量和分析师的手动工作量。


<details>
  <summary>Details</summary>
Motivation: 静态分析工具产生大量诊断警报，其中许多是误报，手动修复缺陷耗时耗力。APR工具可以显著减少警报数量并降低人工审查成本。

Method: 设计、开发和性能测试了一种APR工具，用于修复由多个SA工具产生的3类警报。修复方法简单且局部化。

Result: APR工具成功修复了8718/9234个警报，对2类缺陷、2个SA工具和2个代码库，平均修复或排除了80%以上的警报。修复未显著影响代码性能或引发新警报。

Conclusion: APR工具在减少SA警报方面效果显著，同时推动了CERT编码标准的更新。论文还公开了APR工具和数据集，总结了经验教训。

Abstract: (Note: This work is a preprint.) Static analysis (SA) tools produce many
diagnostic alerts indicating that source code in C or C++ may be defective and
potentially vulnerable to security exploits. Many of these alerts are false
positives. Identifying the true-positive alerts and repairing the defects in
the associated code are huge efforts that automated program repair (APR) tools
can help with. Our experience showed us that APR can reduce the number of SA
alerts significantly and reduce the manual effort of analysts to review code.
This engineering experience paper details the application of design,
development, and performance testing to an APR tool we built that repairs C/C++
code associated with 3 categories of alerts produced by multiple SA tools. Its
repairs are simple and local. Furthermore, our findings convinced the
maintainers of the CERT Coding Standards to re-assess and update the metrics
used to assess when violations of guidelines are detectable or repairable. We
discuss engineering design choices made to support goals of trustworthiness and
acceptability to developers. Our APR tool repaired 8718 out of 9234 alerts
produced by one SA tool on one codebase. It can repair 3 flaw categories. For 2
flaw categories, 2 SA tools, and 2 codebases, our tool repaired or dismissed as
false positives over 80% of alerts, on average. Tests showed repairs did not
appreciably degrade the performance of the code or cause new alerts to appear
(with the possible exception of sqlite3.c). This paper describes unique
contributions that include a new empirical analysis of SA data, our selection
method for flaw categories to repair, publication of our APR tool, and a
dataset of SA alerts from open-source SA tools run on open-source codebases. It
discusses positive and negative results and lessons learned.

</details>


### [6] [Interpreting Performance Profiles with Deep Learning](https://arxiv.org/abs/2508.02729)
*Zhuoran Liu*

Main category: cs.SE

TL;DR: 论文探讨了如何结合性能分析和程序语义，通过深度学习方法改进性能分析工具，帮助用户更直观地理解程序性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有的性能分析工具虽然有用，但用户（尤其是非代码作者）难以将性能数据与程序语义关联，限制了工具的实用性。

Method: 结合Async Profiler生成的性能数据和基于CodeBERT的代码摘要模型，通过图形界面展示调用路径的代码摘要。

Result: 系统在多个Java基准测试中有效辅助了性能分析。

Conclusion: 结合性能分析和程序语义的深度学习方法，能够提升性能分析工具的实用性和用户友好性。

Abstract: Profiling tools (also known as profilers) play an important role in
understanding program performance at runtime, such as hotspots, bottlenecks,
and inefficiencies. While profilers have been proven to be useful, they give
extra burden to software engineers. Software engineers, as the users, are
responsible to interpret the complex performance data and identify actionable
optimization in program source code. However, it can be challenging for users
to associate inefficiencies with the program semantics, especially if the users
are not the authors of the code, which limits the applicability of profilers.
  In this thesis, we explore a new direction to combine performance profiles
and program semantics with a deep learning approach. The key idea is to glean
code summary for semantic information (at a certain level) and integrate it
into a profiler, which can better understand program inefficiencies for
actionable optimization. To be concrete, we combine profiles generated by Async
Profiler (the state-of-the-art Java profiler) with code summarization from a
fine-tuned CodeBERT-based model. We demonstrate the code summaries of any
selected call path in a graphic user interface. Our system can effectively
assist analysis on many Java benchmarks.

</details>


### [7] [StoneDetector: Conventional and versatile code clone detection for Java](https://arxiv.org/abs/2508.03435)
*Thomas S. Heinze,André Schäfer,Wolfram Amme*

Main category: cs.SE

TL;DR: StoneDetector平台用于检测Java源代码和字节码中的代码克隆，基于支配树路径的文本比较，支持多种配置参数，性能优越。


<details>
  <summary>Details</summary>
Motivation: 代码克隆可能导致软件膨胀和漏洞传播，因此识别克隆代码对软件项目至关重要。

Method: StoneDetector采用基于支配树路径文本比较的传统克隆检测方法，支持多种字符串度量和哈希算法配置。

Result: 在多个基准测试中，StoneDetector在检测Java源代码和字节码中的代码克隆方面表现出色，具有高性能和可扩展性。

Conclusion: StoneDetector是一种高效且可配置的代码克隆检测工具，适用于多种克隆类型和场景。

Abstract: Copy & paste is a widespread practice when developing software and, thus,
duplicated and subsequently modified code occurs frequently in software
projects. Since such code clones, i.e., identical or similar fragments of code,
can bloat software projects and cause issues like bug or vulnerability
propagation, their identification is of importance. In this paper, we present
the StoneDetector platform and its underlying method for finding code clones in
Java source and Bytecode. StoneDetector implements a conventional clone
detection approach based upon the textual comparison of paths derived from the
code's representation by dominator trees. In this way, the tool does not only
find exact and syntactically similar near-miss code clones, but also code
clones that are harder to detect due to their larger variety in the syntax. We
demonstrate StoneDetector's versatility as a conventional clone detection
platform and analyze its various available configuration parameters, including
the usage of different string metrics, hashing algorithms, etc. In our
exhaustive evaluation with other conventional clone detectors on several
state-of-the-art benchmarks, we can show StoneDetector's performance and
scalability in finding code clones in both, Java source and Bytecode.

</details>


### [8] [A Note on Code Quality Score: LLMs for Maintainable Large Codebases](https://arxiv.org/abs/2508.02732)
*Sherman Wong,Jalaj Bhandari,Leo Zhou Fan Yang,Xylan Xu,Yi Zhuang,Cem Cayiroglu,Payal Bhuptani,Sheela Yadawad,Hung Duong*

Main category: cs.SE

TL;DR: 论文提出了一种基于Llama3模型的代码质量评分系统（CQS），用于自动检测代码问题并提供改进建议，已在工业环境中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模软件系统中，多工程师并行开发导致代码质量维护困难，需要自动化工具提供实时反馈。

Method: CQS系统结合两个经过微调的Llama3模型（SFT和离线RL方法）检测代码问题，并通过人工规则过滤错误响应。

Result: 离线评估显示CQS系统在识别有效问题方面具有高精度，实际应用中用户满意度达60%。

Conclusion: CQS系统在工业环境中表现优异，同时为LLM微调提供了开发者反馈数据的实践经验。

Abstract: Maintaining code quality in large-scale software systems presents significant
challenges, particularly in settings where a large numbers of engineers work
concurrently on a codebase. This paper introduces Code Quality Score (CQS)
system to automatically detect issues with a set of code changes and provide
actionable insights. At its core, the CQS system is powered by two Llama3
models, fine-tuned (with SFT and offline RL approaches), to a) detect common
code quality issues related to coding best practices and b) to provide good
``critiques'' for LLM-generated code review respectively. To maintain good user
experience, we layer the system with hand-crafted rules to filter out incorrect
responses/hallucinations. Offline evaluations show that our CQS system is able
to achieve an impressive precision rate for identifying valid issues. This
system has already been rolled out to developers in an industrial scale setting
and has consistently achieved 60\% week over week user helpfulness rate,
demonstrating its effectiveness in a real-world environment. In this paper, we
present details of the CQS system along with some learnings on curating
developer feedback to create training data for LLM fine-tuning.

</details>


### [9] [ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs](https://arxiv.org/abs/2508.03603)
*Iti Shree,Karine Even-Mendoz,Tomasz Radzik*

Main category: cs.SE

TL;DR: ReFuzzer是一个框架，通过检测和修正LLM生成的测试程序中的编译和运行时错误，显著提高了测试程序的有效性和代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的编译器模糊测试工具生成的测试程序常存在语法或语义错误，限制了其在测试编译器优化和后端组件中的效果。

Method: ReFuzzer采用反馈循环机制，利用本地LLM验证和过滤错误程序，确保程序在运行前有效。

Result: ReFuzzer将测试程序的有效性从47.0-49.4%提升至96.6-97.3%，并显著提高了关键优化和IR生成组件的代码覆盖率。

Conclusion: ReFuzzer通过系统性修正错误，显著提升了模糊测试的效果，适用于多种测试场景。

Abstract: Existing LLM-based compiler fuzzers often produce syntactically or
semantically invalid test programs, limiting their effectiveness in exercising
compiler optimizations and backend components. We introduce ReFuzzer, a
framework for refining LLM-generated test programs by systematically detecting
and correcting compilation and runtime violations (e.g. division by zero or
array out-of-bounds accesses). ReFuzzer employs a feedback loop with a local
LLM to validate and filter erroneous programs before execution, improving
fuzzing effectiveness beyond crash detection and enabling the generation of
diverse yet valid test programs.
  We evaluated ReFuzzer's effectiveness across black-, grey- and white-box
fuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs'
validity from 47.0-49.4% to 96.6-97.3%, with an average processing time of
2.9-3.5 s per test program on a dual-GPU machine. Further, refuzzing
significantly increased code coverage in critical optimization and IR
generation components. For example, vectorization coverage had an absolute
improvement of 9.2%, 2.3%, and 7.1% in black-, grey-, and white-box fuzzing,
enhancing testing effectiveness.

</details>


### [10] [What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus](https://arxiv.org/abs/2508.02733)
*Rijul Jain,Shraddha Barke,Gabriel Ebner,Md Rakib Hossain Misu,Shan Lu,Sarah Fakhoury*

Main category: cs.SE

TL;DR: 研究通过用户实验分析专家在F*和Verus语言中的证明开发行为，总结出三种策略和非正式实践，并提出了AI证明助手的设计建议。


<details>
  <summary>Details</summary>
Motivation: 尽管证明导向编程语言（POPLs）能提供形式化保证，但其高学习门槛和缺乏对证明开发过程的理解阻碍了广泛应用。

Method: 收集并分析八位专家在F*和Verus中的源代码遥测数据，识别证明开发中的策略和挑战。

Result: 发现三种策略和非正式实践，提出AI证明助手的设计建议（如早期规范起草、显式子目标分解等），并通过F*证明代理验证其效果。

Conclusion: 研究为改进AI证明助手提供了实用指导，并展示了基于建议的F*代理优于基线LLMs。

Abstract: Proof-oriented programming languages (POPLs) empower developers to write code
alongside formal correctness proofs, providing formal guarantees that the code
adheres to specified requirements. Despite their powerful capabilities, POPLs
present a steep learning curve and have not yet been adopted by the broader
software community. The lack of understanding about the proof-development
process and how expert proof developers interact with POPLs has hindered the
advancement of effective proof engineering and the development of
proof-synthesis models/tools.
  In this work, we conduct a user study, involving the collection and analysis
of fine-grained source code telemetry from eight experts working with two
languages, F* and Verus. Results reveal interesting trends and patterns about
how experts reason about proofs and key challenges encountered during the proof
development process. We identify three distinct strategies and multiple
informal practices that are not captured final code snapshots, yet are
predictive of task outcomes. We translate these findings into concrete design
guidance for AI proof assistants: bias toward early specification drafting,
explicit sub-goal decomposition, bounded active errors, and disciplined
verifier interaction. We also present a case study of an F* proof agent
grounded in these recommendations, and demonstrate improved performance over
baseline LLMs

</details>


### [11] [Automated Validation of LLM-based Evaluators for Software Engineering Artifacts](https://arxiv.org/abs/2508.02827)
*Ora Nova Fandina,Eitan Farchi,Shmulik Froimovich,Rami Katan,Alice Podolsky,Orna Raz,Avi Ziv*

Main category: cs.SE

TL;DR: REFINE是一个自动化框架，用于评估基于LLM的代码评估器，通过生成渐进质量下降的数据集和量化评估器配置的排名准确性，提升评估的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 现有的人工评估成本高且不具扩展性，而自动化方法难以捕捉代码质量的细微差异，因此需要一种更可靠的LLM评估方法。

Method: REFINE包含两个模块：Hierarchy Dataset Builder生成渐进质量下降的代码数据集，Evaluator Tester通过排名对齐量化评估器配置的准确性。

Result: REFINE在IBM内部工作流中应用，显著提升了评估器配置的准确性，将某些任务的评分从0.7提升至0.9以上。

Conclusion: REFINE提供了一种可控且高效的LLM评估方法，支持模型训练团队做出更精准的发布决策。

Abstract: Automation in software engineering increasingly relies on large language
models (LLMs) to generate, review, and assess code artifacts. However,
establishing LLMs as reliable evaluators remains an open challenge: human
evaluations are costly, subjective and non scalable, while existing automated
methods fail to discern fine grained variations in artifact quality.
  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation),
an automated framework for benchmarking LLM based evaluators across software
engineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder
applies novel generation techniques to automatically synthesize artifacts with
progressively reduced quality, and Evaluator Tester quantifies each candidate
evaluator configuration by measuring how closely its rankings align with
expected ordering.
  A key feature of REFINE is controllability: users can tune the granularity of
degradation to progressively refine evaluator configurations, from coarse
filtering to stress testing on subtle quality gaps.
  While the methodology is general, we focus on coding tasks reflecting the
practical demands in our production setting. REFINE was integrated into IBM's
internal development workflows and applied to code generation, translation, and
summarization for COBOL, an enterprise critical programming language, using
industrial data. It was used to identify LLM as a Judge configurations that
lifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks.
These nuance sensitive evaluators are now actively used by model training teams
to support model release decisions.

</details>


### [12] [Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors](https://arxiv.org/abs/2508.02968)
*Shavindra Wickramathilaka,John Grundy,Kashumi Madampe,Omar Haggag*

Main category: cs.SE

TL;DR: 论文提出低代码工具AdaptForge，通过自动化代码生成帮助开发者高效创建适应老年用户需求的可访问和自适应应用。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化问题加剧，亟需支持老年人自主性的技术。传统开发方式存在可访问性和个性化障碍，开发者需工具以满足法规要求和同理心需求。

Method: 通过访谈18名软件从业者，评估低代码模型驱动工程工具AdaptForge。

Result: 研究明确了开发者对类似工具的期望，并提供了设计低代码工具的建议。

Conclusion: AdaptForge能有效解决开发约束，支持可访问和自适应软件开发，未来可成为行业标准。

Abstract: The global ageing population presents a growing societal challenge, creating
an urgent need for inclusive technologies that promote autonomy among older
adults. Software practitioners can address this by delivering digital services
that enhance seniors' independence and reduce reliance on routine support from
family members and healthcare infrastructure. However, traditional development
practices, constrained by time and resources, often result in applications with
major accessibility and personalisation barriers. Increasing pressure from
regulatory requirements, such as the European Accessibility Act (EAA), and the
personal empathy many developers feel toward supporting their older loved ones
and their own future selves have created a demand for tools that support the
development of accessible and adaptive software. To address this demand, this
paper presents an interview-based empirical study with 18 software
practitioners, evaluating AdaptForge: a low-code model-driven engineering (MDE)
tool that enables the efficient creation of accessible and adaptive
applications for senior users by mitigating development constraints through
automated code generation. Based on these insights, we identify developer
expectations for adopting such tools as industry-standard solutions and provide
empirically grounded recommendations for designing low-code tools that support
accessible and adaptive software development.

</details>


### [13] [MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation](https://arxiv.org/abs/2508.02998)
*Haiyang Li*

Main category: cs.SE

TL;DR: MRG-Bench是一个新的多语言代码生成评估数据集，解决了现有数据集缺乏可运行测试用例、偏离真实代码分布和仅支持Python的问题。实验表明当前代码生成技术在理解用户需求方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估数据集存在局限性，如缺乏可运行测试用例、偏离真实代码分布和仅支持Python，影响了评估结果的可信度。

Method: 引入MRG-Bench数据集，支持多语言（Python、Java、Go），提供真实代码库数据和项目级可运行测试用例。通过实验评估LLMs、长上下文模型和RAG方法。

Result: 当前代码生成技术在理解用户需求方面表现不佳，且不同编程语言对上下文的需求差异显著。

Conclusion: MRG-Bench为代码生成评估提供了更准确的基准，揭示了当前技术的不足，并强调需针对不同语言设计专用上下文。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
code generation. However, current evaluation datasets suffer from issues such
as the lack of runnable test cases, deviation from the distribution of
real-world code, and the ability to evaluate only the Python language. These
limitations undermine the credibility of the evaluation results.
  To address these limitations, we introduce \textbf{MRG-Bench} (Multi-language
Repository-level Code Generation Benchmark), a novel dataset that provides a
more accurate evaluation of LLMs in practical repository-level code generation
tasks. MRG-Bench has three main features: (1) practical data sourced from
real-world code repositories that align to the practical distribution, (2)
multiple programming languages support, including Python, Java, and Go, and (3)
project-level runnable test cases to assess the quality of the generated code.
  Based on MRG-Bench, we conducted extensive experiments including large
language models, long-context models, and RAG-related methods. These evaluation
results demonstrate that \textbf{current repository-level code generation
techniques suffer from significant performance deficiencies}. To further
investigate why models fail, we designed novel experiments to annotate the
underlying causes of generation errors. The results explicitly show that the
majority of methods suffer from "\textbf{difficulty in understanding user
requirements}," failing to comprehend their assigned tasks accurately.
Moreover, the impact of different repository-level contexts on this issue
exhibits significant disparities across different programming languages,
suggesting that, in practice, specialized contextual information needs to be
designed for different languages.

</details>


### [14] [Tool-integrated Reinforcement Learning for Repo Deep Search](https://arxiv.org/abs/2508.03012)
*Zexiong Ma,Chao Peng,Qunhong Zeng,Pengfei Gao,Yanzhen Zou,Bing Xie*

Main category: cs.SE

TL;DR: ToolTrain是一个两阶段工具集成训练框架，通过结合拒绝采样的监督微调和工具集成强化学习，提升LLM在问题定位中使用检索工具的能力，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言问题描述与错误代码之间的语义鸿沟，以及现有LLM代理在多步推理和导航过程中有效利用检索工具的挑战。

Method: 提出ToolTrain框架，结合拒绝采样的监督微调和工具集成强化学习，训练LLM以更好地使用检索工具进行问题定位。

Result: ToolTrain训练的模型在问题定位上达到最先进性能，32B模型甚至超越Claude-3.7，且定位性能提升带来更好的端到端问题解决性能。

Conclusion: ToolTrain证明了通过问题定位训练提升自动化软件开发的有效性。

Abstract: Issue localization, the process of identifying code locations that need
modification to resolve software issues, is a critical yet challenging task in
software development. The semantic gap between natural language issue
descriptions and faulty code requires complex multi-hop reasoning through code
dependencies. Existing LLM-based agents attempt to address this by integrating
repository retrieval tools. However, this transforms issue localization into a
demanding task we call Repo Deep Search, which requires the LLM to effectively
utilize various repository retrieval tools throughout a multi-step reasoning
and navigation process. To tackle this challenge, we present ToolTrain, a
two-stage tool-integrated training framework combining rejection-sampled
supervised fine-tuning and tool-integrated reinforcement learning to enhance
LLMs' ability to use retrieval tools for issue localization. Experimental
results show that ToolTrain-trained models achieve state-of-the-art
performance, with our 32B model even surpassing Claude-3.7 on function-level
localization. The results also show that improved localization performance
translates to better end-to-end issue resolution performance. This further
demonstrates that training for issue localization is a viable and effective
strategy for improving automated software development.

</details>


### [15] [A System Model Generation Benchmark from Natural Language Requirements](https://arxiv.org/abs/2508.03215)
*Dongming Jin,Zhi Jin,Linyu Li,Zheng Fang,Jia Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: SysMBench是一个包含151个场景的基准测试，用于评估大型语言模型（LLM）生成系统模型的能力，结果显示LLM在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 系统模型在软件开发中至关重要，但开发困难且缺乏公开示例。LLM在代码生成方面有潜力，但缺乏评估其生成系统模型能力的基准。

Method: 提出SysMBench基准，包含自然语言需求描述、系统模型和可视化图表，并引入SysMEval评估指标。

Result: 评估17种LLM，最高BLEU为4%，SysMEval-F1为62%，表现不佳。

Conclusion: LLM在系统模型生成任务上表现有限，SysMBench为未来研究提供了基准和框架。

Abstract: System models, a critical artifact in software development, provide a formal
abstraction of both the structural and behavioral aspects of software systems,
which can facilitate the early requirements analysis and architecture design.
However, developing system models remains challenging due to the specific
syntax of model description languages and the relative scarcity of public model
examples. While large language models (LLMs) have shown promise in generating
code with programming languages and could potentially aid in system model
development, no benchmarks currently exist for evaluating their ability to
generate system models with specific description languages. We present
SysMBench, which comprises 151 human-curated scenarios spanning a wide range of
popular domains and varying difficulty levels. Each scenario mainly comprises a
natural language requirements description, a system model expressed in a
specific model description language, and a visualized system model diagram. The
requirements description is fed as user input to the LLM, the system model with
description language is used to verify if the generated system model conforms
to the requirements, and the visualized diagram serves to support manual
validation. We introduce SysMEval, a semantic-aware evaluation metric to
evaluate the quality of generated system models. We evaluate 17 popular LLMs on
this task with three traditional metrics and SysMEval, from directly prompting
to three commonly used enhancement strategies. Our in-depth evaluation shows
that LLMs perform poorly on SysMBench, with the highest BLEU of 4% and
SysMEval-F1 of 62%. We release the SysMBench and its evaluation framework to
enable future research on LLM-based system model generation.

</details>


### [16] [SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization](https://arxiv.org/abs/2508.03258)
*Yueyue Liu,Hongyu Zhang,Yuantian Miao*

Main category: cs.SE

TL;DR: 论文提出SmartLLMs Scheduler (SLS)，一种动态调度方案，通过实时反馈优化LLM部署，显著提升性能和降低成本。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在软件工程任务中表现优异，但实际部署面临高成本、长响应时间和性能不稳定等问题，现有静态调度方法依赖大量训练数据，限制了灵活性和适用性。

Method: SLS包含三个核心组件：自适应缓存管理器、性能-成本优化调度器和动态更新管理器，通过实时反馈动态调整策略。

Result: 实验表明，SLS在性能上平均提升198.82%，处理时间减少63.28%。

Conclusion: SLS为LLM的动态调度提供了一种高效、灵活的解决方案，显著优于现有方法。

Abstract: Large Language Models (LLMs) such as GPT-4 and Llama have shown remarkable
capabilities in a variety of software engineering tasks. Despite the
advancements, their practical deployment faces challenges, including high
financial costs, long response time, and varying performance, especially when
handling a large number of queries (jobs). Existing optimization strategies for
deploying LLMs for diverse tasks focus on static scheduling, which requires
extensive training data for performance prediction, increasing the
computational costs and limiting the applicability and flexibility. In this
paper, we propose the SmartLLMs Scheduler (SLS), a dynamic and cost-effective
scheduling solution. The key idea is to learn LLMs' performance on diverse
tasks and incorporate their real-time feedback to update strategies
periodically. Specifically, SLS incorporates three key components, including an
Adaptive Cache Manager, a Performance-Cost Optimized Scheduler, and a Dynamic
Update Manager. The Cache Manager stores the outputs of previously processed
queries and employs an adaptive strategy to reduce redundant computations and
minimize response times. For queries not found in the cache, the Scheduler
dynamically allocates them to the most suitable LLM based on the predicted
performance and cost from models that take both query-specific and LLM-specific
features as input. The Update Manager continuously refines the cache and
scheduling strategies based on real-time feedback from the assigned queries to
enhance decision-making and adapt to evolving task characteristics. To evaluate
the effectiveness of SLS, we conduct extensive experiments on two LLM-based
software engineering tasks, including log parsing and code generation. The
results show that SLS significantly outperforms the baseline methods, achieving
an average performance improvement of 198.82% and an average processing time
reduction of 63.28%.

</details>


### [17] [GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking](https://arxiv.org/abs/2508.03298)
*Kristian Kolthoff,Felix Kretzer,Christian Bartelt,Alexander Maedche,Simone Paolo Ponzetto*

Main category: cs.SE

TL;DR: GUI-ReRank是一个结合嵌入检索和MLLM重排的新框架，显著提升了GUI检索的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: GUI原型设计资源密集且耗时，现有NL检索方法性能有限且泛化能力不足。

Method: 集成快速嵌入检索与MLLM重排技术，并提供可定制的GUI库标注和嵌入流程。

Result: 在基准测试中显著优于现有LTR模型，并在检索效果与计算资源间提供权衡分析。

Conclusion: GUI-ReRank为GUI检索提供了高效、可扩展的解决方案。

Abstract: GUI prototyping is a fundamental component in the development of modern
interactive systems, which are now ubiquitous across diverse application
domains. GUI prototypes play a critical role in requirements elicitation by
enabling stakeholders to visualize, assess, and refine system concepts
collaboratively. Moreover, prototypes serve as effective tools for early
testing, iterative evaluation, and validation of design ideas with both end
users and development teams. Despite these advantages, the process of
constructing GUI prototypes remains resource-intensive and time-consuming,
frequently demanding substantial effort and expertise. Recent research has
sought to alleviate this burden through NL-based GUI retrieval approaches,
which typically rely on embedding-based retrieval or tailored ranking models
for specific GUI repositories. However, these methods often suffer from limited
retrieval performance and struggle to generalize across arbitrary GUI datasets.
In this work, we present GUI-ReRank, a novel framework that integrates rapid
embedding-based constrained retrieval models with highly effective MLLM-based
reranking techniques. GUI-ReRank further introduces a fully customizable GUI
repository annotation and embedding pipeline, enabling users to effortlessly
make their own GUI repositories searchable, which allows for rapid discovery of
relevant GUIs for inspiration or seamless integration into customized LLM-based
RAG workflows. We evaluated our approach on an established NL-based GUI
retrieval benchmark, demonstrating that GUI-ReRank significantly outperforms
SOTA tailored LTR models in both retrieval accuracy and generalizability.
Additionally, we conducted a comprehensive cost and efficiency analysis of
employing MLLMs for reranking, providing valuable insights regarding the
trade-offs between retrieval effectiveness and computational resources. Video:
https://youtu.be/_7x9UCh82ug

</details>


### [18] [Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach](https://arxiv.org/abs/2508.03329)
*Mari Ashiga,Vardan Voskanyan,Fateme Dinmohammadi,Jingzhi Gong,Paul Brookes,Matthew Truscott,Rafail Giavrimis,Mike Basios,Leslie Kanthan,Wei Jie*

Main category: cs.SE

TL;DR: 论文提出了一种Mixture-of-Agents（MoA）方法，用于在受监管行业中实现高效代码优化，结合开源模型节省成本并提升速度。


<details>
  <summary>Details</summary>
Motivation: 受监管行业因隐私和合规要求无法使用商业LLM，需找到一种既能保持高质量代码优化又经济高效的方法。

Method: 采用MoA方法，结合多个专用LLM生成代码，并与遗传算法（GA）和单个LLM优化器进行对比。

Result: MoA在开源模型中表现优异，节省14.3%至22.2%成本，优化时间缩短28.6%至32.2%。GA在商业模型中更优，但两种集成方法均优于单个LLM。

Conclusion: MoA为受监管行业提供了兼顾合规性和优化性能的可行方案，并通过实际验证展示了其有效性。

Abstract: Recent advancements in Large Language Models (LLMs) for code optimization
have enabled industrial platforms to automate software performance engineering
at unprecedented scale and speed. Yet, organizations in regulated industries
face strict constraints on which LLMs they can use - many cannot utilize
commercial models due to data privacy regulations and compliance requirements,
creating a significant challenge for achieving high-quality code optimization
while maintaining cost-effectiveness. We address this by implementing a
Mixture-of-Agents (MoA) approach that directly synthesizes code from multiple
specialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm
(GA)-based ensemble system and individual LLM optimizers using real-world
industrial codebases. Our key contributions include: (1) First MoA application
to industrial code optimization using real-world codebases; (2) Empirical
evidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost
savings and 28.6% to 32.2% faster optimization times for regulated
environments; (3) Deployment guidelines demonstrating GA's advantage with
commercial models while both ensembles outperform individual LLMs; and (4)
Real-world validation across 50 code snippets and seven LLM combinations,
generating over 8,700 variants, addresses gaps in industrial LLM ensemble
evaluation. This provides actionable guidance for organizations balancing
regulatory compliance with optimization performance in production environments.

</details>


### [19] [Key-Augmented Neural Triggers for Knowledge Sharing](https://arxiv.org/abs/2508.03340)
*Alex Wolf,Marco Edoardo Palma,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: KANT是一种新方法，通过嵌入知识锚点解决代码库理解中的语义碎片化和检索效率问题，减少推理延迟并支持本地部署。


<details>
  <summary>Details</summary>
Motivation: 解决代码库理解中的语义碎片化、检索效率低、训练数据稀缺以及专有LLM的隐私问题。

Method: 提出Key-Augmented Neural Triggers (KANT)，嵌入知识锚点，合成专用数据，减少推理时的上下文负担。

Result: 合成数据与需求对齐，KANT在人类评估中获60%偏好，推理延迟降低85%。

Conclusion: KANT适合低延迟、本地部署的代码理解，为行业提供实用解决方案。

Abstract: Repository-level code comprehension and knowledge sharing remain core
challenges in software engineering. Large language models (LLMs) have shown
promise by generating explanations of program structure and logic. However,
these approaches still face limitations: First, relevant knowledge is
distributed across multiple files within a repository, aka semantic
fragmentation. Second, retrieval inefficiency and attention saturation degrade
performance in RAG pipelines, where long, unaligned contexts overwhelm
attention. Third, repository specific training data is scarce and often
outdated. Finally, proprietary LLMs hinder industrial adoption due to privacy
and deployment constraints. To address these issues, we propose Key-Augmented
Neural Triggers (KANT), a novel approach that embeds knowledge anchors into
both training and inference. Unlike prior methods, KANT enables internal access
to repository specific knowledge, reducing fragmentation and grounding
inference in localized context. Moreover, we synthesize specialized data
directly from code. At inference, knowledge anchors replace verbose context,
reducing token overhead and latency while supporting efficient, on premise
deployment. We evaluate KANT via: a qualitative human evaluation of the
synthesized dataset's intent coverage and quality across five dimensions;
compare against SOTA baselines across five qualitative dimensions and inference
speed; and replication across different LLMs to assess generalizability.
Results show that the synthetic training data aligned with information-seeking
needs. KANT achieved over 60% preference from human annotators and a LocalStack
expert (preferring 79% of cases). Also, KANT reduced inference latency by up to
85% across all models. Overall, it is well-suited for scalable, low-latency,
on-premise deployments, providing a strong foundation for code comprehension.

</details>


### [20] [Psychological safety in software workplaces: A systematic literature review](https://arxiv.org/abs/2508.03369)
*Beatriz Santana,Lidivânio Monte,Bianca Santana de Araújo Silva,Glauco Carneiro,Sávio Freire,José Amancio Macedo Santos,Manoel Mendonça*

Main category: cs.SE

TL;DR: 本文通过系统文献综述，总结了软件工程中心理安全（PS）的现有知识，识别了其前因后果，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 心理安全对团队福祉和绩效至关重要，但软件工程领域相关研究有限，亟需系统综述。

Method: 采用系统文献综述方法，从四个数字图书馆检索研究，进行定量和定性分析。

Result: 研究发现PS在软件工程中日益受关注，前因包括团队自主权、敏捷方法和领导行为。

Conclusion: PS促进创新和学习，但对其影响因素和提升策略的理解仍有不足，未来需进一步研究。

Abstract: Context: Psychological safety (PS) is an important factor influencing team
well-being and performance, particularly in collaborative and dynamic domains
such as software development. Despite its acknowledged significance, research
on PS within the field of software engineering remains limited. The
socio-technical complexities and fast-paced nature of software development
present challenges to cultivating PS. To the best of our knowledge, no
systematic secondary study has synthesized existing knowledge on PS in the
context of software engineering.
  Objective: This study aims to systematically review and synthesize the
existing body of knowledge on PS in software engineering. Specifically, it
seeks to identify the potential antecedents and consequences associated with
the presence or absence of PS among individuals involved in the software
development process.
  Methods: A systematic literature review was conducted, encompassing studies
retrieved from four digital libraries. The extracted data were subjected to
both quantitative and qualitative analyses.
  Results: The findings indicate a growing academic interest in PS within
software engineering, with the majority of studies grounded in Edmondson's
framework. Factors antecedents of PS were identified at the individual, team,
and organizational levels, including team autonomy, agile methodologies, and
leadership behaviors.
  Conclusion: PS fosters innovation, learning, and team performance within
software development. However, significant gaps persist in understanding the
contextual factors influencing PS, its underlying mechanisms, and effective
strategies for its enhancement. Future research should address these gaps by
investigating the practical applications of PS within diverse organizational
settings in the software engineering domain.

</details>


### [21] [Agentic AI in 6G Software Businesses: A Layered Maturity Model](https://arxiv.org/abs/2508.03393)
*Muhammad Zohaib,Muhammad Azeem Akbar,Sami Hyrynsalmi,Arif Ali Khan*

Main category: cs.SE

TL;DR: 论文研究了6G软件业务中代理型AI系统的机遇与挑战，通过主题映射识别了影响采用的因素，提出了一个可行性评估框架。


<details>
  <summary>Details</summary>
Motivation: 探讨代理型AI系统在6G环境中的战略机遇与挑战，为组织提供采用决策的依据。

Method: 采用多源文献综述和针对性扫描，识别并分类了29个激励因素和27个抑制因素。

Result: 提出了五类高层主题，为代理型转型的组织准备提供了结构化视角。

Conclusion: 研究为软件驱动组织提供了一个评估和提升代理优先能力的实用框架。

Abstract: The emergence of agentic AI systems in 6G software businesses presents both
strategic opportunities and significant challenges. While such systems promise
increased autonomy, scalability, and intelligent decision-making across
distributed environments, their adoption raises concerns regarding technical
immaturity, integration complexity, organizational readiness, and
performance-cost trade-offs. In this study, we conducted a preliminary thematic
mapping to identify factors influencing the adoption of agentic software within
the context of 6G. Drawing on a multivocal literature review and targeted
scanning, we identified 29 motivators and 27 demotivators, which were further
categorized into five high-level themes in each group. This thematic mapping
offers a structured overview of the enabling and inhibiting forces shaping
organizational readiness for agentic transformation. Positioned as a
feasibility assessment, the study represents an early phase of a broader
research initiative aimed at developing and validating a layered maturity model
grounded in CMMI model with the software architectural three dimensions
possibly Data, Business Logic, and Presentation. Ultimately, this work seeks to
provide a practical framework to help software-driven organizations assess,
structure, and advance their agent-first capabilities in alignment with the
demands of 6G.

</details>


### [22] [On the Evaluation of Large Language Models in Multilingual Vulnerability Repair](https://arxiv.org/abs/2508.03470)
*Dong wang,Junji Yu,Honglin Shu,Michael Fu,Chakkrit Tantithamthavorn,Yasutaka Kamei,Junjie Chen*

Main category: cs.SE

TL;DR: 论文研究了基于大型语言模型（LLMs）的多语言漏洞修复方法，发现指令调优的GPT-4o在性能上接近领先方法VulMaster，并在某些方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的漏洞修复方法局限于特定语言（如C/C++），而LLMs具备语言无关性和语义理解能力，可能突破多语言漏洞修复的限制。

Method: 通过大规模实证研究，比较了自动化漏洞修复方法和最新LLMs在七种编程语言中的表现，重点关注指令调优的GPT-4o。

Result: GPT-4o在修复独特漏洞和最危险漏洞方面表现优异，且在未见过的语言中泛化能力强。Go语言修复效果最佳，C/C++最差。

Conclusion: LLMs在多语言漏洞修复中展现出潜力，但仍需进一步研究失败案例的原因。

Abstract: Various Deep Learning-based approaches with pre-trained language models have
been proposed for automatically repairing software vulnerabilities. However,
these approaches are limited to a specific programming language (C/C++). Recent
advances in large language models (LLMs) offer language-agnostic capabilities
and strong semantic understanding, exhibiting potential to overcome
multilingual vulnerability limitations. Although some work has begun to explore
LLMs' repair performance, their effectiveness is unsatisfactory. To address
these limitations, we conducted a large-scale empirical study to investigate
the performance of automated vulnerability repair approaches and
state-of-the-art LLMs across seven programming languages. Results show GPT-4o,
instruction-tuned with few-shot prompting, performs competitively against the
leading approach, VulMaster. Additionally, the LLM-based approach shows
superior performance in repairing unique vulnerabilities and is more likely to
repair the most dangerous vulnerabilities. Instruction-tuned GPT-4o
demonstrates strong generalization on vulnerabilities in previously unseen
language, outperforming existing approaches. Analysis shows Go consistently
achieves the highest effectiveness across all model types, while C/C++ performs
the worst. Based on findings, we discuss the promise of LLM on multilingual
vulnerability repair and the reasons behind LLM's failed cases. This work takes
the first look at repair approaches and LLMs across multiple languages,
highlighting the promising future of adopting LLMs for multilingual
vulnerability repair.

</details>


### [23] [BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice](https://arxiv.org/abs/2508.03487)
*Yuanpeng Li,Qi Long,Zhiyuan Yao,Jian Xu,Lintao Xie,Xu He,Lu Geng,Xin Han,Yueyan Chen,Wenbo Duan*

Main category: cs.SE

TL;DR: BitsAI-Fix是一种基于大型语言模型（LLM）的自动化lint错误修复工作流，通过树解析器扩展上下文并生成补丁，结合渐进式强化学习策略和规则奖励机制，在字节跳动生产中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 企业代码库规模扩大导致lint错误远超工程师手动修复能力，技术债务积累和开发效率受阻。

Method: 使用树解析器扩展上下文，通过LLM生成补丁，结合渐进式强化学习策略和规则奖励机制，持续跟踪在线效果。

Result: 在字节跳动支持5000+工程师，解决12000+静态分析问题，修复准确率约85%，每周活跃用户约1000。

Conclusion: 证明了LLM在代码修复中的可行性，为大规模工业场景提供参考。

Abstract: As enterprise codebases continue to grow in scale and complexity, the volume
of lint errors far exceeds engineers' manual remediation capacity, leading to
continuous accumulation of technical debt and hindered development efficiency.
This paper presents BitsAI-Fix, an automated lint error remediation workflow
based on Large Language Models (LLMs), designed to address this critical
challenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for
context expansion and generates search-and-replace format patches through
specially trained LLMs, followed by lint scan re-verification to output final
remediation results. Additionally, our approach introduces an innovative
progressive reinforcement learning (RL) training strategy that can
automatically acquire verifiable training data during the project cold-start
phase and continuously iterate the model by collecting online samples through
feedback after system deployment. Furthermore, we designed a targeted
rule-based reward mechanism that combines format rewards and correctness
rewards while penalizing redundant modifications. We also propose a "code diff
matching" methodology to continuously track online effectiveness. In production
deployment at ByteDance, our solution has supported over 5,000 engineers,
resolved more than 12,000 static analysis issues, achieved approximately 85%
remediation accuracy, with around 1,000 weekly active adopters. This work
demonstrates the practical feasibility of LLM-based code remediation solutions
in enterprise environments and serves as a reference for automated code fix in
large-scale industrial scenarios.

</details>


### [24] [LaTCoder: Converting Webpage Design to Code with Layout-as-Thought](https://arxiv.org/abs/2508.03560)
*Yi Gui,Zhen Li,Zhongyi Zhang,Guohao Wang,Tianpeng Lv,Gaoyang Jiang,Yi Liu,Dongping Chen,Yao Wan,Hongyu Zhang,Wenbin Jiang,Xuanhua Shi,Hai Jin*

Main category: cs.SE

TL;DR: LaTCoder通过Layout-as-Thought方法提升网页设计到代码转换中的布局保留能力，显著优于直接提示方法。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在网页设计到代码转换中布局保留不准确的问题。

Method: 将网页设计划分为图像块，采用Chain-of-Thought方法生成代码，并通过绝对定位和MLLM组装策略动态选择最优输出。

Result: 在DeepSeek-VL2上，TreeBLEU提升66.67%，MAE降低38%，60%以上人工评估偏好LaTCoder生成结果。

Conclusion: LaTCoder有效提升布局保留能力，为设计到代码转换任务提供新思路。

Abstract: Converting webpage designs into code (design-to-code) plays a vital role in
User Interface (UI) development for front-end developers, bridging the gap
between visual design and functional implementation. While recent Multimodal
Large Language Models (MLLMs) have shown significant potential in
design-to-code tasks, they often fail to accurately preserve the layout during
code generation. To this end, we draw inspiration from the Chain-of-Thought
(CoT) reasoning in human cognition and propose LaTCoder, a novel approach that
enhances layout preservation in webpage design during code generation with
Layout-as-Thought (LaT). Specifically, we first introduce a simple yet
efficient algorithm to divide the webpage design into image blocks. Next, we
prompt MLLMs using a CoTbased approach to generate code for each block.
Finally, we apply two assembly strategies-absolute positioning and an
MLLM-based method-followed by dynamic selection to determine the optimal
output. We evaluate the effectiveness of LaTCoder using multiple backbone MLLMs
(i.e., DeepSeek-VL2, Gemini, and GPT-4o) on both a public benchmark and a newly
introduced, more challenging benchmark (CC-HARD) that features complex layouts.
The experimental results on automatic metrics demonstrate significant
improvements. Specifically, TreeBLEU scores increased by 66.67% and MAE
decreased by 38% when using DeepSeek-VL2, compared to direct prompting.
Moreover, the human preference evaluation results indicate that annotators
favor the webpages generated by LaTCoder in over 60% of cases, providing strong
evidence of the effectiveness of our method.

</details>


### [25] [Intent Preserving Generation of Diverse and Idiomatic (Code-)Artifacts](https://arxiv.org/abs/2508.03642)
*Oliver Westphal*

Main category: cs.SE

TL;DR: 提出一种基于抽象构建块的方法，用于自动生成编程练习任务和相关工件，避免编写复杂的单体生成器。


<details>
  <summary>Details</summary>
Motivation: 解决自动生成编程任务时，编写多样且符合习惯的代码生成器的挑战，尤其是需要生成多个相关工件时的复杂性。

Method: 使用小型抽象构建块定义具体实现，通过组合这些构建块生成相关工件，避免直接编写复杂的单体生成器。

Result: 方法具有通用性，适用于多种上下文，能够自动生成多样化的编程任务和相关工件。

Conclusion: 该方法简化了编程任务生成过程，提高了灵活性和适应性。

Abstract: When automatically generating programming exercise tasks one often also needs
to automatically generate programs. At the very least when providing sample
solutions is part of automated feedback. But programs can also be used as part
of the exercise task description to communicate a task's requirements.
  Writing good program generators that produce varied yet idiomatic code while
being easily adaptable for new tasks is challenging. The challenges are
intensified if task generation requires additional artifacts, like a more
general behavior specification for testing or additional textual descriptions.
Manually writing generators for multiple different but strongly related
artifacts gets complicated quickly.
  We present an approach where instead of writing monolithic generators for
multiple connected artifacts one specifies a small set of abstract building
blocks and for each such building block defines sets of concrete realizations
for various kinds of artifacts. Then the intended structure of the resulting
artifacts is specified as a composition of the small abstract building blocks.
This abstract description then serves as the common source from which related
artifacts can be derived automatically. The approach is generic in the kind of
artifacts it can produce and is therefore adaptable to a wide range of
contexts.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [26] [When are two algorithms the same? Towards addressing Hilbert's 24th problem](https://arxiv.org/abs/2508.02764)
*Konstantin Doubrovinski*

Main category: cs.LO

TL;DR: 探讨两个定理证明或程序是否“本质上相同”的问题，基于递归理论和柯尔莫哥洛夫复杂性提出了一种极简方法。


<details>
  <summary>Details</summary>
Motivation: 受希尔伯特未列入其著名问题列表的启发，研究证明或程序的本质相似性。

Method: 利用递归理论和柯尔莫哥洛夫复杂性构建极简框架。

Result: 提出了一种判断证明或程序本质相似性的方法。

Conclusion: 该方法为研究证明和程序的相似性提供了新视角。

Abstract: The informal question of when two theorem proofs are "essentially the same"
goes back to David Hilbert, who considered adding it (or something largely
equivalent) to his famous list of open problems, but eventually decided to
leave it out. Given that the notion of a formal proof is closely related to
that of a (computer) program, i.e. a recursive function, it may be useful to
ask the same question with regard to programs instead. Here we propose a
minimalistic approach to this question within Recursion Theory, building
heavily on the use of Kolmogorov Complexity.

</details>


### [27] [Intensional FOL over Belnap's Billatice for Strong-AI Robotics](https://arxiv.org/abs/2508.02774)
*Zoran Majkic*

Main category: cs.LO

TL;DR: 论文提出了一种基于扩展的IFOL逻辑系统，用于解决AGI机器人学习中的悖论和不完整知识问题。


<details>
  <summary>Details</summary>
Motivation: AGI机器人需要接近人类智能的学习和问题解决能力，但标准FOL存在悖论和不完整知识的局限性。

Method: 提出了一种扩展的IFOL逻辑系统，基于Belnap的四种真值，支持真值排序和知识排序。

Result: 该方法能够处理不一致公式和不完整知识，适用于AGI机器人的智能发展。

Conclusion: 扩展的IFOL为AGI机器人提供了一种更接近人类智能的逻辑框架。

Abstract: AGI (Strong AI) aims to create intelligent robots that are quasi
indistinguishable from the human mind. Like a child, the AGI robot would have
to learn through input and experiences, constantly progressing and advancing
its abilities over time. The AGI robot would require an intelligence more close
to human's intelligence: it would have a self-aware consciousness that has the
ability to solve problems, learn, and plan. Based on this approach an
Intensional many-sorted First-order Logic (IFOL), as an extension of a standard
FOL with Tarskian's semantics, is proposed in order to avoid the problems of
standard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity
for robots to work with incomplete (unknown) knowledge as well. This is a more
sophisticated version of IFOL with the same syntax but different semantics,
able to deal with truth-ordering and knowledge-ordering as well, based on the
well known Belnap's billatice with four truth-values that extend the set of
classical two truth-values.

</details>


### [28] [Analysis of logics with arithmetic](https://arxiv.org/abs/2508.03574)
*Michael Benedikt,Chia-Hsuan Lu,Tony Tan*

Main category: cs.LO

TL;DR: 论文研究了带计数和算术的逻辑的有限可满足性，给出了二变量逻辑的紧复杂度界限，并简化了先前关键结果的证明。


<details>
  <summary>Details</summary>
Motivation: 探索带计数和算术的逻辑的有限可满足性，填补相关领域的研究空白。

Method: 分析二变量逻辑与一元公式的基数比较，以及局部Presburger量词的逻辑。

Result: 获得了紧复杂度界限，并简化了先前结果的证明。

Conclusion: 论文为相关逻辑的有限可满足性提供了新的理论支持和方法简化。

Abstract: We present new results on finite satisfiability of logics with counting and
arithmetic. This includes tight bounds on the complexity for two-variable logic
with counting and cardinality comparisons between unary formulas, and also on
logics with so-called local Presburger quantifiers. In the process, we provide
simpler proofs of some key prior results on finite satisfiability and
semi-linearity of the spectrum for these logics.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [29] [Learning Event-recording Automata Passively](https://arxiv.org/abs/2508.03627)
*Anirban Majumdar,Sayan Mukherjee,Jean-François Raskin*

Main category: cs.FL

TL;DR: 本文提出了一种状态合并算法LEAP，用于从符号化时间词的样本中学习事件记录自动机（ERA）定义的时间语言，并证明了状态合并的NP完全性。


<details>
  <summary>Details</summary>
Motivation: 研究如何从正负样本中学习时间语言，以解决事件记录自动机的状态合并问题。

Method: 开发了LEAP算法，基于合并技术从样本中构建可能非确定性的事件记录自动机，并使用SMT求解器解决NP完全性问题。

Result: 算法通过实例验证了有效性，并证明所有ERA可定义的语言均可通过合适样本推断。

Conclusion: LEAP算法能有效学习ERA定义的时间语言，解决了状态合并的复杂性问题。

Abstract: This paper presents a state-merging algorithm for learning timed languages
definable by Event-Recording Automata (ERA) using positive and negative samples
in the form of symbolic timed words. Our algorithm, LEAP (Learning
Event-recording Automata Passively), constructs a possibly nondeterministic ERA
from such samples based on merging techniques. We prove that determining
whether two ERA states can be merged while preserving sample consistency is an
NP-complete problem, and address this with a practical SMT-based solution. Our
implementation demonstrates the algorithm's effectiveness through examples. We
also show that every ERA-definable language can be inferred using our algorithm
with a suitable sample.

</details>


### [30] [Design Support for Multitape Turing Machines](https://arxiv.org/abs/2508.03638)
*Marco T. Morazán,Oliwia Kempinski,Andrés M. Garced*

Main category: cs.FL

TL;DR: 论文介绍了三种可视化工具，帮助学生理解和设计多带图灵机，并提供了实证数据支持其有效性。


<details>
  <summary>Details</summary>
Motivation: 学生在学习多带图灵机时面临挑战，现有的FSM编程语言支持不足，需要更直观的工具辅助理解。

Method: 开发了三种可视化工具：动态模拟执行工具、静态过渡图渲染工具和静态计算图渲染工具。

Result: 工具受到学生欢迎，并被证明有助于理解和设计多带图灵机。

Conclusion: 可视化工具能有效提升学生对多带图灵机的理解和设计能力。

Abstract: Many Formal Languages and Automata Theory courses introduce students to
Turing machine extensions. One of the most widely-used extensions endows Turing
machines with multiple tapes. Although multitape Turing machines are an
abstraction to simplify Turing machine design, students find them no less
challenging. To aid students in understanding these machines, the FSM
programming language provides support for their definition and execution. This,
however, has proven insufficient for many students to understand the
operational semantics of such machines and to understand why such machines
accept or reject a word. To address this problem, three visualization tools
have been developed. The first is a dynamic visualization tool that simulates
machine execution. The second is a static visualization tool that automatically
renders a graphic for a multitape Turing machine's transition diagram. The
third is a static visualization tool that automatically renders computation
graphs for multitape Turing machines. This article presents these tools and
illustrates how they are used to help students design and implement multitape
Turing machines. In addition, empirical data is presented that suggests these
tools are well-received and found useful by students.

</details>


### [31] [A Design Recipe and Recipe-Based Errors for Regular Expressions](https://arxiv.org/abs/2508.03639)
*Marco T. Morazán,Shamil Dzhatdoyev,Josephine Des Rosiers,Tijana Minić,Andrés M. Garced,David Anthony K. Fields*

Main category: cs.FL

TL;DR: 提出了一种支持正则表达式设计的新框架，包括设计方法和错误提示系统。


<details>
  <summary>Details</summary>
Motivation: 为形式语言与自动机理论学生提供正则表达式设计的支持。

Method: 框架包含正则表达式的设计方法和定制化的错误提示系统，错误信息基于设计步骤。

Result: 错误信息简洁、无术语且非指令性，并开发了简写语法用于单元测试。

Conclusion: 框架在课堂中应用，展示了调试过程和错误提示系统的实现。

Abstract: This article presents a novel framework to provide Formal Languages and
Automata Theory students design support for the development of regular
expressions. This framework includes a design recipe for regular expressions
and a customized error messaging system. The error messaging system produces
recipe-based errors that include the step of the design recipe not successfully
completed. Furthermore, the error messages follow the established practices of
being concise, succinct, jargon-free, and nonprescriptive. In addition, a
shorthand syntax developed for writing unit tests is described. The in-class
use of the design recipe is illustrated, two debugging sessions using the
described system are discussed, and the implementation of the error messaging
system is briefly sketched.

</details>


### [32] [Visual Execution and Validation of Finite-State Machines and Pushdown Automata](https://arxiv.org/abs/2508.03641)
*Marco T. Morazán,David Anthony K. Fields,Andrés M. Garced,Tijana Minić*

Main category: cs.FL

TL;DR: 论文提出两种动态可视化工具，帮助学生理解非确定性有限状态自动机和下推自动机的操作语义。


<details>
  <summary>Details</summary>
Motivation: 学生在形式语言与自动机理论课程中难以理解非确定性自动机和下推自动机的操作语义，尤其是堆栈相关的推理。

Method: 开发了两种动态可视化工具，逐步展示非确定性有限状态机和下推自动机的所有可能计算，并支持机器验证。

Result: 工具能够帮助学生直观地理解自动机的行为，验证状态转换时的属性。

Conclusion: 动态可视化工具有效提升了学生对非确定性自动机和下推自动机的理解能力。

Abstract: In Formal Languages and Automata Theory courses, students find understanding
nondeterministic finite-state and pushdown automata difficult. In many cases,
this means that it is challenging for them to comprehend the operational
semantics of such machines and, as a consequence, determine why a word is
accepted or rejected. This is not entirely surprising, because students are
mostly trained to design and implement deterministic programs. Comprehension of
pushdown automata is further complicated, because reasoning about the stack is
necessary. A common difficulty students face, for example, is understanding
that two different computations on the same word may reach the same state with
different stack values. To aid student understanding, we present two novel
dynamic visualization tools for FSM -- a domain-specific programming language
for the Automata Theory classroom -- to support the design of such machines.
These tools visualize all computations that may be performed, respectively, by
a nondeterministic finite-state machine or by a pushdown automata in a stepwise
manner. In addition, these tools aid the machine verification process by
allowing users to visually validate whether the properties a state represents
hold when a machine transitions into it.

</details>
