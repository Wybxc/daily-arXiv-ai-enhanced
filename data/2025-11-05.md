<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 7]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 13]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [ScenicProver: A Framework for Compositional Probabilistic Verification of Learning-Enabled Systems](https://arxiv.org/abs/2511.02164)
*Eric Vin,Kyle A. Miller,Inigo Incer,Sanjit A. Seshia,Daniel J. Fremont*

Main category: cs.LO

TL;DR: ScenicProver是一个用于学习型信息物理系统的组合验证框架，支持组件化描述、假设-保证契约、多种证据生成方式，并能自动生成保证案例。


<details>
  <summary>Details</summary>
Motivation: 现有工具要么只能为有限类型的系统提供形式化保证，要么将系统作为整体进行测试，缺乏在复杂现实环境中使用不同验证技术对学习型信息物理系统进行组合分析的通用框架。

Method: 基于Scenic概率编程语言构建，支持：组件化系统描述、使用扩展线性时序逻辑的假设-保证契约、通过测试和Lean 4集成生成证据、系统化组合证据、自动生成保证案例。

Result: 通过自动驾驶车辆自动紧急制动系统的案例研究，展示了该框架的有效性。在相同计算预算下，相比整体测试方法，能够获得更强的概率保证。

Conclusion: ScenicProver填补了学习型信息物理系统组合验证的空白，为复杂现实环境中的系统验证提供了通用框架。

Abstract: Full verification of learning-enabled cyber-physical systems (CPS) has long
been intractable due to challenges including black-box components and complex
real-world environments. Existing tools either provide formal guarantees for
limited types of systems or test the system as a monolith, but no general
framework exists for compositional analysis of learning-enabled CPS using
varied verification techniques over complex real-world environments. This paper
introduces ScenicProver, a verification framework that aims to fill this gap.
Built upon the Scenic probabilistic programming language, the framework
supports: (1) compositional system description with clear component interfaces,
ranging from interpretable code to black boxes; (2) assume-guarantee contracts
over those components using an extension of Linear Temporal Logic containing
arbitrary Scenic expressions; (3) evidence generation through testing, formal
proofs via Lean 4 integration, and importing external assumptions; (4)
systematic combination of generated evidence using contract operators; and (5)
automatic generation of assurance cases tracking the provenance of system-level
guarantees. We demonstrate the framework's effectiveness through a case study
on an autonomous vehicle's automatic emergency braking system with sensor
fusion. By leveraging manufacturer guarantees for radar and laser sensors and
focusing testing efforts on uncertain conditions, our approach enables stronger
probabilistic guarantees than monolithic testing with the same computational
budget.

</details>


### [2] [Non-commutative linear logic fragments with sub-context-free complexity](https://arxiv.org/abs/2511.02348)
*Yusaku Nishimiya,Masaya Taniguchi*

Main category: cs.LO

TL;DR: 本文提出了Lambek演算中正则语言、线性上下文无关语言和上下文无关语言的描述复杂性特征，通过限制推理规则、公式大小和连接词来实现。这是首次将Lambek演算片段与证明复杂性REG和LCFL联系起来的研究。


<details>
  <summary>Details</summary>
Motivation: 研究计算与逻辑之间相互作用的更广泛和更丰富的特征描述，以及各种序列演算的更细粒度复杂性分离。

Method: 通过限制Lambek演算中的推理规则、公式大小和允许的连接词，建立类型逻辑与形式文法之间的直接转换，并使用结构归纳法证明可证序列。

Result: 首次识别了Lambek演算片段与证明复杂性REG和LCFL的对应关系，展示了最弱变体的CFL复杂性，并确定了Lambek文法中Greibach范式精确类比。

Conclusion: 本文建立了Cut消去定理在比较形式文法和序列演算中的概念效用，为计算与逻辑相互作用的研究迈出了第一步。

Abstract: We present new descriptive complexity characterisations of classes REG
(regular languages), LCFL (linear context-free languages) and CFL (context-free
languages) as restrictions on inference rules, size of formulae and permitted
connectives in the Lambek calculus; fragments of the intuitionistic
non-commutative linear logic with direction-sensitive implication connectives.
Our identification of the Lambek calculus fragments with proof complexity REG
and LCFL is the first result of its kind. We further show the CFL complexity of
one of the strictly `weakest' possible variants of the logic, admitting only a
single inference rule. The proof thereof, moreover, is based on a direct
translation between type-logical and formal grammar and structural induction on
provable sequents; a simpler and more intuitive method than those employed in
prior works. We thereby establish a clear conceptual utility of the
Cut-elimination theorem for comparing formal grammar and sequent calculus, and
identify the exact analogue of the Greibach Normal Form in Lambek grammar. We
believe the result presented herein constitutes a first step toward a more
extensive and richer characterisation of the interaction between computation
and logic, as well as a finer-grained complexity separation of various sequent
calculi.

</details>


### [3] [Large Lemma Miners: Can LLMs do Induction Proofs for Hardware?](https://arxiv.org/abs/2511.02521)
*Romy Peled,Daniel Kroening,Michael Tautschnig,Yakir Vizel*

Main category: cs.LO

TL;DR: LLMs可用于生成硬件验证的归纳证明，通过神经符号方法结合提示框架生成候选不变量，经形式化工具验证，在87%的问题上成功生成正确归纳论证。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs解决数学任务的能力，替代形式验证工程师的部分手动工作，为硬件验证提供工业价值。

Method: 采用神经符号方法，包含两个提示框架生成候选不变量，使用形式化符号工具进行验证。

Result: 对于中等规模的开源RTL设计，通过充分重提示，LLMs能够生成归纳论证，在87%的问题集上至少一个提示设置成功产生可证明正确的归纳论证。

Conclusion: LLMs在硬件验证中具有实际应用潜力，能够有效生成归纳证明，减少人工工作量。

Abstract: Large Language Models (LLMs) have shown potential for solving mathematical
tasks. We show that LLMs can be utilized to generate proofs by induction for
hardware verification and thereby replace some of the manual work done by
Formal Verification engineers and deliver industrial value. We present a
neurosymbolic approach that includes two prompting frameworks to generate
candidate invariants, which are checked using a formal, symbolic tool. Our
results indicate that with sufficient reprompting, LLMs are able to generate
inductive arguments for mid-size open-source RTL designs. For $87\%$ of our
problem set, at least one of the prompt setups succeeded in producing a
provably correct inductive argument.

</details>


### [4] [The Limit of Recursion in State-based Systems](https://arxiv.org/abs/2511.02594)
*Bahareh Afshari,Giacomo Barlucchi,Graham E. Leigh*

Main category: cs.LO

TL;DR: 该论文证明了ω²严格限制了模态可定义函数在所有可数结构上达到不动点所需的迭代次数，纠正并扩展了先前关于无交替μ演算闭包序数的结果。


<details>
  <summary>Details</summary>
Motivation: 纠正和扩展先前关于无交替μ演算闭包序数的错误结果，建立更精确的界限。

Method: 重新采用Kozen的良好标注方法，发展'保守'良好标注理论，确保标注的最小性，并分离结构中局部决定闭包序数的部分。

Result: 证明了ω²是模态可定义函数在所有可数结构上达到不动点所需迭代次数的严格上界。

Conclusion: 通过良好标注方法，建立了直接清晰的泵引理过程，排除了ω²与可数极限之间的闭包序数。

Abstract: We prove that omega^2 strictly bounds the iterations required for modal
definable functions to reach a fixed point across all countable structures. The
result corrects and extends the previously claimed result by the first and
third authors on closure ordinals of the alternation-free mu-calculus in [3].
The new approach sees a reincarnation of Kozen's well-annotations, devised for
showing the finite model property for the modal mu-calculus. We develop a
theory of 'conservative' well-annotations where minimality of annotations is
guaranteed, and isolate parts of the structure that locally determine the
closure ordinal of relevant formulas. This adoption of well-annotations enables
a direct and clear pumping process that rules out closure ordinals between
omega^2 and the limit of countability.

</details>


### [5] [Nominal Algebraic-Coalgebraic Data Types, with Applications to Infinitary Lambda-Calculi](https://arxiv.org/abs/2511.02595)
*Rémy Cerda*

Main category: cs.LO

TL;DR: 本文扩展了名义技术，引入混合绑定签名来处理混合归纳-余归纳项，特别是用于描述abc-无穷lambda项及其α等价类上的替换操作。


<details>
  <summary>Details</summary>
Motivation: 十年前的研究表明名义技术可用于设计带变量绑定的余代数数据类型，本文旨在将该方法扩展到混合归纳-余归纳设置中。

Method: 引入混合绑定签名和相应的混合归纳-余归纳项类型，扩展原有的名义技术框架。

Result: 成功实现了对abc-无穷lambda项集合Lambda_abc的名义描述，以及在这些项的α等价类上的捕获避免替换操作。

Conclusion: 名义技术可以有效地扩展到混合归纳-余归纳设置，为处理复杂绑定结构提供了理论基础。

Abstract: Ten years ago, it was shown that nominal techniques can be used to design
coalgebraic data types with variable binding, so that alpha-equivalence classes
of infinitary terms are directly endowed with a corecursion principle. We
introduce "mixed" binding signatures, as well as the corresponding type of
mixed inductive-coinductive terms. We extend the aforementioned work to this
setting. In particular, this allows for a nominal description of the sets
Lambda_abc of abc-infinitary lambda-terms (for a, b, c in {0,1}) and of
capture-avoiding substitution on alpha-equivalence classes of such terms.

</details>


### [6] [Characterizing the Exponential-Space Hierarchy Via Partial Fixpoints](https://arxiv.org/abs/2511.02596)
*Florian Bruse,David Kronenberger,Martin Lange*

Main category: cs.LO

TL;DR: 本文扩展了Vardi'82的经典结果，将PSPACE查询在有序结构上的特征化推广到k-EXPSPACE查询，证明它们恰好可以用带部分不动点的k+1阶高阶逻辑表达。


<details>
  <summary>Details</summary>
Motivation: 扩展描述复杂性领域的经典结果，将PSPACE查询在有序结构上的特征化推广到更高复杂度的k-EXPSPACE查询。

Method: 使用带部分不动点的k+1阶高阶逻辑来表征k-EXPSPACE查询，对于k>1的情况不再需要有序结构的限制。

Result: 成功证明了k-EXPSPACE查询恰好可以用带部分不动点的k+1阶高阶逻辑表达，对于k>1的情况该特征化适用于任意结构。

Conclusion: 本文为描述复杂性理论提供了从PSPACE到k-EXPSPACE的完整特征化框架，展示了高阶逻辑在表达高复杂度查询方面的强大能力。

Abstract: The characterization of PSPACE-queries over ordered structures as exactly
those expressible in first-order logic with partial fixpoints (Vardi'82) is one
of the classical results in the field of descriptive complexity. In this paper,
we extend this result to characterizations of k-EXPSPACE-queries for arbitrary
k, characterizing them as exactly those expressible in order-k+1-higher-order
logic with partial fixpoints. For k>1, the restriction to ordered structures is
no longer necessary due to the high expressive power of higher-order logic.

</details>


### [7] [The mu-calculus' Alternation Hierarchy is Strict over Non-Trivial Fusion Logics](https://arxiv.org/abs/2511.02597)
*Leonardo Pacheco*

Main category: cs.LO

TL;DR: 模态μ-演算的交替层次结构在非平凡融合模态逻辑上是严格的，但在某些特定语义下（如S5框架）会坍塌为普通模态逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究模态μ-演算中交替层次结构在不同语义框架下的行为，特别是探讨在什么条件下该层次结构是严格的，在什么条件下会坍塌。

Method: 通过分析模态μ-演算中最小和最大不动点算子的交替深度，研究在不同模态逻辑融合框架下的层次结构特性。

Result: 证明了在非平凡融合模态逻辑上，μ-演算的交替层次结构是严格的；同时发现在某些特定模态逻辑（如S5）中，μ-演算会坍塌为普通模态逻辑。

Conclusion: 模态μ-演算的交替层次结构严格性取决于所考虑的语义框架，在一般Kripke框架和非平凡融合逻辑上是严格的，但在某些特定逻辑中会坍塌。

Abstract: The modal mu-calculus is obtained by adding least and greatest fixed-point
operators to modal logic. Its alternation hierarchy classifies the mu-formulas
by their alternation depth: a measure of the codependence of their least and
greatest fixed-point operators. The mu-calculus' alternation hierarchy is
strict over the class of all Kripke frames: for all n, there is a mu-formula
with alternation depth n+1 which is not equivalent to any formula with
alternation depth n. This does not always happen if we restrict the semantics.
For example, every mu-formula is equivalent to a formula without fixed-point
operators over S5 frames. We show that the multimodal mu-calculus' alternation
hierarchy is strict over non-trivial fusions of modal logics. We also comment
on two examples of multimodal logics where the mu-calculus collapses to modal
logic.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [8] [Oriented Metrics for Bottom-Up Enumerative Synthesis](https://arxiv.org/abs/2511.02491)
*Roland Meyer,Jakob Tepe*

Main category: cs.PL

TL;DR: 该论文提出了一种称为定向度量的新结构，用于减少语法引导合成中的搜索空间大小，并在字符串和位向量域中开发了新的定向度量。


<details>
  <summary>Details</summary>
Motivation: 语法引导合成中的主要挑战是巨大的搜索空间，大多数搜索空间不是简单的程序集合，而是具有定向度量结构，可以用于优化搜索过程。

Method: 开发了字符串和位向量域的定向度量，提出了四种搜索空间缩减技术：围绕真实值的球修剪、定向度量诱导的等价分解、抽象度量和细化、基于抽象信息改进枚举顺序。

Result: 将技术集成到新的合成算法中，实现了一个通用定向度量的求解器。在字符串和位向量域的实验中，性能比现有技术提高了一个数量级以上。

Conclusion: 通过理解定向度量的理论基础，可以显著提高语法引导合成的适用性和效率，定向度量是减少搜索空间的有效框架。

Abstract: In syntax-guided synthesis, one of the challenges is to reduce the enormous
size of the search space. We observe that most search spaces are not just flat
sets of programs, but can be endowed with a structure that we call an oriented
metric. Oriented metrics measure the distance between programs, like ordinary
metrics do, but are designed for settings in which operations have an
orientation. Our focus is on the string and the bitvector domains, where
operations like concatenation and bitwise conjunction transform an input into
an output in a way that is not symmetric. We develop several new oriented
metrics for these domains. Oriented metrics are designed for search space
reduction, and we present four techniques: (i) pruning the search space to a
ball around the ground truth, (ii) factorizing the search space by an
equivalence that is induced by the oriented metric, (iii) abstracting the
oriented metric (and hence the equivalence) and refining it, and (iv) improving
the enumeration order by learning from abstract information. We acknowledge
that these techniques are inspired by developments in the literature. By
understanding their roots in oriented metrics, we can substantially increase
their applicability and efficiency. We have integrated these techniques into a
new synthesis algorithm and implemented the algorithm in a new solver. Notably,
our solver is generic in the oriented metric over which it computes. We
conducted experiments in the string and the bitvector domains, and consistently
improve the performance over the state-of-the-art by more than an order of
magnitude.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [9] [Detecting Vulnerabilities from Issue Reports for Internet-of-Things](https://arxiv.org/abs/2511.01941)
*Sogol Masoumzadeh*

Main category: cs.SE

TL;DR: 首次探索在IoT系统中使用机器学习和大型语言模型检测漏洞指示问题，提出了两种方法：结合ML、LLM和NLP技术，以及微调BERT模型，在21个Eclipse IoT项目上实现了最佳AUC 0.65的性能。


<details>
  <summary>Details</summary>
Motivation: IoT系统的漏洞分析比非IoT系统更慢，需要及时识别反映软件漏洞的问题报告，而ML和LLM在非IoT系统中已用于检测漏洞指示问题，但在IoT领域的应用尚未探索。

Method: 提出两种方法：(1) 结合ML、LLM和NLP技术检测21个Eclipse IoT项目的漏洞指示问题；(2) 在11,000个GitHub问题上微调预训练的BERT掩码语言模型进行漏洞分类。

Result: 最佳性能来自基于BERT NLP特征训练的SVM，AUC达到0.65；微调BERT的准确率为0.26，强调了训练时暴露所有数据的重要性。

Conclusion: 这项研究为从问题报告中准确检测IoT漏洞奠定了基础，类似于非IoT系统的方法。

Abstract: Timely identification of issue reports reflecting software vulnerabilities is
crucial, particularly for Internet-of-Things (IoT) where analysis is slower
than non-IoT systems. While Machine Learning (ML) and Large Language Models
(LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use
remains unexplored. We are the first to tackle this problem by proposing two
approaches: (1) combining ML and LLMs with Natural Language Processing (NLP)
techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects
and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000
GitHub issues for classifying \vul. Our best performance belongs to a Support
Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the
receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT
achieves 0.26 accuracy, emphasizing the importance of exposing all data during
training. Our contributions set the stage for accurately detecting IoT
vulnerabilities from issue reports, similar to non-IoT systems.

</details>


### [10] [Metamorphic Testing of Large Language Models for Natural Language Processing](https://arxiv.org/abs/2511.02108)
*Steven Cho,Stefano Ruberto,Valerio Terragni*

Main category: cs.SE

TL;DR: 本文对大型语言模型(LLMs)进行最全面的蜕变测试研究，收集191个NLP任务的蜕变关系，实施36个代表性关系进行约56万次测试，揭示MT在LLM测试中的能力、机会和局限性。


<details>
  <summary>Details</summary>
Motivation: LLMs在NLP任务中广泛应用但经常产生错误结果，自动识别这些错误行为对提升LLM效能至关重要。然而标记数据集有限，需要解决oracle问题。

Method: 采用蜕变测试(MT)方法，通过定义输入输出关系的蜕变关系(MRs)来暴露错误行为，无需显式oracle。进行文献综述收集191个MRs，实现36个代表性MRs进行大规模实验。

Result: 通过约560,000次蜕变测试，评估了三个流行LLMs的性能，揭示了MT在检测LLM错误行为方面的有效性。

Conclusion: 蜕变测试是解决LLM测试中oracle问题的有效方法，能够暴露LLM的错误行为，但存在一定局限性，为LLM质量保证提供了重要方向。

Abstract: Using large language models (LLMs) to perform natural language processing
(NLP) tasks has become increasingly pervasive in recent times. The versatile
nature of LLMs makes them applicable to a wide range of such tasks. While the
performance of recent LLMs is generally outstanding, several studies have shown
that they can often produce incorrect results. Automatically identifying these
faulty behaviors is extremely useful for improving the effectiveness of LLMs.
One obstacle to this is the limited availability of labeled datasets, which
necessitates an oracle to determine the correctness of LLM behaviors.
Metamorphic testing (MT) is a popular testing approach that alleviates this
oracle problem. At the core of MT are metamorphic relations (MRs), which define
relationships between the outputs of related inputs. MT can expose faulty
behaviors without the need for explicit oracles (e.g., labeled datasets). This
paper presents the most comprehensive study of MT for LLMs to date. We
conducted a literature review and collected 191 MRs for NLP tasks. We
implemented a representative subset (36 MRs) to conduct a series of experiments
with three popular LLMs, running approximately 560,000 metamorphic tests. The
results shed light on the capabilities and opportunities of MT for LLMs, as
well as its limitations.

</details>


### [11] [Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning Confidence in LLMs](https://arxiv.org/abs/2511.02197)
*Shufan Wang,Xing Hu,Junkai Chen,Zhiyuan Pan,Xin Xia*

Main category: cs.SE

TL;DR: 本文提出了一个针对代码推理任务的LLM置信度分析与增强框架，通过实证研究评估主流LLM的置信度可靠性，并验证提示策略优化和数学校准技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在代码智能领域的广泛应用，其输出在代码推理任务中的可靠性和可控性受到关注，置信度估计是评估这些方面的有效方法。

Method: 采用综合实证研究方法，评估主流LLM在不同任务中的置信度可靠性，并测试提示策略优化和数学校准（如Platt Scaling）在提升置信度可靠性方面的效果。

Result: DeepSeek-Reasoner在各种任务中表现最佳，在ECE、Brier Score和Performance Score上分别比其他模型高出0.680、0.636和13.652。结合重新评估提示策略和Platt Scaling的混合策略在上述三个指标上比原始性能提升了0.541、0.628和15.084。

Conclusion: 具有推理能力的模型展现出更优的置信度可靠性，混合策略在增强各种模型的置信度可靠性方面最为有效。当前LLM在复杂推理任务中的置信度仍有较大改进空间，为LLM辅助软件工程中的置信度应用提供了研究基础和技术参考。

Abstract: With the widespread application of large language models (LLMs) in the field
of code intelligence, increasing attention has been paid to the reliability and
controllability of their outputs in code reasoning tasks. Confidence estimation
serves as an effective and convenient approach for evaluating these aspects.
This paper proposes a confidence analysis and enhancement framework for LLMs
tailored to code reasoning tasks. We conduct a comprehensive empirical study on
the confidence reliability of mainstream LLMs across different tasks, and
further evaluate the effectiveness of techniques such as prompt strategy
optimisation and mathematical calibration (e.g., Platt Scaling) in improving
confidence reliability. Our results show that DeepSeek-Reasoner achieves the
best performance across various tasks, outperforming other models by up to
$0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance
Score, respectively. The hybrid strategy combining the reassess prompt strategy
and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$
over the original performance in the aforementioned three metrics. These
results indicate that models with reasoning capabilities demonstrate superior
confidence reliability, and that the hybrid strategy is the most effective in
enhancing the confidence reliability of various models. Meanwhile, we elucidate
the impact of different task complexities, model scales, and strategies on
confidence performance, and highlight that the confidence of current LLMs in
complex reasoning tasks still has considerable room for improvement. This study
not only provides a research foundation and technical reference for the
application of confidence in LLM-assisted software engineering, but also points
the way for future optimisation and engineering deployment of confidence
mechanisms.

</details>


### [12] [LLMs as Judges: Toward The Automatic Review of GSN-compliant Assurance Cases](https://arxiv.org/abs/2511.02203)
*Gerhard Yu,Mithila Sivakumar,Alvine B. Belle,Soude Ghari,Song Wang,Timothy C. Lethbridge*

Main category: cs.SE

TL;DR: 本文提出了一种利用LLM作为评判者的新方法来自动化保证案例审查过程，通过制定基于谓词的规则来形式化审查标准，并在多个先进LLM上进行实验验证。


<details>
  <summary>Details</summary>
Motivation: 保证案例对于验证关键系统的非功能性需求至关重要，但传统的手动审查过程冗长且容易出错，需要自动化技术来提高效率和准确性。

Method: 采用LLM-as-a-judge范式，提出新的基于谓词的规则来形式化保证案例审查标准，并针对审查任务定制LLM提示。

Result: 实验表明DeepSeek-R1和GPT-4.1表现最佳，其中DeepSeek-R1最终优于GPT-4.1，但LLM生成的审查结果仍需人工进一步优化。

Conclusion: LLM在保证案例审查中展现出良好潜力，但完全自动化审查仍需人类专家的参与和精炼。

Abstract: Assurance cases allow verifying the correct implementation of certain
non-functional requirements of mission-critical systems, including their
safety, security, and reliability. They can be used in the specification of
autonomous driving, avionics, air traffic control, and similar systems. They
aim to reduce risks of harm of all kinds including human mortality,
environmental damage, and financial loss. However, assurance cases often tend
to be organized as extensive documents spanning hundreds of pages, making their
creation, review, and maintenance error-prone, time-consuming, and tedious.
Therefore, there is a growing need to leverage (semi-)automated techniques,
such as those powered by generative AI and large language models (LLMs), to
enhance efficiency, consistency, and accuracy across the entire assurance-case
lifecycle. In this paper, we focus on assurance case review, a critical task
that ensures the quality of assurance cases and therefore fosters their
acceptance by regulatory authorities. We propose a novel approach that
leverages the \textit{LLM-as-a-judge} paradigm to automate the review process.
Specifically, we propose new predicate-based rules that formalize
well-established assurance case review criteria, allowing us to craft LLM
prompts tailored to the review task. Our experiments on several
state-of-the-art LLMs (GPT-4o, GPT-4.1, DeepSeek-R1, and Gemini 2.0 Flash) show
that, while most LLMs yield relatively good review capabilities, DeepSeek-R1
and GPT-4.1 demonstrate superior performance, with DeepSeek-R1 ultimately
outperforming GPT-4.1. However, our experimental results also suggest that
human reviewers are still needed to refine the reviews LLMs yield.

</details>


### [13] [SWE-Sharp-Bench: A Reproducible Benchmark for C# Software Engineering Tasks](https://arxiv.org/abs/2511.02352)
*Sanket Mhatre,Yasharth Bajpai,Sumit Gulwani,Emerson Murphy-Hill,Gustavo Soares*

Main category: cs.SE

TL;DR: SWE-Sharp-Bench是首个针对C#语言的软件工程基准测试，包含150个实例，来自17个代码库。相比Python在SWE-Bench Verified中70%的解决率，C#任务只有40%的解决率。


<details>
  <summary>Details</summary>
Motivation: C#作为排名第5的企业级编程语言，在现有的AI编码代理基准测试中一直缺失，需要专门的基准来评估AI在C#软件工程任务中的表现。

Method: 创建了SWE-Sharp-Bench基准，包含150个C#任务实例，来自17个代码库，并开发了完整的基准构建流程。

Result: 跨语言评估显示显著性能差距：Python任务解决率为70%，而C#任务仅为40%。

Conclusion: C#语言在AI编码代理任务中存在显著性能差距，SWE-Sharp-Bench填补了C#基准测试的空白，并开源了基准和构建流程。

Abstract: AI coding agents have shown great progress on Python software engineering
benchmarks like SWE-Bench, and for other languages like Java and C in
benchmarks like Multi-SWE-Bench. However, C# -- a prominent enterprise language
ranking #5 in the TIOBE index -- remains absent from such benchmarks. We
introduce SWE-Sharp-Bench, a reproducible software engineering benchmark for
C\# featuring 150 instances from 17 repositories. Evaluating identical
model-agent configurations across languages reveals a significant performance
gap: while 70% of Python tasks in SWE-Bench Verified are solved, $only 40% of
our C\# tasks are resolved. We open-source SWE-Sharp-Bench and our entire
curation pipeline.

</details>


### [14] [EvoDev: An Iterative Feature-Driven Framework for End-to-End Software Development with LLM-based Agents](https://arxiv.org/abs/2511.02399)
*Junwei Liu,Chen Xu,Chong Wang,Tong Bai,Weitong Chen,Kaseng Wong,Yiling Lou,Xin Peng*

Main category: cs.SE

TL;DR: EvoDev是一个基于特征驱动开发的迭代式软件开发框架，通过将用户需求分解为特征并构建特征依赖图，显著提升了LLM在复杂软件开发任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的软件开发方法主要采用线性的瀑布式流程，无法有效处理真实世界中复杂、大规模项目的迭代开发需求。

Method: 将用户需求分解为特征集，构建有向无环特征依赖图，每个节点维护业务逻辑、设计和代码等多层次信息，并沿依赖关系传播上下文。

Result: 在Android开发任务中，EvoDev比最佳基线Claude Code性能提升56.8%，在不同基础LLM上单智能体性能提升16.0%-76.6%。

Conclusion: 依赖建模、上下文传播和工作流感知的智能体设计对于复杂软件项目至关重要，为设计迭代式LLM驱动开发框架提供了实用见解。

Abstract: Recent advances in large language model agents offer the promise of
automating end-to-end software development from natural language requirements.
However, existing approaches largely adopt linear, waterfall-style pipelines,
which oversimplify the iterative nature of real-world development and struggle
with complex, large-scale projects. To address these limitations, we propose
EvoDev, an iterative software development framework inspired by feature-driven
development. EvoDev decomposes user requirements into a set of user-valued
features and constructs a Feature Map, a directed acyclic graph that explicitly
models dependencies between features. Each node in the feature map maintains
multi-level information, including business logic, design, and code, which is
propagated along dependencies to provide context for subsequent development
iterations. We evaluate EvoDev on challenging Android development tasks and
show that it outperforms the best-performing baseline, Claude Code, by a
substantial margin of 56.8%, while improving single-agent performance by
16.0%-76.6% across different base LLMs, highlighting the importance of
dependency modeling, context propagation, and workflow-aware agent design for
complex software projects. Our work summarizes practical insights for designing
iterative, LLM-driven development frameworks and informs future training of
base LLMs to better support iterative software development.

</details>


### [15] [Who's Who? LLM-assisted Software Traceability with Architecture Entity Recognition](https://arxiv.org/abs/2511.02434)
*Dominik Fuchß,Haoyu Liu,Sophie Corallo,Tobias Hey,Jan Keim,Johannes von Geisau,Anne Koziolek*

Main category: cs.SE

TL;DR: 本文提出了两种基于LLM的方法（ExArch和ArTEMiS）来自动识别软件架构实体并建立架构文档与源代码之间的可追溯性链接，无需手动创建软件架构模型。


<details>
  <summary>Details</summary>
Motivation: 软件架构文档与源代码之间的可追溯性链接恢复需要识别架构相关实体，但手动创建软件架构模型耗时费力。大型语言模型为自动提取架构实体提供了新的可能性。

Method: ExArch从架构文档和源代码中提取组件名称作为简单软件架构模型；ArTEMiS识别文档中的架构实体并与（手动或自动生成的）软件架构模型实体进行匹配。

Result: ExArch在仅使用架构文档和代码的情况下达到F1分数0.86，与需要手动创建软件架构模型的TransArC（F1:0.87）相当；ArTEMiS与传统启发式方法SWATTR性能相当（F1:0.81），与TransArC集成时可成功替代SWATTR。

Conclusion: LLM能有效识别文本制品中的架构实体，实现自动化的软件架构模型生成和可追溯性链接恢复，使架构-代码可追溯性更加实用和易于实现。

Abstract: Identifying architecturally relevant entities in textual artifacts is crucial
for Traceability Link Recovery (TLR) between Software Architecture
Documentation (SAD) and source code. While Software Architecture Models (SAMs)
can bridge the semantic gap between these artifacts, their manual creation is
time-consuming. Large Language Models (LLMs) offer new capabilities for
extracting architectural entities from SAD and source code to construct SAMs
automatically or establish direct trace links. This paper presents two
LLM-based approaches: ExArch extracts component names as simple SAMs from SAD
and source code to eliminate the need for manual SAM creation, while ArTEMiS
identifies architectural entities in documentation and matches them with
(manually or automatically generated) SAM entities. Our evaluation compares
against state-of-the-art approaches SWATTR, TransArC and ArDoCode. TransArC
achieves strong performance (F1: 0.87) but requires manually created SAMs;
ExArch achieves comparable results (F1: 0.86) using only SAD and code. ArTEMiS
is on par with the traditional heuristic-based SWATTR (F1: 0.81) and can
successfully replace it when integrated with TransArC. The combination of
ArTEMiS and ExArch outperforms ArDoCode, the best baseline without manual SAMs.
Our results demonstrate that LLMs can effectively identify architectural
entities in textual artifacts, enabling automated SAM generation and TLR,
making architecture-code traceability more practical and accessible.

</details>


### [16] [When Continuous Delivery Is Not an Option: Practical Paths to Continuous Engineering in Complex Organizations](https://arxiv.org/abs/2511.02445)
*Eriks Klotins,Magnus Ahlgren,Nicolas Martin Vivaldi,Even-Andre Karlsson*

Main category: cs.SE

TL;DR: 该研究通过四个工业案例分析了持续软件工程（CSE）在受约束环境中的采用情况，提出了更新的准备度模型来指导实践者设定现实的CSE采用目标。


<details>
  <summary>Details</summary>
Motivation: 持续软件工程承诺提高软件密集型组织的效率、质量和响应能力，但完全采用CSE常受到复杂产品、遗留系统、组织惯性和监管要求的限制。

Method: 应用并扩展先前提出的CSE行业准备度模型，通过专家访谈和叙事综合评估四个工业案例的当前和潜在采用水平，识别共同的驱动力和采用障碍。

Result: 提出了更新的准备度模型，引入了额外的内部和外部反馈层级，区分了市场和面向组织的约束，更好地指导实践者设定现实的CSE采用目标。

Conclusion: 虽然完整的端到端CSE采用可能不总是可行，但有意义的内部改进仍然是可能且有益的，本研究为组织在部分或受约束的CSE转型中提供了经验基础指导。

Abstract: Purpose: Continuous Software Engineering (CSE) promises improved efficiency,
quality, and responsiveness in software-intensive organizations. However, fully
adopting CSE is often constrained by complex products, legacy systems,
organizational inertia, and regulatory requirements. In this paper, we examine
four industrial cases from the automation, automotive, retail, and chemical
sectors to explore how such constraints shape CSE adoption in practice.
Methods: We apply and extend a previously proposed CSE Industry Readiness Model
to assess the current and potential levels of adoption in each case. Through
expert interviews and narrative synthesis, we identify common driving forces
and adoption barriers, including organizational preparedness,
cross-organizational dependencies, and limited customer demand for continuous
delivery. Results: Based on our findings, we propose an updated readiness model
that introduces additional levels of internal and external feedback,
distinguishes market- and organization-facing constraints, and better guides
practitioners in setting realistic CSE adoption goals. Conclusions: Our results
highlight that while full end-to-end CSE adoption may not always be feasible,
meaningful internal improvements are still possible and beneficial. This study
provides empirically grounded guidance for organizations navigating partial or
constrained CSE transformations.

</details>


### [17] [Lost in Code Generation: Reimagining the Role of Software Models in AI-driven Software Engineering](https://arxiv.org/abs/2511.02475)
*Jürgen Cito,Dominik Bork*

Main category: cs.SE

TL;DR: 生成式AI使快速"氛围编程"成为可能，但导致原型与工程软件界限模糊，产生脆弱系统。需要重新构想软件模型，将其作为AI生成代码与人类意图之间的中介。


<details>
  <summary>Details</summary>
Motivation: 生成式AI降低了软件开发门槛，但导致原型与工程软件界限模糊，产生缺乏鲁棒性、安全性和可维护性的脆弱系统。

Method: 提出将软件模型从前期蓝图转变为事后从AI生成代码中恢复的工具，以恢复理解、暴露风险和指导改进。

Result: 模型可作为人类意图、AI生成和长期系统演化之间的中介，为可持续的AI驱动软件工程提供路径。

Conclusion: 软件模型应重新定位为AI生成代码与人类意图之间的中介角色，支持可持续的AI驱动软件工程。

Abstract: Generative AI enables rapid ``vibe coding," where natural language prompts
yield working software systems. While this lowers barriers to software
creation, it also collapses the boundary between prototypes and engineered
software, leading to fragile systems that lack robustness, security, and
maintainability. We argue that this shift motivates a reimagining of software
models. Rather than serving only as upfront blueprints, models can be recovered
post-hoc from AI-generated code to restore comprehension, expose risks, and
guide refinement. In this role, models serve as mediators between human intent,
AI generation, and long-term system evolution, providing a path toward
sustainable AI-driven software engineering.

</details>


### [18] [ReleaseEval: A Benchmark for Evaluating Language Models in Automated Release Note Generation](https://arxiv.org/abs/2511.02713)
*Qianru Meng,Zhaochun Ren,Joost Visser*

Main category: cs.SE

TL;DR: ReleaseEval是一个用于自动生成发布说明的基准测试，包含94,987条发布说明，支持三种不同输入粒度的任务设置，评估显示大语言模型在结构化信息处理方面表现出色，但在处理长代码差异时仍有困难。


<details>
  <summary>Details</summary>
Motivation: 解决自动生成发布说明中面临的数据集限制问题，包括缺乏明确许可、可复现性有限，以及任务设计不完整（主要依赖提交信息而忽略细粒度上下文）。

Method: 引入ReleaseEval基准，包含94,987条发布说明，支持三种任务设置：commit2sum（基于提交信息）、tree2sum（结合提交树结构）、diff2sum（利用细粒度代码差异）。

Result: 大语言模型在所有任务中均优于传统基线方法，在tree2sum任务上获得显著提升，但在diff2sum任务上仍存在困难。

Conclusion: 大语言模型擅长利用结构化信息，但在从长代码差异中抽象信息方面仍面临挑战。

Abstract: Automated release note generation addresses the challenge of documenting
frequent software updates, where manual efforts are time-consuming and prone to
human error. Although recent advances in language models further enhance this
process, progress remains hindered by dataset limitations, including the lack
of explicit licensing and limited reproducibility, and incomplete task design
that relies mainly on commit messages for summarization while overlooking
fine-grained contexts such as commit hierarchies and code changes. To fill this
gap, we introduce ReleaseEval, a reproducible and openly licensed benchmark
designed to systematically evaluate language models for automated release note
generation. ReleaseEval comprises 94,987 release notes from 3,369 repositories
across 6 programming languages, and supports three task settings with three
levels of input granularity: (1) commit2sum, which generates release notes from
commit messages; (2) tree2sum, which incorporates commit tree structures; and
(3) diff2sum, which leverages fine-grained code diffs. Both automated and human
evaluations show that large language models consistently outperform traditional
baselines across all tasks, achieving substantial gains on tree2sum, while
still struggling on diff2sum. These findings highlight LLMs' proficiency in
leveraging structured information while revealing challenges in abstracting
from long code diffs.

</details>


### [19] [Investigating the Experience of Autistic Individuals in Software Engineering](https://arxiv.org/abs/2511.02736)
*Madalena Sasportes,Grischa Liebel,Miguel Goulão*

Main category: cs.SE

TL;DR: 本研究分析了自闭症软件工程师在软件工程活动中的经验，特别关注他们的优势，发现他们在逻辑思维、细节关注和编程专注度方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注自闭症个体面临的挑战和可能的适应措施，但很少关注他们的优势。自闭症个体在细节关注和逻辑推理方面具有优势，这些优势在软件工程活动中可能很有价值。

Method: 结合社会技术扎根理论，通过16名自闭症软件工程师的半结构化访谈和49名受访者（包括5名自闭症参与者）的调查，并与Gama等人关于神经多样性认知功能障碍对软件工程绩效影响的理论进行比较。

Result: 结果显示自闭症软件工程师在逻辑思维、细节关注和编程专注度方面表现出色；他们喜欢学习新的编程语言和技术；倾向于书面沟通和远程工作；与AI系统互动时舒适度较高。

Conclusion: 研究结果通过提供自闭症软件工程师优势的进一步证据，扩展了现有工作。

Abstract: Context: Autism spectrum disorder (ASD) leads to various issues in the
everyday life of autistic individuals, often resulting in unemployment and
mental health problems. To improve the inclusion of autistic adults, existing
studies have highlighted the strengths these individuals possess in comparison
to non-autistic individuals, e.g., high attention to detail or excellent
logical reasoning skills. If fostered, these strengths could be valuable in
software engineering activities, such for identifying specific kinds of bugs in
code. However, existing work in SE has primarily studied the challenges of
autistic individuals and possible accommodations, with little attention their
strengths. Objective: Our goal is to analyse the experiences of autistic
individuals in software engineering activities, such as code reviews, with a
particular emphasis on strengths. Methods: This study combines Social-Technical
Grounded Theory through semi-structured interviews with 16 autistic software
engineers and a survey with 49 respondents, including 5 autistic participants.
We compare the emerging themes with the theory by Gama et al. on the Effect of
Neurodivergent Cognitive Dysfunctions in Software Engineering Performance.
Results: Our results suggest that autistic software engineers are often skilled
in logical thinking, attention to detail, and hyperfocus in programming; and
they enjoy learning new programming languages and programming-related
technologies. Confirming previous work, they tend to prefer written
communication and remote work. Finally, we report a high comfort level in
interacting with AI-based systems. Conclusions: Our findings extend existing
work by providing further evidence on the strengths of autistic software
engineers.

</details>


### [20] [Formalizing Regression Testing for Agile and Continuous Integration Environments](https://arxiv.org/abs/2511.02810)
*Suddhasvatta Das,Kevin Gary*

Main category: cs.SE

TL;DR: 本文针对敏捷开发中的持续回归测试需求，将软件版本序列形式化为时间有序的构建链，定义了回归测试窗口的时间限制，并验证了该形式化模型能准确表示现有敏捷回归测试算法。


<details>
  <summary>Details</summary>
Motivation: 现代敏捷开发实践产生连续的软件版本流，需要持续回归测试而非传统的一次性测试，现有回归测试理论无法适应这种连续测试场景。

Method: 将连续回归测试形式化为时间有序的构建链，每个构建包含程序、需求和测试，定义构建间的回归测试窗口以捕获有限时间预算，并验证该形式化模型能直接表示现有算法。

Result: 成功形式化了持续回归测试现象，验证了模型能准确表示两种先进的敏捷回归测试算法，无需辅助假设，并证明了形式化的完备性和正确性。

Conclusion: 提出的形式化模型为连续回归测试提供了理论基础，当时间限制趋于无穷且构建链简化为两个版本时，模型退化为传统的重测全部方法，保持了与传统理论的语义一致性。

Abstract: Software developed using modern agile practices delivers a stream of software
versions that require continuous regression testing rather than testing once
close to the delivery or maintenance phase, as assumed by classical
regression-testing theory. In this work, we formalize the phenomenon of
continuous or near-continuous regression testing using successive builds as a
time-ordered chain, where each build contains the program, requirements, and
the accompanying tests. We also formalize the regression test window between
any two builds, which captures the limited time budget available for regression
testing. As the time limit is set to infinity and the chain is closed to two
builds, the model degenerates to retest-all, thereby preserving semantics for
the classical two-version case. The formalization is validated by directly
representing two state-of-the-art agile regression testing algorithms in terms
of build-tuple operations without requiring auxiliary assumptions, followed by
proof of the soundness and completeness of our formalization.

</details>


### [21] [From Code Changes to Quality Gains: An Empirical Study in Python ML Systems with PyQu](https://arxiv.org/abs/2511.02827)
*Mohamed Almukhtar,Anwar Ghammam,Marouane Kessentini,Hua Ming*

Main category: cs.SE

TL;DR: 该研究开发了PyQu工具，通过分析3400个开源Python机器学习项目的370万次提交和2.7万亿行代码，识别了61种能直接提升软件质量的代码变更，并将其分为13个类别，其中41%是新发现的变更类型。


<details>
  <summary>Details</summary>
Motivation: 在生成式AI代码生成和Python机器学习系统广泛应用的背景下，软件质量成为关键问题。现有研究缺乏对代码变更与ML系统质量之间关系的深入理解，且缺乏质量评估工具。

Method: 对3400个开源Python ML项目进行大规模实证研究，开发PyQu工具利用低级软件指标识别质量提升提交，并通过主题分析对代码变更进行分类。

Result: PyQu工具在识别质量提升提交时达到平均准确率0.84、精确率0.85和召回率0.85，F1分数0.85。识别出61种直接影响软件质量的代码变更，分为13个类别。

Conclusion: 该研究为研究人员、从业者、教育工作者和工具开发者提供了重要基础，推动了Python机器学习软件自动化质量评估和最佳实践的探索。

Abstract: In an era shaped by Generative Artificial Intelligence for code generation
and the rising adoption of Python-based Machine Learning systems (MLS),
software quality has emerged as a major concern. As these systems grow in
complexity and importance, a key obstacle lies in understanding exactly how
specific code changes affect overall quality-a shortfall aggravated by the lack
of quality assessment tools and a clear mapping between ML systems code changes
and their quality effects. Although prior work has explored code changes in
MLS, it mostly stops at what the changes are, leaving a gap in our knowledge of
the relationship between code changes and the MLS quality. To address this gap,
we conducted a large-scale empirical study of 3,340 open-source Python ML
projects, encompassing more than 3.7 million commits and 2.7 trillion lines of
code. We introduce PyQu, a novel tool that leverages low level software metrics
to identify quality-enhancing commits with an average accuracy, precision, and
recall of 0.84 and 0.85 of average F1 score. Using PyQu and a thematic
analysis, we identified 61 code changes, each demonstrating a direct impact on
enhancing software quality, and we classified them into 13 categories based on
contextual characteristics. 41% of the changes are newly discovered by our
study and have not been identified by state-of-the-art Python changes detection
tools. Our work offers a vital foundation for researchers, practitioners,
educators, and tool developers, advancing the quest for automated quality
assessment and best practices in Python-based ML software.

</details>
