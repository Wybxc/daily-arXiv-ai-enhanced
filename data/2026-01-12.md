<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 19]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Discrete dualities for some algebras from rough sets](https://arxiv.org/abs/2601.05843)
*Ivo Düntsch,Ewa Orłowska*

Main category: cs.LO

TL;DR: 本文回顾了粗糙集理论中各类代数与关系系统之间的离散对偶性


<details>
  <summary>Details</summary>
Motivation: 建立粗糙集理论与模态逻辑之间的联系，通过离散对偶性为粗糙集代数提供关系语义，继承Jónsson-Tarski、Kripke和van Benthem的早期工作

Method: 回顾离散对偶性理论，将粗糙集代数类与关系系统类建立对应关系，实现两种表示定理

Result: 系统整理了粗糙集相关代数（如近似代数、粗糙代数等）的离散对偶性框架

Conclusion: 离散对偶性为粗糙集代数提供了统一的关系语义框架，连接了代数方法与关系语义方法

Abstract: A discrete duality is a relationship between classes of algebras and classes of relational systems (frames) resulting in two representation theorems building on the early work of Jónsson and Tarski, Kripke, and van Benthem. In this section we recall discrete dualities for various types of algebras arising from rough sets.

</details>


### [2] [The Modal Logic of Abstraction Refinement](https://arxiv.org/abs/2601.05897)
*Jakob Piribauer,Vinzent Zschuppe*

Main category: cs.LO

TL;DR: 本文研究了在抽象精化过程中CTL公式真值的变化，通过在CTL上定义模态算子◇（存在精化）和□（所有精化），建立了抽象精化的模态逻辑框架。


<details>
  <summary>Details</summary>
Motivation: 迭代抽象精化是分析大型或无限状态系统的重要技术，但缺乏对抽象精化过程中系统属性（CTL公式）真值变化的系统性理论研究。

Method: 在计算树逻辑（CTL）基础上定义模态逻辑算子：◇表示"存在一个精化，在其中..."，□表示"在所有精化中..."。研究三种场景下的模态逻辑复杂性：1)有限抽象 2)所有抽象 3)所有转移系统。

Result: 为三种场景下的抽象精化模态逻辑提供了上下界复杂度结果，并开发了使用新型控制语句获得模态逻辑上界的通用技术。

Conclusion: 建立了抽象精化的模态逻辑理论框架，为理解抽象精化过程中属性真值变化提供了形式化工具，并开发了分析此类逻辑复杂性的通用技术。

Abstract: Iterative abstraction refinement techniques are one of the most prominent paradigms for the analysis and verification of systems with large or infinite state spaces. This paper investigates the changes of truth values of system properties expressible in computation tree logic (CTL) when abstractions of transition systems are refined. To this end, the paper utilizes modal logic by defining alethic modalities expressing possibility and necessity on top of CTL: The modal operator $\lozenge$ is interpreted as "there is a refinement, in which ..." and $\Box$ is interpreted as "in all refinements, ...".
  Upper and lower bounds for the resulting modal logics of abstraction refinement are provided for three scenarios: 1) when considering all finite abstractions of a transition system, 2) when considering all abstractions of a transition system, and 3) when considering the class of all transition systems. Furthermore, to prove these results, generic techniques to obtain upper bounds of modal logics using novel types of so-called control statements are developed.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Categorical Foundations for CuTe Layouts](https://arxiv.org/abs/2601.05972)
*Jack Carlisle,Jay Shah,Reuben Stern,Paul VanKoughnett*

Main category: cs.PL

TL;DR: 该论文为NVIDIA CUTLASS库的布局代数提供了范畴论框架，定义了Tuple和Nest两个范畴，证明了其操作与CUTLASS布局操作的兼容性，并提供了Python实现。


<details>
  <summary>Details</summary>
Motivation: CUTLASS库提供了强大的多维张量布局操作，但缺乏形式化的理论基础。论文旨在通过范畴论为CUTLASS的布局代数提供严格的数学框架，以更好地理解和操作GPU上的张量数据。

Method: 定义了两个范畴Tuple和Nest，其态射产生布局。在这些范畴中定义了一套操作（如组合、逻辑积、逻辑除），并证明了这些操作与CUTLASS布局操作的兼容性。还给出了布局的完整特征描述。

Result: 成功建立了CUTLASS布局代数的范畴论框架，证明了范畴操作与CUTLASS操作的兼容性，并提供了Python实现（https://github.com/ColfaxResearch/layout-categories），测试表明与CUTLASS行为一致。

Conclusion: 范畴论为CUTLASS布局代数提供了优雅且严格的理论基础，有助于更好地理解和操作GPU张量布局。Python实现验证了理论框架的实际可行性。

Abstract: NVIDIA's CUTLASS library provides a robust and expressive set of methods for describing and manipulating multi-dimensional tensor data on the GPU. These methods are conceptually grounded in the abstract notion of a CuTe layout and a rich algebra of such layouts, including operations such as composition, logical product, and logical division. In this paper, we present a categorical framework for understanding this layout algebra by focusing on a naturally occurring class of tractable layouts. To this end, we define two categories Tuple and Nest whose morphisms give rise to layouts. We define a suite of operations on morphisms in these categories and prove their compatibility with the corresponding layout operations. Moreover, we give a complete characterization of the layouts which arise from our construction. Finally, we provide a Python implementation of our categorical constructions, along with tests that demonstrate alignment with CUTLASS behavior. This implementation can be found at our git repository https://github.com/ColfaxResearch/layout-categories.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [DafnyPro: LLM-Assisted Automated Verification for Dafny Programs](https://arxiv.org/abs/2601.05385)
*Debangshu Banerjee,Olivier Bouissou,Stefan Zetzsche*

Main category: cs.SE

TL;DR: DafnyPro是一个推理时框架，通过差分检查器、剪枝器和提示增强系统来提升LLMs生成Dafny验证注释的能力，在多个基准测试中显著提高证明成功率，并使小模型也能保持高验证准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在生成Dafny验证注释时存在困难，需要一种系统性的方法来提升其验证能力，同时希望小模型也能达到接近大模型的验证性能。

Method: DafnyPro包含三个核心组件：1) diff-checker防止修改基础程序逻辑；2) pruner移除不必要的循环不变量；3) hint-augmentation系统检索并应用预定义的问题无关证明策略。框架还利用增强后的大模型生成训练数据来微调小模型。

Result: 在Claude Sonnet 3.5和3.7上测试四个基准（Clover、MBPP-Dafny、HumanEval-Dafny、DafnyBench），均获得一致性能提升。在最具挑战性的DafnyBench上，Claude Sonnet 3.5+DafnyPro达到86%正确证明，比基础模型提升16个百分点。微调的7B和14B Qwen模型分别达到68%和70%正确证明。

Conclusion: DafnyPro有效提升了LLMs生成Dafny验证注释的能力，不仅显著改善了大模型的性能，还使得小模型能够维持高验证准确率，为程序验证领域提供了实用的工具。

Abstract: We present DafnyPro, an inference-time framework that enhances LLMs for generating verification annotations in Dafny. DafnyPro comprises three key components: a diff-checker that prevents modifications to base program logic, a pruner that removes unnecessary invariants, and a hint-augmentation system that retrieves and applies predefined, problem-independent proof strategies. We evaluate DafnyPro using Claude Sonnet 3.5 and 3.7 on four benchmarks: Clover, MBPP-Dafny, HumanEval-Dafny, and DafnyBench, achieving consistent performance gains in all cases. Notably, on DafnyBench, the most challenging benchmark, Claude Sonnet 3.5 enhanced with DafnyPro achieves 86% correct proofs, a 16 pp improvement over the base model. We also fine-tune two Qwen models on training data derived from verification attempts by larger models enhanced with DafnyPro. Our 7B and 14B models achieve 68% and 70% correct proofs on DafnyBench, respectively, demonstrating that smaller models can maintain high verification accuracy.

</details>


### [5] [Uncovering Failures in Cyber-Physical System State Transitions: A Fuzzing-Based Approach Applied to sUAS](https://arxiv.org/abs/2601.05449)
*Theodore Chambers,Arturo Miguel Russell Bernal,Michael Vierhauser,Jane Cleland-Huang*

Main category: cs.SE

TL;DR: SaFUZZ是一个状态感知的模糊测试框架，用于验证小型无人机系统在各种条件下的核心行为，包括状态转换、自动故障安全机制和人机交互，能够发现传统测试未检测到的故障点。


<details>
  <summary>Details</summary>
Motivation: 随着小型无人机系统在安全关键环境中的广泛应用，需要对其机载决策逻辑在各种条件和环境干扰下进行严格验证，确保系统可靠性。

Method: 开发状态感知模糊测试管道，创建模糊测试规范来检测行为偏差，动态生成故障树可视化状态、模式和导致故障的环境因素，在高保真仿真环境中测试并在真实物理无人机上验证。

Result: 在真实无人机系统上验证SaFUZZ，发现了开发团队之前未检测到的多个故障点，证明了该框架能够发现多样化的状态转换故障。

Conclusion: SaFUZZ为无人机系统验证提供了实用且可扩展的方法，能够有效发现状态转换故障，并通过故障树分析帮助利益相关者识别根本原因。

Abstract: The increasing deployment of small Uncrewed Aerial Systems (sUAS) in diverse and often safety-critical environments demands rigorous validation of onboard decision logic under various conditions. In this paper, we present SaFUZZ, a state-aware fuzzing pipeline that validates core behavior associated with state transitions, automated failsafes, and human operator interactions in sUAS applications operating under various timing conditions and environmental disturbances. We create fuzzing specifications to detect behavioral deviations, and then dynamically generate associated Fault Trees to visualize states, modes, and environmental factors that contribute to the failure, thereby helping project stakeholders to analyze the failure and identify its root causes. We validated SaFUZZ against a real-world sUAS system and were able to identify several points of failure not previously detected by the system's development team. The fuzzing was conducted in a high-fidelity simulation environment, and outcomes were validated on physical sUAS in a real-world field testing setting. The findings from the study demonstrated SaFUZZ's ability to provide a practical and scalable approach to uncovering diverse state transition failures in a real-world sUAS application.

</details>


### [6] [Rethinking Basis Path Testing: Mixed Integer Programming Approach for Test Path Set Generation](https://arxiv.org/abs/2601.05463)
*Chao Wei,Xinyi Peng,Yawen Yan,Mao Luo,Ting Cai*

Main category: cs.SE

TL;DR: 将基础路径生成从过程式搜索重构为声明式优化问题，使用混合整数规划框架生成结构简单且全局最优的完整基础路径集。


<details>
  <summary>Details</summary>
Motivation: 传统基于贪心图遍历算法（如DFS/BFS）的自动化方法生成的基础路径往往结构次优，这会阻碍下游测试活动，包括自动化测试数据生成和增加人工工程师的认知负担。

Method: 提出混合整数规划框架，包含两种策略：1）整体MIP模型保证理论最优路径集；2）可扩展的增量MIP策略处理大型复杂拓扑，采用多目标函数优先考虑路径简单性并引入新颖性惩罚以最大化线性独立路径生成。

Result: 在真实代码和大规模合成控制流图上的实证评估显示，增量MIP策略在生成完整基础集方面达到100%成功率，同时保持计算效率。

Conclusion: 该工作为生成高质量结构"脚手架"提供了基础方法，能够增强后续测试生成工作的效率和效果。

Abstract: Basis path testing is a cornerstone of structural testing, yet traditional automated methods, relying on greedy graph-traversal algorithms (e.g., DFS/BFS), often generate sub-optimal paths. This structural inferiority is not a trivial issue; it directly impedes downstream testing activities by complicating automated test data generation and increasing the cognitive load for human engineers. This paper reframes basis path generation from a procedural search task into a declarative optimization problem. We introduce a Mixed Integer Programming (MIP) framework designed to produce a complete basis path set that is globally optimal in its structural simplicity. Our framework includes two complementary strategies: a Holistic MIP model that guarantees a theoretically optimal path set, and a scalable Incremental MIP strategy for large, complex topologies. The incremental approach features a multi-objective function that prioritizes path simplicity and incorporates a novelty penalty to maximize the successful generation of linearly independent paths. Empirical evaluations on both real-code and large-scale synthetic Control Flow Graphs demonstrate that our Incremental MIP strategy achieves a 100\% success rate in generating complete basis sets, while remaining computationally efficient. Our work provides a foundational method for generating a high-quality structural "scaffold" that can enhance the efficiency and effectiveness of subsequent test generation efforts.

</details>


### [7] [STELP: Secure Transpilation and Execution of LLM-Generated Programs](https://arxiv.org/abs/2601.05467)
*Swapnil Shinde,Sahil Wadhwa,Andy Luo,Emily Chen*

Main category: cs.SE

TL;DR: STELP：一个安全执行LLM生成代码的转译器和执行器，解决LLM代码在生成式AI系统中的安全性和可靠性问题


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码直接用于生产系统存在安全隐患，如代码不稳定、包含漏洞、恶意攻击和幻觉等问题，而传统安全测试方法和人工审查在实际应用中不切实际或不可靠

Method: 提出STELP（Secure Transpiler and Executor of LLM-Generated Program），能够在受控和安全的环境中执行LLM生成的代码，填补传统安全测试方法的空白

Result: 在公开数据集上的测试表明，该方法在正确性、安全性和延迟方面显著优于现有方法，特别是在安全执行风险代码片段方面表现突出

Conclusion: STELP为涉及代码生成的自主生产AI系统提供了安全保障，解决了LLM生成代码在现实应用中的安全执行问题

Abstract: Rapid evolution of Large Language Models (LLMs) has achieved major advances in reasoning, planning, and function-calling capabilities. Multi-agentic collaborative frameworks using such LLMs place them at the center of solving software development-related tasks such as code generation. However, direct use of LLM generated code in production software development systems is problematic. The code could be unstable or erroneous and contain vulnerabilities such as data poisoning, malicious attacks, and hallucinations that could lead to widespread system malfunctions. This prohibits the adoption of LLM generated code in production AI systems where human code reviews and traditional secure testing tools are impractical or untrustworthy. In this paper, we discuss safety and reliability problems with the execution of LLM generated code and propose a Secure Transpiler and Executor of LLM-Generated Program (STELP), capable of executing LLM-generated code in a controlled and safe manner. STELP secures autonomous production AI systems involving code generation, filling the critical void left by the impracticality or limitations of traditional secure testing methodologies and human oversight. This includes applications such as headless code generation-execution and LLMs that produce executable code snippets as an action plan to be executed in real time. We contribute a human-validated dataset of insecure code snippets and benchmark our approach on publicly available datasets for correctness, safety, and latency. Our results demonstrate that our approach outperforms an existing method by a significant margin, particularly in its ability to safely execute risky code snippets. Warning: This paper contains malicious code snippets that should be run with caution.

</details>


### [8] [Readability-Robust Code Summarization via Meta Curriculum Learning](https://arxiv.org/abs/2601.05485)
*Wenhao Zeng,Yitian Chai,Hao Zhou,Fandong Meng,Jie Zhou,Xiaodong Gu*

Main category: cs.SE

TL;DR: 提出RoFTCodeSum方法，通过课程学习与元学习结合增强代码摘要模型对低可读性代码的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有代码摘要模型和基准测试局限于高可读性代码，但现实世界代码往往结构混乱或混淆，导致模型性能显著下降

Method: RoFTCodeSum方法结合课程学习和元学习：创建渐进难度的训练集（如混淆函数名和标识符），在每一步训练中使用这些数据集进行元梯度更新

Result: 实验表明RoFTCodeSum在增强对语义扰动的鲁棒性的同时，提高了原始代码上的性能

Conclusion: 该方法有效解决了代码摘要模型对低可读性代码鲁棒性不足的问题，为实际应用提供了更好的解决方案

Abstract: Code summarization has emerged as a fundamental technique in the field of program comprehension. While code language models have shown significant advancements, the current models and benchmarks are confined to high-readability code, which contains sufficient semantic cues such as function and variable names. In the real world, however, code is often poorly structured or obfuscated, significantly degrading model performance. In this paper, we first empirically evaluate the robustness of state-of-the-art language models on poor-readability code for the task of code summarization, focusing on (1) their effectiveness, (2) the impact of prompt engineering, and (3) the robustness of different variants. Experimental results reveal that state-of-the-art models-including GPT-4o and DeepSeek-V3 experience a substantial performance drop when faced with poorly readable code, and that prompt engineering and reasoning-enhanced models offer limited improvements. Motivated by these findings, we propose RoFTCodeSum, a novel fine-tuning method that enhances the robustness of code summarization against poorly readable code. RoFTCodeSum marries the concepts of curriculum learning and meta-learning: based on the original dataset for fine-tuning, it creates curricular training sets, e.g., obfuscating function names and identifiers from the code, respectively, that have progressive difficulty in code comprehension. In each training step, the approach meta-updates the gradients using these progressively challenging datasets, thereby optimizing both accuracy and readability robustness simultaneously. Experimental results demonstrate that RoFTCodeSum exhibits increased robustness against semantic perturbation while enhancing performance on the original code.

</details>


### [9] [Evaluating the Use of LLMs for Automated DOM-Level Resolution of Web Performance Issues](https://arxiv.org/abs/2601.05502)
*Gideon Peters,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 该研究评估了9种最先进的大语言模型在自动解决网页性能问题方面的效果，发现LLMs在SEO和可访问性问题上表现出色，但在性能关键的DOM操作方面效果参差不齐，GPT-4.1表现最佳而GPT-4o-mini表现最差。


<details>
  <summary>Details</summary>
Motivation: 用户对快速、无缝的网页体验有高要求，但开发者在时间限制下难以满足这些期望。性能优化是一个耗时且通常需要手动完成的过程，其中DOM修改是最复杂的任务之一。最近大语言模型的发展为自动化这一复杂任务提供了有前景的途径。

Method: 研究首先提取了15个流行网页（如Facebook）的DOM树，然后使用Lighthouse获取性能审计报告。接着将提取的DOM树和相应的审计报告传递给9种最先进的LLM进行问题解决。研究涵盖了7个独特的审计类别。

Result: LLMs在SEO和可访问性问题上普遍表现出色，但在性能关键的DOM操作方面效果不一。高性能模型如GPT-4.1在初始加载、交互性和网络优化等方面实现了显著减少（46.52%到48.68%的审计发生率减少），而GPT-4o-mini等模型表现不佳。修改分析显示主要采用添加策略和频繁的位置变化，同时对视觉稳定性产生了负面影响。

Conclusion: 大语言模型在自动化网页性能优化方面具有潜力，特别是在SEO和可访问性领域，但在性能关键的DOM操作方面需要进一步改进。模型表现存在显著差异，需要更精细的方法来处理DOM修改的复杂性。

Abstract: Users demand fast, seamless webpage experiences, yet developers often struggle to meet these expectations within tight constraints. Performance optimization, while critical, is a time-consuming and often manual process. One of the most complex tasks in this domain is modifying the Document Object Model (DOM), which is why this study focuses on it. Recent advances in Large Language Models (LLMs) offer a promising avenue to automate this complex task, potentially transforming how developers address web performance issues. This study evaluates the effectiveness of nine state-of-the-art LLMs for automated web performance issue resolution. For this purpose, we first extracted the DOM trees of 15 popular webpages (e.g., Facebook), and then we used Lighthouse to retrieve their performance audit reports. Subsequently, we passed the extracted DOM trees and corresponding audits to each model for resolution. Our study considers 7 unique audit categories, revealing that LLMs universally excel at SEO & Accessibility issues. However, their efficacy in performance-critical DOM manipulations is mixed. While high-performing models like GPT-4.1 delivered significant reductions in areas like Initial Load, Interactivity, and Network Optimization (e.g., 46.52% to 48.68% audit incidence reductions), others, such as GPT-4o-mini, notably underperformed, consistently. A further analysis of these modifications showed a predominant additive strategy and frequent positional changes, alongside regressions particularly impacting Visual Stability.

</details>


### [10] [LIDL: LLM Integration Defect Localization via Knowledge Graph-Enhanced Multi-Agent Analysis](https://arxiv.org/abs/2601.05539)
*Gou Tan,Zilong He,Min Li,Pengfei Chen,Jieke Shi,Zhensu Sun,Ting Zhang,Danwen Chen,Lwin Khin Shar,Chuanfu Zhang,David Lo*

Main category: cs.SE

TL;DR: LIDL是一个用于LLM集成软件缺陷定位的多智能体框架，通过构建代码知识图谱、融合错误证据和上下文感知验证，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: LLM集成软件具有概率性和上下文依赖的行为，与传统软件不同，会引入新的集成缺陷。现有缺陷定位技术无法有效识别这些LLM特定集成缺陷，因为它们无法捕捉异构工件间的跨层依赖关系，不能利用不完整或误导性的错误跟踪，且缺乏语义推理能力来识别根本原因。

Method: LIDL采用多智能体框架：(1)构建带有LLM感知注释的代码知识图谱，表示源代码、提示词和配置文件之间的交互边界；(2)融合由LLM推断的三种互补错误证据来源，以发现候选缺陷位置；(3)应用上下文感知验证，使用反事实推理来区分真正的根本原因和传播的症状。

Result: 在从105个GitHub仓库和16个基于智能体的系统中收集的146个真实缺陷实例上评估LIDL。结果显示LIDL在所有指标上显著优于五个最先进的基线方法，Top-3准确率达到0.64，MAP为0.48，比最佳基线提高了64.1%。同时成本降低了92.5%，实现了高准确性和成本效率。

Conclusion: LIDL通过多智能体框架有效解决了LLM集成软件中的缺陷定位问题，能够捕捉跨层依赖关系，利用不完整的错误证据，并进行语义推理，为LLM集成软件的可靠性和可维护性提供了重要工具。

Abstract: LLM-integrated software, which embeds or interacts with large language models (LLMs) as functional components, exhibits probabilistic and context-dependent behaviors that fundamentally differ from those of traditional software. This shift introduces a new category of integration defects that arise not only from code errors but also from misaligned interactions among LLM-specific artifacts, including prompts, API calls, configurations, and model outputs. However, existing defect localization techniques are ineffective at identifying these LLM-specific integration defects because they fail to capture cross-layer dependencies across heterogeneous artifacts, cannot exploit incomplete or misleading error traces, and lack semantic reasoning capabilities for identifying root causes.
  To address these challenges, we propose LIDL, a multi-agent framework for defect localization in LLM-integrated software. LIDL (1) constructs a code knowledge graph enriched with LLM-aware annotations that represent interaction boundaries across source code, prompts, and configuration files, (2) fuses three complementary sources of error evidence inferred by LLMs to surface candidate defect locations, and (3) applies context-aware validation that uses counterfactual reasoning to distinguish true root causes from propagated symptoms. We evaluate LIDL on 146 real-world defect instances collected from 105 GitHub repositories and 16 agent-based systems. The results show that LIDL significantly outperforms five state-of-the-art baselines across all metrics, achieving a Top-3 accuracy of 0.64 and a MAP of 0.48, which represents a 64.1% improvement over the best-performing baseline. Notably, LIDL achieves these gains while reducing cost by 92.5%, demonstrating both high accuracy and cost efficiency.

</details>


### [11] [Empirical Characterization of Logging Smells in Machine Learning Code](https://arxiv.org/abs/2601.05540)
*Patrick Loic Foalem,Leuson Da Silva,Foutse Khomh,Ettore Merlo,Heng Li*

Main category: cs.SE

TL;DR: 该研究通过大规模挖掘GitHub上的开源ML仓库，识别机器学习系统中的日志异味（logging smells），并通过从业者调查评估这些异味的严重性和频率。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习组件越来越多地集成到软件系统中，有效的日志记录对于确保模型训练和部署的可复现性、可追踪性和可观测性变得至关重要。然而，目前缺乏对机器学习系统中实际日志使用情况的了解，也没有系统性地研究机器学习系统中常见的日志异味。

Method: 1. 对GitHub上开源机器学习仓库进行大规模挖掘，识别和分类重复出现的日志异味；2. 对机器学习工程师进行从业者调查，评估已识别异味的感知相关性、严重性和频率。

Result: 研究尚未完成，但预期将提供机器学习系统中日志异味的实证分类，以及从业者对这些问题严重性的评估。

Conclusion: 该研究是理解和改进机器学习开发中日志实践的重要一步，尽管结果可能无法完全推广到闭源的工业项目中。

Abstract: \underline{Context:} Logging is a fundamental yet complex practice in software engineering, essential for monitoring, debugging, and auditing software systems. With the increasing integration of machine learning (ML) components into software systems, effective logging has become critical to ensure reproducibility, traceability, and observability throughout model training and deployment. Although various general-purpose and ML-specific logging frameworks exist, little is known about how these tools are actually used in practice or whether ML practitioners adopt consistent and effective logging strategies. To date, no empirical study has systematically characterized recurring bad logging practices--or logging smells--in ML System. \underline{Goal:} This study aims to empirically identify and characterize logging smells in ML systems, providing an evidence-based understanding of how logging is implemented and challenged in practice. \underline{Method:} We propose to conduct a large-scale mining of open-source ML repositories hosted on GitHub to catalogue recurring logging smells. Subsequently, a practitioner survey involving ML engineers will be conducted to assess the perceived relevance, severity, and frequency of the identified smells. \underline{Limitations:} % While The study's limitations include that While our findings may not be generalizable to closed-source industrial projects, we believe our study provides an essential step toward understanding and improving logging practices in ML development.

</details>


### [12] [Understanding LLM-Driven Test Oracle Generation](https://arxiv.org/abs/2601.05542)
*Adam Bodicoat,Gunel Jahangirova,Valerio Terragni*

Main category: cs.SE

TL;DR: LLM生成测试预言的研究：探索大语言模型在生成反映预期行为的测试预言方面的有效性，分析不同提示策略和上下文输入对预言质量的影响。


<details>
  <summary>Details</summary>
Motivation: 现有单元测试生成技术主要生成基于实现行为的回归预言，未能解决"预言问题"——区分正确与错误程序行为的挑战。随着基础模型（特别是大语言模型）的兴起，有机会生成反映预期行为的测试预言，将LLM定位为Promptware的推动者。

Method: 进行实证研究，调查LLM在生成暴露软件故障的测试预言方面的有效性。研究不同提示策略和不同级别的上下文输入如何影响LLM生成预言的质量。

Result: 研究结果揭示了LLM基于预言生成的优势和局限性，增进了对其能力的理解，并为该领域的未来研究奠定了基础。

Conclusion: LLM为生成反映预期行为的测试预言提供了新机会，但需要进一步研究不同提示策略和上下文输入的影响，以充分发挥其在Promptware时代的潜力。

Abstract: Automated unit test generation aims to improve software quality while reducing the time and effort required for creating tests manually. However, existing techniques primarily generate regression oracles that predicate on the implemented behavior of the class under test. They do not address the oracle problem: the challenge of distinguishing correct from incorrect program behavior. With the rise of Foundation Models (FMs), particularly Large Language Models (LLMs), there is a new opportunity to generate test oracles that reflect intended behavior. This positions LLMs as enablers of Promptware, where software creation and testing are driven by natural-language prompts. This paper presents an empirical study on the effectiveness of LLMs in generating test oracles that expose software failures. We investigate how different prompting strategies and levels of contextual input impact the quality of LLM-generated oracles. Our findings offer insights into the strengths and limitations of LLM-based oracle generation in the FM era, improving our understanding of their capabilities and fostering future research in this area.

</details>


### [13] [An Empirical Study of Policy-as-Code Adoption in Open-Source Software Projects](https://arxiv.org/abs/2601.05555)
*Patrick Loic Foalem,Foutse Khomh,Leuson Da Silva,Ettore Merlo*

Main category: cs.SE

TL;DR: 首次大规模研究开源软件中Policy-as-Code使用情况，分析399个GitHub仓库，构建包含5类15子类的PaC使用分类法，揭示工具采用多样性和治理意图。


<details>
  <summary>Details</summary>
Motivation: Policy-as-Code已成为将治理、合规和安全要求嵌入软件系统的基础方法，但软件工程社区缺乏对实际开发实践中这些工具使用的实证理解。组织越来越多地采用PaC工具，但缺乏对其实际使用情况的大规模研究。

Method: 分析399个使用9种广泛采用PaC工具的GitHub仓库。采用混合方法：结合工具使用和项目特征的定量分析，以及对策略文件的定性调查。使用LLM辅助分类流程（经专家验证）构建包含5个类别和15个子类别的PaC使用分类法。

Result: 研究显示PaC采用具有显著多样性：工具常用于早期项目，主要面向治理、配置控制和文档。观察到MLOps管道中新兴的PaC使用，以及OPA与Gatekeeper等工具间的强共现模式。分类法突出了重复出现的治理意图。

Conclusion: 研究结果为从业者和工具开发者提供可操作的见解，突出具体使用模式，强调实际PaC使用，并推动改进工具互操作性的机会。为未来研究PaC实践及其在确保可信、合规软件系统中的作用奠定实证基础。

Abstract: \textbf{Context:} Policy-as-Code (PaC) has become a foundational approach for embedding governance, compliance, and security requirements directly into software systems. While organizations increasingly adopt PaC tools, the software engineering community lacks an empirical understanding of how these tools are used in real-world development practices.
  \textbf{Objective:} This paper aims to bridge this gap by conducting the first large-scale study of PaC usage in open-source software. Our goal is to characterize how PaC tools are adopted, what purposes they serve, and what governance activities they support across diverse software ecosystems.
  \textbf{Method:} We analyzed 399 GitHub repositories using nine widely adopted PaC tools. Our mixed-methods approach combines quantitative analysis of tool usage and project characteristics with a qualitative investigation of policy files. We further employ a Large Language Model (LLM)--assisted classification pipeline, refined through expert validation, to derive a taxonomy of PaC usage consisting of 5 categories and 15 sub-categories.
  \textbf{Results:} Our study reveals substantial diversity in PaC adoption. PaC tools are frequently used in early-stage projects and are heavily oriented toward governance, configuration control, and documentation. We also observe emerging PaC usage in MLOps pipelines and strong co-usage patterns, such as between OPA and Gatekeeper. Our taxonomy highlights recurring governance intents.
  \textbf{Conclusion:} Our findings offer actionable insights for practitioners and tool developers. They highlight concrete usage patterns, emphasize actual PaC usage, and motivate opportunities for improving tool interoperability. This study lays the empirical foundation for future research on PaC practices and their role in ensuring trustworthy, compliant software systems.

</details>


### [14] [Package-Aware Approach for Repository-Level Code Completion in Pharo](https://arxiv.org/abs/2601.05617)
*Omar Abedelkader,Stéphane Ducasse,Oleksandr Zaitsev,Romain Robbes,Guillermo Polito*

Main category: cs.SE

TL;DR: 提出一种基于包结构的代码补全启发式方法，相比原有的全局命名空间平铺式搜索，能优先推荐同一包或项目中的类名和变量名，提高补全准确性。


<details>
  <summary>Details</summary>
Motivation: Pharo现有的语义启发式补全引擎虽然强大，但在推荐全局名称（如类名、类变量、全局变量）时忽略了仓库结构，没有优先考虑同一包或项目中的类，将所有全局名称平等对待，导致补全建议不够精准。

Method: 提出新的启发式方法，采用结构化搜索变量名称：首先搜索请求类所在的包，然后扩展到同一仓库中的其他包，最后才考虑全局命名空间。这种方法考虑了代码的组织结构。

Result: 初步结果显示，平均倒数排名（MRR）有所改善，证实了基于包感知的补全比之前的平铺式全局方法能提供更准确和相关的建议。

Conclusion: 通过考虑仓库结构的包感知补全启发式方法能显著提高代码补全的准确性和相关性，解决了原有系统忽略代码组织结构的问题。

Abstract: Pharo offers a sophisticated completion engine based on semantic heuristics, which coordinates specific fetchers within a lazy architecture. These heuristics can be recomposed to support various activities (e.g., live programming or history usage navigation). While this system is powerful, it does not account for the repository structure when suggesting global names such as class names, class variables, or global variables. As a result, it does not prioritize classes within the same package or project, treating all global names equally. In this paper, we present a new heuristic that addresses this limitation. Our approach searches variable names in a structured manner: it begins with the package of the requesting class, then expands to other packages within the same repository, and finally considers the global namespace. We describe the logic behind this heuristic and evaluate it against the default semantic heuristic and one that directly queries the global namespace. Preliminary results indicate that the Mean Reciprocal Rank (MRR) improves, confirming that package-awareness completions deliver more accurate and relevant suggestions than the previous flat global approach.

</details>


### [15] [A Large Scale Empirical Analysis on the Adherence Gap between Standards and Tools in SBOM](https://arxiv.org/abs/2601.05622)
*Chengjie Wang,Jingzheng Wu,Hao Lyu,Xiang Ling,Tianyue Luo,Yanjun Wu,Chen Zhao*

Main category: cs.SE

TL;DR: 本文首次大规模实证分析SBOM工具对标准规范的遵从性差距，发现当前工具存在政策合规支持不足、工具一致性差、软件信息准确性低等根本性限制。


<details>
  <summary>Details</summary>
Motivation: SBOM作为增强软件供应链透明度和安全性的重要工具，已有多种标准和生成工具，但缺乏对这些工具是否符合标准规范的系统性研究，这种遵从性差距可能导致合规失败和SBOM使用中断。

Method: 采用两阶段实证分析方法：基线评估和一年纵向跟踪，使用自动化评估框架SAP，覆盖6个SBOM工具从3,287个真实仓库生成的55,444个SBOM。

Result: 发现当前SBOM工具存在三个根本性限制：1) 政策要求合规支持不足；2) 工具一致性差（跨工具包检测一致性率仅7.84%-12.77%，纵向一致性低）；3) 详细软件信息准确性中等至差（如许可证准确性低于20%）。

Conclusion: 当前SBOM工具在标准遵从性方面存在显著差距，分析了根本原因并提供了实用解决方案，所有代码和评估结果已开源供进一步研究。

Abstract: A Software Bill of Materials (SBOM) is a machine-readable artifact that systematically organizes software information, enhancing supply chain transparency and security. To facilitate the exchange and utilization of SBOMs, organizations such as the Linux Foundation and OWASP have proposed SBOM standards. Following standards, organizations have developed tools for generating and utilizing SBOMs. However, limited research has examined the adherence of these SBOM tools to standard specifications, a gap that could lead to compliance failures and disruptions in SBOM utilization. This paper presents the first large-scale, two-stage empirical analysis of the adherence gap, using our automated evaluation framework, SAP. The evaluation, comprising a baseline evaluation and a one-year longitudinal follow-up, covers 55,444 SBOMs generated by six SBOM tools from 3,287 real-world repositories. Our analysis reveals persistent, fundamental limitations in current SBOM tools: (1) inadequate compliance support with policy requirements; (2) poor tool consistencies, including inter-tool consistency rates as low as 7.84% to 12.77% for package detection across languages, and significant longitudinal inconsistency, where tools show low consistency with their own prior versions; and (3) mediocre to poor accuracy for detailed software information, e.g., accuracy of package licenses below 20%. We analyze the root causes of these gaps and provide practical solutions. All the code, replication docker image, evaluation results are open sourced at [GitHub](https://github.com/dw763j/SAP) and [Zenodo](https://doi.org/10.5281/zenodo.14998624) for further researches.

</details>


### [16] [Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models](https://arxiv.org/abs/2601.05663)
*Gianmario Voria,Moses Openja,Foutse Khomh,Gemma Catolino,Fabio Palomba*

Main category: cs.SE

TL;DR: 研究发现预训练Transformer中存在编码偏见的神经元，通过定位并抑制这些神经元可以显著减少模型偏见，同时保持软件工程任务性能


<details>
  <summary>Details</summary>
Motivation: Transformer模型在软件工程中广泛应用，但可能复制或放大社会偏见。现有研究表明可以通过神经元编辑改变模型行为，因此假设存在编码刻板印象的偏见神经元

Method: 构建包含九种偏见类型的偏见关系数据集，采用神经元归因策略在BERT模型中追踪和抑制偏见神经元，评估抑制对软件工程任务的影响

Result: 偏见知识集中在少量神经元子集中，抑制这些神经元能显著减少偏见，同时性能损失最小

Conclusion: Transformer中的偏见可以在神经元层面追踪和缓解，为软件工程中的公平性提供了可解释的方法

Abstract: The advent of transformer-based language models has reshaped how AI systems process and generate text. In software engineering (SE), these models now support diverse activities, accelerating automation and decision-making. Yet, evidence shows that these models can reproduce or amplify social biases, raising fairness concerns. Recent work on neuron editing has shown that internal activations in pre-trained transformers can be traced and modified to alter model behavior. Building on the concept of knowledge neurons, neurons that encode factual information, we hypothesize the existence of biased neurons that capture stereotypical associations within pre-trained transformers. To test this hypothesis, we build a dataset of biased relations, i.e., triplets encoding stereotypes across nine bias types, and adapt neuron attribution strategies to trace and suppress biased neurons in BERT models. We then assess the impact of suppression on SE tasks. Our findings show that biased knowledge is localized within small neuron subsets, and suppressing them substantially reduces bias with minimal performance loss. This demonstrates that bias in transformers can be traced and mitigated at the neuron level, offering an interpretable approach to fairness in SE.

</details>


### [17] [Drivora: A Unified and Extensible Infrastructure for Search-based Autonomous Driving Testing](https://arxiv.org/abs/2601.05685)
*Mingfei Cheng,Lionel Briand,Yuan Zhou*

Main category: cs.SE

TL;DR: Drivora是一个基于CARLA的统一可扩展基础设施，用于自动驾驶系统的搜索式测试，提供统一场景定义、解耦测试引擎、并行执行机制和12个ADS的统一接口。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统测试方法基于异构框架（不同场景空间、模拟器、ADS），在不同设置间重用和适配需要大量工作，缺乏统一基础设施。

Method: 1. 引入统一场景定义OpenScenario，使用低层次可操作参数；2. 解耦测试引擎、场景执行和ADS集成；3. 测试引擎基于进化计算探索新场景；4. 并行执行机制最大化硬件利用率；5. 提供12个ADS的统一接口。

Result: 开发了Drivora工具，支持大规模批量模拟，简化了不同ADS的配置和集成，代码已在GitHub公开。

Conclusion: Drivora解决了自动驾驶系统测试中的异构框架问题，提供了统一、可扩展的基础设施，支持灵活定制和高效执行，有助于促进搜索式测试研究。

Abstract: Search-based testing is critical for evaluating the safety and reliability of autonomous driving systems (ADSs). However, existing approaches are often built on heterogeneous frameworks (e.g., distinct scenario spaces, simulators, and ADSs), which require considerable effort to reuse and adapt across different settings. To address these challenges, we present Drivora, a unified and extensible infrastructure for search-based ADS testing built on the widely used CARLA simulator. Drivora introduces a unified scenario definition, OpenScenario, that specifies scenarios using low-level, actionable parameters to ensure compatibility with existing methods while supporting extensibility to new testing designs (e.g., multi-autonomous-vehicle testing). On top of this, Drivora decouples the testing engine, scenario execution, and ADS integration. The testing engine leverages evolutionary computation to explore new scenarios and supports flexible customization of core components. The scenario execution can run arbitrary scenarios using a parallel execution mechanism that maximizes hardware utilization for large-scale batch simulation. For ADS integration, Drivora provides access to 12 ADSs through a unified interface, streamlining configuration and simplifying the incorporation of new ADSs. Our tools are publicly available at https://github.com/MingfeiCheng/Drivora.

</details>


### [18] [AIBoMGen: Generating an AI Bill of Materials for Secure, Transparent, and Compliant Model Training](https://arxiv.org/abs/2601.05703)
*Wiebe Vandendriessche,Jordi Thijsman,Laurens D'hooge,Bruno Volckaert,Merlijn Sebrechts*

Main category: cs.SE

TL;DR: 论文提出AI物料清单(AIBOM)作为标准化、可验证的AI模型记录，并开发了自动化生成平台AIBoMGen，通过加密哈希、数字签名等技术确保AI系统透明度、安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 复杂AI系统的快速采用超过了确保其透明度、安全性和监管合规性工具的发展速度，需要建立标准化的可验证记录机制来应对这一挑战。

Method: 提出AI物料清单(AIBOM)概念，作为软件物料清单(SBOM)的扩展；开发AIBoMGen平台自动化生成签名的AIBOM，捕获训练过程中的数据集、模型元数据和环境细节；使用加密哈希、数字签名和in-toto证明确保完整性；训练平台作为中立的第三方观察者和信任根。

Result: AIBoMGen能够可靠检测所有工件的未经授权修改，并能以可忽略的性能开销生成AIBOM，验证了其作为构建安全透明AI生态系统基础步骤的潜力。

Conclusion: AIBOM和AIBoMGen平台为实现安全透明的AI生态系统提供了基础，能够支持欧盟AI法案等监管框架的合规要求，是解决AI系统透明度、安全性和监管挑战的重要一步。

Abstract: The rapid adoption of complex AI systems has outpaced the development of tools to ensure their transparency, security, and regulatory compliance. In this paper, the AI Bill of Materials (AIBOM), an extension of the Software Bill of Materials (SBOM), is introduced as a standardized, verifiable record of trained AI models and their environments. Our proof-of-concept platform, AIBoMGen, automates the generation of signed AIBOMs by capturing datasets, model metadata, and environment details during training. The training platform acts as a neutral, third-party observer and root of trust. It enforces verifiable AIBOM creation for every job. The system uses cryptographic hashing, digital signatures, and in-toto attestations to ensure integrity and protect against threats such as artifact tampering by dishonest model creators. Our evaluation demonstrates that AIBoMGen reliably detects unauthorized modifications to all artifacts and can generate AIBOMs with negligible performance overhead. These results highlight the potential of AIBoMGen as a foundational step toward building secure and transparent AI ecosystems, enabling compliance with regulatory frameworks like the EUs AI Act.

</details>


### [19] [From Issues to Insights: RAG-based Explanation Generation from Software Engineering Artifacts](https://arxiv.org/abs/2601.05721)
*Daniel Pöttgen,Mersedeh Sadeghi,Max Unterbusch,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本研究首次应用检索增强生成(RAG)方法，利用问题跟踪数据生成软件系统解释，实现了90%与人工解释的一致性。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统日益复杂，传统文档往往过时或不完整，难以提供准确解释。问题跟踪系统包含丰富且持续更新的开发知识，但其解释潜力尚未被挖掘。

Method: 采用检索增强生成(RAG)方法，基于开源工具和语言模型构建概念验证系统，利用结构化问题数据生成解释。

Result: 在GitHub问题集上的评估显示，系统生成解释与人工解释的匹配度达90%，同时表现出良好的忠实性和指令遵循性。

Conclusion: RAG方法可将可解释性扩展到更广泛的软件系统，前提是有可用的问题跟踪数据，使系统行为更易理解和解释。

Abstract: The increasing complexity of modern software systems has made understanding their behavior increasingly challenging, driving the need for explainability to improve transparency and user trust. Traditional documentation is often outdated or incomplete, making it difficult to derive accurate, context-specific explanations. Meanwhile, issue-tracking systems capture rich and continuously updated development knowledge, but their potential for explainability remains untapped. With this work, we are the first to apply a Retrieval-Augmented Generation (RAG) approach for generating explanations from issue-tracking data. Our proof-of-concept system is implemented using open-source tools and language models, demonstrating the feasibility of leveraging structured issue data for explanation generation. Evaluating our approach on an exemplary project's set of GitHub issues, we achieve 90% alignment with human-written explanations. Additionally, our system exhibits strong faithfulness and instruction adherence, ensuring reliable and grounded explanations. These findings suggest that RAG-based methods can extend explainability beyond black-box ML models to a broader range of software systems, provided that issue-tracking data is available - making system behavior more accessible and interpretable.

</details>


### [20] [StriderSPD: Structure-Guided Joint Representation Learning for Binary Security Patch Detection](https://arxiv.org/abs/2601.05772)
*Qingyuan Li,Chenchen Yu,Chuanyi Li,Xin-Cheng Wen,Cheryl Lee,Cuiyun Gao,Bin Luo*

Main category: cs.SE

TL;DR: StriderSPD：一个结合图神经网络与大语言模型的结构引导二进制安全补丁检测框架，通过适配器对齐汇编代码和伪代码表示，解决闭源软件安全补丁检测问题。


<details>
  <summary>Details</summary>
Motivation: 闭源软件的安全补丁检测面临挑战：二进制补丁缺乏源代码，现有方法使用汇编代码（语义有限）或伪代码（缺乏结构化语法），且现有研究多在开源软件上评估，无法反映闭源环境。需要更准确表示漏洞修复模式的方法。

Method: 提出StriderSPD框架，将图分支集成到大语言模型中，利用结构信息指导LLM识别安全补丁。设计适配器在LLM令牌级别对齐汇编代码和伪代码表示。采用两阶段训练策略解决两个分支参数不平衡导致的优化问题。

Result: 构建了与现有数据集在项目和领域上都不同的二进制SPD基准测试，并在该基准上广泛评估StriderSPD，验证了其有效性。

Conclusion: StriderSPD通过结构引导的联合表示学习，有效解决了闭源软件二进制安全补丁检测的挑战，为现实世界软件安全提供了更实用的解决方案。

Abstract: Vulnerabilities severely threaten software systems, making the timely application of security patches crucial for mitigating attacks. However, software vendors often silently patch vulnerabilities with limited disclosure, where Security Patch Detection (SPD) comes to protect software assets. Recently, most SPD studies have targeted Open-Source Software (OSS), yet a large portion of real-world software is closed-source, where patches are distributed as binaries without accessible source code. The limited binary SPD approaches often lift binaries to abstraction levels, i.e., assembly code or pseudo-code. However, assembly code is register-based instructions conveying limited semantics, while pseudo-code lacks parser-compatible grammar to extract structure, both hindering accurate vulnerability-fix representation learning. In addition, previous studies often obtain training and testing data from the same project for evaluation, which fails to reflect closed-source conditions. To alleviate the above challenges, we propose \textbf{\textit{StriderSPD}}, a \underline{Str}ucture-gu\underline{ide}d joint \underline{r}epresentation \underline{SPD} framework of binary code that integrates a graph branch into a large language model (LLM), leveraging structural information to guide the LLM in identifying security patches. Our novel design of the adapters in the graph branch effectively aligns the representations between assembly code and pseudo-code at the LLM's token level. We further present a two-stage training strategy to address the optimization imbalance caused by the large parameter disparity between StriderSPD's two branches, which enables proper branch fitting. To enable more realistic evaluation, we construct a binary SPD benchmark that is disjoint from prior datasets in both projects and domains and extensively evaluate StriderSPD on this benchmark.

</details>


### [21] [EET: Experience-Driven Early Termination for Cost-Efficient Software Engineering Agents](https://arxiv.org/abs/2601.05777)
*Yaoqi Guo,Ying Xiao,Jie M. Zhang,Mark Harman,Yiling Lou,Yang Liu,Zhenpeng Chen*

Main category: cs.SE

TL;DR: EET是一种经验驱动的早期终止方法，通过从历史问题解决执行中提取结构化经验，在补丁生成和选择阶段指导早期终止，减少无意义的迭代，从而降低SE代理的成本同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的软件工程代理在实践中应用日益广泛，但它们通常会产生高昂的货币成本。需要一种方法来降低这些成本，同时保持任务解决能力。

Method: EET从先前的问题解决执行中提取结构化经验，利用这些经验在补丁生成和选择阶段指导早期终止决策，减少无生产性的迭代循环。

Result: 在SWE-bench Verified基准测试中，EET在三个代表性SE代理上实现了19%-55%的总成本降低（平均32%），而解决率损失极小（最多0.2%）。平均而言，它为11%的问题识别了早期终止机会，API调用、输入token和输出token分别减少了21%、30%和25%。

Conclusion: EET通过经验驱动的早期终止机制，能够显著降低软件工程代理的成本，同时几乎不影响任务性能，为实际应用提供了有效的成本优化方案。

Abstract: Software engineering (SE) agents powered by large language models are increasingly adopted in practice, yet they often incur substantial monetary cost. We introduce EET, an experience-driven early termination approach that reduces the cost of SE agents while preserving task performance. EET extracts structured experience from prior issue-resolution executions and leverages it to guide early termination during patch generation and selection, reducing unproductive iterations. We evaluate EET on the SWE-bench Verified benchmark across three representative SE agents. EET consistently reduces total cost by 19%-55% (32% on average), with negligible loss in resolution rate (at most 0.2%). These efficiency gains are achieved, on average, by identifying early-termination opportunities for 11% of issues and reducing API calls, input tokens, and output tokens by 21%, 30%, and 25%, respectively. We release the code, prompts, and data at https://github.com/EffiSEAgent/EET.

</details>


### [22] [SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking](https://arxiv.org/abs/2601.05827)
*Zewei Lin,Jiachi Chen,Jingwen Zhang,Zexu Wang,Yuming Feng,Weizhe Zhang,Zibin Zheng*

Main category: cs.SE

TL;DR: SSR工具首次系统研究DeFi质押逻辑缺陷，通过LLM提取质押逻辑信息，检测出22.24%真实合约存在至少一种逻辑缺陷，准确率达92.31%。


<details>
  <summary>Details</summary>
Motivation: DeFi质押作为DeFi生态核心应用，其逻辑缺陷可能导致攻击者非法获取奖励，但目前缺乏系统性研究和检测工具。

Method: 通过分析64个安全事件和144份审计报告，识别6类逻辑缺陷；开发SSR静态分析工具，利用大语言模型提取质押逻辑信息并构建DeFi质押模型，通过语义特征分析检测缺陷。

Result: SSR在基准数据集上达到92.31%精确率、87.92%召回率和88.85%F1分数；在15,992个真实DeFi质押合约中，检测出3,557个（22.24%）存在至少一种逻辑缺陷。

Conclusion: DeFi质押逻辑缺陷普遍存在，SSR工具能有效检测这些缺陷，为DeFi安全提供重要保障，未来可扩展至其他DeFi应用。

Abstract: Decentralized Finance (DeFi) staking is one of the most prominent applications within the DeFi ecosystem, where DeFi projects enable users to stake tokens on the platform and reward participants with additional tokens. However, logical defects in DeFi staking could enable attackers to claim unwarranted rewards by manipulating reward amounts, repeatedly claiming rewards, or engaging in other malicious actions. To mitigate these threats, we conducted the first study focused on defining and detecting logical defects in DeFi staking. Through the analysis of 64 security incidents and 144 audit reports, we identified six distinct types of logical defects, each accompanied by detailed descriptions and code examples. Building on this empirical research, we developed SSR (Safeguarding Staking Reward), a static analysis tool designed to detect logical defects in DeFi staking contracts. SSR utilizes a large language model (LLM) to extract fundamental information about staking logic and constructs a DeFi staking model. It then identifies logical defects by analyzing the model and the associated semantic features. We constructed a ground truth dataset based on known security incidents and audit reports to evaluate the effectiveness of SSR. The results indicate that SSR achieves an overall precision of 92.31%, a recall of 87.92%, and an F1-score of 88.85%. Additionally, to assess the prevalence of logical defects in real-world smart contracts, we compiled a large-scale dataset of 15,992 DeFi staking contracts. SSR detected that 3,557 (22.24%) of these contracts contained at least one logical defect.

</details>
