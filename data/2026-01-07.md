<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 20]
- [cs.LO](#cs.LO) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Backwards Data-Flow Analysis using Prophecy Variable in the BuildIt System](https://arxiv.org/abs/2601.02653)
*Ajay Brahmakshatriya,Saman Amarasinghe,Martin Rinard*

Main category: cs.PL

TL;DR: 该论文提出使用预言变量（prophecy variables）来预测程序未来执行信息，替代传统的反向程序分析，从而简化需要未来行为信息的程序转换和优化。


<details>
  <summary>Details</summary>
Motivation: 许多程序转换和优化需要程序未来行为的信息。传统方法通过构建中间程序表示并使用反向程序分析来传播相关信息，但这种方法实现复杂且工程开销大。

Method: 在BuildIt系统中实现预言变量，这是一个轻量级领域特定语言实现系统。BuildIt采用分阶段编译，第一阶段使用标准C++程序执行生成优化的C、C++和CUDA第二阶段代码。结合预言变量和重复正向程序执行，无需反向分析即可获取未来执行信息。

Result: BuildIt成功实现了预言变量，消除了传统语言实现组件（如解析器和中间表示），显著减少了领域特定语言实现的工程工作量。实验结果显示BuildIt计算能够从预言变量提供的信息中受益。

Conclusion: 预言变量提供了一种有效的方法来获取程序未来执行信息，无需复杂的反向程序分析，简化了需要未来行为信息的程序转换和优化实现。

Abstract: Many program transformations and optimizations require information about the future behavior of the program. A standard way to obtain this information is to build an intermediate program representation, then use a backwards program analysis to propagate relevant information against the flow of control back to the transformation/optimization site. We instead propose to use prophecy variables, which predict information about the future execution of the program, to enable such transformations and optimizations. We implement prophecy variables in BuildIt, a lightweight domain specific language implementation system. BuildIt uses staged compilation to implement high performance domain specific languages embedded within a standard general purpose programming language (C++). The BuildIt first phase uses standard C++ program execution to generate optimized C, C++, and CUDA second phase code. This approach enables BuildIt to eliminate programming language implementation components such as parsers and intermediate representations, delivering a dramatic decrease in the engineering effort required to implement domain specific languages. The combination of prophecy variables and repeated forward program execution enables BuildIt to extend this approach to include transformations and optimizations that require information about the future execution of the program without backwards analyses and without the engineering overhead associated with implementing these analyses. We formalize the use of prophecy variables for this purpose, discuss the implementation of prophecy variables and repeated execution in BuildIt, and present experimental results for BuildIt computations that benefit from optimizations enabled by the information that prophecy variables provide.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments](https://arxiv.org/abs/2601.02399)
*Jiaxin Ai,Yukang Feng,Fanrui Zhang,Jianwen Sun,Zizhen Li,Chuanhao Li,Yifan Chang,Wenxiao Wu,Ruoxi Wang,Mingliang Zhai,Kaipeng Zhang*

Main category: cs.SE

TL;DR: ProSoftArena是一个专门评估多模态智能体在专业软件环境中表现的基准测试平台，包含436个跨6个学科、13个专业应用的真实任务，采用执行评估和人工参与范式。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要局限于浏览器和基础桌面应用，无法评估智能体在真实科学和工业实践中使用的专业软件工作流中的表现，需要填补这一空白。

Method: 构建了针对专业软件使用的首个能力层次结构，创建了包含436个真实任务的基准测试，建立了可执行的真实计算机环境，采用基于执行的评估框架，并独特地融入了人工参与评估范式。

Result: 实验显示，即使是表现最佳的智能体在L2任务上也只有24.4%的成功率，在L3多软件工作流上完全失败，揭示了当前智能体在专业软件环境中的严重局限性。

Conclusion: ProSoftArena为评估专业软件环境中的多模态智能体提供了重要基准，深入分析为克服当前智能体局限性和设计更有效的智能体提供了宝贵见解，推动了专业软件环境中更强大智能体的发展。

Abstract: Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.

</details>


### [3] [Compressed code: the hidden effects of quantization and distillation on programming tokens](https://arxiv.org/abs/2601.02563)
*Viacheslav Siniaev,Iaroslav Chelombitko,Aleksey Komissarov*

Main category: cs.SE

TL;DR: 该论文系统分析了LLM在代码生成中的token级机制，特别是压缩模型中的表现，提出了冷启动概率分析方法，并评估了不同优化技术对token表示和代码生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成方面表现出色，但其token级机制，特别是在压缩模型中的工作机制仍未得到充分探索。需要理解编程语言在LLM tokenizer中的编码方式，以及不同优化技术如何影响token级表示和代码生成质量。

Method: 1. 系统分析编程语言token表示，包括词汇分布和关键词覆盖模式分析；2. 引入新颖的冷启动概率分析方法，无需显式提示即可洞察模型行为；3. 全面评估不同模型优化技术（量化、蒸馏、模型缩放、任务特定微调）对token级表示和代码生成质量的影响；4. 使用概率分布分析和评估指标进行实验验证。

Result: 实验揭示了token级行为的关键洞察，提供了经实证验证的指导原则，帮助在各种优化约束下保持代码生成质量。研究结果增进了对LLM代码生成的理论理解，并为生产环境中优化模型的实践实施提供了指导。

Conclusion: 该研究通过系统分析LLM代码生成的token级机制，特别是压缩模型中的表现，提出了创新的分析方法，并为不同优化技术下的代码生成质量维护提供了实证指导，推动了LLM代码生成的理论理解和实际应用。

Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.

</details>


### [4] [The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming](https://arxiv.org/abs/2601.02410)
*Aizierjiang Aiersilan*

Main category: cs.SE

TL;DR: 论文提出Vibe-Check Protocol (VCP)框架，通过三个量化指标评估Vibe Coding（AI辅助编程）在软件工程教育中的效果，旨在确定其最佳教学边界。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件工程教育中的整合，出现了"Vibe Coding"范式，即开发者用自然语言表达高层意图，由AI代理实现代码。虽然支持者认为这种方法通过强调概念设计而非语法记忆来现代化教学，但积累的实证证据引发了对技能保持和深度概念理解的担忧。

Method: 提出Vibe-Check Protocol (VCP)系统化基准测试框架，包含三个量化指标：1) Cold Start Refactor (M_CSR)用于建模技能衰减；2) Hallucination Trap Detection (M_HT)基于信号检测理论评估错误识别能力；3) Explainability Gap (E_gap)用于量化代码复杂性与概念理解之间的差距。

Result: 通过受控比较，VCP旨在为教育工作者提供量化基础，以确定最佳教学边界：识别Vibe Coding促进真正掌握的上下文，以及引入隐藏技术债务和表面能力的上下文。

Conclusion: 论文提出理论框架来研究Vibe Coding是否是学习软件工程的更好方式，区分学生利用AI进行加速与认知卸载的不同结果，通过VCP评估这些教育权衡。

Abstract: The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.

</details>


### [5] [Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams](https://arxiv.org/abs/2601.02421)
*Nyan Lin Zaw*

Main category: cs.SE

TL;DR: 研究年轻专业人士（18-27岁）产品团队的成功因素，发现好奇心、地理位置接近、文档记录和资源获取等新因素对团队生产力有重要影响


<details>
  <summary>Details</summary>
Motivation: 现有组织沟通研究主要关注27岁以上、有5年以上经验的成熟专业人士，缺乏对年轻新兴专业人士（18-27岁）产品团队的研究，需要填补这一文献空白

Method: 研究年轻产品团队（成员年龄18-27岁），探索影响其成功的因素，基于团队开发产品的成功率来评估团队生产力

Result: 发现一些传统因素仍然适用，但有些变得不那么相关，同时识别出新的关键因素：好奇心、地理位置接近、文档记录和资源获取

Conclusion: 这项研究填补了关于年轻专业人士团队如何被新因素塑造的文献空白，为理解新兴专业人士团队的成功机制提供了新视角

Abstract: This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.

</details>


### [6] [WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics](https://arxiv.org/abs/2601.02430)
*Chenxu Liu,Yingjie Fu,Wei Yang,Ying Zhang,Tao Xie*

Main category: cs.SE

TL;DR: WebCoderBench：首个真实用户需求收集、可泛化且可解释的网页应用生成基准，包含1572个真实用户需求，24个细粒度评估指标，覆盖9个维度，支持全自动评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在网页应用代码生成领域缺乏有效的基准测试工具，现有方法面临三大挑战：需要真实用户需求、不依赖参考实现或测试用例的可泛化评估指标、以及可解释的评估结果。

Method: 收集1572个真实用户需求，涵盖多种模态和表达风格；设计24个细粒度评估指标覆盖9个维度；结合基于规则和LLM作为评判者的评估范式；采用人类偏好对齐的指标权重来获得可解释的综合评分。

Result: 在12个代表性LLM和2个LLM智能体上的实验表明，没有模型在所有评估指标上表现最优，这为LLM开发者提供了针对性优化的机会。

Conclusion: WebCoderBench填补了网页应用生成基准的空白，提供了真实、可泛化、可解释的评估框架，有助于推动LLM在网页应用开发领域的进步。

Abstract: Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.

</details>


### [7] [Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection](https://arxiv.org/abs/2601.02438)
*Yun Bian,Yi Chen,HaiQuan Wang,ShiHao Li,Zhe Cui*

Main category: cs.SE

TL;DR: 提出TaCCS-DFA框架，通过Fisher信息度量特征方向对分类决策的敏感性，实现任务导向的互补融合，提升软件漏洞检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法通常融合自然代码序列和代码属性图表示，但隐含假设添加模态必然带来额外信息。实际上序列和图表示可能存在冗余，且图模态质量波动可能稀释主导模态的判别信号。

Method: 提出TaCCS-DFA框架：1) 引入Fisher信息作为几何度量，评估特征方向对分类决策的敏感性；2) 在线估计低秩主Fisher子空间，将跨模态注意力限制在任务敏感方向；3) 自适应门控机制动态调整每个样本的图模态贡献以抑制噪声传播。

Result: 在BigVul、Devign和ReVeal数据集上验证，使用CodeT5作为骨干网络时，在高度不平衡的BigVul数据集上达到87.80%的F1分数，比强基线Vul-LMGNNs提升6.3个百分点，同时保持低校准误差和计算开销。

Conclusion: TaCCS-DFA通过任务导向的互补融合有效解决了多模态表示中的冗余和噪声问题，在软件漏洞检测任务中取得了显著性能提升，理论分析表明其风险界限优于传统全谱注意力方法。

Abstract: Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.

</details>


### [8] [The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance](https://arxiv.org/abs/2601.02454)
*Saba Naqvi,Mohammad Baqar,Nawaz Ali Mohammad*

Main category: cs.SE

TL;DR: 提出一个基于多智能体的闭环自校正测试框架，通过测试生成、执行分析和优化评审三个智能体协作，利用沙箱执行和迭代修复，显著减少无效测试并提升覆盖率。


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的测试生成器存在静态、单次输出的问题，缺乏执行感知反馈，导致产生大量无效、冗余或不可执行的测试用例。

Method: 采用多智能体框架，包含测试生成智能体、执行分析智能体和评审优化智能体，通过沙箱执行、详细失败报告和迭代修复机制，形成闭环自校正系统，并与CI/CD管道集成。

Result: 在微服务应用上的实证评估显示：无效测试减少60%，覆盖率提升30%，人工工作量显著降低，优于单模型基线方法。

Conclusion: 多智能体、反馈驱动的闭环系统可以将软件测试演变为自主、持续学习的质量保证生态系统，实现自修复、高可靠性的代码库。

Abstract: Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.

</details>


### [9] [Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support](https://arxiv.org/abs/2601.02504)
*Elizaveta Artser,Daniil Karol,Anna Potriasaeva,Aleksei Rostovskii,Katsiaryna Dzialets,Ekaterina Koshchenko,Xiaotian Su,April Yi Wang,Anastasiia Birillo*

Main category: cs.SE

TL;DR: AI驱动的IDE调试助手，通过RAG、程序切片和启发式方法提供实时调试支持，减少LLM调用并提高准确性


<details>
  <summary>Details</summary>
Motivation: 调试是编程教育和软件开发中的关键技能，但在计算机科学课程中经常被忽视，需要工具来支持调试教学和实践

Method: 集成到IDE中的AI调试助手，使用RAG与LLMs、程序切片和自定义启发式方法，分析代码、建议断点并提供上下文提示

Result: 通过三级评估（技术分析、用户体验研究和课堂测试）显示其在教学调试方面的潜力

Conclusion: AI驱动的调试助手有潜力改善调试教学，通过减少LLM调用提高效率，并通过多级评估验证了其有效性

Abstract: Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.

</details>


### [10] [Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?](https://arxiv.org/abs/2601.02512)
*Pelin Rabia Kuran,Rumbidzai Chitakunye,Vincenzo Stoico,Ilja Heitlager,Justus Bogner*

Main category: cs.SE

TL;DR: 研究分析四种优化技术在工业LLM应用中的能耗效果，发现Prompt优化和2-bit量化可显著降低能耗但损害准确性，而大小模型协作是唯一能显著节能且不严重损害其他质量的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在工业规模部署时能耗巨大，但现有优化技术在工业应用中的实际效果缺乏实证研究。本研究旨在填补这一空白，分析不同优化技术对工业LLM应用的能耗、准确性和响应时间的影响。

Method: 选取荷兰IT服务公司Schuberg Philis的聊天机器人应用作为案例，应用四种优化技术（大小模型协作、提示优化、量化、批处理）的八种变体，通过实验比较它们与未优化基线的能耗、准确性和响应时间表现。

Result: 提示优化和2-bit量化等技术可显著降低能耗（最高达90%），但严重损害准确性到不可接受的程度。只有使用Nvidia Prompt Task and Complexity Classifier（NPCC）的大小模型协作技术能在显著降低能耗的同时，不严重损害其他质量指标。

Conclusion: 降低LLM应用的能耗在实践中并不困难，但实现能效提升（即在不损害其他质量的前提下降低能耗）仍然具有挑战性。大小模型协作是当前最有前景的解决方案，本研究为工业实践提供了实用见解。

Abstract: The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.
  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.

</details>


### [11] [On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment](https://arxiv.org/abs/2601.02522)
*Zhinuan,Guo,Chushu Gao,Justus Bogner*

Main category: cs.SE

TL;DR: 本研究通过实验评估了五种降低RAG系统能耗的技术，发现提高相似度检索阈值和减小嵌入尺寸能在不损失准确性的情况下显著降低能耗和延迟，而其他技术则可能导致准确性大幅下降。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统（特别是RAG系统）的能源需求日益增长，引发了对其环境可持续性的担忧。虽然已有研究提出了绿色ML技术，但这些技术在RAG系统中的实证评估仍很缺乏。

Method: 在合作方Software Improvement Group开发的生产级RAG系统上进行控制实验，评估了五种节能技术对能耗、延迟和准确性的影响。使用CRAG数据集进行了9种配置、超过200小时的试验。

Result: 提高相似度检索阈值、减小嵌入尺寸、应用向量索引和使用BM25S重排序等技术可显著降低能耗（某些情况下达60%）。但索引策略等技术可能导致准确性下降达30%。最优检索阈值和减小嵌入尺寸能在不损失准确性的情况下显著降低能耗和延迟。

Conclusion: 这是首个关于RAG系统节能设计技术的全面实证研究，为开发者和研究人员构建可持续RAG应用提供了指导。某些技术能实现真正的能源效率，而其他技术则需要权衡准确性。

Abstract: The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.
  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.

</details>


### [12] [PerspectiveCoach: Exploring LLMs for Developer Reflection](https://arxiv.org/abs/2601.02559)
*Lauren Olson,Emitzá Guzmán,Florian Kunneman*

Main category: cs.SE

TL;DR: PerspectiveCoach是一个基于大语言模型的对话工具，通过结构化视角训练帮助开发者反思软件设计对边缘化社区的影响，研究表明该工具能提升自我意识、拓宽视角并改善伦理推理。


<details>
  <summary>Details</summary>
Motivation: 尽管软件开发中的伦理挑战日益受到关注，但从业者仍缺乏结构化工具来批判性地参与边缘化用户的真实体验。需要一种工具来帮助开发者深入反思软件设计决策如何影响边缘化社区。

Method: 开发了PerspectiveCoach，一个基于大语言模型的对话工具，通过结构化视角训练引导开发者。对18名前端开发者（性别平衡）进行了对照研究，使用在线性别骚扰的真实案例。通过定性分析、文本相似性分析和补充的人与人研究来评估工具效果。

Result: 定性分析显示：自我意识增强、视角拓宽、伦理表达更细致。文本相似性分析表明，参与者通过多次尝试提高了重述的准确性，能捕捉用户关注点的表面和语义层面。但人-工具对话的重述基线低于人与人对话。参与者对工具的可用性和相关性评价很高。

Conclusion: 这项工作为基于大语言模型的终端用户视角训练提供了探索性设计，支持批判性伦理自我反思。研究提供了实证见解（如增强适应性、关注多元性），表明此类工具能帮助从业者构建更具包容性和社会响应性的技术。

Abstract: Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.

</details>


### [13] [State of the Quantum Software Engineering Ecosystem](https://arxiv.org/abs/2601.02601)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 使用GPT-5分析量子软件工程生态系统现状，识别学术界和工业界中活跃且有成就的机构与公司


<details>
  <summary>Details</summary>
Motivation: 研究量子软件工程生态系统的当前状态，特别关注学术界和工业界的成就、活动与参与，重点关注该领域成功的创业企业

Method: 采用新颖的研究方法，利用最先进的人工智能技术——大型语言模型（特别是GPT-5），通过ChatGPT工具进行分析，识别在QSE领域活跃且有显著成果的机构和公司

Result: 识别出在量子软件工程领域高度活跃且取得杰出成果的机构和公司，这些成果通过同行评审出版物或在风险资本市场筹集资金得到证明

Conclusion: 展示了利用先进AI技术分析新兴技术生态系统的有效性，为量子软件工程领域的研究和发展提供了重要参考

Abstract: We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.

</details>


### [14] [TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs](https://arxiv.org/abs/2601.02632)
*Alireza Ezaz,Ghazal Khodabandeh,Majid Babaei,Naser Ezzati-Jivan*

Main category: cs.SE

TL;DR: TAAF框架结合时间索引知识图谱和LLM，将原始执行轨迹转化为可操作的洞察，通过自然语言查询分析复杂系统轨迹，在TraceQA-100基准上提升准确率31.2%


<details>
  <summary>Details</summary>
Motivation: 操作系统内核或大型应用（如Chrome、MySQL）的执行轨迹数据量巨大且难以分析。现有工具依赖预定义分析，定制化洞察需要编写易错耗时的领域特定脚本，缺乏灵活的自然语言查询能力。

Method: 提出TAAF框架：1）从轨迹事件构建时间索引知识图谱，捕捉线程、CPU、系统资源等实体关系；2）使用LLM解释查询特定子图，回答自然语言问题，减少人工检查和深度系统专业知识需求。

Result: 在TraceQA-100基准（基于真实内核轨迹的100个问题）上评估，实验涵盖3个LLM和多种时间设置，TAAF将答案准确率提升高达31.2%，在多跳和因果推理任务中表现尤为突出。

Conclusion: TAAF通过结合知识图谱和LLM，为下一代轨迹分析工具奠定基础，显著提升复杂系统轨迹分析的准确性和易用性，同时分析了图谱基础推理的优势和局限性。

Abstract: Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.

</details>


### [15] [Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study](https://arxiv.org/abs/2601.02698)
*Manideep Reddy Chinthareddy*

Main category: cs.SE

TL;DR: 本文提出了一种将OAuth 2.0和OpenID Connect集成到MCP开发者环境中的企业级身份验证架构，解决了AI辅助开发工具在企业环境中的身份管理和访问控制问题。


<details>
  <summary>Details</summary>
Motivation: 企业需要在AI辅助开发工具中确保身份验证、访问控制和治理要求，但现有的Model Context Protocol (MCP)规范仅提供最小授权模型，缺乏企业单点登录(SSO)集成指导。

Method: 提出了一种实用架构，将OAuth 2.0和OpenID Connect集成到MCP环境中，包括：IDE扩展获取和呈现令牌、MCP服务器通过身份提供商验证令牌、使用范围和声明实施最小权限访问。

Result: 使用Visual Studio Code、Python MCP服务器和OIDC兼容身份提供商的原型实现证明了可行性。案例研究评估了身份验证延迟、令牌验证开销、操作考虑因素和AI特定风险。

Conclusion: 该方法为组织采用AI辅助开发工具提供了可部署的模式，同时保持了身份保证和可审计性，解决了企业环境中的安全治理需求。

Abstract: AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.

</details>


### [16] [Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices](https://arxiv.org/abs/2601.02732)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Mengxi Jia,Ying Li*

Main category: cs.SE

TL;DR: AMER-RCL是一个用于微服务根因定位的智能体记忆增强递归推理框架，通过递归推理和多智能体协作，结合跨警报知识复用，显著提升了定位准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）浅层、症状中心的推理导致准确性不足；2）缺乏跨警报复用导致冗余推理和高延迟。通过研究SRE专家的根因分析过程，发现其具有递归性、多维扩展和跨模态推理三个关键特征，这启发了新框架的设计。

Method: 提出AMER-RCL框架，包含两个核心组件：1）递归推理RCL引擎：多智能体框架，对每个警报执行递归推理，逐步细化候选原因；2）智能体记忆：在时间窗口内增量积累和复用先前警报的推理结果，减少冗余探索并降低推理延迟。

Result: 实验结果表明，AMER-RCL在定位准确性和推理效率方面均优于现有最先进方法，能够更有效地处理复杂的微服务系统故障。

Conclusion: AMER-RCL通过模拟专家级递归推理和跨警报知识复用，解决了现有LLM方法在微服务根因定位中的局限性，为复杂系统的可靠性保障提供了更有效的解决方案。

Abstract: As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.

</details>


### [17] [Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism](https://arxiv.org/abs/2601.02736)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Pei Xiao,Ying Li*

Main category: cs.SE

TL;DR: SpecRCA：基于推测推理的微服务根因分析框架，采用"假设-验证"范式，通过假设草稿模块快速生成候选根因，并行验证器高效验证，在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微服务系统已成为云原生企业应用的支柱，但其内在复杂性和动态运行时交互不可避免地导致异常。确保系统可靠性依赖于有效的根因分析，需要及时、可解释地定位异常源并描述底层故障。现有基于大语言模型的方法存在两个关键限制：(a) 探索多样性有限，影响准确性；(b) 严重依赖大规模LLM，导致推理速度慢。

Method: 提出SpecRCA框架，采用"假设-验证"范式：1) 假设草稿模块快速生成候选根因；2) 并行根因验证器高效验证候选根因。

Result: 在AIOps 2022数据集上的初步实验表明，SpecRCA在准确性和效率方面优于现有方法。

Conclusion: SpecRCA展示了作为复杂微服务环境中可扩展、可解释根因分析实用解决方案的潜力，解决了现有LLM-based方法的探索多样性有限和推理速度慢的问题。

Abstract: Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.

</details>


### [18] [CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation](https://arxiv.org/abs/2601.02868)
*Peiding Wang,Li Zhang,Fang Liu,Chongyang Tao,Yinghao Zhu*

Main category: cs.SE

TL;DR: CodeMEM：基于AST的动态内存管理系统，用于仓库级迭代代码生成，通过AST引导的LLM操作维护仓库上下文，减少遗忘并提升指令遵循能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM在仓库级代码生成中存在两个主要问题：1）随着交互进行，仓库上下文需要持续保存和更新；2）扩大的会话历史增加认知负担，导致遗忘和已解决错误的重新引入。现有基于自然语言的内存管理方法存在局限性。

Method: 提出CodeMEM系统，包含两个核心组件：1）Code Context Memory：通过AST引导的LLM操作动态维护和更新仓库上下文；2）Code Session Memory：构建以代码为中心的交互历史表示，通过AST分析显式检测和缓解遗忘问题。

Result: 在CodeIF-Bench和CoderEval基准测试中达到最先进性能：指令遵循能力提升12.2%（当前轮次）和11.5%（会话级），交互轮次减少2-3轮，同时保持有竞争力的推理延迟和token效率。

Conclusion: CodeMEM通过AST引导的动态内存管理有效解决了仓库级代码生成中的上下文维护和遗忘问题，显著提升了LLM在迭代代码生成中的性能表现。

Abstract: Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.

</details>


### [19] [Few-shot learning for security bug report identification](https://arxiv.org/abs/2601.02971)
*Muhammad Laiq*

Main category: cs.SE

TL;DR: 提出基于SetFit的小样本学习方法，用于在标注数据稀缺的情况下有效识别安全漏洞报告，相比传统机器学习方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 安全漏洞报告需要及时识别以降低软件系统风险，但传统机器学习方法依赖大量标注数据，而实际中安全漏洞报告数据集通常稀缺，导致模型性能不佳且实际应用受限。

Method: 采用SetFit这一先进的小样本学习框架，结合句子转换器和对比学习，通过参数高效微调，在少量标注的漏洞报告数据集上进行训练。

Result: 该方法在评估的所有数据集上均优于传统机器学习基线方法，最佳AUC达到0.865，显示出有效识别安全漏洞报告的潜力。

Conclusion: 基于SetFit的小样本学习为识别安全漏洞报告提供了有前景的替代方案，能够在标注数据稀缺的情况下高效开发模型，最小化标注工作量。

Abstract: Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.

</details>


### [20] [A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis](https://arxiv.org/abs/2601.03009)
*Nek Dil Khan,Javed Ali Khan,Darvesh Khan,Jianqiang Li,Mumrez Khan,Shah Fahad Khan*

Main category: cs.SE

TL;DR: 该研究创建了一个来自亚马逊软件商店64个低评分应用的79,821条用户评论数据集，其中6,000条被手动标注为六大问题类别，为基于机器学习的用户反馈自动分类提供资源。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注高评分应用，而低评分应用虽然能揭示有价值的改进见解，却常被忽视。用户反馈对软件演进至关重要，特别是识别影响用户体验的问题。

Method: 从亚马逊软件商店收集64个低评分应用的79,821条用户评论，并手动标注其中6,000条评论，将其分类为六大问题类别：UI/UX、功能特性、兼容性、性能稳定性、客户支持、安全隐私。

Result: 创建了包含原始数据和标注数据的公开数据集，为研究人员和开发者提供了分析低评分应用常见问题的工具，支持机器学习方法自动分类用户反馈。

Conclusion: 该数据集为基于用户反馈改进软件质量的数据驱动解决方案奠定了基础，帮助理解低评分原因，并为软件演进相关研究（如缺失功能、讽刺、情感分析）提供机会。

Abstract: In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.

</details>


### [21] [NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments](https://arxiv.org/abs/2601.03251)
*Xue Qin,Matthew DiGiovanni*

Main category: cs.SE

TL;DR: NavAI是一个基于大语言模型的通用VR导航框架，支持跨不同VR应用的基本动作和复杂目标导向任务，在目标导向任务中达到89%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有导航技术主要针对360度图像数据集和3D模拟器进行路径优化，无法直接应用于沉浸式VR环境，需要开发适用于VR的通用导航框架。

Method: 提出NavAI框架，基于大语言模型（LLM）构建，支持跨不同VR应用的基本动作和复杂目标导向任务，在三个不同的VR环境中进行评估。

Result: NavAI在目标导向任务中达到89%的成功率，表现出高准确性。分析揭示了完全依赖LLM的局限性，特别是在需要动态目标评估的场景中。

Conclusion: NavAI展示了LLM在VR导航中的潜力，但完全依赖LLM存在局限性，特别是在动态目标评估方面。论文讨论了实验中的限制，并为未来研究方向提供了见解。

Abstract: Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [22] [Proceedings 16th International Workshop on Graph Computation Models](https://arxiv.org/abs/2601.03249)
*Leen Lambers,Oszkár Semeráth*

Main category: cs.LO

TL;DR: GCM 2025是第十六届国际图计算模型研讨会的后论文集，聚焦于图作为计算模型核心的研究与应用


<details>
  <summary>Details</summary>
Motivation: 图作为直观的数学结构，在科学、工程、计算机科学、生物学和业务流程建模等领域具有天然的系统建模优势。图计算模型作为高级模型，将图作为一等公民，需要促进不同研究社区之间的交流与合作。

Method: 通过国际研讨会形式，汇集对基于图和图变换的计算模型各方面感兴趣的研究人员，促进资深和年轻研究者之间的思想交流与经验分享。

Result: 成功举办了第十六届GCM研讨会，作为STAF（软件技术：应用与基础）的一部分，并出版了后论文集。

Conclusion: GCM研讨会系列持续推动图计算模型在理论基础、应用实现和相关领域的发展，促进了跨社区的知识交流与创新。

Abstract: This volume contains the post-proceedings of the Sixteenth International Workshop on Graph Computation Models (GCM 2025). The workshops took place in Koblenz, Germany on June 10 as part of STAF (Software Technologies: Applications and Foundations).  
  Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modeling in science, engineering, and beyond, including computer science, biology, and business process modeling. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.

</details>


### [23] [Bounded Rewriting Induction for LCSTRSs](https://arxiv.org/abs/2601.02803)
*Kasper Hagens,Cynthia Kop*

Main category: cs.LO

TL;DR: 本文提出Bounded RI方法，通过最小化终止要求来改进基于LCSTRS的改写归纳法，增强程序验证能力。


<details>
  <summary>Details</summary>
Motivation: 传统的改写归纳法(RI)在程序验证中面临严格的终止要求限制，所有归纳假设必须在良基序中可定向，这严重限制了RI的证明能力，需要一种方法来最小化这些终止要求。

Method: 提出Bounded RI方法，这是针对逻辑约束简单类型项重写系统(LCSTRSs)的RI改进版本，通过最小化终止要求来增强证明能力。

Result: Bounded RI减少了传统RI中的严格终止要求，从而扩展了程序验证的证明能力，使改写归纳法在实际应用中更加实用。

Conclusion: Bounded RI通过最小化终止要求，显著提升了基于LCSTRS的改写归纳法在程序验证中的实用性和证明能力。

Abstract: Rewriting Induction (RI) is a method to prove inductive theorems, originating from equational reasoning. By using Logically Constrained Simply-typed Term Rewriting Systems (LCSTRSs) as an intermediate language, rewriting induction becomes a tool for program verification, with inductive theorems taking the role of equivalence predicates. Soundness of RI depends on well-founded induction, and one of the core obstacles for obtaining a practically useful proof system is to find suitable well-founded orderings automatically. Using naive approaches, all induction hypotheses must be oriented within the well-founded ordering, which leads to very strong termination requirements. This, in turn, severely limits the proof capacity of RI. Here, we introduce Bounded RI: an adaption of RI for LCSTRSs where such termination requirements are minimized.

</details>


### [24] [Recursive querying of neural networks via weighted structures](https://arxiv.org/abs/2601.03201)
*Martin Grohe,Christoph Standke,Juno Steegmans,Jan Van den Bussche*

Main category: cs.LO

TL;DR: 本文研究用于加权结构（如神经网络）的逻辑查询语言，提出基于函数不动点的逻辑机制，分析其计算复杂性和表达能力。


<details>
  <summary>Details</summary>
Motivation: 动机在于为机器学习模型（特别是前馈神经网络）提供表达性查询语言，将模型视为有意图的数据，通过声明式语言实现模型的验证和解释，使学习到的数据表示更易于访问。

Method: 采用Grädel和Gurevich提出的函数不动点机制，使用类似Datalog的语法，扩展加权结构的不动点逻辑范式，提出"松散"不动点机制允许覆盖归纳定义的权重函数值，并引入"标量"限制的功能不动点逻辑。

Result: 证明了标量限制的功能不动点逻辑具有多项式时间数据复杂度，能够表达所有PTIME模型无关查询（在权重多项式有界的简化网络上）。同时发现非常简单的模型无关查询已经是NP完全问题。

Conclusion: 通过加权结构的迭代转换考虑结构变换，为神经网络等机器学习模型提供了有效的逻辑查询框架，平衡了表达能力和计算复杂度。

Abstract: Expressive querying of machine learning models - viewed as a form of intentional data - enables their verification and interpretation using declarative languages, thereby making learned representations of data more accessible. Motivated by the querying of feedforward neural networks, we investigate logics for weighted structures. In the absence of a bound on neural network depth, such logics must incorporate recursion; thereto we revisit the functional fixpoint mechanism proposed by Grädel and Gurevich. We adopt it in a Datalog-like syntax; we extend normal forms for fixpoint logics to weighted structures; and show an equivalent "loose" fixpoint mechanism that allows values of inductively defined weight functions to be overwritten. We propose a "scalar" restriction of functional fixpoint logic, of polynomial-time data complexity, and show it can express all PTIME model-agnostic queries over reduced networks with polynomially bounded weights. In contrast, we show that very simple model-agnostic queries are already NP-complete. Finally, we consider transformations of weighted structures by iterated transductions.

</details>
