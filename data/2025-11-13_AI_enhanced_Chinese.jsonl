{"id": "2511.09073", "categories": ["cs.FL", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.09073", "abs": "https://arxiv.org/abs/2511.09073", "authors": ["Christoph Weinhuber", "Giuseppe De Giacomo", "Yong Li", "Sven Schewe", "Qiyi Tang"], "title": "Good-for-MDP State Reduction for Stochastic LTL Planning", "comment": "16 pages including appendices, accepted to AAAI 2026", "summary": "We study stochastic planning problems in Markov Decision Processes (MDPs) with goals specified in Linear Temporal Logic (LTL). The state-of-the-art approach transforms LTL formulas into good-for-MDP (GFM) automata, which feature a restricted form of nondeterminism. These automata are then composed with the MDP, allowing the agent to resolve the nondeterminism during policy synthesis. A major factor affecting the scalability of this approach is the size of the generated automata. In this paper, we propose a novel GFM state-space reduction technique that significantly reduces the number of automata states. Our method employs a sophisticated chain of transformations, leveraging recent advances in good-for-games minimisation developed for adversarial settings. In addition to our theoretical contributions, we present empirical results demonstrating the practical effectiveness of our state-reduction technique. Furthermore, we introduce a direct construction method for formulas of the form $\\mathsf{G}\\mathsf{F}\\varphi$, where $\\varphi$ is a co-safety formula. This construction is provably single-exponential in the worst case, in contrast to the general doubly-exponential complexity. Our experiments confirm the scalability advantages of this specialised construction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GFM\u81ea\u52a8\u673a\u72b6\u6001\u7a7a\u95f4\u7f29\u51cf\u6280\u672f\uff0c\u663e\u8457\u51cf\u5c11\u81ea\u52a8\u673a\u72b6\u6001\u6570\u91cf\uff0c\u5e76\u9488\u5bf9\u7279\u5b9a\u5f62\u5f0f\u7684LTL\u516c\u5f0f\u63d0\u4f9b\u4e86\u76f4\u63a5\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06LTL\u516c\u5f0f\u8f6c\u6362\u4e3aGFM\u81ea\u52a8\u673a\uff0c\u4f46\u81ea\u52a8\u673a\u89c4\u6a21\u662f\u5f71\u54cd\u53ef\u6269\u5c55\u6027\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u9700\u8981\u51cf\u5c11\u72b6\u6001\u6570\u91cf\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u91c7\u7528\u590d\u6742\u7684\u8f6c\u6362\u94fe\uff0c\u5229\u7528\u5bf9\u6297\u73af\u5883\u4e2dgood-for-games\u6700\u5c0f\u5316\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u9488\u5bf9G F \u03c6\u5f62\u5f0f\u7684\u516c\u5f0f\u63d0\u4f9b\u76f4\u63a5\u6784\u9020\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u72b6\u6001\u7f29\u51cf\u6280\u672f\u5177\u6709\u5b9e\u9645\u6709\u6548\u6027\uff0c\u4e13\u95e8\u6784\u9020\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u72b6\u6001\u7f29\u51cf\u6280\u672f\u548c\u4e13\u95e8\u6784\u9020\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u57fa\u4e8eLTL\u7684MDP\u89c4\u5212\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.09174", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09174", "abs": "https://arxiv.org/abs/2511.09174", "authors": ["V\u00e1clav K\u016fla", "Qipeng Kuang", "Yuyi Wang", "Yuanhong Wang", "Ond\u0159ej Ku\u017eelka"], "title": "Tractable Weighted First-Order Model Counting with Bounded Treewidth Binary Evidence", "comment": "To be published in AAAI 2026", "summary": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. Conditioning WFOMC on evidence -- fixing the truth values of a set of ground literals -- has been shown impossible in time polynomial in the domain size (unless $\\mathsf{\\#P \\subseteq FP}$) even for fragments of logic that are otherwise tractable for WFOMC without evidence. In this work, we address the barrier by restricting the binary evidence to the case where the underlying Gaifman graph has bounded treewidth. We present a polynomial-time algorithm in the domain size for computing WFOMC for the two-variable fragments $\\text{FO}^2$ and $\\text{C}^2$ conditioned on such binary evidence. Furthermore, we show the applicability of our algorithm in combinatorial problems by solving the stable seating arrangement problem on bounded-treewidth graphs of bounded degree, which was an open problem. We also conducted experiments to show the scalability of our algorithm compared to the existing model counting solvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u9886\u57df\u5927\u5c0f\u4e0a\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97\u4e24\u53d8\u91cf\u903b\u8f91\u7247\u6bb5\uff08FO\u00b2\u548cC\u00b2\uff09\u5728\u4e8c\u5143\u8bc1\u636e\u6761\u4ef6\u4e0b\u7684\u52a0\u6743\u4e00\u9636\u6a21\u578b\u8ba1\u6570\uff08WFOMC\uff09\u7b97\u6cd5\uff0c\u8981\u6c42\u8bc1\u636e\u7684Gaifman\u56fe\u5177\u6709\u6709\u754c\u6811\u5bbd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5bf9\u4e8e\u539f\u672c\u5728\u65e0\u8bc1\u636e\u60c5\u51b5\u4e0b\u53ef\u5904\u7406\u7684\u903b\u8f91\u7247\u6bb5\uff0c\u5728\u8bc1\u636e\u6761\u4ef6\u4e0b\u8ba1\u7b97WFOMC\u5728\u9886\u57df\u5927\u5c0f\u4e0a\u4e5f\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u4e0d\u53ef\u884c\u7684\uff08\u9664\u975e#P \u2286 FP\uff09\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u9650\u5236\u4e8c\u5143\u8bc1\u636e\u7684\u56fe\u7ed3\u6784\u6765\u7a81\u7834\u8fd9\u4e00\u969c\u788d\u3002", "method": "\u901a\u8fc7\u9650\u5236\u4e8c\u5143\u8bc1\u636e\u7684Gaifman\u56fe\u5177\u6709\u6709\u754c\u6811\u5bbd\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97FO\u00b2\u548cC\u00b2\u903b\u8f91\u7247\u6bb5\u5728\u8bc1\u636e\u6761\u4ef6\u4e0b\u7684WFOMC\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u9886\u57df\u5927\u5c0f\u4e0a\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97\u6709\u754c\u6811\u5bbd\u4e8c\u5143\u8bc1\u636e\u6761\u4ef6\u4e0b\u7684WFOMC\uff0c\u5e76\u89e3\u51b3\u4e86\u6709\u754c\u5ea6\u6709\u754c\u6811\u5bbd\u56fe\u4e0a\u7684\u7a33\u5b9a\u5ea7\u4f4d\u5b89\u6392\u95ee\u9898\u8fd9\u4e00\u5f00\u653e\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u76f8\u6bd4\u73b0\u6709\u6a21\u578b\u8ba1\u6570\u6c42\u89e3\u5668\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u901a\u8fc7\u9650\u5236\u8bc1\u636e\u7684\u56fe\u7ed3\u6784\u7279\u6027\uff08\u6709\u754c\u6811\u5bbd\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8bc1\u636e\u6761\u4ef6\u4e0bWFOMC\u7684\u8ba1\u7b97\u590d\u6742\u6027\u969c\u788d\uff0c\u4e3a\u7ec4\u5408\u95ee\u9898\u7684\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.08729", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.08729", "abs": "https://arxiv.org/abs/2511.08729", "authors": ["Sacha-\u00c9lie Ayoun", "Opale Sj\u00f6stedt", "Azalea Raad"], "title": "Soteria: Efficient Symbolic Execution as a Functional Library", "comment": null, "summary": "Symbolic execution (SE) tools often rely on intermediate languages (ILs) to support multiple programming languages, promising reusability and efficiency. In practice, this approach introduces trade-offs between performance, accuracy, and language feature support. We argue that building SE engines \\emph{directly} for each source language is both simpler and more effective. We present Soteria, a lightweight OCaml library for writing SE engines in a functional style, without compromising on performance, accuracy or feature support. Soteria enables developers to construct SE engines that operate directly over source-language semantics, offering \\emph{configurability}, compositional reasoning, and ease of implementation. Using Soteria, we develop Soteria$^{\\text{Rust}}$, the \\emph{first} Rust SE engine supporting Tree Borrows (the intricate aliasing model of Rust), and Soteria$^{\\text{C}}$, a compositional SE engine for C. Both tools are competitive with or outperform state-of-the-art tools such as Kani, Pulse, CBMC and Gillian-C in performance and the number of bugs detected. We formalise the theoretical foundations of Soteria and prove its soundness, demonstrating that sound, efficient, accurate, and expressive SE can be achieved without the compromises of ILs.", "AI": {"tldr": "Soteria\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7OCaml\u5e93\uff0c\u7528\u4e8e\u76f4\u63a5\u4e3a\u6e90\u8bed\u8a00\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff0c\u907f\u514d\u4e86\u4e2d\u95f4\u8bed\u8a00\u7684\u6027\u80fd\u3001\u51c6\u786e\u6027\u548c\u529f\u80fd\u652f\u6301\u65b9\u9762\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7b26\u53f7\u6267\u884c\u5de5\u5177\u4f9d\u8d56\u4e2d\u95f4\u8bed\u8a00\u6765\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u5b58\u5728\u6027\u80fd\u3001\u51c6\u786e\u6027\u548c\u8bed\u8a00\u7279\u6027\u652f\u6301\u4e4b\u95f4\u7684\u6743\u8861\u3002\u4f5c\u8005\u8ba4\u4e3a\u76f4\u63a5\u4e3a\u6bcf\u79cd\u6e90\u8bed\u8a00\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\u66f4\u7b80\u5355\u6709\u6548\u3002", "method": "\u5f00\u53d1Soteria\u5e93\uff0c\u91c7\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\uff0c\u652f\u6301\u76f4\u63a5\u57fa\u4e8e\u6e90\u8bed\u8a00\u8bed\u4e49\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff0c\u63d0\u4f9b\u53ef\u914d\u7f6e\u6027\u3001\u7ec4\u5408\u63a8\u7406\u548c\u6613\u4e8e\u5b9e\u73b0\u7684\u7279\u6027\u3002", "result": "\u4f7f\u7528Soteria\u5f00\u53d1\u4e86Soteria^Rust\uff08\u9996\u4e2a\u652f\u6301Rust Tree Borrows\u522b\u540d\u6a21\u578b\u7684\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff09\u548cSoteria^C\uff08\u7ec4\u5408\u5f0fC\u8bed\u8a00\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff09\uff0c\u5728\u6027\u80fd\u548cbug\u68c0\u6d4b\u6570\u91cf\u4e0a\u4f18\u4e8e\u6216\u4e0eKani\u3001Pulse\u3001CBMC\u548cGillian-C\u7b49\u6700\u5148\u8fdb\u5de5\u5177\u76f8\u5f53\u3002", "conclusion": "\u8bc1\u660e\u4e86\u65e0\u9700\u4e2d\u95f4\u8bed\u8a00\u7684\u59a5\u534f\uff0c\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u6548\u3001\u51c6\u786e\u3001\u8868\u8fbe\u6027\u5f3a\u7684\u7b26\u53f7\u6267\u884c\uff0c\u5e76\u5f62\u5f0f\u5316\u4e86Soteria\u7684\u7406\u8bba\u57fa\u7840\u5e76\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\u3002"}}
{"id": "2511.08607", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.08607", "abs": "https://arxiv.org/abs/2511.08607", "authors": ["Yongxin Zhao", "Shenglin Zhang", "Yujia Wu", "Yuxin Sun", "Yongqian Sun", "Dan Pei", "Chetan Bansal", "Minghua Ma"], "title": "Triage in Software Engineering: A Systematic Review of Research and Practice", "comment": null, "summary": "As modern software systems continue to grow in complexity, triage has become a fundamental process in system operations and maintenance. Triage aims to efficiently prioritize, assign, and assess issues to ensure the reliability of complex environments. The vast amount of heterogeneous data generated by software systems has made effective triage indispensable for maintaining reliability, facilitating maintainability, and enabling rapid issue response. Motivated by these challenges, researchers have devoted extensive effort to advancing triage automation and have achieved significant progress over the past two decades. This survey provides a comprehensive review of 234 papers from 2004 to the present, offering an in-depth examination of the fundamental concepts, system architecture, and problem statement. By comparing the distinct goals of academic and industrial research and by analyzing empirical studies of industrial practices, we identify the major obstacles that limit the practical deployment of triage systems. To assist practitioners in method selection and performance evaluation, we summarize widely adopted open-source datasets and evaluation metrics, providing a unified perspective on the measurement of triage effectiveness. Finally, we outline potential future directions and emerging opportunities to foster a closer integration between academic innovation and industrial application. All reviewed papers and projects are available at https://github.com/AIOps-Lab-NKU/TriageSurvey.", "AI": {"tldr": "\u672c\u6587\u5bf92004\u5e74\u81f3\u4eca\u7684234\u7bc7\u8bba\u6587\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u6df1\u5165\u5206\u6790\u4e86\u8f6f\u4ef6\u7cfb\u7edf\u6545\u969c\u5206\u8bca\u7684\u57fa\u672c\u6982\u5ff5\u3001\u7cfb\u7edf\u67b6\u6784\u548c\u95ee\u9898\u9648\u8ff0\uff0c\u603b\u7ed3\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u6545\u969c\u5206\u8bca\u5df2\u6210\u4e3a\u7cfb\u7edf\u8fd0\u7ef4\u4e2d\u7684\u57fa\u672c\u6d41\u7a0b\u3002\u6d77\u91cf\u5f02\u6784\u6570\u636e\u4f7f\u5f97\u6709\u6548\u7684\u6545\u969c\u5206\u8bca\u5bf9\u4e8e\u7ef4\u62a4\u7cfb\u7edf\u53ef\u9760\u6027\u3001\u4fc3\u8fdb\u53ef\u7ef4\u62a4\u6027\u548c\u5b9e\u73b0\u5feb\u901f\u95ee\u9898\u54cd\u5e94\u53d8\u5f97\u4e0d\u53ef\u6216\u7f3a\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5b66\u672f\u548c\u5de5\u4e1a\u7814\u7a76\u7684\u4e0d\u540c\u76ee\u6807\uff0c\u5206\u6790\u5de5\u4e1a\u5b9e\u8df5\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc6\u522b\u9650\u5236\u6545\u969c\u5206\u8bca\u7cfb\u7edf\u5b9e\u9645\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u5e76\u603b\u7ed3\u5e7f\u6cdb\u91c7\u7528\u7684\u5f00\u6e90\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u63d0\u4f9b\u4e86\u6545\u969c\u5206\u8bca\u9886\u57df\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u8bc6\u522b\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4e3b\u8981\u969c\u788d\uff0c\u5e76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u548c\u6027\u80fd\u8bc4\u4f30\u7684\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u6982\u8ff0\u4e86\u6f5c\u5728\u672a\u6765\u65b9\u5411\u548c\u65b0\u5174\u673a\u9047\uff0c\u4ee5\u4fc3\u8fdb\u5b66\u672f\u521b\u65b0\u4e0e\u5de5\u4e1a\u5e94\u7528\u4e4b\u95f4\u66f4\u7d27\u5bc6\u7684\u6574\u5408\u3002"}}
{"id": "2511.09203", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.09203", "abs": "https://arxiv.org/abs/2511.09203", "authors": ["Robert Atkey", "Roly Perera"], "title": "Galois Slicing as Automatic Differentiation", "comment": null, "summary": "Galois slicing is a technique for program slicing for provenance, developed by Perera and collaborators. Galois slicing aims to explain program executions by demonstrating how to track approximations of the input and output forwards and backwards along a particular execution. In this paper, we explore an analogy between Galois slicing and differentiable programming, seeing the implementation of forwards and backwards slicing as a kind of automatic differentiation. Using the CHAD approach to automatic differentiation due to V\u00e1k\u00e1r and collaborators, we reformulate Galois slicing via a categorical semantics. In doing so, we are able to explore extensions of the Galois slicing idea to quantitative interval analysis, and to clarify the implicit choices made in existing instantiations of this approach.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7c7b\u6bd4Galois\u5207\u7247\u4e0e\u53ef\u5fae\u7f16\u7a0b\uff0c\u4f7f\u7528CHAD\u81ea\u52a8\u5fae\u5206\u65b9\u6cd5\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\uff0c\u63a2\u7d22\u5176\u5728\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u4e2d\u7684\u6269\u5c55\u5e94\u7528\u3002", "motivation": "\u63a2\u7d22Galois\u5207\u7247\u4e0e\u53ef\u5fae\u7f16\u7a0b\u4e4b\u95f4\u7684\u7c7b\u6bd4\u5173\u7cfb\uff0c\u5c06\u524d\u5411\u548c\u540e\u5411\u5207\u7247\u5b9e\u73b0\u89c6\u4e3a\u4e00\u79cd\u81ea\u52a8\u5fae\u5206\uff0c\u4ee5\u6f84\u6e05\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u9690\u5f0f\u9009\u62e9\u3002", "method": "\u4f7f\u7528V\u00e1k\u00e1r\u7b49\u4eba\u7684CHAD\u81ea\u52a8\u5fae\u5206\u65b9\u6cd5\uff0c\u901a\u8fc7\u8303\u7574\u8bed\u4e49\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\u6280\u672f\u3002", "result": "\u6210\u529f\u5c06Galois\u5207\u7247\u91cd\u65b0\u8868\u8ff0\u4e3a\u8303\u7574\u8bed\u4e49\u5f62\u5f0f\uff0c\u5e76\u63a2\u7d22\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u4e2d\u7684\u6269\u5c55\u5e94\u7528\u3002", "conclusion": "\u901a\u8fc7CHAD\u65b9\u6cd5\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\uff0c\u4e0d\u4ec5\u6f84\u6e05\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u9009\u62e9\uff0c\u8fd8\u4e3a\u6269\u5c55\u5230\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.08644", "categories": ["cs.SE", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.08644", "abs": "https://arxiv.org/abs/2511.08644", "authors": ["Punit Kumar", "Asif Imran", "Tevfik Kosar"], "title": "Energy Consumption of Dataframe Libraries for End-to-End Deep Learning Pipelines:A Comparative Analysis", "comment": null, "summary": "This paper presents a detailed comparative analysis of the performance of three major Python data manipulation libraries - Pandas, Polars, and Dask - specifically when embedded within complete deep learning (DL) training and inference pipelines. The research bridges a gap in existing literature by studying how these libraries interact with substantial GPU workloads during critical phases like data loading, preprocessing, and batch feeding. The authors measured key performance indicators including runtime, memory usage, disk usage, and energy consumption (both CPU and GPU) across various machine learning models and datasets.", "AI": {"tldr": "\u5bf9Pandas\u3001Polars\u548cDask\u4e09\u4e2aPython\u6570\u636e\u5904\u7406\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u548c\u63a8\u7406\u6d41\u6c34\u7ebf\u4e2d\u7684\u6027\u80fd\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790", "motivation": "\u586b\u8865\u73b0\u6709\u6587\u732e\u7a7a\u767d\uff0c\u7814\u7a76\u8fd9\u4e9b\u5e93\u5728\u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u6279\u6b21\u9988\u9001\u7b49\u5173\u952e\u9636\u6bb5\u4e0eGPU\u5927\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4ea4\u4e92\u60c5\u51b5", "method": "\u6d4b\u91cf\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u8fd0\u884c\u65f6\u3001\u5185\u5b58\u4f7f\u7528\u3001\u78c1\u76d8\u4f7f\u7528\u548c\u80fd\u8017\uff08CPU\u548cGPU\uff09\u7b49\u5173\u952e\u6027\u80fd\u6307\u6807", "result": "\u63d0\u4f9b\u4e86\u4e09\u4e2a\u5e93\u5728\u6df1\u5ea6\u5b66\u4e60\u6d41\u6c34\u7ebf\u4e2d\u7684\u6027\u80fd\u5bf9\u6bd4\u6570\u636e", "conclusion": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5b9e\u8df5\u4e2d\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u5904\u7406\u5e93\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e"}}
{"id": "2511.09000", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09000", "abs": "https://arxiv.org/abs/2511.09000", "authors": ["Jarin Tasnim", "Debasish Chakroborti", "Chanchal K. Roy", "Kevin A. Schneider"], "title": "An insight into the technical debt-fix trade off in software backporting", "comment": "10 Pages", "summary": "Maintaining software is an ongoing process that stretches beyond the initial release. Stable software versions continuously evolve to fix bugs, add improvements, address security issues, and ensure compatibility. This ongoing support involves Backporting, which means taking a fix or update from a newer version and applying it to an older version of the same software. As software versions evolve, new technical debt can arise during backport maintenance activities. This study examines the technical debt involved in fixing 105,396 commits from 31,076 backport sources across 87 repositories in three software ecosystems (Apache, Eclipse, and Python). The goal is to identify when and why new technical debt arises during backporting in stable source code. Our results indicate that approximately 4.3% of backports introduce new technical debt. Apache contributes the most absolute instances, while Python and Eclipse exhibit nearly three times higher debt-to-commit ratios than Apache. Feature migrations make older Apache releases debt-prone in the early phase, whereas Python and Eclipse releases tend to accumulate technical debt mostly during the middle phase of their release cycles. Additionally, developers who are inexperienced, under high workloads, or non-owners are more likely to introduce technical debt during backporting.", "AI": {"tldr": "\u5206\u6790\u4e86105,396\u4e2a\u63d0\u4ea4\u4e2d\u7684\u6280\u672f\u503a\u52a1\u95ee\u9898\uff0c\u53d1\u73b0\u5728\u56de\u79fb\u690d\u8fc7\u7a0b\u4e2d\u7ea64.3%\u7684\u63d0\u4ea4\u4f1a\u5f15\u5165\u65b0\u7684\u6280\u672f\u503a\u52a1\uff0c\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u548c\u5f00\u53d1\u9636\u6bb5\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u7a33\u5b9a\u8f6f\u4ef6\u7248\u672c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u56de\u79fb\u690d\u6d3b\u52a8\u5f15\u5165\u6280\u672f\u503a\u52a1\u7684\u60c5\u51b5\uff0c\u8bc6\u522b\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u5728\u56de\u79fb\u690d\u8fc7\u7a0b\u4e2d\u4f1a\u4ea7\u751f\u65b0\u7684\u6280\u672f\u503a\u52a1\u3002", "method": "\u5206\u6790\u4e8687\u4e2a\u4ed3\u5e93\u4e2d31,076\u4e2a\u56de\u79fb\u690d\u6e90\u7684105,396\u4e2a\u63d0\u4ea4\uff0c\u6db5\u76d6Apache\u3001Eclipse\u548cPython\u4e09\u4e2a\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u3002", "result": "4.3%\u7684\u56de\u79fb\u690d\u5f15\u5165\u4e86\u65b0\u7684\u6280\u672f\u503a\u52a1\uff1bApache\u8d21\u732e\u4e86\u6700\u591a\u7684\u7edd\u5bf9\u5b9e\u4f8b\uff0c\u800cPython\u548cEclipse\u7684\u503a\u52a1\u63d0\u4ea4\u6bd4\u662fApache\u7684\u8fd1\u4e09\u500d\uff1b\u4e0d\u540c\u751f\u6001\u7cfb\u7edf\u5728\u4e0d\u540c\u53d1\u5e03\u5468\u671f\u9636\u6bb5\u79ef\u7d2f\u6280\u672f\u503a\u52a1\u7684\u6a21\u5f0f\u4e0d\u540c\u3002", "conclusion": "\u56de\u79fb\u690d\u8fc7\u7a0b\u4e2d\u786e\u5b9e\u4f1a\u5f15\u5165\u6280\u672f\u503a\u52a1\uff0c\u5176\u53d1\u751f\u7387\u548c\u6a21\u5f0f\u53d7\u751f\u6001\u7cfb\u7edf\u3001\u53d1\u5e03\u5468\u671f\u9636\u6bb5\u4ee5\u53ca\u5f00\u53d1\u8005\u7ecf\u9a8c\u3001\u5de5\u4f5c\u8d1f\u8377\u548c\u6240\u6709\u6743\u72b6\u6001\u7b49\u56e0\u7d20\u5f71\u54cd\u3002"}}
{"id": "2511.09038", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09038", "abs": "https://arxiv.org/abs/2511.09038", "authors": ["Oussama Jebbar", "Ferhat Khendek", "Maria Toeroe"], "title": "Test Plan Generation for Live Testing of Cloud Services", "comment": null, "summary": "Live testing is performed in the production environment ideally without causing unacceptable disturbance to the production traffic. Thus, test activities have to be orchestrated properly to avoid interferences with the production traffic. A test plan is the road map that specifies how the test activities need to be orchestrated. Developing a test plan includes tasks such as test configuration selection/generation, test configuration deployment planning, creating the test runs schedule, choosing strategies to mitigate the risk of interferences, etc. The manual design of a test plan is tedious and error prone. This task becomes harder especially when the systems are large and complex. In this paper we propose an approach for automating test plans generation. With this approach we aim at reducing service disruption that may be induced by the testing activities in production. We illustrate our approach with a case study and discuss its different aspects.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u5316\u751f\u6210\u6d4b\u8bd5\u8ba1\u5212\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u8bd5\u6d3b\u52a8\u53ef\u80fd\u5f15\u8d77\u7684\u670d\u52a1\u4e2d\u65ad", "motivation": "\u624b\u52a8\u8bbe\u8ba1\u6d4b\u8bd5\u8ba1\u5212\u7e41\u7410\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u590d\u6742\u7cfb\u7edf\u4e2d\u66f4\u4e3a\u56f0\u96be\uff0c\u9700\u8981\u907f\u514d\u6d4b\u8bd5\u6d3b\u52a8\u5bf9\u751f\u4ea7\u6d41\u91cf\u9020\u6210\u4e0d\u53ef\u63a5\u53d7\u7684\u5e72\u6270", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u65b9\u6cd5\uff0c\u5305\u62ec\u6d4b\u8bd5\u914d\u7f6e\u9009\u62e9/\u751f\u6210\u3001\u6d4b\u8bd5\u914d\u7f6e\u90e8\u7f72\u89c4\u5212\u3001\u6d4b\u8bd5\u8fd0\u884c\u8c03\u5ea6\u521b\u5efa\u4ee5\u53ca\u9009\u62e9\u964d\u4f4e\u5e72\u6270\u98ce\u9669\u7684\u7b56\u7565\u7b49", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bf4\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5c55\u793a\u4e86\u5176\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5e94\u7528", "conclusion": "\u81ea\u52a8\u5316\u6d4b\u8bd5\u8ba1\u5212\u751f\u6210\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u8bd5\u6d3b\u52a8\u53ef\u80fd\u5f15\u8d77\u7684\u670d\u52a1\u4e2d\u65ad"}}
{"id": "2511.09122", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09122", "abs": "https://arxiv.org/abs/2511.09122", "authors": ["Joschka Kersting", "Michael Rummel", "Gesa Benndorf"], "title": "Vendor-Aware Industrial Agents: RAG-Enhanced LLMs for Secure On-Premise PLC Code Generation", "comment": null, "summary": "Programmable Logic Controllers are operated by proprietary code dialects; this makes it challenging to train coding assistants. Current LLMs are trained on large code datasets and are capable of writing IEC 61131-3 compatible code out of the box, but they neither know specific function blocks, nor related project code. Moreover, companies like Mitsubishi Electric and their customers do not trust cloud providers. Hence, an own coding agent is the desired solution to cope with this. In this study, we present our work on a low-data domain coding assistant solution for industrial use. We show how we achieved high quality code generation without fine-tuning large models and by fine-tuning small local models for edge device usage. Our tool lets several AI models compete with each other, uses reasoning, corrects bugs automatically and checks code validity by compiling it directly in the chat interface. We support our approach with an extensive evaluation that comes with code compilation statistics and user ratings. We found that a Retrieval-Augmented Generation (RAG) supported coding assistant can work in low-data domains by using extensive prompt engineering and directed retrieval.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u5de5\u4e1aPLC\u7f16\u7a0b\u7684\u4f4e\u6570\u636e\u9886\u57df\u7f16\u7801\u52a9\u624b\uff0c\u901a\u8fc7RAG\u3001\u591a\u6a21\u578b\u7ade\u4e89\u548c\u5373\u65f6\u7f16\u8bd1\u9a8c\u8bc1\uff0c\u5728\u65e0\u9700\u5fae\u8c03\u5927\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4ee3\u7801\u751f\u6210\u3002", "motivation": "PLC\u7f16\u7a0b\u4f7f\u7528\u4e13\u6709\u4ee3\u7801\u65b9\u8a00\uff0c\u96be\u4ee5\u8bad\u7ec3\u7f16\u7801\u52a9\u624b\uff1b\u73b0\u6709LLM\u4e0d\u4e86\u89e3\u7279\u5b9a\u529f\u80fd\u5757\u548c\u9879\u76ee\u4ee3\u7801\uff1b\u5de5\u4e1a\u5ba2\u6237\u4e0d\u4fe1\u4efb\u4e91\u63d0\u4f9b\u5546\uff0c\u9700\u8981\u672c\u5730\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u5de5\u7a0b\u548c\u5b9a\u5411\u68c0\u7d22\uff0c\u8ba9\u591a\u4e2aAI\u6a21\u578b\u7ade\u4e89\uff0c\u81ea\u52a8\u7ea0\u9519\u5e76\u5728\u804a\u5929\u754c\u9762\u4e2d\u76f4\u63a5\u7f16\u8bd1\u9a8c\u8bc1\u4ee3\u7801\u6709\u6548\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8be5\u7f16\u7801\u52a9\u624b\u80fd\u591f\u901a\u8fc7\u7f16\u8bd1\u7edf\u8ba1\u548c\u7528\u6237\u8bc4\u5206\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u5728\u4f4e\u6570\u636e\u9886\u57df\u4e2d\u5b9e\u73b0\u9ad8\u8d28\u91cf\u4ee3\u7801\u751f\u6210\u3002", "conclusion": "RAG\u652f\u6301\u7684\u7f16\u7801\u52a9\u624b\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u5b9a\u5411\u68c0\u7d22\uff0c\u53ef\u4ee5\u5728\u4f4e\u6570\u636e\u5de5\u4e1a\u9886\u57df\u4e2d\u6709\u6548\u5de5\u4f5c\uff0c\u65e0\u9700\u5fae\u8c03\u5927\u578b\u6a21\u578b\u3002"}}
{"id": "2511.09212", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09212", "abs": "https://arxiv.org/abs/2511.09212", "authors": ["Zeru Cheng", "Yanjing Yang", "He Zhang", "Lanxin Yang", "Jinghao Hu", "Jinwei Xu", "Bohan Liu", "Haifeng Shen"], "title": "Leveraging Self-Paced Learning for Software Vulnerability Detection", "comment": null, "summary": "Software vulnerabilities are major risks to software systems. Recently, researchers have proposed many deep learning approaches to detect software vulnerabilities. However, their accuracy is limited in practice. One of the main causes is low-quality training data (i.e., source code). To this end, we propose a new approach: SPLVD (Self-Paced Learning for Software Vulnerability Detection). SPLVD dynamically selects source code for model training based on the stage of training, which simulates the human learning process progressing from easy to hard. SPLVD has a data selector that is specifically designed for the vulnerability detection task, which enables it to prioritize the learning of easy source code. Before each training epoch, SPLVD uses the data selector to recalculate the difficulty of the source code, select new training source code, and update the data selector. When evaluating SPLVD, we first use three benchmark datasets with over 239K source code in which 25K are vulnerable for standard evaluations. Experimental results demonstrate that SPLVD achieves the highest F1 of 89.2%, 68.7%, and 43.5%, respectively, outperforming the state-of-the-art approaches. Then we collect projects from OpenHarmony, a new ecosystem that has not been learned by general LLMs, to evaluate SPLVD further. SPLVD achieves the highest precision of 90.9%, demonstrating its practical effectiveness.", "AI": {"tldr": "SPLVD\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u6b65\u5b66\u4e60\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u8bad\u7ec3\u6570\u636e\u6a21\u62df\u4eba\u7c7b\u4ece\u6613\u5230\u96be\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u51c6\u786e\u7387\u6709\u9650\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bad\u7ec3\u6570\u636e\uff08\u6e90\u4ee3\u7801\uff09\u8d28\u91cf\u4f4e\u3002", "method": "\u63d0\u51faSPLVD\u65b9\u6cd5\uff0c\u5305\u542b\u4e13\u95e8\u4e3a\u6f0f\u6d1e\u68c0\u6d4b\u8bbe\u8ba1\u7684\u6570\u636e\u9009\u62e9\u5668\uff0c\u6839\u636e\u8bad\u7ec3\u9636\u6bb5\u52a8\u6001\u9009\u62e9\u6e90\u4ee3\u7801\uff0c\u4f18\u5148\u5b66\u4e60\u7b80\u5355\u4ee3\u7801\uff0c\u5e76\u5728\u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u524d\u91cd\u65b0\u8ba1\u7b97\u4ee3\u7801\u96be\u5ea6\u5e76\u66f4\u65b0\u9009\u62e9\u5668\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5305\u542b\u8d85\u8fc7239K\u6e90\u4ee3\u7801\uff0c\u5176\u4e2d25K\u6709\u6f0f\u6d1e\uff09\u4e0a\uff0cSPLVD\u5206\u522b\u8fbe\u523089.2%\u300168.7%\u548c43.5%\u7684\u6700\u9ad8F1\u5206\u6570\uff1b\u5728OpenHarmony\u9879\u76ee\u4e0a\u8fbe\u523090.9%\u7684\u6700\u9ad8\u7cbe\u786e\u5ea6\u3002", "conclusion": "SPLVD\u901a\u8fc7\u81ea\u6b65\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.09223", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09223", "abs": "https://arxiv.org/abs/2511.09223", "authors": ["Panya Trakoolgerntong", "Tao Xiao", "Masanari Kondo", "Chaiyong Ragkhitwetsagul", "Morakot Choetkiertikul", "Pattaraporn Sangaroonsilp", "Yasutaka Kamei"], "title": "AILINKPREVIEWER: Enhancing Code Reviews with LLM-Powered Link Previews", "comment": null, "summary": "Code review is a key practice in software engineering, where developers evaluate code changes to ensure quality and maintainability. Links to issues and external resources are often included in Pull Requests (PRs) to provide additional context, yet they are typically discarded in automated tasks such as PR summarization and code review comment generation. This limits the richness of information available to reviewers and increases cognitive load by forcing context-switching. To address this gap, we present AILINKPREVIEWER, a tool that leverages Large Language Models (LLMs) to generate previews of links in PRs using PR metadata, including titles, descriptions, comments, and link body content. We analyzed 50 engineered GitHub repositories and compared three approaches: Contextual LLM summaries, Non-Contextual LLM summaries, and Metadata-based previews. The results in metrics such as BLEU, BERTScore, and compression ratio show that contextual summaries consistently outperform other methods. However, in a user study with seven participants, most preferred non-contextual summaries, suggesting a trade-off between metric performance and perceived usability. These findings demonstrate the potential of LLM-powered link previews to enhance code review efficiency and to provide richer context for developers and automation in software engineering.\n  The video demo is available at https://www.youtube.com/watch?v=h2qH4RtrB3E, and the tool and its source code can be found at https://github.com/c4rtune/AILinkPreviewer.", "AI": {"tldr": "AILINKPREVIEWER\u5de5\u5177\u4f7f\u7528LLM\u751f\u6210PR\u4e2d\u94fe\u63a5\u7684\u9884\u89c8\uff0c\u901a\u8fc7\u7ed3\u5408PR\u5143\u6570\u636e\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u4e2d\u94fe\u63a5\u901a\u5e38\u88ab\u5ffd\u7565\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u4e30\u5bcc\u6027\uff0c\u589e\u52a0\u4e86\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "method": "\u5206\u679050\u4e2aGitHub\u4ed3\u5e93\uff0c\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\uff1a\u4e0a\u4e0b\u6587LLM\u6458\u8981\u3001\u975e\u4e0a\u4e0b\u6587LLM\u6458\u8981\u548c\u57fa\u4e8e\u5143\u6570\u636e\u7684\u9884\u89c8\u3002", "result": "\u4e0a\u4e0b\u6587\u6458\u8981\u5728BLEU\u3001BERTScore\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u7528\u6237\u7814\u7a76\u663e\u793a\u591a\u6570\u53c2\u4e0e\u8005\u66f4\u559c\u6b22\u975e\u4e0a\u4e0b\u6587\u6458\u8981\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u94fe\u63a5\u9884\u89c8\u6709\u6f5c\u529b\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\uff0c\u4f46\u5728\u6307\u6807\u6027\u80fd\u548c\u7528\u6237\u504f\u597d\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002"}}
{"id": "2511.09231", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09231", "abs": "https://arxiv.org/abs/2511.09231", "authors": ["Tobias Eisenreich", "Nicholas Friedlaender", "Stefan Wagner"], "title": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements", "comment": "Accepted at the Intelligent Software Engineering Workshop (ISE 2025) at ASE 2025", "summary": "Use case modeling employs user-centered scenarios to outline system requirements. These help to achieve consensus among relevant stakeholders. Because the manual creation of use case models is demanding and time-consuming, it is often skipped in practice. This study explores the potential of Large Language Models (LLMs) to assist in this tedious process. The proposed method integrates an open-weight LLM to systematically extract actors and use cases from software requirements with advanced prompt engineering techniques. The method is evaluated using an exploratory study conducted with five professional software engineers, which compares traditional manual modeling to the proposed LLM-based approach. The results show a substantial acceleration, reducing the modeling time by 60\\%. At the same time, the model quality remains on par. Besides improving the modeling efficiency, the participants indicated that the method provided valuable guidance in the process.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7528\u4f8b\u5efa\u6a21\uff0c\u901a\u8fc7\u96c6\u6210\u5f00\u6e90LLM\u548c\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u4ece\u8f6f\u4ef6\u9700\u6c42\u4e2d\u63d0\u53d6\u53c2\u4e0e\u8005\u548c\u7528\u4f8b\uff0c\u76f8\u6bd4\u4f20\u7edf\u624b\u52a8\u65b9\u6cd5\u53ef\u51cf\u5c1160%\u5efa\u6a21\u65f6\u95f4\u4e14\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u624b\u52a8\u521b\u5efa\u7528\u4f8b\u6a21\u578b\u8017\u65f6\u8d39\u529b\uff0c\u5b9e\u8df5\u4e2d\u5e38\u88ab\u8df3\u8fc7\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u96c6\u6210\u5f00\u6e90LLM\uff0c\u91c7\u7528\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u4ece\u8f6f\u4ef6\u9700\u6c42\u4e2d\u7cfb\u7edf\u63d0\u53d6\u53c2\u4e0e\u8005\u548c\u7528\u4f8b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5efa\u6a21\u65f6\u95f4\u51cf\u5c1160%\uff0c\u6a21\u578b\u8d28\u91cf\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u53c2\u4e0e\u8005\u8ba4\u4e3a\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002", "conclusion": "LLM\u8f85\u52a9\u7684\u7528\u4f8b\u5efa\u6a21\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\uff0c\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u63d0\u4f9b\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2511.09268", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09268", "abs": "https://arxiv.org/abs/2511.09268", "authors": ["Helio Victor F. Santos", "Vitor Costa", "Joao Eduardo Montandon", "Marco Tulio Valente"], "title": "Decoding the Configuration of AI Coding Agents: Insights from Claude Code Projects", "comment": null, "summary": "Agentic code assistants are a new generation of AI systems capable of performing end-to-end software engineering tasks. While these systems promise unprecedented productivity gains, their behavior and effectiveness depend heavily on configuration files that define architectural constraints, coding practices, and tool usage policies. However, little is known about the structure and content of these configuration artifacts. This paper presents an empirical study of the configuration ecosystem of Claude Code, one of the most widely used agentic coding systems. We collected and analyzed 328 configuration files from public Claude Code projects to identify (i) the software engineering concerns and practices they specify and (ii) how these concerns co-occur within individual files. The results highlight the importance of defining a wide range of concerns and practices in agent configuration files, with particular emphasis on specifying the architecture the agent should follow.", "AI": {"tldr": "\u5bf9Claude Code\u914d\u7f6e\u6587\u4ef6\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86328\u4e2a\u914d\u7f6e\u6587\u4ef6\u7684\u7ed3\u6784\u548c\u5185\u5bb9\uff0c\u91cd\u70b9\u5173\u6ce8\u8f6f\u4ef6\u5de5\u7a0b\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\u89c4\u8303\u3002", "motivation": "\u867d\u7136\u667a\u80fd\u4ee3\u7801\u52a9\u624b\u627f\u8bfa\u5e26\u6765\u524d\u6240\u672a\u6709\u7684\u751f\u4ea7\u529b\u63d0\u5347\uff0c\u4f46\u5176\u884c\u4e3a\u548c\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u4e8e\u5b9a\u4e49\u67b6\u6784\u7ea6\u675f\u3001\u7f16\u7801\u5b9e\u8df5\u548c\u5de5\u5177\u4f7f\u7528\u7b56\u7565\u7684\u914d\u7f6e\u6587\u4ef6\u3002\u7136\u800c\uff0c\u4eba\u4eec\u5bf9\u8fd9\u4e9b\u914d\u7f6e\u5de5\u4ef6\u7684\u7ed3\u6784\u548c\u5185\u5bb9\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e86\u6765\u81ea\u516c\u5171Claude Code\u9879\u76ee\u7684328\u4e2a\u914d\u7f6e\u6587\u4ef6\uff0c\u8bc6\u522b\u4e86(i)\u5b83\u4eec\u6307\u5b9a\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\uff0c\u4ee5\u53ca(ii)\u8fd9\u4e9b\u5173\u6ce8\u70b9\u5728\u5355\u4e2a\u6587\u4ef6\u4e2d\u7684\u5171\u73b0\u60c5\u51b5\u3002", "result": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u667a\u80fd\u4f53\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u5e7f\u6cdb\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u6307\u5b9a\u667a\u80fd\u4f53\u5e94\u9075\u5faa\u7684\u67b6\u6784\u3002", "conclusion": "\u914d\u7f6e\u6587\u4ef6\u4e2d\u9700\u8981\u5b9a\u4e49\u5e7f\u6cdb\u7684\u5173\u6ce8\u70b9\u548c\u5b9e\u8df5\u89c4\u8303\uff0c\u5176\u4e2d\u67b6\u6784\u89c4\u8303\u7684\u6307\u5b9a\u5c24\u4e3a\u91cd\u8981\u3002"}}
{"id": "2511.09373", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09373", "abs": "https://arxiv.org/abs/2511.09373", "authors": ["Adam \u0160torek", "Vikas Upadhyay", "Marianne Menglin Liu", "Daniel W. Peterson", "Anshul Mittal", "Sujeeth Bharadwaj", "Fahad Shah", "Dan Roth"], "title": "Routesplain: Towards Faithful and Intervenable Routing for Software-related Tasks", "comment": null, "summary": "LLMs now tackle a wide range of software-related tasks, yet we show that their performance varies markedly both across and within these tasks. Routing user queries to the appropriate LLMs can therefore help improve response quality while reducing cost. Prior work, however, has focused mainly on general-purpose LLM routing via black-box models. We introduce Routesplain, the first LLM router for software-related tasks, including multilingual code generation and repair, input/output prediction, and computer science QA. Unlike existing routing approaches, Routesplain first extracts human-interpretable concepts from each query (e.g., task, domain, reasoning complexity) and only routes based on these concepts, thereby providing intelligible, faithful rationales. We evaluate Routesplain on 16 state-of-the-art LLMs across eight software-related tasks; Routesplain outperforms individual models both in terms of accuracy and cost, and equals or surpasses all black-box baselines, with concept-level intervention highlighting avenues for further router improvements.", "AI": {"tldr": "Routesplain\u662f\u9996\u4e2a\u9488\u5bf9\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u7684LLM\u8def\u7531\u5668\uff0c\u901a\u8fc7\u63d0\u53d6\u53ef\u89e3\u91ca\u6982\u5ff5\u8fdb\u884c\u8def\u7531\u51b3\u7b56\uff0c\u5728\u51c6\u786e\u6027\u548c\u6210\u672c\u65b9\u9762\u4f18\u4e8e\u5355\u4e2a\u6a21\u578b\uff0c\u5e76\u8fbe\u5230\u6216\u8d85\u8fc7\u6240\u6709\u9ed1\u76d2\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709LLM\u5728\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u4f46\u4e4b\u524d\u7684\u8def\u7531\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u76ee\u7684\u7684\u9ed1\u76d2\u6a21\u578b\u8def\u7531\u3002\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u7684\u667a\u80fd\u8def\u7531\u7cfb\u7edf\u6765\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "Routesplain\u9996\u5148\u4ece\u6bcf\u4e2a\u67e5\u8be2\u4e2d\u63d0\u53d6\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\uff08\u5982\u4efb\u52a1\u7c7b\u578b\u3001\u9886\u57df\u3001\u63a8\u7406\u590d\u6742\u5ea6\uff09\uff0c\u7136\u540e\u4ec5\u57fa\u4e8e\u8fd9\u4e9b\u6982\u5ff5\u8fdb\u884c\u8def\u7531\u51b3\u7b56\uff0c\u63d0\u4f9b\u53ef\u7406\u89e3\u4e14\u53ef\u4fe1\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u572816\u4e2a\u6700\u5148\u8fdb\u7684LLM\u548c8\u4e2a\u8f6f\u4ef6\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cRoutesplain\u5728\u51c6\u786e\u6027\u548c\u6210\u672c\u65b9\u9762\u90fd\u4f18\u4e8e\u5355\u4e2a\u6a21\u578b\uff0c\u5e76\u4e14\u7b49\u4e8e\u6216\u8d85\u8fc7\u4e86\u6240\u6709\u9ed1\u76d2\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Routesplain\u8bc1\u660e\u4e86\u57fa\u4e8e\u6982\u5ff5\u7684\u8def\u7531\u5728\u8f6f\u4ef6\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u6982\u5ff5\u7ea7\u5e72\u9884\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdb\u8def\u7531\u5668\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
