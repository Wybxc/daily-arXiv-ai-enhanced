<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Prebiotic Functional Programs: Endogenous Selection in an Artificial Chemistry](https://arxiv.org/abs/2509.03534)
*Devansh Vimal,Cole Mathis,Westley Weimer,Stephanie Forrest*

Main category: cs.FL

TL;DR: 提出了一种无需外部适应度函数或内置学习机制的方法，用于引导基于无类型lambda演算的AlChemy人工化学模型的动力学，成功合成了Church加法和后继函数等复杂lambda函数


<details>
  <summary>Details</summary>
Motivation: 人工化学模拟虽然能产生有趣的涌现行为，但往往难以引导或控制。本文旨在解决AlChemy模型中的动力学控制问题

Method: 利用AlChemy模型内生的特征，不构建显式的外部适应度函数，也不在动力学中内置学习机制

Result: 成功从简单原语合成了非平凡的lambda函数，包括Church加法和后继函数

Conclusion: 研究结果为自催化化学网络和软件系统等多样化系统中内源性选择的可能性提供了见解

Abstract: Artificial chemistry simulations produce many intriguing emergent behaviors,
but they are often difficult to steer or control. This paper proposes a method
for steering the dynamics of a classic artificial chemistry model, known as
AlChemy (Algorithmic Chemistry), which is based on untyped lambda calculus. Our
approach leverages features that are endogenous to AlChemy without constructing
an explicit external fitness function or building learning into the dynamics.
We demonstrate the approach by synthesizing non-trivial lambda functions, such
as Church addition and succession, from simple primitives. The results provide
insight into the possibility of endogenous selection in diverse systems such as
autocatalytic chemical networks and software systems.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [When Lifetimes Liberate: A Type System for Arenas with Higher-Order Reachability Tracking](https://arxiv.org/abs/2509.04253)
*Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 这篇论文提出了一种新的类型系统，统一了区域系统、所有权类型和可达性类型的优点，支持随意共享的资源池管理和静态证明的词法生命周期控制。


<details>
  <summary>Details</summary>
Motivation: 解决高阶函数语言中静态资源管理的挑战，区域系统、所有权类型和可达性类型都有各自的限制，需要一种统一方案来结合它们的优点。

Method: 在可达性类型基础上提出了两个新扩展：A<:使用二维存储模型支持粗粒度可达性跟踪，{A}<:实现词法生命周期控制。两种计算法都在Rocq中形式化并证明类型安全。

Result: 设计出的类型系统能够同时支持资源池的随意共享和静态证明的词法生命周期，也支持个体资源的非词法生命周期管理，保持了语言的高阶参数性质。

Conclusion: 该工作提供了第一个用于生命周期控制的可达性形式系统，避免了流效感推理的复杂性，同时保持了表达力和简洁性，为高阶函数语言的静态资源管理提供了统一的解决方案。

Abstract: Static resource management in higher-order functional languages remains
elusive due to tensions between control, expressiveness, and flexibility.
Region-based systems [Grossman et al. 2002; Tofte et al. 2001] offer control
over lifetimes and expressive in-region sharing, but restrict resources to
lexical scopes. Rust, an instance of ownership types [Clarke et al. 2013],
offers non-lexical lifetimes and robust safety guarantees, yet its global
invariants make common sharing patterns hard to express. Reachability types
[Wei et al. 2024] enable reasoning about sharing and separation, but lack
practical tools for controlling resource lifetimes.
  In this work, we try to unify their strengths. Our solution enables grouping
resources as arenas for arbitrary sharing and static guarantees of lexically
scoped lifetimes. Crucially, arenas and lexical lifetimes are not the only
choice: users may also manage resources individually, with non-lexical
lifetimes. Regardless of mode, resources share the same type, preserving the
higher-order parametric nature of the language.
  Obtaining static safety guarantee in a higher-order language with flexible
sharing is nontrivial. To this end, we propose two new extensions atop
reachability types [Wei et al. 2024]. First, A<: features a novel
two-dimensional store model to enable coarse-grained reachability tracking for
arbitrarily shared resources within arenas. Building on this, {A}<: establishes
lexical lifetime control with static guarantees. As the first reachability
formalism presented for lifetime control, {A}<: avoids the complication of
flow-sensitive reasoning and retains expressive power and simplicity. Both
calculi are formalized and proven type safe in Rocq.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [3] [A Cegar-centric Bounded Reachability Analysis for Compositional Affine Hybrid Systems](https://arxiv.org/abs/2509.03560)
*Atanu Kundu,Pratyay Sarkar,Rajarshi Ray*

Main category: cs.LO

TL;DR: 提出基于CEGAR的边界可达性分析算法，用于分析具有分段仿射动力学的组合混合系统，避免显式计算乘积自动机，通过抽象反例引导的状态空间细化来提高效率。


<details>
  <summary>Details</summary>
Motivation: 组合混合系统的可达性分析面临独特挑战，需要保持组合语义的同时处理并行乘积自动机中位置数量的爆炸问题。

Method: 使用反例引导抽象细化(CEGAR)原则，在组合模型的离散抽象中搜索反例，通过符号可达性分析进行状态空间细化，采用支持函数作为连续状态表示，并混合不同组合语义以提高效率。

Result: 算法在SAT-Reach工具中实现，展示了可扩展性优势。

Conclusion: 该方法有效解决了组合混合系统可达性分析的计算复杂度问题，通过避免显式乘积计算和优化策略实现了更好的可扩展性。

Abstract: Reachability analysis of compositional hybrid systems, where individual
components are modeled as hybrid automata, poses unique challenges. In addition
to preserving the compositional semantics while computing system behaviors,
algorithms have to cater to the explosion in the number of locations in the
parallel product automaton. In this paper, we propose a bounded reachability
analysis algorithm for compositional hybrid systems with piecewise affine
dynamics, based on the principle of counterexample guided abstraction
refinement (CEGAR). In particular, the algorithm searches for a counterexample
in the discrete abstraction of the composition model, without explicitly
computing a product automaton. When a counterexample is discovered in the
abstraction, its validity is verified by a refinement of the state-space guided
by the abstract counterexample. The state-space refinement is through a
symbolic reachability analysis, particularly using a state-of-the-art algorithm
with support functions as the continuous state representation. In addition, the
algorithm mixes different semantics of composition with the objective of
improved efficiency. Step compositional semantics is followed while exploring
the abstract (discrete) state-space, while shallow compositional semantics is
followed during state-space refinement with symbolic reachability analysis.
Optimizations such as caching the results of the symbolic reachability
analysis, which can be later reused, have been proposed. We implement this
algorithm in the tool SAT-Reach and demonstrate the scalability benefits.

</details>


### [4] [Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on Controllers in Reactive Synthesis](https://arxiv.org/abs/2509.04129)
*Mickael Randour*

Main category: cs.LO

TL;DR: 本文探讨了控制器合成中策略复杂性的最新研究进展，重点关注内存使用和随机性在不同合成环境中的作用。


<details>
  <summary>Details</summary>
Motivation: 在博弈论控制器合成中，简单策略（如有限内存）通常被认为更好，因为对应的控制器更易理解、生产和维护成本更低。本文旨在分析策略复杂性的各个方面。

Method: 通过讨论近期关于内存使用和随机性的研究成果，分析不同合成环境下策略的复杂性特征。

Result: 文章综述了策略复杂性研究的最新进展，包括内存需求和随机性在策略设计中的作用，并探讨了传统复杂性概念之外的新研究方向。

Conclusion: 策略复杂性是控制器合成中的重要考量因素，需要综合考虑内存使用、随机性等维度，未来研究需要超越传统的复杂性概念框架。

Abstract: In the game-theoretic approach to controller synthesis, we model the
interaction between a system to be controlled and its environment as a game
between these entities, and we seek an appropriate (e.g., winning or optimal)
strategy for the system. This strategy then serves as a formal blueprint for a
real-world controller. A common belief is that simple (e.g., using limited
memory) strategies are better: corresponding controllers are easier to conceive
and understand, and cheaper to produce and maintain.
  This invited contribution focuses on the complexity of strategies in a
variety of synthesis contexts. We discuss recent results concerning memory and
randomness, and take a brief look at what lies beyond our traditional notions
of complexity for strategies.

</details>


### [5] [Janus-faces of temporal constraint languages: a dichotomy of expressivity](https://arxiv.org/abs/2509.04347)
*Johanna Brunar,Michael Pinsker,Moritz Schöbi*

Main category: cs.LO

TL;DR: 该论文分析了Bodirsky-Kára时间约束语言分类中的可处理案例，发现这些语言具有有限的表达能力，并证明了它们存在4元伪Siggers多态性，支持Bodirsky-Pinsker猜想的可能性。


<details>
  <summary>Details</summary>
Motivation: Bodirsky-Kára时间约束语言分类是无限域约束满足问题中最早且最重要的复杂性分类之一，但其可处理案例的算法和代数不变量仍然神秘，需要深入研究。

Method: 通过分析时间语言不能pp-构造所有内容的能力限制，测量它们能够pp-解释的图和超图，研究其表达能力的局限性。

Result: 发现这些时间约束语言具有非常有限的表达能力，获得了许多先前未知的代数结果，并为已知的不变性提供了新的统一证明，特别是证明了它们存在4元伪Siggers多态性。

Conclusion: 这些发现支持了Bodirsky-Pinsker猜想的可能性，即伪Siggers多态性的存在可能扩展到更广泛的上下文环境中。

Abstract: The Bodirsky-K\'ara classification of temporal constraint languages stands as
one of the earliest and most seminal complexity classifications within
infinite-domain Constraint Satisfaction Problems (CSPs), yet it remains one of
the most mysterious in terms of algorithms and algebraic invariants for the
tractable cases. We show that those temporal languages which do not
pp-construct EVERYTHING (and thus by the classification are solvable in
polynomial time) have, in fact, very limited expressive power as measured by
the graphs and hypergraphs they can pp-interpret. This limitation yields many
previously unknown algebraic consequences, while also providing new, uniform
proofs for known invariance properties. In particular, we show that such
temporal constraint languages admit $4$-ary pseudo-Siggers polymorphisms -- a
result that sustains the possibility that the existence of such polymorphisms
extends to the much broader context of the Bodirsky-Pinsker conjecture.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 本文通过系统映射研究分析了移动应用需求工程领域的数据集使用状况，发现Google Play和Apple App Store占据了超过90%的研究数据来源，并建议扩大数据源范围以获得更具普遍性的研究结果。


<details>
  <summary>Details</summary>
Motivation: 目前移动应用需求工程研究使用的数据集源平台和需求活动研究范围不明，需要进行系统性评估。

Method: 采用Kitchenham等人的系统映射研究指南，对43篇选定论文进行分析。

Result: 发现Google Play和Apple App Store提供了超过90%的需求工究数据集，最常研究的需求活动是需求获取和需求分析。

Conclusion: 需求工程研究对移动应用的数据集使用从2012年以来增长，但过度依赖主要平台可能导致知识偏差，需要扩大数据源范围和研究其他需求活动。

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [7] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: 基于层次随机森林的自动化APB交易错误诊断框架，在ICCAD 2025竞赛中获得了91.36%的整体准确率和测试阶段第一名


<details>
  <summary>Details</summary>
Motivation: 解决手动检测APB交易错误在大规模VCD文件中效率低下、容易出错的问题

Method: 使用四个预训练的二元分类器构成的层次随机森林架构，逐步检测超出范围访问、地址污染和数据污染错误

Result: 整体准确率91.36%，地址错误检测准确率和召回率接近100%，数据错误检测稳健，在ICCAD 2025竞赛测试阶段获得第一名

Conclusion: 层次机器学习方法在EDA硬件调试中具有强大潜力，能够有效解决手动诊断的效率问题

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [8] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: 开发了首个算法来追踪解析树节点随时间变化，用于分析学生编程过程中的代码结构演变，发现了新的编程行为统计模式。


<details>
  <summary>Details</summary>
Motivation: 传统方法只能使用高级描述性统计来分析编程过程数据，无法自动追踪代码抽象语法树在时间和不可解析状态下的变化，限制了深入理解学生编程行为。

Method: 使用两种新算法追踪解析树节点随时间变化，并为不可解析代码状态构建树表示，应用于2021年CS1课程的学生击键数据进行分析。

Result: 发现了新的可观测统计规律：条件语句和循环内外的代码删除率相似，三分之一的注释代码最终被恢复，代码跳转频率不一定反映学习困难。

Conclusion: 追踪解析树随时间变化的能力为理解学生编程的新维度打开了大门，包括代码结构发展最佳实践、语法结构困难量化、重构行为和代码内注意力转移等。

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [9] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: 这篇论文提出了SECO-TransDX概念模型，从开发者体验角度系统化研究软件生态系统中的透明性问题，识别了63个相关概念并通过專家调查精炼模型。


<details>
  <summary>Details</summary>
Motivation: 虽然透明性被认为对软件生态系统的信任、公平和参与度至关重要，但其与开发者体验的关系仍缺乏系统化理论化。本研究希望从开发者中心视角提升对SECO透明性的理解。

Method: 基于先前研究，通过Delphi研究方法与学术界和业界專家合作，构建了SECO-TransDX概念模型。该模型包含条件因素、生态系统程序、产出物和关系动态等组成部分。

Result: 研究提出了一个包含63个相互关联概念的结构化模型，描述了透明性如何在技术、社会和组织层面中作为开发者体验的中介因素。

Conclusion: SECO-TransDX模型为研究人员提供了未来研究和工具开发的基础，同时为实践者设计更可信赖、以开发者为中心的平台提供支持，通过提高透明性来促进软件生态系统的长期参与。

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [10] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex是一个基于大语言模型推理能力的漏洞相关issue报告识别方法，通过构建漏洞推理数据库和检索相关案例来指导LLM分析目标IR的富文本信息，在数据不平衡情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源软件中存在安全漏洞，开发者提交的issue报告需要安全从业者手动识别漏洞相关报告，耗时且存在时间差可能被攻击者利用。现有方法主要关注文本描述，缺乏对IR富文本信息的综合分析。

Method: VulRTex首先利用LLM的推理能力构建漏洞推理数据库，然后检索相关案例生成推理指导，引导LLM对目标IR的富文本信息进行推理分析来识别漏洞。

Result: 在973,572个IR上的实验显示，VulRTex在数据不平衡情况下表现最佳，比最佳基线F1提高11.0%，AUPRC提高20.2%，Macro-F1提高10.5%，时间成本比基线推理方法低2倍。成功识别2024年GitHub IR中10个代表性OSS项目的30个新兴漏洞，其中11个获得CVE-ID分配。

Conclusion: VulRTex通过利用LLM的推理能力和富文本信息分析，有效识别漏洞相关IR，具有实际应用价值，能够帮助安全从业者更高效地发现和应对软件漏洞。

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [11] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: 首个全面的漏洞影响版本识别实证研究，评估12种工具在1128个真实C/C++漏洞上的表现，发现所有工具准确率不超过45%，集成策略最多提升10.1%但仍低于60%


<details>
  <summary>Details</summary>
Motivation: 现有漏洞影响版本识别工具在真实环境中的有效性不明确，评估范围狭窄且局限于早期SZZ变体、过时技术和小规模数据集

Method: 构建包含1128个真实C/C++漏洞的高质量基准，从追踪和匹配两种范式系统评估12种代表性工具，涵盖漏洞级别和版本级别的有效性、误报误诊根因、对补丁特性的敏感性以及集成潜力四个维度

Result: 发现根本性局限：无工具超过45.0%准确率，主要挑战来自启发式依赖、有限语义推理和僵化匹配逻辑；仅添加和跨文件更改等补丁结构进一步降低性能；集成策略最多提升10.1%但整体准确率仍低于60.0%

Conclusion: 需要从根本上开发新方法，研究为工具开发、组合策略和未来研究提供了可行见解，并公开复现代码和基准以鼓励未来贡献

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [12] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 代码异味之间的相互作用会显著增加模块间的依赖关系，导致维护复杂性和成本上升


<details>
  <summary>Details</summary>
Motivation: 代码异味作为漏洞设计的形式表现，可能通过相互作用增加模块间的依赖关系，这会给系统维护带来难度和成本

Method: 对116个开源Java系统进行依赖分析，量化代码异味之间的相互作用，并与非异味情况进行对比

Result: 代码异味对之间的相互作用导致总依赖关系的增加，例如Feature Envy方法与Data Classes相互作用时依赖数量是单独存在时的7倍

Conclusion: 开发者应优先处理相互作用的代码异味，而非单独存在的异味，以减少模块间的依赖关系和降低维护复杂性

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [13] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: 本文提出了Auth Shim架构模式，通过外部代理服务解决开源软件缺乏企业级身份认证协议支持的问题，实现了OSS工具与企业SSO生态系统的安全集成。


<details>
  <summary>Details</summary>
Motivation: 企业广泛采用开源软件，但许多OSS工具缺乏对SAML、OIDC等企业级身份认证协议的原生支持，导致安全集成缺口，阻碍了开源创新在企业环境中的采用。

Method: 提出Auth Shim轻量级架构模式：作为外部代理服务，在身份提供商和目标应用之间充当兼容层，将IdP请求转换为目标应用的原生会话管理机制。要求目标应用必须提供安全的程序化管理API。

Result: 在Adobe的案例研究中成功实现了将流行OSS BI工具与Okta SAML集成，实现了基于IAM组映射的自动化RBAC，消除了手动用户配置，证明了该模式的有效性。

Conclusion: Auth Shim模式提供了一个可重用、安全且经济高效的蓝图，使企业能够在保持安全治理的同时采用开源创新，解决了OSS工具与企业身份认证生态系统集成的关键问题。

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [14] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: RepoDebug是一个多任务、多语言的仓库级代码调试数据集，包含22种错误子类型、8种编程语言和3种调试任务，用于评估LLM在复杂仓库级调试场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有调试数据集主要关注函数级代码修复，忽略了更复杂和现实的仓库级场景，导致对LLM在仓库级调试中面临的挑战理解不完整。

Method: 构建RepoDebug数据集，包含多任务、多语言和多种错误类型，并在10个大型语言模型上进行评估实验。

Result: 实验结果显示，即使是表现最好的Claude 3.5 Sonnet模型在仓库级调试任务中仍然表现不佳。

Conclusion: 仓库级代码调试对LLM来说仍然是一个具有挑战性的任务，需要更先进的数据集和方法来提升模型在此类复杂场景中的表现。

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [15] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: PyVul是首个全面的Python包漏洞基准测试套件，包含1157个公开报告的开发者验证漏洞，提供提交和函数级别的标注，准确率分别达到100%和94%。评估发现现有检测工具在识别真实世界Python包安全问题上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: Python包作为组织、重用和分发单元存在大量漏洞报告，且Python常与其他语言协作增加了漏洞复杂性，当前漏洞检测工具的有效性尚未充分探索。

Method: 引入PyVul基准套件，包含1157个公开报告的开发者验证漏洞，提供提交和函数级别标注，采用LLM辅助数据清洗方法提高标签准确性。

Result: PyVul达到100%提交级别和94%函数级别准确率，是多语言Python包漏洞的最精确大规模基准。分析发现多语言Python包更容易受到漏洞影响，现有检测工具存在显著能力差距。

Conclusion: PyVul为Python包漏洞检测提供了高质量基准，揭示了当前工具的局限性，强调了该领域未来发展的必要性，特别是针对多语言环境下的漏洞检测。

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [16] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard是一个针对开源无服务器环境的统一DevSecOps管道，通过在开发生命周期的各个阶段嵌入轻量级安全检查，有效检测和防止关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算虽然简化了基础设施管理，但其短暂执行和细粒度可扩展性等特性带来了独特的安全挑战，特别是在OpenFaaS等开源平台中。现有方法通常只关注DevSecOps生命周期的孤立阶段，缺乏集成化的全面安全策略。

Method: 提出FaaSGuard统一DevSecOps管道，在开发生命周期的每个阶段（规划、编码、构建、部署和监控）系统性地嵌入轻量级、故障关闭的安全检查，有效应对注入攻击、硬编码密钥和资源耗尽等威胁。

Result: 通过对来自GitHub公共仓库的20个真实无服务器函数进行案例研究验证，FaaSGuard能够有效检测和防止关键漏洞，表现出高精度（95%）和高召回率（91%），且不会显著干扰现有的CI/CD实践。

Conclusion: FaaSGuard为开源无服务器环境提供了一个有效的集成安全解决方案，通过在DevSecOps全生命周期中嵌入安全检查，成功解决了无服务器计算特有的安全挑战。

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [17] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: 开发了一个基于网络的献血平台，使用PHP(Laravel)、HTML、CSS、Bootstrap和MySQL技术，通过集中式数字空间连接患者、献血者和管理员，提高紧急情况下血液获取效率。


<details>
  <summary>Details</summary>
Motivation: 医疗保健中献血至关重要，但在紧急情况下寻找合适献血者存在重大挑战，需要建立数字化连接平台来解决这一问题。

Method: 采用用例图、数据库图、类图和序列图指导平台设计，使用PHP(Laravel框架)、HTML、CSS、Bootstrap和MySQL技术栈，通过XAMPP和Visual Studio Code开发动态交互式网络平台。

Result: 实现了献血者注册个人信息、患者按血型和位置搜索献血者、系统提供附近可用献血者列表等功能，建立了结构良好的系统架构。

Conclusion: 该平台通过简化献血者注册、血液请求和沟通流程，减少了紧急情况下的延误和复杂性，提高了血液及时可及性和献血服务整体效率。

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>
