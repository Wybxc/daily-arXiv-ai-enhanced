<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 8]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Aspect-Oriented Programming in Secure Software Development: A Case Study of Security Aspects in Web Applications](https://arxiv.org/abs/2509.07449)
*Mterorga Ukor*

Main category: cs.SE

TL;DR: AOP在web应用安全开发中比传统OOP更好地模块化安全关刃，提高了代码质量和可维护性，仅带来最小性能开销。


<details>
  <summary>Details</summary>
Motivation: 传统面向对象编程将安全逻辑与业务功能混在一起，导致代码缀缘化、散布和维护性下降，需要找到更好的安全开发方法。

Method: 采用案例研究法，比较AOP与传统OOP/中间件在认证、授权、输入验证、加密、日志、会话管理等安全功能的实现。通过代码质量指标、性能指标、可维护性评估和开发者反馈进行数据收集分析。

Result: AOP在模块化度、可重用性和可维护性方面显著提升了安全机制，同时仅导致最小的性能开销。

Conclusion: 面向切面编程为web应用开发中平衡安全性与软件质量提供了有效方法，具有重要的实践价值。

Abstract: Security remains a critical challenge in modern web applications, where
threats such as unauthorized access, data breaches, and injection attacks
continue to undermine trust and reliability. Traditional Object-Oriented
Programming (OOP) often intertwines security logic with business functionality,
leading to code tangling, scattering, and reduced maintainability. This study
investigates the role of Aspect-Oriented Programming (AOP) in enhancing secure
software development by modularizing cross-cutting security concerns. Using a
case study approach, we compare AOP-based implementations of security features
including authentication, authorization, input validation, encryption, logging,
and session management with conventional OOP or middleware-based approaches.
Data collection involves analyzing code quality metrics (e.g., lines of code,
coupling, cohesion, modularity index, reusability), performance metrics
(response time, throughput, memory usage), and maintainability indicators.
Developer feedback is also incorporated to assess integration and debugging
experiences. Statistical methods, guided by the ISO/IEC 25010 software quality
model, are applied to evaluate differences across implementations. The findings
demonstrate that AOP enhances modularity, reusability, and maintainability of
security mechanisms, while introducing only minimal performance overhead. The
study contributes practical insights for software engineers and researchers
seeking to balance security with software quality in web application
development.

</details>


### [2] [CRACI: A Cloud-Native Reference Architecture for the Industrial Compute Continuum](https://arxiv.org/abs/2509.07498)
*Hai Dinh-Tuan*

Main category: cs.SE

TL;DR: CRACI是一个云原生工业计算连续体参考架构，解决了传统工业架构在工业4.0中的局限性，通过解耦和事件驱动模型实现灵活的数据流。


<details>
  <summary>Details</summary>
Motivation: 工业4.0中IT和OT的融合暴露了传统分层架构（如ISA-95和RAMI 4.0）的局限性，包括刚性结构、数据孤岛以及缺乏对云原生技术的支持，这些限制了可扩展和互操作工业系统的发展。

Method: 提出CRACI云原生参考架构，采用解耦和事件驱动模型，嵌入信任、治理与策略、可观测性和生命周期管理等横切关注点作为基础支柱。通过理论对比分析和基于实际智能制造实施性能数据的定量评估进行验证。

Result: 结果表明CRACI提供了一个可行的、最先进的架构，能够利用计算连续体克服传统模型的结构限制，实现可扩展的现代工业系统。

Conclusion: CRACI架构成功解决了传统工业架构的局限性，为工业4.0提供了云原生、可扩展的解决方案，通过理论分析和实际数据验证了其有效性。

Abstract: The convergence of Information Technology (IT) and Operational Technology
(OT) in Industry 4.0 exposes the limitations of traditional, hierarchical
architectures like ISA-95 and RAMI 4.0. Their inherent rigidity, data silos,
and lack of support for cloud-native technologies impair the development of
scalable and interoperable industrial systems. This paper addresses this issue
by introducing CRACI, a Cloud-native Reference Architecture for the Industrial
Compute Continuum. Among other features, CRACI promotes a decoupled and
event-driven model to enable flexible, non-hierarchical data flows across the
continuum. It embeds cross-cutting concerns as foundational pillars: Trust,
Governance & Policy, Observability, and Lifecycle Management, ensuring quality
attributes are core to the design. The proposed architecture is validated
through a two-fold approach: (1) a comparative theoretical analysis against
established standards, operational models, and academic proposals; and (2) a
quantitative evaluation based on performance data from previously published
real-world smart manufacturing implementations. The results demonstrate that
CRACI provides a viable, state-of-the-art architecture that utilizes the
compute continuum to overcome the structural limitations of legacy models and
enable scalable, modern industrial systems.

</details>


### [3] [PatchSeeker: Mapping NVD Records to their Vulnerability-fixing Commits with LLM Generated Commits and Embeddings](https://arxiv.org/abs/2509.07540)
*Huu Hung Nguyen,Anh Tuan Nguyen,Thanh Le-Cong,Yikun Li,Han Wei Ang,Yide Yin,Frank Liauw,Shar Lwin Khin,Ouh Eng Lieh,Ting Zhang,David Lo*

Main category: cs.SE

TL;DR: PatchSeeker利用大语言模型自动将NVD漏洞描述与修复提交(VFCs)进行语义匹配，通过生成详细的提交摘要来弥补信息差距，在基准测试中比现有最佳方法性能提升显著


<details>
  <summary>Details</summary>
Motivation: NVD漏洞数据库缺乏与具体修复提交的明确链接，现有方法依赖稀疏且嘈杂的提交消息，无法捕捉漏洞描述的深层语义信息

Method: 使用大语言模型生成NVD描述的嵌入向量，并为简短或无信息的提交消息合成详细摘要，建立漏洞报告与代码变更之间的语义桥梁

Result: 在基准数据集上比最佳基线方法Prospector的MRR提高59.3%，Recall@10提高27.9%，在最新CVE上的扩展评估进一步证实了有效性

Conclusion: 提交消息生成方法和骨干LLM的选择都对PatchSeeker有积极贡献，但仍存在局限性和开放挑战需要未来工作解决

Abstract: Software vulnerabilities pose serious risks to modern software ecosystems.
While the National Vulnerability Database (NVD) is the authoritative source for
cataloging these vulnerabilities, it often lacks explicit links to the
corresponding Vulnerability-Fixing Commits (VFCs). VFCs encode precise code
changes, enabling vulnerability localization, patch analysis, and dataset
construction. Automatically mapping NVD records to their true VFCs is therefore
critical. Existing approaches have limitations as they rely on sparse, often
noisy commit messages and fail to capture the deep semantics in the
vulnerability descriptions. To address this gap, we introduce PatchSeeker, a
novel method that leverages large language models to create rich semantic links
between vulnerability descriptions and their VFCs. PatchSeeker generates
embeddings from NVD descriptions and enhances commit messages by synthesizing
detailed summaries for those that are short or uninformative. These generated
messages act as a semantic bridge, effectively closing the information gap
between natural language reports and low-level code changes. Our approach
PatchSeeker achieves 59.3% higher MRR and 27.9% higher Recall@10 than the
best-performing baseline, Prospector, on the benchmark dataset. The extended
evaluation on recent CVEs further confirms PatchSeeker's effectiveness.
Ablation study shows that both the commit message generation method and the
selection of backbone LLMs make a positive contribution to PatchSeeker. We also
discuss limitations and open challenges to guide future work.

</details>


### [4] [What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring Motivations in Open-Source Projects](https://arxiv.org/abs/2509.07763)
*Mikel Robredo,Matteo Esposito,Fabio Palomba,Rafael Peñaloza,Valentina Lenarduzzi*

Main category: cs.SE

TL;DR: LLMs能有效识别80%的代码重构动机，但与文献动机匹配度仅47%，主要关注可读性和可维护性等实用动机，在架构推理方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 理解开发者重构代码的动机以及哪些指标能够捕捉这些动机，以支持更广泛和有效的重构实践。

Method: 通过大规模实证研究分析开发者重构活动，利用大语言模型从版本控制数据中识别潜在动机，并与文献中报告的动机进行比较。

Result: LLMs在80%的情况下与人工判断一致，但仅与47%的文献动机匹配；丰富了22%的动机细节，主要关注可读性、清晰度和结构改进；大多数动机是实用性的，关注简化和可维护性；开发者经验和代码可读性相关指标排名最高，但与动机类别的相关性较弱。

Conclusion: LLMs能有效捕捉表面层动机但在架构推理方面存在困难，其价值在于提供局部化解释，与软件指标结合可形成混合方法，为更系统地优先处理重构和平衡短期改进与长期架构目标提供有前景的路径。

Abstract: Context. Code refactoring improves software quality without changing external
behavior. Despite its advantages, its benefits are hindered by the considerable
cost of time, resources, and continuous effort it demands. Aim. Understanding
why developers refactor, and which metrics capture these motivations, may
support wider and more effective use of refactoring in practice. Method. We
performed a large-scale empirical study to analyze developers refactoring
activity, leveraging Large Language Models (LLMs) to identify underlying
motivations from version control data, comparing our findings with previous
motivations reported in the literature. Results. LLMs matched human judgment in
80% of cases, but aligned with literature-based motivations in only 47%. They
enriched 22% of motivations with more detailed rationale, often highlighting
readability, clarity, and structural improvements. Most motivations were
pragmatic, focused on simplification and maintainability. While metrics related
to developer experience and code readability ranked highest, their correlation
with motivation categories was weak. Conclusions. We conclude that LLMs
effectively capture surface-level motivations but struggle with architectural
reasoning. Their value lies in providing localized explanations, which, when
combined with software metrics, can form hybrid approaches. Such integration
offers a promising path toward prioritizing refactoring more systematically and
balancing short-term improvements with long-term architectural goals.

</details>


### [5] [Bridging the Gap Between Binary and Source Based Package Management in Spack](https://arxiv.org/abs/2509.07728)
*John Gouwar,Gregory Becker,Tamara Dahlgren,Nathan Hanford,Arjun Guha,Todd Gamblin*

Main category: cs.SE

TL;DR: Spack包管理器通过splicing技术实现二进制兼容性模型，允许混合使用源码和预编译二进制包，解决了HPC环境中二进制包安装快速但配置受限，源码包灵活但编译慢的问题。


<details>
  <summary>Details</summary>
Motivation: 解决二进制包管理器因严格的ABI要求而限制配置灵活性，以及源码包管理器编译速度慢的问题，特别是在HPC环境中安装新MPI实现时需要完全重新构建的痛点。

Method: 提出splicing技术，扩展Spack的打包语言和依赖解析引擎，建立二进制包兼容性模型，允许重用兼容的二进制包同时保持源码构建的灵活性。

Result: 实现了源码和二进制分发的无缝混合，安装时间开销最小，即使对于ABI敏感的依赖（如MPI）也能快速从二进制安装，避免大量重新构建。

Conclusion: splicing技术成功解决了HPC包管理中二进制和源码构建的权衡问题，为Spack提供了高效的二进制兼容性解决方案。

Abstract: Binary package managers install software quickly but they limit
configurability due to rigid ABI requirements that ensure compatibility between
binaries. Source package managers provide flexibility in building software, but
compilation can be slow. For example, installing an HPC code with a new MPI
implementation may result in a full rebuild. Spack, a widely deployed,
HPC-focused package manager, can use source and pre-compiled binaries, but
lacks a binary compatibility model, so it cannot mix binaries not built
together. We present splicing, an extension to Spack that models binary
compatibility between packages and allows seamless mixing of source and binary
distributions. Splicing augments Spack's packaging language and dependency
resolution engine to reuse compatible binaries but maintains the flexibility of
source builds. It incurs minimal installation-time overhead and allows rapid
installation from binaries, even for ABI-sensitive dependencies like MPI that
would otherwise require many rebuilds.

</details>


### [6] [What's Coming Next? Short-Term Simulation of Business Processes from Current State](https://arxiv.org/abs/2509.07747)
*Maksym Avramenko,David Chapela-Campa,Marlon Dumas,Fredrik Milani*

Main category: cs.SE

TL;DR: 这篇论文研究了一种从当前过程状态出发的短期业务流程模拟方法，通过事件日志初始化模拟来提高短期性能预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有业务流程模拟方法主要支持战术性决策，而运营性决策需要基于当前进行中案例的短期性能预测，以分析临时中断的影响。

Method: 提出一种方法，从事件日志中推导当前案例和资源状态来初始化模拟，并在指定时间范围内进行短期模拟预测。

Result: 实验评估显示，该方法比使用热身期的长期模拟更能准确预测短期性能，尤其是在存在概念漏涞或爆发式性能模式时。

Conclusion: 该研究为运营性业务流程模拟提供了一种有效方法，能够更准确地预测短期性能并分析临时干扰的影响。

Abstract: Business process simulation is an approach to evaluate business process
changes prior to implementation. Existing methods in this field primarily
support tactical decision-making, where simulations start from an empty state
and aim to estimate the long-term effects of process changes. A complementary
use-case is operational decision-making, where the goal is to forecast
short-term performance based on ongoing cases and to analyze the impact of
temporary disruptions, such as demand spikes and shortfalls in available
resources. An approach to tackle this use-case is to run a long-term simulation
up to a point where the workload is similar to the current one (warm-up), and
measure performance thereon. However, this approach does not consider the
current state of ongoing cases and resources in the process. This paper studies
an alternative approach that initializes the simulation from a representation
of the current state derived from an event log of ongoing cases. The paper
addresses two challenges in operationalizing this approach: (1) Given a
simulation model, what information is needed so that a simulation run can start
from the current state of cases and resources? (2) How can the current state of
a process be derived from an event log? The resulting short-term simulation
approach is embodied in a simulation engine that takes as input a simulation
model and a log of ongoing cases, and simulates cases for a given time horizon.
An experimental evaluation shows that this approach yields more accurate
short-term performance forecasts than long-term simulations with warm-up
period, particularly in the presence of concept drift or bursty performance
patterns.

</details>


### [7] ["We provide our resources in a dedicated repository": Surveying the Transparency of HICSS publications](https://arxiv.org/abs/2509.07851)
*Irdin Pekaric,Giovanni Apruzzese*

Main category: cs.SE

TL;DR: 研究分析了HICSS论文使用外部仓库的情况，发现仅3%论文有可用的公开仓库


<details>
  <summary>Details</summary>
Motivation: 评估科研论文利用外部仓库提供补充材料的程度，以提高研究透明度和可复现性

Method: 收集2017-2024年HICSS论文集，识别包含人类研究或技术实现的论文，审查文本中是否包含外部仓库链接并检查其内容

Result: 在2028篇论文中，仅3%具有功能正常、公开可用且适合下游研究使用的仓库

Conclusion: 当前科研论文对外部仓库的利用率极低，需要推进研究资源共享以提升透明度和可复现性

Abstract: Every day, new discoveries are made by researchers from all across the globe
and fields. HICSS is a flagship venue to present and discuss such scientific
advances. Yet, the activities carried out for any given research can hardly be
fully contained in a single document of a few pages-the "paper." Indeed, any
given study entails data, artifacts, or other material that is crucial to truly
appreciate the contributions claimed in the corresponding paper. External
repositories (e.g., GitHub) are a convenient tool to store all such resources
so that future work can freely observe and build upon them -- thereby improving
transparency and promoting reproducibility of research as a whole. In this
work, we scrutinize the extent to which papers recently accepted to HICSS
leverage such repositories to provide supplementary material. To this end, we
collect all the 5579 papers included in HICSS proceedings from 2017-2024. Then,
we identify those entailing either human subject research (850) or technical
implementations (737), or both (147). Finally, we review their text, examining
how many include a link to an external repository-and, inspect its contents.
Overall, out of 2028 papers, only 3\% have a functional and publicly available
repository that is usable by downstream research. We release all our tools.

</details>


### [8] [Breaking Android with AI: A Deep Dive into LLM-Powered Exploitation](https://arxiv.org/abs/2509.07933)
*Wanni Vidulige Ishan Perera,Xing Liu,Fan liang,Junyi Zhang*

Main category: cs.SE

TL;DR: 这篇论文研究了使用大语言模型自动化Android洗入测试，通过对比传统手动方法和AI生成的洗入脚本，评估了自动化测试的效果、可靠性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 利用AI和大语言模型的迅速发展，探索在网络安全领域特别是洗入测试自动化中的新机会，以提高安全测试的效率和效果。

Method: 使用Android模拟器(Genymotion)作为测试平台，执行传统手动和AI生成的洗入脚本方法，并通过集成OpenAI API开发自动化脚本生成的网站应用。

Result: 研究发现大语言模型虽然能够显著提高洗入流程效率，但需要人类监管以确保准确性和遵守道德规范，同时也揭示了AI洗入的强势与弱点。

Conclusion: 这项研究为AI驱动的网络安全领域添籭了新的文献，并影响了道德黑客技术、安全研究以及移动设备安全的发展。

Abstract: The rapid evolution of Artificial Intelligence (AI) and Large Language Models
(LLMs) has opened up new opportunities in the area of cybersecurity, especially
in the exploitation automation landscape and penetration testing. This study
explores Android penetration testing automation using LLM-based tools,
especially PentestGPT, to identify and execute rooting techniques. Through a
comparison of the traditional manual rooting process and exploitation methods
produced using AI, this study evaluates the efficacy, reliability, and
scalability of automated penetration testing in achieving high-level privilege
access on Android devices. With the use of an Android emulator (Genymotion) as
the testbed, we fully execute both traditional and exploit-based rooting
methods, automating the process using AI-generated scripts. Secondly, we create
a web application by integrating OpenAI's API to facilitate automated script
generation from LLM-processed responses. The research focuses on the
effectiveness of AI-enabled exploitation by comparing automated and manual
penetration testing protocols, by determining LLM weaknesses and strengths
along the way. We also provide security suggestions of AI-enabled exploitation,
including ethical factors and potential misuse. The findings exhibit that while
LLMs can significantly streamline the workflow of exploitation, they need to be
controlled by humans to ensure accuracy and ethical application. This study
adds to the increasing body of literature on AI-powered cybersecurity and its
effect on ethical hacking, security research, and mobile device security.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Contradictions](https://arxiv.org/abs/2509.07026)
*Yang Xu,Shuwei Chen,Xiaomei Zhong,Jun Liu,Xingxing He*

Main category: cs.LO

TL;DR: 本文提出了一种基于标准矛盾构造的自动定理证明方法，通过系统构建最大三角标准矛盾和三角型标准矛盾，扩展了传统二元归结的局限性，为矛盾分离动态多子句自动推理提供了方法基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统二元归结在自动定理证明中的局限性（每次只能处理两个子句、最多消除两个文字），需要发展更强大的推理系统来提升AI的可信度和推理能力。

Method: 研究两种主要标准矛盾形式的构造方法：最大三角标准矛盾和三角型标准矛盾，并基于这些结构提出通过最大标准矛盾判断子句集可满足性的程序，同时推导了计算标准子矛盾数量的公式。

Result: 建立了标准矛盾构造的系统方法，提供了计算标准子矛盾数量的具体公式，为矛盾分离动态多子句自动推理奠定了方法论基础。

Conclusion: 该方法扩展了自动推理系统的表达和演绎能力，超越了传统的二元归结范式，为构建更透明可靠的AI推理系统提供了重要技术支持。

Abstract: Trustworthy AI requires reasoning systems that are not only powerful but also
transparent and reliable. Automated Theorem Proving (ATP) is central to formal
reasoning, yet classical binary resolution remains limited, as each step
involves only two clauses and eliminates at most two literals. To overcome this
bottleneck, the concept of standard contradiction and the theory of
contradiction-separation-based deduction were introduced in 2018. This paper
advances that framework by focusing on the systematic construction of standard
contradictions. Specially, this study investigates construction methods for two
principal forms of standard contradiction: the maximum triangular standard
contradiction and the triangular-type standard contradiction. Building on these
structures, we propose a procedure for determining the satisfiability and
unsatisfiability of clause sets via maximum standard contradiction.
Furthermore, we derive formulas for computing the number of standard
sub-contradictions embedded within both the maximum triangular standard
contradiction and the triangular-type standard contradiction. The results
presented herein furnish the methodological basis for advancing
contradiction-separation-based dynamic multi-clause automated deduction,
thereby extending the expressive and deductive capabilities of automated
reasoning systems beyond the classical binary paradigm.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [veScale: Consistent and Efficient Tensor Programming with Eager-Mode SPMD](https://arxiv.org/abs/2509.07003)
*Youjie Li,Cheng Wan,Zhiqi Lin,Hongyu Zhu,Jiacheng Yang,Ziang Song,Xinyi Di,Jiawei Wu,Huiyao Shu,Wenlei Bao,Yanghua Peng,Haibin Lin,Li-Wen Chang*

Main category: cs.PL

TL;DR: veScale是一个基于SPMD范式的分布式训练系统，解决了LLM训练中的结果一致性和性能问题，比现有系统快2.2倍，代码复杂度降低78.4%


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和复杂度的快速增长，需要更复杂的并行训练技术（如3D并行），这促使向更简单、更易调试的SPMD编程范式转变。但SPMD在即时执行模式下存在两个关键挑战：确保与单设备执行结果一致性和实现高性能。

Method: veScale引入了与任意分片算子兼容的分布式随机数生成(RNG)算法来解决结果一致性问题，同时通过减少PyTorch原语开销和提升通信效率来显著提高训练性能。

Result: 评估显示veScale比最先进的训练系统（如TorchTitan）快达2.2倍，代码复杂度降低78.4%，同时保持与单设备等效的结果。

Conclusion: veScale成功实现了SPMD范式在分布式张量编程中的民主化，解决了结果一致性和性能扩展的关键挑战，为大规模LLM训练提供了简单高效的解决方案。

Abstract: Large Language Models (LLMs) have scaled rapidly in size and complexity,
requiring increasingly intricate parallelism for distributed training, such as
3D parallelism. This sophistication motivates a shift toward simpler, more
debuggable programming paradigm like Single Program Multiple Data (SPMD).
However, SPMD in eager execution introduces two key challenges: ensuring
consistency with single-device execution and achieving high performance at
scale. In this paper, we introduce veScale, an eager-mode training system that
fully embraces SPMD paradigm to democratize distributed tensor programming.
veScale addresses the prevalent issue of inconsistent results in systems like
PyTorch by introducing a novel algorithm of distributed Random Number
Generation (RNG) compatible with arbitrary sharded operators. veScale also
significantly boosts training performance by reducing PyTorch primitive's
overhead and improving communication efficiency. Evaluations show that veScale
delivers up to 2.2x speedup over the state-of-the-art training systems, like
TorchTitan, and cuts code complexity by 78.4%, while preserving
single-device-equivalent results.

</details>


### [11] [Fast and Extensible Hybrid Embeddings with Micros](https://arxiv.org/abs/2509.07551)
*Sean Bocirnea,William J. Bowman*

Main category: cs.PL

TL;DR: 小型嵌入技术通过语法到中间表示转换器，在编译性能方面显著改善來宏嵌入方案


<details>
  <summary>Details</summary>
Motivation: 宏嵌入技术虽然支持扩展性语言嵌入，但编译时性能成本过高

Method: 采用micros技术（语法到IR转换器），通过深度嵌入生成高效IR，再浅嵌入回源代码，并使用多种设计模式保证IR的扩展性

Result: 实现了可扩展的混合型静态类型语言嵌入，编译时性能显著提升

Conclusion: 小型嵌入技术组合适当的设计模式可以在保持扩展性的同时大幅提升编译性能

Abstract: Macro embedding is a popular approach to defining extensible shallow
embeddings of object languages in Scheme like host languages. While macro
embedding has even been shown to enable implementing extensible typed languages
in systems like Racket, it comes at a cost: compile-time performance. In this
paper, we revisit micros - syntax to intermediate representation (IR)
transformers, rather than source syntax to source syntax transformers (macros).
Micro embedding enables stopping at an IR, producing a deep embedding and
enabling high performance compile-time functions over an efficient IR, before
shallowly embedding the IR back into source syntax. Combining micros with
several design patterns to enable the IR and functions over it to be
extensible, we achieve extensible hybrid embedding of statically typed
languages with significantly improved compile-time compared to macro-embedding
approaches. We describe our design patterns and propose new abstractions
packaging these patterns.

</details>


### [12] [What's in the Box: Ergonomic and Expressive Capture Tracking over Generic Data Structures (Extended Version)](https://arxiv.org/abs/2509.07609)
*Yichen Xu,Oliver Bračevac,Cao Nguyen Pham,Martin Odersky*

Main category: cs.PL

TL;DR: System Capless通过引入reach capabilities机制，解决了Scala捕获类型在泛型数据结构中能力跟踪的局限性，使捕获检查能够扩展到标准集合库，实现了最小化语法开销的生产级应用。


<details>
  <summary>Details</summary>
Motivation: 现有Scala捕获类型系统无法有效跟踪嵌入在泛型数据结构中的能力，限制了其在标准集合库等关键场景的应用，阻碍了更广泛的采用。

Method: 开发System Capless演算，引入reach capabilities机制，通过存在性和通用性捕获集量化来命名"盒子里的内容"，并在Lean中形式化验证元理论。

Result: 在Scala 3中基于System Capless完全重新实现了捕获检查，成功迁移了整个Scala集合库和异步编程库，证明在实践中具有最小改动和几乎零语法开销。

Conclusion: reach capabilities机制使捕获检查能够在生产代码中实用化，解决了表达能力不足的问题，为捕获类型系统的广泛应用奠定了基础。

Abstract: Capturing types in Scala unify static effect and resource tracking with
object capabilities, enabling lightweight effect polymorphism with minimal
notational overhead. However, their expressiveness has been insufficient for
tracking capabilities embedded in generic data structures, preventing them from
scaling to the standard collections library -- an essential prerequisite for
broader adoption. This limitation stems from the inability to name capabilities
within the system's notion of box types.
  This paper develops System Capless, a new foundation for capturing types that
provides the theoretical basis for reach capabilities (rcaps), a novel
mechanism for naming "what's in the box." The calculus refines the universal
capability notion into a new scheme with existential and universal capture set
quantification. Intuitively, rcaps witness existentially quantified capture
sets inside the boxes of generic types in a way that does not require exposing
existential capture types in the surface language. We have fully mechanized the
formal metatheory of System Capless in Lean, including proofs of type soundness
and scope safety. System Capless supports the same lightweight notation of
capturing types plus rcaps, as certified by a type-preserving translation, and
also enables fully optional explicit capture-set quantification to increase
expressiveness.
  Finally, we present a full reimplementation of capture checking in Scala 3
based on System Capless and migrate the entire Scala collections library and an
asynchronous programming library to evaluate its practicality and ergonomics.
Our results demonstrate that reach capabilities enable the adoption of capture
checking in production code with minimal changes and minimal-to-zero notational
overhead in a vast majority of cases.

</details>
