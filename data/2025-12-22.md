<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 14]
- [cs.LO](#cs.LO) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization](https://arxiv.org/abs/2512.16956)
*Shravan Chaudhari,Rahul Thomas Jacob,Mononito Goswami,Jiajun Cao,Shihab Rashid,Christian Bock*

Main category: cs.SE

TL;DR: SpIDER是一种增强的密集检索方法，通过图结构探索和LLM推理来改进代码单元的语义检索性能


<details>
  <summary>Details</summary>
Motivation: 现有代码检索方法（如BM25和密集嵌入）存在局限性：密集嵌入方法虽然性能优于BM25，但缺乏对代码库的充分探索，未能充分利用代码的图结构信息

Method: 提出SpIDER方法，结合图结构探索获取辅助上下文，并使用LLM进行推理，增强密集嵌入检索能力

Result: 实验结果显示SpIDER在多种编程语言上都能持续提升密集检索性能

Conclusion: 通过结合图结构探索和LLM推理，SpIDER能够有效改进代码单元的语义检索，为LLM编码代理提供更好的检索支持

Abstract: Retrieving code units (e.g., files, classes, functions) that are semantically relevant to a given user query, bug report, or feature request from large codebases is a fundamental challenge for LLM-based coding agents. Agentic approaches typically employ sparse retrieval methods like BM25 or dense embedding strategies to identify relevant units. While embedding-based approaches can outperform BM25 by large margins, they often lack exploration of the codebase and underutilize its underlying graph structure. To address this, we propose SpIDER (Spatially Informed Dense Embedding Retrieval), an enhanced dense retrieval approach that incorporates LLM-based reasoning over auxiliary context obtained through graph-based exploration of the codebase. Empirical results show that SpIDER consistently improves dense retrieval performance across several programming languages.

</details>


### [2] [Resilient Microservices: A Systematic Review of Recovery Patterns, Strategies, and Evaluation Frameworks](https://arxiv.org/abs/2512.16959)
*Muzeeb Mohammad*

Main category: cs.SE

TL;DR: 对2014-2025年间微服务恢复策略的实证研究进行PRISMA系统文献综述，识别9个韧性主题，提出恢复模式分类法、韧性评估评分清单和约束感知决策矩阵


<details>
  <summary>Details</summary>
Motivation: 微服务系统容易受到部分故障、级联超时和不一致恢复行为的影响。现有关于韧性和恢复模式的调查大多是描述性的，缺乏系统证据综合或定量严谨性

Method: 采用PRISMA标准的系统文献综述方法，从IEEE Xplore、ACM Digital Library和Scopus数据库中筛选2014-2025年间的实证研究。从412条初始记录中，通过透明的纳入、排除和质量评估标准，最终选择26项高质量研究

Result: 识别出9个重复出现的韧性主题：断路器、抖动和预算重试、带补偿的saga、幂等性、舱壁隔离、自适应背压、可观测性、混沌验证。提出了恢复模式分类法、韧性评估评分清单和约束感知决策矩阵

Conclusion: 将分散的韧性研究整合为结构化、可分析的证据基础，支持可重复评估和知情设计容错且性能感知的微服务系统

Abstract: Microservice based systems underpin modern distributed computing environments but remain vulnerable to partial failures, cascading timeouts, and inconsistent recovery behavior. Although numerous resilience and recovery patterns have been proposed, existing surveys are largely descriptive and lack systematic evidence synthesis or quantitative rigor. This paper presents a PRISMA aligned systematic literature review of empirical studies on microservice recovery strategies published between 2014 and 2025 across IEEE Xplore, ACM Digital Library, and Scopus. From an initial corpus of 412 records, 26 high quality studies were selected using transparent inclusion, exclusion, and quality assessment criteria. The review identifies nine recurring resilience themes encompassing circuit breakers, retries with jitter and budgets, sagas with compensation, idempotency, bulkheads, adaptive backpressure, observability, and chaos validation. As a data oriented contribution, the paper introduces a Recovery Pattern Taxonomy, a Resilience Evaluation Score checklist for standardized benchmarking, and a constraint aware decision matrix mapping latency, consistency, and cost trade offs to appropriate recovery mechanisms. The results consolidate fragmented resilience research into a structured and analyzable evidence base that supports reproducible evaluation and informed design of fault tolerant and performance aware microservice systems.

</details>


### [3] [Sensor Management System (SMS): Open-source software for FAIR sensor metadata management in Earth system sciences](https://arxiv.org/abs/2512.17280)
*Christof Lorenza,Nils Brinckmann,Jan Bumberger,Marc Hanisch,Tobias Kuhnert,Ulrich Loup,Rubankumar Moorthy,Florian Obsersteiner,David Schäfer,Thomas Schnicke*

Main category: cs.SE

TL;DR: 开发了传感器管理系统（SMS），用于建模复杂传感器系统并管理其全生命周期信息，促进环境观测数据的FAIR元数据管理


<details>
  <summary>Details</summary>
Motivation: 环境观测数据需要一致、全面的元数据（包括时间分辨的上下文信息）来得出可靠结论和洞察

Method: 开发用户友好、功能丰富的SMS平台，使用明确定义的术语（设备、平台、配置、站点等）建模传感器系统，记录系统相关行动的连续历史，并链接到后续系统和服务

Result: SMS成为数字生态系统的核心元素，促进传感器相关元数据更一致、可持续和FAIR的提供

Conclusion: SMS通过建立终端用户社区和连接各种系统服务，为环境观测数据提供了关键的元数据管理解决方案

Abstract: Deriving reliable conclusions and insights from environmental observational data urgently requires the enrichment with consistent and comprehensive metadata, including time-resolved context such as changing deployments, configurations, and maintenance actions. We have therefore developed the Sensor Management System (SMS), which provides a user-friendly and feature-rich platform for modeling even the most complex sensor systems and managing all sensor-related information across their life cycle. Each entity is described via well-defined terms like Devices, Platforms and Configurations, as well as Sites that are further enhanced with attributes for, e.g., instrument manufacturers, contact information or measured quantities and complemented by a continuous history of system-related actions. By further linking the SMS to sub-sequent systems and services like PID-registration or controlled vocabularies and establishing a community of end-users, the SMS provides the central element of a digital ecosystem, that fosters a more consistent, sustainable and FAIR provision of sensor-related metadata.

</details>


### [4] [Bridging Natural Language and Formal Specification--Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs](https://arxiv.org/abs/2512.17334)
*Zhi Ma,Cheng Wen,Zhexin Su,Xiao Liang,Cong Tian,Shengchao Qin,Mengfei Yang*

Main category: cs.SE

TL;DR: Req2LTL：一个模块化框架，通过分层中间表示OnionL将自然语言软件需求自动转换为线性时序逻辑（LTL）规范，结合LLM语义分解和确定性规则合成，在航空航天需求上达到88.4%语义准确率和100%句法正确率。


<details>
  <summary>Details</summary>
Motivation: 将自然语言软件需求自动转换为形式化规范是扩展形式化验证到工业环境（特别是安全关键领域）的关键挑战。现有方法（基于规则和基于学习）存在显著局限性，LLM在处理真实工业需求的复杂性、模糊性和逻辑深度方面仍有困难。

Method: 提出Req2LTL框架，通过分层中间表示OnionL桥接自然语言和LTL。利用LLM进行语义分解，结合确定性规则合成，确保句法有效性和语义保真度。

Result: 在真实世界航空航天需求上，Req2LTL达到88.4%语义准确率和100%句法正确率，显著优于现有方法。

Conclusion: Req2LTL通过结合LLM语义能力和规则合成，有效解决了自然语言需求到形式化规范的转换问题，为工业级形式化验证提供了可行方案。

Abstract: Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to industrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT-4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose Req2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. Req2LTL leverages LLMs for semantic decomposition and combines them with deterministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that Req2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, significantly outperforming existing methods.

</details>


### [5] [What You Trust Is Insecure: Demystifying How Developers (Mis)Use Trusted Execution Environments in Practice](https://arxiv.org/abs/2512.17363)
*Yuqing Niu,Jieke Shi,Ruidong Han,Ye Liu,Chengyan Ma,Yunbo Lyu,David Lo*

Main category: cs.SE

TL;DR: 首个大规模TEE应用实证研究：分析241个开源项目，发现物联网安全是主要应用场景（30%），32.4%项目重新实现加密功能，25.3%存在不安全编码行为。


<details>
  <summary>Details</summary>
Motivation: 虽然可信执行环境（TEEs）如Intel SGX和ARM TrustZone被广泛用于保护敏感数据和代码，但开发者实际如何使用这些技术尚不清楚。本研究旨在通过实证分析了解TEE在真实世界应用中的使用情况。

Method: 收集并分析GitHub上241个使用Intel SGX和ARM TrustZone的开源项目。结合人工检查和定制化静态分析脚本，从三个维度进行研究：1）应用领域分类和时间趋势分析；2）TEE集成方式分析；3）安全实践检查。

Result: 主要发现：1）物联网设备安全是主导应用场景（30%），与学术界关注的区块链和密码系统（7%）形成鲜明对比，AI模型保护（12%）正在快速增长；2）32.4%的项目重新实现加密功能而非使用官方SDK API，表明当前SDK可用性和可移植性不足；3）25.3%的项目存在不安全编码行为（如硬编码密钥、缺少输入验证），削弱了安全保证。

Conclusion: 研究揭示了TEE实际应用与学术关注点之间的差距，指出了当前TEE SDK在可用性和可移植性方面的不足，以及开发者安全实践中的问题。这些发现对改进TEE SDK可用性和支持可信软件开发具有重要意义。

Abstract: Trusted Execution Environments (TEEs), such as Intel SGX and ARM TrustZone, provide isolated regions of CPU and memory for secure computation and are increasingly used to protect sensitive data and code across diverse application domains. However, little is known about how developers actually use TEEs in practice. This paper presents the first large-scale empirical study of real-world TEE applications. We collected and analyzed 241 open-source projects from GitHub that utilize the two most widely-adopted TEEs, Intel SGX and ARM TrustZone. By combining manual inspection with customized static analysis scripts, we examined their adoption contexts, usage patterns, and development practices across three phases. First, we categorized the projects into 8 application domains and identified trends in TEE adoption over time. We found that the dominant use case is IoT device security (30%), which contrasts sharply with prior academic focus on blockchain and cryptographic systems (7%), while AI model protection (12%) is rapidly emerging as a growing domain. Second, we analyzed how TEEs are integrated into software and observed that 32.4% of the projects reimplement cryptographic functionalities instead of using official SDK APIs, suggesting that current SDKs may have limited usability and portability to meet developers' practical needs. Third, we examined security practices through manual inspection and found that 25.3% (61 of 241) of the projects exhibit insecure coding behaviors when using TEEs, such as hardcoded secrets and missing input validation, which undermine their intended security guarantees. Our findings have important implications for improving the usability of TEE SDKs and supporting developers in trusted software development.

</details>


### [6] [GraphCue for SDN Configuration Code Synthesis](https://arxiv.org/abs/2512.17371)
*Haomin Qi,Fengfei Yu,Chengbo Huang*

Main category: cs.SE

TL;DR: GraphCue：基于拓扑感知检索和智能体循环的SDN自动配置框架，通过图神经网络嵌入和结构化提示实现高效配置生成与验证


<details>
  <summary>Details</summary>
Motivation: 解决软件定义网络（SDN）配置自动化问题，传统方法难以处理复杂的网络拓扑和配置约束，需要更智能的自动化配置解决方案

Method: 1. 将配置案例抽象为JSON图结构；2. 使用三层轻量级图卷积网络（GCN）进行图嵌入；3. 基于对比学习训练；4. 检索最近已验证参考配置；5. 结构化提示约束代码生成；6. 验证器执行候选配置并反馈失败信息给智能体

Result: 在628个验证案例上，GraphCue在20次迭代内达到88.2%通过率，95%的验证循环在9秒内完成。消融实验表明，缺少检索或结构化提示会显著降低性能

Conclusion: 拓扑感知检索和约束条件提示是GraphCue性能的关键驱动因素，该框架为SDN配置自动化提供了有效的解决方案

Abstract: We present GraphCue, a topology-grounded retrieval and agent-in-the-loop framework for automated SDN configuration. Each case is abstracted into a JSON graph and embedded using a lightweight three-layer GCN trained with contrastive learning. The nearest validated reference is injected into a structured prompt that constrains code generation, while a verifier closes the loop by executing the candidate configuration and feeding failures back to the agent. On 628 validation cases, GraphCue achieves an 88.2 percent pass rate within 20 iterations and completes 95 percent of verification loops within 9 seconds. Ablation studies without retrieval or structured prompting perform substantially worse, indicating that topology-aware retrieval and constraint-based conditioning are key drivers of performance.

</details>


### [7] [CIFE: Code Instruction-Following Evaluation](https://arxiv.org/abs/2512.17387)
*Sravani Gunnu,Shanmukha Guttula,Hima Patel*

Main category: cs.SE

TL;DR: 论文提出了一个包含1000个Python任务的基准测试，每个任务平均有7个开发者指定的约束条件，用于评估LLM在代码生成中遵循约束的能力，而不仅仅是功能性正确。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要通过测试用例执行评估代码正确性，但实际部署中开发者还要求代码满足鲁棒性、格式化和安全性等约束条件，现有方法无法可靠评估模型遵循这些约束的能力。

Method: 通过四阶段人机协作流程创建包含13个类别约束的基准测试，评估14个开源和闭源模型，提出C2A分数作为综合衡量正确性和约束遵循的指标。

Result: 结果显示部分遵循和严格遵循之间存在显著差距：强模型部分遵循率超过90%，但严格遵循率仅为39-66%，表明仅追求正确性不足以实现可信的代码生成。

Conclusion: 可信的代码生成不仅需要功能性正确，还需要一致地遵循开发者意图，现有模型在严格遵循约束方面仍有很大改进空间。

Abstract: Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.

</details>


### [8] [SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories](https://arxiv.org/abs/2512.17419)
*Lilin Wang,Lucas Ramalho,Alan Celestino,Phuc Anthony Pham,Yu Liu,Umang Kumar Sinha,Andres Portillo,Onassis Osunwa,Gabriel Maduekwe*

Main category: cs.SE

TL;DR: SWE-Bench++是一个自动化框架，从GitHub拉取请求生成仓库级编程任务，支持11种语言，包含11,133个实例，用于评估和改进大语言模型的仓库级代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准如SWE-bench存在局限性：手动策划、静态数据集、主要关注Python错误修复。需要更自动化、多语言、覆盖更广任务类型的基准来评估LLM在软件工程任务上的表现。

Method: 通过四个阶段自动化生成任务：1) 程序化采集GitHub拉取请求；2) 环境合成；3) 测试预言提取；4) 质量保证。还包含提示引导的轨迹合成步骤，将模型失败的实例转化为训练轨迹。

Result: 构建了包含11,133个实例的基准，覆盖3,971个仓库和11种语言。在1,782个实例子集上测试，Claude Sonnet 4.5达到36.20% pass@10，GPT-5 34.57%，Gemini 2.5 Pro 24.92%，GPT-4o 16.89%。微调SWE-Bench++数据能提升在SWE-bench多语言基准上的表现。

Conclusion: SWE-Bench++提供了一个可扩展、多语言的基准，用于评估和改进仓库级代码生成，解决了现有基准的局限性，支持更全面的软件工程任务评估。

Abstract: Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.

</details>


### [9] [An Investigation on How AI-Generated Responses Affect SoftwareEngineering Surveys](https://arxiv.org/abs/2512.17455)
*Ronnie de Souza Santos,Italo Santos,Maria Teresa Baldassarre,Cleyton Magalhaes,Mairieli Wessel*

Main category: cs.SE

TL;DR: 该研究探讨了大型语言模型在软件工程调查中的滥用问题，分析了AI生成回答对数据真实性和研究有效性的威胁，并提出了检测和预防方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，调查参与者可能使用生成工具伪造或操纵回答，这对软件工程调查的数据真实性、有效性和研究完整性构成了新的风险。

Method: 通过Prolific平台收集2025年两次调查部署的数据，分析参与者回答内容以识别异常或伪造回答。对疑似AI生成的回答子集进行定性模式检查、叙事特征描述，并使用Scribbr AI检测器进行自动检测。

Result: 在49个调查回答中发现了表明合成作者身份的重复结构模式，包括重复序列、统一措辞和表面个性化。这些虚假叙事模仿连贯推理同时隐藏伪造内容，破坏了结构、内部和外部有效性。

Conclusion: 研究将数据真实性确定为软件工程调查中有效性的新兴维度。强调可靠的证据现在需要结合自动和解释性验证程序、透明报告和社区标准来检测和预防AI生成回答，从而保护软件工程调查的可信度。

Abstract: Survey research is a fundamental empirical method in software engineering, enabling the systematic collection of data on professional practices, perceptions, and experiences. However, recent advances in large language models (LLMs) have introduced new risks to survey integrity, as participants can use generative tools to fabricate or manipulate their responses. This study explores how LLMs are being misused in software engineering surveys and investigates the methodological implications of such behavior for data authenticity, validity, and research integrity. We collected data from two survey deployments conducted in 2025 through the Prolific platform and analyzed the content of participants' answers to identify irregular or falsified responses. A subset of responses suspected of being AI generated was examined through qualitative pattern inspection, narrative characterization, and automated detection using the Scribbr AI Detector. The analysis revealed recurring structural patterns in 49 survey responses indicating synthetic authorship, including repetitive sequencing, uniform phrasing, and superficial personalization. These false narratives mimicked coherent reasoning while concealing fabricated content, undermining construct, internal, and external validity. Our study identifies data authenticity as an emerging dimension of validity in software engineering surveys. We emphasize that reliable evidence now requires combining automated and interpretive verification procedures, transparent reporting, and community standards to detect and prevent AI generated responses, thereby protecting the credibility of surveys in software engineering.

</details>


### [10] [When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction](https://arxiv.org/abs/2512.17460)
*Emmanuel Charleson Dapaah,Jens Grabowski*

Main category: cs.SE

TL;DR: 首次大规模实证分析软件缺陷预测中五种数据质量问题（类别不平衡、类别重叠、无关特征、属性噪声、异常值）的共现效应，揭示普遍共现现象、关键阈值和条件效应。


<details>
  <summary>Details</summary>
Motivation: 现有SDP研究通常孤立分析单一数据质量问题，但现实数据问题常共现且相互作用。缺乏对多种问题同时存在时的系统性分析，导致模型在实际应用中的效果受限。

Method: 使用374个数据集和5种分类器，采用可解释提升机（EBM）和分层交互分析，量化默认超参数设置下的直接效应和条件效应，反映实际基线使用情况。

Result: 共现现象普遍存在（最不频繁的属性噪声问题也在93%数据集中与其他问题共现）；类别重叠是最具破坏性的问题；识别出关键阈值：类别重叠0.20、不平衡0.65-0.70、无关特征0.94；发现反直觉模式（如低无关特征时异常值可提升性能）；揭示性能-鲁棒性权衡。

Conclusion: 研究填补了SDP领域长期存在的空白，强调需要超越孤立分析，提供对数据质量问题如何在实际环境中共同影响模型性能的整体性、数据感知的理解。

Abstract: Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.
  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.
  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.

</details>


### [11] [Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem](https://arxiv.org/abs/2512.17500)
*Yujing Chen,Xuanming Liu,Zhiyuan Wan,Zuobin Wang,David Lo,Difan Xie,Xiaohu Yang*

Main category: cs.SE

TL;DR: 该研究对NFT生态系统中智能合约的语义和交互进行了大规模实证分析，发现智能合约语义多样性有限，诈骗代币存在字节码趋同现象，并识别了与风险交易相关的特定交互模式。


<details>
  <summary>Details</summary>
Motivation: NFT生态系统存在诈骗代币风险，但先前研究缺乏对智能合约语义和交互的理解，特别是诈骗代币风险如何通过合约语义和交互表现出来。本研究旨在填补这一空白。

Method: 使用以太坊上近1亿笔交易、2000万个区块的精选数据集，对NFT生态系统中智能合约的语义和交互进行大规模实证研究。

Result: 发现NFT生态系统中智能合约语义多样性有限，主要由代理、代币和DeFi合约主导；市场平台和代理注册合约在交易中最常参与交互；代币合约在字节码层面具有多样性，而诈骗代币则表现出字节码趋同；某些智能合约交互模式在风险和非风险交易中都常见，而其他模式则主要与风险交易相关。

Conclusion: 基于研究发现，提出了降低区块链生态系统风险的建议，并指出了未来研究方向，为理解NFT生态系统中智能合约交互和诈骗代币风险提供了实证基础。

Abstract: The NFT ecosystem represents an interconnected, decentralized environment that encompasses the creation, distribution, and trading of Non-Fungible Tokens (NFTs), where key actors, such as marketplaces, sellers, and buyers, utilize smart contracts to facilitate secure, transparent, and trustless transactions. Scam tokens are deliberately created to mislead users and facilitate financial exploitation, posing significant risks in the NFT ecosystem. Prior work has explored the NFT ecosystem from various perspectives, including security challenges, actor behaviors, and risks from scams and wash trading, leaving a gap in understanding the semantics and interactions of smart contracts during transactions, and how the risks associated with scam tokens manifest in relation to the semantics and interactions of contracts. To bridge this gap, we conducted a large-scale empirical study on smart contract semantics and interactions in the NFT ecosystem, using a curated dataset of nearly 100 million transactions across 20 million blocks on Ethereum. We observe a limited semantic diversity among smart contracts in the NFT ecosystem, dominated by proxy, token, and DeFi contracts. Marketplace and proxy registry contracts are the most frequently involved in smart contract interactions during transactions, engaging with a broad spectrum of contracts in the ecosystem. Token contracts exhibit bytecode-level diversity, whereas scam tokens exhibit bytecode convergence. Certain interaction patterns between smart contracts are common to both risky and non-risky transactions, while others are predominantly associated with risky transactions. Based on our findings, we provide recommendations to mitigate risks in the blockchain ecosystem, and outline future research directions.

</details>


### [12] [SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review](https://arxiv.org/abs/2512.17540)
*Kai Wang,Bingcheng Mao,Shuai Jia,Yujie Ding,Dongming Han,Tianyi Ma,Bin Cao*

Main category: cs.SE

TL;DR: SGCR框架通过将LLM基于人工编写的规范进行代码审查，采用显式和隐式双路径架构，在工业环境中实现了42%的开发者采纳率，相比基线LLM提升90.9%。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的代码审查自动化虽然前景广阔，但实际应用受到可靠性不足、缺乏上下文感知和控制能力等问题的限制，需要一种更可靠、可控的解决方案。

Method: 提出规范驱动的代码审查框架SGCR，采用双路径架构：显式路径确保确定性遵守从规范派生的预定义规则；隐式路径启发式地发现和验证超出这些规则的问题。

Result: 在HiThink Research的工业环境中部署SGCR，其建议获得了42%的开发者采纳率，相比基线LLM的22%实现了90.9%的相对提升。

Conclusion: 规范驱动是弥合LLM生成能力与软件工程严格可靠性需求之间差距的强大范式，SGCR框架为代码审查自动化提供了可靠且相关的反馈。

Abstract: Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate-a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.

</details>


### [13] [A Practical Solution to Systematically Monitor Inconsistencies in SBOM-based Vulnerability Scanners](https://arxiv.org/abs/2512.17710)
*Martin Rosso,Muhammad Asad Jahangir Jaffar,Alessandro Brighente,Mauro Conti*

Main category: cs.SE

TL;DR: 该论文介绍了SVS-TEST，一种用于评估软件物料清单（SBOM）漏洞扫描工具能力、成熟度和故障条件的方法和工具，发现现有工具存在显著可靠性问题。


<details>
  <summary>Details</summary>
Motivation: SBOM为软件产品漏洞识别提供了新机会，但行业采用SBOM漏洞扫描（SVS）时，观察到不一致和意外行为，导致漏报和静默故障，需要系统评估工具可靠性。

Method: 提出SVS-TEST方法和工具，通过16个精心设计的SBOM及其真实基准，在真实场景中分析SVS工具的能力、成熟度和故障条件。

Result: 评估7个真实SVS工具显示，工具间可靠性存在显著差异，多个工具在有效输入SBOM上静默故障，造成虚假安全感。

Conclusion: 研究人员和从业者需关注SVS工具可靠性问题，组织可使用SVS-TEST监控工具能力，所有结果和发现已公开并提前披露给工具开发者。

Abstract: Software Bill of Materials (SBOM) provides new opportunities for automated vulnerability identification in software products. While the industry is adopting SBOM-based Vulnerability Scanning (SVS) to identify vulnerabilities, we increasingly observe inconsistencies and unexpected behavior, that result in false negatives and silent failures. In this work, we present the background necessary to understand the underlying complexity of SVS and introduce SVS-TEST, a method and tool to analyze the capability, maturity, and failure conditions of SVS-tools in real-world scenarios. We showcase the utility of SVS-TEST in a case study evaluating seven real-world SVS-tools using 16 precisely crafted SBOMs and their respective ground truth. Our results unveil significant differences in the reliability and error handling of SVS-tools; multiple SVS-tools silently fail on valid input SBOMs, creating a false sense of security. We conclude our work by highlighting implications for researchers and practitioners, including how organizations and developers of SVS-tools can utilize SVS-TEST to monitor SVS capability and maturity. All results and research artifacts are made publicly available and all findings were disclosed to the SVS-tool developers ahead of time.

</details>


### [14] [LLM-based Behaviour Driven Development for Hardware Design](https://arxiv.org/abs/2512.17814)
*Rolf Drechsler,Qian Liu*

Main category: cs.SE

TL;DR: 利用LLM自动化从文本规范生成硬件设计的行为场景，支持硬件设计中的BDD方法


<details>
  <summary>Details</summary>
Motivation: 硬件和系统设计中测试验证复杂度随系统规模增长而显著增加，BDD在软件工程中有效但在硬件设计中尚未成熟，主要障碍是需要从文本规范手动推导精确行为场景的繁重工作

Method: 研究基于大型语言模型（LLMs）的技术来支持硬件设计中的BDD，利用LLM自动化从文本规范生成行为场景

Result: 未在摘要中明确说明具体结果，但提出了LLM为硬件设计BDD提供新机会的研究方向

Conclusion: LLM技术为自动化硬件设计中的行为场景生成提供了新机遇，有望解决BDD在硬件设计中应用的主要障碍

Abstract: Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.
  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [When Symmetry Yields NP-Hardness: Affine ML-SAT on S5 Frames](https://arxiv.org/abs/2512.17378)
*Andreas Krebs,Arne Meier*

Main category: cs.LO

TL;DR: 本文反驳了Hemaspaandra等人关于多模态逻辑（仅含XOR和1连接词）在S5框架下可多项式时间求解的猜想，证明了该问题是NP难的。


<details>
  <summary>Details</summary>
Motivation: Hemaspaandra等人在2010年提出猜想：在多模态逻辑中，当逻辑连接词仅限于XOR和1时，在T、S4和S5框架类下的可满足性问题可以在多项式时间内解决。本文旨在验证这一猜想，特别是针对S5框架。

Method: 通过计算复杂性理论的方法，证明了该逻辑可满足性问题的NP难度。具体来说，为S5框架下的多模态逻辑（仅含XOR和1连接词）的可满足性问题构造了NP难度的归约。

Result: 成功反驳了原猜想，证明了在S5框架下，该逻辑的可满足性问题是NP难的，因此不可能在多项式时间内解决（除非P=NP）。

Conclusion: Hemaspaandra等人关于多模态逻辑（仅含XOR和1连接词）在S5框架下可多项式时间求解的猜想是错误的。该问题的计算复杂度实际上是NP难的，这为相关逻辑系统的计算复杂性提供了更准确的理解。

Abstract: Hemaspaandra~et~al.~[JCSS 2010] conjectured that satisfiability for multi-modal logic restricted to the connectives XOR and 1, over frame classes T, S4, and S5, is solvable in polynomial time. We refute this for S5 frames, by proving NP-hardness.

</details>


### [16] [Derivates for Containers in Univalent Foundations](https://arxiv.org/abs/2512.17484)
*Philipp Joram,Niccolò Veltri*

Main category: cs.LO

TL;DR: 在单值基础中扩展容器导数到非截断容器，证明其满足通用性质，研究链规则的可逆性及其与经典原理的关系，并在Cubical Agda中形式化验证。


<details>
  <summary>Details</summary>
Motivation: 传统容器导数仅适用于离散容器（位置具有可判定相等性），但在单值基础中需要处理非截断容器（形状和位置为任意类型），以扩展导数操作的应用范围。

Method: 在单值基础框架下，将导数操作扩展到非截断容器，基于孤立位置集合定义导数，在非截断容器和笛卡尔态射的野生范畴中研究其性质。

Result: 证明了扩展导数满足适当的通用性质，建立了与常数、和、积的基本定律，发现链规则一般不可逆，全局可逆链规则与非集合类型存在不一致性，推导了最小不动点的导数规则。

Conclusion: 成功将容器导数扩展到非截断容器，在单值基础中建立了完整的理论框架，所有结果在Cubical Agda中形式化验证，为树遍历算法提供了更通用的理论基础。

Abstract: Containers conveniently represent a wide class of inductive data types. Their derivatives compute representations of types of one-hole contexts, useful for implementing tree-traversal algorithms. In the category of containers and cartesian morphisms, derivatives of discrete containers (whose positions have decidable equality) satisfy a universal property. Working in Univalent Foundations, we extend the derivative operation to untruncated containers (whose shapes and positions are arbitrary types). We prove that this derivative, defined in terms of a set of isolated positions, satisfies an appropriate universal property in the wild category of untruncated containers and cartesian morphisms, as well as basic laws with respect to constants, sums and products. A chain rule exists, but is in general non-invertible. In fact, a globally invertible chain rule is inconsistent in the presence of non-set types, and equivalent to a classical principle when restricted to set-truncated containers. We derive a rule for derivatives of smallest fixed points from the chain rule, and characterize its invertibility. All of our results are formalized in Cubical Agda.

</details>


### [17] [Yet another cubical type theory, but via a semantic approach](https://arxiv.org/abs/2512.17548)
*Chris Kapulkin,Yufeng Li*

Main category: cs.LO

TL;DR: 提出一种新的立方类型理论（称为"朴素立方类型理论"），并利用宇宙范畴框架研究其语义学，证明该理论可在多种设置中解释，包括单纯集和笛卡尔立方集。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的立方类型理论，旨在创建一个更通用、更灵活的框架，能够在多种数学结构中实现语义解释，扩展立方类型理论的应用范围。

Method: 提出"朴素立方类型理论"，采用宇宙范畴框架（类似于Uemura的可表示态射范畴）来研究其语义学，建立类型理论的形式化系统。

Result: 证明该新类型理论可在多种设置中实现解释，包括单纯集和笛卡尔立方集，展示了理论的广泛适用性和语义灵活性。

Conclusion: 朴素立方类型理论提供了一个通用的立方类型理论框架，能够在多种数学结构中实现语义解释，为立方类型理论的进一步发展提供了新的可能性。

Abstract: We propose a new cubical type theory, termed (self-deprecatingly) the naive cubical type theory, and study its semantics using the universe category framework, which is similar to Uemura's categories with representable morphisms. In particular, we show that this new type theory admits an interpretation in a wide variety of settings, including simplicial sets and cartesian cubical sets.

</details>
