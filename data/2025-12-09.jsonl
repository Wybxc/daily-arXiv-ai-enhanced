{"id": "2512.06442", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.06442", "abs": "https://arxiv.org/abs/2512.06442", "authors": ["Xuanyu Peng", "Dominic Kennedy", "Yuyou Fan", "Ben Greenman", "John Regehr", "Loris D'Antoni"], "title": "Nice to Meet You: Synthesizing Practical MLIR Abstract Transformers", "comment": null, "summary": "Static analyses play a fundamental role during compilation: they discover facts that are true in all executions of the code being compiled, and then these facts are used to justify optimizations and diagnostics. Each static analysis is based on a collection of abstract transformers that provide abstract semantics for the concrete instructions that make up a program. It can be challenging to implement abstract transformers that are sound, precise, and efficient, and in fact both LLVM and GCC have suffered from miscompilations caused by unsound abstract transformers. Moreover, even after more than 20 years of development, LLVM lacks abstract transformers for hundreds of instructions in its intermediate representation (IR). We developed NiceToMeetYou, a program synthesis framework for abstract transformers that are aimed at the kinds of non-relational integer abstract domains that are heavily used by today's production compilers. It exploits a simple but novel technique for breaking the synthesis problem into parts: each of our transformers is the meet of a collection of simpler, sound transformers that are synthesized such that each new piece fills a gap in the precision of the final transformer. Our design point is bulk automation: no sketches are required. Transformers are verified by lowering to a previously created SMT dialect of MLIR. Each of our synthesized transformers is provably sound and some (17 percent) are more precise than those provided by LLVM."}
{"id": "2512.07299", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.07299", "abs": "https://arxiv.org/abs/2512.07299", "authors": ["Håvard Rognebakke Krogstie", "Helge Bahmann", "Magnus Själander", "Nico Reissmann"], "title": "PIP: Making Andersen's Points-to Analysis Sound and Practical for Incomplete C Programs", "comment": "11 pages, 10 figures. To be published in CGO 2026", "summary": "Compiling files individually lends itself well to parallelization, but forces the compiler to operate on incomplete programs. State-of-the-art points-to analyses guarantee sound solutions only for complete programs, requiring summary functions to describe any missing program parts. Summary functions are rarely available in production compilers, however, where soundness and efficiency are non-negotiable. This paper presents an Andersen-style points-to analysis that efficiently produces sound solutions for incomplete C programs. The analysis accomplishes soundness by tracking memory locations and pointers that are accessible from external modules, and efficiency by performing this tracking implicitly in the constraint graph. We show that implicit pointee tracking makes the constraint solver 15$\\times$ faster than any combination of five different state-of-the-art techniques using explicit pointee tracking. We also present the Prefer Implicit Pointees (PIP) technique that further reduces the use of explicit pointees. PIP gives an additional speedup of 1.9$\\times$, compared to the fastest solver configuration not benefiting from PIP. The precision of the analysis is evaluated in terms of an alias-analysis client, where it reduces the number of MayAlias-responses by 40% compared to LLVM's BasicAA pass alone. Finally, we show that the analysis is scalable in terms of memory, making it suitable for optimizing compilers in practice."}
{"id": "2512.07511", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.07511", "abs": "https://arxiv.org/abs/2512.07511", "authors": ["Zanzi Mihejevs", "Jules Hedges"], "title": "Canonical bidirectional typechecking", "comment": null, "summary": "We demonstrate that the checkable/synthesisable split in bidirectional typechecking coincides with existing dualities in polarised System L, also known as polarised $μ\\tildeμ$-calculus. Specifically, positive terms and negative coterms are checkable, and negative terms and positive coterms are synthesisable. This combines a standard formulation of bidirectional typechecking with Zeilberger's `cocontextual' variant. We extend this to ordinary `cartesian' System L using Mc Bride's co-de Bruijn formulation of scopes, and show that both can be combined in a linear-nonlinear style, where linear types are positive and cartesian types are negative. This yields a remarkable 3-way coincidence between the shifts of polarised System L, LNL calculi, and bidirectional calculi."}
{"id": "2512.06242", "categories": ["cs.LO", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06242", "abs": "https://arxiv.org/abs/2512.06242", "authors": ["Ian J. Hayes", "Larissa A. Meinicke", "Cliff B. Jones"], "title": "Reasoning about concurrent loops and recursion with rely-guarantee rules", "comment": "21 pages, 2 figures", "summary": "The objective of this paper is to present general, mechanically verified, refinement rules for reasoning about recursive programs and while loops in the context of concurrency. Unlike many approaches to concurrency, we do not assume that expression evaluation is atomic. We make use of the rely-guarantee approach to concurrency that facilitates reasoning about interference from concurrent threads in a compositional manner. Recursive programs can be defined as fixed points over a lattice of commands and hence we develop laws for reasoning about fixed points. Loops can be defined in terms of fixed points and hence the laws for recursion can be applied to develop laws for loops."}
{"id": "2512.06832", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2512.06832", "abs": "https://arxiv.org/abs/2512.06832", "authors": ["Linh Anh Nguyen", "Son Thanh Cao", "Stefan Stanimirović"], "title": "Soft state reduction of fuzzy automata over residuated lattices", "comment": null, "summary": "State reduction of finite automata plays a significant role in improving efficiency in formal verification, pattern recognition, and machine learning, where automata-based models are widely used. While deterministic automata have well-defined minimization procedures, reducing states in nondeterministic fuzzy finite automata (FfAs) remains challenging, especially for FfAs over non-locally finite residuated lattices like the product and Hamacher structures. This work introduces soft state reduction, an approximate method that leverages a small threshold $\\varepsilon$ possibly combined with a word length bound $k$ to balance reduction accuracy and computational feasibility. By omitting fuzzy values smaller than $\\varepsilon$, the underlying residuated lattice usually becomes locally finite, making computations more tractable. We introduce and study approximate invariances, which are fuzzy relations that allow merging of almost equivalent states of an FfA up to a tolerance level $\\varepsilon$ and, optionally, to words of bounded length $k$. We further present an algorithm which iteratively applies such invariances to achieve reduction while preserving approximate language equivalence. Our method effectively reduces FfAs where existing techniques fail."}
{"id": "2512.06042", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06042", "abs": "https://arxiv.org/abs/2512.06042", "authors": ["Ashish Hooda", "Mihai Christodorescu", "Chuangang Ren", "Aaron Wilson", "Kassem Fawaz", "Somesh Jha"], "title": "Auto-SPT: Automating Semantic Preserving Transformations for Code", "comment": null, "summary": "Machine learning (ML) models for code clone detection determine whether two pieces of code are semantically equivalent, which in turn is a key building block for software-engineering tasks like refactoring and security tasks like vulnerability and malware detection. While these models are predominantly trained on clean, structured code datasets, real-world code often undergoes a variety of semantic-preserving transformations, including refactoring, minification, automated formatting, and compiler optimizations. To address this critical gap between training and test data, we propose Auto-SPT, a novel framework to automatically construct synthetic-data generators for code. Auto-SPT is designed to produce Semantic Preserving Transformations (SPTs) that alter a program's syntactic structure while preserving its functionality and is instantiated on top of Large Language Models (LLMs). In particular, we use LLMs to craft a diverse set of SPTs, generate strong implementations for these SPTs, and compose them to result into strong transformations. Our formal analysis shows that the diversity of SPTs impacts the strength of their composition. We then empirically demonstrate that Auto-SPT generates more diverse SPTs than existing approaches and these SPTs significantly drop the performance of state-of-the-art code clone detectors. Further experiments show Auto-SPT can be used to enhance code datasets for training, to produce code-clone detection models that are robust to real-world, adversarial code transformations."}
{"id": "2512.06203", "categories": ["cs.LO", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2512.06203", "abs": "https://arxiv.org/abs/2512.06203", "authors": ["Julius Tranquilli", "Naman Gupta"], "title": "Formal State-Machine Models for Uniswap v3 Concentrated-Liquidity AMMs: Priced Timed Automata, Finite-State Transducers, and Provable Rounding Bounds", "comment": "10 pages, 1 table", "summary": "Concentrated-liquidity automated market makers (CLAMMs), as exemplified by Uniswap v3, are now a common primitive in decentralized finance frameworks. Their design combines continuous trading on constant-function curves with discrete tick boundaries at which liquidity positions change and rounding effects accumulate. While there is a body of economic and game-theoretic analysis of CLAMMs, there is negligible work that treats Uniswap v3 at the level of formal state machines amenable to model checking or theorem proving.\n  In this paper we propose a formal modeling approach for Uniswap v3-style CLAMMs using (i) networks of priced timed automata (PTA), and (ii) finite-state transducers (FST) over discrete ticks. Positions are treated as stateful objects that transition only when the pool price crosses the ticks that bound their active range. We show how to encode the piecewise constant-product invariant, fee-growth variables, and tick-crossing rules in a PTA suitable for tools such as UPPAAL, and how to derive a tick-level FST abstraction for specification in TLA+.\n  We define an explicit tick-wise invariant for a discretized, single-tick CLAMM model and prove that it is preserved up to a tight additive rounding bound under fee-free swaps. This provides a formal justification for the \"$ε$-slack\" used in invariance properties and shows how rounding enters as a controlled perturbation. We then instantiate these models in TLA+ and use TLC to exhaustively check the resulting invariants on structurally faithful instances, including a three-tick concentrated-liquidity configuration and a bounded no-rounding-only-arbitrage property in a bidirectional single-tick model. We discuss how these constructions lift to the tick-wise structure of Uniswap v3 via virtual reserves, and how the resulting properties can be phrased as PTA/TLA+ invariants about cross-tick behaviour and rounding safety."}
{"id": "2512.06836", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.06836", "abs": "https://arxiv.org/abs/2512.06836", "authors": ["Weixing Zhang", "Regina Hebig", "Daniel Strüber"], "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs", "comment": null, "summary": "Software languages evolve over time for various reasons, such as the addition of new features. When the language's grammar definition evolves, textual instances that originally conformed to the grammar become outdated. For DSLs in a model-driven engineering context, there exists a plethora of techniques to co-evolve models with the evolving metamodel. However, these techniques are not geared to support DSLs with a textual syntax -- applying them to textual language definitions and instances may lead to the loss of information from the original instances, such as comments and layout information, which are valuable for software comprehension and maintenance. This study explores the potential of Large Language Model (LLM)-based solutions in achieving grammar and instance co-evolution, with attention to their ability to preserve auxiliary information when directly processing textual instances. By applying two advanced language models, Claude-3.5 and GPT-4o, and conducting experiments across seven case languages, we evaluated the feasibility and limitations of this approach. Our results indicate a good ability of the considered LLMs for migrating textual instances in small-scale cases with limited instance size, which are representative of a subset of cases encountered in practice. In addition, we observe significant challenges with the scalability of LLM-based solutions to larger instances, leading to insights that are useful for informing future research."}
{"id": "2512.07476", "categories": ["cs.FL", "cs.CC", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.07476", "abs": "https://arxiv.org/abs/2512.07476", "authors": ["Klaus Jansen", "Dirk Nowotka", "Lis Pirotton", "Corinna Wambsganz", "Max Wiedenhöft"], "title": "An Analysis of Decision Problems for Relational Pattern Languages under Various Constraints", "comment": "44 pages (incl. appendix and references), 5 tables", "summary": "Patterns are words with terminals and variables. The language of a pattern is the set of words obtained by uniformly substituting all variables with words that contain only terminals. In their original definition, patterns only allow for multiple distinct occurrences of some variables to be related by the equality relation, represented by using the same variable multiple times. In an extended notion, called relational patterns and relational pattern languages, variables may be related by arbitrary other relations. We extend the ongoing investigation of the main decision problems for patterns (namely, the membership problem, the inclusion problem, and the equivalence problem) to relational pattern languages under a wide range of individual relations. It is shown show that - even for many much simpler or less restrictive relations - the complexity and (un)decidability characteristics of these problems do not change compared to the classical case where variables are related only by equality."}
{"id": "2512.06046", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06046", "abs": "https://arxiv.org/abs/2512.06046", "authors": ["Ramprasath Ganesaraja", "Swathika N", "Saravanan AP", "Kamalkumar Rathinasamy", "Chetana Amancharla", "Rahul Das", "Sahil Dilip Panse", "Aditya Batwe", "Dileep Vijayan", "Veena Ashok", "Thanushree A P", "Kausthubh J Rao", "Alden Olivero", "Roshan", "Rajeshwar Reddy Manthena", "Asmitha Yuga Sre A", "Harsh Tripathi", "Suganya Selvaraj", "Vito Chin", "Kasthuri Rangan Bhaskar", "Kasthuri Rangan Bhaskar", "Venkatraman R", "Sajit Vijayakumar"], "title": "Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework", "comment": "17 pages, 9 figures", "summary": "We present AI4UI, a framework of autonomous front-end development agents purpose-built to meet the rigorous requirements of enterprise-grade application delivery. Unlike general-purpose code assistants designed for rapid prototyping, AI4UI focuses on production readiness delivering secure, scalable, compliant, and maintainable UI code integrated seamlessly into enterprise workflows. AI4UI operates with targeted human-in-the-loop involvement: at the design stage, developers embed a Gen-AI-friendly grammar into Figma prototypes to encode requirements for precise interpretation; and at the post processing stage, domain experts refine outputs for nuanced design adjustments, domain-specific optimizations, and compliance needs. Between these stages, AI4UI runs fully autonomously, converting designs into engineering-ready UI code. Technical contributions include a Figma grammar for autonomous interpretation, domain-aware knowledge graphs, a secure abstract/package code integration strategy, expertise driven architecture templates, and a change-oriented workflow coordinated by specialized agent roles. In large-scale benchmarks against industry baselines and leading competitor systems, AI4UI achieved 97.24% platform compatibility, 87.10% compilation success, 86.98% security compliance, 78.00% feature implementation success, 73.50% code-review quality, and 73.36% UI/UX consistency. In blind preference studies with 200 expert evaluators, AI4UI emerged as one of the leaders demonstrating strong competitive standing among leading solutions. Operating asynchronously, AI4UI generates thousands of validated UI screens in weeks rather than months, compressing delivery timeline"}
{"id": "2512.06242", "categories": ["cs.LO", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06242", "abs": "https://arxiv.org/abs/2512.06242", "authors": ["Ian J. Hayes", "Larissa A. Meinicke", "Cliff B. Jones"], "title": "Reasoning about concurrent loops and recursion with rely-guarantee rules", "comment": "21 pages, 2 figures", "summary": "The objective of this paper is to present general, mechanically verified, refinement rules for reasoning about recursive programs and while loops in the context of concurrency. Unlike many approaches to concurrency, we do not assume that expression evaluation is atomic. We make use of the rely-guarantee approach to concurrency that facilitates reasoning about interference from concurrent threads in a compositional manner. Recursive programs can be defined as fixed points over a lattice of commands and hence we develop laws for reasoning about fixed points. Loops can be defined in terms of fixed points and hence the laws for recursion can be applied to develop laws for loops."}
{"id": "2512.07595", "categories": ["cs.FL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.07595", "abs": "https://arxiv.org/abs/2512.07595", "authors": ["Joel Nguetoum", "Boutheina Bannour", "Pascale Le Gall", "Erwan Mahe"], "title": "Specializing anti-unification for interaction models composition via gate connections", "comment": "26 pages (21 in the article, 5 pages in appendices), 7 figures, 6 tables, submitted to Formal Methods 2026 (FM 2026)", "summary": "Interaction models describe distributed systems as algebraic terms, with gates marking interaction points between local views. Composing local models into a coherent global one requires aligning these gates while respecting the algebraic laws of interaction operators. We specialize anti-unification (or generalization) via a special constant-preserving variant, which preserves designated constants while generalizing the remaining structure. We develop a dedicated rule-based procedure for computing these generalizations, prove its termination, soundness, and completeness, extend it modulo equational theories, and integrate it into a standard anti-unification framework. A prototype tool demonstrates the approach's ability to recompose global interactions from partial views."}
{"id": "2512.06060", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06060", "abs": "https://arxiv.org/abs/2512.06060", "authors": ["Mohanakrishnan Hariharan"], "title": "Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring", "comment": null, "summary": "This paper introduces a framework that integrates reinforcement learning (RL) with autonomous agents to enable continuous improvement in the automated process of software test cases authoring from business requirement documents within Quality Engineering (QE) workflows. Conventional systems employing Large Language Models (LLMs) generate test cases from static knowledge bases, which fundamentally limits their capacity to enhance performance over time. Our proposed Reinforcement Infused Agentic RAG (Retrieve, Augment, Generate) framework overcomes this limitation by employing AI agents that learn from QE feedback, assessments, and defect discovery outcomes to automatically improve their test case generation strategies. The system combines specialized agents with a hybrid vector-graph knowledge base that stores and retrieves software testing knowledge. Through advanced RL algorithms, specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), these agents optimize their behavior based on QE-reported test effectiveness, defect detection rates, and workflow metrics. As QEs execute AI-generated test cases and provide feedback, the system learns from this expert guidance to improve future iterations. Experimental validation on enterprise Apple projects yielded substantive improvements: a 2.4% increase in test generation accuracy (from 94.8% to 97.2%), and a 10.8% improvement in defect detection rates. The framework establishes a continuous knowledge refinement loop driven by QE expertise, resulting in progressively superior test case quality that enhances, rather than replaces, human testing capabilities."}
{"id": "2512.06466", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.06466", "abs": "https://arxiv.org/abs/2512.06466", "authors": ["Lê Thành Dũng Nguyên", "Paweł Parys"], "title": "A finer reparameterisation theorem for MSO and FO queries on strings", "comment": "4 pages; not submitted to a journal yet, some details need to be fleshed out", "summary": "We show a theorem on monadic second-order k-ary queries on finite words. It may be illustrated by the following example: if the number of results of a query on binary strings is O(number of 0s $\\times$ number of 1s), then each result can be MSO-definably identified from a 0-position, a 1-position and some finite data.\n  Our proofs also handle the case of first-order logic / aperiodic monoids. Thus we can state and prove the folklore theorem that dimension minimisation holds for first-order string-to-string interpretations."}
{"id": "2512.06466", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.06466", "abs": "https://arxiv.org/abs/2512.06466", "authors": ["Lê Thành Dũng Nguyên", "Paweł Parys"], "title": "A finer reparameterisation theorem for MSO and FO queries on strings", "comment": "4 pages; not submitted to a journal yet, some details need to be fleshed out", "summary": "We show a theorem on monadic second-order k-ary queries on finite words. It may be illustrated by the following example: if the number of results of a query on binary strings is O(number of 0s $\\times$ number of 1s), then each result can be MSO-definably identified from a 0-position, a 1-position and some finite data.\n  Our proofs also handle the case of first-order logic / aperiodic monoids. Thus we can state and prove the folklore theorem that dimension minimisation holds for first-order string-to-string interpretations."}
{"id": "2512.06123", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.06123", "abs": "https://arxiv.org/abs/2512.06123", "authors": ["Qilin Zhou", "Zhengyuan Wei", "Haipeng Wang", "Zhuo Wang", "W. K. Chan"], "title": "Toward Patch Robustness Certification and Detection for Deep Learning Systems Beyond Consistent Samples", "comment": "accepted by IEEE Transactions on Reliability; extended technical report", "summary": "Patch robustness certification is an emerging kind of provable defense technique against adversarial patch attacks for deep learning systems. Certified detection ensures the detection of all patched harmful versions of certified samples, which mitigates the failures of empirical defense techniques that could (easily) be compromised. However, existing certified detection methods are ineffective in certifying samples that are misclassified or whose mutants are inconsistently pre icted to different labels. This paper proposes HiCert, a novel masking-based certified detection technique. By focusing on the problem of mutants predicted with a label different from the true label with our formal analysis, HiCert formulates a novel formal relation between harmful samples generated by identified loopholes and their benign counterparts. By checking the bound of the maximum confidence among these potentially harmful (i.e., inconsistent) mutants of each benign sample, HiCert ensures that each harmful sample either has the minimum confidence among mutants that are predicted the same as the harmful sample itself below this bound, or has at least one mutant predicted with a label different from the harmful sample itself, formulated after two novel insights. As such, HiCert systematically certifies those inconsistent samples and consistent samples to a large extent. To our knowledge, HiCert is the first work capable of providing such a comprehensive patch robustness certification for certified detection. Our experiments show the high effectiveness of HiCert with a new state-of the-art performance: It certifies significantly more benign samples, including those inconsistent and consistent, and achieves significantly higher accuracy on those samples without warnings and a significantly lower false silent ratio."}
{"id": "2512.06499", "categories": ["cs.LO", "math.CT"], "pdf": "https://arxiv.org/pdf/2512.06499", "abs": "https://arxiv.org/abs/2512.06499", "authors": ["Callum Reader", "Alessandro Di Giorgio"], "title": "String Diagrams for Closed Symmetric Monoidal Categories", "comment": null, "summary": "We introduce a graphical language for closed symmetric monoidal categories based on an extension of string diagrams with special bracket wires representing internal homs. These bracket wires make the structure of the internal hom functor explicit, allowing standard morphism wires to interact with them through a well-defined set of graphical rules.\n  We establish the soundness and completeness of the diagrammatic calculus, and illustrate its expressiveness through examples drawn from category theory, logic and programming language semantics."}
{"id": "2512.07434", "categories": ["cs.SE", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.07434", "abs": "https://arxiv.org/abs/2512.07434", "authors": ["Bram Pellen", "María Belén Rodríguez", "Frits Vaandrager", "Petra van den Bos"], "title": "Systematic Evaluation of Black-Box Checking for Fast Bug Detection", "comment": "23 pages, 4 figures", "summary": "Combinations of active automata learning, model-based testing and model checking have been successfully used in numerous applications, e.g., for spotting bugs in implementations of major network protocols and to support refactoring of embedded controllers. However, in the large majority of these applications, model checking is only used at the very end, when no counterexample can be found anymore for the latest hypothesis model. This contrasts with the original proposal of black-box checking (BBC) by Peled, Vardi & Yannakakis, which applies model checking for all hypotheses, also the intermediate ones. In this article, we present the first systematic evaluation of the ability of BBC to find bugs quickly, based on 77 benchmarks models from real protocol implementations and controllers for which specifications of safety properties are available. Our main finding are: (a) In cases where the full model can be learned, BBC detects violations of the specifications with just 3.4% of the queries needed by an approach in which model checking is only used for the full model. (b) Even when the full model cannot be learned, BBC is still able to detect many violations of the specification. In particular, BBC manages to detect 94% of the safety properties violations in the challenging RERS 2019 industrial LTL benchmarks. (c) Our results also confirm that BBC is way more effective than existing MBT algorithms in finding deep bugs in implementations."}
{"id": "2512.06178", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06178", "abs": "https://arxiv.org/abs/2512.06178", "authors": ["Georgiana Haldeman", "Peter Ohmann", "Paul Denny"], "title": "Systematically Thinking about the Complexity of Code Structuring Exercises at Introductory Level", "comment": null, "summary": "Decomposition and abstraction is an essential component of computational thinking, yet it is not always emphasized in introductory programming courses. In addition, as generative AI further reduces the focus on syntax and increases the importance of higher-level code reasoning, there is renewed opportunity to teach DA explicitly. In this paper, we introduce a framework for systematically assessing the complexity of code structuring tasks, where students must identify and separate meaningful abstractions within existing, unstructured code. The framework defines three dimensions of task complexity, each with multiple levels: repetition, code pattern, and data dependency. To support practical use, we provide example tasks mapped to these levels and offer an interactive tool for generating and exploring DA problems. The framework is designed to support the development of educational tasks that build students' skills with DA in the procedural paradigm."}
{"id": "2512.06542", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06542", "abs": "https://arxiv.org/abs/2512.06542", "authors": ["Baltag Alexandru", "Smets Sonja"], "title": "Comparing Knowledge: An Analysis of the Relative Epistemic Powers of Groups", "comment": "20 pages, 3 figures, 3rd International Workshop on Logic and Philosophy", "summary": "We use a novel type of epistemic logic, employing comparative knowledge assertions, to analyze the relative epistemic powers of individuals or groups of agents. Such comparative assertions can express that a group has the potential to (collectively) know everything that another group can know. Moreover, we look at comparisons involving various types of knowledge (fully introspective, positively introspective, etc.), satisfying the corresponding modal-epistemic conditions (e.g., $S5$, $S4$, $KT$). For each epistemic attitude, we are particularly interested in what agents or groups can know about their own epistemic position relative to that of others."}
{"id": "2512.06247", "categories": ["cs.SE", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.06247", "abs": "https://arxiv.org/abs/2512.06247", "authors": ["Gus Henry Smith", "Sandesh Adhikary", "Vineet Thumuluri", "Karthik Suresh", "Vivek Pandit", "Kartik Hegde", "Hamid Shojaei", "Chandra Bhagavatula"], "title": "DUET: Agentic Design Understanding via Experimentation and Testing", "comment": null, "summary": "AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation."}
{"id": "2512.06604", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06604", "abs": "https://arxiv.org/abs/2512.06604", "authors": ["Michał Sochański", "Przemysław Andrzej Wałęga", "Michał Zawidzki"], "title": "Description Logics with Two Types of Definite Descriptions: Complexity, Expressiveness, and Automated Deduction", "comment": "Accepted for publication at AAAI 2026; pre-print with full proofs and supplementary results", "summary": "Definite descriptions are expressions of the form \"the unique $x$ satisfying property $C$,\" which allow reference to objects through their distinguishing characteristics. They play a crucial role in ontology and query languages, offering an alternative to proper names (IDs), which lack semantic content and serve merely as placeholders.\n  In this paper, we introduce two extensions of the well-known description logic $\\mathcal{ALC}$ with local and global definite descriptions, denoted $\\mathcal{ALC}ι_L$ and $\\mathcal{ALC}ι_G$, respectively. We define appropriate bisimulation notions for these logics, enabling an analysis of their expressiveness. We show that although both logics share the same tight ExpTime complexity bounds for concept and ontology satisfiability, $\\mathcal{ALC}ι_G$ is strictly more expressive than $\\mathcal{ALC}ι_L$. Moreover, we present tableau-based decision procedures for satisfiability in both logics, provide their implementation, and report on a series of experiments. The empirical results demonstrate the practical utility of the implementation and reveal interesting correlations between performance and structural properties of the input formulas."}
{"id": "2512.06248", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06248", "abs": "https://arxiv.org/abs/2512.06248", "authors": ["Cheng Cheng", "Jinqiu Yang"], "title": "CFCEval: Evaluating Security Aspects in Code Generated by Large Language Models", "comment": null, "summary": "Code-focused Large Language Models (LLMs), such as CodeX and Star-Coder, have demonstrated remarkable capabilities in enhancing developer productivity through context-aware code generation. However, evaluating the quality and security of LLM-generated code remains a significant challenge. Existing evaluation protocols for Code LLMs lack both methodological rigor and comprehensive scope. A key limitation is dataset bias, which arises from unintentional overlap between training and testing data. Furthermore, while CodeBLEU, a BLEU-based metric, is widely used to assess code similarity, it suffers from critical shortcomings, including imprecise tokenization, structural limitations, and low reference diversity. To address these challenges, we introduce CFCEval, a novel framework for evaluating the quality and security of code generated by LLMs. CFCEval mitigates dataset bias by creating a new benchmark, MLVBench, and incorporates ELRM, a new metric designed to assess the relevance between reference code and generated code. CFCEval evaluates generated code across four dimensions: programming quality, vulnerability-fixing capability, post-transformation fixing capability, and relevance. Our experiments show that CFCEval not only captures both quality and security aspects of generated code more effectively but also that its ELRM aligns more closely with human judgments than CodeBLEU, thus paving the way for future advancements in Code LLMs evaluation."}
{"id": "2512.06627", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06627", "abs": "https://arxiv.org/abs/2512.06627", "authors": ["Xindi Zhang", "Furong Ye", "Zhihan Chen", "Shaowei Cai"], "title": "FastLEC: Parallel Datapath Equivalence Checking with Hybrid Engines", "comment": null, "summary": "Combinational equivalence checking (CEC) remains a challenge EDA task in the formal verification of datapath circuits due to their complex arithmetic structures and the limited capability or scalability of SAT, BDD, and exact-simulation (ES) based techniques when used independently. This work presents FastLEC, a hybrid prover that unifies these three formal reasoning engines and introduces three strategies that substantially enhance verification efficiency. First, a regression-based engine-scheduling heuristic predicts solver effectiveness, enabling more accurate and balanced allocation of computational resources. Second, datapath-structure-aware partitioning strategies, along with a dynamic divide-and-conquer SAT prover, exploit the regularity of arithmetic designs while preserving completeness. Third, the memory overhead of ES is significantly reduced through address-reference-count tracking, and simulation is further accelerated through a GPU-enabled backend. FastLEC is evaluated across 368 datapath circuits. Using 32 CPU cores, it proves 5.07x more circuits than the widely used ABC &cec tool. Compared with the latest best datapath-oriented serial and parallel CEC provers, FastLEC outperforms them by 3.33x and 2.67x in PAR-2 time, demonstrating an improvement of 74 newly solved circuits. With the addition of a single GPU, it achieves a further 4.07x improvement. The prover also demonstrates excellent scalability."}
{"id": "2512.06401", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06401", "abs": "https://arxiv.org/abs/2512.06401", "authors": ["Zhenzhen Yang", "Chenhui Cui", "Tao Li", "Rubing Huang", "Nan Niu", "Dave Towey", "Shikai Guo"], "title": "LLMCFG-TGen: Using LLM-Generated Control Flow Graphs to Automatically Create Test Cases from Use Cases", "comment": null, "summary": "Appropriate test case generation is critical in software testing, significantly impacting the quality of the testing. Requirements-Based Test Generation (RBTG) derives test cases from software requirements, aiming to verify whether or not the system's behaviors align with user needs and expectations. Requirements are often documented in Natural Language (NL), with use-case descriptions being a popular method for capturing functional behaviors and interaction flows in a structured form. Large Language Models (LLMs) have shown strong potential for automating test generation directly from NL requirements. However, current LLM-based approaches may not provide comprehensive, non-redundant coverage. They may also fail to capture complex conditional logic in requirements, resulting in incomplete test cases. We propose a new approach that automatically generates test cases from NL use-case descriptions, called Test Generation based on LLM-generated Control Flow Graphs (LLMCFG-TGen). LLMCFG-TGen comprises three main steps: (1) An LLM transforms a use case into a structured CFG that encapsulates all potential branches; (2) The generated CFG is explored, and all complete execution paths are enumerated; and (3) The execution paths are then used to generate the test cases. To evaluate our proposed approach, we conducted a series of experiments. The results show that LLMs can effectively construct well-structured CFGs from NL use cases. Compared with the baseline methods, LLMCFG-TGen achieves full path coverage, improving completeness and ensuring clear and accurate test cases. Practitioner assessments confirm that LLMCFG-TGen produces logically consistent and comprehensive test cases, while substantially reducing manual effort. The findings suggest that coupling LLM-based semantic reasoning with structured modeling effectively bridges the gap between NL requirements and systematic test generation."}
{"id": "2512.06643", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06643", "abs": "https://arxiv.org/abs/2512.06643", "authors": ["Changyuan Yu", "Wenbin Che", "Hongce Zhang"], "title": "Functional Reduction to Speed Up Bounded Model Checking", "comment": null, "summary": "Bounded model checking (BMC) is a widely used technique for formal property verification (FPV), where the transition relation is repeatedly unrolled to increasing depths and encoded into Boolean satisfiability (SAT) queries. As the bound grows deeper, these SAT queries typically become more difficult to solve, posing scalability challenges. Howevefor, many FPV problems involve multiple copies of related circuits, creating opportunities to simplify the unrolled transition relation. Motivated by the functionally reduced and-inverter-graph (FRAIG) technique, we propose FRAIG-BMC, which incrementally identifies and merges functionally equivalent nodes during the unrolling process. By reducing redundancy, FRAIG-BMC improves the efficiency of SAT solving and accelerates property checking. Experiments demonstrate that FRAIG-BMC significantly speeds up BMC across a range of applications, including sequential equivalence checking, partial retention register detection, and information flow checking"}
{"id": "2512.06448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06448", "abs": "https://arxiv.org/abs/2512.06448", "authors": ["Takaaki Tateishi", "Yasuharu Katsuno"], "title": "Translating PL/I Macro Procedures into Java Using Automatic Templatization and Large Language Models", "comment": "5 pages, 7 figures, to be published in ICSE 2026 NIER", "summary": "Modernizing legacy enterprise systems often involves translating PL/I programs into modern languages such as Java. This task becomes significantly more complex when PL/I macro procedures are involved. The PL/I macro procedures are considered string-manipulating programs that generate PL/I code, and they make automated translation more complex. Recently, large language models (LLMs) have been explored for automated code translation. However, LLM-based code translation struggles to translate the PL/I macro procedures to Java programs that reproduce the behavior of the plain PL/I code generated by the original PL/I macro procedures.\n  This paper proposes a novel method called templatization, which uses symbolic execution to generate code templates (code with named placeholders) as an intermediate representation. In this approach, symbolic values are treated as parts of macro-generated code. By symbolically executing macro procedures and generating code templates, our approach facilitates LLMs to generate readable and maintainable Java code. Our preliminary experiment on ten PL/I macro procedures shows that the LLM-based translation through templatization successfully generates Java programs that reproduce the behavior of the macro-generated PL/I programs."}
{"id": "2512.06850", "categories": ["cs.LO", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.06850", "abs": "https://arxiv.org/abs/2512.06850", "authors": ["Hansa Mohanty", "Vaisakh Naduvodi Viswambharan", "Deepak Narayan Gadde"], "title": "Formal that \"Floats\" High: Formal Verification of Floating Point Arithmetic", "comment": "To appear at the 37th IEEE International Conference on Microelectronics (ICM), December 14-17, 2025, Cairo, Egypt", "summary": "Formal verification of floating-point arithmetic remains challenging due to non-linear arithmetic behavior and the tight coupling between control and datapath logic. Existing approaches often rely on high-level C models for equivalence checking against Register Transfer Level (RTL) designs, but this introduces abstraction gaps, translation overhead, and limits scalability at the RTL level. To address these challenges, this paper presents a scalable methodology for verifying floating-point arithmetic using direct RTL-to-RTL model checking against a golden reference model. The approach adopts a divide-and conquer strategy that decomposes verification into modular stages, each captured by helper assertions and lemmas that collectively prove a main correctness theorem. Counterexample (CEX)-guided refinement is used to iteratively localize and resolve implementation defects, while targeted fault injection validates the robustness of the verification process against precision-critical datapath errors. To assess scalability and practicality, the methodology is extended with agentic AI-based formal property generation, integrating large language model (LLM)-driven automation with Human-in-the-Loop (HITL) refinement. Coverage analysis evaluates the effectiveness of the approach by comparing handwritten and AI-generated properties in both RTL-to-RTL model checking and standalone RTL verification settings. Results show that direct RTL-to-RTL model checking achieves higher coverage efficiency and requires fewer assertions than standalone verification, especially when combined with AI-generated properties refined through HITL guidance."}
{"id": "2512.06806", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06806", "abs": "https://arxiv.org/abs/2512.06806", "authors": ["Benjamin Weigell", "Simon Hornung", "Bernhard Bauer"], "title": "METRION: A Framework for Accurate Software Energy Measurement", "comment": "(Accepted/In press) 10th IEEE/ACM International Workshop on Green and Sustainable Software (GREENS'26): GREENS@ICSE 2026", "summary": "The Information and Communication Technology sector accounted for approximately 1.4% of global greenhouse gas emissions and 4% of the world's electricity consumption in 2020, with both expected to rise. To reduce this environmental impact, optimization strategies are employed to reduce energy consumption at the IT infrastructure and application levels. However, effective optimization requires, firstly, the identification of major energy consumers and, secondly, the ability to quantify whether an optimization has achieved the intended energy savings. Accurate determination of application-level energy consumption is thus essential. Therefore, we introduce an energy attribution model that quantifies the energy consumption of applications on CPU and DRAM at the thread level, considering the influence of Simultaneous Multithreading, frequency scaling, multi-socket architectures, and Non-Uniform Memory Access. To ensure cross-platform applicability, we integrate the proposed model into an extensible framework, METRION, including a platform-independent data model and an initial implementation for Linux systems using Intel CPUs. We evaluate METRION across three different workloads and demonstrate that the energy attribution model can accurately capture the CPU energy consumption of applications targeting solely the CPU with a Mean Absolute Percentage Error of 4.2%, and the DRAM energy consumption of applications targeting DRAM with an 16.1% error."}
{"id": "2512.06952", "categories": ["cs.LO", "cs.CE", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.06952", "abs": "https://arxiv.org/abs/2512.06952", "authors": ["Mirco A. Mannucci", "Corey Thuro"], "title": "Resource-Bounded Type Theory: Compositional Cost Analysis via Graded Modalities", "comment": "20 pages, 2 figures", "summary": "We present a compositional framework for certifying resource bounds in typed programs. Terms are typed with synthesized bounds drawn from an abstract resource lattice, enabling uniform treatment of time, memory, gas, and domain-specific costs.\n  We introduce a graded feasibility modality with co-unit and monotonicity laws. Our main result is a syntactic cost soundness theorem for the recursion-free simply-typed fragment: if a closed term has synthesized bound b under a given budget, its operational cost is bounded by b. We provide a syntactic term model in the topos of presheaves over the lattice -- where resource bounds index a cost-stratified family of definable values -- with cost extraction as a natural transformation. We prove canonical forms via reification and establish initiality of the syntactic model: it embeds uniquely into all resource-bounded models.\n  A case study demonstrates compositional reasoning for binary search using Lean's native recursion with separate bound proofs."}
{"id": "2512.06836", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.06836", "abs": "https://arxiv.org/abs/2512.06836", "authors": ["Weixing Zhang", "Regina Hebig", "Daniel Strüber"], "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs", "comment": null, "summary": "Software languages evolve over time for various reasons, such as the addition of new features. When the language's grammar definition evolves, textual instances that originally conformed to the grammar become outdated. For DSLs in a model-driven engineering context, there exists a plethora of techniques to co-evolve models with the evolving metamodel. However, these techniques are not geared to support DSLs with a textual syntax -- applying them to textual language definitions and instances may lead to the loss of information from the original instances, such as comments and layout information, which are valuable for software comprehension and maintenance. This study explores the potential of Large Language Model (LLM)-based solutions in achieving grammar and instance co-evolution, with attention to their ability to preserve auxiliary information when directly processing textual instances. By applying two advanced language models, Claude-3.5 and GPT-4o, and conducting experiments across seven case languages, we evaluated the feasibility and limitations of this approach. Our results indicate a good ability of the considered LLMs for migrating textual instances in small-scale cases with limited instance size, which are representative of a subset of cases encountered in practice. In addition, we observe significant challenges with the scalability of LLM-based solutions to larger instances, leading to insights that are useful for informing future research."}
{"id": "2512.06959", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.06959", "abs": "https://arxiv.org/abs/2512.06959", "authors": ["Marco Bernardo", "Andrea Esposito", "Claudio A. Mezzina"], "title": "Hereditary History-Preserving Bisimilarity: Characterizations via Backward Ready Multisets", "comment": null, "summary": "We devise two complementary characterizations of hereditary history-preserving bisimilarity (HHPB): a denotational one, based on stable configuration structures, and an operational one, formulated in a reversible process calculus. Our characterizations rely on forward-reverse bisimilarity augmented with backward ready multiset equality. This shifts the emphasis from uniquely identifying events, as done in previous characterizations, to counting occurrences of identically labeled events associated with incoming transitions, which yields a more lightweight behavioral equivalence than HHPB. We show that our characterizations correctly distinguish between autoconcurrency and autocausation, but are valid only in the absence of non-local conflicts. We then study the logical foundations of these characterizations by relating event identifier logic, which captures the classical view of HHPB, and backward ready multiset logic, developed for our new equivalence."}
{"id": "2512.06902", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06902", "abs": "https://arxiv.org/abs/2512.06902", "authors": ["Fazle Rabbi", "Soumit Kanti Saha", "Tri Minh Triet Pham", "Song Wang", "Jinqiu Yang"], "title": "BabelCoder: Agentic Code Translation with Specification Alignment", "comment": "21 pages, 8 figures, 4 tables", "summary": "As software systems evolve, developers increasingly work across multiple programming languages and often face the need to migrate code from one language to another. While automatic code translation offers a promising solution, it has long remained a challenging task. Recent advancements in Large Language Models (LLMs) have shown potential for this task, yet existing approaches remain limited in accuracy and fail to effectively leverage contextual and structural cues within the code. Prior work has explored translation and repair mechanisms, but lacks a structured, agentic framework where multiple specialized agents collaboratively improve translation quality. In this work, we introduce BabelCoder, an agentic framework that performs code translation by decomposing the task into specialized agents for translation, testing, and refinement, each responsible for a specific aspect such as generating code, validating correctness, or repairing errors. We evaluate BabelCoder on four benchmark datasets and compare it against four state-of-the-art baselines. BabelCoder outperforms existing methods by 0.5%-13.5% in 94% of cases, achieving an average accuracy of 94.16%."}
{"id": "2512.06985", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.06985", "abs": "https://arxiv.org/abs/2512.06985", "authors": ["Tikhon Pshenitsyn"], "title": "Extending Action Logic with Omega Iteration", "comment": "technical report, draft", "summary": "We present a proof system that extends action logic by omega iteration, which is viewed as infinitary multiplicative conjunction. We prove cut admissibility and establish complexity bounds for the provability predicate."}
{"id": "2512.06906", "categories": ["cs.SE", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06906", "abs": "https://arxiv.org/abs/2512.06906", "authors": ["Wenjie Zhang", "Yun Lin", "Chun Fung Amos Kwok", "Xiwen Teoh", "Xiaofei Xie", "Frank Liauw", "Hongyu Zhang", "Jin Song Dong"], "title": "MINES: Explainable Anomaly Detection through Web API Invariant Inference", "comment": null, "summary": "Detecting the anomalies of web applications, important infrastructures for running modern companies and governments, is crucial for providing reliable web services. Many modern web applications operate on web APIs (e.g., RESTful, SOAP, and WebSockets), their exposure invites intended attacks or unintended illegal visits, causing abnormal system behaviors. However, such anomalies can share very similar logs with normal logs, missing crucial information (which could be in database) for log discrimination. Further, log instances can be also noisy, which can further mislead the state-of-the-art log learning solutions to learn spurious correlation, resulting superficial models and rules for anomaly detection. In this work, we propose MINES which infers explainable API invariants for anomaly detection from the schema level instead of detailed raw log instances, which can (1) significantly discriminate noise in logs to identify precise normalities and (2) detect abnormal behaviors beyond the instrumented logs. Technically, MINES (1) converts API signatures into table schema to enhance the original database shema; and (2) infers the potential database constraints on the enhanced database schema to capture the potential relationships between APIs and database tables. MINES uses LLM for extracting potential relationship based on two given table structures; and use normal log instances to reject and accept LLM-generated invariants. Finally, MINES translates the inferred constraints into invariants to generate Python code for verifying the runtime logs. We extensively evaluate MINES on web-tamper attacks on the benchmarks of TrainTicket, NiceFish, Gitea, Mastodon, and NextCloud against baselines such as LogRobust, LogFormer, and WebNorm. The results show that MINES achieves high recall for the anomalies while introducing almost zero false positives, indicating a new state-of-the-art."}
{"id": "2512.07240", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.07240", "abs": "https://arxiv.org/abs/2512.07240", "authors": ["Filippo Bonchi", "Alessandro Di Giorgio", "Elena Di Lavore"], "title": "A Diagrammatic Basis for Computer Programming", "comment": null, "summary": "Tape diagrams provide a convenient graphical notation for arrows of rig categories, i.e., categories equipped with two monoidal products, $\\oplus$ and $\\otimes$. In this work, we introduce Kleene-Cartesian rig categories, namely rig categories where $\\otimes$ provides a Cartesian bicategory, while $\\oplus$ a Kleene bicategory. We show that the associated tape diagrams can conveniently deal with imperative programs and various program logic."}
{"id": "2512.06915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06915", "abs": "https://arxiv.org/abs/2512.06915", "authors": ["Kelin Fu", "Tianyu Liu", "Zeyu Shang", "Yingwei Ma", "Jian Yang", "Jiaheng Liu", "Kaigui Bian"], "title": "Multi-Docker-Eval: A `Shovel of the Gold Rush' Benchmark on Automatic Environment Building for Software Engineering", "comment": null, "summary": "Automated environment configuration is a critical bottleneck in scaling software engineering (SWE) automation. To provide a reliable evaluation standard for this task, we present Multi-Docker-Eval benchmark. It includes 40 real-world repositories spanning 9 programming languages and measures both success in achieving executable states and efficiency under realistic constraints. Our extensive evaluation of state-of-the-art LLMs and agent frameworks reveals key insights: (1) the overall success rate of current models is low (F2P at most 37.7%), with environment construction being the primary bottleneck; (2) model size and reasoning length are not decisive factors, and open-source models like DeepSeek-V3.1 and Kimi-K2 are competitive in both efficiency and effectiveness; (3) agent framework and programming language also have significantly influence on success rate. These findings provide actionable guidelines for building scalable, fully automated SWE pipelines."}
{"id": "2512.07349", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.07349", "abs": "https://arxiv.org/abs/2512.07349", "authors": ["Vikraman Choudhury", "Wind Wong"], "title": "Symmetries in Sorting", "comment": "In submission, comments welcome", "summary": "Sorting algorithms are fundamental to computer science, and their correctness criteria are well understood as rearranging elements of a list according to a specified total order on the underlying set of elements. As mathematical functions, they are functions on lists that perform combinatorial operations on the representation of the input list. In this paper, we study sorting algorithms conceptually as abstract sorting functions.\n  There is a canonical surjection from the free monoid on a set (lists of elements) to the free commutative monoid on the same set (multisets of elements). We show that sorting functions determine a section (right inverse) to this surjection satisfying two axioms, that do not presuppose a total order on the underlying set. Then, we establish an equivalence between (decidable) total orders on the underlying set and correct sorting functions.\n  The first part of the paper develops concepts from universal algebra from the point of view of functorial signatures, and gives constructions of free monoids and free commutative monoids in (univalent) type theory. Using these constructions, the second part of the paper develops the axiomatisation of sorting functions. The paper uses informal mathematical language, and comes with an accompanying formalisation in Cubical Agda."}
{"id": "2512.07022", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.07022", "abs": "https://arxiv.org/abs/2512.07022", "authors": ["Genevieve Caumartin", "Glaucia Melo"], "title": "Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization", "comment": "Accepted at BoatSE 2026", "summary": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent."}
{"id": "2512.07511", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.07511", "abs": "https://arxiv.org/abs/2512.07511", "authors": ["Zanzi Mihejevs", "Jules Hedges"], "title": "Canonical bidirectional typechecking", "comment": null, "summary": "We demonstrate that the checkable/synthesisable split in bidirectional typechecking coincides with existing dualities in polarised System L, also known as polarised $μ\\tildeμ$-calculus. Specifically, positive terms and negative coterms are checkable, and negative terms and positive coterms are synthesisable. This combines a standard formulation of bidirectional typechecking with Zeilberger's `cocontextual' variant. We extend this to ordinary `cartesian' System L using Mc Bride's co-de Bruijn formulation of scopes, and show that both can be combined in a linear-nonlinear style, where linear types are positive and cartesian types are negative. This yields a remarkable 3-way coincidence between the shifts of polarised System L, LNL calculi, and bidirectional calculi."}
{"id": "2512.07122", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07122", "abs": "https://arxiv.org/abs/2512.07122", "authors": ["Liping Han", "Tingting Nie", "Le Yu", "Mingzhe Hu", "Tao Yue"], "title": "RisConFix: LLM-based Automated Repair of Risk-Prone Drone Configurations", "comment": null, "summary": "Flight control software is typically designed with numerous configurable parameters governing multiple functionalities, enabling flexible adaptation to mission diversity and environmental uncertainty. Although developers and manufacturers usually provide recommendations for these parameters to ensure safe and stable operations, certain combinations of parameters with recommended values may still lead to unstable flight behaviors, thereby degrading the drone's robustness. To this end, we propose a Large Language Model (LLM) based approach for real-time repair of risk-prone configurations (named RisConFix) that degrade drone robustness. RisConFix continuously monitors the drone's operational state and automatically triggers a repair mechanism once abnormal flight behaviors are detected. The repair mechanism leverages an LLM to analyze relationships between configuration parameters and flight states, and then generates corrective parameter updates to restore flight stability. To ensure the validity of the updated configuration, RisConFix operates as an iterative process; it continuously monitors the drone's flight state and, if an anomaly persists after applying an update, automatically triggers the next repair cycle. We evaluated RisConFix through a case study of ArduPilot (with 1,421 groups of misconfigurations). Experimental results show that RisConFix achieved a best repair success rate of 97% and an optimal average number of repairs of 1.17, demonstrating its capability to effectively and efficiently repair risk-prone configurations in real time."}
{"id": "2512.07193", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07193", "abs": "https://arxiv.org/abs/2512.07193", "authors": ["Manthan Shenoy", "Andreas Rausch"], "title": "Towards Benchmarking Design Pattern Detection Under Obfuscation: Reproducing and Evaluating Attention-Based Detection Method", "comment": "Pre-peer-review version of the paper submitted to the Workshop Track of the European Conference on Software Architecture (ECSA 2025), Springer LNCS 15982. Dataset: https://github.com/manthan410/Benchmark_dpd_att. Version of Record: https://doi.org/10.1007/978-3-032-04403-7_13", "summary": "This paper investigates the semantic robustness of attention-based classifiers for design pattern detection, particularly focusing on their reliance on structural and behavioral semantics. We reproduce the DPDAtt, an attention-based design pattern detection approach using learning-based classifiers, and evaluate its performance under obfuscation. To this end, we curate an obfuscated version of the DPDAtt Corpus, where the name identifiers in code such as class names, method names, etc., and string literals like print statements and comment blocks are replaced while preserving control flow, inheritance, and logic. Our findings reveal that these trained classifiers in DPDAtt depend significantly on superficial syntactic features, leading to substantial misclassification when such cues are removed through obfuscation. This work highlights the need for more robust detection tools capable of capturing deeper semantic meanings in source code. We propose our curated Obfuscated corpus (containing 34 Java source files) as a reusable proof-of-concept benchmark for evaluating state-of-the-art design pattern detectors on their true semantic generalization capabilities."}
{"id": "2512.07261", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07261", "abs": "https://arxiv.org/abs/2512.07261", "authors": ["Yusei Ishimizu", "Takuto Yamauchi", "Sinan Chen", "Jinyu Cai", "Jialong Li", "Kenji Tei"], "title": "Automatic Syntax Error Repair for Discrete Controller Synthesis using Large Language Model", "comment": null, "summary": "Discrete Controller Synthesis (DCS) is a powerful formal method for automatically generating specifications of discrete event systems. However, its practical adoption is often hindered by the highly specialized nature of formal models written in languages such as FSP and FLTL. In practice, syntax errors in modeling frequently become an important bottleneck for developers-not only disrupting the workflow and reducing productivity, but also diverting attention from higher-level semantic design. To this end, this paper presents an automated approach that leverages Large Language Models (LLMs) to repair syntax errors in DCS models using a well-designed, knowledge-informed prompting strategy. Specifically, the prompting is derived from a systematic empirical study of common error patterns, identified through expert interviews and student workshops. It equips the LLM with DCS-specific domain knowledge, including formal grammar rules and illustrative examples, to guide accurate corrections. To evaluate our method, we constructed a new benchmark by systematically injecting realistic syntax errors into validated DCS models. The quantitative evaluation demonstrates the high effectiveness of the proposed approach in terms of repair accuracy and its practical utility regarding time, achieving a speedup of 3.46 times compared to human developers. The experimental replication suite, including the benchmark and prompts, is available at https://github.com/Uuusay1432/DCSModelRepair.git"}
{"id": "2512.07293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07293", "abs": "https://arxiv.org/abs/2512.07293", "authors": ["Roberto Verdecchia", "Justus Bogner"], "title": "The Human Need for Storytelling: Reflections on Qualitative Software Engineering Research With a Focus Group of Experts", "comment": "Published in ACM SIGSOFT Software Engineering Notes (SEN), Volume 51, Issue 1, 2026", "summary": "From its first adoption in the late 80s, qualitative research has slowly but steadily made a name for itself in what was, and perhaps still is, the predominantly quantitative software engineering (SE) research landscape. As part of our regular column on empirical software engineering (ACM SIGSOFT SEN-ESE), we reflect on the state of qualitative SE research with a focus group of experts. Among other things, we discuss why qualitative SE research is important, how it evolved over time, common impediments faced while practicing it today, and what the future of qualitative SE research might look like. Joining the conversation are Rashina Hoda (Monash University, Australia), Carolyn Seaman (University of Maryland, United States), and Klaas Stol (University College Cork, Ireland). The content of this paper is a faithful account of our conversation from October 25, 2025, which we moderated and edited for our column."}
{"id": "2512.07368", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.07368", "abs": "https://arxiv.org/abs/2512.07368", "authors": ["Alex R. Mattukat", "Timo Langstrof", "Horst Lichter"], "title": "Challenges in Developing Secure Software -- Results of an Interview Study in the German Software Industry", "comment": "This paper includes 6 pages, 1 table, 1 figure. It is an English translation of our paper published in the German journal \"Softwaretechnik Trends\": ISSN 0720-8928, vol. 45, no. 4, pp. 2-7, year 2025", "summary": "The damage caused by cybercrime makes the development of secure software inevitable. Although many tools and frameworks exist to support the development of secure software, statistics on cybercrime show no improvement in recent years. To understand the challenges software companies face in developing secure software, we conducted an interview study with 19 industry experts from 12 cross-industry companies. The results of our study show that the challenges are mainly due to high complexity, a lack of security awareness, and unsuitable processes, which are further exacerbated by an immediate lack of skilled personnel. This article presents our study and the challenges we identified, and derives potential research directions from them."}
{"id": "2512.07404", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07404", "abs": "https://arxiv.org/abs/2512.07404", "authors": ["Francisco Ribeiro", "Claudio Spiess", "Prem Devanbu", "Sarah Nadi"], "title": "Do LLMs Trust the Code They Write?", "comment": null, "summary": "Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code."}
{"id": "2512.07434", "categories": ["cs.SE", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.07434", "abs": "https://arxiv.org/abs/2512.07434", "authors": ["Bram Pellen", "María Belén Rodríguez", "Frits Vaandrager", "Petra van den Bos"], "title": "Systematic Evaluation of Black-Box Checking for Fast Bug Detection", "comment": "23 pages, 4 figures", "summary": "Combinations of active automata learning, model-based testing and model checking have been successfully used in numerous applications, e.g., for spotting bugs in implementations of major network protocols and to support refactoring of embedded controllers. However, in the large majority of these applications, model checking is only used at the very end, when no counterexample can be found anymore for the latest hypothesis model. This contrasts with the original proposal of black-box checking (BBC) by Peled, Vardi & Yannakakis, which applies model checking for all hypotheses, also the intermediate ones. In this article, we present the first systematic evaluation of the ability of BBC to find bugs quickly, based on 77 benchmarks models from real protocol implementations and controllers for which specifications of safety properties are available. Our main finding are: (a) In cases where the full model can be learned, BBC detects violations of the specifications with just 3.4% of the queries needed by an approach in which model checking is only used for the full model. (b) Even when the full model cannot be learned, BBC is still able to detect many violations of the specification. In particular, BBC manages to detect 94% of the safety properties violations in the challenging RERS 2019 industrial LTL benchmarks. (c) Our results also confirm that BBC is way more effective than existing MBT algorithms in finding deep bugs in implementations."}
{"id": "2512.07501", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07501", "abs": "https://arxiv.org/abs/2512.07501", "authors": ["Weilin Luo", "Xueyi Liang", "Haotian Deng", "Yanan Liu", "Hai Wan"], "title": "AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution", "comment": null, "summary": "Automatically synthesizing verifiable code from natural language requirements ensures software correctness and reliability while significantly lowering the barrier to adopting the techniques of formal methods. With the rise of large language models (LLMs), long-standing efforts at autoformalization have gained new momentum. However, existing approaches suffer from severe syntactic and semantic errors due to the scarcity of domain-specific pre-training corpora and often fail to formalize implicit knowledge effectively. In this paper, we propose AutoICE, an LLM-driven evolutionary search for synthesizing verifiable C code. It introduces the diverse individual initialization and the collaborative crossover to enable diverse iterative updates, thereby mitigating error propagation inherent in single-agent iterations. Besides, it employs the self-reflective mutation to facilitate the discovery of implicit knowledge. Evaluation results demonstrate the effectiveness of AutoICE: it successfully verifies $90.36$\\% of code, outperforming the state-of-the-art (SOTA) approach. Besides, on a developer-friendly dataset variant, AutoICE achieves a $88.33$\\% verification success rate, significantly surpassing the $65$\\% success rate of the SOTA approach."}
{"id": "2512.07814", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.07814", "abs": "https://arxiv.org/abs/2512.07814", "authors": ["Hua Yang", "Alejandro Velasco", "Sen Fang", "Bowen Xu", "Denys Poshyvanyk"], "title": "Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach", "comment": "21 pages, 8 figures", "summary": "Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks among different types. We investigate whether distinct PII types vary in their likelihood of being learned and leaked by LLM4Code, and whether this relationship is causal. Our methodology includes building a dataset with diverse PII types, fine-tuning representative models of different scales, computing training dynamics on real PII data, and formulating a structural causal model to estimate the causal effect of learnability on leakage. Results show that leakage risks differ substantially across PII types and correlate with their training dynamics: easy-to-learn instances such as IP addresses exhibit higher leakage, while harder types such as keys and passwords leak less frequently. Ambiguous types show mixed behaviors. This work provides the first causal evidence that leakage risks are type-dependent and offers guidance for developing type-aware and learnability-aware defenses for LLM4Code."}
{"id": "2512.07824", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07824", "abs": "https://arxiv.org/abs/2512.07824", "authors": ["Rabe Abdalkareem"], "title": "Studying the Role of Reusing Crowdsourcing Knowledge in Software Development", "comment": null, "summary": "Crowdsourcing platforms, such as Stack Overflow, have changed and impacted the software development practice. In these platforms, developers share and reuse their software development and programming experience. Therefore, a plethora of research work focused on crowdsourcing in software engineering and showed that, among other things, crowdsourced development tends to increase developers' productivity and reduce time-to-market. However, in crowdsourcing, the empirical studies of software quality are lacking, and simple questions, such as what developers use the crowdsourcing knowledge for, are unanswered.\n  Therefore, our research focused on studying the impact of reusing crowdsourcing knowledge on software projects. To do so, we conduct several large-scale empirical studies on some of the well-known crowdsourcing platforms, including Stack Overflow and npm. Our results showed that reusing knowledge from these crowdsourcing platforms has the potential to assist software development practice, specifically in the form of reusing crowdsourced code. However, using such knowledge affects the quality of the software in several aspects, such as making the software projects suffer from dependency overhead and increasing the maintenance effort. Based on these findings, we use the gained knowledge to make sound data-driven decisions where we examine software quality assurance methods to mitigate the risk of relying on crowd sourcing knowledge in software development. We examine the use of continuous integration (CI). Our analysis showed how CI can be improved to increase developers' productivity and save their resources."}
{"id": "2512.06242", "categories": ["cs.LO", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06242", "abs": "https://arxiv.org/abs/2512.06242", "authors": ["Ian J. Hayes", "Larissa A. Meinicke", "Cliff B. Jones"], "title": "Reasoning about concurrent loops and recursion with rely-guarantee rules", "comment": "21 pages, 2 figures", "summary": "The objective of this paper is to present general, mechanically verified, refinement rules for reasoning about recursive programs and while loops in the context of concurrency. Unlike many approaches to concurrency, we do not assume that expression evaluation is atomic. We make use of the rely-guarantee approach to concurrency that facilitates reasoning about interference from concurrent threads in a compositional manner. Recursive programs can be defined as fixed points over a lattice of commands and hence we develop laws for reasoning about fixed points. Loops can be defined in terms of fixed points and hence the laws for recursion can be applied to develop laws for loops."}
