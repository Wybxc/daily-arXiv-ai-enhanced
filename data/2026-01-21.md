<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 2]
- [cs.PL](#cs.PL) [Total: 10]
- [cs.SE](#cs.SE) [Total: 59]
- [cs.LO](#cs.LO) [Total: 8]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Learning Deterministic Finite-State Machines from the Prefixes of a Single String is NP-Complete](https://arxiv.org/abs/2601.12621)
*Radu Cosmin Dumitru,Ryo Yoshinaka,Ayumi Shinohara*

Main category: cs.FL

TL;DR: 研究前缀封闭样本下计算最小DFA的复杂度，证明即使样本为单个二进制字符串的前缀，问题仍是NP-hard


<details>
  <summary>Details</summary>
Motivation: 已知计算与给定正负样本一致的最小DFA是NP-hard问题，前人研究了不同输入样本条件下的复杂度。本文研究前缀封闭样本（等价于计算与运行观测一致的最小Moore机）的计算复杂度。

Method: 通过理论分析证明，当样本集包含所有二进制字符串的前缀时，该问题在近似意义下是NP-hard的；进一步证明即使样本集仅包含单个二进制字符串的前缀，作为决策问题仍然是NP-hard的。

Result: 证明了前缀封闭样本下计算最小DFA是NP-hard的，且难以近似；即使样本仅来自单个二进制字符串的前缀，决策问题仍是NP-hard；该结论也适用于Mealy机。

Conclusion: 前缀封闭样本并不能简化最小DFA计算问题的复杂度，即使在最受限的情况下（单个字符串的前缀）问题仍然是NP-hard的，这为自动机最小化问题的复杂度边界提供了新的理解。

Abstract: It is well known that computing a minimum DFA consistent with a given set of positive and negative examples is NP-hard. Previous work has identified conditions on the input sample under which the problem becomes tractable or remains hard. In this paper, we study the computational complexity of the case where the input sample is prefix-closed. This formulation is equivalent to computing a minimum Moore machine consistent with observations along its runs. We show that the problem is NP-hard to approximate when the sample set consists of all prefixes of binary strings. Furthermore, we show that the problem remains NP-hard as a decision problem even when the sample set consists of the prefixes of a single binary string. Our argument also extends to the corresponding problem for Mealy machines.

</details>


### [2] [From Trees to Tree-Like: Distribution and Synthesis for Asynchronous Automata](https://arxiv.org/abs/2601.14078)
*Mathieu Lehaut,Anca Muscholl,Nir Piterman*

Main category: cs.FL

TL;DR: 本文重新审视了受限设置下Zielonka异步自动机的分布与综合构造，提出了树状架构下的二次分布构造，并将分布式控制器综合的可判定性边界从树架构扩展到树状架构。


<details>
  <summary>Details</summary>
Motivation: 研究受限设置下异步自动机的分布与综合问题，旨在改进现有构造的复杂度，扩展可判定性边界，为分布式系统设计提供更高效的算法。

Method: 1. 提出树状架构下的二次分布构造，其中架构具有底层生成树且通信在树上局部进行；2. 将分布式控制器综合问题扩展到树状架构，保持原有的复杂度界限。

Result: 1. 为树状架构设计了简单的二次分布构造，改进了三角化依赖字母表的指数构造；2. 证明了树状架构下分布式控制器综合的可判定性，复杂度保持为Tower_d(n)，其中n为系统规模，d为进程树深度。

Conclusion: 本文成功将异步自动机的分布构造复杂度从指数级改进到二次级，并将分布式控制器综合的可判定性边界从树架构扩展到更一般的树状架构，为分布式系统设计提供了更高效的理论基础。

Abstract: We revisit constructions for distribution and synthesis of Zielonka's asynchronous automata in restricted settings. We show first a simple, quadratic, distribution construction for asynchronous automata, where the process architecture is tree-like. An architecture is tree-like if there is an underlying spanning tree of the architecture and communications are local on the tree. This quadratic distribution result generalizes the known construction for tree architectures and improves on an older, exponential construction for triangulated dependence alphabets. Lastly we consider the problem of distributed controller synthesis and show that it is decidable for tree-like architectures. This extends the decidability boundary from tree architectures to tree-like keeping the same $\text{Tower}_d(n)$ complexity bound, where $n$ is the size of the system and $d \ge 0$ the depth of the process tree.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Context-Free Grammar Inference for Complex Programming Languages in Black Box Settings](https://arxiv.org/abs/2601.12385)
*Feifei Li,Xiao Chen,Xiaoyu Sun,Xi Xiao,Shaohua Wang,Yong Ding,Sheng Wen,Qing Li*

Main category: cs.PL

TL;DR: Crucio是一个新的语法推断方法，通过构建分解森林和分布矩阵来提取短示例，能够高效推断复杂编程语言（如C、C++、Java）的语法，在时间和效果上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语法推断工具（如Arvada、Treevada、Kedavra）无法在合理时间内处理复杂编程语言（C、C++、Java）的大型文件，存在效率低下和过度泛化限制等问题。

Method: 提出Crucio方法，构建分解森林来提取短示例，通过分布矩阵进行词法和语法推断，避免了直接处理完整输入文件的效率问题。

Result: Crucio是唯一能在合理时间内成功推断复杂编程语言语法的方法（非终结符数量比先前基准多23倍）。在简单基准测试中，相比Treevada和Kedavra，平均召回率分别提高1.37倍和1.19倍，F1分数分别提高1.21倍和1.13倍。

Conclusion: Crucio通过创新的分解森林和分布矩阵方法，有效解决了复杂编程语言语法推断的扩展性问题，在效率和准确性上都显著优于现有技术。

Abstract: Grammar inference for complex programming languages remains a significant challenge, as existing approaches fail to scale to real world datasets within practical time constraints. In our experiments, none of the state-of-the-art tools, including Arvada, Treevada and Kedavra were able to infer grammars for complex languages such as C, C++, and Java within 48 hours. Arvada and Treevada perform grammar inference directly on full-length input examples, which proves inefficient for large files commonly found in such languages. While Kedavra introduces data decomposition to create shorter examples for grammar inference, its lexical analysis still relies on the original inputs. Additionally, its strict no-overgeneralization constraint limits the construction of complex grammars.
  To overcome these limitations, we propose Crucio, which builds a decomposition forest to extract short examples for lexical and grammar inference via a distributional matrix. Experimental results show that Crucio is the only method capable of successfully inferring grammars for complex programming languages (where the number of nonterminals is up to 23x greater than in prior benchmarks) within reasonable time limits. On the prior simple benchmark, Crucio achieves an average recall improvement of 1.37x and 1.19x over Treevada and Kedavra, respectively, and improves F1 scores by 1.21x and 1.13x.

</details>


### [4] [An Introduction to Razborov's Flag Algebra as a Proof System for Extremal Graph Theory](https://arxiv.org/abs/2601.12741)
*Gyeongwon Jeong,Seonghun Park,Hongseok Yang*

Main category: cs.PL

TL;DR: 本文从逻辑角度介绍Razborov的标志代数框架，将其呈现为语法、语义和证明策略的形式，特别关注通过标记变体证明不等式并利用伴随对概念转移到未标记设置的策略。


<details>
  <summary>Details</summary>
Motivation: 向计算机科学家（特别是逻辑、编程语言、自动验证和形式方法领域的研究者）介绍标志代数这一强大的图论工具，采用更接近形式逻辑的风格，便于计算机科学背景的研究者理解和应用。

Method: 从逻辑视角重新表述标志代数，包括语法、语义和证明策略。重点解释通过标记变体证明不等式，然后利用"向下算子"转移到未标记设置的策略，强调这一转移机制依赖于伴随对的概念。

Result: 成功将标志代数框架以计算机科学家熟悉的逻辑形式呈现，阐明了证明策略中伴随对的作用，并通过Mantel定理和Goodman的Ramsey多重性界等代表性例子展示了如何在标志代数框架中进行符号化数学论证。

Conclusion: 标志代数不仅是一个强大的图论工具，其逻辑结构和伴随对的概念与计算机科学中的Galois连接和范畴伴随有密切联系，为计算机科学家理解和应用这一框架提供了桥梁。

Abstract: Razborov's flag algebra forms a powerful framework for deriving asymptotic inequalities between induced subgraph densities, underpinning many advances in extremal graph theory. This survey introduces flag algebra to computer scientists working in logic, programming languages, automated verification, and formal methods. We take a logical perspective on flag algebra and present it in terms of syntax, semantics, and proof strategies, in a style closer to formal logic. One popular proof strategy derives valid inequalities by first proving inequalities in a labelled variant of flag algebra and then transferring them to the original unlabelled setting using the so-called downward operator. We explain this strategy in detail and highlight that its transfer mechanism relies on the notion of what we call an adjoint pair, reminiscent of Galois connections and categorical adjunctions, which appear frequently in work on automated verification and programming languages. Along the way, we work through representative examples, including Mantel's theorem and Goodman's bound on Ramsey multiplicity, to illustrate how mathematical arguments can be carried out symbolically in the flag algebra framework.

</details>


### [5] [A Formally Verified Procedure for Width Inference in FIRRTL](https://arxiv.org/abs/2601.12813)
*Keyin Wang,Xiaomu Shi,Jiaxiang Liu,Zhilin Wu,Taolve Chen,Fu Song,David N. Jansen*

Main category: cs.PL

TL;DR: FIRRTL宽度推断问题的形式化验证解决方案：提出完整算法，在Rocq中实现并证明正确性，提取OCaml代码，性能优于官方编译器。


<details>
  <summary>Details</summary>
Motivation: FIRRTL作为RTL硬件设计的中间表示语言，其宽度推断问题在主流编译器（如firtool）中可能失败，需要更可靠、完整的解决方案。

Method: 证明FIRRTL宽度约束存在唯一最小解，提出完整求解算法，在Rocq定理证明器中实现并验证正确性，然后提取为OCaml实现。

Result: 实现了第一个形式化验证的InferWidths通道，实验表明能解决比官方编译器更多的实例，且通常具有高效率。

Conclusion: 通过形式化方法为FIRRTL宽度推断提供了可靠解决方案，证明了理论可行性并实现了实用工具，提升了编译器的可靠性。

Abstract: FIRRTL is an intermediate representation language for Register Transfer Level (RTL) hardware designs. In FIRRTL programs, the bit widths of many components are not specified explicitly and must be inferred during compilation. In mainstream FIRRTL compilers, such as the official compiler firtool, width inference is conducted by a compilation pass referred to as InferWidths, which may fail even for simple FIRRTL programs. In this paper, we thoroughly investigate the width inference problem for FIRRTL programs. We show that, if the constraints obtained from a FIRRTL program are satisfiable, there exists a unique least solution. Based on this result, we propose a complete procedure for solving the width inference problem. We implement it in the interactive theorem prover Rocq and prove its functional correctness. From the Rocq implementation, we extract an OCaml implementation, which is the first formally verified implementation of the InferWidths pass. Extensive experiments demonstrate that our approach can solve more instances than the official InferWidths pass in firtool, normally with high efficiency.

</details>


### [6] [Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs](https://arxiv.org/abs/2601.12943)
*Han Xu,Di Wang*

Main category: cs.PL

TL;DR: λ_amor^na 是一个非仿射的AARA风格依赖类型系统，用于高阶函数程序的资源推理，通过解耦资源和类型来解决传统仿射类型系统在高阶程序资源分析中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的仿射类型系统在分析高阶程序（特别是涉及部分应用的情况）时，无法精确推导资源消耗行为。主要问题在于：(1) 类型与资源的紧密耦合；(2) 仿射类型机制与高阶类型机制之间的冲突。

Method: 提出λ_amor^na系统，采用非仿射类型机制，通过依赖类型将资源与类型解耦，允许在类型层面表达独立的潜在函数（potential functions），而不是将资源信息嵌入普通类型中。

Result: 形式化了λ_amor^na的语法和语义，证明了其可靠性（soundness），保证了资源界限的正确性。通过多个具有挑战性的经典和高阶示例展示了系统的表达能力和组合性。

Conclusion: λ_amor^na通过解耦资源和类型，采用非仿射依赖类型系统，成功解决了传统仿射类型系统在高阶函数资源分析中的局限性，能够更精确地推导高阶程序的资源行为。

Abstract: Static resource analysis determines the resource consumption (e.g., time complexity) of a program without executing it. Among the numerous existing approaches for resource analysis, affine type systems have been one dominant approach. However, these affine type systems fall short of deriving precise resource behavior of higher-order programs, particularly in cases that involve partial applications.
  This article presents λ_\ms{amor}^\ms{na}}, a non-affine AARA-style dependent type system for resource reasoning about higher-order functional programs. The key observation is that the main issue in previous approaches comes from (i) the close coupling of types and resources, and (ii) the conflict between affine and higher-order typing mechanisms. To derive precise resource behavior of higher-order functions, λ_\ms{amor}^\ms{na}} decouples resources from types and follows a non-affine typing mechanism. The non-affine type system of λ_\ms{amor}^\ms{na}} achieves this by using dependent types, which allows expressing type-level potential functions separate from ordinary types. This article formalizes λ_\ms{amor}^\ms{na}}'s syntax and semantics, and proves its soundness, which guarantees the correctness of resource bounds. Several challenging classic and higher-order examples are presented to demonstrate the expressiveness and compositionality of λ_\ms{amor}^\ms{na}}'s reasoning capability.

</details>


### [7] [Functional Logic Program Transformations](https://arxiv.org/abs/2601.13224)
*Michael Hanus,Steven Libby*

Main category: cs.PL

TL;DR: 使用函数逻辑编程实现程序转换，通过部分定义和非确定性操作简化实现，并与确定性方法比较性能


<details>
  <summary>Details</summary>
Motivation: 程序转换工具（如编译器、分析器、验证器）需要在中间表示（如AST）上进行转换，实现这些转换通常很复杂，需要遍历完整语法树并在节点应用各种变换

Method: 提出使用函数逻辑编程的特性，将程序转换编写为部分定义和非确定性操作，利用函数逻辑语言Curry及其中间表示FlatCurry实现

Result: 比较了非确定性方法与确定性转换方法的性能，评估了在Curry语言和FlatCurry中间表示上的实现效果

Conclusion: 函数逻辑编程的特性有助于以紧凑且易于理解的方式实现程序转换，虽然非确定性实现可能带来性能开销，但提供了更简洁的实现方式

Abstract: Many tools used to process programs, like compilers, analyzers, or verifiers, perform transformations on their intermediate program representation, like abstract syntax trees. Implementing such program transformations is a non-trivial task, since it is necessary to iterate over the complete syntax tree and apply various transformations at nodes in a tree. In this paper we show how the features of functional logic programming are useful to implement program transformations in a compact and comprehensible manner. For this purpose, we propose to write program transformations as partially defined and non-deterministic operations. Since the implementation of non-determinism usually causes some overhead compared to deterministically defined operations, we compare our approach to a deterministic transformation method. We evaluate these alternatives for the functional logic language Curry and its intermediate representation FlatCurry which is used in various analysis and verification tools and compilers.

</details>


### [8] [Reduction for Structured Concurrent Programs](https://arxiv.org/abs/2601.13341)
*Namratha Gangamreddypalli,Constantin Enea,Shaz Qadeer*

Main category: cs.PL

TL;DR: 提出一种新颖的归约技术，统一了两种关键进展：将并行组合替换为顺序组合，以及扩展Lipton归约以支持包含过程调用的原子段，从而显著扩展了基于归约的推理范围。


<details>
  <summary>Details</summary>
Motivation: 基于Lipton移动子的交换性推理是验证并发程序的强大技术，但将其扩展到软件系统中常规使用的特性（如过程和并行组合）仍然是一个重大挑战。

Method: 引入一种结构化并发程序的新颖归约技术，统一了两种关键进展：1) 将并行组合替换为顺序组合的归约策略；2) 扩展Lipton归约以支持包含（可能递归）过程调用的原子段。这两种基础策略可以任意组合。

Result: 在Civl中实现了该技术，并在多个具有挑战性的案例研究中证明了其有效性，包括快照对象、容错可线性化寄存器、FLASH缓存一致性协议和Two-Phase Commit的非平凡变体。

Conclusion: 该工作通过统一两种关键归约策略并支持任意组合，极大地扩展了基于归约推理的范围和灵活性，为结构化并发程序的验证提供了更强大的工具。

Abstract: Commutativity reasoning based on Lipton's movers is a powerful technique for verification of concurrent programs. The idea is to define a program transformation that preserves a subset of the initial set of interleavings, which is sound modulo reorderings of commutative actions. Scaling commutativity reasoning to routinely-used features in software systems, such as procedures and parallel composition, remains a significant challenge.
  In this work, we introduce a novel reduction technique for structured concurrent programs that unifies two key advances. First, we present a reduction strategy that soundly replaces parallel composition with sequential composition. Second, we generalize Lipton's reduction to support atomic sections containing (potentially recursive) procedure calls. Crucially, these two foundational strategies can be composed arbitrarily, greatly expanding the scope and flexibility of reduction-based reasoning. We implemented this technique in Civl and demonstrated its effectiveness on a number of challenging case studies, including a snapshot object, a fault-tolerant and linearizable register, the FLASH cache coherence protocol, and a non-trivial variant of Two-Phase Commit.

</details>


### [9] [Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring](https://arxiv.org/abs/2601.13727)
*Bart Jacobs*

Main category: cs.PL

TL;DR: VeriFast工具通过扩展功能，在成功验证Rust程序后生成Rocq证明脚本，从而增强其在安全关键领域的适用性


<details>
  <summary>Details</summary>
Motivation: VeriFast作为领先的形式验证工具，其本身约30K行OCaml代码未经形式化验证，可能存在导致错误报告程序正确性的bug，这限制了其在安全关键领域的应用

Method: 采用"提示镜像"技术：记录VeriFast符号执行运行的关键信息，并利用这些信息在Rocq中指导重放运行，生成Rocq证明脚本

Result: 成功扩展VeriFast，使其在验证Rust程序后能够生成Rocq证明脚本，证明程序相对于Rocq编码的Rust公理语义的正确性

Conclusion: 通过生成Rocq证明脚本，显著增强了VeriFast在安全关键领域的适用性，解决了工具本身未经形式化验证带来的可靠性问题

Abstract: VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.

</details>


### [10] [Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)](https://arxiv.org/abs/2601.13991)
*Darion Haase,Kevin Batz,Adrian Gallus,Benjamin Lucien Kaminski,Joost-Pieter Katoen,Lutz Klinkenberg,Tobias Winkler*

Main category: cs.PL

TL;DR: 论文提出基于占用测度的概率循环不变量（occupation invariants），用于程序精确推理，并开发了自动模板合成方法。


<details>
  <summary>Details</summary>
Motivation: 概率编程中的核心计算任务是从先验分布推断后验分布，这对包含循环或无限递归的表达性语言尤其困难。现有文献多关注统计近似方法，本文旨在解决数学精确推理问题。

Method: 引入占用测度（occupation measure）概念，将程序状态与其期望访问次数关联，基于此定义占用不变量。提出自动模板合成方法，通过生成函数编码占用不变量。

Result: 开发了基于占用不变量的自动推理系统，并在基准测试集上进行了实现和评估，证明该方法能有效进行精确推理。

Conclusion: 占用不变量为概率循环分析提供了新视角，与传统的概率鞅方法形成对偶，能考虑初始分布并自然获得正几乎必然终止性证明，实现了自动化的精确推理。

Abstract: A fundamental computational task in probabilistic programming is to infer a program's output (posterior) distribution from a given initial (prior) distribution. This problem is challenging, especially for expressive languages that feature loops or unbounded recursion. While most of the existing literature focuses on statistical approximation, in this paper we address the problem of mathematically exact inference.
  To achieve this for programs with loops, we rely on a relatively underexplored type of probabilistic loop invariant, which is linked to a loop's so-called occupation measure. The occupation measure associates program states with their expected number of visits, given the initial distribution. Based on this, we derive the notion of an occupation invariant. Such invariants are essentially dual to probabilistic martingales, the predominant technique for formal probabilistic loop analysis in the literature. A key feature of occupation invariants is that they can take the initial distribution into account and often yield a proof of positive almost sure termination as a by-product.
  Finally, we present an automatic, template-based invariant synthesis approach for occupation invariants by encoding them as generating functions. The approach is implemented and evaluated on a set of benchmarks.

</details>


### [11] [Verifying Floating-Point Programs in Stainless](https://arxiv.org/abs/2601.14059)
*Andrea Gilot,Axel Bergström,Eva Darulova*

Main category: cs.PL

TL;DR: Stainless验证器扩展支持浮点数，成为首个支持Scala子集（含多态、递归、高阶函数）的浮点数自动验证工具，验证Scala数学API函数并确保公理正确性。


<details>
  <summary>Details</summary>
Motivation: 现有验证工具缺乏对浮点数的自动化验证支持，特别是对于包含多态、递归和高阶函数的Scala语言子集。需要为实际编程中的浮点运算提供可靠的验证能力。

Method: 扩展Stainless验证器，采用类似KeY验证器的数学函数公理化方法，但进一步支持所有Scala数学API函数，并在Stainless内部验证公理的正确性。

Result: 在GitHub真实代码基准测试中验证了浮点支持的有效性，能够验证输出范围、特殊值不存在等规范，或在规范不成立时生成反例。

Conclusion: 成功实现了首个支持Scala子集浮点数自动验证的工具，为实际编程中的浮点运算验证提供了实用解决方案。

Abstract: We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.

</details>


### [12] [Partial Reductions for Kleene Algebra with Linear Hypotheses](https://arxiv.org/abs/2601.14114)
*Liam Chung,Tobias Kappé*

Main category: cs.PL

TL;DR: 提出一种基于自动机的构造方法，用于为广泛类别的假设自动推导出归约函数，这些归约可以是部分的，从而获得部分完备性，能够自动证明比现有工作更多的等价关系。


<details>
  <summary>Details</summary>
Motivation: Kleene代数（KA）虽然具有可判定的完备等式理论，但无法证明特定程序之间的等价性。传统上通过添加假设并使用归约函数来提升表达能力，但显式构造归约需要大量人工工作，且由于正则性约束，并非所有表达式和假设组合都存在归约。

Method: 提出一种基于自动机的构造方法，能够机械地为广泛类别的假设推导出归约函数。这些归约可以是部分的，当归约函数是部分函数时，它们在其定义域内提供完备性。

Result: 该方法能够自动建立比现有工作更多的等价关系的可证明性，通过部分归约实现部分完备性，扩展了可处理表达式和假设组合的范围。

Conclusion: 提出的自动机构造方法能够自动生成归约函数，包括部分归约，从而在更广泛的假设类别下实现部分完备性，显著减少了人工构造归约的工作量，并扩展了可证明等价关系的范围。

Abstract: Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis.
  We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [13] [Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines](https://arxiv.org/abs/2601.11647)
*Aniket Abhishek Soni,Milan Parikh,Rashi Nimesh Kumar Dhenia,Jubin Abhishek Soni,Ayush Raj Jha,Sneja Mitinbhai Shah*

Main category: cs.SE

TL;DR: 本文提出了一种基于强化学习的CI/CD管道动态优化方法，通过RL代理实时决策测试执行策略，相比静态基线可提升30%吞吐量并减少25%测试时间，同时保持缺陷遗漏率低于5%。


<details>
  <summary>Details</summary>
Motivation: 现代软件交付中CI/CD管道至关重要，但静态工作流在系统扩展时会产生效率低下问题。需要动态优化CI/CD工作流程以提高效率。

Method: 将CI/CD管道建模为马尔可夫决策过程，训练强化学习代理在运行时做出决策（如选择完整测试、部分测试或不测试），开发可配置的CI/CD仿真环境进行评估。

Result: RL优化管道相比静态基线实现：吞吐量提升最高30%，测试执行时间减少约25%，缺陷遗漏率保持在5%以下。代理学会为低风险提交选择性跳过或简化测试。

Conclusion: 强化学习能够实现自适应和智能的DevOps工作流，为更高效、弹性和可持续的CI/CD自动化提供了实用途径。

Abstract: Continuous Integration and Continuous Deployment (CI/CD) pipelines are central to modern software delivery, yet their static workflows often introduce inefficiencies as systems scale. This paper proposes a reinforcement learning (RL) based approach to dynamically optimize CI/CD pipeline workflows. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions such as selecting full, partial, or no test execution in order to maximize throughput while minimizing testing overhead.
  A configurable CI/CD simulation environment is developed to evaluate the approach across build, test, and deploy stages. Experimental results show that the RL optimized pipeline achieves up to a 30 percent improvement in throughput and approximately a 25 percent reduction in test execution time compared to static baselines, while maintaining a defect miss rate below 5 percent. The agent learns to selectively skip or abbreviate tests for low risk commits, accelerating feedback cycles without significantly increasing failure risk.
  These results demonstrate the potential of reinforcement learning to enable adaptive and intelligent DevOps workflows, providing a practical pathway toward more efficient, resilient, and sustainable CI/CD automation.

</details>


### [14] [Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey](https://arxiv.org/abs/2601.11655)
*Caihua Li,Lianghong Guo,Yanlin Wang,Daya Guo,Wei Tao,Zhenyu Shan,Mingwei Liu,Jiachi Chen,Haoyu Song,Duyu Tang,Hongyu Zhang,Zibin Zheng*

Main category: cs.SE

TL;DR: 该论文对AI解决软件工程问题（issue resolution）领域进行了系统性综述，涵盖数据构建、方法学、质量分析和未来方向


<details>
  <summary>Details</summary>
Motivation: 问题解决是软件工程中的复杂任务，SWE-bench等基准测试显示大型语言模型在此任务上表现困难，这推动了自主编码代理的发展，需要对该新兴领域进行系统性梳理

Method: 采用系统性综述方法：1) 分析数据构建管道（自动收集与合成方法）；2) 全面分析方法学（无训练框架及其模块组件、基于训练的技术如监督微调和强化学习）；3) 讨论数据质量和代理行为的关键分析；4) 探讨实际应用

Result: 建立了该领域的系统性知识框架，创建了开源资源库（Awesome-Issue-Resolution），为研究者和实践者提供动态资源

Conclusion: 识别了该领域的关键挑战，并提出了未来研究的有前景方向，通过开源资源库促进该领域的持续发展

Abstract: Issue resolution, a complex Software Engineering (SWE) task integral to real-world development, has emerged as a compelling challenge for artificial intelligence. The establishment of benchmarks like SWE-bench revealed this task as profoundly difficult for large language models, thereby significantly accelerating the evolution of autonomous coding agents. This paper presents a systematic survey of this emerging domain. We begin by examining data construction pipelines, covering automated collection and synthesis approaches. We then provide a comprehensive analysis of methodologies, spanning training-free frameworks with their modular components to training-based techniques, including supervised fine-tuning and reinforcement learning. Subsequently, we discuss critical analyses of data quality and agent behavior, alongside practical applications. Finally, we identify key challenges and outline promising directions for future research. An open-source repository is maintained at https://github.com/DeepSoftwareAnalytics/Awesome-Issue-Resolution to serve as a dynamic resource in this field.

</details>


### [15] [The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes](https://arxiv.org/abs/2601.11659)
*Aaron Adcock,Aayushi Srivastava,Abhimanyu Dubey,Abhinav Jauhri,Abhinav Pande,Abhinav Pandey,Abhinav Sharma,Abhishek Kadian,Abhishek Kumawat,Adam Kelsey,Adam Stelle,Adeel Cheema,Adela Kabiljo,Adina Katz,Adithya Gangidi,Aditya Tayade,Adolfo Victoria,Adrian Samatan Alastuey,Adrien Conrath,Afroz Mohiuddin,Ahmed Sharif,Ahnaf Siddiqui,Ahuva Goldstand,Aijung Li,Aidan Boyd,Aidin Kazemi Daliri,Aisha Iqbal,Ajay Menon,Ajit Mathews,Akhil Mathur,Akshat Agarwal,Alan Schelten,Alana Shine,Alejandro Castillejo Muñoz,Aleksei Guliaev,Alex Radovic,Alex Song,Alex Vaughan,Alexander Simeonov,Alexandre Rezende,Alexandre Rezende,Alexei Baevski,Alexey Roubaud,Allen Ma,Alvin Lee,Alyssa Pereira,Aman Ahmed,Aman Shankar,Amanda Kallet,Amar Budhiraja,Ameya Khandekar,Amine Benhalloum,Amir Gershman,Amit Nagpal,Amit Zohar,Amr Sharaf,Anant Desai,Anastasia Razdaibiedina,Anca Agape,Andranik Kurghinyan,Andre Perunicic,Andrea Madotto,Andrei Darabanov,Andrés Alvarado,Andrew Brown,Andrew Cohen,Andrew Fang,Andrew Freeman,Andrew Gallagher,Andrew Gu,Andrew Prasetyo Jo,Andrew Ryan,Andrew Steffen,Andrew Wei,Andrey Rusakov,Andrii Golovei,Andy Shang,Angela Fan,Angela Fan,Angela Flewellen,Animesh Pathak,Anirudh Goyal,Ankit Ramchandani,Ankur Pai,Ankur Singh,Ankush Garg,Anlu Xing,Anna Cai,Anna Grosul,Anna Prochowska,Anna Sun,Annie Dong,Annie Franco,Anqi Hu,Anshul Chawla,Anthony Hartshorn,Antonia Sheng,Antony Thomas,Anuj Goyal,Anusha De,Anvit Bodiwala,Anvit Bodiwala,Aobo Yang,Aparajita Saraf,Apurva Samudra,Aran Mun,Arash Rahnama,Archi Mitra,Archie Sravankumar,Archit Gupta,Aria Haghighi,Ariel Stolerman,Arkabandhu Chowdhury,Arnab Choudhury,Artem Korenev,Arthur Guo,Arthur Hinsvark,Arun Mallya,Arvind Neelakantan,Arya Talebzadeh,Ashish Shah,Ashmitha Jeevaraj Shetty,Ashwin Bharambe,Asif Islam,Aston Zhang,Austen Gregerson,Avi Lewis,Aya Ibrahim,Ayaz Minhas,Ayelet Dahan,Ayelet Regev Dabah,Bangsheng Tang,Bar Ulman,Bardiya Sadeghi,Bartosz Jedrzejewski,Barys Skarabahaty,Beibei Zhu,Beibin Li,Ben Bharier,Benjamin Leonhardi,Benjamin Muller,Bennett Plessala,Bernie Huang,Beth Loyd,Bhargavi Paranjape,Bhavik Sheth,Bill Bonner,Bill Holland,Bill Wang,Bingzhe Liu,Binh Tang,Bo Liu,Bo Wu,Boduo Li,Bokai Yu,Bor-Chun Chen,Boris Araya,Boris Vidolov,Botao Chen,Boya Peng,Boyu Ni,Bradley Davis,Bram Wasti,Brandon Adams,Brandon Taylor,Brandon Wu,Brant Swidler,Brian Chiang,Brian Clerkin,Brian Fuller,Brooks Cutter,Bruno Novais,Bryan Gmyrek,Bysshe Easton,Cait Campos,Canaan Case,Carl Chengyan Fu,Carly Burton,Caro Diaz,Catherine Cole,Ce Liu,Cedric Fougerat,Cen Peng,Cen Peng,Cen Zhao,Changhan Wang,Changkyu Kim,Chantal Shaib,Chao Zhou,Charlotte Caucheteux,Chau Nguyen,Chawin Sitawarin,Chaya Nayak,Chelsea Asher,Chen Fan,Chen Zhu,Cheng Cheng,Cheng Zhang,Chenguang Zhu,Chengxiong Ruan,Chengzhu Yu,Chenheli Hua,Chenxi Whitehouse,Cheryl Holloway,Ching-Hsiang Chu,Ching-Yao Chuang,Chinmay Karande,Chirag Nagpal,Chloé Bakalar,Chloe Bi,Chris Cai,Chris Marra,Chris McConnell,Chris Thi,Chris Tindal,Chris Waterson,Christian Deverall,Christian Fuegen,Christian Keller,Christine Cheng,Christine Jou,Christine Smith,Christine Wang,Christoph Feichtenhofer,Christophe Touret,Christopher Luc,Christy Sauper,Chuanhao Zhuge,Chun-Yi Sung,Chunqiang Tang,Chunyang Wu,Clara Siegel,Cody Heale,Cody Wilbourn,Colin White,Congying Xia,Corinne Wong,Cornel Rat,Cristian Canton Ferrer,Cyrille Habis,Cyrus Nikolaidis,D Lohachov,Da Ju,Dalton Flanagan,Damien Allonsius,Damon Civin,Dan Johnson,Daniel Bolya,Daniel Francisco,Daniel Fried,Daniel Hawthorne,Daniel Haziza,Daniel Ho,Daniel Kreymer,Daniel Li,Daniel Machlab,Daniel McKinnon,Daniel Obenshain,Daniel Rodriguez,Daniel Song,Daniel Tse,Danielle Pintz,Danny Livshits,Daryl James Rodrigo,Dat Huynh,Daulet Askarov,David Brandfonbrener,David Esiobu,David Kant,David Levin,David Renardy,David Soofian,David Stevens,David Xu,David Zhang,Deep Shah,Delia David,Demi Douglas,Denis Boyda,Desh Raj,Devamanyu Hazarika,Dheeraj Mekala,Dhruv Choudhary,Dhruv Mahajan,Di Jin,Didac Suris Coll-Vinent,Didem Foss,Diego Garcia-Olano,Diego Perino,Dieuwke Hupkes,DiJia Su,Dilip Madathil,Dinesh Govindasamy,Dinesh Yeduguru,Dmitry Vengertsev,Dong He,Dong Li,Dong Wang,Dongzhuo Li,Duc Le,Dunant Hin,Dustin Holland,Duy Nguyen,Duy Nguyen,Ed Dowling,Eden Litt,Egor Lakomkin,Ehab AlBadawy,Ehsan K. Ardestani,Elad Eckstein,Elahe Dabir,Elaine Montgomery,Elina Lobanova,Elior Abramoviz,Eliot Hedeman,Elissa Li,Elizabeth Hilbert,Ellen Xiaoqing Tan,Elliot Yun,Elodie Stener,Emilian Stoimenov,Emilien Garreau,Emily Dinan,Emily Hahn,Emily Wood,Emma Li,Emmanuel Ademuwagun,Emrah Seker,Eric Alamillo,Eric Gan,Eric Han,Eric Huang,Eric Michael Smith,Eric-Tuan Le,Ernie Chang,Eryk Helenowski,Eslam Elnikety,Esteban Arcaute,Ethan Myers,Eugene Nho,Eugene Poliukhovych,Evan Dunbar,Evgeniy Litvinenko,Evrim Altıntaş,Eyal Hochman,Eyal Shtrauch,Fabian Mastenbroek,Faiza Zeb,Faizan Ahmad,Farhad Farahbakhshian,Fei Kou,Fei Sun,Feiyu Chen,Felix Chung,Feng Tian,Feng Xu,Filip Radenovic,Filippos Kokkinos,Francesco Barbieri,Francesco Caggioni,Francisco Esparza,Francisco Guzmán,Frank Kanayet,Frank Seide,Frank Zhang,Fred Lewis,Freda Huang,Fulton Wang,Gabriel Synnaeve,Gabriela Jacques-Silva,Gabriella Schwarz,Gaganjit Ghardhora,Gal Elfer,Garrett Dickson,Gaurav Chaurasia,Gautam Sewani,Geet Shingi,Gefei Zuo,Geonhwa Jeong,George Puthanpurackal,Georgia Swee,Gerard Moreno-Torres Bertran,Gil Keren,Gina Ling,Gjergji Stasa,Gobinda Saha,Gor Safran,Gordy French,Goutham Rajendran,Govind Thattai,Grace Cineas,Graeme Nail,Greg Fletcher,Grégoire Mialon,Griffin Adams,Grigory Sizov,Guan Pang,Hady Elsahar,Hai Dang Tran,Hailey Nguyen,Haiping Wu,Hakan Inan,Hamid Eghbalzadeh,Han Fang,Han Zou,Hannah Doyle,Hannah Korevaar,Hannah Wang,Hannah Werbel,Hanwen Zha,Hany Morsy,Hao Ma,Haoci Zhang,Haonan Sun,Haozhu Wang,Hardik Shah,Haroun Habeeb,Harrison Rudolph,Harsh Gupta,Harsh Poddar,Harshil Parikh,Hejia Zhang,Heming Wang,Hengduo Li,Himanshu Sharma,Hoang Phi Nguyen,Hongbo Zhang,Honghao Qiu,Hongjiang Lv,Hongli Xu,Hongyuan Zhan,Hossein Hamooni,Howard Huang,Hu Xu,Hugo Laurençon,Hugo Touvron,Hung Dinh,Hunter Goldman,Hussein Mehanna,Huy Nguyen,Hweimi Tsuo,Ian Graves,Ian Yu,Ibrahim Damlaj,Idan Cohen,Igor Tufanov,Ilan Goldenstein,Ilias Leontiadis,Iliyan Zarov,Imad Ahmed,Innocent Djiofack,Iosif Spulber,Irina-Elena Veliche,Isabella Ramos,Ishan Misra,Itai Gal,Ivan Evtimov,Ivan Evtimov,Ivan Obraztsov,Jack Wu,Jacqueline Romero Vertino,Jaemo Koo,Jaewon Lee,Jake Jung,Jake Weissman,James Beldock,James Crnkovich,James Grinage,James Hongyi Zeng,James Kohli,James Tian,Jamie Cahill,Jan Geffert,Jan Seidel,Jan Seidel,Janey Tracey,Jang Hyun Cho,Janice Wei,Jarrod Kahn,Jasmyn Howell,Jason Long Vu,Jason Park,Jason Yan,Jason Yip,Jay Li,Jay Mahadeokar,Jaya Bharath R Goluguri,Jayasi Mehar,Jean-Baptiste Gaya,Jeet Shah,Jeff Hanson,Jeff Marcus,Jeff Walsh,Jeff Yang,Jelmer van der Linde,Jemma Fan,Jennifer Chan,Jenny Zhen,Jenya Lee,Jeremy Fu,Jeremy Reizenstein,Jeremy Teboul,Jesse He,Jessica Zhong,Ji Hou,Ji Yang,Jia Ding,Jiabo Hu,Jiacheng Zhu,Jiadong Guo,Jialiang Wang,Jialin Ouyang,Jianfeng Chi,Jianyu Huang,Jianyun Zhao,Jiaowen Yang,Jiatong Zhou,Jiawei Zhao,Jiawen Liu,Jie Wang,Jie You,Jiecao Yu,Jillian Schwiep,Jilong Wu,Jing Huang,Jing Li,Jing Yu Koh,Jing Zhang,Jingxiang Chen,Jingyi Yang,Jingyue Shen,Jinho Hwang,Jinxi Guo,Jiwan Khatiwada,Joanna Bitton,Joe Li,Joe Quanaim,Joel Beales,Johan Schuijt,John Chang,John Quan,Johnnie Chan,Jon Shepard,Jona Harris,Jonah Rubin,Jonathan Janzen,Jonathan Kaldor,Jorge Lopez Silva,Jose Leitao,Joseph Greer,Joseph Moon,Joseph Rocca,Joseph Tighe,Josh Fromm,Joshua Deng,Joshua Fernandes,Joshua Saxe,Joyce Zheng,Juan Pino,Julien Prigent,Jun Chen,Junjiao Tian,Junjie Qi,Junjie Wang,Junteng Jia,Kade Baker,Kai Londenberg,Kai Wang,Kainan Peng,Kaiyan Peng,Kaiyue Yang,Kalyan Vasudev Alwala,Kam Hou Yu,Kanika Narang,Karan Chadha,Karan Sikka,Karen Zhang,Karina Schuberts,Karishma Mandyam,Karthik Abinav Sankararaman,Karthik Padthe,Karthik Prasad,Karthik Sivakumar,Kartikeya Upasani,Kate Plawiak,Kate Saenko,Kateřina Žmolíková,Kathryn Stadler,Kathy Matosich,Katie Doulgass,Kaveh Hassani,Kay Ji,Ke Li,Kenneth Heafield,Kenny Yu,Keqian Li,Kevin Chih-Yao Ma,Kevin Hannan,Keyu Man,Kezhen Chen,Khalid El-Arini,Khrystyna Hutsulyak,Kieran Nash,Kiran Jagadeesh,Kody Bartelt,Konstantin Topaloglou-Mundy,Konstantinos Chatziioannou,Konstantinos Karanasos,Konstantinos Vougioukas,Kostas Tsiampouris,Kristen Hamill,Kristy Choi,Krithika Iyer,Kshitiz Malik,Kuenley Chiu,Kun Huang,Kunal Bhalla,Kunal Chawla,Kunpeng Li,Kushal Lakhotia,Kyle Monk,Lakshya Garg,Lalit Chourey,Lars Hamre,Laura Gustafson,Lauren Deason,Laurence Rouesnel,Laurens van der Maaten,Lavender A,Lawrence Chen,Lawrence Jang,Leandro Silva,Leda Sari,Lee Hetherington,Lei Zhang,Leiyu Zhao,Lele Chen,Leo Chenghui Li,Leon Yang,Leon Zhan,Levi Corallo,Liang Tan,Licheng Yu,Lijuan Liu,Lilach Mor,Lincoln Lin,Linfeng Li,Lisa Titus,Liz Jenkins,Lovish Madaan,Lu Fang,Lu Yuan,Lucas Nava,Lucas Pasqualin,Lucas Switzer,Lucia Fang,Lucy Sun,Luka Tadic,Lukas Blecher,Lukas Landzaat,Luxin Zhang,Madhavi Rao,Madian Khabsa,Mahalia Miller,Mahendra Kariya,Mahesh Pasupuleti,Mahi Luthra,Manaal Faruqui,Manav Avlani,Manchen Wang,Mannat Singh,Manohar Paluri,Manoj Chakkaravarthy,Manoj Nair,Maquelle Tiffany,Marcin Pawlowski,Marcus Wu,Maria Lomeli,Mario Consuegra,Marion Boiteux,Marios Andreas Galanis,Marshall Chen,Martin Gleize,Maryam Fazel-Zarandi,Matan Hasson,Mathew Oldham,Mathieu Rita,Matt Dordal,Matt Setzler,Matt Staats,Matt Staats,Matt Wilde,Matthew Clark,Matthew Grange,Matthew Lennie,Matthew Schmohl,Max Raphael,Maxim Naumov,Maxim Samoylov,Maxime Lecanu,Maya Pavlova,Md Taha Bin Jawaid,Meghan Keneally,Melanie Kambadur,Meng Zhang,Mengchen Liu,Mengdi Lin,Mengjiao Wang,Mervyn Abraham,Miao Liu,Michael Au-Yeung,Michael Feldergraf,Michael Man,Michael Matheny,Michael Suo,Michael Tontchev,Michel Meyer,Michelle Ma,Mihir Patel,Mihir Sanjay Kale,Mik Vyatskov,Mikayla Alexander,Mike Andersland,Mike Clark,Mike Lewis,Mike Li,Mike Macey,Mike Macey,Mike Seltzer,Mikel Jimenez Fernandez,Mikhail Antonov,Mikhail Plekhanov,Milan Zhou,Min Si,Ming Qiao,Mingbo Ma,Mingjun Zhang,Mingyi Liang,Miquel Jubert Hermoso,Mirac Suzgun,Mirjam Skarica,Mitesh Kumar Singh,Mohammad Kabbani,Mohammad Rastegari,Mona Sarantakos,Monica Sim,Monika Gangapuram,Mor Moshe,Morrie Doulaty,Morvarid Metanat,Moya Chen,Mrinal Kumar,Munish Bansal,Murali Ramarao,Na Li,Nadav Azaria,Nahiyan Malik,Naman Goyal,Nancy Vargas Balderas,Nanshu Wang,Naoyuki Kanda,Natalia Gimelshein,Natalia Neverova,Nathan Aclander,Natt Sithiviraporn,Navneet Madhu Kumar,Ned Newton,Neeraj Bahl,Negar Ghorbani,Neil Patel,Neta-lee Golan,Nicholas Longenbaugh,Nick Egebo,Nikhil Johri,Nikhil Mehta,Nikhil Naik,Niko Moritz,Nikolay Bashlykov,Nikolay Bogoychev,Nikolay Pavlovich Laptev,Niladri Chatterji,Nile Jones,Nimish Shah,Ning Dong,Ning Li,Ning Li,Ning Zhang,Nishant Yadav,Noam Paz,Norman Cheng,Norman Cheng,Olaoluwa Adesanya,Oleg Repin,Oleksandr Maksymets,Omkar Salpekar,Omri Harosh,Onkar Pednekar,Onur Çelebi,Oran Gafni,Oren Edinger,Osama Hanna,Owais Khan Mohammed,Ozlem Kalinli,Paden Tomasello,Pankaj Singh,Paola Quevedo,Parag Jain,Paria Rashidinejad,Parker Tooley,Parth Parekh,Parth Thakkar,Parvin Taheri,Pasan Hapuarachchi,Pascal Kesseli,Patrick Alrassy,Paulo de Rezende Pinatti,Pavan Balaji,Pawan Sisodiya,Pedro Jose Ferreira Moreira,Pedro Rittner,Pedro Valenzuela,Peize Sun,Peizhao Zhang,Peng-Jen Chen,Pengchao Wang,Pengchuan Zhang,Pengwei Li,Petar Vasic,Peter Carras,Peter Ney,Peter Weng,Petru Dumea,Phil Hayes,Philip Woods,Pierre Andrews,Pierre Ménard,Ping-Hao Wu,Pingchuan Liu,Piotr Dollar,Plamen Dzhelepov,Polina Zvyagina,Posten A,Prabhav Agrawal,Pradhapan Rajendran,Pradyot Prakash,Prajjwal Bhargava,Pramono,Pranay Shah,Pranshu Dave,Prash Jain,Pratik Dubal,Praveen Gollakota,Praveen Krishnan,Pritish Yuvraj,Projjal Ghosh,Punit Singh Koura,Puxin Xu,Qi Qi,Qi Zhou,Qian Guan,Qian Sun,Qiang Liu,Qing He,Qinqing Zheng,Qirui Yang,Qizhen Guo,Quanzeng You,Quentin Carbonneaux,Quentin Carbonneaux,Quentin Duval,Quintin Fettes,Rachad Alao,Rachel Batish,Rachel Guo,Rachel Rodriguez,Radhika Bhargava,Rafael Asuncion,Raghotham Murthy,Rahul Dutta,Rahul Jha,Rahul Kindi,Rahul Mitra,Raj Ganapathy,Raj Shah,Rajarshi Das,Rajat Shrivastava,Rajesh Nishtala,Ramakant Shankar,Raman Shukhau,Ramon Calderer,Rangaprabhu Parthasarathy,Ranjan Subramanian,Raphael Bensadoun,Rares Bostan,Rashnil Chaturvedi,Ravi Agrawal,Ray Gao,Raymond Li,Rebecca Kogen,Ricardo Juan Palma Duran,Ricardo Silveira Cabral,Richard Lee,Richard Yuanzhe Pang,Riddhish Bhalodia,Riham Mansour,Rishabh Singh,Rishi Godugu,Ritun Patney,Rob Boyle,Robbie Goldfarb,Robert Caldwell,Robert Kuo,Roberta Raileanu,Robin Battey,Robin Sharma,Rochit Sapra,Rocky Wang,Rodolfo Granata,Rodrigo De Castro,Rodrigo Paim,Rohan Maheshwari,Rohan Varma,Rohit Girdhar,Rohit Patel,Roshan Sumbaly,Roy Sheaffer,Ruan Silva,Ruben Rodriguez Buchillon,Rui Hou,Ruiming Xie,Ruslan Mavlyutov,Ruslan Semenov,Rustam Dinov,Ruxiao Bao,Ryan Fox,Ryan Kilpatrick,Ryan Kwan,Ryan Lim,Ryan Smith,Saaketh Narayan,Sabrina Qiao,Sachin Mehta,Sachin Siby,Sagar Jain,Saghar Hosseini,Sagie Gur-Ari,Sahana Chennabasappa,Sahin Geyik,Sai Jayesh Bondu,Sai Mounika Chowdhary Nekkalapudi,Saif Hasan,Saisuke Okabayashi,Saketh Rambhatla,Salil Sawhney,Sam Dunster,Sam Zhao,Saman Keon,Samaneh Azadi,Sameet Sapra,Samuel Dooley,Samyak Datta,Sandeep Parab,Sang Michael Xie,Sanjay Singh,Sanyuan Chen,Sara Behn,Sara Khodeir,Sarah Shirazyan,Sargun Dhillon,Sarunya Pumma,Sasha Sidorov,Saskia Adaime,Saurabh Khanna,Sayem Wani,Scott Brenton,Sean Bell,Sean Kelly,Sean Koger,Sean Nunley,Sean Perry,Sebastian Caicedo,Sebastian Dahlgren,Sebastian Ruder,Seiji Yamamoto,Selam Mehretu,Selvan Sunitha Ravi,Sen Lyu,Senthil Chellapan,Serafeim Mellos,Sergey Edunov,Sergey Royt,Shaina Cohen,Shangfu Peng,Shannon Adams,Shaoliang Nie,Sharadh Ramaswamy,Sharan Narang,Shashank Pisupati,Shashi Gandham,Shaun Lim,Shaun Lindsay,Sheena Artrip,Shelly Sheynin,Shen Yan,Sheng Feng,Sheng Shen,Shengbao Zheng,Shenghao Lin,Shengjie Bi,Shengxin Cindy Zha,Shengye Wan,Shengyi Qian,Shengyong Cai,Shengzhi Shao,Shervin Shahidi,Shikai Li,Shimon Bernholtz,Shiqi Wang,Shishir G. Patil,Shiv Verma,Shiva Shankar P,Shiyang Chen,Sho Yaida,Shoubhik Debnath,Shreyas Siravara,Shruti Bhosale,Shuang Ma,Shun Zhang,Shuo Tang,Shuqiang Zhang,Shuyan Zhou,Sicong Che,Sidd Srinivisan,Siddharth Bhattacharya,Siddharth Patki,Sijia Chen,Sili Chen,Simon Vandenhende,Simone Merello,Sinong Wang,Sivan Barzily,Sixian Yi,Siyu Lin,SK Bong,Sky Yin,Sneha Agarwal,Sneha Agarwal,Soerian Lieve,Soji Sajuyigbe,Song Jiang,Songlin Li,Sonia Kim,Sopan Khosla,Soumi Maiti,Spencer Whitman,Sravya Popuri,Sreen Tallam,Srinivas Vaidyanathan,Srinivas Vaidyanathan,Sten Sootla,Stephane Collot,Stephanie Ding,Stephen Chen,Steven Cai,Suchin Gururangan,Sudarshan Govindaprasad,Sue Young,Suganthi Dewakar,Sujan Kumar Gonugondla,Sujeet Bhandari,Suman Gumudavelli,Suman Gumudavelli,Sumit Gupta,Summer Deng,Sungmin Cho,Suresh Ganapathy,Surjyendu Dhal,Susan Fedynak,Susana Contrera,Suyoun Kim,Sylvestre Rebuffi,Takshak Chahande,Tamar Herman,Tan Li,Tao Xu,Tara Fowler,Tarek Sheasha,Tarun Anand,Tarun Kalluri,Tarun Singh,Tatiana Shavrina,Ted Li,Teja Rao,Tejas Patil,Teng Li,Thach Bui,Thai Quach,Thamer Alharbash,Thanh Vinh Vo,Thawan Kooburat,Thilo Koehler,Thomas Georgiou,Thomas Scialom,Tian Ye,Tianhe Li,Tianjun Zhang,Tianyu Li,Tijmen Blankevoort,Timon Willi,Timothy Chou,Timothy Leung,TJ Lee,Todor Mihaylov,Tom Heatwole,Tong Xiao,Tony Cao,Tony Lee,Trang Le,Tristan Rice,Tsz Kei Serena Chan,Tuan Tran,Tudor Tiplea,Tyler Baumgartner,Uday Savagaonkar,Ujjwal Karn,Ulises Martinez Araiza,Umar Farooq,Uriel Cohen,Usman Sharif,Utkarsh Murarka,Van Phung,Varun Joginpalli,Varun Saravagi,Vasu Sharma,Vasudha Viswamurthy,Vedanuj Goswami,Vedika Seth,Venkat Ramesh,Venkat Ramesh,Vibhor Gupta,Victoria Montanez,Vidhya Natarajan,Vidya Sarma,Vignesh Ramanathan,Viktor Kerkez,Vinay Rao,Vincent Gonguet,Vincent Mauge,Virginie Do,Vish Vogeti,Vishrav Chaudhary,Viswesh Sankaran,Vítor Albiero,Vivek Miglani,Vivek Pai,Vlad Cojanu,Vlad Shubin,Vlad Tiberiu Mihailescu,Vladan Petrovic,Vladimir Ivanov,Vladislav Vorotilov,Vrushali Bhutada,Wai I Ng,Wei Cheng,Wei Sun,Wei Tu,Wei Wei,Wei Zhou,Wei-Ning Hsu,Weiwei Chu,Weizhe Yuan,Wenchen Wang,Wenjun Zhao,Wenwen Jiang,Wenyin Fu,Wenzhe Jiang,Whitney Meers,Will Constable,Will Wang,William R. Wong,Xavier Martinet,Xi Victoria Lin,Xi Yan,Xi Yin,Xian Li,Xianfeng Rui,Xianjun Yang,Xiaocheng Tang,Xiaodong Wang,Xiaofang Wang,Xiaolan Wang,Xiaoliang Dai,Xiaoliang Peng,Xiaopeng Li,Xiaozhu Meng,Xibei Zhang,Xide Xia,Xin Jin,xinbo Gao,Xinfeng Xie,Xingyi Zhou,Xu Ma,Xuan Ju,Xuanyi Zhao,Xubo Liu,Xuchao Jia,Xuedong Zhang,Xuefei Cao,Xuewei Wang,Xuewei Wu,Xunnan Xu,Xutai Ma,Xuyang Wang,Yan Cui,Yang Chen,Yang Li,Yang Shu,Yang Xia,Yanjun Chen,Yanjun Zhou,Yash Mehta,Yash Patel,Yash Tekena,Yashesh Gaur,Yasmine Babaei,Yaxuan Zhou,Ye Hu,Ye Qi,Yejin Lee,Yeming Wen,Yen-Cheng Liu,Yexin Bruce Wu,Yi Pan,Yi Yang,Yi-Hui Lin,Yifan Wang,Yifan Wu,Yifan Yang,Yifei Huang,Yiftah Ben Aharon,Yilin Yang,Yiling You,Ying Xu,Ying Zhang,Yingquan Yuan,Yingru Liu,Yingyi Ma,Yining Yang,Yiting Lu,Yonatan Komornik,Yongjie Lin,Yoni Goyhman,Yossi Moran Mamo,Youngjin Nam,Yu Wang,Yu Lu,Yu Zhao,Yu-Ho Hsieh,Yu-Jung Lo,Yuandong Tian,Yuanhan Zhang,Yuanhao Xiong,Yuanshun Yao,Yuchen Hao,Yuchen Zhang,Yuchuan Li,Yue Cao,Yue Yu,Yue Zhao,Yuhan Guo,Yuhao Wang,Yuheng Huang,Yujie Lu,Yujun Shi,Yulun Wang,Yun He,Yun Wang,Yundi Qian,Yunfan Wang,Yunhao Tang,Yuning Mao,Yunlu Li,Yuqi Dai,Yuriy Hulovatyy,Yushi Hu,Yuxuan Sun,Zach Rait,Zach Wentz,Zacharie Delpierre Coudert,Zachary Collins,Zahra Hankir,Zecheng He,Zeeshan Ahmed,Zeeshan Ahmed,Zef RosnBrick,Zhan Shu,Zhanna Rohalska,Zhaoduo Wen,Zhe Liu,Zhe Liu,Zhen Qiao,Zhenggang Xu,Zhengwen Zhou,Zhengxing Chen,Zhenyu Tang,Zhichen Wu,Zhicheng Ouyang,Zhihong Lei,Zhipeng Hong,Zhiping Xiu,Zhiwei Zhao,Zhong Meng,Zhou Jin,Zhouhao Zeng,Zichang Liu,Zihang Meng,Zihuan Qiao,Zinnia Zheng,Zixi Qi,Ziyi Luo,Zoe Foulkes Birkhead,Zoey Sun,Zohar Achdut*

Main category: cs.SE

TL;DR: 本文档整合了Meta Llama 4模型系列的公开技术细节，包括模型变体、架构特性、训练方法、基准测试结果和部署限制，旨在为研究人员和从业者提供准确的技术参考。


<details>
  <summary>Details</summary>
Motivation: Meta Llama 4模型系列发布后，公开信息分散且缺乏系统整理。本文档旨在整合所有公开技术细节，为研究者和实践者提供准确、基于来源的技术参考，帮助他们理解模型特性、部署限制和许可要求。

Method: 文档采用文献综述方法，系统收集和整合Meta官方发布的公开技术信息，包括模型发布材料、技术文档、基准测试报告和部署指南等，按技术维度进行分类整理。

Result: 文档提供了Llama 4模型系列的全面技术概览：包括Scout和Maverick两个变体、MoE架构细节、多模态融合设计、长上下文处理策略、训练流程（预训练、中期训练、后训练）、基准测试性能数据、部署环境限制以及许可和安全评估信息。

Conclusion: 本文档成功创建了Llama 4模型系列的技术参考手册，为研究者和开发者提供了准确、系统的技术信息，有助于更好地理解、部署和应用该模型系列，同时明确了许可要求和安全考虑。

Abstract: This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.

</details>


### [16] [From Everything-is-a-File to Files-Are-All-You-Need: How Unix Philosophy Informs the Design of Agentic AI Systems](https://arxiv.org/abs/2601.11672)
*Deepak Babu Piskala*

Main category: cs.SE

TL;DR: 论文探讨了早期Unix系统"万物皆文件"抽象原则如何类比于当代智能体AI的发展，提出文件与代码为中心的交互模型可使智能体系统更易维护、可审计和稳健运行。


<details>
  <summary>Details</summary>
Motivation: 探索早期Unix系统的"万物皆文件"核心抽象原则如何为当代自主智能体AI系统提供启示，寻找统一的交互模型来管理异构资源和系统。

Method: 追溯从Unix到DevOps、基础设施即代码，再到自主软件智能体的演化历程，分析文件类抽象和基于代码的规范如何将多样化资源统一为一致的、可组合的接口。

Result: 发现文件与代码为中心的交互模型在智能体AI系统中具有类比价值，这种统一抽象能够将异构设备和内核资源通过统一的读写接口进行操作。

Conclusion: 采用文件与代码为中心的交互模型可能使智能体系统更具可维护性、可审计性和操作稳健性，延续了Unix哲学在现代AI系统中的价值。

Abstract: A core abstraction in early Unix systems was the principle that 'everything is a file', enabling heterogeneous devices and kernel resources to be manipulated via uniform read/write interfaces. This paper explores how an analogous unification is emerging in contemporary agentic AI. We trace the evolution from Unix to DevOps, Infrastructure-as-Code, and finally autonomous software agents, highlighting how file-like abstractions and code-based specifications collapse diverse resources into consistent, composable interfaces. The resulting perspective suggests that adopting file- and code-centric interaction models may enable agentic systems that are more maintainable, auditable, and operationally robust.

</details>


### [17] [Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems](https://arxiv.org/abs/2601.11687)
*Harmohit Singh*

Main category: cs.SE

TL;DR: 提出一个生产优化的多智能体系统，将自然语言查询转换为可执行的Python代码进行结构化数据分析，通过语义缓存、双阈值决策和意图驱动的动态提示组装实现高准确率和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖昂贵的前沿模型，需要开发一个既能保持高准确率又能实现成本效益的解决方案，以支持企业级结构化数据分析需求。

Method: 采用三个关键技术：1) 基于LLM的语义缓存系统，包含等价检测和结构化适配提示；2) 双阈值决策机制，分离精确匹配检索和参考引导生成；3) 意图驱动的动态提示组装系统，通过表感知上下文过滤减少token消耗。

Result: 在生产环境中处理超过10,000个查询，平均延迟8.2秒，语义准确率达到94.3%。语义缓存命中率达到67%，token消耗减少40-60%。

Conclusion: 该系统成功部署于企业库存管理生产环境，展示了LLM驱动的分析系统在大规模部署中的可行性和实际价值，为类似系统提供了架构参考和实践经验。

Abstract: We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.

</details>


### [18] [SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering](https://arxiv.org/abs/2601.11688)
*Vedant Nipane,Pulkit Agrawal,Amit Singh*

Main category: cs.SE

TL;DR: 提出分层数据表到代码映射方法，使用LLM进行语义分析，通过多级抽象逐步缩小搜索空间，显著提升嵌入式系统规格与代码的追溯精度和效率。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统数据表与代码实现之间的精确追溯是系统工程中的基本挑战，现有基于词汇相似性和信息检索的方法难以捕捉嵌入式系统软件中的语义、结构和符号级关系。

Method: 分层数据表到代码映射方法：1) 仓库级结构推断；2) 文件级相关性估计；3) 细粒度符号级对齐。使用大语言模型进行语义分析，覆盖函数、宏、结构体、常量、配置参数和寄存器定义等系统级C/C++代码元素。

Result: 在多个开源嵌入式系统仓库上评估，相比传统信息检索基线有显著改进，文件映射准确率达到73.3%，LLM令牌消耗降低84%，端到端运行时间减少约80%。

Conclusion: 该方法支持大型嵌入式软件系统的自动化分析，可用于系统感知机器学习模型的训练数据生成、标准合规性验证和大规模规格覆盖分析等下游应用。

Abstract: Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.

</details>


### [19] [Technical Lag as Latent Technical Debt: A Rapid Review](https://arxiv.org/abs/2601.11693)
*Shane K. Panter,Nasir U. Eisty*

Main category: cs.SE

TL;DR: 技术债务研究综述：技术滞后作为被动积累的技术债务指标，通过快速回顾方法分析其定义、检测、原因、后果及管理策略。


<details>
  <summary>Details</summary>
Motivation: 技术系统未能跟上技术进步时会产生技术滞后，导致软件质量恶化。本文旨在整合现有研究，澄清定义，探索检测量化方法，分析原因后果，回顾管理实践，并将其作为被动积累技术债务的指标。

Method: 采用快速回顾法结合滚雪球抽样，从ACM Digital Library、IEEE Xplore、Scopus和Springer等主要数据库筛选同行评审研究。

Result: 技术滞后通常被动积累且不易察觉，因缺乏适当的检测指标和工具。它通过过时依赖、废弃API、不支持平台和老化基础设施对软件质量产生负面影响。管理策略主要包括自动化依赖更新、持续集成流程和定期审计。

Conclusion: 增强和扩展当前标准化指标、检测方法和实证研究，将技术滞后作为积累的潜在债务指标，可显著改善维护依赖外部包的大型代码库的过程。已识别研究空白并为研究人员和从业者规划了未来研究方向。

Abstract: Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.

</details>


### [20] [The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing](https://arxiv.org/abs/2601.11783)
*Murtuza N. Shergadwala*

Main category: cs.SE

TL;DR: 研究发现LLM法官在评估AI系统时存在"稳定性陷阱"：虽然判决结果高度一致（>99%），但推理过程稳定性差异很大，客观指令的推理稳定性可低至19%，主观指令在35%-83%之间波动。


<details>
  <summary>Details</summary>
Motivation: 在受监管行业（如人力资源）中，企业需要对生成式AI进行可扩展且可复现的审计。虽然LLM-as-a-Judge方法提供了可扩展性，但其在评估不同类型系统指令时的可靠性尚未得到验证。本研究旨在探究应用测试指令类型如何影响法官评估的稳定性。

Method: 提出了范围化指令分解框架，将应用测试指令分类为客观和主观类型，以分离导致法官不稳定的因素。将该框架应用于两个代表性的人力资源生成式AI应用，评估了四种法官架构在多次运行中的稳定性。

Result: 发现了"稳定性陷阱"现象：判决稳定性与推理稳定性之间存在分歧。虽然法官在客观和主观评估中都达到了近乎完美的判决一致性（>99%），但他们的推理轨迹差异显著。客观指令（如字数统计）的推理稳定性可低至约19%，而主观指令的推理稳定性在35%-83%之间波动。只有专注于离散实体提取的客观指令实现了高推理稳定性（>90%）。

Conclusion: 高判决稳定性可能掩盖脆弱的推理过程。建议审计员严格限定自动化评估协议的范围：将所有可确定性验证的逻辑委托给代码，同时保留LLM法官用于复杂的语义评估。

Abstract: The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\approx19\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\%$--$83\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.

</details>


### [21] [Changes in Coding Behavior and Performance Since the Introduction of LLMs](https://arxiv.org/abs/2601.11835)
*Yufan Zhang,Jaromir Savelka,Seth Goldstein,Michael Conway*

Main category: cs.SE

TL;DR: 研究分析ChatGPT发布前后五年间研究生云计算课程学生编程行为变化，发现学生过度依赖LLM导致学习效果下降


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLM)的普及，学生编程和解决问题的方式发生变化。虽然这些工具可能提高学生生产力，但也使教师评估学生学习和努力变得更加困难。需要研究LLM对学生学习行为和成果的实际影响。

Method: 采用准纵向研究方法，分析研究生云计算课程五年间的学生源代码提交数据。研究聚焦于一个未改变的作业，比较ChatGPT发布前五个学期和发布后五个学期的学生行为变化。

Result: 自2022年秋季以来，学生编程行为发生显著变化：最终提交代码长度增加；连续提交间的平均编辑距离增加而平均分数提升减少，表明学生生产力和学习效果均下降。这些行为变化与整体表现存在统计学显著相关性。

Conclusion: 虽然不能明确归因于LLM滥用，但研究结果支持假设：部分学生过度依赖LLM，对其学习成果产生负面影响。这为LLM时代的第一代毕业生敲响警钟，呼吁教育者和雇主反思评估真实专业知识和生产力的方法。

Abstract: The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.
  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.

</details>


### [22] [Trace Validation of Unmodified Concurrent Systems with OmniLink](https://arxiv.org/abs/2601.11836)
*Finn Hackett,Evan Wrench,Peter Macko,A. Jesse Jiryu Davis,Yuanhao Wei,Ivan Beschastnikh*

Main category: cs.SE

TL;DR: OmniLink是一种验证并发系统的新方法，使用TLA+规范，通过求解逻辑总序来检测并发bug，在工业级数据库和数据结构验证中表现优异。


<details>
  <summary>Details</summary>
Motivation: 并发系统验证困难，现有工具需要侵入式插桩或不现实的执行模型，需要更有效的验证方法。

Method: OmniLink将系统事件视为黑盒，包含时间窗口和TLA+语义，求解逻辑总序，使用现成的模型检查进行线性化检查。

Result: 成功验证WiredTiger数据库、BAT无锁数据结构和ConcurrentQueue队列，发现已知bug并帮助发现2个新bug。

Conclusion: OmniLink提供灵活的规范语言和不同的线性化检查方法，在大规模验证任务中优于现有技术。

Abstract: Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.
  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.

</details>


### [23] [Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces](https://arxiv.org/abs/2601.11868)
*Mike A. Merrill,Alexander G. Shaw,Nicholas Carlini,Boxuan Li,Harsh Raj,Ivan Bercovich,Lin Shi,Jeong Yeon Shin,Thomas Walshe,E. Kelly Buchanan,Junhong Shen,Guanghao Ye,Haowei Lin,Jason Poulos,Maoyu Wang,Marianna Nezhurina,Jenia Jitsev,Di Lu,Orfeas Menis Mastromichalakis,Zhiwei Xu,Zizhao Chen,Yue Liu,Robert Zhang,Leon Liangyu Chen,Anurag Kashyap,Jan-Lucas Uslu,Jeffrey Li,Jianbo Wu,Minghao Yan,Song Bian,Vedang Sharma,Ke Sun,Steven Dillmann,Akshay Anand,Andrew Lanpouthakoun,Bardia Koopah,Changran Hu,Etash Guha,Gabriel H. S. Dreiman,Jiacheng Zhu,Karl Krauth,Li Zhong,Niklas Muennighoff,Robert Amanfu,Shangyin Tan,Shreyas Pimpalgaonkar,Tushar Aggarwal,Xiangning Lin,Xin Lan,Xuandong Zhao,Yiqing Liang,Yuanli Wang,Zilong Wang,Changzhi Zhou,David Heineman,Hange Liu,Harsh Trivedi,John Yang,Junhong Lin,Manish Shetty,Michael Yang,Nabil Omi,Negin Raoof,Shanda Li,Terry Yue Zhuo,Wuwei Lin,Yiwei Dai,Yuxin Wang,Wenhao Chai,Shang Zhou,Dariush Wahdany,Ziyu She,Jiaming Hu,Zhikang Dong,Yuxuan Zhu,Sasha Cui,Ahson Saiyed,Arinbjörn Kolbeinsson,Jesse Hu,Christopher Michael Rytting,Ryan Marten,Yixin Wang,Alex Dimakis,Andy Konwinski,Ludwig Schmidt*

Main category: cs.SE

TL;DR: Terminal-Bench 2.0是一个包含89个终端环境任务的硬基准测试，用于评估AI代理在真实工作流程中的长时程任务完成能力，前沿模型得分低于65%。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试要么不测量真实世界任务，要么难度不足以有效评估前沿模型。需要创建一个能够衡量AI代理在真实工作流程中自主完成有价值长时程任务能力的硬基准测试。

Method: 构建了包含89个计算机终端环境任务的基准测试，每个任务都有独特环境、人工编写的解决方案和全面的验证测试。任务灵感来源于真实工作流程中的问题。

Result: 前沿模型和代理在该基准测试上得分低于65%。通过错误分析识别了模型和代理需要改进的领域。

Conclusion: Terminal-Bench 2.0是一个具有挑战性的基准测试，能够有效评估AI代理在真实终端环境中的任务完成能力。发布了数据集和评估框架以支持未来研究。

Abstract: AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ .

</details>


### [24] [CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation](https://arxiv.org/abs/2601.13682)
*Jianfeng Cai,Jinhua Zhu,Ruopei Sun,Kangwen Zhao,Dongyun Xue,Mingxiao Feng,Wengang Zhou,Houqiang Li*

Main category: cs.SE

TL;DR: 提出反馈驱动的迭代框架，通过LLM生成测试用例并利用执行失败结果作为反馈进行优化，构建了高质量的CodeContests-O数据集，显著提升了测试覆盖率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 推理模型需要大规模可验证数据，编程任务是理想来源，但现有竞争编程平台缺乏高质量的测试用例。现有方法仅依赖LLM内在生成能力，导致测试用例多样性不足。

Method: 提出反馈驱动的迭代框架：1）使用LLM生成初始测试用例；2）在正确和错误解决方案上执行测试；3）利用失败结果作为反馈指导LLM优化测试用例，提高保真度和区分度。

Result: 在CodeContests数据集上构建了CodeContests-O，评估1.1×10^7个解决方案，平均真阳性率89.37%，真阴性率90.89%，比CodeContests和CodeContests+分别提升4.32%和9.37%。在Qwen2.5-7B模型上微调后，LiveCodeBench（Pass@1）提升9.52%。

Conclusion: 提出的反馈驱动迭代框架有效提升了测试用例质量，构建的CodeContests-O数据集显著优于现有数据集，并开源代码和数据集以支持可复现性和未来研究。

Abstract: The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\%$ and True Negative Rate (TNR) of $90.89\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\%$ and $9.37\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.

</details>


### [25] [Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps](https://arxiv.org/abs/2601.11926)
*Ananya Halgatti,Shaunak Biswas,Hiya Bhatt,Srinivasan Rakhunathan,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: Harmonica是一个基于MAPE-K循环的自适应MLOps示例系统，通过监控可持续性指标并在阈值违规时自动触发架构策略，提高ML系统的稳定性和可持续性。


<details>
  <summary>Details</summary>
Motivation: ML系统在运行时常面临环境变化带来的不确定性，可能导致模型性能下降、运营成本增加和系统效用降低。虽然MLOps简化了ML模型生命周期管理，但对影响ML系统长期可持续性的运行时不确定性支持有限。目前缺乏允许研究人员在MLOps管道中研究这些挑战的示例系统。

Method: Harmonica基于HarmonE方法构建，采用MAPE-K（监控-分析-规划-执行-知识）循环实现结构化自适应控制。它将高层适应策略与低层策略执行分离，持续监控可持续性指标，根据动态适应边界进行评估，并在阈值违规时自动触发架构策略。

Result: 通过时间序列回归和计算机视觉的案例研究，Harmonica展示了提高系统稳定性和减少人工干预的能力。结果表明，该工具为依赖MLOps管道持续运行的ML系统提供了实用且可重用的自适应行为基础。

Conclusion: Harmonica为可持续和自适应的ML系统提供了一个实用的研究示例，通过结构化自适应控制机制，能够检测执行漂移并调整系统行为，从而提高MLOps管道的长期可持续性。

Abstract: Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.

</details>


### [26] [Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation](https://arxiv.org/abs/2601.11972)
*Chi Thien Tran*

Main category: cs.SE

TL;DR: 提出基于静态分析的自动化模糊测试目标生成方法，用于C/C++库的漏洞检测


<details>
  <summary>Details</summary>
Motivation: 模糊测试是检测软件安全漏洞最有效的方法，但在大型软件项目中手动创建模糊测试目标既耗时又费力，需要自动化技术来生成测试目标并分析结果

Method: 通过静态分析库源代码来改进模糊测试目标生成：分析源代码结构以构建函数调用和生成测试目标；将模糊测试输入数据映射到相应函数参数；合成测试目标的编译信息；自动收集和分析执行结果

Result: 该方法已应用于C/C++库的模糊测试目标生成，展示了其有效性

Conclusion: 提出的静态分析方法能够自动化生成模糊测试目标，解决了手动创建测试目标的效率问题，有助于提高漏洞检测的覆盖率和效果

Abstract: Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.

</details>


### [27] [From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler](https://arxiv.org/abs/2601.12146)
*Viktor Kjellberg,Miroslaw Staron,Farnaz Fotrousi*

Main category: cs.SE

TL;DR: 研究LLM编程代理如何通过编译器工具提升代码生成质量，发现编译器访问显著提高编译成功率并减少语法错误


<details>
  <summary>Details</summary>
Motivation: LLM生成的源代码质量参差不齐，经常无法编译。本研究旨在探索编程代理通过访问编译器工具（如gcc）能否从被动生成转变为主动迭代开发可运行程序

Method: 在RosettaCode数据集的699个C语言编程任务上进行计算实验，评估16个不同规模的LLM（从1.35亿到700亿参数），比较有/无编译器访问时的性能差异

Result: 编译器访问使编译成功率提升5.3-79.4个百分点，语法错误减少75%，未定义引用错误减少87%。在某些情况下，带编译器的小模型甚至优于带编译器的大模型

Conclusion: LLM必须访问软件工程工具以提升性能，这可以减少对大型模型的依赖，降低能耗，同时将LLM从被动生成器转变为能够基于编译器反馈迭代开发程序的主动代理

Abstract: Large Language Models have demonstrated a remarkable capability in natural language and program generation and software development. However, the source code generated by the LLMs does not always meet quality requirements and may fail to compile. Therefore, many studies evolve into agents that can reason about the problem before generating the source code for the solution. The goal of this paper is to study the degree to which such agents benefit from access to software development tools, in our case, a \texttt{gcc} compiler. We conduct a computational experiment on the RosettaCode dataset, on 699 programming tasks in C. We evaluate how the integration with a compiler shifts the role of the language model from a passive generator to an active agent capable of iteratively developing runnable programs based on feedback from the compiler. We evaluated 16 language models with sizes ranging from small (135 million) to medium (3 billion) and large (70 billion). Our results show that access to a compiler improved the compilation success by 5.3 to 79.4 percentage units in compilation without affecting the semantics of the generated program. Syntax errors dropped by 75\%, and errors related to undefined references dropped by 87\% for the tasks where the agents outperformed the baselines. We also observed that in some cases, smaller models with a compiler outperform larger models with a compiler. We conclude that it is essential for LLMs to have access to software engineering tools to enhance their performance and reduce the need for large models in software engineering, such as reducing our energy footprint.

</details>


### [28] [Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages](https://arxiv.org/abs/2601.12148)
*Muhammad Umar Zeshan,Motunrayo Ibiyo,Claudio Di Sipio,Phuong T. Nguyen,Davide Di Ruscio*

Main category: cs.SE

TL;DR: LAMPS是一个多智能体系统，利用协作式LLM检测PyPI恶意软件包，通过四个角色特定智能体实现，在多个数据集上超越现有方法达到97.7%-99.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 开源仓库中的恶意代码对软件供应链构成日益增长的威胁，传统基于规则的工具常忽略源代码中的语义模式，而LLM在软件分析中虽有潜力，但在可解释和模块化安全管道中的应用仍有限。

Method: 提出LAMPS多智能体系统，包含四个角色特定智能体：包检索、文件提取、分类和裁决聚合，通过CrewAI框架协调。原型结合微调的CodeBERT模型进行分类，以及LLaMA-3智能体进行上下文推理。

Result: 在两个互补数据集上评估：D1（6000个setup.py文件）达到97.7%准确率，超越MPHunter；D2（1296个多文件数据集）达到99.5%准确率和99.5%平衡准确率，优于RAG方法和微调单智能体基线。McNemar检验确认改进高度显著。

Conclusion: 结果证明了分布式LLM推理在恶意代码检测中的可行性，并突显了模块化多智能体设计在软件供应链安全中的优势。

Abstract: Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.

</details>


### [29] [Aletheia: What Makes RLVR For Code Verifiers Tick?](https://arxiv.org/abs/2601.12186)
*Vatsal Venkatkrishna,Indraneil Paul,Iryna Gurevych*

Main category: cs.SE

TL;DR: 论文研究了基于RLVR训练的代码验证器，创建了Aletheia测试平台评估其鲁棒性，发现RLVR方法最优但可简化，小规模时在线学习最关键，大规模时基于思考的训练最重要。


<details>
  <summary>Details</summary>
Motivation: 代码验证器在代码生成中应用较少，执行反馈是主要信号，但在难以获得执行反馈的场景中，代码验证器仍有价值。需要系统评估代码验证器在不同策略模型和协变量偏移下的鲁棒性。

Method: 创建并开源Aletheia测试平台，用于基于执行的代码验证器评估。研究RLVR验证器训练方法的关键组件：中间思考轨迹、从负样本学习、在线训练，分析各组件的重要性。

Result: 实验显示RLVR方法最优，但可简化训练流程。代码验证在训练和推理阶段都呈现正缩放性，小规模验证器中在线学习最关键，大规模验证器中基于思考的训练最重要。

Conclusion: 代码验证器是代码生成后训练工具箱的有力补充，RLVR方法有效但可简化，不同规模下关键组件不同，为代码验证器的实际应用提供了指导。

Abstract: Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.

</details>


### [30] [Environment-Aware Code Generation: How far are We?](https://arxiv.org/abs/2601.12262)
*Tongtong Wu,Rongyi Chen,Wenjie Du,Suyu Ma,Guilin Qi,Zhenchang Xing,Shahram Khadivi,Ramesh Periyathambi,Gholamreza Haffari*

Main category: cs.SE

TL;DR: 该论文提出了环境感知代码生成（EACG）的概念，并创建了VersiBCB基准测试来评估LLM在特定软件环境下生成可执行代码的能力，发现当前LLM在这方面存在困难，但通过数据、参数和缓存三个维度的适配可以改善环境兼容性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码生成评估大多测试孤立的小规模代码，忽略了实际软件环境的复杂性。不清楚LLM是否能生成针对用户特定环境可执行的代码，需要系统研究环境感知代码生成。

Method: 引入VersiBCB基准测试，该基准具有多包、执行验证和废弃感知特性，能捕捉复杂演化的环境。研究三个适配维度：数据、参数和缓存，并为每个维度开发代表性策略。

Result: 当前LLM在环境特定代码生成方面表现不佳，但提出的适配方法能显著改善环境兼容性和可执行性。

Conclusion: 研究揭示了LLM在实际软件工程工作流中部署的关键挑战和机遇，强调了环境感知代码生成的重要性。

Abstract: Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.

</details>


### [31] [Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs](https://arxiv.org/abs/2601.12273)
*Chihiro Yoshida,Yuta Ishimoto,Olivier Nourry,Masanari Kondo,Makoto Matsushita,Yasutaka Kamei,Yoshiki Higo*

Main category: cs.SE

TL;DR: LLM-based量子程序自动修复框架，通过结合突变分析等上下文信息，显著提升修复成功率至94.4%，同时改善补丁可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有量子程序自动修复技术存在修复成功率低和生成补丁可理解性差的问题，需要开发既能提高修复成功率又能增强可解释性的新方法。

Method: 构建LLM框架生成代码修复及自然语言解释，设计四种提示配置（静态信息、动态信息、突变分析结果的不同组合），突变分析通过评估程序微小变化对执行结果的影响提供更详细的动态信息。

Result: 突变分析为基于LLM的量子程序APR提供有价值的上下文信息，修复成功率提升至94.4%，在某些情况下还改善了生成解释的质量。

Conclusion: 突变分析能有效提升量子程序自动修复的性能和可解释性，为开发兼具可靠性和可解释性的量子程序APR技术指明了新方向。

Abstract: In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.

</details>


### [32] [Hybrid Concolic Testing with Large Language Models for Guided Path Exploration](https://arxiv.org/abs/2601.12274)
*Mahdi Eslamimehr*

Main category: cs.SE

TL;DR: 本文提出了一种结合符号执行与大型语言模型的新型混合测试框架，通过LLM的语义推理能力指导路径探索和约束求解，显著提升了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统的符号测试存在路径爆炸和约束求解成本高等根本性限制，阻碍了其在大规模实际软件系统中的应用。需要新的方法来克服这些挑战。

Method: 提出了一种新颖的算法框架，将符号执行与大型语言模型协同集成。利用LLM的语义推理能力来指导路径探索、优先处理有趣的执行路径，并协助约束求解。正式定义了构成这一新范式的系统架构和算法。

Result: 通过在合成和真实金融科技应用上的实验表明，该方法在分支覆盖率、路径覆盖率和达到覆盖率的时间方面，显著优于传统的符号测试、随机测试和基于遗传算法的方法。

Conclusion: 通过结合符号执行和LLM的优势，该方法实现了对程序状态空间更高效和有效的探索，从而提高了错误检测能力。

Abstract: Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.

</details>


### [33] [The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering](https://arxiv.org/abs/2601.12327)
*Lucas Gren,Felix Dobslaw*

Main category: cs.SE

TL;DR: 提出专家验证框架，将领域专家置于构建GenAI系统的中心，通过结构化规范、测试、验证和持续监控，确保企业环境中生成式AI的质量和可信度。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统有望通过自动化各种任务来改变知识工作，但在企业环境中的部署仍然受到缺乏系统化质量保证机制的阻碍。需要解决AI能力与组织信任之间的关键差距。

Method: 提出专家验证框架，将领域专家置于构建GenAI软件的核心位置。通过四阶段实施过程：规范制定、系统创建、验证和生产监控，使专家能够通过结构化流程保持对系统行为的权威控制。

Result: 该框架建立了严格的、专家驱动的方法论，确保在不同GenAI应用中的质量。使组织能够在保持专家监督和质量标准的同时，利用GenAI能力。

Conclusion: 专家验证框架通过将领域专家置于中心位置，为企业部署生成式AI系统提供了系统化的质量保证机制，填补了AI能力与组织信任之间的关键差距。

Abstract: Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.

</details>


### [34] [Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition](https://arxiv.org/abs/2601.12360)
*Xinabang He,Yuanwei Chen,Hao Wu,Jikang Zhang,Zicheng Wang,Ligeng Chen,Junjie Peng,Haiyang Wei,Yi Qian,Tiantai Zhang,Linzhang Wang,Bing Mao*

Main category: cs.SE

TL;DR: FeatureFuzz是一个编译器模糊测试工具，通过组合特征（包含bug触发语义的代码片段）来生成程序，相比传统方法能更好地保留bug触发语义，在GCC和LLVM测试中发现大量新bug。


<details>
  <summary>Details</summary>
Motivation: 当前编译器模糊测试方法（基于语法变异或通用LLM微调）难以保留bug触发程序的特定语义，导致关键的语义触发器丢失，限制了生成程序的多样性。编译器作为软件供应链的信任根，其复杂性隐藏着关键缺陷。

Method: FeatureFuzz采用三阶段工作流程：1) 从历史bug报告中提取特征（特征=bug易发不变量的自然语言描述+具体代码实现）；2) 合成特征组；3) 将特征组实例化为有效程序用于编译器模糊测试。

Result: 在24小时测试中，FeatureFuzz发现167个独特崩溃，是第二佳模糊测试工具的2.78倍。在72小时测试中，在GCC和LLVM中发现106个bug，其中76个已被编译器开发者确认。

Conclusion: FeatureFuzz通过显式重用bug触发语义，能有效对现代编译器进行压力测试，显著提高了编译器模糊测试的效果和bug发现能力。

Abstract: Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.
  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.
  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.

</details>


### [35] [Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software](https://arxiv.org/abs/2601.12448)
*Yang Liu,Yixing Luo,Xiaofeng Li,Xiaogang Dong,Bin Gu,Zhi Jin*

Main category: cs.SE

TL;DR: ATSADBench是首个航空航天时间序列异常检测基准，包含9个任务、108,000个数据点，评估LLM在两种范式下的表现，并提出三个用户导向的评估指标。


<details>
  <summary>Details</summary>
Motivation: 航空航天软件系统需要可靠的时间序列异常检测，LLM作为免训练的无监督方法替代方案很有前景，但其在航空航天领域的有效性尚未充分研究，存在复杂遥测数据、评估指标不匹配和缺乏领域知识等问题。

Method: 提出ATSADBench基准，包含9个任务（三种异常类型×单/多变量×反馈场景），评估LLM在直接检测和基于预测检测两种范式下的表现，引入窗口级评估和三个用户导向指标（AA、AL、AC），并测试少样本学习和RAG两种增强策略。

Result: LLM在单变量任务表现良好，但在多变量遥测任务中表现接近随机猜测；少样本学习有适度提升，RAG无显著改进；实践中LLM能检测真实异常起始点，但有时会产生误报，少样本提示能缓解而RAG会加剧误报。

Conclusion: 研究为未来基于LLM的航空航天软件时间序列异常检测提供了指导，揭示了LLM在多变量任务中的局限性，并展示了不同增强策略的效果差异。

Abstract: Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.

</details>


### [36] [Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition](https://arxiv.org/abs/2601.12522)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: CogniGent是一个基于多智能体AI的bug定位技术，通过因果推理、调用图分析和上下文工程，模拟开发者的动态认知调试过程，在文档和方法级别上显著优于现有传统和LLM方法。


<details>
  <summary>Details</summary>
Motivation: 软件bug给技术提供商造成数十亿美元损失，开发者约50%时间用于bug修复。传统bug定位方法孤立分析代码组件，忽视组件间连接；现有LLM方法缺乏因果推理能力，难以有效管理上下文，限制了bug定位能力。

Method: CogniGent采用多智能体AI技术，结合因果推理、基于调用图的根本原因分析和上下文工程。模拟开发者的动态认知调试实践，进行假设测试来支持bug定位。

Result: 在591个bug报告的数据集上评估，使用三个广泛采用的性能指标，与六个文献中的基准方法比较。CogniGent在文档和方法级别上MAP提升23.33-38.57%，MRR提升25.14-53.74%。统计显著性测试确认了其优越性。

Conclusion: 通过解决推理、依赖和上下文限制，CogniGent推进了bug定位技术状态，将类人认知与智能体自动化结合，实现了性能提升。

Abstract: Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.

</details>


### [37] [Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use](https://arxiv.org/abs/2601.12559)
*Yvan Labiche*

Main category: cs.SE

TL;DR: 开发了一个支持图形用户界面的自动化类别分区测试工具，能够自动生成测试框架和测试用例


<details>
  <summary>Details</summary>
Motivation: 类别分区是一种功能测试技术，但手动执行多个步骤（识别类别、选择、约束、组合等）效率低下，需要自动化工具支持

Method: 开发图形用户界面工具，允许用户指定参数和环境变量，定义类别和带约束的选择，然后工具根据不同类型（布尔、整数、实数、字符串）自动构建测试框架，按照不同选择标准组合选择，并为这些测试框架识别输入值

Result: 工具能够自动化类别分区测试的多个步骤，通过九个不同的案例研究展示了工具的能力

Conclusion: 成功开发了自动化类别分区测试工具，能够显著提高测试效率，通过多个案例验证了工具的实用性

Abstract: Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.

</details>


### [38] [OpenAI for OpenAPI: Automated generation of REST API specification via LLMs](https://arxiv.org/abs/2601.12735)
*Hao Chen,Yunchun Li,Chen Chen,Fengxu Lin,Wei Li*

Main category: cs.SE

TL;DR: OOPS：首个技术无关的LLM静态分析方法，用于从REST API代码自动生成OpenAPI规范，解决传统方法的语言限制和LLM的幻觉问题


<details>
  <summary>Details</summary>
Motivation: OpenAPI规范对REST API开发至关重要，但手动编写和维护困难。现有静态分析方法受限于特定编程语言和框架，而LLM方法存在上下文限制和幻觉问题，需要更通用的解决方案

Method: 提出OOPS方法，采用LLM代理工作流：1）端点方法提取；2）OAS生成。通过构建API依赖图解决上下文限制，采用多阶段生成和自优化机制缓解语法和语义幻觉

Result: 在12个真实REST API（5种编程语言、8种开发框架）上评估，端点方法推断F1-score超98%，请求参数和响应推断达97%，参数约束推断达92%。输入token平均低于5.6K，输出平均低于0.9K

Conclusion: OOPS是首个技术无关的LLM静态分析方法，能准确为多种技术实现的REST API生成高质量OpenAPI规范，减少技术特定规则和人工干预需求

Abstract: REST APIs, based on the REpresentational State Transfer (REST) architecture, are the primary type of Web API. The OpenAPI Specification (OAS) serves as the de facto standard for describing REST APIs and is crucial for multiple software engineering tasks. However, developers face challenges in writing and maintaining OAS. Although static analysis shows potential for OAS generation, it is limited to specific programming languages and development frameworks. The powerful code understanding capabilities of LLMs offer new opportunities for OAS generation, yet they are constrained by context limitations and hallucinations. To address these challenges, we propose the OpenAI OpenAPI Project Scanner (OOPS), the first technology-agnostic LLM-based static analysis method for OAS generation, requiring fewer technology-specific rules and less human expert intervention. OOPS is implemented as an LLM agent workflow comprising two key steps: endpoint method extraction and OAS generation. By constructing an API dependency graph, it establishes necessary file associations to address LLMs' context limitations. Through multi-stage generation and self-refine, it mitigates both syntactic and semantic hallucinations during OAS generation. We evaluated OOPS on 12 real-world REST APIs spanning 5 programming languages and 8 development frameworks. Experimental results demonstrate that OOPS accurately generates high-quality OAS for REST APIs implemented with diverse technologies, achieving an average F1-score exceeding 98% for endpoint method inference, 97% for both request parameter and response inference, and 92% for parameter constraint inference. The input tokens average below 5.6K with a maximum of 16.2K, while the output tokens average below 0.9K with a maximum of 7.7K.

</details>


### [39] [Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction](https://arxiv.org/abs/2601.12762)
*Xingjie Gao,Pengcheng Huang,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Chen Qian,Ge Yu,Yu Gu*

Main category: cs.SE

TL;DR: ToolMaster框架通过试错执行范式，让LLM从模仿静态轨迹转向主动与环境交互学习工具使用，显著提升了对新工具的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖记忆静态解决方案轨迹，限制了LLM对新引入或未见工具的泛化能力，工具使用的鲁棒性面临挑战。

Method: 采用试错执行范式：先让LLM模仿包含显式工具尝试和自我修正的教师生成轨迹，然后通过强化学习联合协调试错和执行阶段。

Result: ToolMaster在未见或不熟悉工具上的泛化能力和鲁棒性显著优于现有基线方法。

Conclusion: 通过主动与环境交互形成经验知识，ToolMaster能够自主探索正确的工具使用方法，有效解决了工具使用泛化问题。

Abstract: Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.

</details>


### [40] [Docker Does Not Guarantee Reproducibility](https://arxiv.org/abs/2601.12811)
*Julien Malka,Stefano Zacchiroli,Théo Zimmermann*

Main category: cs.SE

TL;DR: 该研究通过文献综述和实证分析，评估Docker在实践中的可复现性保证和局限性，发现虽然Docker常被视为理论上的可复现工具，但其实际效果仍需系统评估。


<details>
  <summary>Details</summary>
Motivation: 软件环境的可复现性对协作工作流、软件供应链安全和科学可复现性至关重要。Docker等容器化技术通过将软件环境封装成可共享的文件系统快照（镜像）来解决此问题。尽管文献中常引用Docker作为理论上支持可复现性的工具，但其实际保证和局限性仍未被充分探索。

Method: 采用两种互补方法：1）进行系统性文献综述，分析Docker在科学可复现性讨论中的定位，并识别实现可复现镜像构建的Dockerfile最佳实践；2）对从GitHub工作流收集的5298个Docker构建进行大规模实证研究，通过重建这些镜像并与历史版本比较，评估Docker镜像的实际可复现性以及文献中识别的最佳实践的有效性。

Result: 研究通过实证分析揭示了Docker镜像在实际构建中的可复现性程度，并评估了文献中最佳实践的实际效果。具体结果未在摘要中提供，但研究框架为理解Docker在实际应用中的可复现性保证提供了系统方法。

Conclusion: 该研究填补了Docker在可复现性方面理论与实践之间的差距，通过系统性文献综述和实证分析相结合的方法，为评估和改进Docker镜像的可复现性提供了重要见解，有助于提升软件工程实践中的环境可复现性。

Abstract: The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.
  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.

</details>


### [41] [Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles](https://arxiv.org/abs/2601.12845)
*João Pascoal Faria,Emanuel Trigo,Vinicius Honorato,Rui Abreu*

Main category: cs.SE

TL;DR: LLMs自动为Dafny程序生成形式化验证注释，结合Claude Opus 4.5和GPT-5.2的多模型方法在最多8次修复迭代中成功率为98.2%


<details>
  <summary>Details</summary>
Motivation: 当前形式化验证工具需要大量手动标注工作，包括前置条件、后置条件、循环不变式等，这需要专业知识和大量人工努力。研究旨在利用LLMs自动生成这些验证注释，降低形式化验证的门槛。

Method: 采用多模型方法结合Claude Opus 4.5和GPT-5.2，从带有自然语言注释和测试代码的常规程序开始，利用验证器反馈进行最多8次修复迭代。使用测试用例中的断言作为静态预言机验证生成的前置/后置条件。

Result: 在110个Dafny程序上的实验显示，该方法在最多8次修复迭代中为98.2%的程序生成了正确的验证注释。逻辑回归分析表明，证明辅助注释对当前LLMs构成不成比例的难度。IDE扩展获得了积极的可用性反馈。

Conclusion: LLMs能够有效自动生成形式化验证注释，显著减少手动标注工作。多模型方法和验证器反馈是关键成功因素，证明辅助注释仍是当前LLMs的主要挑战。该方法有望使形式化验证更易于软件工程师使用。

Abstract: Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.

</details>


### [42] [Efficient Code Analysis via Graph-Guided Large Language Models](https://arxiv.org/abs/2601.12890)
*Hang Gao,Tao Peng,Baoquan Cui,Hong Huang,Fengge Wu,Junsuo Zhao,Jian Zhang*

Main category: cs.SE

TL;DR: 提出图注意力获取管道，通过GNN引导LLM关注关键代码区域，提升恶意行为检测效果


<details>
  <summary>Details</summary>
Motivation: 恶意行为常隐藏在小型代码片段中，跨文件依赖使得即使强大LLM也难以可靠检测，需要增强LLM定位恶意行为的能力

Method: 将项目解析为代码图，用LLM编码节点语义和结构信息，在稀疏监督下训练GNN进行初步检测，回溯预测结果识别关键代码区域，引导LLM注意力进行深入分析

Result: 在多个公开和自建数据集上持续超越现有方法，显著减少无关上下文干扰，同时保持低标注成本

Conclusion: 该方法在软件安全场景中具有实际部署潜力，能有效增强LLM检测恶意代码的能力

Abstract: Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.

</details>


### [43] [A Benchmark for Language Models in Real-World System Building](https://arxiv.org/abs/2601.12927)
*Weilin Jin,Chenyu Zhao,Zeshun Huang,Chaoyun Zhang,Qingwei Lin,Chetan Bansal,Saravan Rajmohan,Shenglin Zhang,Yongqian Sun,Dan Pei,Yifan Wu,Tong Jia,Ying Li,Zhonghai Wu,Minghua Ma*

Main category: cs.SE

TL;DR: 提出了一个跨指令集架构和编程语言的软件包构建修复基准测试，包含268个真实构建失败案例，评估了6个先进LLM，发现跨ISA软件包修复仍然困难，需要进一步研究。


<details>
  <summary>Details</summary>
Motivation: 在跨指令集架构迁移过程中，软件包构建修复对于确保软件部署可靠性和操作系统稳定性至关重要。现有研究主要关注单一ISA和同质编程语言，缺乏跨架构和语言的评估基准。

Method: 引入了一个新的基准测试，专门用于评估跨多样架构和语言的软件包构建修复能力。该基准包含268个真实世界的软件包构建失败案例，并提供了标准化的评估流程。使用该基准评估了6个最先进的大型语言模型。

Result: 评估结果显示，跨ISA的软件包构建修复仍然是一个困难的任务，现有的大型语言模型在这一挑战上表现有限，需要进一步的技术进步来改善。

Conclusion: 通过系统性地揭示跨ISA软件包修复的挑战，该基准为未来方法的发展奠定了基础，旨在提高软件可移植性并弥合架构差距。

Abstract: During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.

</details>


### [44] [Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models](https://arxiv.org/abs/2601.12951)
*Felix Mächtle,Jan-Niclas Serr,Nils Loose,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: 本文研究发现LLM代码理解能力与传统人类中心软件度量指标相关性很弱，揭示了LLM具有模型特定的规律性，需要超越聚合准确率的基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试仅提供粗略性能总结，无法揭示模型在代码理解方面的多样化能力和局限性。需要探究LLM的代码理解性能是否与传统人类中心软件度量指标一致，还是反映了独特的非人类规律性。

Method: 引入诊断框架，将代码理解重构为二元输入输出一致性任务，支持分类和生成模型评估。使用大规模数据集，将模型性能与传统人类中心复杂度指标（如词汇量、控制流复杂度、抽象语法树结构）进行相关性分析。

Result: 人类定义指标与LLM成功之间的相关性很弱（AUROC 0.63），而影子模型获得显著更高的预测性能（AUROC 0.86），捕捉到了超越传统软件度量的复杂、部分可预测模式。

Conclusion: LLM理解反映了模型特定的规律性，这些规律性只能通过人类设计或学习特征部分获取。强调需要超越聚合准确率、转向实例级诊断的基准测试方法，同时承认预测正确结果存在根本性限制。

Abstract: Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.

</details>


### [45] [ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs](https://arxiv.org/abs/2601.13007)
*Rusheng Pan,Bingcheng Mao,Tianyi Ma,Zhenhua Ling*

Main category: cs.SE

TL;DR: ArchAgent：一个基于智能体的可扩展框架，通过结合静态分析、自适应代码分割和LLM驱动的合成，从跨仓库代码库中重构多视图、业务对齐的软件架构。


<details>
  <summary>Details</summary>
Motivation: 从大规模遗留软件中恢复准确架构面临三大挑战：架构漂移、关系缺失以及大型语言模型（LLM）的上下文限制。现有方法难以有效处理跨仓库代码库和业务关键模块的识别。

Method: ArchAgent框架结合静态分析、自适应代码分割和LLM驱动的合成。引入可扩展的图表生成机制，包含上下文剪枝，并集成跨仓库数据来识别业务关键模块。

Result: 在典型的大规模GitHub项目评估中，相比现有基准有显著改进。消融研究证实依赖上下文能提高生产级仓库生成架构的准确性，真实案例研究展示了从遗留项目中有效恢复关键业务逻辑的能力。

Conclusion: ArchAgent能够有效解决大规模遗留软件架构恢复的挑战，通过智能体框架实现可扩展的多视图架构重构，并成功识别业务关键模块，数据集已公开供研究使用。

Abstract: Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.

</details>


### [46] [MeltRTL: Multi-Expert LLMs with Inference-time Intervention for RTL Code Generation](https://arxiv.org/abs/2601.13015)
*Nowfel Mashnoor,Mohammad Akyash,Hadi Kamali,Kimia Azar*

Main category: cs.SE

TL;DR: MeltRTL框架通过多专家注意力架构和推理时干预机制，显著提升LLM生成硬件RTL代码的准确率，无需重新训练基础模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的硬件寄存器传输级（RTL）代码自动生成方法在生成复杂数字设计的语法和功能正确代码方面存在困难。

Method: 提出MeltRTL框架，包含三个关键创新：1）多专家注意力架构，动态路由设计规范到专业专家网络；2）推理时干预机制，使用非线性探针检测和纠正硬件特定错误；3）高效干预框架，选择性地操作专家特定注意力头，计算开销最小。

Result: 在VerilogEval基准测试中，MeltRTL实现了96%的可综合性和60%的功能正确性，相比基础LLM的85.3%和45.3%有显著提升。这些改进完全在推理时获得，仅增加27%计算开销，无需模型微调。

Conclusion: MeltRTL通过结合多专家架构和推理时干预，显著提高了LLM生成RTL代码的准确性，且可直接部署在现有预训练LLM上，无需重新训练。

Abstract: The automated generation of hardware register-transfer level (RTL) code with large language models (LLMs) shows promise, yet current solutions struggle to produce syntactically and functionally correct code for complex digital designs. This paper introduces MeltRTL, a novel framework that integrates multi-expert attention with inference-time intervention (ITI) to significantly improve LLM-based RTL code generation accuracy without retraining the base model. MeltRTL introduces three key innovations: (1) A multi-expert attention architecture that dynamically routes design specifications to specialized expert networks, enabling targeted reasoning across various hardware categories; (2) An inference-time intervention mechanism that employs non-linear probes to detect and correct hardware-specific inaccuracies during generation; and (3) An efficient intervention framework that selectively operates on expert-specific attention heads with minimal computational overhead. We evaluate MeltRTL on the VerilogEval benchmark, achieving 96% synthesizability and 60% functional correctness, compared to the base LLM's 85.3% and 45.3%, respectively. These improvements are obtained entirely at inference time, with only 27% computational overhead and no model fine-tuning, making MeltRTL immediately deployable on existing pre-trained LLMs. Ablation studies further show the complementary benefits of multi-expert architecture and ITI, highlighting their synergistic effects when combined.

</details>


### [47] [RM -RF: Reward Model for Run-Free Unit Test Evaluation](https://arxiv.org/abs/2601.13097)
*Elena Bruches,Daniil Grebenkin,Mikhail Klementev,Vadim Alperovich,Roman Derunets,Dari Baturova,Georgy Mkrtchyan,Oleg Sedukhin,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

TL;DR: RM-RF是一个轻量级奖励模型，用于免运行评估自动生成的单元测试，通过源代码和测试代码预测三个执行相关信号，相比传统编译执行方法显著降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 传统测试生成评估需要反复编译和执行测试，导致高延迟和高基础设施成本，限制了大规模测试生成和基于强化学习的代码优化的可扩展性。

Method: 构建多语言数据集（Java、Python、Go），包含源代码、测试文件和候选测试添加的标签；训练RM-RF模型从源代码和测试代码直接预测三个执行相关信号：编译运行成功、代码覆盖率提升、突变杀死率改进；测试多种模型家族和调优策略（零样本、全微调、LoRA PEFT）。

Result: 在三个预测目标上平均F1达到0.69；相比传统编译执行方法，RM-RF提供显著更低的延迟和基础设施成本，同时保持有竞争力的预测保真度。

Conclusion: RM-RF能够为大规模测试生成和基于强化学习的代码优化提供快速、可扩展的反馈，解决了传统评估方法的高成本和延迟问题。

Abstract: We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.

</details>


### [48] [Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization](https://arxiv.org/abs/2601.13118)
*Alessandro Midolo,Alessandro Giagnorio,Fiorella Zampetti,Rosalia Tufano,Gabriele Bavota,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: 本文提出并评估了针对代码生成的特定提示优化指南，通过测试驱动方法识别有效的提示改进模式，并制定了10条实用指南。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型已广泛用于软件工程任务（特别是代码生成），且已有研究表明合适的提示工程能改善代码生成效果，但目前缺乏专门针对代码生成的提示优化指南来指导开发者编写更有效的提示。

Method: 采用迭代的测试驱动方法自动优化代码生成提示，分析优化过程中的成功模式，从中提取出10条提示改进指南，包括更好地指定输入输出、前置后置条件、提供示例、添加细节和澄清歧义等方面。随后对50名从业者进行评估，了解他们对这些指南的使用情况和感知有用性。

Result: 研究识别出了有效的提示改进模式，并制定了10条具体的提示优化指南。从业者评估显示，这些指南的实际使用情况与感知有用性并不完全一致，表明开发者可能没有充分认识到某些有效提示模式的价值。

Conclusion: 该研究为从业者、教育工作者以及开发LLM辅助软件开发工具的人员提供了实用的提示优化指南，有助于提高代码生成的质量和效率。

Abstract: Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.

</details>


### [49] [Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access](https://arxiv.org/abs/2601.13134)
*Heng Fang,Adam J. Stewart,Isaac Corley,Xiao Xiang Zhu,Hossein Azizpour*

Main category: cs.SE

TL;DR: 论文提出统一API标准化地理空间基础模型嵌入数据产品的加载和查询，解决现有产品格式不兼容、分辨率不一致导致的工程瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型(GFMs)虽然提供强大表示能力，但高计算成本阻碍其广泛应用。预计算嵌入数据产品提供了实用的"冻结"替代方案，但当前存在格式不兼容、分辨率不一致的碎片化生态系统，缺乏标准化导致模型比较和可复现性困难。

Method: 1. 通过三层分类法(数据、工具、价值)形式化描述当前格局；2. 调查现有产品识别互操作性障碍；3. 扩展TorchGeo提供统一API，标准化不同嵌入产品的加载和查询，将嵌入视为一等地理空间数据集。

Result: 开发了统一API框架，解耦下游分析与模型特定工程，为更透明和可访问的地球观测工作流程提供路线图。

Conclusion: 通过标准化嵌入数据产品的访问接口，解决了地理空间基础模型应用中的工程瓶颈，促进了模型比较、可复现性和更高效的地球观测工作流程。

Abstract: Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical "frozen" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.

</details>


### [50] [From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability](https://arxiv.org/abs/2601.13139)
*Alessandro Midolo,Emiliano Tramontana,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: GPT-4o能有效进行行为保持的代码重构，减少代码异味并提升质量指标，但会降低代码可读性。


<details>
  <summary>Details</summary>
Motivation: 尽管自动化重构工具已有广泛研究，但其实际应用仍有限制。大型语言模型（LLMs）为自动化代码重构带来了新机遇，但LLM驱动方法对代码质量的影响尚未得到充分评估。

Method: 使用GPT-4o对ClassEval基准测试中的100个Python类进行全面的实证研究。研究探索了基于Fowler重构目录的广泛类级重构，并从三个互补角度评估效果：1）通过单元测试验证行为正确性；2）使用Pylint、Flake8和SonarCloud评估代码质量；3）使用最先进的可读性工具测量可读性。

Result: GPT-4o通常能产生行为保持的重构，减少代码异味并改善质量指标，但代价是降低了代码可读性。

Conclusion: 研究结果为LLMs在自动化软件重构中的能力和局限性提供了新证据，突出了将LLMs集成到实际重构工作流中的方向。

Abstract: Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.

</details>


### [51] [KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?](https://arxiv.org/abs/2601.13240)
*Xue Jiang,Jiaru Qian,Xianjie Shi,Chenjie Li,Hao Zhu,Ziyu Wang,Jielun Zhang,Zheyu Zhao,Kechi Zhang,Jia Li,Wenpin Jiao,Zhi Jin,Ge Li,Yihong Dong*

Main category: cs.SE

TL;DR: KOCO-BENCH是一个针对领域专业化方法的代码基准测试，包含6个新兴领域、11个软件框架和25个项目，通过知识库和多粒度评估任务来测试LLMs获取和应用领域知识的能力。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定代码基准测试无法有效评估领域专业化方法，它们主要关注LLMs拥有什么知识，而不是如何获取和应用新知识，且缺乏明确的知识库来开发领域专业化方法。

Method: 构建包含6个新兴领域、11个软件框架和25个项目的基准测试，提供精心策划的知识库，设计多粒度评估任务：从函数级到项目级的领域代码生成（带有严格测试套件）和领域知识理解（通过多项选择题）。

Result: KOCO-BENCH对最先进的LLMs构成重大挑战，即使应用领域专业化方法（如SFT、RAG、kNN-LM），改进也很有限。表现最佳的编码代理Claude Code仅达到34.2%的准确率。

Conclusion: 该基准测试揭示了当前领域专业化方法的不足，迫切需要更有效的领域专业化方法，并发布了完整的基准测试、评估代码和基线以促进进一步研究。

Abstract: Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.

</details>


### [52] [SEER: Spectral Entropy Encoding of Roles for Context-Aware Attention-Based Design Pattern Detection](https://arxiv.org/abs/2601.13334)
*Tarik Houichime,Younes El Amrani*

Main category: cs.SE

TL;DR: SEER是GoF设计模式检测方法的升级版，通过谱熵角色编码和时间加权调用上下文改进角色识别和调用重要性评估，在保持跨语言可移植性的同时提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 先前方法缺乏对类内角色的明确区分，且将调用边统一处理，无法准确识别"谁做什么"和"调用重要性"，需要改进设计模式检测的精确性和鲁棒性。

Method: 1. 谱熵角色编码器：从每个类的交互图的拉普拉斯谱中推导每个成员的嵌入；2. 时间加权调用上下文：为不同方法类别（构造函数、getter/setter、静态调用等）分配经验校准的持续时间先验。

Result: 在PyDesignNet数据集上，macro-F1从92.47%提升到93.20%，准确率从92.52%提升到93.98%，假阳性减少近20%，同时保持可解释性和鲁棒性。

Conclusion: SEER通过角色区分和时间加权改进了设计模式检测，不仅提升性能指标，还增强实际可靠性，为设计模式分析提供了更精确和可解释的工具。

Abstract: This paper presents SEER, an upgraded version of our prior method Context Is All You Need for detecting Gang of Four (GoF) design patterns from source code. The earlier approach modeled code as attention-ready sequences that blended lightweight structure with behavioral context; however, it lacked explicit role disambiguation within classes and treated call edges uniformly. SEER addresses these limitations with two principled additions: (i) a spectral-entropy role encoder that derives per-member role embeddings from the Laplacian spectrum of each class's interaction graph, and (ii) a time-weighted calling context that assigns empirically calibrated duration priors to method categories (e.g., constructors, getters/setters, static calls, virtual dispatch, cloning). Together, these components sharpen the model's notion of "who does what" and "how much it matters," while remaining portable across languages with minimal adaptation and fully compatible with Transformer-based sequence encoders. Importantly, SEER does not "force" a win by capacity or data; it nudges the classifier, steering attention toward role-consistent and temporally calibrated signals that matter most. We evaluate SEER on PyDesignNet (1,832 files, 35,000 sequences, 23 GoF patterns) and observe consistent gains over our previous system: macro-F1 increases from 92.47% to 93.20% and accuracy from 92.52% to 93.98%, with macro-precision 93.98% and macro-recall 92.52%. Beyond aggregate metrics, SEER reduces false positives by nearly 20%, a decisive improvement that strengthens its robustness and practical reliability. Moreover, SEER yields interpretable, symbol-level attributions aligned with canonical roles, exhibits robustness under small graph perturbations, and shows stable calibration.

</details>


### [53] [FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels](https://arxiv.org/abs/2601.13345)
*Saurabhsingh Rajput,Alexander Brandt,Vadim Elisseev,Tushar Sharma*

Main category: cs.SE

TL;DR: FlipFlop是一个使用静态代码分析预测GPU程序能耗并推荐帕累托最优线程块配置的框架，无需运行时执行，可显著减少能耗和优化搜索空间。


<details>
  <summary>Details</summary>
Motivation: GPU程序（内核）消耗大量能源，但软件开发者通常缺乏硬件专业知识和专门知识来优化能效。现有方法需要运行时执行或依赖专家经验，效率低下。

Method: 使用静态代码分析分析PTX代码（CUDA GPU的低级指令集），预测能耗并推荐帕累托最优的线程块配置，考虑功耗和执行时间。框架无需运行时执行，集成静态分析与实时监控，提供可解释的优化指导。

Result: 在多样化GPU和内核（包括多头注意力、卷积和矩阵乘法）上验证，达到83%准确率识别局部最优能效配置，减少93.4%优化搜索空间。对多头注意力内核，相比NVIDIA占用率启发式方法，实现高达79%节能和106%吞吐量增益。

Conclusion: FlipFlop通过静态分析与实时监控相结合，为开发者提供可解释的优化指导，赋能创建可持续、高性能的GPU软件，最小化环境和计算成本。

Abstract: Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.

</details>


### [54] [From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning](https://arxiv.org/abs/2601.13384)
*Jiajun Zhang,Zeyu Cui,Jiaxi Yang,Lei Zhang,Yuheng Jing,Zeyao Ma,Tianyi Bai,Zilei Wang,Qiang Liu,Liang Wang,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: SRI框架将代理式验证-编辑机制融入单次推理，让Chat模型超越Base模型完成性能，同时保持推理延迟与FIM相当


<details>
  <summary>Details</summary>
Motivation: 传统FIM范式无法修正上下文错误且依赖不安全的基础模型，而Chat模型虽安全但性能下降，代理工作流灵活但延迟过高，需要解决这一困境

Method: 提出Search-and-Replace Infilling框架，通过显式搜索阶段结构化编辑，将代理验证编辑机制统一到单次推理中，并创建SRI-200K数据集微调SRI-Coder系列

Result: 仅用2万样本，SRI-Coder使Chat模型超越基础模型完成性能，保持通用编码能力，推理延迟与标准FIM相当，已赋能整个Qwen3-Coder系列

Conclusion: SRI框架将静态填充扩展到动态上下文感知编辑，为开发者社区提供先进的自动完成和辅助开发工具

Abstract: The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.

</details>


### [55] [A Tool for Automatically Cataloguing and Selecting Pre-Trained Models and Datasets for Software Engineering](https://arxiv.org/abs/2601.13460)
*Alexandra González,Oscar Cerezo,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: MLAssetSelection是一个帮助软件工程师从大型注册库中筛选机器学习模型和数据集的Web应用，支持可配置排行榜、基于需求的选择、实时更新和个性化功能。


<details>
  <summary>Details</summary>
Motivation: 机器学习资产快速增长，软件工程师难以从大型注册库（如Hugging Face）中找到适合软件工程任务的模型和数据集，现有浏览方式耗时、易错且不针对SE任务。

Method: 开发了MLAssetSelection Web应用，自动提取SE资产，提供四个核心功能：可配置的跨基准和指标模型排行榜、基于需求的模型和数据集选择、通过定时任务实现实时自动化更新、用户登录、个性化资产列表和可配置警报通知等用户中心功能。

Result: 提出了一个功能完整的Web应用原型，包含演示视频（https://youtu.be/t6CJ6P9asV4），能够帮助软件工程师更高效地发现和选择适合其SE任务的机器学习资产。

Conclusion: MLAssetSelection通过自动化提取和智能筛选机制，解决了软件工程师在大型机器学习资产注册库中寻找合适资源的难题，提高了资产发现的效率和针对性。

Abstract: The rapid growth of machine learning assets has made it increasingly difficult for software engineers to identify models and datasets that match their specific needs. Browsing large registries, such as Hugging Face, is time-consuming, error-prone, and rarely tailored to Software Engineering (SE) tasks. We present MLAssetSelection, a web application that automatically extracts SE assets and supports four key functionalities: (i) a configurable leaderboard for ranking models across multiple benchmarks and metrics; (ii) requirements-based selection of models and datasets; (iii) real-time automated updates through scheduled jobs that keep asset information current; and (iv) user-centric features including login, personalized asset lists, and configurable alert notifications. A demonstration video is available at https://youtu.be/t6CJ6P9asV4.

</details>


### [56] [Governance Matters: Lessons from Restructuring the data.table OSS Project](https://arxiv.org/abs/2601.13466)
*Pedro Oliveira,Doris Amoakohene,Toby Hocking,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: 该论文通过对data.table R包社区治理改革的案例研究，展示了开源软件治理结构改革如何显著提升项目可持续性、贡献者参与度和问题解决效率。


<details>
  <summary>Details</summary>
Motivation: 开源软件在工业数据工作流和企业系统中扮演关键角色，但许多项目面临非正式或集中式治理带来的运营风险。data.table作为广泛用于生产分析管道的高性能R包，面临未解决问题积压、贡献者路径不清晰、依赖单一核心维护者等可持续性问题，需要进行治理改革。

Method: 采用混合方法研究：结合贡献者调查（n=17）和项目仓库数据挖掘，评估data.table社区治理改革的影响。

Result: 治理改革后，项目新贡献者招募增加200%，pull request解决时间从700多天降至一周内，贡献者保留率提升3倍。社区对透明度、入门流程和项目动力的情感改善，但公平性和冲突解决方面仍存在担忧。

Conclusion: 社区主导的治理改革能显著提升开源项目的可持续性和运营效率，为维护者、公司和基金会提供了实用的治理改进指导。

Abstract: Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.

</details>


### [57] [AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development](https://arxiv.org/abs/2601.13597)
*Shyam Agarwal,Hao He,Bogdan Vasilescu*

Main category: cs.SE

TL;DR: LLM代码代理在开源项目中带来短期开发速度提升但长期质量风险，尤其当项目已有AI IDE工具时收益有限


<details>
  <summary>Details</summary>
Motivation: 研究LLM代码代理在真实软件开发项目中的实际影响，特别是相对于广泛采用的IDE AI助手的效果差异

Method: 使用AIDev数据集进行纵向因果研究，采用交错差分法匹配对照组，分析代理采纳后的月度仓库级结果

Result: 代理仅在项目首次使用AI工具时带来显著速度提升；已有AI IDE的项目收益有限；质量风险持续存在，静态分析警告增加18%，认知复杂度增加35%

Conclusion: AI代理存在收益递减效应，需要质量保障措施、来源追踪和选择性部署，以平衡开发速度与可维护性

Abstract: Large language model (LLM)-based coding agents increasingly act as autonomous contributors that generate and merge pull requests, yet their real-world effects on software projects are unclear, especially relative to widely adopted IDE-based AI assistants. We present a longitudinal causal study of agent adoption in open-source repositories using staggered difference-in-differences with matched controls. Using the AIDev dataset, we define adoption as the first agent-generated pull request and analyze monthly repository-level outcomes spanning development velocity (commits, lines added) and software quality (static-analysis warnings, cognitive complexity, duplication, and comment density). Results show large, front-loaded velocity gains only when agents are the first observable AI tool in a project; repositories with prior AI IDE usage experience minimal or short-lived throughput benefits. In contrast, quality risks are persistent across settings, with static-analysis warnings and cognitive complexity rising roughly 18% and 35%, indicating sustained agent-induced complexity debt even when velocity advantages fade. These heterogeneous effects suggest diminishing returns to AI assistance and highlight the need for quality safeguards, provenance tracking, and selective deployment of autonomous agents. Our findings establish an empirical basis for understanding how agentic and IDE-based tools interact, and motivate research on balancing acceleration with maintainability in AI-integrated development workflows.

</details>


### [58] [Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs](https://arxiv.org/abs/2601.13655)
*Guangba Yu,Zirui Wang,Yujie Huang,Renyi Zhong,Yuedong Zhong,Yilun Wang,Michael R. Lyu*

Main category: cs.SE

TL;DR: 该研究首次对开源LLM生态系统中的真实世界故障进行大规模实证分析，发现白盒编排将可靠性瓶颈从模型算法缺陷转移到部署栈的系统脆弱性上。


<details>
  <summary>Details</summary>
Motivation: 开源LLM的民主化使用户能够在本地基础设施上微调和部署模型，但暴露了"第一英里"部署环境的可靠性问题。与黑盒API消费不同，用户管理的编排可靠性是一个关键盲点，需要填补这一研究空白。

Method: 对来自DeepSeek、Llama和Qwen生态系统的705个真实世界故障进行大规模实证研究，分析开源LLM部署中的失败案例。

Result: 研究发现三个关键现象：1) 诊断分歧：运行时崩溃独特地指示基础设施摩擦，而不正确功能是内部tokenizer缺陷的特征；2) 系统同质性：根本原因在不同系列中趋同，确认可靠性障碍是生态系统固有的；3) 生命周期升级：障碍从微调期间的内在配置斗争升级到推理期间的复合环境不兼容。

Conclusion: 白盒编排将可靠性瓶颈从模型算法缺陷转移到部署栈的系统脆弱性。这些见解为增强LLM生态系统的可靠性提供了可操作的指导，并支持公开可用的数据集。

Abstract: The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.
  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.

</details>


### [59] [SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories](https://arxiv.org/abs/2601.13713)
*Aditya Bharat Soni,Rajat Ghosh,Vaishnavi Bhargava,Valerie Chen,Debojyoti Dutta*

Main category: cs.SE

TL;DR: 提出SWE-Tester框架，通过训练开源LLM从自然语言问题描述自动生成问题复现测试，在SWT-Bench Verified上成功率提升10%，变更覆盖率提升21%


<details>
  <summary>Details</summary>
Motivation: 软件测试对确保软件正确性和可靠性至关重要。从自然语言问题描述自动生成问题复现测试能提高开发效率、促进测试驱动开发，并增强自动化问题解决系统（如编码代理）的效果。现有方法主要依赖闭源LLM，对开源模型探索有限。

Method: 提出SWE-Tester训练管道：1) 从2.6K个开源GitHub仓库中整理41K个高质量训练实例数据集；2) 使用该数据集训练不同规模和系列的开源LLM；3) 通过微调模型生成问题复现测试。

Result: 微调模型在SWT-Bench Verified上实现绝对成功率提升10%，变更覆盖率提升21%。分析显示增加推理计算量、更多数据和更大模型能带来持续改进。

Conclusion: SWE-Tester框架有效推进了开源LLM在问题复现测试生成领域的应用，展示了开源模型在该任务上的潜力。

Abstract: Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- "test first, write code later", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\% in success rate and 21\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.

</details>


### [60] [Counterexample Classification against Signal Temporal Logic Specifications](https://arxiv.org/abs/2601.13743)
*Zhenya Zhang,Parv Kapoor,Jie An,Eunsuk Kang*

Main category: cs.SE

TL;DR: 提出基于参数信号时序逻辑(PSTL)的反例分类方法，通过推导类间包含关系并采用二分搜索策略提高分类效率


<details>
  <summary>Details</summary>
Motivation: 实际系统中违反STL规范的反例可能源于不同原因，对应不同系统缺陷，需要有效的分类标准来理解违规模式及其分布

Method: 使用参数信号时序逻辑(PSTL)表示每个反例类，推导类间包含关系，提出基于二分搜索的类识别方法以减少查询次数

Result: 实现了原型工具，在两个广泛研究的系统上实验验证了方法的有效性

Conclusion: 提出的PSTL分类标准和高效识别方法能够有效分类反例，帮助理解系统违规模式分布

Abstract: Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.

</details>


### [61] [On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source](https://arxiv.org/abs/2601.13754)
*Haoyu Gao,Peerachai Banyongrakkul,Hao Guan,Mansooreh Zahedi,Christoph Treude*

Main category: cs.SE

TL;DR: 研究发现：在开源软件中，AI协作的PR（Pull Requests）主要由无代码所有权的贡献者发起，但多数仓库缺乏AI使用指南；AI协作的PR合并速度更快、反馈更少，约80%无需明确审查即被合并。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件工程任务中的自动化应用增加，"AI作为队友"在开源软件中的采用加速，但开发者与AI协作的互动模式尚未得到充分探索。本研究旨在调查项目级指南和开发者与AI辅助PR的互动模式。

Method: 通过扩展AIDev数据集，纳入更细粒度的贡献者代码所有权信息，并与人类创建的PR建立比较基线。分析AI协作PR的来源、项目指南情况以及开发者互动模式。

Result: 1. 超过67.5%的AI协作PR来自无先前代码所有权的贡献者；2. 大多数仓库缺乏AI编码代理使用指南；3. AI协作PR合并速度显著更快，反馈极少；4. 与人类PR不同，AI协作PR中非所有者贡献者收到的反馈最少，约80%无需明确审查即被合并。

Conclusion: AI协作PR呈现出独特的互动模式：主要由外部贡献者发起，合并速度快且审查少，这为开发者和研究者提出了关于代码质量、审查流程和协作规范的重要问题。

Abstract: Large Language Models (LLMs) increasingly automate software engineering tasks. While recent studies highlight the accelerated adoption of ``AI as a teammate'' in Open Source Software (OSS), developer interaction patterns remain under-explored. In this work, we investigated project-level guidelines and developers' interactions with AI-assisted pull requests (PRs) by expanding the AIDev dataset to include finer-grained contributor code ownership and a comparative baseline of human-created PRs. We found that over 67.5\% of AI-co-authored PRs originate from contributors without prior code ownership. Despite this, the majority of repositories lack guidelines for AI-coding agent usage. Notably, we observed a distinct interaction pattern: AI-co-authored PRs are merged significantly faster with minimal feedback. In contrast to human-created PRs where non-owner developers receive the most feedback, AI-co-authored PRs from non-owners receive the least, with approximately 80\% merged without any explicit review. Finally, we discuss implications for developers and researchers.

</details>


### [62] [A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems](https://arxiv.org/abs/2601.13772)
*Matteo Vaccargiu,Azmat Ullah,Pierluigi Gallo*

Main category: cs.SE

TL;DR: 提出基于区块链的碳信用认证架构，整合物联网实时数据采集、边缘聚合和许可链智能合约，通过100kWp光伏案例验证，符合欧洲法规和自愿碳市场标准。


<details>
  <summary>Details</summary>
Motivation: 现有区块链和物联网技术在排放监测和交易中的应用有限，尤其缺乏对中小型可再生能源装置认证流程的支持，需要符合法规的可靠碳信用认证机制。

Method: 设计区块链碳信用认证架构，整合物联网实时数据采集、边缘级数据聚合，在许可区块链上通过智能合约实现安全链上存储，以100kWp光伏系统为案例验证。

Result: 开发出符合欧洲立法和自愿碳市场标准的认证系统，为光伏运营商提供明确的实践要求和约束，建立可验证碳信用记录的结构化路径，支持第三方验证。

Conclusion: 该区块链架构为中小型可再生能源装置提供了可靠的碳信用认证解决方案，填补了现有技术空白，支持可验证的减排记录生成和第三方审计。

Abstract: Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.

</details>


### [63] [Multi-Location Software Model Completion](https://arxiv.org/abs/2601.13894)
*Alisa Welter,Christof Tinnes,Sven Apel*

Main category: cs.SE

TL;DR: 提出NextFocus方法，首次实现多位置软件模型自动补全，通过全局嵌入和注意力机制预测跨多个位置的协调变更


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法仅支持单位置模型补全，无法处理大型复杂模型中跨多个位置的协调变更，需要解决这一局限性

Method: 提出基于全局嵌入的下一个焦点预测器NextFocus，使用带注意力机制的神经网络，在历史软件模型演化数据上训练，从现有变更开始预测多个模型元素的变更

Result: 在真实项目中的多位置模型变更上评估，NextFocus取得显著成果，即使变更分散在模型中，Precision@k分数平均达0.98（k≤10），显著优于三个基线方法

Conclusion: NextFocus首次实现了多位置模型补全，能有效处理跨多个位置的协调变更，为自动化软件建模活动提供了重要进展

Abstract: In model-driven engineering and beyond, software models are key development artifacts. In practice, they often grow to substantial size and complexity, undergoing thousands of modifications over time due to evolution, refactoring, and maintenance. The rise of AI has sparked interest in how software modeling activities can be automated. Recently, LLM-based approaches for software model completion have been proposed, however, the state of the art supports only single-location model completion by predicting changes at a specific location. Going beyond, we aim to bridge the gap toward handling coordinated changes that span multiple locations across large, complex models. Specifically, we propose a novel global embedding-based next focus predictor, NextFocus, which is capable of multi-location model completion for the first time. The predictor consists of a neural network with an attention mechanism that is trained on historical software model evolution data. Starting from an existing change, it predicts further model elements to change, potentially spanning multiple parts of the model. We evaluate our approach on multi-location model changes that have actually been performed by developers in real-world projects. NextFocus achieves promising results for multi-location model completion, even when changes are heavily spread across the model. It achieves an average Precision@k score of 0.98 for $k \leq 10$, significantly outperforming the three baseline approaches.

</details>


### [64] [VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution](https://arxiv.org/abs/2601.13933)
*Mingming Zhang,Xu Wang,Jian Zhang,Xiangxin Meng,Jiayi Zhang,Chunming Hu*

Main category: cs.SE

TL;DR: VulnResolver：首个基于LLM的混合代理框架，用于自动化漏洞问题解决，通过两个专门代理结合自主代理的适应性和工作流引导修复的稳定性，在SEC-bench基准测试中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性增加，安全漏洞日益普遍且代价高昂。现有自动化漏洞修复方法严重依赖人工标注（如故障位置或CWE标签），这些标注难以获取且耗时，同时忽略了开发者问题报告中丰富的自然语义上下文。

Method: 提出VulnResolver框架，包含两个专门代理：上下文预收集代理（CPCAgent）自适应探索仓库收集依赖和上下文信息；安全属性分析代理（SPAAgent）生成并验证被漏洞违反的安全属性。这些代理共同生成结构化分析，丰富原始问题报告，实现更准确的漏洞定位和补丁生成。

Result: 在SEC-bench基准测试中，VulnResolver在SEC-bench Lite上解决了75%的问题，达到最佳解决性能。在SEC-bench Full上，也显著优于最强的基于代理的基线OpenHands，证实了其有效性。

Conclusion: VulnResolver提供了一个自适应且安全感知的框架，通过工作流稳定性和专门代理在上下文推理和基于属性分析方面的能力，推进了端到端自动化漏洞问题解决的进展。

Abstract: As software systems grow in complexity, security vulnerabilities have become increasingly prevalent, posing serious risks and economic costs. Although automated detection tools such as fuzzers have advanced considerably, effective resolution still often depends on human expertise. Existing automated vulnerability repair (AVR) methods rely heavily on manually provided annotations (e.g., fault locations or CWE labels), which are often difficult and time-consuming to obtain, while overlooking the rich, naturally embedded semantic context found in issue reports from developers.
  In this paper, we present VulnResolver, the first LLM-based hybrid agent framework for automated vulnerability issue resolution. VulnResolver unites the adaptability of autonomous agents with the stability of workflow-guided repair through two specialized agents. The Context Pre-Collection Agent (CPCAgent) adaptively explores the repository to gather dependency and contextual information, while the Safety Property Analysis Agent (SPAAgent) generates and validates the safety properties violated by vulnerabilities. Together, these agents produce structured analyses that enrich the original issue reports, enabling more accurate vulnerability localization and patch generation.
  Evaluations on the SEC-bench benchmark show that VulnResolver resolves 75% of issues on SEC-bench Lite, achieving the best resolution performance. On SEC-bench Full, VulnResolver also significantly outperforms the strongest baseline, the agent-based OpenHands, confirming its effectiveness. Overall, VulnResolver delivers an adaptive and security-aware framework that advances end-to-end automated vulnerability issue resolution through workflow stability and the specialized agents' capabilities in contextual reasoning and property-based analysis.

</details>


### [65] [RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository](https://arxiv.org/abs/2601.13943)
*Zhiyuan Peng,Xin Yin,Pu Zhao,Fangkai Yang,Lu Wang,Ran Jia,Xu Chen,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.SE

TL;DR: RepoGenesis是首个多语言仓库级端到端Web微服务生成基准，包含106个仓库，评估显示现有系统在架构一致性、依赖管理和跨文件一致性方面存在不足，而基于该基准微调的模型能达到GPT-5 mini相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注孤立函数/类级代码生成或现有代码库修改，缺乏反映真实0到1开发流程的完整微服务仓库生成基准，需要填补这一空白。

Method: 创建包含106个仓库（60个Python，46个Java）的多语言基准，涵盖18个领域和11个框架，包含1,258个API端点和2,335个测试用例，通过"评审-反驳"质量保证流程验证。使用Pass@1、API覆盖率和部署成功率评估开源代理和商业IDE。

Result: 尽管API覆盖率高达73.91%，部署成功率高达100%，但最佳系统在Python和Java上的Pass@1分别仅为23.67%和21.45%，暴露了架构一致性、依赖管理和跨文件一致性的缺陷。基于RepoGenesis微调的GenesisAgent-8B能达到GPT-5 mini相当的性能。

Conclusion: RepoGenesis基准揭示了当前微服务生成系统的局限性，并为推进该领域发展提供了高质量评估框架。基于该基准微调的模型表现出色，证明了基准的质量和实用性。

Abstract: Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a "review-rebuttal" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis.

</details>


### [66] [Software Testing in the Quantum World](https://arxiv.org/abs/2601.13996)
*Rui Abreu,Shaukat Ali,Paolo Arcaini,Jose Campos,Michael Felderer,Claude Gravel,Fuyuki Ishikawa,Stefan Klikovits,Andriy Miranskyy,Mohammad Mousavi,Masaomi Yamaguchi,Lei Zhang,Jianjun Zhao,Anila Mjeda*

Main category: cs.SE

TL;DR: 量子软件测试面临新挑战：随着量子软件复杂度增加，经典模拟变得不可行，需要直接在真实量子计算机上进行质量保证的新方法


<details>
  <summary>Details</summary>
Motivation: 量子计算在物理、化学、生物系统模拟以及优化和机器学习方面具有显著加速优势。随着量子软件复杂度增加，长期以来用于质量保证的经典模拟变得不可行，需要开发直接在真实量子计算机上运行的新质量保证方法

Method: 本文分析了大规模量子软件测试的关键挑战，并从软件工程角度提出了解决这些挑战的视角和方法

Result: 识别了量子软件测试面临的主要挑战，包括经典模拟不可行性、量子硬件限制、噪声和错误率等问题，为量子软件质量保证提供了新的研究方向

Conclusion: 随着量子计算从模拟转向实际硬件执行，需要开发新的软件工程方法和测试技术来确保大规模量子软件的质量，这是量子计算领域的重要研究方向

Abstract: Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.

</details>


### [67] [Analyzing the Availability of E-Mail Addresses for PyPI Libraries](https://arxiv.org/abs/2601.14034)
*Alexandros Tsakpinis,Alexander Pretschner*

Main category: cs.SE

TL;DR: 分析PyPI上68.6万个Python库的维护者联系信息可用性，发现81.6%的库包含至少一个有效邮箱，PyPI是主要来源（79.5%），依赖链中可达性高达97%以上，但存在69.8万个无效条目。


<details>
  <summary>Details</summary>
Motivation: 开源软件库的长期可持续性依赖于维护者的可联系性，但缺乏对维护者联系信息（特别是邮箱）可用性的实证研究。本研究旨在分析Python生态系统中维护者联系信息的现状。

Method: 对Python Package Index (PyPI)上的686,034个Python库及其关联的GitHub仓库进行实证分析，检查维护者如何提供联系信息、评估其有效性，并分析依赖链中的覆盖情况。

Result: 81.6%的库包含至少一个有效邮箱地址，PyPI是主要来源（79.5%）。在依赖链分析中，直接依赖和传递依赖分别有97.8%和97.7%提供有效联系信息。同时发现超过698,000个无效条目，主要原因是字段缺失。

Conclusion: Python生态系统整体上维护者可达性很强，但仍存在改进空间：需要在打包过程中为维护者提供更清晰的指导，并为现有邮箱地址引入选择加入的验证机制。

Abstract: Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.

</details>


### [68] [Feature-Aware Test Generation for Deep Learning Models](https://arxiv.org/abs/2601.14081)
*Xingcheng Chen,Oliver Weissl,Andrea Stocco*

Main category: cs.SE

TL;DR: Detect是一个特征感知的深度学习测试生成框架，通过在潜在空间中扰动解耦的语义属性来生成测试输入，提供细粒度语义控制和行为原因分析。


<details>
  <summary>Details</summary>
Motivation: 当前基于生成AI的测试生成方法缺乏对错误行为的语义洞察和细粒度语义控制能力，需要一种能够提供语义解释和可控性的测试框架。

Method: Detect在潜在空间中可控地扰动单个潜在特征，观察模型输出的变化，识别导致行为变化的特征，并使用视觉语言模型进行语义归因。通过区分任务相关和无关特征，应用特征感知扰动进行泛化和鲁棒性测试。

Result: 在图像分类和检测任务上的实验表明，Detect能生成高质量、细粒度可控的测试用例，揭示不同模型架构（卷积和Transformer）的独特捷径行为，以及准确率指标无法捕获的错误。在决策边界发现和鲁棒性故障识别方面优于现有方法。

Conclusion: 完全微调的卷积模型容易过拟合局部线索（如共现视觉特征），而弱监督Transformer倾向于依赖全局特征（如环境变化）。特征感知的可解释测试对提高深度学习模型可靠性具有重要价值。

Abstract: As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.

</details>


### [69] [Practitioner Views on Mobile App Accessibility: Practices and Challenges](https://arxiv.org/abs/2601.14131)
*Amila Indika,Rick Kazman,Anthony Peruma*

Main category: cs.SE

TL;DR: 移动应用开发者普遍认识到无障碍功能的重要性，但实践中主要依赖平台特定指南，测试较晚，且面临API限制和组织约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究已发现广泛的无障碍问题并提高了对开发者挑战的认识，但缺乏跨平台、全球代表性的关于开发者实际如何实践无障碍功能的洞察。

Method: 采用混合方法对来自43个国家的110名移动应用开发者进行调查，考察平台生态系统（iOS vs Android）和开发者经验如何影响无障碍实践。

Result: 开发者主要依赖平台特定指南，通常在开发后期进行合规测试，主要实现文本相关功能，同时面临API限制和组织约束。通过跨平台比较发现了新的平台特定障碍，并展示了无障碍实践如何随开发者经验水平不同而变化。

Conclusion: 研究结果提供了关于实践中实现无障碍功能挑战的新见解，并为各利益相关者提供了促进更一致和包容性应用开发的可操作步骤。

Abstract: As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.

</details>


### [70] [Toward self-coding information systems](https://arxiv.org/abs/2601.14132)
*Rodrigo Falcão,Frank Elberzhager,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 提出自编码信息系统作为智能AI新研究方向，系统能动态评估、生成、测试和部署代码，实现运行时自主适应


<details>
  <summary>Details</summary>
Motivation: 缩短新功能上市时间，实现信息系统在运行时的自主适应和演化，提升系统灵活性和响应速度

Method: 提出自编码信息系统的形式化定义，系统能评估适应决策、生成源代码、测试并自主部署代码

Result: 提出了新的研究主题框架，讨论了该技术的预期影响，并指出了潜在的研究方向

Conclusion: 自编码信息系统代表了智能AI的重要发展方向，具有缩短开发周期、提升系统适应性的潜力，值得深入研究

Abstract: In this extended abstract, we propose a novel research topic in the field of agentic AI, which we refer to as self-coding information systems. These systems will be able to dynamically adapt their structure or behavior by evaluating potential adaptation decisions, generate source code, test, and (re)deploy their source code autonomously, at runtime, reducing the time to market of new features. Here we motivate the topic, provide a formal definition of self-coding information systems, discuss some expected impacts of the new technology, and indicate potential research directions.

</details>


### [71] [An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems](https://arxiv.org/abs/2601.14163)
*Mohammed Latif Siddiq,Tanzim Hossain Romel,Natalie Sekerak,Beatrice Casey,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 对5个主流模型共享平台进行首次大规模实证研究，发现自定义模型加载普遍存在安全风险，包括不安全的默认设置、平台间安全执行不均衡、开发者对远程代码执行风险认知不足等问题。


<details>
  <summary>Details</summary>
Motivation: 模型共享平台（如Hugging Face、ModelScope、OpenCSG）已成为现代机器学习开发的核心，但平台灵活性带来了关键的安全问题：在模型加载过程中执行不受信任的代码（通过trust_remote_code或trust_repo）。需要评估这些做法的普遍性、相关风险以及开发者的认知。

Method: 1. 量化模型需要自定义代码才能运行的频率，识别在加载过程中执行任意Python文件的模型
2. 应用三种互补的静态分析工具（Bandit、CodeQL、Semgrep）检测安全异味和潜在漏洞，按CWE标识符分类
3. 使用YARA识别恶意模式和有效载荷签名
4. 系统分析每个平台的文档、API设计和安全机制，了解其缓解策略和执行水平
5. 对GitHub、Hugging Face、PyTorch Hub论坛以及Stack Overflow上的600多个开发者讨论进行定性分析，捕捉社区关注点和误解

Result: 研究发现普遍依赖不安全的默认设置，平台间安全执行不均衡，开发者对执行远程代码的影响存在持续困惑。识别了自定义代码加载的普遍性以及相关的安全风险。

Conclusion: 提出了可操作的建议，用于设计更安全的模型共享基础设施，在未来AI生态系统中实现可用性和安全性之间的平衡。

Abstract: Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [72] [Complexity of Model Checking Second-Order Hyperproperties on Finite Structures](https://arxiv.org/abs/2601.12361)
*Bernd Finkbeiner,Hadar Frenkel,Tim Rohde*

Main category: cs.LO

TL;DR: Hyper2LTL模型检测在有限结构（树形/无环图）上可判定：树形模型为PSPACE，无环模型为EXPSPACE；其片段Fixpoint Hyper2LTLfp更简单，树形为P-完全，无环为EXP-完全


<details>
  <summary>Details</summary>
Motivation: Hyper2LTL是二阶超逻辑，扩展了HyperLTL，能表达复杂超属性（如认知和异步超属性），但其通用模型检测问题不可判定。因此研究在有限结构（树形或无环图）上的模型检测问题，这对监控应用特别有用。

Method: 研究Hyper2LTL在有限结构上的模型检测问题，包括树形模型和无环图模型。分析不同模型结构的计算复杂度，并特别研究Fixpoint Hyper2LTLfp片段的模型检测复杂度。

Result: 1. Hyper2LTL模型检测在有限结构上可判定；2. 树形模型复杂度为PSPACE（模型大小）；3. 无环模型复杂度为EXPSPACE；4. Fixpoint Hyper2LTLfp片段更简单：树形模型为P-完全，无环模型为EXP-完全；5. 初步考虑了公式大小的影响。

Conclusion: Hyper2LTL在有限结构上的模型检测是可判定的，尽管复杂度较高，但为实际监控应用提供了理论基础。Fixpoint Hyper2LTLfp片段具有更优的复杂度特性，适合实际应用。未来工作可进一步优化算法并考虑公式大小的影响。

Abstract: We study the model checking problem of Hyper2LTL over finite structures. Hyper2LTL is a second-order hyperlogic, that extends the well-studied logic HyperLTL by adding quantification over sets of traces, to express complex hyperproperties such as epistemic and asynchronous hyperproperties. While Hyper2LTL is very expressive, its expressiveness comes with a price, and its general model checking problem is undecidable. This motivates us to study the model checking problem for Hyper2LTL over finite structures -- tree-shaped or acyclic graphs, which are particularly useful for monitoring purposes. We show that Hyper2LTL model checking is decidable on finite structures. It is in PSPACE (in the size of the model) on tree-shaped models and in EXPSPACE on acyclic models. Additionally, we show that for an expressive fragment of Hyper2LTL, namely the Fixpoint Hyper2LTLfp fragment, the model checking problem is much simpler and is P-complete on tree-shaped models and EXP-complete on acyclic models. Last, we present some preliminary results that take into account not only the size of the model, but also the formula size.

</details>


### [73] [Sequencelib: A Computational Platform for Formalizing the OEIS in Lean](https://arxiv.org/abs/2601.11757)
*Walter Moreira,Joe Stubbs*

Main category: cs.LO

TL;DR: Sequencelib项目使用Lean编程语言形式化OEIS中的数学内容，包括序列库、元编程工具和OEIS-LT服务器，通过计算流水线形式化了超过25,000个序列并证明了160万条定理。


<details>
  <summary>Details</summary>
Motivation: OEIS（整数序列在线百科全书）是理论数学中引用最广泛的资源之一，包含大量有趣的整数序列和相关定理。然而，这些数学内容缺乏形式化验证，Sequencelib项目旨在使用Lean编程语言对这些内容进行形式化验证，确保数学严谨性。

Method: 1. 开发Sequencelib库，包含OEIS序列的Lean形式化定义；2. 创建元编程工具，程序化地附加OEIS元数据到Lean定义并推导定理；3. 构建OEIS-LT服务器，通过低延迟API暴露这些工具；4. 使用能够将Standard ML子集转换为Lean的转译器，结合性能改进变换和正确性证明；5. 利用Gauthier等人的先前工作，建立计算流水线。

Result: 成功形式化了超过25,000个OEIS序列，证明了超过160万条关于这些序列值的定理。开发了可扩展的OEIS-LT服务器和从Standard ML到Lean的转译器，实现了大规模自动化形式化验证。

Conclusion: Sequencelib项目展示了使用Lean编程语言大规模形式化数学内容的可行性，为OEIS数据库提供了形式化验证框架，推动了数学形式化验证的发展，并为其他数学资源的形式化提供了可借鉴的方法。

Abstract: The On-Line Encyclopedia of Integer Sequences (OEIS) is a web-accessible database cataloging interesting integer sequences and associated theorems. With more than 12,000 citations, the OEIS is one of the most highly cited resources in all of theoretical mathematics. In this paper, we present Sequencelib, a project to formalize the mathematics contained within the OEIS using the Lean programming language. Sequencelib includes a library of Lean formalizations of OEIS sequences as well as metaprogramming tools for programmatically attaching OEIS metadata to Lean definitions and deriving theorems about their values. Further, we describe OEIS-LT, a highly scalable Lean server that exposes these tools via a low-latency API. Finally, using OEIS-LT and prior work of Gauthier, et al., we describe a computational pipeline that formalized more than 25,000 sequences from the OEIS and proved more than 1.6 million theorems about their values. Our method makes use of a transpiler, available in OEIS-LT, that is capable of translating a subset of Standard ML to Lean, together with a set of performance improvement transformations and proofs of correctness.

</details>


### [74] [Robust Verification of Concurrent Stochastic Games](https://arxiv.org/abs/2601.12003)
*Angel Y. He,David Parker*

Main category: cs.LO

TL;DR: 提出鲁棒并发随机博弈模型处理转移概率不确定性，开发理论框架与算法，在PRISM-games中实现并验证可行性


<details>
  <summary>Details</summary>
Motivation: 现实多智能体系统中转移概率难以精确指定，传统并发随机博弈模型要求精确概率不切实际，需要处理概率不确定性的鲁棒模型

Method: 引入鲁棒并发随机博弈及其子类区间CSG，在最坏情况假设下开发鲁棒验证理论框架，针对有限/无限时域、零和/非零和场景设计高效算法

Result: 在PRISM-games模型检查器中实现该框架，在多个大型基准测试中验证了区间CSG鲁棒验证的可行性

Conclusion: 鲁棒CSG模型能有效处理转移概率不确定性，为多智能体系统在不确定环境中的验证与控制提供了实用解决方案

Abstract: Autonomous systems often operate in multi-agent settings and need to make concurrent, strategic decisions, typically in uncertain environments. Verification and control problems for these systems can be tackled with concurrent stochastic games (CSGs), but this model requires transition probabilities to be precisely specified - an unrealistic requirement in many real-world settings. We introduce *robust CSGs* and their subclass *interval CSGs* (ICSGs), which capture epistemic uncertainty about transition probabilities in CSGs. We propose a novel framework for *robust* verification of these models under worst-case assumptions about transition uncertainty. Specifically, we develop the underlying theoretical foundations and efficient algorithms, for finite- and infinite-horizon objectives in both zero-sum and nonzero-sum settings, the latter based on (social-welfare optimal) Nash equilibria. We build an implementation in the PRISM-games model checker and demonstrate the feasibility of robust verification of ICSGs across a selection of large benchmarks.

</details>


### [75] [Blurred Drinker Paradoxes and Blurred Choice Axioms: Constructive Reverse Mathematics of the Downward Löwenheim-Skolem Theorem](https://arxiv.org/abs/2601.12592)
*Dominik Kirst,Haoyi Zeng*

Main category: cs.LO

TL;DR: 在构造性逆向数学中，作者分析了向下Löwenheim-Skolem定理，揭示了其在选择公理和排中律片段方面的精细逻辑分解。


<details>
  <summary>Details</summary>
Motivation: 研究向下Löwenheim-Skolem定理在构造性数学框架下的逻辑地位，细化经典结果中该定理与依赖选择公理的等价关系。

Method: 采用构造性逆向数学方法，分析DLS定理的逻辑分解，引入新的逻辑原理如模糊饮酒者悖论，并与选择公理的不同形式进行组合研究。

Result: 1. 在可数选择公理下，DLS定理等价于依赖选择公理与模糊饮酒者悖论的合取
2. 无可数选择公理时，DLS定理等价于模糊饮酒者悖论与模糊化选择公理的合取
3. 模糊饮酒者悖论是排中律中不包含马尔可夫原理的部分

Conclusion: 向下Löwenheim-Skolem定理在构造性数学中具有精细的逻辑结构，可以分解为选择公理和排中律片段的组合，这些分解独立于经典结果并提供了新的逻辑洞察。

Abstract: In the setting of constructive reverse mathematics, we analyse the downward Löwenheim-Skolem (DLS) theorem of first-order logic, stating that every infinite model has a countable elementary submodel. Refining the well-known equivalence of the DLS theorem to the axiom of dependent choice (DC) over classical base theories, our constructive approach allows for several finer logical decompositions: Just assuming countable choice (CC), the DLS theorem is equivalent to the conjunction of DC with a newly identified fragment of the excluded middle (LEM) that we call the blurred drinker paradox (BDP). Further without CC, the DLS theorem is equivalent to the conjunction of BDP with similarly blurred weakenings of DC and CC. Independently of their connection with the DLS theorem, we also study BDP and the blurred choice axioms on their own, for instance by showing that BDP is LEM without a contribution of Markov's principle and that blurred DC is DC without a contribution of CC. The paper is hyperlinked with an accompanying Coq development.

</details>


### [76] [Probabilistic Linear Logic Programming with an application to Bayesian Networks computations](https://arxiv.org/abs/2601.13270)
*Matteo Acclavio,Roberto Maieli*

Main category: cs.LO

TL;DR: 提出probLO语言，在线性逻辑编程框架中嵌入贝叶斯网络表示和计算


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络是表示概率依赖关系的规范形式，但将其集成到逻辑编程框架中仍然具有挑战性，主要由于网络结构的复杂性

Method: 扩展Andreoli和Pareschi的LO语言，使用多头部Prolog风格方法重建网络结构（不限于树结构），并采用线性逻辑中的切片操作进行内部数值概率计算

Result: 开发了probLO（概率线性对象）语言，能够在乘法-加法线性逻辑编程框架中嵌入贝叶斯网络表示和计算

Conclusion: 通过probLO实现了在线性逻辑编程框架内直接表示和计算贝叶斯网络，无需依赖外部语义解释

Abstract: Bayesian networks are a canonical formalism for representing probabilistic dependencies, yet their integration within logic programming frameworks remains a nontrivial challenge, mainly due to the complex structure of these networks. In this paper, we propose probLO (probabilistic Linear Objects) an extension of Andreoli and Pareschi's LO language which embeds Bayesian network representation and computation within the framework of multiplicative-additive linear logic programming. The key novelty is the use of multi-head Prolog-like methods to reconstruct network structures, which are not necessarily trees, and the operation of slicing, standard in the literature of linear logic, enabling internal numerical probability computations without relying on external semantic interpretation.

</details>


### [77] [Verifying First-Order Temporal Properties of Infinite-State Systems via Timers and Rankings](https://arxiv.org/abs/2601.13325)
*Raz Lotan,Neta Elad,Oded Padon,Sharon Shoham*

Main category: cs.LO

TL;DR: 提出基于良基排名的统一演绎验证框架，用于一阶时序属性验证，通过预言计时器变量将时序验证转化为终止性验证，无需公平性假设


<details>
  <summary>Details</summary>
Motivation: 现有时序属性验证方法通常基于表结构转换，需要引入公平性假设，且验证过程复杂。需要一种更直接、无需公平性假设的统一验证框架

Method: 1. 引入预言计时器变量预测时序公式成立前的步数；2. 将任意时序属性验证转化为终止性验证；3. 使用隐式排名方法表达状态排名；4. 将隐式排名扩展到无限域；5. 利用SMT求解器自动验证排名递减

Result: 在多个先前工作的时序验证任务上进行了评估，能够在框架内给出简单直观的证明，验证了方法的有效性

Conclusion: 提出了一种基于良基排名的统一时序验证框架，通过将时序验证转化为终止性验证，无需公平性假设，能够处理更一般的系统，并为时序属性提供简单直观的证明

Abstract: We present a unified deductive verification framework for first-order temporal properties based on well-founded rankings, where verification conditions are discharged using SMT solvers. To that end, we introduce a novel reduction from verification of arbitrary temporal properties to verification of termination. Our reduction augments the system with prophecy timer variables that predict the number of steps along a trace until the next time certain temporal formulas, including the negated property, hold. In contrast to standard tableaux-based reductions, which reduce the problem to fair termination, our reduction does not introduce fairness assumptions. To verify termination of the augmented system, we follow the traditional approach of assigning each state a rank from a well-founded set and showing that the rank decreases in every transition. We leverage the recently proposed formalism of implicit rankings to express and automatically verify the decrease of rank using SMT solvers, even when the rank is not expressible in first-order logic. We extend implicit rankings from finite to infinite domains, enabling verification of more general systems and making them applicable to the augmented systems generated by our reduction, which allows us to exploit the decrease of timers in termination proofs. We evaluate our technique on a range of temporal verification tasks from previous works, giving simple, intuitive proofs for them within our framework.

</details>


### [78] [Modular Attractor Acceleration in Infinite-State Games (Full Version)](https://arxiv.org/abs/2601.14068)
*Philippe Heim,Rayna Dimitrova*

Main category: cs.LO

TL;DR: 提出模块化加速参数计算和摘要化技术，提高无限状态博弈求解效率


<details>
  <summary>Details</summary>
Motivation: 无限状态博弈为具有无界数据域的反应式系统合成提供了框架，但符号不动点计算（特别是符号吸引子）可能不终止，现有加速技术表达能力有限

Method: 1) 模块化加速参数计算方法：通过组合简单加速参数构建复杂加速参数；2) 摘要化技术：泛化发现的加速参数，使其能在多个上下文中高效复用

Result: 提高了无限状态博弈求解的效率和可扩展性，实验评估验证了方法的有效性

Conclusion: 模块化加速参数计算和摘要化技术显著改进了反应式合成中无限状态博弈的求解效率

Abstract: Infinite-state games provide a framework for the synthesis of reactive systems with unbounded data domains. Solving such games typically relies on computing symbolic fixpoints, particularly symbolic attractors. However, these computations may not terminate, and while recent acceleration techniques have been proposed to address this issue, they often rely on acceleration arguments of limited expressiveness. In this work, we propose an approach for the modular computation of acceleration arguments. It enables the construction of complex acceleration arguments by composing simpler ones, thereby improving both scalability and flexibility. In addition, we introduce a summarization technique that generalizes discovered acceleration arguments, allowing them to be efficiently reused across multiple contexts. Together, these contributions improve the efficiency of solving infinite-state games in reactive synthesis, as demonstrated by our experimental evaluation.

</details>


### [79] [Unification of Deterministic Higher-Order Patterns](https://arxiv.org/abs/2601.14211)
*Johannes Niederhauser,Aart Middeldorp*

Main category: cs.LO

TL;DR: 提出确定性高阶模式的完备合一算法，该算法是完整高阶合一的特例，能解决flex-flex对，但可能产生无限最小完备合一集


<details>
  <summary>Details</summary>
Motivation: Yokoyama等人引入的确定性高阶模式具有确定性匹配特性，需要研究其合一问题。现有方法如Libal和Miller的函数作为构造器方法有全局变量参数限制，需要更通用的解决方案

Method: 提出确定性高阶模式的合一算法，作为完整高阶合一的特例，能最一般地解决flex-flex对，并推广了Libal和Miller的方法，去除了全局变量参数条件

Result: 算法是完备的，但确定性高阶模式的可解问题不一定有最一般合一子，最小完备合一集可能是无限的，合一问题的可判定性仍是开放问题

Conclusion: 提出了确定性高阶模式的合一算法，扩展了现有方法，但揭示了该问题的复杂性，包括可能无限的最小完备合一集和未解决的可判定性问题

Abstract: We present a sound and complete unification procedure for deterministic higher-order patterns, a class of simply-typed lambda terms introduced by Yokoyama et al. which comes with a deterministic matching problem. Our unification procedure can be seen as a special case of full higher-order unification where flex-flex pairs can be solved in a most general way. Moreover, our method generalizes Libal and Miller's recent functions-as-constructors higher-order unification by dropping their global condition on variable arguments, thereby losing the property that every solvable problem has a most general unifier. In fact, minimal complete sets of unifiers of deterministic higher-order patterns may be infinite, so decidability of the unification problem remains an open question.

</details>
