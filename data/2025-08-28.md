<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [The Power of Regular Constraint Propagation (Technical Report)](https://arxiv.org/abs/2508.19888)
*Matthew Hague,Artur Jeż,Anthony W. Lin,Oliver Markgraf,Philipp Rümmer*

Main category: cs.LO

TL;DR: 本文提出了一种基于正则约束传播的字符串求解方法，通过重复计算字符串函数在正则语言下的前像或后像来推断字符串变量的可能值，直到发现冲突或确定可满足性。


<details>
  <summary>Details</summary>
Motivation: 现有字符串求解器策略复杂，需要一种简单通用的方法来处理包含连接、替换和字符串转换等多种操作的字符串约束。

Method: 使用正则约束传播方法，反复计算字符串函数在正则语言下的前像或后像，逐步推断字符串变量的可能取值。

Result: 理论证明该方法对大型字符串约束片段是完备的，实验表明在OSTRICH求解器中实现后显著提升了性能，在随机PCP和生物信息学基准测试中优于其他求解器。

Conclusion: 正则约束传播是一种有效且通用的字符串求解方法，将其与其他技术结合可以显著提升现有求解器的性能。

Abstract: The past decade has witnessed substantial developments in string solving.
Motivated by the complexity of string solving strategies adopted in existing
string solvers, we investigate a simple and generic method for solving string
constraints: regular constraint propagation. The method repeatedly computes
pre- or post-images of regular languages under the string functions present in
a string formula, inferring more and more knowledge about the possible values
of string variables, until either a conflict is found or satisfiability of the
string formula can be concluded. Such a propagation strategy is applicable to
string constraints with multiple operations like concatenation, replace, and
almost all flavors of string transductions. We demonstrate the generality and
effectiveness of this method theoretically and experimentally. On the
theoretical side, we show that RCP is sound and complete for a large fragment
of string constraints, subsuming both straight-line and chain-free constraints,
two of the most expressive decidable fragments for which some modern string
solvers provide formal completeness guarantees. On the practical side, we
implement regular constraint propagation within the open-source string solver
OSTRICH.
  Our experimental evaluation shows that this addition significantly improves
OSTRICH's performance and makes it competitive with existing solvers. In fact,
it substantially outperforms other solvers on random PCP and bioinformatics
benchmarks. The results also suggest that incorporating regular constraint
propagation alongside other techniques could lead to substantial performance
gains for existing solvers.

</details>


### [2] [Between Markov and restriction: Two more monads on categories for relations](https://arxiv.org/abs/2508.20054)
*Cipriano Junior Cioffo,Fabio Gadducci,Davide Trotta*

Main category: cs.LO

TL;DR: 该论文进一步丰富了关系范畴的分类学，提出了两个比马尔可夫范畴和限制范畴更抽象的gs-幺半范畴实例，通过质量(axiomatic mass)和域(domain)的公理化概念来刻画，并引入了质量和域保持单子。


<details>
  <summary>Details</summary>
Motivation: 扩展现有的关系范畴分类体系，提供比马尔可夫范畴和限制范畴更抽象的关系结构范畴实例，以更一般化的方式捕捉关系的基本结构特性。

Method: 提出两个新的gs-幺半范畴实例，通过公理化的质量和域概念来刻画；引入质量和域保持单子，证明相关的Kleisli范畴保持对应方程；展示这些单子在半环加权关系范畴中的自然出现。

Result: 建立了更抽象的关系范畴框架，扩展了现有的分类体系；证明了质量和域保持单子的理论性质；展示了这些构造在半环加权关系中的具体实现。

Conclusion: 该研究进一步丰富了关系范畴的理论体系，提供了比现有构造更抽象和一般化的范畴实例，为关系结构的范畴化研究提供了新的理论工具和分类框架。

Abstract: The study of categories abstracting the structural properties of relations
has been extensively developed over the years, resulting in a rich and diverse
body of work. A previous paper offered a survey providing a modern and
comprehensive presentation of these ``categories for relations'' as instances
of gs-monoidal categories, showing how they arise as Kleisli categories of
suitable symmetric monoidal monads. The end result was a taxonomy that
organised numerous related concepts in the literature, including in particular
Markov and restriction categories. This paper further enriches the taxonomy: it
proposes two categories that are once more instances of gs-monoidal categories,
yet more abstract than Markov and restriction categories. They are
characterised by an axiomatic notion of mass and domain of an arrow, the latter
one of the key ingredient of restriction categories, which generalises the
domain of partial functions. The paper then introduces mass and domain
preserving monads, proving that the associated Kleisli categories in fact
preserve the corresponding equations and that these monads arise naturally for
the categories of semiring-weighted relations.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: 本文提出了一个面向功能的代码自进化框架，用于构建多样化的代码功能一致性基准测试，显著提升了嵌入模型在代码克隆检测、功能一致性识别和代码检索等任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注代码克隆检测，强调语法相似性而忽视了功能理解。大型语言模型的代码嵌入能否反映代码级功能语义尚不清楚，需要构建更好的基准来评估功能一致性。

Method: 提出了Functionality-Oriented Code Self-Evolution数据合成框架，从单个代码实例生成四种独特的变体，涵盖四个语义和语法类别，提供更广泛的代码示例谱系以更好地反映功能差异。

Result: 在三个下游任务（代码克隆检测、代码功能一致性识别和代码检索）上的广泛实验表明，使用进化数据集训练的嵌入模型性能显著提升。

Conclusion: 该数据合成框架有效且具有泛化能力，推动了代码功能理解的发展，证明了功能导向的数据合成对提升代码嵌入模型性能的重要性。

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


### [4] [Stack Trace-Based Crash Deduplication with Transformer Adaptation](https://arxiv.org/abs/2508.19449)
*Md Afif Al Mamun,Gias Uddin,Lan Xia,Longyu Zhang*

Main category: cs.SE

TL;DR: dedupT是一个基于Transformer的崩溃报告去重方法，通过整体建模堆栈轨迹而非孤立帧，显著优于现有深度学习和传统方法


<details>
  <summary>Details</summary>
Motivation: 自动化崩溃报告系统产生大量重复报告，传统基于字符串相似度、规则启发式或深度学习的方法无法有效捕捉堆栈轨迹中的上下文和结构关系

Method: 首先适配预训练语言模型到堆栈轨迹，然后使用其嵌入训练全连接网络来有效排名重复崩溃

Result: 在四个公共数据集上，dedupT相比最佳深度学习基线平均倒数排名提升超过15%，相比传统方法提升达9%，在检测唯一崩溃报告时获得更高的ROC-AUC

Conclusion: 该工作推动了现代自然语言处理技术在软件工程中的集成，为基于堆栈轨迹的崩溃去重提供了有效解决方案

Abstract: Automated crash reporting systems generate large volumes of duplicate
reports, overwhelming issue-tracking systems and increasing developer workload.
Traditional stack trace-based deduplication methods, relying on string
similarity, rule-based heuristics, or deep learning (DL) models, often fail to
capture the contextual and structural relationships within stack traces. We
propose dedupT, a transformer-based approach that models stack traces
holistically rather than as isolated frames. dedupT first adapts a pretrained
language model (PLM) to stack traces, then uses its embeddings to train a
fully-connected network (FCN) to rank duplicate crashes effectively. Extensive
experiments on real-world datasets show that dedupT outperforms existing DL and
traditional methods (e.g., sequence alignment and information retrieval
techniques) in both duplicate ranking and unique crash detection, significantly
reducing manual triage effort. On four public datasets, dedupT improves Mean
Reciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up
to 9% over traditional methods while achieving higher Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) in detecting unique crash
reports. Our work advances the integration of modern natural language
processing (NLP) techniques into software engineering, providing an effective
solution for stack trace-based crash deduplication.

</details>


### [5] [The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts](https://arxiv.org/abs/2508.19610)
*Kathrin Figl,Maria Kirchner,Sebastian Baltes,Michael Felderer*

Main category: cs.SE

TL;DR: 代码注释显著影响Stack Overflow答案的感知帮助性，块注释比行内注释更受新手青睐，而答案位置和评分等表面特征影响较小


<details>
  <summary>Details</summary>
Motivation: 理解代码注释如何影响Stack Overflow答案的感知帮助性，因为重用理解不足的代码可能导致严重问题

Method: 在线实验模拟Stack Overflow环境（n=91），比较块注释、行内注释和无注释代码的感知帮助性

Result: 块注释和行内注释都比无注释代码显著更有帮助；新手认为块注释比行内注释更有帮助；答案位置和评分等表面特征重要性较低

Conclusion: 研究结果有助于改进社区驱动平台的相关性，并为AI代码生成工具提供针对性提示策略以生成更易读的代码片段

Abstract: Question-and-answer platforms such as Stack Overflow have become an important
way for software developers to share and retrieve knowledge. However, reusing
poorly understood code can lead to serious problems, such as bugs or security
vulnerabilities. To better understand how code comments affect the perceived
helpfulness of Stack Overflow answers, we conducted an online experiment
simulating a Stack Overflow environment (n=91). The results indicate that both
block and inline comments are perceived as significantly more helpful than
uncommented source code. Moreover, novices rated code snippets with block
comments as more helpful than those with inline comments. Interestingly, other
surface features, such as the position of an answer and its answer score, were
considered less important. The content of Stack Overflow has been a major
source for training large language models. AI-based coding assistants such as
GitHub Copilot, which are based on these models, might change the way Stack
Overflow is used. However, our findings have implications beyond this specific
platform. First, they may help to improve the relevance of community-driven
platforms such as Stack Overflow, which provide human advice and explanations
of code solutions, complementing AI-based support for software developers.
Second, since chat-based AI tools can be prompted to generate code in different
ways, knowing which properties influence perceived helpfulness might lead to
targeted prompting strategies to generate more readable code snippets.

</details>


### [6] [Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation](https://arxiv.org/abs/2508.19663)
*Lola Solovyeva,Eduardo Carneiro Oliveira,Shiyu Fan,Alper Tuncay,Shamil Gareev,Andrea Capiluppi*

Main category: cs.SE

TL;DR: 本研究探讨了使用大型语言模型将PL/SQL代码翻译为Java的可行性，通过定制化提示策略在有限数据集上取得了语法准确和功能正确的翻译结果。


<details>
  <summary>Details</summary>
Motivation: VT遗留系统包含约250万行PL/SQL代码，缺乏一致的文档和自动化测试，给重构和现代化带来了重大挑战，需要寻找自动化解决方案。

Method: 利用包含10个PL/SQL-Java代码对和15个Java类的数据集，评估多个LLM，并提出结合指导链推理和n-shot提示的定制化提示策略。

Result: 该方法能有效指导LLM生成语法准确的翻译并实现功能正确性，但受限于可用代码文件的小样本量和测试用例的有限访问。

Conclusion: 这些发现为现代化大型遗留系统的可扩展自动化解决方案奠定了基础，尽管当前结果受限于数据集规模。

Abstract: The VT legacy system, comprising approximately 2.5 million lines of PL/SQL
code, lacks consistent documentation and automated tests, posing significant
challenges for refactoring and modernisation. This study investigates the
feasibility of leveraging large language models (LLMs) to assist in translating
PL/SQL code into Java for the modernised "VTF3" system. By leveraging a dataset
comprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively
established a domain model for the translated files, multiple LLMs were
evaluated. Furthermore, we propose a customized prompting strategy that
integrates chain-of-guidance reasoning with $n$-shot prompting. Our findings
indicate that this methodology effectively guides LLMs in generating
syntactically accurate translations while also achieving functional
correctness. However, the findings are limited by the small sample size of
available code files and the restricted access to test cases used for
validating the correctness of the generated code. Nevertheless, these findings
lay the groundwork for scalable, automated solutions in modernising large
legacy systems.

</details>


### [7] [Enabling Content Management Systems as an Information Source in Model-driven Projects](https://arxiv.org/abs/2508.19797)
*Joan Giner-Miguelez,Abel Gómez,Jordi Cabot*

Main category: cs.SE

TL;DR: 提出一个模型基于框架来发现和表示无头CMS的信息模型，生成中间件库以支持软件开发过程中的CMS集成


<details>
  <summary>Details</summary>
Motivation: 无头CMS已成为信息系统的重要组件，但缺乏自动化工具来发现和管理其中的信息模型，目前主要依靠手工处理效率低且容易出错

Method: 开发了一个模型基于框架，能够自动发现并显式表示CMS的信息模型，然后生成中间件库提供平台无关的CMS访问接口

Result: 完整框架已开源并在线可用，能够支持软件开发过程中的CMS集成需求

Conclusion: 该框架有效解决了无头CMS集成过程中的信息模型发现和管理问题，提高了开发效率和质量

Abstract: Content Management Systems (CMSs) are the most popular tool when it comes to
create and publish content across the web. Recently, CMSs have evolved,
becoming \emph{headless}. Content served by a \emph{headless CMS} aims to be
consumed by other applications and services through REST APIs rather than by
human users through a web browser. This evolution has enabled CMSs to become a
notorious source of content to be used in a variety of contexts beyond pure web
navigation. As such, CMS have become an important component of many information
systems. Unfortunately, we still lack the tools to properly discover and manage
the information stored in a CMS, often highly customized to the needs of a
specific domain. Currently, this is mostly a time-consuming and error-prone
manual process.
  In this paper, we propose a model-based framework to facilitate the
integration of headless CMSs in software development processes. Our framework
is able to discover and explicitly represent the information schema behind the
CMS. This facilitates designing the interaction between the CMS model and other
components consuming that information. These interactions are then generated as
part of a middleware library that offers platform-agnostic access to the CMS to
all the client applications. The complete framework is open-source and
available online.

</details>


### [8] [Towards a fundamental theory of modeling discrete systems](https://arxiv.org/abs/2508.19803)
*Peter Fettke,Wolfgang Reisig*

Main category: cs.SE

TL;DR: 提出Heraklit建模框架作为数字时代建模的新理论基础，解决传统建模方法面临的挑战


<details>
  <summary>Details</summary>
Motivation: 数字时代对建模提出了新的挑战，需要新的基础理论来应对这些挑战，传统建模方法已不足以满足当前需求

Method: 引入Heraklit建模框架作为新的建模方法，详细阐述了该框架的理论基础和应用方式

Result: 提出了一个全新的建模理论框架，为数字时代的建模问题提供了系统性的解决方案

Conclusion: Heraklit框架为建模领域提供了新的理论基础，未来工作需要关注建模的正确性、信息概念和不变性描述等问题

Abstract: Modeling is a central concern in both science and engineering. However, we
need a new fundamental theory to address the challenges of the digital age. In
this paper, we first explain why modeling is fundamental and which challenges
must be addressed in the digital world. As a main contribution, we introduce
the Heraklit modeling framework as a new approach to modeling. We conclude with
some general remarks. Future work will involve the correctness of modeling, the
notion of information, and the description of invariance in modeling.

</details>


### [9] [On the Future of Software Reuse in the Era of AI Native Software Engineering](https://arxiv.org/abs/2508.19834)
*Antero Taivalsaari,Tommi Mikkonen,Cesare Pautasso*

Main category: cs.SE

TL;DR: 论文探讨AI辅助生成式软件重用的影响，指出其类似于货物崇拜开发，并提出研究议程来解决相关问题


<details>
  <summary>Details</summary>
Motivation: 随着AI和生成式软件重用成为软件开发的核心范式，传统的有机开发方法正被"AI原生"方法取代，这引发了新的软件重用形式，需要研究其影响和问题

Method: 通过讨论AI辅助生成式软件重用的含义，提出相关问题，并定义研究议程来应对这种新兴方法的核心问题

Result: 识别了AI辅助软件重用与货物崇拜开发的相似性，提出了需要解决的关键问题和研究方向

Conclusion: AI辅助生成式软件重用正在改变软件开发范式，需要系统性的研究来应对其带来的挑战和机遇，确保软件质量和可靠性

Abstract: Software development is currently under a paradigm shift in which artificial
intelligence and generative software reuse are taking the center stage in
software creation. Earlier opportunistic software reuse practices and organic
software development methods are rapidly being replaced by "AI Native"
approaches in which developers place their trust on code that has been
generated by artificial intelligence. This is leading to a new form of software
reuse that is conceptually not all that different from cargo cult development.
In this paper we discuss the implications of AI-assisted generative software
reuse, bring forth relevant questions, and define a research agenda for
tackling the central issues associated with this emerging approach.

</details>


### [10] [Generative AI for Testing of Autonomous Driving Systems: A Survey](https://arxiv.org/abs/2508.19882)
*Qunying Song,He Ye,Mark Harman,Federica Sarro*

Main category: cs.SE

TL;DR: 本文系统综述了生成式AI在自动驾驶系统测试中的应用，分析了91项相关研究，总结了6个主要应用类别、评估工具和现有局限性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要在大规模部署前进行广泛测试以确保安全性和功能性，但实现高效测试仍面临挑战。生成式AI因其强大的上下文理解、复杂任务推理和多样化输出能力，为ADS测试提供了新的解决方案。

Method: 通过系统分析91项相关研究，将生成式AI在ADS测试中的应用归纳为6个主要类别，主要围绕基于场景的测试。同时综述了评估使用的数据集、模拟器、ADS系统、指标和基准。

Result: 识别了生成式AI在ADS测试中的27个局限性，总结了现有方法的有效性，并整理了广泛使用的评估工具和资源。

Conclusion: 本调查为生成式AI在ADS测试中的应用提供了全面概述和实践见解，突出了现有挑战，并为这个快速发展领域的未来研究方向提供了指导。

Abstract: Autonomous driving systems (ADS) have been an active area of research, with
the potential to deliver significant benefits to society. However, before
large-scale deployment on public roads, extensive testing is necessary to
validate their functionality and safety under diverse driving conditions.
Therefore, different testing approaches are required, and achieving effective
and efficient testing of ADS remains an open challenge. Recently, generative AI
has emerged as a powerful tool across many domains, and it is increasingly
being applied to ADS testing due to its ability to interpret context, reason
about complex tasks, and generate diverse outputs. To gain a deeper
understanding of its role in ADS testing, we systematically analyzed 91
relevant studies and synthesized their findings into six major application
categories, primarily centered on scenario-based testing of ADS. We also
reviewed their effectiveness and compiled a wide range of datasets, simulators,
ADS, metrics, and benchmarks used for evaluation, while identifying 27
limitations. This survey provides an overview and practical insights into the
use of generative AI for testing ADS, highlights existing challenges, and
outlines directions for future research in this rapidly evolving field.

</details>


### [11] [Smart Contract Intent Detection with Pre-trained Programming Language Model](https://arxiv.org/abs/2508.20086)
*Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu,Tao Zhang*

Main category: cs.SE

TL;DR: SmartIntentNN2是基于BERT预训练语言模型的智能合约恶意意图检测系统，相比前代版本性能显著提升，F1分数达到0.927，成为该领域的最先进模型。


<details>
  <summary>Details</summary>
Motivation: 智能合约开发中的恶意意图可能导致重大经济损失，需要有效的检测方法来识别不安全意图。

Method: 采用BERT预训练语言模型（在16,000个真实智能合约上训练）、BiLSTM多标签分类网络，结合K-means聚类的意图突出机制。

Result: 在区分10种不同意图类别上，F1分数达到0.927，相比前代模型的0.8633有显著提升。

Conclusion: SmartIntentNN2通过集成BERT预训练模型，在智能合约意图检测方面达到了最先进的性能水平。

Abstract: Malicious intent in smart contract development can lead to substantial
economic losses. SmartIntentNN is a deep learning model specifically designed
to identify unsafe intents in smart contracts. This model integrates the
Universal Sentence Encoder, a K-means clustering-based intent highlighting
mechanism, and a Bidirectional Long Short-Term Memory network for multi-label
classification, achieving an F1 of 0.8633 in distinguishing ten different
intent categories. In this study, we present an upgraded version of this model,
SmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant
enhancement in V2 is the incorporation of a BERT-based pre-trained language
model, which has been trained on a dataset of 16,000 real smart contracts using
a Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based
multi-label classification network. With an improved F1 of 0.927, V2
demonstrates enhanced performance compared to its predecessor, establishing
itself as the state-of-the-art model for smart contract intent detection.

</details>
