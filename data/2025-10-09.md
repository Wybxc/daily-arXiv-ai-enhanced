<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems](https://arxiv.org/abs/2510.06343)
*Fikret Mert Gültekin,Oscar Lilja,Ranim Khojah,Rebekka Wohlrab,Marvin Damschen,Mazen Mohamad*

Main category: cs.SE

TL;DR: 使用本地部署的大型语言模型结合检索增强生成技术，支持林业领域网络安全风险评估，同时满足数据保护要求。


<details>
  <summary>Details</summary>
Motivation: 在安全关键软件系统中，网络安全专家稀缺，工程师需要自行进行风险评估，需要工具支持。

Method: 采用设计科学研究方法，通过12位专家的访谈、互动会议和问卷调查。

Result: LLM能够协助生成初步风险评估、识别威胁和提供冗余检查，但需要人工监督确保准确性。

Conclusion: 尽管存在信任问题，专家愿意在特定评估和辅助角色中使用LLM，鼓励在安全关键领域使用LLM代理支持风险评估。

Abstract: In safety-critical software systems, cybersecurity activities become
essential, with risk assessment being one of the most critical. In many
software teams, cybersecurity experts are either entirely absent or represented
by only a small number of specialists. As a result, the workload for these
experts becomes high, and software engineers would need to conduct
cybersecurity activities themselves. This creates a need for a tool to support
cybersecurity experts and engineers in evaluating vulnerabilities and threats
during the risk assessment process. This paper explores the potential of
leveraging locally hosted large language models (LLMs) with retrieval-augmented
generation to support cybersecurity risk assessment in the forestry domain
while complying with data protection and privacy requirements that limit
external data sharing. We performed a design science study involving 12 experts
in interviews, interactive sessions, and a survey within a large-scale project.
The results demonstrate that LLMs can assist cybersecurity experts by
generating initial risk assessments, identifying threats, and providing
redundancy checks. The results also highlight the necessity for human oversight
to ensure accuracy and compliance. Despite trust concerns, experts were willing
to utilize LLMs in specific evaluation and assistance roles, rather than solely
relying on their generative capabilities. This study provides insights that
encourage the use of LLM-based agents to support the risk assessment process of
cyber-physical systems in safety-critical domains.

</details>


### [2] [Improving Assignment Submission in Higher Education through a Git-Enabled System: An Iterative Case Study](https://arxiv.org/abs/2510.06363)
*Ololade Babatunde,Tomisin Ayodabo,Raqibul Raqibul*

Main category: cs.SE

TL;DR: 本研究通过引入和评估定制化的Git提交系统，解决了高等教育中传统作业提交方法的挑战，显著提升了作业跟踪、协作和提交效率。


<details>
  <summary>Details</summary>
Motivation: 解决高等教育中传统作业提交方法在跟踪、协作和效率方面的挑战，探索分布式版本控制在教育环境中的应用价值。

Method: 采用迭代软件开发和以用户为中心的设计方法，将系统整合到真实大学环境中，通过可用性测试和学生反馈进行实证评估。

Result: 85%的教师认为Git系统更易使用，84%的学生偏好该系统；提交和评审时间减少38%，存储需求降低48%，学生报告了积极的学习体验和协作改进。

Conclusion: 该系统为在教育环境中集成分布式版本控制提供了实用见解，增强了教师监督和学生参与度，尽管存在初始采用和学习曲线挑战，但通过迭代改进得到了缓解。

Abstract: This study addresses challenges in traditional assignment submission methods
used in higher education by introducing and evaluating a customized Git-based
submission system. Employing iterative software development and user-centered
design methodologies, the system was integrated within a real-world university
environment. Empirical evaluation, including usability testing and student
feedback, indicated significant improvements in assignment tracking,
collaboration, and submission efficiency. Students reported positive
experiences using distributed version control workflows, highlighting improved
learning outcomes and reduced administrative burden. Challenges related to
initial adoption and student learning curves were identified and mitigated
through iterative improvements. The proposed system contributes practical
insights for integrating distributed version control into educational settings,
enhancing both instructor oversight and student engagement in software
engineering and related disciplines. Based on our results, the research showed
that 85% of instructors found the git based system easier to use, with 84% of
students preferring it over traditional methods, as it provides a 38% reduction
in time taken for submission and review, while also leading to a 48% reduction
in storage requirements.

</details>


### [3] [Addressing Visual Impairments with Model-Driven Engineering: A Systematic Literature Review](https://arxiv.org/abs/2510.06483)
*Judith Michael,Lukas Netz,Bernhard Rumpe,Ingo Müller,John Grundy,Shavindra Wickramathilaka,Hourieh Khalajzadeh*

Main category: cs.SE

TL;DR: 本文通过系统文献综述分析了模型驱动工程(MDE)如何解决视觉障碍的可访问性问题，发现当前研究在方法细节、用户参与和实证验证方面存在不足，并提出了改进研究议程。


<details>
  <summary>Details</summary>
Motivation: 软件应用经常为有可访问性需求的用户（如视觉障碍者）设置障碍。模型驱动工程(MDE)通过系统化的代码推导方法，为将可访问性问题集成到软件开发中提供了系统化途径，同时减少人工工作量。

Method: 对MDE解决视觉障碍可访问性问题的研究进行系统文献综述，从447篇初步识别论文中筛选出30篇符合纳入标准的主要研究进行分析。

Result: 约三分之二的研究参考了Web内容可访问性指南(WCAG)，但项目特定的适配和最终用户验证阻碍了在MDE中的更广泛采用。研究主要建模用户界面结构、交互导航、用户能力、需求和上下文信息，但只有少数研究具体说明了如何整合可访问性需求或展示了完全功能的系统。MDE方法细节不足（如转换规则或代码模板）阻碍了重用性、通用性和可重复性。

Conclusion: 当前MDE研究对视觉相关可访问性的支持不足，主要问题包括方法细节不充分、受影响用户参与有限、开发人员可访问性专业知识不足导致实证验证薄弱。文章最后提出了如何更有效地将视觉障碍支持嵌入MDE流程的研究议程。

Abstract: Software applications often pose barriers for users with accessibility needs,
e.g., visual impairments. Model-driven engineering (MDE), with its systematic
nature of code derivation, offers systematic methods to integrate accessibility
concerns into software development while reducing manual effort. This paper
presents a systematic literature review on how MDE addresses accessibility for
vision impairments. From 447 initially identified papers, 30 primary studies
met the inclusion criteria. About two-thirds reference the Web Content
Accessibility Guidelines (WCAG), yet their project-specific adaptions and
end-user validations hinder wider adoption in MDE. The analyzed studies model
user interface structures, interaction and navigation, user capabilities,
requirements, and context information. However, only few specify concrete
modeling techniques on how to incorporate accessibility needs or demonstrate
fully functional systems. Insufficient details on MDE methods, i.e.,
transformation rules or code templates, hinder the reuse, generalizability, and
reproducibility. Furthermore, limited involvement of affected users and limited
developer expertise in accessibility contribute to weak empirical validation.
Overall, the findings indicate that current MDE research insufficiently
supports vision-related accessibility. Our paper concludes with a research
agenda outlining how support for vision impairments can be more effectively
embedded in MDE processes.

</details>


### [4] [Beyond More Context: How Granularity and Order Drive Code Completion Quality](https://arxiv.org/abs/2510.06606)
*Uswat Yusuf,Genevieve Caumartin,Diego Elias Costa*

Main category: cs.SE

TL;DR: 本文提出了一种基于静态分析的代码块检索方法，用于改进代码补全的上下文收集策略，在ASE 2025挑战中相比文件级检索提升6%，相比无上下文基线提升16%。


<details>
  <summary>Details</summary>
Motivation: 大型代码库中为LLM提供相关上下文面临挑战：LLM上下文长度有限，无法包含所有文件；生成代码质量对噪声或无关上下文高度敏感。

Method: 开发了文件级和代码块级的检索策略，重点关注上下文大小和文件排序对LLM性能的影响，并引入了基于静态分析的代码块检索方法。

Result: 上下文的数量和顺序显著影响模型性能，基于静态分析的代码块检索在Python任务中比最佳文件检索策略提升6%，比无上下文基线提升16%。

Conclusion: 检索粒度、排序策略和混合方法对于构建有效的现实开发场景上下文收集管道至关重要。

Abstract: Context plays an important role in the quality of code completion, as Large
Language Models (LLMs) require sufficient and relevant information to assist
developers in code generation tasks. However, composing a relevant context for
code completion poses challenges in large repositories: First, the limited
context length of LLMs makes it impractical to include all repository files.
Second, the quality of generated code is highly sensitive to noisy or
irrelevant context. In this paper, we present our approach for the ASE 2025
Context Collection Challenge. The challenge entails outperforming JetBrains
baselines by designing effective retrieval and context collection strategies.
We develop and evaluate a series of experiments that involve retrieval
strategies at both the file and chunk levels. We focus our initial experiments
on examining the impact of context size and file ordering on LLM performance.
Our results show that the amount and order of context can significantly
influence the performance of the models. We introduce chunk-based retrieval
using static analysis, achieving a 6% improvement over our best file-retrieval
strategy and a 16% improvement over the no-context baseline for Python in the
initial phase of the competition. Our results highlight the importance of
retrieval granularity, ordering and hybrid strategies in developing effective
context collection pipelines for real-world development scenarios.

</details>


### [5] [AISysRev -- LLM-based Tool for Title-abstract Screening](https://arxiv.org/abs/2510.06708)
*Aleksi Huotala,Miikka Kuutila,Olli-Pekka Turtio,Mika Mäntylä*

Main category: cs.SE

TL;DR: 开发了AiSysRev工具，利用LLM辅助系统评价中的文献筛选，通过实验发现LLM在边界案例中需要人工干预，但能显著减轻筛选负担。


<details>
  <summary>Details</summary>
Motivation: 系统评价中的文献筛选阶段工作量大且耗时，需要开发自动化工具来减轻人工负担。

Method: 开发基于LLM的AiSysRev网络应用工具，支持零样本和少样本筛选，允许用户指定纳入排除标准，并通过OpenRouter使用多种LLM模型。

Result: 在137篇论文的试验中，发现论文可分为四类：易纳入、易排除、边界纳入和边界排除，其中边界案例LLM容易出错。

Conclusion: LLM不能完全替代人工判断，但能显著减轻大规模科学文献筛选的负担。

Abstract: Systematic reviews are a standard practice for summarizing the state of
evidence in software engineering. Conducting systematic reviews is laborious,
especially during the screening or study selection phase, where the number of
papers can be overwhelming. During this phase, papers are assessed against
inclusion and exclusion criteria based on their titles and abstracts. Recent
research has demonstrated that large language models (LLMs) can perform
title-abstract screening at a level comparable to that of a master's student.
While LLMs cannot be fully trusted, they can help, for example, in Rapid
Reviews, which try to expedite the review process. Building on recent research,
we developed AiSysRev, an LLM-based screening tool implemented as a web
application running in a Docker container. The tool accepts a CSV file
containing paper titles and abstracts. Users specify inclusion and exclusion
criteria. One can use multiple LLMs for screening via OpenRouter. AiSysRev
supports both zero-shot and few-shot screening, and also allows for manual
screening through interfaces that display LLM results as guidance for human
reviewers.We conducted a trial study with 137 papers using the tool. Our
findings indicate that papers can be classified into four categories: Easy
Includes, Easy Excludes, Boundary Includes, and Boundary Excludes. The Boundary
cases, where LLMs are prone to errors, highlight the need for human
intervention. While LLMs do not replace human judgment in systematic reviews,
they can significantly reduce the burden of assessing large volumes of
scientific literature. Video: https://www.youtube.com/watch?v=jVbEj4Y4tQI Tool:
https://github.com/EvoTestOps/AISysRev

</details>


### [6] [LLM Company Policies and Policy Implications in Software Organizations](https://arxiv.org/abs/2510.06718)
*Ranim Khojah,Mazen Mohamad,Linda Erlenhov,Francisco Gomes de Oliveira Neto,Philipp Leitner*

Main category: cs.SE

TL;DR: 研究11家公司制定LLM聊天机器人政策的实践和影响因素，帮助管理者安全整合聊天机器人到开发流程中


<details>
  <summary>Details</summary>
Motivation: 软件组织采用大型语言模型聊天机器人存在风险，需要明确政策来指导安全使用

Method: 研究11家公司的政策制定过程，分析影响政策制定的因素

Result: 识别了公司制定LLM聊天机器人政策的方法和关键影响因素

Conclusion: 研究结果可帮助管理者更安全地将聊天机器人集成到开发工作流程中

Abstract: The risks associated with adopting large language model (LLM) chatbots in
software organizations highlight the need for clear policies. We examine how 11
companies create these policies and the factors that influence them, aiming to
help managers safely integrate chatbots into development workflows.

</details>


### [7] [Oops!... I did it again. Conclusion (In-)Stability in Quantitative Empirical Software Engineering: A Large-Scale Analysis](https://arxiv.org/abs/2510.06844)
*Nicole Hoess,Carlos Paradis,Rick Kazman,Wolfgang Mauerer*

Main category: cs.SE

TL;DR: 该研究评估了软件仓库挖掘工具在进化分析中的有效性威胁和工具间一致性，发现工具设计和实现的技术细节会导致数据、统计结果甚至结论的显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究软件仓库挖掘工具在复杂分析管道中的有效性威胁，评估不同工具对相同研究问题在数据、结果和结论上的一致性。

Method: 通过轻量级文献综述选择三个高质量研究，使用四个独立选择的挖掘工具进行正式复制，定量和定性比较提取的数据、分析结果和结论。

Result: 发现工具设计和实现中的技术细节在复杂挖掘管道中累积，会导致基线数据、衍生数据、统计分析结果以及特定情况下的结论出现显著差异。

Conclusion: 用户必须谨慎选择工具并评估其局限性，建议重用工具。研究人员和工具作者可通过复制包和比较研究来提高可重用性并减少不确定性。

Abstract: Context: Mining software repositories is a popular means to gain insights
into a software project's evolution, monitor project health, support decisions
and derive best practices. Tools supporting the mining process are commonly
applied by researchers and practitioners, but their limitations and agreement
are often not well understood.
  Objective: This study investigates some threats to validity in complex tool
pipelines for evolutionary software analyses and evaluates the tools' agreement
in terms of data, study outcomes and conclusions for the same research
questions.
  Method: We conduct a lightweight literature review to select three studies on
collaboration and coordination, software maintenance and software quality from
high-ranked venues, which we formally replicate with four independent,
systematically selected mining tools to quantitatively and qualitatively
compare the extracted data, analysis results and conclusions.
  Results: We find that numerous technical details in tool design and
implementation accumulate along the complex mining pipelines and can cause
substantial differences in the extracted baseline data, its derivatives,
subsequent results of statistical analyses and, under specific circumstances,
conclusions.
  Conclusions: Users must carefully choose tools and evaluate their limitations
to assess the scope of validity in an adequate way. Reusing tools is
recommended. Researchers and tool authors can promote reusability and help
reducing uncertainties by reproduction packages and comparative studies
following our approach.

</details>


### [8] [An empirical study on declined proposals: why are these proposals declined?](https://arxiv.org/abs/2510.06984)
*Masanari Kondo,Mahmoud Alfadel,Shane McIntosh,Yasutaka Kamei,Naoyasu Ubayashi*

Main category: cs.SE

TL;DR: 该研究分析了Go编程语言项目中提案被拒绝的原因，发现提案被拒绝比接受更常见，主要拒绝原因包括重复、用例有限或违反项目原则等9个关键因素，并证明GPT模型可以在讨论早期预测拒绝决策。


<details>
  <summary>Details</summary>
Motivation: 开源软件项目的设计决策通过提案机制进行，但提案过程资源密集且常因缺乏明确反馈导致贡献者沮丧。提案被拒绝的原因理解不足，限制了流程优化和有效指导贡献者的机会。

Method: 对Go项目的1,091个提案进行混合方法实证研究，量化提案结果，构建拒绝原因分类法，并评估大型语言模型预测这些结果的能力。

Result: 提案被拒绝比接受更常见，解决通常需要超过一个月时间。只有14.7%的被拒绝提案会重新提交。识别出9个关键拒绝原因，GPT模型可以在讨论早期预测拒绝决策（F1分数=0.71）。

Conclusion: 研究揭示了提案过程的低效性，并强调通过早期分类和基于过去拒绝原因的结构化理解指导贡献者改进提案，可以改善贡献者体验和审阅者工作负载。

Abstract: Design-level decisions in open-source software (OSS) projects are often made
through structured mechanisms such as proposals, which require substantial
community discussion and review. Despite their importance, the proposal process
is resource-intensive and often leads to contributor frustration, especially
when proposals are declined without clear feedback. Yet, the reasons behind
proposal rejection remain poorly understood, limiting opportunities to
streamline the process or guide contributors effectively. This study
investigates the characteristics and outcomes of proposals in the Go
programming language to understand why proposals are declined and how such
outcomes might be anticipated. We conduct a mixed-method empirical study on
1,091 proposals submitted to the Go project. We quantify proposal outcomes,
build a taxonomy of decline reasons, and evaluate large language models (LLMs)
for predicting these outcomes. We find that proposals are more often declined
than accepted, and resolution typically takes over a month. Only 14.7% of
declined proposals are ever resubmitted. Through qualitative coding, we
identify nine key reasons for proposal decline, such as duplication, limited
use cases, or violations of project principles. This taxonomy can help
contributors address issues in advance, e.g., checking for existing
alternatives can reduce redundancy. We also demonstrate that GPT-based models
can predict decline decisions early in the discussion (F1 score = 0.71 with
partial comments), offering a practical tool for prioritizing review effort.
Our findings reveal inefficiencies in the proposal process and highlight
actionable opportunities for improving both contributor experience and reviewer
workload by enabling early triage and guiding contributors to strengthen their
proposals using a structured understanding of past decline reasons.

</details>


### [9] [Human-aligned AI Model Cards with Weighted Hierarchy Architecture](https://arxiv.org/abs/2510.06989)
*Pengyue Yang,Haolin Jin,Qingwen Zeng,Jiawen Wen,Harry Rao,Huaming Chen*

Main category: cs.SE

TL;DR: 提出了CRAI-MCF框架，从静态文档转向可操作、人类对齐的文档，解决大语言模型发现和采用中的挑战。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生态快速发展导致模型发现和采用困难，现有文档框架如Model Cards和FactSheets存在静态、定性为主、缺乏定量比较机制等问题。

Method: 基于价值敏感设计(VSD)，通过对240个开源项目的实证分析，提炼217个参数构建八模块、价值对齐的架构，引入定量充分性标准。

Result: CRAI-MCF框架能够实现严格的跨模型比较，平衡技术、伦理和操作维度。

Conclusion: 该框架使从业者能够更有效地评估、选择和采用大语言模型，提高信心和操作完整性。

Abstract: The proliferation of Large Language Models (LLMs) has led to a burgeoning
ecosystem of specialized, domain-specific models. While this rapid growth
accelerates innovation, it has simultaneously created significant challenges in
model discovery and adoption. Users struggle to navigate this landscape due to
inconsistent, incomplete, and imbalanced documentation across platforms.
Existing documentation frameworks, such as Model Cards and FactSheets, attempt
to standardize reporting but are often static, predominantly qualitative, and
lack the quantitative mechanisms needed for rigorous cross-model comparison.
This gap exacerbates model underutilization and hinders responsible adoption.
To address these shortcomings, we introduce the Comprehensive Responsible AI
Model Card Framework (CRAI-MCF), a novel approach that transitions from static
disclosures to actionable, human-aligned documentation. Grounded in Value
Sensitive Design (VSD), CRAI-MCF is built upon an empirical analysis of 240
open-source projects, distilling 217 parameters into an eight-module,
value-aligned architecture. Our framework introduces a quantitative sufficiency
criterion to operationalize evaluation and enables rigorous cross-model
comparison under a unified scheme. By balancing technical, ethical, and
operational dimensions, CRAI-MCF empowers practitioners to efficiently assess,
select, and adopt LLMs with greater confidence and operational integrity.

</details>


### [10] [Building an Open AIBOM Standard in the Wild](https://arxiv.org/abs/2510.07070)
*Gopi Krishnan Rajbahadur,Keheliya Gallaba,Elyas Rashno,Arthit Suriyawongkul,Karen Bennet,Kate Stewart,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 本文介绍了AI物料清单(AIBOM)规范的开发过程，这是SPDX软件物料清单标准的扩展，用于记录AI组件如数据集和训练工件。


<details>
  <summary>Details</summary>
Motivation: 探索在AI系统等快速发展领域中，如何创建开放、社区驱动的标准，填补相关研究空白。

Method: 采用行动研究方法，组织全球多利益相关方参与(超过90名贡献者)，通过结构化AR周期开发规范，并通过四种互补方法进行验证。

Result: 开发出经过验证的AIBOM规范，该规范与主要法规和伦理标准保持一致，并成功映射到行业用例。

Conclusion: 不仅交付了验证后的制品，还记录了在真实环境中构建AIBOM规范的过程，提炼出可为软件工程社区未来标准化工作提供参考的经验教训。

Abstract: Modern software engineering increasingly relies on open, community-driven
standards, yet how such standards are created in fast-evolving domains like
AI-powered systems remains underexplored. This paper presents a detailed
experience report on the development of the AI Bill of Materials AIBOM
specification, an extension of the ISO/IEC 5962:2021 Software Package Data
Exchange (SPDX) software bill of materials (SBOM) standard, which captures AI
components such as datasets and iterative training artifacts. Framed through
the lens of Action Research (AR), we document a global, multi-stakeholder
effort involving over 90 contributors and structured AR cycles. The resulting
specification was validated through four complementary approaches: alignment
with major regulations and ethical standards (e.g., EU AI Act and IEEE 7000
standards), systematic mapping to six industry use cases, semi-structured
practitioner interviews, and an industrial case study. Beyond delivering a
validated artefact, our paper documents the process of building the AIBOM
specification in the wild, and reflects on how it aligns with the AR cycle, and
distills lessons that can inform future standardization efforts in the software
engineering community.

</details>


### [11] [Prompt, Synthesize, Fine-Tune: A Secure Code Generation Recipe](https://arxiv.org/abs/2510.07189)
*Junjie Li,Fazle Rabbi,Bo Yang,Song Wang,Jinqiu Yang*

Main category: cs.SE

TL;DR: Secure-Instruct是一个通过自动合成高质量漏洞和安全代码示例来改进大语言模型安全代码生成能力的框架，显著提升了生成代码的安全性和功能正确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型生成的代码往往不安全，现有方法（如SafeCoder）受限于有限且不平衡的数据集，影响了其有效性和泛化能力。

Method: 提出Secure-Instruct框架，自动合成漏洞和安全代码示例，生成微调指令，并通过指令微调使LLMs对齐任务描述和安全代码生成能力。

Result: 在两个基准测试中表现优异：在CWEBench上安全代码生成平均提升14.3%，优于SafeCoder 7.6%；在CWEval上Func-Sec@1指标提升14%（CodeLlama-7B）和5.8%（Mistral-7B），分别优于SafeCoder 15.8%和6.8%。

Conclusion: Secure-Instruct不仅能提高生成代码的安全性，还能提升其功能正确性，为安全代码生成提供了有效的解决方案。

Abstract: Although Large Language Models (LLMs) show promising solutions to automated
code generation, they often produce insecure code that threatens software
security. Current approaches (e.g., SafeCoder) to improve secure code
generation suffer from limited and imbalanced datasets, reducing their
effectiveness and generalizability. In this work, we present Secure-Instruct, a
novel framework that automatically synthesizes high-quality vulnerable and
secure code examples, generates fine-tuning instructions, and instruction-tunes
LLMs to align task description and secure code generation abilities. We
evaluate Secure-Instruct on four representative LLMs using two benchmarks: our
own CWEBench and the existing CWEval. CWEBench comprises 93 scenarios on 44
CWEs, all without overlap with Secure-Instruct's synthetic instruction-tuning
dataset, while CWEval covers 31 CWEs with 119 manually verified
security-critical tasks. We find that Secure-Instruct improves not only the
security but also the functional correctness of the generated code. On
CWEBench, Secure-Instruct substantially improves secure code generation, giving
a 14.3% average increase in secure ratio over the pretrained models and
outperforms SafeCoder by 7.6%. On CWEval, Secure-Instruct achieves a 14%
increase for CodeLlama-7B and 5.8% for Mistral-7B in Func-Sec@1 over pretrained
models, and surpasses SafeCoder by 15.8% and 6.8% respectively.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [12] [VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code](https://arxiv.org/abs/2510.06296)
*Lingfei Zeng,Fengdi Che,Xuhan Huang,Fei Ye,Xu Xu,Binhang Yuan,Jie Fu*

Main category: cs.PL

TL;DR: VeriEquivBench是一个包含2389个复杂算法问题的新基准，用于评估LLM生成可验证代码的能力，采用形式化等价评分代替传统基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前形式化验证中规范质量评估的瓶颈问题，传统方法依赖人工标注的真实规范，过程繁琐且数据集规模有限。

Method: 引入形式化等价评分作为评估指标，建立包含2389个复杂算法问题的基准，对生成的规范和代码进行严格验证。

Result: 结果表明，当前最先进的LLM在生成可形式化验证的代码方面仍面临重大挑战。

Conclusion: 该基准突显了任务的难度，并强调了需要此类基准来推动可扩展和可靠编码代理的发展。

Abstract: Formal verification is the next frontier for ensuring the correctness of code
generated by Large Language Models (LLMs). While methods that co-generate code
and formal specifications in formal languages, like Dafny, can, in principle,
prove alignment with user intent, progress is bottlenecked by specification
quality evaluation. Current benchmarks rely on matching against ground-truth
specifications, a manual and expertise-intensive process that has limited
existing datasets to a few hundred simple problems and also suffers from a
reliability issue. To address this, we introduce VeriEquivBench, a new
benchmark with $2,389$ complex algorithmic problems that probe the limitations
of current models in both code generation and formal reasoning. Our evaluation
framework replaces ground-truth matching with a formally grounded metric, the
equivalence score, and rigorously verifies the quality of generated
specifications and code. Our results show that generating formally verifiable
code remains a profound challenge for state-of-the-art LLMs. This underscores
both the difficulty of the task and the need for benchmarks like VeriEquivBench
to drive progress toward scalable and reliable coding agents.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [13] [Strong Dinatural Transformations and Generalised Codensity Monads](https://arxiv.org/abs/2510.06777)
*Maciej Piróg,Filip Sieczkowski*

Main category: cs.LO

TL;DR: 本文介绍了dicodensity monads，这是对点态codensity monads的推广，通过混合变体双函子生成monads。该构造基于强双自然性概念，并受到多态lambda演算中某些类型的指称模型启发。


<details>
  <summary>Details</summary>
Motivation: 受多态lambda演算中具有全称量化变量的continuation monads（如System F中的列表monad的Church编码）的指称模型启发，旨在推广传统的codensity monads构造。

Method: 基于强双自然性（Barr双自然性）概念，通过混合变体双函子构造dicodensity monads。提供了建立monad与给定双函子的dicodensity monad之间同构的充分条件。

Result: 获得了由同态函子和更一般的双函子（即Eilenberg-Moore代数间的内化hom-sets）实例化构造的monads类，为建模有序非确定性计算的不同类型半环和其他理论提供了新的monad表示。

Conclusion: dicodensity monads为codensity monads提供了有意义的推广，能够统一表示多种用于建模有序非确定性计算的代数结构，扩展了Cayley风格表示的应用范围。

Abstract: We introduce dicodensity monads: a generalisation of pointwise codensity
monads generated by functors to monads generated by mixed-variant bifunctors.
Our construction is based on the notion of strong dinaturality (also known as
Barr dinaturality), and is inspired by denotational models of certain types in
polymorphic lambda calculi - in particular, a form of continuation monads with
universally quantified variables, such as the Church encoding of the list monad
in System F. Extending some previous results on Cayley-style representations,
we provide a set of sufficient conditions to establish an isomorphism between a
monad and the dicodensity monad for a given bifunctor. Then, we focus on the
class of monads obtained by instantiating our construction with hom-functors
and, more generally, bifunctors given by objects of homomorphisms (that is,
internalised hom-sets between Eilenberg--Moore algebras). This gives us, for
example, novel presentations of monads generated by different kinds of
semirings and other theories used to model ordered nondeterministic
computations.

</details>


### [14] [Reversible computations are computations](https://arxiv.org/abs/2510.06585)
*Clément Aubert,Jean Krivine*

Main category: cs.LO

TL;DR: 本文提出了一种支持可逆计算的并发因果模型扩展，通过对称剩余操作在配置结构中建模可逆计算，并证明了稳定配置结构在剩余操作下保持稳定性。


<details>
  <summary>Details</summary>
Motivation: 因果性作为并发系统的抽象时间概念，传统因果模型只考虑正向计算，但可逆计算中事件的发生是可逆的，需要扩展因果模型来适应这种特性。

Method: 在配置结构模型中引入对称剩余操作来建模可逆计算，然后推导出主事件结构的可逆计算语义，该语义与将冲突和因果性对偶化的切换操作相一致。

Result: 证明了稳定配置结构（对应主代数域）在剩余操作下保持稳定性，并建立了可逆计算语义与冲突-因果对偶化操作的一致性。

Conclusion: 简单的因果要求同样适用于可逆事件发生的情况，提出的可逆并发因果模型扩展是有效的，为可逆计算提供了理论基础。

Abstract: Causality serves as an abstract notion of time for concurrent systems. A
computation is causal, or simply valid, if each observation of a computation
event is preceded by the observation of its causes. The present work
establishes that this simple requirement is equally relevant when the
occurrence of an event is invertible. We propose a conservative extension of
causal models for concurrency that accommodates reversible computations. We
first model reversible computations using a symmetric residuation operation in
the general model of configuration structures. We show that stable
configuration structures, which correspond to prime algebraic domains, remain
stable under the action of this residuation. We then derive a semantics of
reversible computations for prime event structures, which is shown to coincide
with a switch operation that dualizes conflict and causality.

</details>


### [15] [A simple proof of the coincidence of observational and labeled equivalence of processes in applied pi-calculus](https://arxiv.org/abs/2510.07258)
*Andrew M. Mironov*

Main category: cs.LO

TL;DR: 本文为应用π演算中的观测等价与标记等价概念提供了更简单的证明


<details>
  <summary>Details</summary>
Motivation: 简化应用π演算中观测等价与标记等价概念重合定理的证明过程

Method: 提出新的证明方法，相比原有证明更加简单直接

Result: 成功证明了观测等价与标记等价在扩展过程中是等价的

Conclusion: 新证明方法显著简化了原定理的证明，为应用π演算理论提供了更易理解的证明框架

Abstract: This paper presents a new, significantly simpler proof of one of the main
results of applied pi-calculus: the theorem that the concepts of observational
and labeled equivalence of extended processes in applied pi-calculus coincide.

</details>
