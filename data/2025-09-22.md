<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 9]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Automatic layout of railroad diagrams](https://arxiv.org/abs/2509.15834)
*Shardul Chiplunkar,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 本文提出了铁路图布局的第一个形式化处理方法，包括一个原则性的实用实现，将图语言编译为布局语言，并实现线包装、对齐和调整等优化功能。


<details>
  <summary>Details</summary>
Motivation: 铁路图是常见的语法可视化方法，但由于工具限制和缺乏形式化布局关注，主要局限于手绘文档。需要系统化的布局方法。

Method: 将问题描述为将图语言编译为布局语言，实现编译器进行线包装以满足目标宽度，以及垂直对齐和水平调整。将线包装构建为优化问题，使用启发式方法。

Result: 通过将正则表达式和巴科斯-诺尔范式编译到图语言，证明该方法的适用性；通过与其他工具和手绘图的比较，验证编译器的实用性。

Conclusion: 提出的形式化铁路图布局方法和编译器实现是实用且有效的，为语法可视化提供了系统化的解决方案。

Abstract: Railroad diagrams (also called "syntax diagrams") are a common, intuitive
visualization of grammars, but limited tooling and a lack of formal attention
to their layout mostly confines them to hand-drawn documentation. We present
the first formal treatment of railroad diagram layout along with a principled,
practical implementation. We characterize the problem as compiling a *diagram
language* (specifying conceptual components and how they connect and compose)
to a *layout language* (specifying basic graphical shapes and their sizes and
positions). We then implement a compiler that performs *line wrapping* to meet
a target width, as well as vertical *alignment* and horizontal *justification*
per user-specified policies. We frame line wrapping as an optimization problem,
where we describe principled dimensions of optimality and implement
corresponding heuristics. For front-end evaluation, we show that our diagram
language is well-suited for common applications by describing how regular
expressions and Backus-Naur form can be compiled to it. For back-end
evaluation, we argue that our compiler is practical by comparing its output to
diagrams laid out by hand and by other tools.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [2] [Two Optimizations on the Stålmarck Procedure](https://arxiv.org/abs/2509.16172)
*Sergei Leonov,Liam Davis*

Main category: cs.LO

TL;DR: 本文介绍了StalmarckSAT——Stålmarck过程的现代重新实现，并提出了两种新策略：基数驱动分支(CDB)和演绎优先级排序(DPO)来改进该过程。


<details>
  <summary>Details</summary>
Motivation: 改进Stålmarck过程的SAT求解性能，通过开发新的分支启发式和规则排序策略来提高求解效率。

Method: 提出了两种新策略：CDB（改进分支选择的启发式方法）和DPO（基于演绎潜力智能排序简单规则）。这些策略集成到StalmarckSAT中。

Result: 实验结果表明，两种策略都显著提高了求解时间。

Conclusion: CDB和DPO策略有效提升了Stålmarck过程的性能，证明了这些新方法在SAT求解中的价值。

Abstract: In this paper, we introduce StalmarckSAT, the a modern re-implementation of
the St\aa lmarck Procedure for SAT solving, and present two novel strategies to
improve the Procedure, Cardinality Driven Branching (CDB) and Deductive
Priority Ordering (DPO). CDB is a heuristic to improve branching with the
dilemma rule, and DPO intelligently orders simple rules based on their
deductive potential. Our results demonstrate improved solve times with both
strategies.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges](https://arxiv.org/abs/2509.15283)
*Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo*

Main category: cs.SE

TL;DR: 本研究评估了开源本地大语言模型在复杂编程竞赛任务中的表现，发现其准确率约为专有模型的一半，揭示了开源与专有模型之间的性能差距，但也展示了开源模型的快速进步。


<details>
  <summary>Details</summary>
Motivation: 评估当前开源本地大语言模型处理具有扩展问题描述和上下文的复杂编程竞赛任务的能力，比较开源模型与专有模型的性能差异。

Method: 基于FACE框架进行改造，使其完全离线运行，使用Ollama运行时，将目录结构整合为JSON文件并添加检查点功能。对Kattis语料库的3,589个问题在8个代码导向模型（6.7-90亿参数）上进行测试。

Result: 本地模型的整体pass@1准确率较为一般，最佳模型的接受率约为专有模型（Gemini 1.5和ChatGPT-4）的一半。

Conclusion: 开源本地模型与最先进专有服务之间存在明显差距，但开源模型进步迅速，且可在组织内部硬件上复现的评估流程具有实际价值。

Abstract: This study examines the performance of today's open-source, locally hosted
large-language models (LLMs) in handling complex competitive programming tasks
with extended problem descriptions and contexts. Building on the original
Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit
the pipeline to work entirely offline through the Ollama runtime, collapsing
FACE's sprawling per-problem directory tree into a handful of consolidated JSON
files, and adding robust checkpointing so multi-day runs can resume after
failures. The enhanced framework generates, submits, and records solutions for
the full Kattis corpus of 3,589 problems across eight code-oriented models
ranging from 6.7-9 billion parameters. The submission results show that the
overall pass@1 accuracy is modest for the local models, with the best models
performing at approximately half the acceptance rate of the proprietary models,
Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between
private, cost-controlled LLM deployments and state-of-the-art proprietary
services, yet also highlight the rapid progress of open models and the
practical benefits of an evaluation workflow that organizations can replicate
on in-house hardware.

</details>


### [4] [LoCaL: Countering Surface Bias in Code Evaluation Metrics](https://arxiv.org/abs/2509.15397)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 本文提出了LoCaL基准测试，用于评估基于参考的代码评估指标（CEMs），发现现有CEMs存在表面特征偏见，并在新基准上表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和基于LLM的代理日益流行，可靠的代码评估指标变得至关重要。现有参考型CEMs与功能正确性的相关性较弱，但原因未被深入探究，解决方案也未被探索。

Method: 批判性评估四种最先进的参考型CEMs，提出LoCaL基准测试，包含3117个代码对，通过差分模糊测试计算功能相似性分数，无需预定义测试用例。

Result: 所有四种CEMs在LoCaL基准上的性能相比基线都出现显著下降，表明它们对表面特征存在强烈偏见。

Conclusion: 将CEMs暴露于LoCaL类似数据可能有助于开发对表面偏见具有鲁棒性的指标。

Abstract: With the increasing popularity of large language models (LLMs) and LLM-based
agents, reliable and effective code evaluation metrics (CEMs) have become
crucial for progress across several software engineering tasks. While popular
benchmarks often provide test cases to assess the correctness of generated
code, crafting and executing test cases is expensive. Reference-based CEMs
provide a cheaper alternative by scoring a candidate program based on its
functional similarity to a reference. Although prior research has focused on
reporting the weak correlation between these CEMs and functional correctness,
the causes are only assumed, and plausible solutions remain unexplored. In this
work, we critically evaluate four state-of-the-art reference-based CEMs,
revealing their strong bias towards surface-level features rather than code
functionality. Despite this surface bias, current evaluation datasets for these
CEMs rarely include code pairs that are surface-similar yet functionally
dissimilar, or functionally similar yet surface-dissimilar. To mitigate this
gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117
code pairs at both the method and program levels. Each pair is labeled with a
functional similarity score and aims to target regions where CEMs are likely to
perform poorly. The functional similarity scores are calculated through
differential fuzzing, which eliminates the need for predefined test cases and,
at the same time, improves the reliability of the scores by executing an order
of magnitude more tests than prior work. We find that all four CEMs show
significant performance degradation on LoCaL, compared to the baselines.
Finally, based on our findings, we draw the implication that exposing CEMs to
LoCaL-like data might facilitate the development of metrics that are robust to
surface bias.

</details>


### [5] [Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation](https://arxiv.org/abs/2509.15567)
*Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang*

Main category: cs.SE

TL;DR: 本文提出了一种通过文本模板来压缩代码变更信息的方法，用于自动生成高质量的提交消息。该方法使用包含三部分的模板（代码变更摘要、提取的注释、强调的代码标识符），结合ChangeScribe工具和CodeLlama-7B模型，在多个指标上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 开发者在实际工作中经常忽视编写高质量的提交消息，而现有的自动生成方法需要更好地组织和表示代码变更信息。本文旨在通过简洁的文本模板来更好地利用预训练语言模型，生成更易读的提交消息。

Method: 首先使用基于启发式的ChangeScribe工具将代码变更压缩为包含三部分的文本模板：(1)代码变更摘要、(2)提取的注释、(3)强调的代码标识符。然后在模板与对应提交消息的配对数据上微调CodeLlama-7B模型。

Result: 在广泛使用的数据集上评估，该方法在BLEU-Norm、METEOR和ROUGE-L指标上分别比六个基线方法平均提升了51.7%、78.7%和62.5%。消融研究和人工评估进一步验证了方法的有效性。

Conclusion: 提出的文本模板方法能够有效压缩代码变更信息，更好地利用预训练语言模型生成高质量的提交消息，为开发者提供自然简洁且可读性强的补充信息。

Abstract: Commit messages are valuable resources for describing why code changes are
committed to repositories in version control systems (e.g., Git). They
effectively help developers understand code changes and better perform software
maintenance tasks. Unfortunately, developers often neglect to write
high-quality commit messages in practice. Therefore, a growing body of work is
proposed to generate commit messages automatically. These works all
demonstrated that how to organize and represent code changes is vital in
generating good commit messages, including the use of fine-grained graphs or
embeddings to better represent code changes. In this study, we choose an
alternative way to condense code changes before generation, i.e., proposing
brief yet concise text templates consisting of the following three parts: (1)
summarized code changes, (2) elicited comments, and (3) emphasized code
identifiers. Specifically, we first condense code changes by using our proposed
templates with the help of a heuristic-based tool named ChangeScribe, and then
fine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding
commit messages. Our proposed templates better utilize pre-trained language
models, while being naturally brief and readable to complement generated commit
messages for developers. Our evaluation based on a widely used dataset showed
that our approach can outperform six baselines in terms of BLEU-Norm, METEOR,
and ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,
respectively. The ablation study and human evaluation also provide further
insights into the effectiveness of our approach.

</details>


### [6] [How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches](https://arxiv.org/abs/2509.15777)
*Haoran Xu,Zhi Chen,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文提出了一种新颖的两阶段框架，结合版本驱动候选过滤和基于大语言模型的多轮对话投票，用于开源软件漏洞补丁检测，在750个真实漏洞数据集上验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统手动检测方法在大规模提交历史处理中面临可扩展性挑战且易出错，现有自动化方法存在准确率有限、泛化能力差和方法约束等问题，需要更有效的解决方案。

Method: 提出两阶段框架：第一阶段通过版本驱动候选过滤缩小搜索空间，第二阶段使用基于大语言模型的多轮对话投票机制进行精确识别。

Result: 在包含750个真实漏洞的数据集上进行广泛实验，证明该方法优于现有方法。

Conclusion: 基于实证研究发现的四个关键洞察设计的框架能够实现准确高效的开源软件漏洞补丁检测，解决了现有方法的局限性。

Abstract: Open-source software vulnerability patch detection is a critical component
for maintaining software security and ensuring software supply chain integrity.
Traditional manual detection methods face significant scalability challenges
when processing large volumes of commit histories, while being prone to human
errors and omissions. Existing automated approaches, including heuristic-based
methods and pre-trained model solutions, suffer from limited accuracy, poor
generalization capabilities, and inherent methodological constraints that
hinder their practical deployment. To address these fundamental challenges,
this paper conducts a comprehensive empirical study of existing vulnerability
patch detection methods, revealing four key insights that guide the design of
effective solutions: the critical impact of search space reduction, the
superiority of pre-trained semantic understanding over architectural
complexity, the temporal limitations of web crawling approaches, and the
advantages of knowledge-driven methods. Based on these insights, we propose a
novel two-stage framework that combines version-driven candidate filtering with
large language model-based multi-round dialogue voting to achieve accurate and
efficient vulnerability patch identification. Extensive experiments on a
dataset containing 750 real vulnerabilities demonstrate that our method
outperforms current approaches.

</details>


### [7] [Failure Modes and Effects Analysis: An Experience from the E-Bike Domain](https://arxiv.org/abs/2509.15893)
*Andrea Bombarda,Federico Conti,Marcello Minervini,Aurora Zanenga,Claudio Menghi*

Main category: cs.SE

TL;DR: 本文通过工业案例研究验证了基于仿真的FMEA方法在CPS安全分析中的有效性，使用Simulink Fault Analyzer工具对电动自行车系统进行故障分析，发现该方法能有效帮助工程师改进模型并发现意外故障效应。


<details>
  <summary>Details</summary>
Motivation: 工业界需要证据证明基于仿真的FMEA方法在实际应用中的有效性，以促进其更广泛的实际采用。本文旨在通过一个具体的CPS（电动自行车）案例来验证这种方法的实用性。

Method: 使用Simulink Fault Analyzer工业工具，识别了13个现实故障并建模分析其影响。通过专家反馈评估模型准确性和故障检测安全违规的有效性。

Result: 对于识别的故障，模型准确或仅包含轻微不精确（已修正）。38.4%（5/13）的故障仿真结果与工程师预期不符，帮助他们发现意外的故障效应。FMEA确实能帮助工程师改进模型。

Conclusion: 基于仿真的FMEA方法在CPS安全分析中具有实际价值，能有效发现意外故障效应并改进系统模型。研究结果为Simulink工程师、安全分析师等提供了实用的经验教训。

Abstract: Software failures can have catastrophic and costly consequences. Functional
Failure Mode and Effects Analysis (FMEA) is a standard technique used within
Cyber-Physical Systems (CPS) to identify software failures and assess their
consequences. Simulation-driven approaches have recently been shown to be
effective in supporting FMEA. However, industries need evidence of the
effectiveness of these approaches to increase practical adoption. This
industrial paper presents our experience with using FMEA to analyze the safety
of a CPS from the e-Bike domain. We used Simulink Fault Analyzer, an industrial
tool that supports engineers with FMEA. We identified 13 realistic faults,
modeled them, and analyzed their effects. We sought expert feedback to analyze
the appropriateness of our models and the effectiveness of the faults in
detecting safety breaches. Our results reveal that for the faults we
identified, our models were accurate or contained minor imprecision that we
subsequently corrected. They also confirm that FMEA helps engineers improve
their models. Specifically, the output provided by the simulation-driven
support for 38.4% (5 out of 13) of the faults did not match the engineers'
expectations, helping them discover unexpected effects of the faults. We
present a thorough discussion of our results and ten lessons learned. Our
findings are useful for software engineers who work as Simulink engineers, use
the Simulink Fault Analyzer, or work as safety analysts.

</details>


### [8] [LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines](https://arxiv.org/abs/2509.15971)
*Owen Truong,Terrence Zhang,Arnav Marchareddy,Ryan Lee,Jeffery Busold,Michael Socas,Eman Abdullah AlOmar*

Main category: cs.SE

TL;DR: 开发了一个名为LeakageDetector的VS Code扩展，用于检测和修复Jupyter Notebook中的数据泄漏问题，包括重叠泄漏、预处理泄漏和多测试泄漏。


<details>
  <summary>Details</summary>
Motivation: 在机器学习开发中，数据泄漏会导致模型性能评估失真，影响代码质量。ML工程师需要有效工具来识别和解决这一问题。

Method: 创建VS Code扩展，包含检测机制和两种修复方式：传统手动修复和基于LLM的指导性修复。

Result: 开发了能够自动检测数据泄漏并提供修复建议的工具。

Conclusion: LeakageDetector扩展有助于ML开发者避免数据泄漏，提升模型评估的准确性。

Abstract: In software development environments, code quality is crucial. This study
aims to assist Machine Learning (ML) engineers in enhancing their code by
identifying and correcting Data Leakage issues within their models. Data
Leakage occurs when information from the test dataset is inadvertently included
in the training data when preparing a data science model, resulting in
misleading performance evaluations. ML developers must carefully separate their
data into training, evaluation, and test sets to avoid introducing Data Leakage
into their code. In this paper, we develop a new Visual Studio Code (VS Code)
extension, called LeakageDetector, that detects Data Leakage, mainly Overlap,
Preprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond
detection, we included two correction mechanisms: a conventional approach,
known as a quick fix, which manually fixes the leakage, and an LLM-driven
approach that guides ML developers toward best practices for building ML
pipelines.

</details>


### [9] [Software Development Aspects of Integrating Linear Algebra Libraries](https://arxiv.org/abs/2509.16081)
*Marcel Koch,Tobias Ribizel,Pratik Nayak,Fritz Göbel,Gregor Olenik,Terry Cojean*

Main category: cs.SE

TL;DR: 本文讨论了应用软件采用Ginkgo稀疏数值线性代数库的挑战和益处，通过CFD、电网仿真和心电生理学等领域的案例，从软件工程角度分析集成对应用代码的影响，并强调可持续软件开发的方法。


<details>
  <summary>Details</summary>
Motivation: 许多科学发现依赖于模拟软件，这些软件通常需要集成来自不同领域的特定功能组件。Ginkgo作为处理稀疏数值线性代数的基础库，能帮助应用软件更好地适应现代系统并加速仿真过程。

Method: 通过分析不同领域（CFD、电网仿真、心电生理学）的应用案例，从软件工程角度评估Ginkgo集成对应用代码的影响，重点关注可持续软件开发的方法和策略。

Result: Ginkgo能够帮助应用软件简化向现代系统的过渡，并通过更快的数值线性代数例程加速仿真过程。集成过程中需要解决软件工程方面的挑战，但能带来显著的性能提升。

Conclusion: Ginkgo作为稀疏数值线性代数的基础组件，为科学计算应用提供了有效的解决方案，通过合理的软件工程方法可以实现可持续的集成和开发。

Abstract: Many scientific discoveries are made through, or aided by, the use of
simulation software. These sophisticated software applications are not built
from the ground up, instead they rely on smaller parts for specific use cases,
usually from domains unfamiliar to the application scientists. The software
library Ginkgo is one of these building blocks to handle sparse numerical
linear algebra on different platforms. By using Ginkgo, applications are able
to ease the transition to modern systems, and speed up their simulations
through faster numerical linear algebra routines. This paper discusses the
challenges and benefits for application software in adopting Ginkgo. It will
present examples from different domains, such as CFD, power grid simulation, as
well as electro-cardiophysiology. For these cases, the impact of the
integrations on the application code is discussed from a software engineering
standpoint, and in particular, the approaches taken by Ginkgo and the
applications to enable sustainable software development are highlighted.

</details>


### [10] [When Bugs Linger: A Study of Anomalous Resolution Time Outliers and Their Themes](https://arxiv.org/abs/2509.16140)
*Avinash Patil*

Main category: cs.SE

TL;DR: 该研究分析了七个开源软件项目中bug解决时间的异常情况，使用统计方法和文本分析技术识别异常bug报告的主题模式。


<details>
  <summary>Details</summary>
Motivation: 高效解决bug对于维护软件质量和用户满意度至关重要，但某些bug报告存在异常长的解决时间，这可能表明存在潜在的过程效率低下或复杂问题。

Method: 使用Z-score和四分位距(IQR)统计方法识别bug解决时间的异常值，应用TF-IDF进行文本特征提取，并使用KMeans聚类对相似的bug摘要进行分组。

Result: 研究发现异常bug通常围绕测试失败、功能增强请求和用户界面问题等主题聚类，这些模式在七个项目中表现一致。

Conclusion: 该方法为项目维护者提供了可操作的见解，帮助他们优先处理并有效解决长期存在的bug。

Abstract: Efficient bug resolution is critical for maintaining software quality and
user satisfaction. However, specific bug reports experience unusually long
resolution times, which may indicate underlying process inefficiencies or
complex issues. This study presents a comprehensive analysis of bug resolution
anomalies across seven prominent open-source repositories: Cassandra, Firefox,
Hadoop, HBase, SeaMonkey, Spark, and Thunderbird. Utilizing statistical methods
such as Z-score and Interquartile Range (IQR), we identify anomalies in bug
resolution durations. To understand the thematic nature of these anomalies, we
apply Term Frequency-Inverse Document Frequency (TF-IDF) for textual feature
extraction and KMeans clustering to group similar bug summaries. Our findings
reveal consistent patterns across projects, with anomalies often clustering
around test failures, enhancement requests, and user interface issues. This
approach provides actionable insights for project maintainers to prioritize and
effectively address long-standing bugs.

</details>


### [11] [MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair](https://arxiv.org/abs/2509.16187)
*Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening*

Main category: cs.SE

TL;DR: MatchFixAgent是一个基于大语言模型的编程语言无关框架，用于代码翻译的等价性验证和修复，通过多智能体架构实现语义分析和测试执行，在多个编程语言对上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有自动化验证和修复方法难以泛化到多种编程语言，且依赖不充分的测试套件，导致等价性判断错误和修复效果不佳。

Method: 采用多智能体架构，将等价性验证分解为多个子任务，包括语义分析、测试编写执行、错误修复和最终裁决，实现编程语言无关的验证和修复。

Result: 在2,219个翻译对（覆盖6种编程语言对）上测试，MatchFixAgent为99.2%的翻译对生成等价性判断，与先前工作一致率达72.8%，不一致时60.7%的情况下MatchFixAgent正确，修复成功率50.6%远超先前工作的18.5%。

Conclusion: MatchFixAgent相比现有方法能更好地适应多种编程语言对，同时产生高度准确的验证结果，显著提升了代码翻译的验证和修复能力。

Abstract: Code translation transforms source code from one programming language (PL) to
another. Validating the functional equivalence of translation and repairing, if
necessary, are critical steps in code translation. Existing automated
validation and repair approaches struggle to generalize to many PLs due to high
engineering overhead, and they rely on existing and often inadequate test
suites, which results in false claims of equivalence and ineffective
translation repair. We develop MatchFixAgent, a large language model
(LLM)-based, PL-agnostic framework for equivalence validation and repair of
translations. MatchFixAgent features a multi-agent architecture that divides
equivalence validation into several sub-tasks to ensure thorough and consistent
semantic analysis of the translation. Then it feeds this analysis to test agent
to write and execute tests. Upon observing a test failure, the repair agent
attempts to fix the translation bug. The final (in)equivalence decision is made
by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four
repository-level code translation techniques. We use 2,219 translation pairs
from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub
projects totaling over 900K lines of code. Our results demonstrate that
MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,
with the same equivalence validation result as prior work on 72.8% of them.
When MatchFixAgent's result disagrees with prior work, we find that 60.7% of
the time MatchFixAgent's result is actually correct. In addition, we show that
MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior
work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to
many PL pairs than prior work, while producing highly accurate validation
results.

</details>
