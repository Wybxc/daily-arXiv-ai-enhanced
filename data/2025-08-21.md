<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Tuning Random Generators: Property-Based Testing as Probabilistic Programming](https://arxiv.org/abs/2508.14394)
*Ryan Tjoa,Poorva Garg,Harrison Goldstein,Todd Millstein,Benjamin Pierce,Guy Van den Broeck*

Main category: cs.PL

TL;DR: 本文提出了自动调优属性测试生成器权重的方法，通过概率编程系统Loaded Dice实现权重优化，显著提升bug发现效率


<details>
  <summary>Details</summary>
Motivation: 传统属性测试中，用户需要手动调整生成器的随机选择权重来获得理想的测试输入分布，这个过程繁琐且难以实现期望的分布

Method: 开发了基于符号权重和目标函数的自动离线调优技术，使用支持微分和参数学习的概率编程系统Loaded Dice作为生成器语言

Result: 实验证明该方法能有效优化生成器分布，在针对多样性和有效性自动调优后，生成器在bug发现方面实现了3.1-7.4倍的加速

Conclusion: 自动权重调优技术能够显著改善属性测试生成器的性能，使测试输入分布更符合预期，提高测试效率

Abstract: Property-based testing validates software against an executable specification
by evaluating it on randomly generated inputs. The standard way that PBT users
generate test inputs is via generators that describe how to sample test inputs
through random choices. To achieve a good distribution over test inputs, users
must tune their generators, i.e., decide on the weights of these individual
random choices. Unfortunately, it is very difficult to understand how to choose
individual generator weights in order to achieve a desired distribution, so
today this process is tedious and limits the distributions that can be
practically achieved.
  In this paper, we develop techniques for the automatic and offline tuning of
generators. Given a generator with undetermined symbolic weights and an
objective function, our approach automatically learns values for these weights
that optimize for the objective. We describe useful objective functions that
allow users to (1) target desired distributions and (2) improve the diversity
and validity of their test cases. We have implemented our approach in a novel
discrete probabilistic programming system, Loaded Dice, that supports
differentiation and parameter learning, and use it as a language for
generators. We empirically demonstrate that our approach is effective at
optimizing generator distributions according to the specified objective
functions. We also perform a thorough evaluation on PBT benchmarks,
demonstrating that, when automatically tuned for diversity and validity, the
generators exhibit a 3.1-7.4x speedup in bug finding.

</details>


### [2] [Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity](https://arxiv.org/abs/2508.14614)
*Ashish Mishra,Suresh Jagannathan*

Main category: cs.PL

TL;DR: 该文章提出了一种基于质量树自动机(QTA)的组件合成算法，通过利用精化类型的逻辑类似性进行路径控制，提高了复杂查询条件下的程序合成效率。


<details>
  <summary>Details</summary>
Motivation: 解决组件基础合成(CBS)中遇到的挑战：越精确的查询约束和越丰富的库方法规范会导致可行解空间更稀疏，使循环元素枚举更加困难。

Method: 使用精化类型规范库方法，建立质量树自动机(QTA)进行搜索。利用精化类型的子类型约束进行逻辑类似性推理，记录已枚举项的信息，避免搜索语义相似的路径。

Result: 实现了工具\name，综合评估显示其能够合成复杂CBS查询的解决方案，性能远超现有最先进技术。

Conclusion: 通过逻辑类似性推理的路径控制技术，有效提升了组件基础合成在严格约束条件下的搜索效率和能力。

Abstract: Component-based synthesis (CBS) aims to generate loop-free programs from a
set of libraries whose methods are annotated with specifications and whose
output must satisfy a set of logical constraints, expressed as a query. The
effectiveness of a CBS algorithm critically depends on the severity of the
constraints imposed by the query. The more exact these constraints are, the
sparser the space of feasible solutions. This maxim also applies when we enrich
the expressiveness of the specifications affixed to library methods. In both
cases, the search must now contend with constraints that may only hold over a
small number of the possible execution paths that can be enumerated by a CBS
procedure.
  In this paper, we address this challenge by equipping CBS search with the
ability to reason about logical similarities among the paths it explores. Our
setting considers library methods equipped with refinement-type specifications
that enrich ordinary base types with a set of rich logical qualifiers to
constrain the set of values accepted by that type. We perform a search over a
tree automata variant called Qualified Tree Automata that intelligently records
information about enumerated terms, leveraging subtyping constraints over the
refinement types associated with these terms to enable reasoning about
similarity among candidate solutions as search proceeds, thereby avoiding
exploration of semantically similar paths.
  We present an implementation of this idea in a tool called \name, and provide
a comprehensive evaluation that demonstrates \name's ability to synthesize
solutions to complex CBS queries that go well-beyond the capabilities of the
existing state-of-the-art.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [3] [Efficient Learning of Weak Deterministic Büchi Automata](https://arxiv.org/abs/2508.14274)
*Mona Alluwayma,Yong Li,Sven Schewe,Qiyi Tang*

Main category: cs.FL

TL;DR: 提出了一种高效的Angluin式学习算法，用于学习弱确定性Büchi自动机（wDBA）的最小范式，相比之前的方法将查询复杂度从五次方降低到二次方。


<details>
  <summary>Details</summary>
Motivation: 弱确定性Büchi自动机具有最小范式特性，但之前的学习算法查询复杂度较高（五次方），需要开发更高效的算法来减少查询次数。

Method: 采用Angluin式学习算法框架，针对wDBA的最小范式特性进行优化，设计新的查询策略和数据结构。

Result: 理论分析表明查询复杂度从O(n^5)降低到O(n^2)，基准测试证实实际查询次数显著减少，算法效率大幅提升。

Conclusion: 该算法成功实现了对wDBA最小范式的高效学习，在理论和实践上都显著优于现有方法，为自动机学习领域提供了重要的改进。

Abstract: We present an efficient Angluin-style learning algorithm for weak
deterministic B\"uchi automata (wDBAs). Different to ordinary deterministic
B\"uchi and co-B\"uchi automata, wDBAs have a minimal normal form, and we show
that we can learn this minimal normal form efficiently. We provide an improved
result on the number of queries required and show on benchmarks that this
theoretical advantage translates into significantly fewer queries: while
previous approaches require a quintic number of queries, we only require
quadratically many queries in the size of the canonic wDBA that recognises the
target language.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [To Zip Through the Cost Analysis of Probabilistic Programs](https://arxiv.org/abs/2508.14249)
*Matthias Hetzenberger,Georg Moser,Florian Zuleger*

Main category: cs.LO

TL;DR: 在Liquid Haskell中引入精化类型的概率单子，通过类型编码概率行为实现期望值和运行成本的自动化推理，支持离散和无限分布，并通过四个案例研究验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 概率编程和概率算法形式分析是研究热点，但自动化推理期望运行时间方面相对有限，需要解决这一挑战。

Method: 在Liquid Haskell中设计精化类型的概率单子，利用SMT-based精化类型检查实现自动化，支持离散有限分布并通过公理化方法扩展到无限分布。

Result: 通过四个案例研究（可合并堆、优惠券收集器、随机快速排序、zip树）验证了方法的有效性，前两个案例展示了最小标注开销的自动化，后两个展示了与交互式证明的集成，并首次形式验证了zip树的期望运行时间。

Conclusion: 提出的精化类型概率单子为概率程序的期望值和时间成本自动化推理提供了有效框架，在Liquid Haskell中实现了高度自动化，并通过多个案例证明了其实用性。

Abstract: Probabilistic programming and the formal analysis of probabilistic algorithms
are active areas of research, driven by the widespread use of randomness to
improve performance. While functional correctness has seen substantial
progress, automated reasoning about expected runtime remains comparatively
limited. In this work, we address this challenge by introducing a
refinement-typed probability monad in Liquid Haskell. Our monad enables
automated reasoning about expected values and costs by encoding probabilistic
behaviour directly in types. Initially defined for discrete distributions over
finite support, it is extended to support infinite distributions via an
axiomatic approach. By leveraging Liquid Haskell's SMT-based refinement type
checking, our framework provides a high degree of automation. We evaluate our
approach through four case studies: meldable heaps, coupon collector,
randomised quicksort, and zip trees. The first two demonstrate automation with
minimal annotation overhead. The latter two showcase how our monad integrates
with interactive proofs, including the first formal verification of the
expected runtime of zip trees.

</details>


### [5] [Quantum Petri Nets with Event Structures semantics](https://arxiv.org/abs/2508.14531)
*Julien Saan Joachim,Marc de Visme,Stefan Haar*

Main category: cs.LO

TL;DR: 本文提出了量子Petri网(QPNs)模型，为量子并发建立了基于Petri网理论的严格语义框架，填补了量子并发建模的理论空白。


<details>
  <summary>Details</summary>
Motivation: 经典Petri网具有成熟的并发语义和展开理论，但现有的"量子Petri网"缺乏严格的量子语义、分析工具和展开理论，需要建立一个语义基础良好的量子并发模型。

Method: 引入量子Petri网(QPNs)，配备与量子事件结构语义兼容的量子估值；提出局部量子发生网(LQONs)定义；构建具有明确定义展开语义的QPNs；建立QPNs的组合框架。

Result: 成功建立了量子Petri网的展开语义理论，实现了与量子事件结构的兼容，为量子并发提供了语义基础良好的建模工具。

Conclusion: 该工作填补了量子并发建模的理论空白，搭建了Petri网理论与量子编程之间的桥梁，为量子并发系统的形式化分析和验证提供了坚实基础。

Abstract: Classical Petri nets provide a canonical model of concurrency, with unfolding
semantics linking nets, occurrence nets, and event structures. No comparable
framework exists for quantum concurrency: existing ''quantum Petri nets'' lack
rigorous concurrent and sound quantum semantics, analysis tools, and unfolding
theory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a
quantum valuation compatible with the quantum event structure semantics of
Clairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local
definition of Quantum Occurrence Nets (LQONs) compatible with quantum event
structures, (ii) a construction of QPNs with a well-defined unfolding
semantics, (iii) a compositional framework for QPNs. This establishes a
semantically well grounded model of quantum concurrency, bridging Petri net
theory and quantum programming.

</details>


### [6] [A Complete and Natural Rule Set for Multi-Qutrit Clifford Circuits](https://arxiv.org/abs/2508.14670)
*Sarah Meng Li,Michele Mosca,Neil J. Ross,John van de Wetering,Yuming Zhao*

Main category: cs.LO

TL;DR: 提出了n-qutrit Clifford电路的完整重写规则集，这是奇数素数维度量子电路片段的第一个完备性结果


<details>
  <summary>Details</summary>
Motivation: 为奇数素数维度（特别是qutrit）的量子电路建立完备的重写系统，填补该领域的研究空白

Method: 首先将Selinger的n-qubit Clifford电路正规形式推广到qutrit设置，然后提出重写系统将任意Clifford电路约简为该正规形式，最后简化重写规则为小而自然的规则集

Result: 获得了n-qutrit Clifford电路的完备重写规则集，给出了qutrit Clifford酉群的生成元和关系的清晰表示

Conclusion: 成功建立了qutrit Clifford电路的完整代数理论框架，为奇数素数维度量子计算提供了重要理论基础

Abstract: We present a complete set of rewrite rules for n-qutrit Clifford circuits
where n is any non-negative integer. This is the first completeness result for
any fragment of quantum circuits in odd prime dimensions. We first generalize
Selinger's normal form for n-qubit Clifford circuits to the qutrit setting.
Then, we present a rewrite system by which any Clifford circuit can be reduced
to this normal form. We then simplify the rewrite rules in this procedure to a
small natural set of rules, giving a clean presentation of the group of qutrit
Clifford unitaries in terms of generators and relations.

</details>


### [7] [Emerson-Lei and Manna-Pnueli Games for LTLf+ and PPLTL+ Synthesis](https://arxiv.org/abs/2508.14725)
*Daniel Hausmann,Shufang Zhu,Gianmarco Parretti,Christoph Weinhuber,Giuseppe De Giacomo,Nir Piterman*

Main category: cs.LO

TL;DR: 本文提出了首个针对LTLfp和PPLTLp逻辑的反应式综合求解器，基于Manna-Pnueli层次结构，通过符号求解器和Manna-Pnueli游戏两种方法实现，后者在效率上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: Manna-Pnueli层次结构定义了LTLfp和PPLTLp逻辑，这些逻辑允许在无限轨迹设置中使用有限轨迹技术，同时实现完整LTL的表达能力，但目前缺乏实际的反应式综合求解器。

Method: 提出了两种求解器：基于Emerson-Lei游戏的符号求解器，将低层属性（保证性、安全性）规约到高层属性（重复性、持久性）；以及Manna-Pnueli游戏，通过组合更简单Emerson-Lei游戏的解决方案来原生嵌入Manna-Pnueli目标。

Result: 实现了这两种求解器并在代表性公式上进行了实际性能评估，结果显示Manna-Pnueli游戏通常具有显著优势，但并非普遍适用。

Conclusion: Manna-Pnueli游戏提供了更高效的方法，但结合两种方法可以进一步提升实际性能。

Abstract: Recently, the Manna-Pnueli Hierarchy has been used to define the temporal
logics LTLfp and PPLTLp, which allow to use finite-trace LTLf/PPLTL techniques
in infinite-trace settings while achieving the expressiveness of full LTL. In
this paper, we present the first actual solvers for reactive synthesis in these
logics. These are based on games on graphs that leverage DFA-based techniques
from LTLf/PPLTL to construct the game arena. We start with a symbolic solver
based on Emerson-Lei games, which reduces lower-class properties (guarantee,
safety) to higher ones (recurrence, persistence) before solving the game. We
then introduce Manna-Pnueli games, which natively embed Manna-Pnueli objectives
into the arena. These games are solved by composing solutions to a DAG of
simpler Emerson-Lei games, resulting in a provably more efficient approach. We
implemented the solvers and practically evaluated their performance on a range
of representative formulas. The results show that Manna-Pnueli games often
offer significant advantages, though not universally, indicating that combining
both approaches could further enhance practical performance.

</details>


### [8] [Constraint satisfaction problems, compactness and non-measurable sets](https://arxiv.org/abs/2508.14838)
*Claude Tardif*

Main category: cs.LO

TL;DR: 该论文研究了有限关系结构的紧致性，证明了一维结构的紧致性可以在ZF公理系统中证明，而更高维结构的紧致性则与非可测集的存在性相关。


<details>
  <summary>Details</summary>
Motivation: 研究有限关系结构的紧致性特性，探索其与集合论公理系统的关系，特别是与可测性公理的联系。

Method: 通过分析关系结构的维度（宽度），研究其在ZF公理系统下的可证明性，以及与非可测集存在性的逻辑关联。

Result: 发现一维关系结构的紧致性可在ZF中证明，而更高维结构的紧致性则蕴含三维空间中非可测集的存在。

Conclusion: 关系结构的紧致性性质与基础数学的公理系统深度相关，不同维度的结构呈现出不同的可证明性特征。

Abstract: A finite relational structure A is called compact if for any infinite
relational structure B of the same type, the existence of a homomorphism from B
to A is equivalent to the existence of homomorphisms from all finite
substructures of B to A. We show that if A has width one, then the compactness
of A can be proved in the axiom system of Zermelo and Fraenkel, but otherwise,
the compactness of A implies the existence of non-measurable sets in 3-space.

</details>


### [9] [Correct Black-Box Monitors for Distributed Deadlock Detection: Formalisation and Implementation (Technical Report)](https://arxiv.org/abs/2508.14851)
*Radosław Jan Rowicki,Adrian Francalanza,Alceste Scalas*

Main category: cs.LO

TL;DR: 提出了分布式黑盒监控器DDMon，通过观察消息流和交换探针来检测Erlang/OTP等RPC系统中的死锁，无需修改服务代码


<details>
  <summary>Details</summary>
Motivation: 随着并发分布式系统的规模增长，死锁风险增加且诊断困难，传统方法难以应对分布式环境下的死锁检测

Method: 基于形式化模型开发分布式黑盒监控算法，部署在每个服务旁监控进出消息，通过交换探针实现死锁检测

Result: 证明了算法的正确性（无假阳性/假阴性），实现了DDMon工具并在Erlang/OTP应用中验证性能

Conclusion: 首个形式化证明正确性的分布式黑盒死锁检测方案，为RPC系统提供了有效的死锁诊断工具

Abstract: Many software applications rely on concurrent and distributed (micro)services
that interact via message-passing and various forms of remote procedure calls
(RPC). As these systems organically evolve and grow in scale and complexity,
the risk of introducing deadlocks increases and their impact may worsen: even
if only a few services deadlock, many other services may block while awaiting
responses from the deadlocked ones. As a result, the "core" of the deadlock can
be obfuscated by its consequences on the rest of the system, and diagnosing and
fixing the problem can be challenging.
  In this work we tackle the challenge by proposing distributed black-box
monitors that are deployed alongside each service and detect deadlocks by only
observing the incoming and outgoing messages, and exchanging probes with other
monitors. We present a formal model that captures popular RPC-based application
styles (e.g., gen_servers in Erlang/OTP), and a distributed black-box
monitoring algorithm that we prove sound and complete (i.e., identifies
deadlocked services with neither false positives nor false negatives). We
implement our results in a tool called DDMon for the monitoring of Erlang/OTP
applications, and we evaluate its performance.
  This is the first work that formalises, proves the correctness, and
implements distributed black-box monitors for deadlock detection. Our results
are mechanised in Coq. DDMon is the companion artifact of this paper.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [10] [You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation](https://arxiv.org/abs/2508.14104)
*Yutong Bian,Xianhao Lin,Yupeng Xie,Tianyang Liu,Mingchen Zhuge,Siyuan Lu,Haoming Tang,Jinlin Wang,Jiayi Zhang,Jiaqi Chen,Xiangru Tang,Yongxin Ni,Sirui Hong,Chenglin Wu*

Main category: cs.SE

TL;DR: RealDevWorld是一个用于评估大语言模型生成生产级软件能力的端到端评估框架，包含多样化任务集和基于GUI交互的自动评估系统，能够有效评估软件的交互行为和运行时动态。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要依赖静态检查或二进制通过/失败脚本，无法捕捉真实软件应用的交互行为和运行时动态，存在评估盲区。需要一种能够模拟真实用户交互的评估方法来全面评估LLM生成的软件质量。

Method: 提出RealDevWorld框架，包含两个核心组件：1) RealDevBench - 194个跨领域开放式软件工程任务集合；2) AppEvalPilot - 基于代理即法官的评估系统，通过模拟GUI用户交互来自动评估软件功能正确性、视觉保真度和运行时行为。

Result: 实证结果显示，RealDevWorld实现了0.92的准确率和0.85的人类专家评估相关性，显著减少了对人工评审的依赖，能够提供细粒度的任务特定诊断反馈。

Conclusion: 该框架实现了可扩展的、与人类评估对齐的生产级软件自动评估，为大语言模型在软件开发中的能力评估提供了有效解决方案。

Abstract: Large Language Models (LLMs) and code agents in software development are
rapidly evolving from generating isolated code snippets to producing
full-fledged software applications with graphical interfaces, interactive
logic, and dynamic behaviors. However, current benchmarks fall short in
evaluating such production-ready software, as they often rely on static checks
or binary pass/fail scripts, failing to capture the interactive behaviors and
runtime dynamics that define real-world usability - qualities that only emerge
when an application is actively used. This is the blind spot of current
evaluation: you don't know if an app works until you click through it, interact
with it, and observe how it responds. To bridge this gap, we introduce
RealDevWorld, a novel evaluation framework for automated end-to-end assessment
of LLMs' ability to generate production-ready repositories from scratch. It
features two key components: (1) RealDevBench, a diverse collection of 194
open-ended software engineering tasks across multiple domains, incorporating
multimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a
new agent-as-a-judge evaluation system that simulates realistic, GUI-based user
interactions to automatically and holistically assess software functional
correctness, visual fidelity, and runtime behavior. The framework delivers
fine-grained, task-specific diagnostic feedback, supporting nuanced evaluation
beyond simple success/failure judgments. Empirical results show that
RealDevWorld delivers effective, automatic, and human-aligned evaluations,
achieving an accuracy of 0.92 and a correlation of 0.85 with expert human
assessments, while significantly reducing the reliance on manual review. This
enables scalable, human-aligned assessment of production-level software
generated by LLMs. Our code is available on GitHub.

</details>


### [11] [Ambiguity Resolution with Human Feedback for Code Writing Tasks](https://arxiv.org/abs/2508.14114)
*Aditey Nandan,Viraj Kumar*

Main category: cs.SE

TL;DR: 提出基于ARHF技术的原型系统，通过识别代码任务规范中的歧义、获取人类反馈并生成解决歧义的代码


<details>
  <summary>Details</summary>
Motivation: 代码编写任务规范通常用自然语言表达，可能存在歧义，程序员需要具备识别和解决这些歧义的能力

Method: 基于ARHF（Ambiguity Resolution with Human Feedback）技术，系统首先识别可能产生歧义的输入，然后寻求有限的人类反馈，最后利用反馈生成解决歧义的代码

Result: 开发并评估了原型系统的有效性

Conclusion: 讨论了此类辅助系统对计算机科学教育的影响

Abstract: Specifications for code writing tasks are usually expressed in natural
language and may be ambiguous. Programmers must therefore develop the ability
to recognize ambiguities in task specifications and resolve them by asking
clarifying questions. We present and evaluate a prototype system, based on a
novel technique (ARHF: Ambiguity Resolution with Human Feedback), that (1)
suggests specific inputs on which a given task specification may be ambiguous,
(2) seeks limited human feedback about the code's desired behavior on those
inputs, and (3) uses this feedback to generate code that resolves these
ambiguities. We evaluate the efficacy of our prototype, and we discuss the
implications of such assistive systems on Computer Science education.

</details>


### [12] [Measuring LLM Code Generation Stability via Structural Entropy](https://arxiv.org/abs/2508.14288)
*Yewei Song,Tiezhu Sun,Xunzhu Tang,Prateek Rajput,Tegawende F. Bissyande,Jacques Klein*

Main category: cs.SE

TL;DR: 本文提出了一种基于抽象语法树（AST）的结构熵方法来评估大语言模型代码生成的稳定性，无需参考代码或执行测试


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型代码生成的稳定性对于判断其在真实开发环境中的可靠性至关重要，现有评估方法如pass@k、BLEU等存在局限性

Method: 将结构熵概念扩展到程序领域，通过分析AST的深度受限子树的多重集，使用Jensen-Shannon散度和结构交叉熵比来测量结构重叠和缺失模式

Result: 在标准代码生成任务上对多个领先LLM进行基准测试，证明AST驱动的结构熵能够揭示模型一致性和鲁棒性的细微差别

Conclusion: 该方法时间复杂度为O(n,d)，无需外部测试，为代码生成评估工具包提供了一个轻量级的补充方案

Abstract: Assessing the stability of code generation from large language models (LLMs)
is essential for judging their reliability in real-world development. We extend
prior "structural-entropy concepts" to the program domain by pairing entropy
with abstract syntax tree (AST) analysis. For any fixed prompt, we collect the
multiset of depth-bounded subtrees of AST in each generated program and treat
their relative frequencies as a probability distribution. We then measure
stability in two complementary ways: (i) Jensen-Shannon divergence, a
symmetric, bounded indicator of structural overlap, and (ii) a Structural
Cross-Entropy ratio that highlights missing high-probability patterns. Both
metrics admit structural-only and token-aware variants, enabling separate views
on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or
CodeBLEU, our metrics are reference-free, language-agnostic, and
execution-independent. We benchmark several leading LLMs on standard code
generation tasks, demonstrating that AST-driven structural entropy reveals
nuances in model consistency and robustness. The method runs in O(n,d) time
with no external tests, providing a lightweight addition to the code-generation
evaluation toolkit.

</details>


### [13] [Preguss: It Analyzes, It Specifies, It Verifies](https://arxiv.org/abs/2508.14532)
*Zhongyi Wang,Tengjie Lin,Mingshuai Chen,Mingqi Yang,Haokun Li,Xiao Yi,Shengchao Qin,Jianwei Yin*

Main category: cs.SE

TL;DR: Preguss是一个模块化框架，结合静态分析和演绎验证，通过RTE引导的验证单元构建和LLM辅助的规范合成，实现大规模程序的形式化规范自动生成和精化。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在形式化验证中由于上下文长度限制和复杂过程间规范推断困难导致的扩展性问题，提高大规模软件硬件系统验证的自动化程度。

Method: 采用模块化细粒度框架，结合两个组件：(1)基于潜在运行时错误的验证单元构建和优先级排序；(2)在单元级别使用LLM辅助合成过程间规范。

Result: 提出了Preguss框架，为大规模程序自动化验证提供了一条有前景的技术路径。

Conclusion: Preguss通过静态分析与演绎验证的协同作用，为解决大规模系统形式化验证的自动化挑战提供了有效的解决方案。

Abstract: Fully automated verification of large-scale software and hardware systems is
arguably the holy grail of formal methods. Large language models (LLMs) have
recently demonstrated their potential for enhancing the degree of automation in
formal verification by, e.g., generating formal specifications as essential to
deductive verification, yet exhibit poor scalability due to context-length
limitations and, more importantly, the difficulty of inferring complex,
interprocedural specifications. This paper outlines Preguss - a modular,
fine-grained framework for automating the generation and refinement of formal
specifications. Preguss synergizes between static analysis and deductive
verification by orchestrating two components: (i) potential runtime error
(RTE)-guided construction and prioritization of verification units, and (ii)
LLM-aided synthesis of interprocedural specifications at the unit level. We
envisage that Preguss paves a compelling path towards the automated
verification of large-scale programs.

</details>


### [14] [Static Analysis as a Feedback Loop: Enhancing LLM-Generated Code Beyond Correctness](https://arxiv.org/abs/2508.14419)
*Scott Blyth,Sherlock A. Licorish,Christoph Treude,Markus Wagner*

Main category: cs.SE

TL;DR: 大语言模型在代码生成中虽然功能正确性高，但忽视了代码质量的其他维度。本文通过迭代静态分析提示算法，使得GPT-4o在安全性、可读性和可靠性方面都得到显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前的代码生成测试基准主要关注功能正确性，而忽略了代码质量的其他重要维度，如安全性、可靠性、可读性和可维护性。需要系统性地评估LLM在多维度代码质量上的能力。

Method: 使用PythonSecurityEval基准进行评估，提出了一种迭代静态分析驱动的提示算法，利用Bandit和Pylint工具来识别和解决代码质量问题。

Result: 在十次迭代后，GPT-4o显示出显著改善：安全问题从>40%降至13%，可读性违规从>80%降至11%，可靠性警告从>50%降至11%。

Conclusion: 研究证明，在静态分析反馈的指导下，大语言模型能够在功能正确性之外显著提升代码质量。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
code generation, achieving high scores on benchmarks such as HumanEval and
MBPP. However, these benchmarks primarily assess functional correctness and
neglect broader dimensions of code quality, including security, reliability,
readability, and maintainability. In this work, we systematically evaluate the
ability of LLMs to generate high-quality code across multiple dimensions using
the PythonSecurityEval benchmark. We introduce an iterative static
analysis-driven prompting algorithm that leverages Bandit and Pylint to
identify and resolve code quality issues. Our experiments with GPT-4o show
substantial improvements: security issues reduced from >40% to 13%, readability
violations from >80% to 11%, and reliability warnings from >50% to 11% within
ten iterations. These results demonstrate that LLMs, when guided by static
analysis feedback, can significantly enhance code quality beyond functional
correctness.

</details>


### [15] [Design and Evaluation of a Scalable Data Pipeline for AI-Driven Air Quality Monitoring in Low-Resource Settings](https://arxiv.org/abs/2508.14451)
*Richard Sserujongi,Daniel Ogenrwot,Nicholas Niwamanya,Noah Nsimbe,Martin Bbaale,Benjamin Ssempala,Noble Mutabazi,Raja Fidel Wabinyai,Deo Okure,Engineer Bainomugisha*

Main category: cs.SE

TL;DR: 本文提出了AirQo数据管道，一个模块化的云原生ETL系统，用于在非洲资源受限地区处理异构空气质量数据，支持实时和批处理，集成了低成本传感器、天气API和参考级监测器。


<details>
  <summary>Details</summary>
Motivation: 低成本环境传感器和AI应用的日益普及，特别是在数据稀缺和资源受限地区，对可扩展和弹性的数据基础设施提出了更高需求。

Method: 使用Apache Airflow、Apache Kafka和Google BigQuery等开源技术构建模块化ETL系统，包含工作流编排、解耦的摄入层、机器学习驱动的传感器校准和可观测性框架。

Result: 系统每月能够摄入、转换和分发来自400多个监测设备的数百万个空气质量测量值，在受限的电力和连接条件下实现低延迟、高吞吐量和强大的数据可用性。

Conclusion: 通过开源平台和部署经验文档，这项工作为在低资源环境中通过数据工程推进环境智能的类似倡议提供了可重用的蓝图。

Abstract: The increasing adoption of low-cost environmental sensors and AI-enabled
applications has accelerated the demand for scalable and resilient data
infrastructures, particularly in data-scarce and resource-constrained regions.
This paper presents the design, implementation, and evaluation of the AirQo
data pipeline: a modular, cloud-native Extract-Transform-Load (ETL) system
engineered to support both real-time and batch processing of heterogeneous air
quality data across urban deployments in Africa. It is Built using open-source
technologies such as Apache Airflow, Apache Kafka, and Google BigQuery. The
pipeline integrates diverse data streams from low-cost sensors, third-party
weather APIs, and reference-grade monitors to enable automated calibration,
forecasting, and accessible analytics. We demonstrate the pipeline's ability to
ingest, transform, and distribute millions of air quality measurements monthly
from over 400 monitoring devices while achieving low latency, high throughput,
and robust data availability, even under constrained power and connectivity
conditions. The paper details key architectural features, including workflow
orchestration, decoupled ingestion layers, machine learning-driven sensor
calibration, and observability frameworks. Performance is evaluated across
operational metrics such as resource utilization, ingestion throughput,
calibration accuracy, and data availability, offering practical insights into
building sustainable environmental data platforms. By open-sourcing the
platform and documenting deployment experiences, this work contributes a
reusable blueprint for similar initiatives seeking to advance environmental
intelligence through data engineering in low-resource settings.

</details>


### [16] [What You See Is What It Does: A Structural Pattern for Legible Software](https://arxiv.org/abs/2508.14511)
*Eagon Meng,Daniel Jackson*

Main category: cs.SE

TL;DR: 论文提出了一种新的软件结构模式，通过概念和同步机制来提升代码可读性和模块化，以解决LLM编程时代软件缺乏直接代码-行为对应关系的问题。


<details>
  <summary>Details</summary>
Motivation: 当前软件往往缺乏可读性（代码与观察行为之间缺乏直接对应）和模块化不足，无法满足增量开发、完整性和透明性这三个健壮编程的关键要求，特别是在LLM编程时代需要重新评估软件结构。

Method: 提出基于概念和同步的结构模式：完全独立的服务和基于事件的规则来协调它们。使用领域特定语言表达同步行为，使行为特征能够以细粒度和声明式方式表达（便于LLM生成）。通过RealWorld基准案例进行研究验证。

Result: 新结构模式提供了改进的可读性和模块化，使行为特征能够以细粒度和声明式方式表达，便于LLM生成代码。

Conclusion: 该研究为解决LLM编程时代软件结构问题提供了有效的解决方案，通过概念和同步机制实现了更好的代码可读性、模块化和LLM友好性。

Abstract: The opportunities offered by LLM coders (and their current limitations)
demand a reevaluation of how software is structured. Software today is often
"illegible" - lacking a direct correspondence between code and observed
behavior - and insufficiently modular, leading to a failure of three key
requirements of robust coding: incrementality (the ability to deliver small
increments by making localized changes), integrity (avoiding breaking prior
increments) and transparency (making clear what has changed at build time, and
what actions have happened at runtime).
  A new structural pattern offers improved legibility and modularity. Its
elements are concepts and synchronizations: fully independent services and
event-based rules that mediate between them. A domain-specific language for
synchronizations allows behavioral features to be expressed in a granular and
declarative way (and thus readily generated by an LLM). A case study of the
RealWorld benchmark is used to illustrate and evaluate the approach.

</details>


### [17] [Post-hoc LLM-Supported Debugging of Distributed Processes](https://arxiv.org/abs/2508.14540)
*Dennis Schiese,Andreas Both*

Main category: cs.SE

TL;DR: 提出了一种利用生成式AI和系统过程数据自动生成自然语言解释的方法，以简化复杂分布式系统的调试过程


<details>
  <summary>Details</summary>
Motivation: 传统手动调试方法在日益复杂的分布式系统中变得资源密集且效率低下，需要更智能的自动化调试解决方案

Method: 利用系统过程数据、接口信息和文档，结合生成式AI技术，生成自然语言解释来指导开发者理解系统行为和潜在错误

Result: 开发了一个基于组件化Java系统的演示器，证明了该方法的可行性，该方法具有语言无关性，可作为开源Web应用使用

Conclusion: 该方法能够为开发者提供对系统过程的深入理解，即使开发者不熟悉系统的所有细节，显著提高了调试效率

Abstract: In this paper, we address the problem of manual debugging, which nowadays
remains resource-intensive and in some parts archaic. This problem is
especially evident in increasingly complex and distributed software systems.
Therefore, our objective of this work is to introduce an approach that can
possibly be applied to any system, at both the macro- and micro-level, to ease
this debugging process. This approach utilizes a system's process data, in
conjunction with generative AI, to generate natural-language explanations.
These explanations are generated from the actual process data, interface
information, and documentation to guide the developers more efficiently to
understand the behavior and possible errors of a process and its sub-processes.
Here, we present a demonstrator that employs this approach on a component-based
Java system. However, our approach is language-agnostic. Ideally, the generated
explanations will provide a good understanding of the process, even if
developers are not familiar with all the details of the considered system. Our
demonstrator is provided as an open-source web application that is freely
accessible to all users.

</details>


### [18] [Towards LLM-generated explanations for Component-based Knowledge Graph Question Answering Systems](https://arxiv.org/abs/2508.14553)
*Dennis Schiese,Aleksandr Perevalov,Andreas Both*

Main category: cs.SE

TL;DR: 本文提出使用大型语言模型自动生成基于RDF和SPARQL的问答系统组件行为解释，相比模板方法获得更高质量的用户评价。


<details>
  <summary>Details</summary>
Motivation: 问答系统中的AI组件决策过程难以解释，即使专家也难以理解执行过程和结果，需要提高系统的可解释性。

Method: 利用组件的输入(SPARQL查询)和输出(RDF三元组)数据流作为解释源，通过模板基线方法和不同配置的大型语言模型自动生成解释。

Result: LLM生成的解释在用户评分中达到高质量，大多优于模板方法，能够自动解释QA组件的行为和决策。

Conclusion: 使用大型语言模型结合RDF和SPARQL上下文可以有效地自动生成问答系统组件的可解释性说明，提升用户对AI决策的理解。

Abstract: Over time, software systems have reached a level of complexity that makes it
difficult for their developers and users to explain particular decisions made
by them. In this paper, we focus on the explainability of component-based
systems for Question Answering (QA). These components often conduct processes
driven by AI methods, in which behavior and decisions cannot be clearly
explained or justified, s.t., even for QA experts interpreting the executed
process and its results is hard. To address this challenge, we present an
approach that considers the components' input and output data flows as a source
for representing the behavior and provide explanations for the components,
enabling users to comprehend what happened. In the QA framework used here, the
data flows of the components are represented as SPARQL queries (inputs) and RDF
triples (outputs). Hence, we are also providing valuable insights on
verbalization regarding these data types. In our experiments, the approach
generates explanations while following template-based settings (baseline) or
via the use of Large Language Models (LLMs) with different configurations
(automatic generation). Our evaluation shows that the explanations generated
via LLMs achieve high quality and mostly outperform template-based approaches
according to the users' ratings. Therefore, it enables us to automatically
explain the behavior and decisions of QA components to humans while using RDF
and SPARQL as a context for explanations.

</details>


### [19] [Towards a DSL to Formalize Multimodal Requirements](https://arxiv.org/abs/2508.14631)
*Marcos Gomez-Vazquez,Jordi Cabot*

Main category: cs.SE

TL;DR: MERLAN是一个用于指定多模态界面需求的领域特定语言(DSL)，包含元模型、文本语法和原型工具，可自动生成基于代理框架的合规系统实现。


<details>
  <summary>Details</summary>
Motivation: 多模态系统日益普及，但缺乏专门的语言和方法来定义涉及多种输入类型(文本、音频、图像等)的需求，存在AI增强系统无法满足用户需求的风险。

Method: 开发MERLAN DSL，包括定义元模型、实现ANTLR语法文本语法，并提供原型工具让需求工程师编写需求并自动生成基于代理框架的系统实现。

Result: 提出了完整的MERLAN DSL框架，包含语言规范、语法实现和工具支持，能够有效支持多模态界面需求的规格说明。

Conclusion: MERLAN为解决多模态系统需求工程挑战提供了专门的语言和工具支持，有助于确保AI增强系统更好地满足用户需求。

Abstract: Multimodal systems, which process multiple input types such as text, audio,
and images, are becoming increasingly prevalent in software systems, enabled by
the huge advancements in Machine Learning. This triggers the need to easily
define the requirements linked to these new types of user interactions,
potentially involving more than one modality at the same time. This remains an
open challenge due to the lack of languages and methods adapted to the diverse
nature of multimodal interactions, with the risk of implementing AI-enhanced
systems that do not properly satisfy the user needs.
  In this sense, this paper presents MERLAN, a Domain-Specific Language (DSL)
to specify the requirements for these new types of multimodal interfaces. We
present the metamodel for such language together with a textual syntax
implemented as an ANTLR grammar. A prototype tool enabling requirements
engineers to write such requirements and automatically generate a possible
implementation of a system compliant with them on top of an agentic framework
is also provided.

</details>


### [20] [Assessing the Quality and Security of AI-Generated Code: A Quantitative Analysis](https://arxiv.org/abs/2508.14727)
*Abbas Sabra,Olivier Schmitt,Joseph Tyler*

Main category: cs.SE

TL;DR: 对5个主流大语言模型生成的Java代码进行静态分析，发现虽然功能正常但存在多种缺陷，包括严重安全漏洞，且功能测试通过率与代码质量无直接关联。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM生成代码的功能性能，但缺乏对其代码质量和安全性的系统性评估，需要验证LLM生成代码是否真正具备生产就绪的质量标准。

Method: 使用SonarQube对4,442个Java编程作业生成的代码进行全面的静态分析，评估5个主流LLM（Claude Sonnet 4、Claude 3.7 Sonnet、GPT-4o、Llama 3.2 90B和OpenCoder 8B）的代码质量。

Result: 所有评估的LLM都存在软件缺陷，包括bug、安全漏洞和代码异味，特别是硬编码密码和路径遍历等严重安全问题。功能测试通过率与代码质量无直接相关性。

Conclusion: LLM生成的代码需要经过验证才能用于生产环境，静态分析是检测潜在缺陷的重要工具，功能基准测试分数不能很好地反映整体代码质量和安全性。

Abstract: This study presents a quantitative evaluation of the code quality and
security of five prominent Large Language Models (LLMs): Claude Sonnet 4,
Claude 3.7 Sonnet, GPT-4o, Llama 3.2 90B, and OpenCoder 8B. While prior
research has assessed the functional performance of LLM-generated code, this
research tested LLM output from 4,442 Java coding assignments through
comprehensive static analysis using SonarQube. The findings suggest that
although LLMs can generate functional code, they also introduce a range of
software defects, including bugs, security vulnerabilities, and code smells.
These defects do not appear to be isolated; rather, they may represent shared
weaknesses stemming from systemic limitations within current LLM code
generation methods. In particular, critically severe issues, such as hard-coded
passwords and path traversal vulnerabilities, were observed across multiple
models. These results indicate that LLM-generated code requires verification in
order to be considered production-ready. This study found no direct correlation
between a model's functional performance (measured by Pass@1 rate of unit
tests) and the overall quality and security of its generated code, measured by
the number of SonarQube issues in benchmark solutions that passed the
functional tests. This suggests that functional benchmark performance score is
not a good indicator of overall code quality and security. The goal of this
study is not to rank LLM performance but to highlight that all evaluated models
appear to share certain weaknesses. Consequently, these findings support the
view that static analysis can be a valuable instrument for detecting latent
defects and an important safeguard for organizations that deploy AI in software
development.

</details>


### [21] [Challenges of Virtual Validation and Verification for Automotive Functions](https://arxiv.org/abs/2508.14747)
*Beatriz Cabrero-Daniel,Mazen Mohamad*

Main category: cs.SE

TL;DR: 本研究通过专家研讨会和调查识别了车辆验证验证中的17个关键挑战及解决方案，发现许多问题已有已知解法，但资源不足成为实施的主要障碍。


<details>
  <summary>Details</summary>
Motivation: 车辆验证验证是确保安全的关键过程，但实现真实有用的模拟面临重大挑战，需要系统性地识别和解决这些障碍。

Method: 通过组织领域专家研讨会进行头脑风暴识别关键挑战，随后分发调查问卷以整合发现并深入了解潜在解决方案。

Result: 专家们识别出17个关键挑战及相应解决方案，发现资源不足是实施解决方案的主要障碍，许多问题已有已知解法但尚未系统应用。

Conclusion: 研究揭示了车辆验证验证领域的现状，许多挑战已有解决方案但需要更多资源支持实施，应将重点转向未解决的挑战并与更广泛社区分享下一步工作。

Abstract: Verification and validation of vehicles is a complex yet critical process,
particularly for ensuring safety and coverage through simulations. However,
achieving realistic and useful simulations comes with significant challenges.
To explore these challenges, we conducted a workshop with experts in the field,
allowing them to brainstorm key obstacles. Following this, we distributed a
survey to consolidate findings and gain further insights into potential
solutions. The experts identified 17 key challenges, along with proposed
solutions, an assessment of whether they represent next steps for research, and
the roadblocks to their implementation. While a lack of resources was not
initially highlighted as a major challenge, utilizing more resources emerged as
a critical necessity when experts discussed solutions. Interestingly, we
expected some of these challenges to have already been addressed or to have
systematic solutions readily available, given the collective expertise in the
field. Many of the identified problems already have known solutions, allowing
us to shift focus towards unresolved challenges and share the next steps with
the broader community.

</details>
