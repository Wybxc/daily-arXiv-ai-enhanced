<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 4]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Complexity of Abduction in Łukasiewicz Logic](https://arxiv.org/abs/2507.13847)
*Katsumi Inoue,Daniil Kozhemiachenko*

Main category: cs.LO

TL;DR: 论文探讨了在涉及模糊逻辑的上下文中解释观察结果的问题，使用无限值Łukasiewicz模糊逻辑，并分析了其复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究模糊逻辑中的解释问题，特别是在Łukasiewicz逻辑中，如何形式化和解决这类问题。

Method: 定义和分析了Łukasiewicz逻辑中的溯因问题，并研究了其复杂性，包括完整语言和仅含析取子句的情况。

Result: 发现在析取子句片段中溯因的复杂性低于一般情况，与经典命题逻辑不同。

Conclusion: Łukasiewicz逻辑中的溯因问题在析取子句片段中具有较低的复杂性，为模糊逻辑的应用提供了理论支持。

Abstract: We explore the problem of explaining observations in contexts involving
statements with truth degrees such as `the lift is loaded', `the symptoms are
severe', etc. To formalise these contexts, we consider infinitely-valued
{\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction
problems and explanations in the language of {\L}ukasiewicz logic expanded with
`interval literals' of the form $p\geq\mathbf{c}$, $p\leq\mathbf{c}$, and their
negations that express the set of values a variable can have. We analyse the
complexity of standard abductive reasoning tasks (solution recognition,
solution existence, and relevance / necessity of hypotheses) in {\L}ukasiewicz
logic for the case of the full language and for the case of theories containing
only disjunctive clauses and show that in contrast to classical propositional
logic, the abduction in the clausal fragment has lower complexity than in the
general case.

</details>


### [2] [Application Placement with Constraint Relaxation](https://arxiv.org/abs/2507.13895)
*Damiano Azzolini,Marco Duca,Stefano Forti,Francesco Gallo,Antonio Ielo*

Main category: cs.LO

TL;DR: 本文提出了一种基于答案集编程（ASP）的方法，用于解决云边网络中服务放置的组合优化问题，能够处理不可满足的问题实例和偏好需求。


<details>
  <summary>Details</summary>
Motivation: 现有的解决方案难以处理不可满足的问题实例和偏好需求（即可放宽的要求），因此需要一种更灵活的方法。

Method: 利用答案集编程（ASP）的优化能力来解决服务放置问题。

Result: 在模拟环境中，该方法在真实网络和应用程序中表现出有效性。

Conclusion: ASP方法为解决云边网络中的服务放置问题提供了一种有效的解决方案，尤其适用于处理复杂约束和偏好需求。

Abstract: Novel utility computing paradigms rely upon the deployment of multi-service
applications to pervasive and highly distributed cloud-edge infrastructure
resources. Deciding onto which computational nodes to place services in
cloud-edge networks, as per their functional and non-functional constraints,
can be formulated as a combinatorial optimisation problem. Most existing
solutions in this space are not able to deal with \emph{unsatisfiable} problem
instances, nor preferences, i.e. requirements that DevOps may agree to relax to
obtain a solution. In this article, we exploit Answer Set Programming
optimisation capabilities to tackle this problem. Experimental results in
simulated settings show that our approach is effective on lifelike networks and
applications.

</details>


### [3] [Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity](https://arxiv.org/abs/2507.13946)
*Tadeusz Litak,Katsuhiko Sano*

Main category: cs.LO

TL;DR: 命题探究逻辑是其$n$-有界逼近的极限，但在谓词逻辑中不成立。作者引入无切割标记序列演算，探讨了模式有效性的复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究谓词探究逻辑中$n$-有界逼近的极限问题，并开发相应的演算系统。

Method: 引入无切割标记序列演算，分析模式有效性在系统中的表现。

Result: Casari公式在弱子逻辑中原子有效，但在模式有效性下不成立，而在有限有界假设下成立。

Conclusion: 特定规则未被使用时，演算中的推导保证模式有效性。

Abstract: Propositional inquisitive logic is the limit of its $n$-bounded
approximations. In the predicate setting, however, this does not hold anymore,
as discovered by Ciardelli and Grilletti, who also found complete
axiomatizations of $n$-bounded inquisitive logics $\mathsf{InqBQ}_{n}$, for
every fixed $n$. We introduce cut-free labelled sequent calculi for these
logics. We illustrate the intricacies of \textit{schematic validity} in such
systems by showing that the well-known Casari formula is \textit{atomically}
valid in (a weak sublogic of) predicate inquisitive logic $\mathsf{InqBQ}$,
fails to be schematically valid in it, and yet is schematically valid under the
finite boundedness assumption. The derivations in our calculi, however, are
guaranteed to be schematically valid whenever a single specific rule is not
used.

</details>


### [4] [ChemLog: Making MSOL Viable for Ontological Classification and Learning](https://arxiv.org/abs/2507.13987)
*Simon Flügel,Martin Glauer,Till Mossakowski,Fabian Neuhaus*

Main category: cs.LO

TL;DR: 论文提出了一种使用单子二阶逻辑形式化进行本体分类的方法，并以化学本体ChEBI中的肽类为例验证了其有效性。结合深度学习模型，该方法显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: OWL在许多领域中不足以定义本体类，因此需要更强大的形式化方法。

Method: 采用单子二阶逻辑形式化方法，应用于ChEBI中的14个肽类，并结合深度学习模型进行扩展分类。

Result: 逻辑方法有效分类指定类，而深度学习模型进一步扩展分类范围并显著提升性能。

Conclusion: 结合逻辑形式化和深度学习的方法，能够显著提升本体分类的性能和扩展性。

Abstract: Despite its prevalence, in many domains, OWL is not expressive enough to
define ontology classes. In this paper, we present an approach that allows to
use monadic second-order formalisations for ontology classification. As a case
study, we have applied our approach to 14 peptide-related classes from the
chemistry ontology ChEBI. For these classes, a monadic second-order logic
formalisation has been developed and applied both to ChEBI as well as to 119
million molecules from the chemistry database PubChem. While this logical
approach alone is limited to classification for the specified classes (in our
case, (sub)classes of peptides), transformer deep learning models scale
classification to the whole of the ChEBI ontology. We show that when using the
classifications obtained by the logical approach as training data, the
performance of the deep learning models can be significantly enhanced.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Random Variate Generation with Formal Guarantees](https://arxiv.org/abs/2507.13494)
*Feras A. Saad,Wonyeol Lee*

Main category: cs.PL

TL;DR: 提出一种基于有限精度数值程序定义CDF的随机变量生成方法，确保精确生成且不溢出。


<details>
  <summary>Details</summary>
Motivation: 解决传统随机变量生成方法在精度、效率和自动化方面的不足。

Method: 通过数值CDF合成精确随机变量生成器，支持多种二进制格式，避免高精度计算。

Result: 在C语言库中实现，相比GNU科学库，具有更高精度和熵效率。

Conclusion: 该方法在精度、效率和自动化方面优于现有技术。

Abstract: This article introduces a new approach to principled and practical random
variate generation with formal guarantees. The key idea is to first specify the
desired probability distribution in terms of a finite-precision numerical
program that defines its cumulative distribution function (CDF), and then
generate exact random variates according to this CDF. We present a universal
and fully automated method to synthesize exact random variate generators given
any numerical CDF implemented in any binary number format, such as
floating-point, fixed-point, and posits. The method is guaranteed to operate
with the same precision used to specify the CDF, does not overflow, avoids
expensive arbitrary-precision arithmetic, and exposes a consistent API. The
method rests on a novel space-time optimal implementation for the class of
generators that attain the information-theoretically optimal Knuth and Yao
entropy rate, consuming the least possible number of input random bits per
output variate. We develop a random variate generation library using our method
in C and evaluate it on a diverse set of ``continuous'' and ``discrete''
distributions, showing competitive runtime with the state-of-the-art GNU
Scientific Library while delivering higher accuracy, entropy efficiency, and
automation.

</details>


### [6] [Increasing the Expressiveness of a Gradual Verifier](https://arxiv.org/abs/2507.13533)
*Priyam Gupta*

Main category: cs.PL

TL;DR: 本文扩展了Gradual C0的规范语言，支持展开表达式，以更直观地描述递归堆数据结构。


<details>
  <summary>Details</summary>
Motivation: 静态验证虽然能提供强正确性保证，但完全规范程序的过程复杂且繁琐。逐步验证旨在简化这一过程，但现有工具Gradual C0的表达能力有限。

Method: 设计并实现了对Gradual C0的扩展，支持展开表达式。

Result: 扩展后的Gradual C0能够更直观地验证递归堆数据结构的程序。

Conclusion: 通过支持展开表达式，提高了逐步验证工具的实用性和表达能力。

Abstract: Static verification provides strong correctness guarantees for code; however,
fully specifying programs for static verification is a complex, burdensome
process for users. Gradual verification was introduced to make this process
easier by supporting the verification of partially specified programs. The only
currently working gradual verifier, Gradual C0, successfully verifies heap
manipulating programs, but lacks expressiveness in its specification language.
This paper describes the design and implementation of an extension to Gradual
C0 that supports unfolding expressions, which allow more intuitive
specifications of recursive heap data structures.

</details>


### [7] [AdapTT: Functoriality for Dependent Type Casts](https://arxiv.org/abs/2507.13774)
*Arthur Adjedj,Meven Lennon-Bertrand,Thibaut Benjamin,Kenji Maillard*

Main category: cs.PL

TL;DR: AdapTT是一种类型理论，通过抽象适配器关系系统地研究类型构造器的函子性，并推导出通用归纳类型构造器的类型转换结构规律。


<details>
  <summary>Details</summary>
Motivation: 研究相关类型间值转换的共性行为，特别是类型构造器的函子性。

Method: 提出AdapTT类型理论，利用抽象适配器关系描述函子性类型构造器，并推导通用归纳类型的转换规律。

Result: 成功建立了基于适配器的类型转换结构规律，适用于通用归纳类型构造器。

Conclusion: AdapTT为类型转换提供了一种系统化的理论基础，扩展了类型理论的应用范围。

Abstract: The ability to cast values between related types is a leitmotiv of many
flavors of dependent type theory, such as observational type theories,
subtyping, or cast calculi for gradual typing. These casts all exhibit a common
structural behavior that boils down to the pervasive functoriality of type
formers. We propose and extensively study a type theory, called AdapTT, which
makes systematic and precise this idea of functorial type formers, with respect
to an abstract notion of adapters relating types. Leveraging descriptions for
functorial inductive types in AdapTT, we derive structural laws for type casts
on general inductive type formers.

</details>


### [8] [Don't exhaust, don't waste](https://arxiv.org/abs/2507.13792)
*Riccardo Bianchini,Francesco Dagnino,Paola Giannini,Elena Zucca*

Main category: cs.PL

TL;DR: 扩展了带常见构造的lambda演算的语义和类型系统，使其具备资源感知能力，确保资源不被耗尽或浪费。


<details>
  <summary>Details</summary>
Motivation: 为程序提供资源使用保障，避免资源耗尽或浪费。

Method: 基于任意等级代数参数化扩展语义，采用大步语义形式化，并利用共归纳推理技术证明资源感知的健全性。

Result: 类型系统保证良好类型程序存在无资源耗尽或浪费的计算路径。

Conclusion: 通过共归纳推理成功实现了资源感知的语义和类型系统扩展。

Abstract: We extend the semantics and type system of a lambda calculus equipped with
common constructs to be resource-aware. That is, the semantics keep tracks of
the usage of resources, and is stuck, besides in case of type errors, if either
a needed resource is exhausted, or a provided resource would be wasted. In such
way, the type system guarantees, besides standard soundness, that for
well-typed programs there is a computation where no resource gets either
exhausted or wasted.
  The no-waste extension is parametric on an arbitrary grade algebra, modeling
an arbitrary assortment of possible usages, and does not require ad-hoc changes
to the underlying language. To this end, the semantics needs to be formalized
in big-step style; as a consequence, expressing and proving (resource-aware)
soundness is challenging, and is achieved by applying recent techniques based
on coinductive reasoning.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [9] [Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence](https://arxiv.org/abs/2507.13481)
*Arthur Bueno,Bruno Cafeo,Maria Cagnin,Awdren Fontão*

Main category: cs.SE

TL;DR: 研究开源生态系统中代码样本的社会技术退化问题，发现社区问题常导致技术问题。


<details>
  <summary>Details</summary>
Motivation: 代码样本在开源生态中很重要，但管理松散，易受社会技术退化影响。

Method: 采用多声文献综述，分析30篇学术论文和17篇实践导向资料。

Result: 识别出9种模式，显示社区问题常先于或加剧技术退化。

Conclusion: 开源生态中，社区问题与代码样本的可维护性退化相关，需轻量级治理机制。

Abstract: Code samples play a pivotal role in open-source ecosystems (OSSECO), serving
as lightweight artifacts that support knowledge transfer, onboarding, and
framework adoption. Despite their instructional relevance, these samples are
often governed informally, with minimal review and unclear ownership, which
increases their exposure to socio-technical degradation. In this context, the
co-occurrence and longitudinal interplay of code smells (e.g., large classes,
poor modularity) and community smells (e.g., lone contributors, fragmented
communication) become particularly critical. While each type of smell has been
studied in isolation, little is known about how community-level dysfunctions
anticipate or exacerbate technical anomalies in code samples over time. This
study investigates how code and community smells emerge, co-occur, and evolve
within code samples maintained in OSSECOs. A Multivocal Literature Review
protocol was applied, encompassing 30 peer-reviewed papers and 17
practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to
identify recurring socio-technical patterns related to smell dynamics. Nine
patterns were identified, showing that community smells often precede or
reinforce technical degradation in code samples. Symptoms such as "radio
silence" and centralized ownership were frequently associated with persistent
structural anomalies. Additionally, limited onboarding, the absence of
continuous refactoring, and informal collaboration emerged as recurring
conditions for smell accumulation. Conclusion: In OSSECOs, particularly within
code samples, community-level dysfunctions not only correlate with but often
signal maintainability decay. These findings underscore the need for
socio-technical quality indicators and lightweight governance mechanisms
tailored to shared instructional artifacts.

</details>


### [10] [AI-Assisted Fixes to Code Review Comments at Scale](https://arxiv.org/abs/2507.13499)
*Chandra Maddila,Negar Ghorbani,James Saindon,Parth Thakkar,Vijayaraghavan Murali,Rui Abreu,Jingyue Shen,Brian Zhou,Nachiappan Nagappan,Peter C. Rigby*

Main category: cs.SE

TL;DR: Meta开发了MetaMateCR工具，通过AI辅助修复代码审查意见，并在生产环境中大规模应用。通过微调Llama模型，其性能优于GPT-4o，但需通过安全试验优化用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决Meta每周数万条代码审查意见的处理问题，提高效率。

Method: 使用64k数据点微调Llama模型，并进行离线测试、安全试验和生产实验。

Result: LargeLSFT模型离线准确率68%，优于GPT-4o 9个百分点；生产中ActionableToApplied率19.7%，提升9.2个百分点。

Conclusion: MetaMateCR成功展示了AI辅助工具在大规模应用中的潜力，同时强调了安全试验的重要性。

Abstract: Aim. There are 10s of thousands of code review comments each week at Meta. We
developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes
for reviewer comments in production at scale.
  Method. We developed an internal benchmark of 64k <review comment, patch>
data points to fine-tune Llama models. Once our models achieve reasonable
offline results, we roll them into production. To ensure that our AI-assisted
fixes do not negatively impact the time it takes to do code reviews, we conduct
randomized controlled safety trials as well as full production experiments.
  Offline Results. As a baseline, we compare GPT-4o to our small and large
Llama models. In offline results, our LargeLSFT model creates an exact match
patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The
internal models also use more modern Hack functions when compared to the PHP
functions suggested by GPT-4o.
  Safety Trial. When we roll MetaMateCR into production in a safety trial that
compares no AI patches with AI patch suggestions, we see a large regression
with reviewers taking over 5% longer to conduct reviews. After investigation,
we modify the UX to only show authors the AI patches, and see no regressions in
the time for reviews.
  Production. When we roll LargeLSFT into production, we see an
ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.
Our results illustrate the importance of safety trials in ensuring that AI does
not inadvertently slow down engineers, and a successful review comment to AI
patch product running at scale.

</details>


### [11] [Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software](https://arxiv.org/abs/2507.13553)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 研究探讨了开源软件中功能请求的模糊性和不完整性，以及开发者如何处理这些问题。


<details>
  <summary>Details</summary>
Motivation: 功能请求常因自然语言表达不清或信息不全导致误解或实现错误，影响软件质量。

Method: 通过分析开源软件平台上的功能请求和开发者澄清对话，研究模糊性和不完整性的表现及处理方式。

Result: 发现功能请求普遍存在模糊性和不完整性，开发者更关注项目目标而非文本澄清，澄清时侧重用户意图和可行性。

Conclusion: 研究揭示了功能请求处理中的模式，有助于改善用户与开发者协作，优化功能请求处理实践。

Abstract: As user demands evolve, effectively incorporating feature requests is crucial
for maintaining software relevance and user satisfaction. Feature requests,
typically expressed in natural language, often suffer from ambiguity or
incomplete information due to communication gaps or the requester's limited
technical expertise. These issues can lead to misinterpretation, faulty
implementation, and reduced software quality. While seeking clarification from
requesters is a common strategy to mitigate these risks, little is known about
how developers engage in this clarification process in practice-how they
formulate clarifying questions, seek technical or contextual details, align on
goals and use cases, or decide to close requests without attempting
clarification. This study investigates how feature requests are prone to NL
defects (i.e. ambiguous or incomplete) and the conversational dynamics of
clarification in open-source software (OSS) development, aiming to understand
how developers handle ambiguous or incomplete feature requests. Our findings
suggest that feature requests published on the OSS platforms do possess
ambiguity and incompleteness, and in some cases, both. We also find that
explicit clarification for the resolution of these defects is uncommon;
developers usually focus on aligning with project goals rather than resolving
unclear text. When clarification occurs, it emphasizes understanding user
intent/goal and feasibility, rather than technical details. By characterizing
the dynamics of clarification in open-source issue trackers, this work
identifies patterns that can improve user-developer collaboration and inform
best practices for handling feature requests effectively.

</details>


### [12] [Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software](https://arxiv.org/abs/2507.13555)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 论文提出了一种利用大型语言模型（LLMs）自动检测和优化自然语言（NL）缺陷的方法，以改进开源软件（OSS）中的功能请求。


<details>
  <summary>Details</summary>
Motivation: 随着软件应用的普及，功能请求常因自然语言的模糊性和不完整性而难以解读，传统验证方法在分散环境中不实用。

Method: 利用LLMs自动识别模糊和不完整的请求，并生成澄清问题（CQs）。

Result: 方法在真实OSS功能请求上评估，性能与人工标注对比，并通过开发者访谈验证效果。

Conclusion: 该方法能有效提升功能请求的清晰度，对下游软件工程任务有积极影响。

Abstract: The growing popularity and widespread use of software applications (apps)
across various domains have driven rapid industry growth. Along with this
growth, fast-paced market changes have led to constantly evolving software
requirements. Such requirements are often grounded in feature requests and
enhancement suggestions, typically provided by users in natural language (NL).
However, these requests often suffer from defects such as ambiguity and
incompleteness, making them challenging to interpret. Traditional validation
methods (e.g., interviews and workshops) help clarify such defects but are
impractical in decentralized environments like open-source software (OSS),
where change requests originate from diverse users on platforms like GitHub.
This paper proposes a novel approach leveraging Large Language Models (LLMs) to
detect and refine NL defects in feature requests. Our approach automates the
identification of ambiguous and incomplete requests and generates clarification
questions (CQs) to enhance their usefulness for developers. To evaluate its
effectiveness, we apply our method to real-world OSS feature requests and
compare its performance against human annotations. In addition, we conduct
interviews with GitHub developers to gain deeper insights into their
perceptions of NL defects, the strategies they use to address these defects,
and the impact of defects on downstream software engineering (SE) tasks.

</details>


### [13] [Testing Autonomous Driving Systems -- What Really Matters and What Doesn't](https://arxiv.org/abs/2507.13661)
*Changwen Li,Joseph Sifakis,Rongjie Yan,Jian Zhang*

Main category: cs.SE

TL;DR: 本文探讨了自动驾驶系统（ADS）测试方法的有效性和有效性，指出当前方法存在不足，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的测试方法缺乏统一标准，无法有效评估其性能和贡献，亟需改进。

Method: 提出一个比较测试方法的框架，分析其有效性和有效性，并研究测试结果与自动驾驶设计的关系。

Result: 发现多数测试方法未能满足有效性和有效性要求，且测试结果高度依赖于自动驾驶的设计原则。

Conclusion: 建议自动驾驶开发需注重理性和确定性，以提升测试方法的有效性和有效性。

Abstract: Despite extensive research, the testing of autonomous driving systems (ADS)
landscape remains fragmented, and there is currently no basis for an informed
technical assessment of the importance and contribution of the current state of
the art. This paper attempts to address this problem by exploring two
complementary aspects.
  First, it proposes a framework for comparing existing test methods in terms
of their intrinsic effectiveness and validity. It shows that many methods do
not meet both of these requirements. Either because they are based on criteria
that do not allow for rapid, inexpensive, and comprehensive detection of
failures, or because the degree of validity of the properties tested cannot be
accurately estimated. In particular, it is shown that most critical test
methods do not take into account the nominal operational capabilities of
autopilots and generate scenarios that are impossible for the tested vehicles
to handle, resulting in unjustified rejections.
  Secondly, the paper shows that test effectiveness and validity are highly
dependent on how autopilots are designed: how they choose between different
control policies to perform maneuvers, as well as on the reproducibility of the
results. In fact, most test methods take for granted two principles underlying
traditional methods, but do not generally apply to ADS. We maintain that the
absence of rationality and determinacy significantly impairs the effectiveness
and validity of test methods, and provide test results on eight open
autopilots, in which most do not satisfy these properties, thereby illustrating
this fact.
  We conclude that under the current state of the art, it is impossible to
obtain strong enough guarantees for essential autopilot properties and
recommend that autopilots be developed with a view to both rationality and
determinacy.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [14] [Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications](https://arxiv.org/abs/2507.14082)
*Nelma Moreira,Luca Prigioniero*

Main category: cs.FL

TL;DR: NCMA 2025是第十五届非经典自动机模型与应用国际研讨会，旨在促进非经典与经典自动机模型的研究与应用。


<details>
  <summary>Details</summary>
Motivation: 促进非经典与经典自动机模型的理论与应用研究，通过跨学科交流推动新见解和实质性进展。

Method: 通过年度研讨会形式，汇集研究人员分享和讨论非经典自动机模型及相关设备的研究成果。

Result: 研讨会为研究者提供了交流平台，推动了该领域的深入研究和应用发展。

Conclusion: NCMA系列研讨会通过持续的学术交流，为非经典自动机模型的研究和应用提供了重要支持。

Abstract: The Fifteenth International Workshop on Non-Classical Models of Automata and
Applications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,
organized by the Department of Computer Science at Loughborough University and
co-located with the 26th International Conference on Descriptional Complexity
of Formal Systems (DCFS 2025, 22-24 July).
  The NCMA workshop series was established in 2009 as an annual event for
researchers working on non-classical and classical models of automata, grammars
or related devices. Such models are investigated both as theoretical models and
as formal models for applications from various points of view. The goal of the
NCMA workshop series is to exchange and develop novel ideas in order to gain
deeper and interdisciplinary coverage of this particular area that may foster
new insights and substantial progress.

</details>
