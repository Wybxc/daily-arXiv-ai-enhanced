<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 6]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement](https://arxiv.org/abs/2508.10059)
*Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: FormalGrad通过将形式化方法融入LLM的迭代生成循环，显著提升了代码的正确性、鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码常缺乏正确性、鲁棒性和效率的保证，尤其在严格约束的领域。

Method: 将代码视为可微分变量，利用形式化约束生成文本伪梯度，指导模型迭代优化代码。

Result: 在HumanEval和LiveCodeBench基准测试中表现优异，绝对提升达27%，相对提升41%。

Conclusion: FormalGrad为高风险应用中的AI辅助软件开发提供了可靠解决方案。

Abstract: While Large Language Models (LLMs) have demonstrated remarkable capabilities
in code generation, they often produce solutions that lack guarantees of
correctness, robustness, and efficiency. The limitation is acute in domains
requiring strict constraints. FormalGrad introduces a principled framework that
integrates formal methods directly into an iterative LLM-based generation loop.
It uniquely treats code as a differentiable variable, converting structured
feedback and formal constraints into a textual pseudo-gradient. This gradient
guides the model to iteratively refine solutions, ensuring they are not only
functional but also robust and formally justified. We evaluate FormalGrad on
the HumanEval, HumanEval+, and LiveCodeBench benchmarks. Our implementation
outperforms strong baselines, achieving an absolute improvement of up to 27% on
HumanEval and a 41% relative improvement on the challenging LiveCodeBench V6.
FormalGrad generates formally justified code that is robust and efficient,
paving the way for reliable AI-assisted software development in high-stakes
applications.

</details>


### [2] [SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion](https://arxiv.org/abs/2508.10068)
*Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen*

Main category: cs.SE

TL;DR: Saracoder通过分层特征优化和外部感知标识符消解，显著提升了代码补全的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本相似性的检索增强生成方法存在语义误导、冗余和同质化问题，且无法解决外部符号歧义。

Method: 提出Saracoder框架，包括分层特征优化模块（语义关系蒸馏、重复修剪、基于图的结构相似性评估）和外部感知标识符消解模块。

Result: 在CrossCodeEval和RepoEval-Updated基准测试中，Saracoder显著优于现有基线。

Conclusion: 系统化多维度优化检索结果为构建更准确、鲁棒的代码补全系统提供了新范式。

Abstract: Retrieval-augmented generation (RAG) for repository-level code completion
commonly relies on superficial text similarity, leading to results plagued by
semantic misguidance, redundancy, and homogeneity, while also failing to
resolve external symbol ambiguity. To address these challenges, we introduce
Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core
Hierarchical Feature Optimization module systematically refines candidates by
distilling deep semantic relationships, pruning exact duplicates, assessing
structural similarity with a novel graph-based metric that weighs edits by
their topological importance, and reranking results to maximize both relevance
and diversity. Furthermore, an External-Aware Identifier Disambiguator module
accurately resolves cross-file symbol ambiguity via dependency analysis.
Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated
benchmarks demonstrate that Saracoder significantly outperforms existing
baselines across multiple programming languages and models. Our work proves
that systematically refining retrieval results across multiple dimensions
provides a new paradigm for building more accurate and robust repository-level
code completion systems.

</details>


### [3] [Next Edit Prediction: Learning to Predict Code Edits from Context and Interaction History](https://arxiv.org/abs/2508.10074)
*Ruofan Lu,Yintong Huo,Meng Zhang,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文提出了一种名为“Next Edit Prediction”的新任务，旨在通过开发者最近的交互历史预测其下一步编辑的位置和内容，以提升代码编辑体验。


<details>
  <summary>Details</summary>
Motivation: 当前AI代码助手存在两种模式：低延迟代码补全和基于聊天的编辑，但均无法主动预测开发者的一系列相关编辑，导致用户体验不佳。

Method: 研究团队构建了一个高质量的有监督微调数据集和评估基准，并对一系列模型进行了微调和全面评估。

Result: 实验结果表明，微调后的模型在预测开发者下一步编辑方面表现优于基线模型。

Conclusion: 该研究为一种新的交互模式奠定了基础，能够通过预测开发者行为主动协作，而非仅响应显式指令。

Abstract: The rapid advancement of large language models (LLMs) has led to the
widespread adoption of AI-powered coding assistants integrated into a
development environment. On one hand, low-latency code completion offers
completion suggestions but is fundamentally constrained to the cursor's current
position. On the other hand, chat-based editing can perform complex
modifications, yet forces developers to stop their work, describe the intent in
natural language, which causes a context-switch away from the code. This
creates a suboptimal user experience, as neither paradigm proactively predicts
the developer's next edit in a sequence of related edits. To bridge this gap
and provide the seamless code edit suggestion, we introduce the task of Next
Edit Prediction, a novel task designed to infer developer intent from recent
interaction history to predict both the location and content of the subsequent
edit. Specifically, we curate a high-quality supervised fine-tuning dataset and
an evaluation benchmark for the Next Edit Prediction task. Then, we conduct
supervised fine-tuning on a series of models and performed a comprehensive
evaluation of both the fine-tuned models and other baseline models, yielding
several novel findings. This work lays the foundation for a new interaction
paradigm that proactively collaborate with developers by anticipating their
following action, rather than merely reacting to explicit instructions.

</details>


### [4] [On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository](https://arxiv.org/abs/2508.10157)
*Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 预训练语言模型（PTLM）的开发涉及GitHub和Hugging Face两个平台，但两者间的协调问题导致版本不一致和功能孤立。研究发现存在八种同步模式，揭示了当前跨平台发布实践中的结构性脱节。


<details>
  <summary>Details</summary>
Motivation: 探讨GitHub和Hugging Face在PTLM开发中的协调问题，以解决版本不一致和功能孤立等挑战。

Method: 对325个PTLM家族（904个Hugging Face变体）进行混合方法研究，分析提交活动的协调方式。

Result: 发现八种同步模式，部分同步模式（如分散同步和稀疏同步）揭示了跨平台发布实践中的结构性脱节。

Conclusion: 识别这些同步模式对改进PTLM发布流程的监督和可追溯性至关重要。

Abstract: Pretrained language models (PTLMs) have advanced natural language processing
(NLP), enabling progress in tasks like text generation and translation. Like
software package management, PTLMs are trained using code and environment
scripts in upstream repositories (e.g., GitHub, GH) and distributed as variants
via downstream platforms like Hugging Face (HF). Coordinating development
between GH and HF poses challenges such as misaligned release timelines,
inconsistent versioning, and limited reuse of PTLM variants. We conducted a
mixed-method study of 325 PTLM families (904 HF variants) to examine how commit
activities are coordinated. Our analysis reveals that GH contributors typically
make changes related to specifying the version of the model, improving code
quality, performance optimization, and dependency management within the
training scripts, while HF contributors make changes related to improving model
descriptions, data set handling, and setup required for model inference.
Furthermore, to understand the synchronization aspects of commit activities
between GH and HF, we examined three dimensions of these activities -- lag
(delay), type of synchronization, and intensity -- which together yielded eight
distinct synchronization patterns. The prevalence of partially synchronized
patterns, such as Disperse synchronization and Sparse synchronization, reveals
structural disconnects in current cross-platform release practices. These
patterns often result in isolated changes -- where improvements or fixes made
on one platform are never replicated on the other -- and in some cases,
indicate an abandonment of one repository in favor of the other. Such
fragmentation risks exposing end users to incomplete, outdated, or behaviorally
inconsistent models. Hence, recognizing these synchronization patterns is
critical for improving oversight and traceability in PTLM release workflows.

</details>


### [5] [Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution](https://arxiv.org/abs/2508.10517)
*Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren*

Main category: cs.SE

TL;DR: 论文研究了Solidity版本升级中的编译错误问题，提出了一种结合专家知识检索和LLM的修复框架SMCFIXER，显著提升了修复准确率。


<details>
  <summary>Details</summary>
Motivation: Solidity频繁版本更新带来编译错误和维护挑战，需研究如何有效解决这些问题。

Method: 通过实证研究分析编译错误，评估LLM修复能力，并提出SMCFIXER框架，结合专家知识检索和LLM修复机制。

Result: SMCFIXER在真实数据集上比GPT-4o提升24.24%，准确率达96.97%。

Conclusion: SMCFIXER框架显著提升了Solidity编译错误的修复效果，强调了领域知识在LLM修复系统中的重要性。

Abstract: Solidity, the dominant smart contract language for Ethereum, has rapidly
evolved with frequent version updates to enhance security, functionality, and
developer experience. However, these continual changes introduce significant
challenges, particularly in compilation errors, code migration, and
maintenance. Therefore, we conduct an empirical study to investigate the
challenges in the Solidity version evolution and reveal that 81.68% of examined
contracts encounter errors when compiled across different versions, with 86.92%
of compilation errors.
  To mitigate these challenges, we conducted a systematic evaluation of large
language models (LLMs) for resolving Solidity compilation errors during version
migrations. Our empirical analysis across both open-source (LLaMA3, DeepSeek)
and closed-source (GPT-4o, GPT-3.5-turbo) LLMs reveals that although these
models exhibit error repair capabilities, their effectiveness diminishes
significantly for semantic-level issues and shows strong dependency on prompt
engineering strategies. This underscores the critical need for domain-specific
adaptation in developing reliable LLM-based repair systems for smart contracts.
  Building upon these insights, we introduce SMCFIXER, a novel framework that
systematically integrates expert knowledge retrieval with LLM-based repair
mechanisms for Solidity compilation error resolution. The architecture
comprises three core phases: (1) context-aware code slicing that extracts
relevant error information; (2) expert knowledge retrieval from official
documentation; and (3) iterative patch generation for Solidity migration.
Experimental validation across Solidity version migrations demonstrates our
approach's statistically significant 24.24% improvement over baseline GPT-4o on
real-world datasets, achieving near-perfect 96.97% accuracy.

</details>


### [6] [EVOSCAT: Exploring Software Change Dynamics in Large-Scale Historical Datasets](https://arxiv.org/abs/2508.10852)
*Souhaila Serbout,Diana Carolina Muñoz Hurtado,Hassan Atwi,Edoardo Riggio,Cesare Pautasso*

Main category: cs.SE

TL;DR: EvoScat是一个用于可视化大规模软件历史数据的工具，通过交互式密度散点图提供全局视图，支持灵活配置以分析数百万事件。


<details>
  <summary>Details</summary>
Motivation: 长期软件项目包含大量不断修订的工件，研究软件演化的研究人员需要处理数百万事件的数据集，EvoScat旨在提供一种可扩展的全局可视化方法。

Method: EvoScat使用交互式密度散点图，支持时间轴缩放、对齐、工件排序和交互式颜色映射，适用于多种分析需求（如变更速度比较、克隆检测、新鲜度评估）。

Result: 工具能够分析来自数万软件工件的数百万事件，并通过案例展示了其在OpenAPI描述和GitHub工作流定义等数据集中的应用。

Conclusion: EvoScat为研究人员提供了一种高效、灵活的可视化工具，帮助探索和比较软件演化数据集。

Abstract: Long lived software projects encompass a large number of artifacts, which
undergo many revisions throughout their history. Empirical software engineering
researchers studying software evolution gather and collect datasets with
millions of events, representing changes introduced to specific artifacts. In
this paper, we propose EvoScat, a tool that attempts addressing temporal
scalability through the usage of interactive density scatterplot to provide a
global overview of large historical datasets mined from open source
repositories in a single visualization. EvoScat intents to provide researchers
with a mean to produce scalable visualizations that can help them explore and
characterize evolution datasets, as well as comparing the histories of
individual artifacts, both in terms of 1) observing how rapidly different
artifacts age over multiple-year-long time spans 2) how often metrics
associated with each artifacts tend towards an improvement or worsening. The
paper shows how the tool can be tailored to specific analysis needs (pace of
change comparison, clone detection, freshness assessment) thanks to its support
for flexible configuration of history scaling and alignment along the time
axis, artifacts sorting and interactive color mapping, enabling the analysis of
millions of events obtained by mining the histories of tens of thousands of
software artifacts. We include in this paper a gallery showcasing datasets
gathering specific artifacts (OpenAPI descriptions, GitHub workflow
definitions) across multiple repositories, as well as diving into the history
of specific popular open source projects.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Generating Compilers for Qubit Mapping and Routing](https://arxiv.org/abs/2508.10781)
*Abtin Molavi,Amanda Xu,Ethan Cecchetti,Swamit Tannu,Aws Albarghouthi*

Main category: cs.PL

TL;DR: 提出了一种自动生成量子比特映射和路由编译器的方法，适用于任意量子架构，简化未来量子编译器的开发。


<details>
  <summary>Details</summary>
Motivation: 量子计算机潜力巨大，但需要优化编译器以减少资源使用和错误率。量子比特映射和路由（QMR）是关键步骤，但现有方法针对不同架构和约束条件，缺乏通用解决方案。

Method: 通过识别QMR问题的共同核心结构（设备状态机），提出抽象QMR问题，并设计领域特定语言Marol。使用参数化求解器解决Marol定义的QMR问题。

Result: 生成的编译器在运行时和解决方案质量上与手工编写的专用编译器相当，适用于多种硬件平台和架构。

Conclusion: 该方法为未来量子编译器的开发提供了通用且高效的解决方案，适应不断演进的量子架构。

Abstract: Quantum computers promise to solve important problems faster than classical
computers, potentially unlocking breakthroughs in materials science, chemistry,
and beyond. Optimizing compilers are key to realizing this potential, as they
minimize expensive resource usage and limit error rates. A critical compilation
step is qubit mapping and routing (QMR), which finds mappings from circuit
qubits to qubits on a target device and plans instruction execution while
satisfying the device's connectivity constraints. The challenge is that the
landscape of quantum architectures is incredibly diverse and fast-evolving.
Given this diversity, hundreds of papers have addressed the QMR problem for
different qubit hardware, connectivity constraints, and quantum error
correction schemes.
  We present an approach for automatically generating qubit mapping and routing
compilers for arbitrary quantum architectures. Though each QMR problem is
different, we identify a common core structure-device state machine-that we use
to formulate an abstract QMR problem. Our formulation naturally leads to a
domain-specific language, Marol, for specifying QMR problems-for example, the
well-studied NISQ mapping and routing problem requires only 12 lines of Marol.
We demonstrate that QMR problems, defined in Marol, can be solved with a
powerful parametric solver that can be instantiated for any Marol program. We
evaluate our approach through case studies of important QMR problems from prior
and recent work, covering noisy and fault-tolerant quantum architectures on all
major hardware platforms. Our thorough evaluation shows that generated
compilers are competitive with handwritten, specialized compilers in terms of
runtime and solution quality. We envision that our approach will simplify
development of future quantum compilers as new quantum architectures continue
to emerge.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [8] [Active Automata Learning with Advice](https://arxiv.org/abs/2508.10535)
*Michał Fica,Jan Otop*

Main category: cs.FL

TL;DR: 提出了一种结合主动自动机学习和演绎推理的扩展框架，通过引入建议机制减少查询次数。


<details>
  <summary>Details</summary>
Motivation: 减少查询次数，提高学习效率。

Method: 结合主动学习和演绎推理，利用字符串重写系统提供建议。

Result: 显著降低了查询复杂度。

Conclusion: 该框架在减少查询次数方面表现出色，且易于集成到现有算法中。

Abstract: We present an extended automata learning framework that combines active
automata learning with deductive inference. The learning algorithm asks
membership and equivalence queries as in the original framework, but it is also
given advice, which is used to infer answers to queries when possible and
reduce the burden on the teacher. We consider advice given via string rewriting
systems, which specify equivalence of words w.r.t. the target languages. The
main motivation for the proposed framework is to reduce the number of queries.
We show how to adapt Angluin-style learning algorithms to this framework with
low overhead. Finally, we present empirical evaluation of our approach and
observe substantial improvement in query complexity.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Repairing General Game Descriptions (extended version)](https://arxiv.org/abs/2508.10438)
*Yifan He,Munyque Mittelmann,Aniello Murano,Abdallah Saffidine,Michael Thielscher*

Main category: cs.LO

TL;DR: 论文提出了一种基于自动定理证明和回答集编程的方法，用于修复违反形式要求的GDL描述，并提供了相关计算问题的复杂性分析。


<details>
  <summary>Details</summary>
Motivation: GDL描述的正确性对非专家来说具有挑战性，现有方法只能手动修复错误，因此需要自动化修复工具。

Method: 定义了GDL描述的最小修复问题，提供了复杂性分析，并使用回答集编程编码实现自动修复。

Result: 展示了该方法在修复定义不明确的游戏描述中的实际应用效果。

Conclusion: 该方法为GDL描述的自动化修复提供了可行方案，并扩展了相关理论。

Abstract: The Game Description Language (GDL) is a widely used formalism for specifying
the rules of general games. Writing correct GDL descriptions can be
challenging, especially for non-experts. Automated theorem proving has been
proposed to assist game design by verifying if a GDL description satisfies
desirable logical properties. However, when a description is proved to be
faulty, the repair task itself can only be done manually. Motivated by the work
on repairing unsolvable planning domain descriptions, we define a more general
problem of finding minimal repairs for GDL descriptions that violate formal
requirements, and we provide complexity results for various computational
problems related to minimal repair. Moreover, we present an Answer Set
Programming-based encoding for solving the minimal repair problem and
demonstrate its application for automatically repairing ill-defined game
descriptions.

</details>


### [10] [Modal definability in Euclidean modal logics](https://arxiv.org/abs/2508.10813)
*Philippe Balbiani,Tinko Tinchev*

Main category: cs.LO

TL;DR: 本文研究了欧几里得模态逻辑框架类中模态可定义性问题的可计算性，并确定了导致该问题不可判定的逻辑类别。


<details>
  <summary>Details</summary>
Motivation: 探讨欧几里得模态逻辑框架类中模态可定义性问题的可计算性，填补相关理论空白。

Method: 通过分析欧几里得模态逻辑框架类的性质，确定模态可定义性问题的可计算性条件。

Result: 确定了导致模态可定义性问题不可判定的欧几里得模态逻辑类别。

Conclusion: 研究为欧几里得模态逻辑的可计算性提供了理论支持，并揭示了其局限性。

Abstract: This paper is about the computability of the modal definability problem in
classes of frames determined by Euclidean modal logics. We characterize those
Euclidean modal logics such that the classes of frames they determine give rise
to an undecidable modal definability problem.

</details>
