{"id": "2509.14372", "categories": ["cs.FL", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14372", "abs": "https://arxiv.org/abs/2509.14372", "authors": ["Tom\u00e1\u0161 Masopust", "Jakub Ve\u010de\u0159a"], "title": "On the Complexity of the Secret Protection Problem for Discrete-Event Systems", "comment": null, "summary": "The secret protection problem (SPP) seeks to synthesize a minimum-cost policy\nensuring that every execution from an initial state to a secret state includes\na sufficient number of protected events. Previous work showed that the problem\nis solvable in polynomial time under the assumptions that transitions are\nuniquely labeled and that the clearance level for every event is uniformly set\nto one. When these assumptions are relaxed, the problem was shown to be weakly\nNP-hard, leaving the complexity of the uniform variant open. In this paper, we\nclose this gap by proving that the uniform secret protection problem is\nNP-hard, even if all parameters are restricted to binary values. Moreover, we\nstrengthen the existing results by showing that the general problem becomes\nNP-hard as soon as the uniqueness constraint on event labels is removed. We\nfurther propose a formulation of SPP as an Integer Linear Programming (ILP)\nproblem. Our empirical evaluation demonstrates the scalability and\neffectiveness of the ILP-based approach on relatively large systems. Finally,\nwe examine a variant of SPP in which only distinct protected events contribute\nto clearance and show that its decision version is $\\Sigma_{2}^{P}$-complete.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5747\u5300\u79d8\u5bc6\u4fdd\u62a4\u95ee\u9898\u7684NP\u96be\u6027\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5206\u6790\u4e86\u53d8\u4f53\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "motivation": "\u89e3\u51b3\u5148\u524d\u5de5\u4f5c\u4e2d\u5173\u4e8e\u5747\u5300\u79d8\u5bc6\u4fdd\u62a4\u95ee\u9898\u590d\u6742\u6027\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660eNP\u96be\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212(ILP)\u7684\u6c42\u89e3\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u8bc1\u660e\u4e86\u5747\u5300\u79d8\u5bc6\u4fdd\u62a4\u95ee\u9898\u5373\u4f7f\u5728\u4e8c\u5143\u53c2\u6570\u9650\u5236\u4e0b\u4e5f\u662fNP\u96be\u7684\uff0cILP\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u79d8\u5bc6\u4fdd\u62a4\u95ee\u9898\u5728\u4e00\u822c\u6761\u4ef6\u4e0b\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u4f46ILP\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u53d8\u4f53\u95ee\u9898\u7684\u66f4\u9ad8\u590d\u6742\u6027\u7b49\u7ea7\u3002"}}
{"id": "2509.14694", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2509.14694", "abs": "https://arxiv.org/abs/2509.14694", "authors": ["Kengo Irie", "Masaki Waga", "Kohei Suenaga"], "title": "Active Learning of Symbolic Mealy Automata", "comment": "Accepted to ICTAC 2025", "summary": "We propose $\\Lambda^*_M$-an active learning algorithm that learns symbolic\nMealy automata, which support infinite input alphabets and multiple output\ncharacters. Each of these two features has been addressed separately in prior\nwork. Combining these two features poses a challenge in learning the outputs\ncorresponding to potentially infinite sets of input characters at each state.\nTo address this challenge, we introduce the notion of essential input\ncharacters, a finite set of input characters that is sufficient for learning\nthe output function of a symbolic Mealy automaton. $\\Lambda^*_M$ maintains an\nunderapproximation of the essential input characters and refines this set\nduring learning. We prove that $\\Lambda^*_M$ terminates under certain\nassumptions. Moreover, we provide upper and lower bounds for the query\ncomplexity. Their similarity suggests the tightness of the bounds. We\nempirically demonstrate that $\\Lambda^*_M$ is i) efficient regarding the number\nof queries on practical benchmarks and ii) scalable according to evaluations\nwith randomly generated benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u039b*_M\u7b97\u6cd5\uff0c\u4e00\u79cd\u5b66\u4e60\u652f\u6301\u65e0\u9650\u8f93\u5165\u5b57\u6bcd\u8868\u548c\u591a\u8f93\u51fa\u5b57\u7b26\u7684\u7b26\u53f7Mealy\u81ea\u52a8\u673a\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5fc5\u8981\u8f93\u5165\u5b57\u7b26\u6982\u5ff5\u89e3\u51b3\u8f93\u51fa\u51fd\u6570\u5b66\u4e60\u6311\u6218", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u5de5\u4f5c\u5206\u522b\u89e3\u51b3\u4e86\u65e0\u9650\u8f93\u5165\u5b57\u6bcd\u8868\u548c\u591a\u8f93\u51fa\u5b57\u7b26\u7684\u95ee\u9898\uff0c\u4f46\u5c06\u8fd9\u4e24\u4e2a\u7279\u5f81\u7ed3\u5408\u8d77\u6765\u65f6\uff0c\u5728\u72b6\u6001\u7ea7\u522b\u5b66\u4e60\u8f93\u51fa\u51fd\u6570\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u6f5c\u5728\u7684\u65e0\u9650\u8f93\u5165\u5b57\u7b26\u96c6", "method": "\u5f15\u5165\u5fc5\u8981\u8f93\u5165\u5b57\u7b26\u7684\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u4e2a\u6709\u9650\u7684\u8f93\u5165\u5b57\u7b26\u96c6\uff0c\u8db3\u4ee5\u5b66\u4e60\u7b26\u53f7Mealy\u81ea\u52a8\u673a\u7684\u8f93\u51fa\u51fd\u6570\u3002\u039b*_M\u7b97\u6cd5\u7ef4\u62a4\u5fc5\u8981\u8f93\u5165\u5b57\u7b26\u7684\u4e0b\u8fd1\u4f3c\u5e76\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u4f18\u5316\u8fd9\u4e2a\u96c6\u5408", "result": "\u8bc1\u660e\u4e86\u039b*_M\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\u4f1a\u7ec8\u6b62\uff0c\u63d0\u4f9b\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u4e0a\u4e0b\u754c\uff0c\u5176\u76f8\u4f3c\u6027\u8868\u660e\u754c\u9650\u7684\u7d27\u81f4\u6027\u3002\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u5b9e\u9645\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u67e5\u8be2\u6548\u7387\u9ad8\uff0c\u5728\u968f\u673a\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027", "conclusion": "\u039b*_M\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u5b66\u4e60\u652f\u6301\u65e0\u9650\u8f93\u5165\u5b57\u6bcd\u8868\u548c\u591a\u8f93\u51fa\u5b57\u7b26\u7684\u7b26\u53f7Mealy\u81ea\u52a8\u673a\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5fc5\u8981\u8f93\u5165\u5b57\u7b26\u7684\u6982\u5ff5\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u5b66\u4e60"}}
{"id": "2509.14914", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2509.14914", "abs": "https://arxiv.org/abs/2509.14914", "authors": ["Zolt\u00e1n F\u00fcl\u00f6p", "Heiko Vogler"], "title": "Characterization of deterministically recognizable weighted tree languages over commutative semifields by finitely generated and cancellative scalar algebras", "comment": null, "summary": "Due to the works of S. Bozapalidis and A. Alexandrakis, there is a well-known\ncharacterization of recognizable weighted tree languages over fields in terms\nof finite-dimensionality of syntactic vector spaces. Here we prove a\ncharacterization of bottom-up deterministically recognizable weighted tree\nlanguages over commutative semifields in terms of the requirement that the\nrespective m-syntactic scalar algebras are finitely generated. The concept of\nscalar algebra is introduced in this paper; it is obtained from the concept of\nvector space by disregarding the addition of vectors. Moreover, we prove a\nminimization theorem for bottom-up-deterministic weighted tree automata and we\nconstruct the minimal automaton.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5728\u4ea4\u6362\u534a\u57df\u4e0a\u53ef\u8bc6\u522b\u7684\u52a0\u6743\u6811\u8bed\u8a00\u7684\u8868\u5f81\u5b9a\u7406\uff0c\u901a\u8fc7\u5f15\u5165\u6807\u91cf\u4ee3\u6570\u6982\u5ff5\u5e76\u8bc1\u660em-\u53e5\u6cd5\u6807\u91cf\u4ee3\u6570\u7684\u6709\u9650\u751f\u6210\u6027\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86\u81ea\u5e95\u5411\u4e0a\u786e\u5b9a\u6027\u52a0\u6743\u6811\u81ea\u52a8\u673a\u7684\u6700\u5c0f\u5316\u5b9a\u7406\u548c\u6700\u5c0f\u81ea\u52a8\u673a\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5df2\u5efa\u7acb\u4e86\u5728\u57df\u4e0a\u53ef\u8bc6\u522b\u52a0\u6743\u6811\u8bed\u8a00\u4e0e\u53e5\u6cd5\u5411\u91cf\u7a7a\u95f4\u6709\u9650\u7ef4\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4f46\u7f3a\u4e4f\u5728\u4ea4\u6362\u534a\u57df\u4e0a\u7684\u76f8\u5e94\u7406\u8bba\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u66f4\u4e00\u822c\u7684\u4ee3\u6570\u7ed3\u6784\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f15\u5165\u6807\u91cf\u4ee3\u6570\u6982\u5ff5\uff08\u5ffd\u7565\u5411\u91cf\u52a0\u6cd5\u7684\u5411\u91cf\u7a7a\u95f4\uff09\uff0c\u8bc1\u660e\u81ea\u5e95\u5411\u4e0a\u786e\u5b9a\u6027\u53ef\u8bc6\u522b\u52a0\u6743\u6811\u8bed\u8a00\u7b49\u4ef7\u4e8e\u76f8\u5e94m-\u53e5\u6cd5\u6807\u91cf\u4ee3\u6570\u7684\u6709\u9650\u751f\u6210\u6027\uff0c\u5e76\u5efa\u7acb\u6700\u5c0f\u5316\u5b9a\u7406\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u4ea4\u6362\u534a\u57df\u4e0a\u52a0\u6743\u6811\u8bed\u8a00\u7684\u53ef\u8bc6\u522b\u6027\u8868\u5f81\u5b9a\u7406\uff0c\u8bc1\u660e\u4e86\u6700\u5c0f\u5316\u5b9a\u7406\u7684\u6709\u6548\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u6700\u5c0f\u81ea\u52a8\u673a\u7684\u5177\u4f53\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u52a0\u6743\u6811\u8bed\u8a00\u7406\u8bba\u5230\u4ea4\u6362\u534a\u57df\u60c5\u5f62\uff0c\u63d0\u51fa\u7684\u6807\u91cf\u4ee3\u6570\u6982\u5ff5\u548c\u8868\u5f81\u5b9a\u7406\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2509.15074", "categories": ["cs.FL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.15074", "abs": "https://arxiv.org/abs/2509.15074", "authors": ["Dominik Gei\u00dfler", "Tobias Winkler"], "title": "Weighted Automata for Exact Inference in Discrete Probabilistic Programs", "comment": null, "summary": "In probabilistic programming, the inference problem asks to determine a\nprogram's posterior distribution conditioned on its \"observe\" instructions.\nInference is challenging, especially when exact rather than approximate results\nare required. Inspired by recent work on probability generating functions\n(PGFs), we propose encoding distributions on $\\mathbb{N}^k$ as weighted\nautomata over a commutative alphabet with $k$ symbols. Based on this, we map\nthe semantics of various imperative programming statements to\nautomata-theoretic constructions. For a rich class of programs, this results in\nan effective translation from prior to posterior distribution, both encoded as\nautomata. We prove that our approach is sound with respect to a standard\noperational program semantics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u81ea\u52a8\u673a\u7684\u65b9\u6cd5\u6765\u5904\u7406\u6982\u7387\u7f16\u7a0b\u4e2d\u7684\u7cbe\u786e\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u5206\u5e03\u7f16\u7801\u4e3a\u4ea4\u6362\u5b57\u6bcd\u8868\u4e0a\u7684\u81ea\u52a8\u673a\u6765\u5b9e\u73b0\u4ece\u5148\u9a8c\u5206\u5e03\u5230\u540e\u9a8c\u5206\u5e03\u7684\u6709\u6548\u8f6c\u6362\u3002", "motivation": "\u6982\u7387\u7f16\u7a0b\u4e2d\u7684\u63a8\u7406\u95ee\u9898\u9700\u8981\u786e\u5b9a\u7a0b\u5e8f\u5728\u7ed9\u5b9a\u89c2\u5bdf\u6307\u4ee4\u4e0b\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u7cbe\u786e\u63a8\u7406\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\u3002\u53d7\u6982\u7387\u751f\u6210\u51fd\u6570\u5de5\u4f5c\u7684\u542f\u53d1\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u5c06N^k\u4e0a\u7684\u5206\u5e03\u7f16\u7801\u4e3a\u5177\u6709k\u4e2a\u7b26\u53f7\u7684\u4ea4\u6362\u5b57\u6bcd\u8868\u4e0a\u7684\u52a0\u6743\u81ea\u52a8\u673a\uff0c\u5c06\u5404\u79cd\u547d\u4ee4\u5f0f\u7f16\u7a0b\u8bed\u53e5\u7684\u8bed\u4e49\u6620\u5c04\u5230\u81ea\u52a8\u673a\u7406\u8bba\u6784\u9020\uff0c\u5b9e\u73b0\u4ece\u5148\u9a8c\u5230\u540e\u9a8c\u5206\u5e03\u7684\u6709\u6548\u8f6c\u6362\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u4e30\u5bcc\u7c7b\u522b\u7684\u7a0b\u5e8f\uff0c\u5e76\u5c06\u5206\u5e03\u7f16\u7801\u4e3a\u81ea\u52a8\u673a\u5f62\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u6807\u51c6\u64cd\u4f5c\u7a0b\u5e8f\u8bed\u4e49\u662f\u53ef\u9760\u7684\uff0c\u4e3a\u6982\u7387\u7f16\u7a0b\u4e2d\u7684\u7cbe\u786e\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u673a\u7406\u8bba\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.14265", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14265", "abs": "https://arxiv.org/abs/2509.14265", "authors": ["Siyuan Chen", "Zhichao Lu", "Qingfu Zhang"], "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models", "comment": "Technical report", "summary": "Automated kernel design is critical for overcoming software ecosystem\nbarriers in emerging hardware platforms like RISC-V. While large language\nmodels (LLMs) have shown promise for automated kernel optimization,\ndemonstrating success in CUDA domains with comprehensive technical documents\nand mature codebases, their effectiveness remains unproven for reference-scarce\ndomains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based\nevolutionary program search framework that automates kernel design for domains\nwith limited reference material. EoK mitigates reference scarcity by mining and\nformalizing reusable optimization ideas (general design principles + actionable\nthoughts) from established kernel libraries' development histories; it then\nguides parallel LLM explorations using these ideas, enriched via\nRetrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing\nhistorically effective techniques. Empirically, EoK achieves a median 1.27x\nspeedup, surpassing human experts on all 80 evaluated kernel design tasks and\nimproving upon prior LLM-based automated kernel design methods by 20%. These\nresults underscore the viability of incorporating human experience into\nemerging domains and highlight the immense potential of LLM-based automated\nkernel optimization.", "AI": {"tldr": "EoK\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u8fdb\u5316\u7a0b\u5e8f\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u6210\u719f\u5185\u6838\u5e93\u7684\u5f00\u53d1\u5386\u53f2\u4e2d\u6316\u6398\u53ef\u91cd\u7528\u4f18\u5316\u601d\u60f3\uff0c\u7ed3\u5408RISC-V\u7279\u5b9a\u4e0a\u4e0b\u6587\u7684RAG\u6280\u672f\uff0c\u5728\u53c2\u8003\u6750\u6599\u7a00\u7f3a\u7684RISC-V\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u5185\u6838\u8bbe\u8ba1\uff0c\u6027\u80fd\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u548c\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5728\u53c2\u8003\u6750\u6599\u7a00\u7f3a\u7684\u65b0\u5174\u786c\u4ef6\u5e73\u53f0\uff08\u5982RISC-V\uff09\u4e0a\u81ea\u52a8\u5316\u5185\u6838\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u4f20\u7edfLLM\u65b9\u6cd5\u5728CUDA\u7b49\u6210\u719f\u9886\u57df\u6709\u6548\uff0c\u4f46\u5728RISC-V\u7b49\u7f3a\u4e4f\u53c2\u8003\u7684\u9886\u57df\u6548\u679c\u672a\u7ecf\u9a8c\u8bc1\u3002", "method": "\u63d0\u51faEoK\u6846\u67b6\uff1a1\uff09\u4ece\u6210\u719f\u5185\u6838\u5e93\u5f00\u53d1\u5386\u53f2\u4e2d\u6316\u6398\u53ef\u91cd\u7528\u4f18\u5316\u601d\u60f3\uff08\u901a\u7528\u8bbe\u8ba1\u539f\u5219+\u53ef\u64cd\u4f5c\u601d\u8def\uff09\uff1b2\uff09\u4f7f\u7528RAG\u6280\u672f\u589e\u5f3aRISC-V\u7279\u5b9a\u4e0a\u4e0b\u6587\uff1b3\uff09\u57fa\u4e8e\u5386\u53f2\u6709\u6548\u6280\u672f\u6307\u5bfc\u5e76\u884cLLM\u63a2\u7d22\u7684\u8fdb\u5316\u7a0b\u5e8f\u641c\u7d22\u3002", "result": "\u572880\u4e2a\u5185\u6838\u8bbe\u8ba1\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0cEoK\u5b9e\u73b0\u4e86\u4e2d\u4f4d\u65701.27\u500d\u52a0\u901f\uff0c\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u90fd\u8d85\u8d8a\u4e86\u4eba\u7c7b\u4e13\u5bb6\uff0c\u6bd4\u4e4b\u524d\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5185\u6838\u8bbe\u8ba1\u65b9\u6cd5\u63d0\u5347\u4e8620%\u3002", "conclusion": "EoK\u8bc1\u660e\u4e86\u5c06\u4eba\u7c7b\u7ecf\u9a8c\u878d\u5165\u65b0\u5174\u9886\u57df\u7684\u53ef\u884c\u6027\uff0c\u51f8\u663e\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5185\u6838\u4f18\u5316\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u53c2\u8003\u6750\u6599\u7a00\u7f3a\u7684\u786c\u4ef6\u5e73\u53f0\u4e0a\u3002"}}
{"id": "2509.14496", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.14496", "abs": "https://arxiv.org/abs/2509.14496", "authors": ["Wyatt Petula", "Anushcka Joshi", "Peggy Tu", "Amrutha Somasundar", "Suman Saha"], "title": "DeliverC: Teaching Pointers through GenAI-Powered Game-Based Learning", "comment": "The paper before Camera-ready paper. The paper has been accepted by\n  SIGCSE 2026", "summary": "While game-based learning is widely used in programming education, few tools\noffer adaptive, real-time support for complex topics, such as C pointers. We\npresent DeliverC, a GenAI-enhanced game that integrates GPT-4-mini to provide\npersonalized hints and generate pointer-related challenges on the fly. In a\npilot study involving 25 undergraduate students, we investigated the impact of\nthe system on learning through gameplay data and a 15-item survey that covered\nconstructs such as motivation, self-efficacy, metacognition, and feedback\nquality. Results show that most students felt more confident and reflective\nafter using the tool, and error rates decreased as students progressed through\nscaffolded levels. However, participation decreased with task difficulty, and\nsome students reported receiving unclear or vague feedback. These findings\nsuggest that DeliverC can enhance engagement and understanding in systems\nprogramming, although refinement in AI-generated feedback is still needed. Our\nstudy highlights the potential of combining GenAI with game-based learning to\nsupport personalized and interactive practice in traditionally challenging\nprogramming domains.", "AI": {"tldr": "DeliverC\u662f\u4e00\u4e2a\u96c6\u6210GPT-4-mini\u7684GenAI\u589e\u5f3a\u6e38\u620f\uff0c\u4e3aC\u8bed\u8a00\u6307\u9488\u5b66\u4e60\u63d0\u4f9b\u5b9e\u65f6\u4e2a\u6027\u5316\u63d0\u793a\u548c\u6311\u6218\u751f\u6210\u3002\u8bd5\u70b9\u7814\u7a76\u8868\u660e\u80fd\u63d0\u5347\u5b66\u751f\u81ea\u4fe1\u548c\u53cd\u601d\u80fd\u529b\uff0c\u4f46AI\u53cd\u9988\u8d28\u91cf\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u89e3\u51b3\u7f16\u7a0b\u6559\u80b2\u4e2d\u590d\u6742\u4e3b\u9898\uff08\u5982C\u6307\u9488\uff09\u7f3a\u4e4f\u5b9e\u65f6\u81ea\u9002\u5e94\u652f\u6301\u5de5\u5177\u7684\u95ee\u9898\uff0c\u63a2\u7d22GenAI\u4e0e\u6e38\u620f\u5316\u5b66\u4e60\u7ed3\u5408\u5728\u4f20\u7edf\u6311\u6218\u6027\u7f16\u7a0b\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u5f00\u53d1DeliverC\u6e38\u620f\u7cfb\u7edf\uff0c\u96c6\u6210GPT-4-mini\u63d0\u4f9b\u4e2a\u6027\u5316\u63d0\u793a\u548c\u52a8\u6001\u751f\u6210\u6307\u9488\u76f8\u5173\u6311\u6218\u3002\u901a\u8fc725\u540d\u672c\u79d1\u751f\u7684\u8bd5\u70b9\u7814\u7a76\uff0c\u6536\u96c6\u6e38\u620f\u6570\u636e\u548c15\u9879\u95ee\u5377\u8c03\u67e5\uff08\u6db5\u76d6\u52a8\u673a\u3001\u81ea\u6211\u6548\u80fd\u3001\u5143\u8ba4\u77e5\u548c\u53cd\u9988\u8d28\u91cf\u7b49\u7ef4\u5ea6\uff09\u3002", "result": "\u5927\u591a\u6570\u5b66\u751f\u4f7f\u7528\u540e\u611f\u5230\u66f4\u81ea\u4fe1\u548c\u5584\u4e8e\u53cd\u601d\uff0c\u9519\u8bef\u7387\u968f\u7740\u652f\u67b6\u5f0f\u5173\u5361\u8fdb\u5c55\u800c\u4e0b\u964d\u3002\u4f46\u53c2\u4e0e\u5ea6\u968f\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u800c\u964d\u4f4e\uff0c\u90e8\u5206\u5b66\u751f\u53cd\u9988AI\u751f\u6210\u7684\u63d0\u793a\u4e0d\u591f\u6e05\u6670\u660e\u786e\u3002", "conclusion": "DeliverC\u80fd\u591f\u589e\u5f3a\u7cfb\u7edf\u7f16\u7a0b\u5b66\u4e60\u7684\u53c2\u4e0e\u5ea6\u548c\u7406\u89e3\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdbAI\u751f\u6210\u53cd\u9988\u7684\u8d28\u91cf\u3002\u7814\u7a76\u8bc1\u660e\u4e86GenAI\u4e0e\u6e38\u620f\u5316\u5b66\u4e60\u7ed3\u5408\u5728\u652f\u6301\u4e2a\u6027\u5316\u4ea4\u4e92\u5f0f\u7f16\u7a0b\u5b9e\u8df5\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.14988", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.14988", "abs": "https://arxiv.org/abs/2509.14988", "authors": ["Thorsten Altenkirch", "Ambrus Kaposi", "Szumi Xie"], "title": "The Groupoid-syntax of Type Theory is a Set", "comment": null, "summary": "Categories with families (CwFs) have been used to define the semantics of\ntype theory in type theory. In the setting of Homotopy Type Theory (HoTT), one\nof the limitations of the traditional notion of CwFs is the requirement to\nset-truncate types, which excludes models based on univalent categories, such\nas the standard set model. To address this limitation, we introduce the concept\nof a Groupoid Category with Families (GCwF). This framework truncates types at\nthe groupoid level and incorporates coherence equations, providing a natural\nextension of the CwF framework when starting from a 1-category.\n  We demonstrate that the initial GCwF for a type theory with a base family of\nsets and Pi-types (groupoid-syntax) is set-truncated. Consequently, this allows\nus to utilize the conventional intrinsic syntax of type theory while enabling\ninterpretations in semantically richer and more natural models. All\nconstructions in this paper were formalised in Cubical Agda.", "AI": {"tldr": "\u63d0\u51fa\u4e86Groupoid Category with Families (GCwF)\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7fa4\u80da\u5c42\u9762\u622a\u65ad\u7c7b\u578b\u5e76\u5f15\u5165\u4e00\u81f4\u6027\u65b9\u7a0b\uff0c\u6269\u5c55\u4e86\u4f20\u7edfCwF\u6846\u67b6\uff0c\u89e3\u51b3\u4e86HoTT\u4e2d\u4f20\u7edfCwF\u9700\u8981\u96c6\u5408\u622a\u65ad\u7684\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfCwF\u5728Homotopy Type Theory\u4e2d\u9700\u8981\u96c6\u5408\u622a\u65ad\u7c7b\u578b\uff0c\u8fd9\u6392\u9664\u4e86\u57fa\u4e8e\u5355\u503c\u8303\u7574\u7684\u6a21\u578b\uff08\u5982\u6807\u51c6\u96c6\u5408\u6a21\u578b\uff09\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u6765\u652f\u6301\u66f4\u4e30\u5bcc\u548c\u81ea\u7136\u7684\u8bed\u4e49\u6a21\u578b\u3002", "method": "\u5f15\u5165Groupoid Category with Families (GCwF)\u6982\u5ff5\uff0c\u5728\u7fa4\u80da\u5c42\u9762\u622a\u65ad\u7c7b\u578b\u5e76\u5305\u542b\u4e00\u81f4\u6027\u65b9\u7a0b\uff0c\u4f5c\u4e3a\u4ece1-\u8303\u7574\u51fa\u53d1\u65f6CwF\u6846\u67b6\u7684\u81ea\u7136\u6269\u5c55\u3002", "result": "\u8bc1\u660e\u4e86\u5177\u6709\u57fa\u7840\u96c6\u5408\u65cf\u548cPi\u7c7b\u578b\u7684\u7c7b\u578b\u7406\u8bba\u7684\u521d\u59cbGCwF\u662f\u96c6\u5408\u622a\u65ad\u7684\uff0c\u4ece\u800c\u53ef\u4ee5\u5728\u4fdd\u6301\u4f20\u7edf\u5185\u5728\u8bed\u6cd5\u7684\u540c\u65f6\uff0c\u652f\u6301\u66f4\u4e30\u5bcc\u8bed\u4e49\u6a21\u578b\u7684\u89e3\u91ca\u3002", "conclusion": "GCwF\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edfCwF\uff0c\u5141\u8bb8\u5728\u66f4\u81ea\u7136\u7684\u6a21\u578b\u4e2d\u8fdb\u884c\u7c7b\u578b\u7406\u8bba\u89e3\u91ca\uff0c\u6240\u6709\u6784\u9020\u90fd\u5728Cubical Agda\u4e2d\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002"}}
{"id": "2509.14273", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14273", "abs": "https://arxiv.org/abs/2509.14273", "authors": ["Swapnil Sharma Sarker", "Tanzina Taher Ifty"], "title": "Automated and Context-Aware Code Documentation Leveraging Advanced LLMs", "comment": null, "summary": "Code documentation is essential to improve software maintainability and\ncomprehension. The tedious nature of manual code documentation has led to much\nresearch on automated documentation generation. Existing automated approaches\nprimarily focused on code summarization, leaving a gap in template-based\ndocumentation generation (e.g., Javadoc), particularly with publicly available\nLarge Language Models (LLMs). Furthermore, progress in this area has been\nhindered by the lack of a Javadoc-specific dataset that incorporates modern\nlanguage features, provides broad framework/library coverage, and includes\nnecessary contextual information. This study aims to address these gaps by\ndeveloping a tailored dataset and assessing the capabilities of publicly\navailable LLMs for context-aware, template-based Javadoc generation. In this\nwork, we present a novel, context-aware dataset for Javadoc generation that\nincludes critical structural and semantic information from modern Java\ncodebases. We evaluate five open-source LLMs (including LLaMA-3.1, Gemma-2,\nPhi-3, Mistral, Qwen-2.5) using zero-shot, few-shot, and fine-tuned setups and\nprovide a comparative analysis of their performance. Our results demonstrate\nthat LLaMA 3.1 performs consistently well and is a reliable candidate for\npractical, automated Javadoc generation, offering a viable alternative to\nproprietary systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9488\u5bf9Javadoc\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e94\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0LLaMA 3.1\u5728\u81ea\u52a8\u5316Javadoc\u751f\u6210\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u6587\u6863\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u6458\u8981\uff0c\u7f3a\u4e4f\u9488\u5bf9\u6a21\u677f\u5316\u6587\u6863\uff08\u5982Javadoc\uff09\u7684\u7814\u7a76\uff0c\u7279\u522b\u662f\u4f7f\u7528\u516c\u5f00\u53ef\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u540c\u65f6\uff0c\u7f3a\u4e4f\u5305\u542b\u73b0\u4ee3\u8bed\u8a00\u7279\u6027\u3001\u5e7f\u6cdb\u6846\u67b6/\u5e93\u8986\u76d6\u548c\u5fc5\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684Javadoc\u4e13\u7528\u6570\u636e\u96c6\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u5c55\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u4e0a\u4e0b\u6587\u611f\u77e5Javadoc\u751f\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u73b0\u4ee3Java\u4ee3\u7801\u5e93\u7684\u5173\u952e\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002\u8bc4\u4f30\u4e86\u4e94\u4e2a\u5f00\u6e90LLM\uff08LLaMA-3.1\u3001Gemma-2\u3001Phi-3\u3001Mistral\u3001Qwen-2.5\uff09\u5728\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "result": "LLaMA 3.1\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4e00\u81f4\u826f\u597d\uff0c\u662f\u5b9e\u7528\u81ea\u52a8\u5316Javadoc\u751f\u6210\u7684\u53ef\u9760\u5019\u9009\u6a21\u578b\uff0c\u4e3a\u4e13\u6709\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u6a21\u677f\u5316\u6587\u6863\u751f\u6210\u9886\u57df\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316Javadoc\u751f\u6210\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662fLLaMA 3.1\u6a21\u578b\u7684\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2509.15005", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.15005", "abs": "https://arxiv.org/abs/2509.15005", "authors": ["Facundo Dom\u00ednguez", "Arnaud Spiwack"], "title": "Refinement-Types Driven Development: A study", "comment": "11 pages, 3 figures, artifacts\n  https://github.com/tweag/ifl2025-liquidhaskell", "summary": "This paper advocates for the broader application of SMT solvers in everyday\nprogramming, challenging the conventional wisdom that these tools are solely\nfor formal methods and verification. We claim that SMT solvers, when seamlessly\nintegrated into a compiler's static checks, significantly enhance the\ncapabilities of ordinary type checkers in program composition. Specifically, we\nargue that refinement types, as embodied by Liquid Haskell, enable the use of\nSMT solvers in mundane programming tasks. Through a case study on handling\nbinder scopes in compilers, we envision a future where ordinary programming is\nmade simpler and more enjoyable with the aid of refinement types and SMT\nsolvers. As a secondary contribution, we present a prototype implementation of\na theory of finite maps for Liquid Haskell's solver, developed to support our\ncase study.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06SMT\u6c42\u89e3\u5668\u66f4\u5e7f\u6cdb\u5730\u5e94\u7528\u4e8e\u65e5\u5e38\u7f16\u7a0b\uff0c\u901a\u8fc7\u7cbe\u5316\u7c7b\u578b\uff08\u5982Liquid Haskell\uff09\u5c06SMT\u6c42\u89e3\u5668\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u9759\u6001\u68c0\u67e5\u4e2d\uff0c\u63d0\u5347\u666e\u901a\u7c7b\u578b\u68c0\u67e5\u5668\u7684\u7a0b\u5e8f\u7ec4\u5408\u80fd\u529b\u3002", "motivation": "\u6311\u6218SMT\u6c42\u89e3\u5668\u4ec5\u7528\u4e8e\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u9a8c\u8bc1\u7684\u4f20\u7edf\u89c2\u5ff5\uff0c\u63a2\u7d22\u5176\u5728\u65e5\u5e38\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4f7f\u666e\u901a\u7f16\u7a0b\u66f4\u7b80\u5355\u3001\u66f4\u6109\u5feb\u3002", "method": "\u91c7\u7528\u7cbe\u5316\u7c7b\u578b\uff08Liquid Haskell\u4f53\u73b0\uff09\uff0c\u5c06SMT\u6c42\u89e3\u5668\u65e0\u7f1d\u96c6\u6210\u5230\u7f16\u8bd1\u5668\u9759\u6001\u68c0\u67e5\u4e2d\uff0c\u5e76\u901a\u8fc7\u5904\u7406\u7f16\u8bd1\u5668\u4e2d\u7684\u7ed1\u5b9a\u5668\u4f5c\u7528\u57df\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5c55\u793a\u4e86\u7cbe\u5316\u7c7b\u578b\u548cSMT\u6c42\u89e3\u5668\u5728\u65e5\u5e38\u7f16\u7a0b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5e76\u5f00\u53d1\u4e86Liquid Haskell\u6c42\u89e3\u5668\u7684\u6709\u9650\u6620\u5c04\u7406\u8bba\u539f\u578b\u5b9e\u73b0\u6765\u652f\u6301\u6848\u4f8b\u7814\u7a76\u3002", "conclusion": "\u7cbe\u5316\u7c7b\u578b\u548cSMT\u6c42\u89e3\u5668\u7684\u7ed3\u5408\u4e3a\u65e5\u5e38\u7f16\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u6709\u671b\u6539\u53d8\u7f16\u7a0b\u5b9e\u8df5\uff0c\u4f7f\u666e\u901a\u7f16\u7a0b\u4efb\u52a1\u66f4\u52a0\u7b80\u5355\u548c\u9ad8\u6548\u3002"}}
{"id": "2509.15015", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.15015", "abs": "https://arxiv.org/abs/2509.15015", "authors": ["Harrison Oates", "Hyeonggeun Yun", "Nikhila Gurusinghe"], "title": "Theorem Provers: One Size Fits All?", "comment": null, "summary": "Theorem provers are important tools for people working in formal\nverification. There are a myriad of interactive systems available today, with\nvarying features and approaches motivating their development. These design\nchoices impact their usability, alongside the problem domain in which they are\nemployed. We test-drive two such provers, Coq and Idris2, by proving the\ncorrectness of insertion sort, before providing a qualitative evaluation of\ntheir performance. We then compare their community and library support. This\nwork helps users to make an informed choice of system, and highlight approaches\nin other systems that developers might find useful.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5728\u5b9e\u9645\u6848\u4f8b\uff08\u63d2\u5165\u6392\u5e8f\u6b63\u786e\u6027\u8bc1\u660e\uff09\u4e2d\u6d4b\u8bd5Coq\u548cIdris2\u4e24\u4e2a\u5b9a\u7406\u8bc1\u660e\u5668\uff0c\u5bf9\u5b83\u4eec\u7684\u6027\u80fd\u8fdb\u884c\u5b9a\u6027\u8bc4\u4f30\uff0c\u5e76\u6bd4\u8f83\u793e\u533a\u548c\u5e93\u652f\u6301\uff0c\u5e2e\u52a9\u7528\u6237\u505a\u51fa\u660e\u667a\u9009\u62e9", "motivation": "\u5b9a\u7406\u8bc1\u660e\u5668\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u8bbe\u8ba1\u9009\u62e9\u5404\u5f02\uff0c\u5f71\u54cd\u53ef\u7528\u6027\u548c\u9002\u7528\u9886\u57df\u3002\u9700\u8981\u5b9e\u9645\u6d4b\u8bd5\u6765\u8bc4\u4f30\u4e0d\u540c\u8bc1\u660e\u5668\u7684\u6027\u80fd\u548c\u652f\u6301\u60c5\u51b5", "method": "\u901a\u8fc7\u8bc1\u660e\u63d2\u5165\u6392\u5e8f\u7684\u6b63\u786e\u6027\u6765\u6d4b\u8bd5Coq\u548cIdris2\u4e24\u4e2a\u5b9a\u7406\u8bc1\u660e\u5668\uff0c\u8fdb\u884c\u5b9a\u6027\u6027\u80fd\u8bc4\u4f30\uff0c\u5e76\u6bd4\u8f83\u5b83\u4eec\u7684\u793e\u533a\u548c\u5e93\u652f\u6301", "result": "\u63d0\u4f9b\u4e86\u4e24\u4e2a\u5b9a\u7406\u8bc1\u660e\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u8bc4\u4f30\u7ed3\u679c\uff0c\u4ee5\u53ca\u793e\u533a\u548c\u5e93\u652f\u6301\u7684\u5bf9\u6bd4\u5206\u6790", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5176\u4ed6\u7cfb\u7edf\u4e2d\u53ef\u80fd\u6709\u7528\u7684\u65b9\u6cd5\u53c2\u8003"}}
{"id": "2509.14279", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14279", "abs": "https://arxiv.org/abs/2509.14279", "authors": ["Robert Tjarko Lange", "Qi Sun", "Aaditya Prasad", "Maxence Faldor", "Yujin Tang", "David Ha"], "title": "Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization", "comment": "62 pages, 10 figures", "summary": "Recent advances in large language models (LLMs) demonstrate their\neffectiveness in scaling test-time compute for software engineering tasks.\nHowever, these approaches often focus on high-level solutions, with limited\nattention to optimizing low-level CUDA kernel implementations. Additionally,\nexisting kernel generation benchmarks suffer from exploitable loopholes and\ninsufficient diversity in testing conditions, hindering true generalization\nassessment. To address these limitations, we introduce robust-kbench, a new\nbenchmark for rigorous evaluation of kernel performance and correctness across\nvaried scenarios. Furthermore, we present a comprehensive agentic framework\nthat automates CUDA kernel discovery, verification, and optimization. This\npipeline enables frontier LLMs to translate torch code to CUDA kernels and\niteratively improve their runtime within our robust evaluation setting. Our\nsequential workflow first translates PyTorch code into equivalent CUDA kernels.\nIt then optimizes their runtime using a novel evolutionary meta-generation\nprocedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for\ncorrectness and efficient filtering. Evaluated on robust-kbench, our approach\nproduces CUDA kernels outperforming torch implementations for practical\napplications, including forward and backward passes. It can fuse operations and\ndeploy various runtime optimization strategies. The verifier workflow\naccurately classifies incorrect kernels, enhancing hardware verification\nefficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86robust-kbench\u57fa\u51c6\u6d4b\u8bd5\u548c\u81ea\u52a8\u5316CUDA\u5185\u6838\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5c06PyTorch\u4ee3\u7801\u8f6c\u6362\u4e3aCUDA\u5185\u6838\u5e76\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5728\u6027\u80fd\u548c\u6b63\u786e\u6027\u65b9\u9762\u8d85\u8d8atorch\u5b9e\u73b0", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9ad8\u5c42\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u5bf9\u5e95\u5c42CUDA\u5185\u6838\u4f18\u5316\u5173\u6ce8\u4e0d\u8db3\uff0c\u4e14\u73b0\u6709\u5185\u6838\u751f\u6210\u57fa\u51c6\u5b58\u5728\u53ef\u88ab\u5229\u7528\u7684\u6f0f\u6d1e\u548c\u6d4b\u8bd5\u6761\u4ef6\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u5f00\u53d1robust-kbench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6784\u5efa\u5305\u542b\u7ffb\u8bd1\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u4f7f\u7528\u8fdb\u5316\u5143\u751f\u6210\u8fc7\u7a0b\u4f18\u5316CUDA\u5185\u6838\u8fd0\u884c\u65f6\u6027\u80fd\uff0c\u57fa\u4e8eLLM\u7684\u9a8c\u8bc1\u5668\u786e\u4fdd\u6b63\u786e\u6027", "result": "\u5728robust-kbench\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684CUDA\u5185\u6838\u5728\u5b9e\u7528\u5e94\u7528\u4e2d\u8d85\u8d8atorch\u5b9e\u73b0\uff0c\u80fd\u591f\u878d\u5408\u64cd\u4f5c\u5e76\u90e8\u7f72\u591a\u79cd\u8fd0\u884c\u65f6\u4f18\u5316\u7b56\u7565\uff0c\u9a8c\u8bc1\u5668\u5de5\u4f5c\u6d41\u80fd\u51c6\u786e\u5206\u7c7b\u9519\u8bef\u5185\u6838", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316CUDA\u5185\u6838\u7684\u53d1\u73b0\u548c\u4f18\u5316\u8fc7\u7a0b\uff0c\u5728\u4e25\u683c\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u548c\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4e3aLLM\u5728\u5e95\u5c42\u786c\u4ef6\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2509.14404", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.14404", "abs": "https://arxiv.org/abs/2509.14404", "authors": ["Haoye Tian", "Chong Wang", "BoYang Yang", "Lyuye Zhang", "Yang Liu"], "title": "A Taxonomy of Prompt Defects in LLM Systems", "comment": null, "summary": "Large Language Models (LLMs) have become key components of modern software,\nwith prompts acting as their de-facto programming interface. However, prompt\ndesign remains largely empirical and small mistakes can cascade into\nunreliable, insecure, or inefficient behavior. This paper presents the first\nsystematic survey and taxonomy of prompt defects, recurring ways that prompts\nfail to elicit their intended behavior from LLMs. We organize defects along six\ndimensions: (1) Specification and Intent, (2) Input and Content, (3) Structure\nand Formatting, (4) Context and Memory, (5) Performance and Efficiency, and (6)\nMaintainability and Engineering. Each dimension is refined into fine-grained\nsubtypes, illustrated with concrete examples and root cause analysis. Grounded\nin software engineering principles, we show how these defects surface in real\ndevelopment workflows and examine their downstream effects. For every subtype,\nwe distill mitigation strategies that span emerging prompt engineering\npatterns, automated guardrails, testing harnesses, and evaluation frameworks.\nWe then summarize these strategies in a master taxonomy that links defect,\nimpact, and remedy. We conclude with open research challenges and a call for\nrigorous engineering-oriented methodologies to ensure that LLM-driven systems\nare dependable by design.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u548c\u5206\u7c7b\u4e86\u63d0\u793a\u7f3a\u9677\uff0c\u5c06\u63d0\u793a\u8bbe\u8ba1\u4e2d\u7684\u5e38\u89c1\u95ee\u9898\u5f52\u7eb3\u4e3a\u516d\u4e2a\u7ef4\u5ea6\u7684\u7f3a\u9677\u7c7b\u578b\uff0c\u5e76\u9488\u5bf9\u6bcf\u79cd\u7f3a\u9677\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u7f13\u89e3\u7b56\u7565\u548c\u5de5\u7a0b\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u6210\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u4f46\u63d0\u793a\u8bbe\u8ba1\u4ecd\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\uff0c\u5c0f\u7684\u9519\u8bef\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u9760\u3001\u4e0d\u5b89\u5168\u6216\u4f4e\u6548\u7684\u884c\u4e3a\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5de5\u7a0b\u65b9\u6cd5\u6765\u786e\u4fddLLM\u9a71\u52a8\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u8c03\u67e5\u548c\u5206\u7c7b\u5b66\u65b9\u6cd5\uff0c\u5c06\u63d0\u793a\u7f3a\u9677\u7ec4\u7ec7\u4e3a\u516d\u4e2a\u7ef4\u5ea6\uff08\u89c4\u8303\u4e0e\u610f\u56fe\u3001\u8f93\u5165\u4e0e\u5185\u5bb9\u3001\u7ed3\u6784\u4e0e\u683c\u5f0f\u3001\u4e0a\u4e0b\u6587\u4e0e\u8bb0\u5fc6\u3001\u6027\u80fd\u4e0e\u6548\u7387\u3001\u53ef\u7ef4\u62a4\u6027\u4e0e\u5de5\u7a0b\uff09\uff0c\u6bcf\u4e2a\u7ef4\u5ea6\u7ec6\u5206\u4e3a\u5177\u4f53\u5b50\u7c7b\u578b\uff0c\u5e76\u63d0\u4f9b\u5b9e\u4f8b\u5206\u6790\u548c\u6839\u672c\u539f\u56e0\u5206\u6790\u3002", "result": "\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u63d0\u793a\u7f3a\u9677\u5206\u7c7b\u4f53\u7cfb\uff0c\u4e3a\u6bcf\u79cd\u7f3a\u9677\u7c7b\u578b\u63d0\u70bc\u4e86\u7f13\u89e3\u7b56\u7565\uff0c\u5305\u62ec\u65b0\u5174\u7684\u63d0\u793a\u5de5\u7a0b\u6a21\u5f0f\u3001\u81ea\u52a8\u5316\u9632\u62a4\u673a\u5236\u3001\u6d4b\u8bd5\u6846\u67b6\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u8fde\u63a5\u7f3a\u9677\u3001\u5f71\u54cd\u548c\u8865\u6551\u63aa\u65bd\u7684\u4e3b\u5206\u7c7b\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u9762\u5411\u5de5\u7a0b\u7684\u4e25\u683c\u65b9\u6cd5\u5b66\u9700\u6c42\uff0c\u4ee5\u786e\u4fddLLM\u9a71\u52a8\u7cfb\u7edf\u5728\u8bbe\u8ba1\u4e0a\u5c31\u662f\u53ef\u9760\u7684\uff0c\u5e76\u6307\u51fa\u4e86\u5f00\u653e\u7684\u7814\u7a76\u6311\u6218\u3002"}}
{"id": "2509.15116", "categories": ["cs.LO", "cs.AI", "math.AG"], "pdf": "https://arxiv.org/pdf/2509.15116", "abs": "https://arxiv.org/abs/2509.15116", "authors": ["Arnaud Mayeux", "Jujian Zhang"], "title": "The mechanization of science illustrated by the Lean formalization of the multi-graded Proj construction", "comment": "Short note", "summary": "We formalize the multi-graded Proj construction in Lean4, illustrating\nmechanized mathematics and formalization.", "AI": {"tldr": "\u5728Lean4\u4e2d\u5f62\u5f0f\u5316\u591a\u7ea7\u5206\u6b21Proj\u6784\u9020", "motivation": "\u5c55\u793a\u673a\u68b0\u5316\u6570\u5b66\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u80fd\u529b\uff0c\u4e3a\u4ee3\u6570\u51e0\u4f55\u4e2d\u7684\u591a\u7ea7\u5206\u6b21\u73af\u7406\u8bba\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840", "method": "\u4f7f\u7528Lean4\u5b9a\u7406\u8bc1\u660e\u5668\u5bf9\u591a\u7ea7\u5206\u6b21Proj\u6784\u9020\u8fdb\u884c\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u9a8c\u8bc1", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u7ea7\u5206\u6b21Proj\u6784\u9020\u7684\u5b8c\u6574\u5f62\u5f0f\u5316\uff0c\u9a8c\u8bc1\u4e86\u76f8\u5173\u6570\u5b66\u5b9a\u7406\u7684\u6b63\u786e\u6027", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86Lean4\u5728\u590d\u6742\u4ee3\u6570\u7ed3\u6784\u5f62\u5f0f\u5316\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u540e\u7eed\u4ee3\u6570\u51e0\u4f55\u7684\u5f62\u5f0f\u5316\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.14281", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14281", "abs": "https://arxiv.org/abs/2509.14281", "authors": ["Xifeng Yao", "Dongyu Lang", "Wu Zhang", "Xintong Guo", "Huarui Xie", "Yinhao Ni", "Ping Liu", "Guang Shen", "Yi Bai", "Dandan Tu", "Changzheng Zhang"], "title": "SCoGen: Scenario-Centric Graph-Based Synthesis of Real-World Code Problems", "comment": null, "summary": "Significant advancements have been made in the capabilities of code large\nlanguage models, leading to their rapid adoption and application across a wide\nrange of domains. However, their further advancements are often constrained by\nthe scarcity of real-world coding problems. To bridge this gap, we propose a\nnovel framework for synthesizing code problems that emulate authentic\nreal-world scenarios. This framework systematically integrates domain\nknowledge, domain skills, and coding skills, all of which are meticulously\nextracted from real-world programming-related datasets, including Stack\nOverflow and Kaggle. The extracted elements serve as the foundational building\nblocks for constructing code problems. To align the generated problems with\npractical applications, application scenarios are also mined from the\naforementioned datasets. These scenarios are then utilized to construct a\nscenario-centric graph that interconnects domain knowledge, domain skills, and\ncoding skills. Based on this structured representation, a sampling strategy on\nthe graph is designed, which effectively controls the generation of a code\nproblem with complexity and diversity, reflects real-world challenges.\nExperimental results demonstrate that the proposed method consistently achieves\nsuperior performance over state-of-the-art open-source large language models of\nvarying sizes and functionalities, including both coders and general-purpose\nmodels, across a diverse set of real-world benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u771f\u5b9e\u7f16\u7a0b\u6570\u636e\u4e2d\u5408\u6210\u4ee3\u7801\u95ee\u9898\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u77e5\u8bc6\u3001\u9886\u57df\u6280\u80fd\u548c\u7f16\u7801\u6280\u80fd\u6765\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u7f16\u7a0b\u573a\u666f\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u53d7\u5230\u771f\u5b9e\u4e16\u754c\u7f16\u7a0b\u95ee\u9898\u7a00\u7f3a\u6027\u7684\u9650\u5236\uff0c\u9700\u8981\u6784\u5efa\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u573a\u666f\u7684\u4ee3\u7801\u95ee\u9898\u6765\u4fc3\u8fdb\u6a21\u578b\u8fdb\u6b65\u3002", "method": "\u4eceStack Overflow\u548cKaggle\u7b49\u771f\u5b9e\u7f16\u7a0b\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u9886\u57df\u77e5\u8bc6\u3001\u9886\u57df\u6280\u80fd\u548c\u7f16\u7801\u6280\u80fd\uff0c\u6784\u5efa\u573a\u666f\u4e2d\u5fc3\u56fe\u8fde\u63a5\u8fd9\u4e9b\u5143\u7d20\uff0c\u5e76\u8bbe\u8ba1\u56fe\u91c7\u6837\u7b56\u7565\u6765\u63a7\u5236\u95ee\u9898\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d consistently \u4f18\u4e8e\u4e0d\u540c\u89c4\u6a21\u548c\u529f\u80fd\u7684\u6700\u5148\u8fdb\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u548c\u901a\u7528\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5408\u6210\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u6311\u6218\u7684\u4ee3\u7801\u95ee\u9898\uff0c\u4e3a\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u3002"}}
{"id": "2509.14623", "categories": ["cs.SE", "cs.AI", "cs.PL", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14623", "abs": "https://arxiv.org/abs/2509.14623", "authors": ["Hanlong Wan", "Xing Lu", "Yan Chen", "Karthik Devaprasad", "Laura Hinkle"], "title": "Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language", "comment": "This is the pre-peer-review version of a journal paper; the repo is\n  available at: https://github.com/pnnl/prompt2control", "summary": "Dynamic energy systems and controls require advanced modeling frameworks to\ndesign and test supervisory and fault tolerant strategies. Modelica is a widely\nused equation based language, but developing control modules is labor intensive\nand requires specialized expertise. This paper examines the use of large\nlanguage models (LLMs) to automate the generation of Control Description\nLanguage modules in the Building Modelica Library as a case study. We developed\na structured workflow that combines standardized prompt scaffolds, library\naware grounding, automated compilation with OpenModelica, and human in the loop\nevaluation. Experiments were carried out on four basic logic tasks (And, Or,\nNot, and Switch) and five control modules (chiller enable/disable, bypass valve\ncontrol, cooling tower fan speed, plant requests, and relief damper control).\nThe results showed that GPT 4o failed to produce executable Modelica code in\nzero shot mode, while Claude Sonnet 4 achieved up to full success for basic\nlogic blocks with carefully engineered prompts. For control modules, success\nrates reached 83 percent, and failed outputs required medium level human repair\n(estimated one to eight hours). Retrieval augmented generation often produced\nmismatches in module selection (for example, And retrieved as Or), while a\ndeterministic hard rule search strategy avoided these errors. Human evaluation\nalso outperformed AI evaluation, since current LLMs cannot assess simulation\nresults or validate behavioral correctness. Despite these limitations, the LLM\nassisted workflow reduced the average development time from 10 to 20 hours down\nto 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.\nThese results highlight both the potential and current limitations of LLM\nassisted Modelica generation, and point to future research in pre simulation\nvalidation, stronger grounding, and closed loop evaluation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u81ea\u52a8\u751f\u6210Modelica\u63a7\u5236\u6a21\u5757\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7ed3\u5408\u6807\u51c6\u5316\u63d0\u793a\u3001\u5e93\u611f\u77e5\u63a5\u5730\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u5728\u63a7\u5236\u6a21\u5757\u4e0a\u8fbe\u523083%\u7684\u6210\u529f\u7387\uff0c\u5f00\u53d1\u65f6\u95f4\u51cf\u5c1140-60%\u3002", "motivation": "Modelica\u662f\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u4e8e\u65b9\u7a0b\u7684\u8bed\u8a00\uff0c\u4f46\u5f00\u53d1\u63a7\u5236\u6a21\u5757\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5f00\u53d1\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u6807\u51c6\u5316\u63d0\u793a\u652f\u67b6\u3001\u5e93\u611f\u77e5\u63a5\u5730\u3001OpenModelica\u81ea\u52a8\u7f16\u8bd1\u548c\u4eba\u5de5\u5faa\u73af\u8bc4\u4f30\uff0c\u5728\u57fa\u7840\u903b\u8f91\u4efb\u52a1\u548c\u63a7\u5236\u6a21\u5757\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "GPT 4o\u5728\u96f6\u6837\u672c\u6a21\u5f0f\u4e0b\u65e0\u6cd5\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0cClaude Sonnet 4\u5728\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u4e0b\u5bf9\u57fa\u7840\u903b\u8f91\u5757\u8fbe\u5230\u5b8c\u5168\u6210\u529f\uff0c\u63a7\u5236\u6a21\u5757\u6210\u529f\u7387\u8fbe83%\uff0c\u5f00\u53d1\u65f6\u95f4\u4ece10-20\u5c0f\u65f6\u51cf\u5c11\u52304-6\u5c0f\u65f6\u3002", "conclusion": "LLM\u8f85\u52a9\u5de5\u4f5c\u6d41\u7a0b\u5728Modelica\u751f\u6210\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\u4f46\u4ecd\u6709\u5c40\u9650\uff0c\u672a\u6765\u9700\u8981\u5728\u9884\u6a21\u62df\u9a8c\u8bc1\u3001\u66f4\u5f3a\u63a5\u5730\u548c\u95ed\u73af\u8bc4\u4f30\u65b9\u9762\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.14294", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14294", "abs": "https://arxiv.org/abs/2509.14294", "authors": ["Hira Naveed", "Scott Barnett", "Chetan Arora", "John Grundy", "Hourieh Khalajzadeh", "Omar Haggag"], "title": "Monitoring Machine Learning Systems: A Multivocal Literature Review", "comment": null, "summary": "Context: Dynamic production environments make it challenging to maintain\nreliable machine learning (ML) systems. Runtime issues, such as changes in data\npatterns or operating contexts, that degrade model performance are a common\noccurrence in production settings. Monitoring enables early detection and\nmitigation of these runtime issues, helping maintain users' trust and prevent\nunwanted consequences for organizations. Aim: This study aims to provide a\ncomprehensive overview of the ML monitoring literature. Method: We conducted a\nmultivocal literature review (MLR) following the well established guidelines by\nGarousi to investigate various aspects of ML monitoring approaches in 136\npapers. Results: We analyzed selected studies based on four key areas: (1) the\nmotivations, goals, and context; (2) the monitored aspects, specific\ntechniques, metrics, and tools; (3) the contributions and benefits; and (4) the\ncurrent limitations. We also discuss several insights found in the studies,\ntheir implications, and recommendations for future research and practice.\nConclusion: Our MLR identifies and summarizes ML monitoring practices and gaps,\nemphasizing similarities and disconnects between formal and gray literature.\nOur study is valuable for both academics and practitioners, as it helps select\nappropriate solutions, highlights limitations in current approaches, and\nprovides future directions for research and tool development.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u591a\u6e90\u6587\u732e\u7efc\u8ff0(MLR)\u65b9\u6cd5\uff0c\u5bf9136\u7bc7\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u673a\u5668\u5b66\u4e60\u76d1\u63a7\u9886\u57df\u7684\u5168\u9762\u6982\u8ff0\uff0c\u5305\u62ec\u76d1\u63a7\u52a8\u673a\u3001\u65b9\u6cd5\u3001\u5de5\u5177\u548c\u5f53\u524d\u5c40\u9650\u6027\u3002", "motivation": "\u52a8\u6001\u751f\u4ea7\u73af\u5883\u4e2d\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u9762\u4e34\u8fd0\u884c\u65f6\u95ee\u9898\uff08\u5982\u6570\u636e\u6a21\u5f0f\u53d8\u5316\uff09\uff0c\u9700\u8981\u76d1\u63a7\u6765\u65e9\u671f\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7ef4\u62a4\u7528\u6237\u4fe1\u4efb\u5e76\u9632\u6b62\u7ec4\u7ec7\u4e0d\u826f\u540e\u679c\u3002", "method": "\u91c7\u7528\u591a\u6e90\u6587\u732e\u7efc\u8ff0(MLR)\u65b9\u6cd5\uff0c\u9075\u5faaGarousi\u7684\u6210\u719f\u6307\u5357\uff0c\u4ece\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u5206\u6790136\u7bc7\u8bba\u6587\uff1a\u52a8\u673a\u76ee\u6807\u80cc\u666f\u3001\u76d1\u63a7\u65b9\u9762\u6280\u672f\u6307\u6807\u5de5\u5177\u3001\u8d21\u732e\u6548\u76ca\u3001\u5f53\u524d\u5c40\u9650\u6027\u3002", "result": "\u7cfb\u7edf\u8bc6\u522b\u548c\u603b\u7ed3\u4e86\u673a\u5668\u5b66\u4e60\u76d1\u63a7\u5b9e\u8df5\u4e0e\u7a7a\u767d\uff0c\u5f3a\u8c03\u4e86\u6b63\u5f0f\u6587\u732e\u4e0e\u7070\u8272\u6587\u732e\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u548c\u8131\u8282\uff0c\u63d0\u4f9b\u4e86\u76d1\u63a7\u89e3\u51b3\u65b9\u6848\u9009\u62e9\u6307\u5357\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5b66\u672f\u754c\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4ef7\u503c\uff0c\u5e2e\u52a9\u9009\u62e9\u5408\u9002\u7684\u76d1\u63a7\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u51fa\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.14646", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.14646", "abs": "https://arxiv.org/abs/2509.14646", "authors": ["Yongpan Wang", "Xin Xu", "Xiaojie Zhu", "Xiaodong Gu", "Beijun Shen"], "title": "SALT4Decompile: Inferring Source-level Abstract Logic Tree for LLM-Based Binary Decompilation", "comment": "13 pages, 7 figures", "summary": "Decompilation is widely used in reverse engineering to recover high-level\nlanguage code from binary executables. While recent approaches leveraging Large\nLanguage Models (LLMs) have shown promising progress, they typically treat\nassembly code as a linear sequence of instructions, overlooking arbitrary jump\npatterns and isolated data segments inherent to binary files. This limitation\nsignificantly hinders their ability to correctly infer source code semantics\nfrom assembly code. To address this limitation, we propose \\saltm, a novel\nbinary decompilation method that abstracts stable logical features shared\nbetween binary and source code. The core idea of \\saltm is to abstract selected\nbinary-level operations, such as specific jumps, into a high-level logic\nframework that better guides LLMs in semantic recovery. Given a binary\nfunction, \\saltm constructs a Source-level Abstract Logic Tree (\\salt) from\nassembly code to approximate the logic structure of high-level language. It\nthen fine-tunes an LLM using the reconstructed \\salt to generate decompiled\ncode. Finally, the output is refined through error correction and symbol\nrecovery to improve readability and correctness. We compare \\saltm to three\ncategories of baselines (general-purpose LLMs, commercial decompilers, and\ndecompilation methods) using three well-known datasets (Decompile-Eval, MBPP,\nExebench). Our experimental results demonstrate that \\saltm is highly effective\nin recovering the logic of the source code, significantly outperforming\nstate-of-the-art methods (e.g., 70.4\\% TCP rate on Decompile-Eval with a 10.6\\%\nimprovement). The results further validate its robustness against four commonly\nused obfuscation techniques. Additionally, analyses of real-world software and\na user study confirm that our decompiled output offers superior assistance to\nhuman analysts in comprehending binary functions.", "AI": {"tldr": "SALT\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u4e8c\u8fdb\u5236\u53cd\u7f16\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u6e90\u7ea7\u62bd\u8c61\u903b\u8f91\u6811(SALT)\u6765\u62bd\u8c61\u4e8c\u8fdb\u5236\u548c\u6e90\u4ee3\u7801\u4e4b\u95f4\u7684\u7a33\u5b9a\u903b\u8f91\u7279\u5f81\uff0c\u6307\u5bfcLLM\u8fdb\u884c\u8bed\u4e49\u6062\u590d\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u53cd\u7f16\u8bd1\u65b9\u6cd5\u5c06\u6c47\u7f16\u4ee3\u7801\u89c6\u4e3a\u7ebf\u6027\u6307\u4ee4\u5e8f\u5217\uff0c\u5ffd\u7565\u4e86\u4e8c\u8fdb\u5236\u6587\u4ef6\u56fa\u6709\u7684\u4efb\u610f\u8df3\u8f6c\u6a21\u5f0f\u548c\u5b64\u7acb\u6570\u636e\u6bb5\uff0c\u8fd9\u4e25\u91cd\u963b\u788d\u4e86\u4ece\u6c47\u7f16\u4ee3\u7801\u6b63\u786e\u63a8\u65ad\u6e90\u4ee3\u7801\u8bed\u4e49\u7684\u80fd\u529b\u3002", "method": "SALT\u65b9\u6cd5\u9996\u5148\u4ece\u6c47\u7f16\u4ee3\u7801\u6784\u5efa\u6e90\u7ea7\u62bd\u8c61\u903b\u8f91\u6811(SALT)\u6765\u8fd1\u4f3c\u9ad8\u7ea7\u8bed\u8a00\u7684\u903b\u8f91\u7ed3\u6784\uff0c\u7136\u540e\u4f7f\u7528\u91cd\u6784\u7684SALT\u5fae\u8c03LLM\u751f\u6210\u53cd\u7f16\u8bd1\u4ee3\u7801\uff0c\u6700\u540e\u901a\u8fc7\u9519\u8bef\u7ea0\u6b63\u548c\u7b26\u53f7\u6062\u590d\u6765\u6539\u8fdb\u8f93\u51fa\u7684\u53ef\u8bfb\u6027\u548c\u6b63\u786e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u77e5\u540d\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSALT\u5728\u6062\u590d\u6e90\u4ee3\u7801\u903b\u8f91\u65b9\u9762\u975e\u5e38\u6709\u6548\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff08\u5982\u5728Decompile-Eval\u4e0a\u8fbe\u523070.4%\u7684TCP\u7387\uff0c\u63d0\u534710.6%\uff09\uff0c\u5e76\u4e14\u5bf9\u56db\u79cd\u5e38\u7528\u6df7\u6dc6\u6280\u672f\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "SALT\u901a\u8fc7\u62bd\u8c61\u4e8c\u8fdb\u5236\u7ea7\u64cd\u4f5c\u4e3a\u9ad8\u7ea7\u903b\u8f91\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u4e8c\u8fdb\u5236\u53cd\u7f16\u8bd1\u4e2d\u7684\u8bed\u4e49\u6062\u590d\u80fd\u529b\uff0c\u4e3a\u4eba\u7c7b\u5206\u6790\u4eba\u5458\u7406\u89e3\u4e8c\u8fdb\u5236\u51fd\u6570\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u5e2e\u52a9\u3002"}}
{"id": "2509.14347", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14347", "abs": "https://arxiv.org/abs/2509.14347", "authors": ["Henri A\u00efdasso", "Francis Bordeleau", "Ali Tizghadam"], "title": "On the Illusion of Success: An Empirical Study of Build Reruns and Silent Failures in Industrial CI", "comment": "17 pages, 7 figures", "summary": "Reliability of build outcomes is a cornerstone of effective Continuous\nIntegration (CI). Yet in practice, developers often struggle with\nnon-deterministic issues in the code or CI infrastructure, which undermine\ntrust in build results. When faced with such unexpected outcomes, developers\noften repeatedly rerun jobs hoping for true success, but this practice is known\nto increase CI costs and reduce productivity. While recent studies have focused\non intermittent job failures, no prior work has investigated silent failures,\nwhere build jobs are marked as successful but fail to complete all or part of\ntheir tasks. Such silent failures often go unnoticed, creating an illusion of\nsuccess with detrimental consequences such as bugs escaping into production.\nThis paper presents the first empirical study of silent failures through the\npractice of rerunning successful jobs. An analysis of 142,387 jobs across 81\nindustrial projects shows that 11% of successful jobs are rerun, with 35% of\nthese reruns occurring after more than 24 hours. Using mixed-effects models on\n32 independent variables (AUC of 85%), we identified key factors associated\nwith reruns of successful jobs, notably testing and static analysis tasks,\nscripting languages like Shell, and developers prior rerun tendencies. A\nfurther analysis of 92 public issues revealed 11 categories of silent failures\naligning with these factors, the most frequent being artifact operation errors,\ncaching errors, and ignored exit codes. Overall, our findings provide valuable\ninsights into the circumstances and causes of silent failures to raise\nawareness among teams, and present solutions to improve CI reliability.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u6301\u7eed\u96c6\u6210\u4e2d\u7684\u9759\u9ed8\u5931\u8d25\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b011%\u7684\u6210\u529f\u4f5c\u4e1a\u4f1a\u88ab\u91cd\u65b0\u8fd0\u884c\uff0c\u5176\u4e2d35%\u572824\u5c0f\u65f6\u540e\u91cd\u8dd1\uff0c\u8bc6\u522b\u51fa\u6d4b\u8bd5\u3001\u9759\u6001\u5206\u6790\u3001Shell\u811a\u672c\u7b49\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63ed\u793a\u4e8611\u7c7b\u9759\u9ed8\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u6301\u7eed\u96c6\u6210\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f00\u53d1\u8005\u7ecf\u5e38\u9762\u4e34\u975e\u786e\u5b9a\u6027\u95ee\u9898\u548c\u9759\u9ed8\u5931\u8d25\uff08\u4f5c\u4e1a\u6807\u8bb0\u4e3a\u6210\u529f\u4f46\u672a\u5b8c\u6210\u6240\u6709\u4efb\u52a1\uff09\uff0c\u8fd9\u4e9b\u95ee\u9898\u4f1a\u964d\u4f4e\u5bf9\u6784\u5efa\u7ed3\u679c\u7684\u4fe1\u4efb\uff0c\u589e\u52a0\u6210\u672c\u5e76\u53ef\u80fd\u5bfc\u81f4bug\u8fdb\u5165\u751f\u4ea7\u73af\u5883\u3002", "method": "\u901a\u8fc7\u5bf981\u4e2a\u5de5\u4e1a\u9879\u76ee\u7684142,387\u4e2a\u4f5c\u4e1a\u8fdb\u884c\u5206\u6790\uff0c\u4f7f\u7528\u6df7\u5408\u6548\u5e94\u6a21\u578b\u5bf932\u4e2a\u81ea\u53d8\u91cf\uff08AUC\u4e3a85%\uff09\u8fdb\u884c\u7814\u7a76\uff0c\u5e76\u8fdb\u4e00\u6b65\u5206\u679092\u4e2a\u516c\u5f00\u95ee\u9898\u6765\u8bc6\u522b\u9759\u9ed8\u5931\u8d25\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b011%\u7684\u6210\u529f\u4f5c\u4e1a\u4f1a\u88ab\u91cd\u65b0\u8fd0\u884c\uff0c35%\u7684\u91cd\u8dd1\u53d1\u751f\u572824\u5c0f\u65f6\u540e\uff1b\u8bc6\u522b\u51fa\u6d4b\u8bd5\u548c\u9759\u6001\u5206\u6790\u4efb\u52a1\u3001Shell\u7b49\u811a\u672c\u8bed\u8a00\u3001\u5f00\u53d1\u8005\u91cd\u8dd1\u503e\u5411\u7b49\u5173\u952e\u56e0\u7d20\uff1b\u63ed\u793a\u4e8611\u7c7b\u9759\u9ed8\u5931\u8d25\uff0c\u6700\u5e38\u89c1\u7684\u662f\u5de5\u4ef6\u64cd\u4f5c\u9519\u8bef\u3001\u7f13\u5b58\u9519\u8bef\u548c\u5ffd\u7565\u9000\u51fa\u7801\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u9759\u9ed8\u5931\u8d25\u60c5\u51b5\u548c\u539f\u56e0\u7684\u91cd\u8981\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u56e2\u961f\u610f\u8bc6\uff0c\u5e76\u4e3a\u6539\u8fdbCI\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5173\u6ce8\u8fd9\u4e9b\u5bb9\u6613\u88ab\u5ffd\u89c6\u4f46\u5177\u6709\u7834\u574f\u6027\u7684\u5931\u8d25\u6a21\u5f0f\u3002"}}
{"id": "2509.14373", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14373", "abs": "https://arxiv.org/abs/2509.14373", "authors": ["Huy Le", "Phong Nguyen", "Hao Do", "Tuan Nguyen", "Thien Pham", "Anh Nguyen-Duc", "Tho Quan"], "title": "CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning", "comment": null, "summary": "Context: Automated code generation using Foundation Models (FMs) offers\npromising solutions for enhancing software development efficiency. However,\nchallenges remain in ensuring domain specificity, cost-effectiveness, and\nsecurity - especially when relying on third-party APIs. This paper introduces\nCodeLSI, a framework that combines low-rank optimization and domain-specific\ninstruction tuning to address these challenges.\n  Objectives: The aim of this study is to develop and evaluate CodeLSI, a novel\napproach for generating high-quality code tailored to specific domains, using\nFMs fine-tuned on company infrastructure without dependence on external APIs.\n  Methods: CodeLSI applies low-rank adaptation techniques to reduce the\ncomputational cost of model pre-training and fine-tuning. Domain-specific\ninstruction tuning is employed to align code generation with organizational\nneeds. We implemented and tested the framework on real-world JavaScript coding\ntasks using datasets drawn from internal software projects.\n  Results: Experimental evaluations show that CodeLSI produces high-quality,\ncontext aware code. It outperforms baseline models in terms of relevance,\naccuracy, and domain fit. The use of low-rank optimization significantly\nreduced resource requirements, enabling scalable training on company-owned\ninfrastructure.\n  Conclusion: CodeLSI demonstrates that combining low-rank optimization with\ndomain specific tuning can enhance the practicality and performance of FMs for\nautomated code generation. This approach provides a secure, cost-efficient\nalternative to commercial API based solutions and supports faster, more\ntargeted innovation in software development.", "AI": {"tldr": "CodeLSI\u662f\u4e00\u4e2a\u7ed3\u5408\u4f4e\u79e9\u4f18\u5316\u548c\u9886\u57df\u7279\u5b9a\u6307\u4ee4\u8c03\u4f18\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5185\u90e8\u57fa\u7840\u8bbe\u65bd\u4e0a\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9886\u57df\u7279\u5b9a\u7684\u4ee3\u7801\uff0c\u907f\u514d\u4f9d\u8d56\u7b2c\u4e09\u65b9API\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u4e2d\u9886\u57df\u7279\u5f02\u6027\u3001\u6210\u672c\u6548\u76ca\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4f9d\u8d56\u7b2c\u4e09\u65b9API\u65f6\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u5e94\u7528\u4f4e\u79e9\u9002\u5e94\u6280\u672f\u964d\u4f4e\u6a21\u578b\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u91c7\u7528\u9886\u57df\u7279\u5b9a\u6307\u4ee4\u8c03\u4f18\u4f7f\u4ee3\u7801\u751f\u6210\u4e0e\u7ec4\u7ec7\u9700\u6c42\u5bf9\u9f50\uff0c\u5728\u771f\u5b9eJavaScript\u7f16\u7801\u4efb\u52a1\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "CodeLSI\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\uff0c\u5728\u76f8\u5173\u6027\u3001\u51c6\u786e\u6027\u548c\u9886\u57df\u9002\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4f4e\u79e9\u4f18\u5316\u663e\u8457\u964d\u4f4e\u4e86\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "\u4f4e\u79e9\u4f18\u5316\u4e0e\u9886\u57df\u7279\u5b9a\u8c03\u4f18\u76f8\u7ed3\u5408\u53ef\u4ee5\u63d0\u5347\u57fa\u7840\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u5546\u4e1aAPI\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.15150", "categories": ["cs.SE", "cs.PL", "D.2.6; D.3.3; D.2.3; D.2.5; D.2.13"], "pdf": "https://arxiv.org/pdf/2509.15150", "abs": "https://arxiv.org/abs/2509.15150", "authors": ["Federico Bruzzone", "Walter Cazzola", "Luca Favalli"], "title": "Code Less to Code More: Streamlining Language Server Protocol and Type System Development for Language Families", "comment": "34 pages, 10 figures, Journal of Systems and Software, June 2025, for\n  the replication package, see https://doi.org/10.5281/zenodo.15276991", "summary": "Developing editing support for $L$ languages in $E$ editors is complex and\ntime-consuming. Some languages do not provide dedicated editors, while others\noffer a single native editor. The $\\textit{language server protocol}$ (LSP)\nreduces the language-editor combinations $L \\times E$ to $L + E$, where a\nsingle language server communicates with editors via LSP plugins. However,\noverlapping implementations of linguistic components remain an issue. Existing\nlanguage workbenches struggle with modularity, reusability, and leveraging type\nsystems for language server generation. In this work, we propose: (i) Typelang,\na family of domain-specific languages for modular, composable, and reusable\ntype system implementation, (ii) a modular language server generation process,\nproducing servers for languages built in a modular workbench, (iii) the\nvariant-oriented programming paradigm and a cross-artifact coordination layer\nto manage interdependent software variants, and (iv) an LSP plugin generator,\nreducing $E$ to $1$ by automating plugin creation for multiple editors. To\nsimplify editing support for language families, each language artifact\nintegrates its own Typelang variant, used to generate language servers. This\nreduces combinations to $T \\times 1$, where $T = L$ represents the number of\ntype systems. Further reuse of language artifacts across languages lowers this\nto $N \\times 1$, where $N << T$, representing unique type systems. We implement\nTypelang in Neverlang, generating language servers for each artifact and LSP\nplugins for three editors. Empirical evaluation shows a 93.48% reduction in\ncharacters needed for type system implementation and 100% automation of LSP\nplugin generation, significantly lowering effort for editing support in\nlanguage families, especially when artifacts are reused.", "AI": {"tldr": "\u63d0\u51fa\u4e86Typelang\u8bed\u8a00\u5bb6\u65cf\u548c\u6a21\u5757\u5316\u8bed\u8a00\u670d\u52a1\u5668\u751f\u6210\u65b9\u6cd5\uff0c\u5c06\u8bed\u8a00\u7f16\u8f91\u5668\u7ec4\u5408\u4eceL\u00d7E\u51cf\u5c11\u5230N\u00d71\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bed\u8a00\u7f16\u8f91\u652f\u6301\u7684\u5f00\u9500", "motivation": "\u89e3\u51b3\u73b0\u6709\u8bed\u8a00\u5de5\u4f5c\u53f0\u5728\u6a21\u5757\u5316\u3001\u53ef\u91cd\u7528\u6027\u548c\u5229\u7528\u7c7b\u578b\u7cfb\u7edf\u751f\u6210\u8bed\u8a00\u670d\u52a1\u5668\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u51cf\u5c11\u8bed\u8a00\u7f16\u8f91\u5668\u7ec4\u5408\u7684\u590d\u6742\u6027", "method": "\u5f00\u53d1Typelang DSL\u5bb6\u65cf\u7528\u4e8e\u6a21\u5757\u5316\u7c7b\u578b\u7cfb\u7edf\u5b9e\u73b0\uff0c\u5efa\u7acb\u6a21\u5757\u5316\u8bed\u8a00\u670d\u52a1\u5668\u751f\u6210\u6d41\u7a0b\uff0c\u91c7\u7528\u53d8\u4f53\u5bfc\u5411\u7f16\u7a0b\u548c\u8de8\u5de5\u4ef6\u534f\u8c03\u5c42\u7ba1\u7406\u8f6f\u4ef6\u53d8\u4f53\uff0c\u81ea\u52a8\u5316\u751f\u6210LSP\u63d2\u4ef6", "result": "\u5b9e\u73b0\u4e8693.48%\u7684\u7c7b\u578b\u7cfb\u7edf\u5b9e\u73b0\u5b57\u7b26\u6570\u51cf\u5c11\uff0c100%\u81ea\u52a8\u5316LSP\u63d2\u4ef6\u751f\u6210\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bed\u8a00\u5bb6\u65cf\u7f16\u8f91\u652f\u6301\u7684\u5de5\u4f5c\u91cf", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u8a00\u7f16\u8f91\u5668\u7ec4\u5408\u7684\u590d\u6742\u6027\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u91cd\u7528\u548c\u81ea\u52a8\u5316\u751f\u6210\u5927\u5e45\u964d\u4f4e\u4e86\u5f00\u53d1\u6210\u672c\uff0c\u7279\u522b\u5728\u8bed\u8a00\u5de5\u4ef6\u590d\u7528\u65f6\u6548\u679c\u66f4\u663e\u8457"}}
{"id": "2509.14483", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14483", "abs": "https://arxiv.org/abs/2509.14483", "authors": ["Thanh-Long Bui", "Hoa Khanh Dam", "Rashina Hoda"], "title": "An LLM-based multi-agent framework for agile effort estimation", "comment": "Submitted to ASE'25", "summary": "Effort estimation is a crucial activity in agile software development, where\nteams collaboratively review, discuss, and estimate the effort required to\ncomplete user stories in a product backlog. Current practices in agile effort\nestimation heavily rely on subjective assessments, leading to inaccuracies and\ninconsistencies in the estimates. While recent machine learning-based methods\nshow promising accuracy, they cannot explain or justify their estimates and\nlack the capability to interact with human team members. Our paper fills this\nsignificant gap by leveraging the powerful capabilities of Large Language\nModels (LLMs). We propose a novel LLM-based multi-agent framework for agile\nestimation that not only can produce estimates, but also can coordinate,\ncommunicate and discuss with human developers and other agents to reach a\nconsensus. Evaluation results on a real-life dataset show that our approach\noutperforms state-of-the-art techniques across all evaluation metrics in the\nmajority of the cases. Our human study with software development practitioners\nalso demonstrates an overwhelmingly positive experience in collaborating with\nour agents in agile effort estimation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5de5\u4f5c\u91cf\u4f30\u7b97\uff0c\u80fd\u591f\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u534f\u4f5c\u8ba8\u8bba\u5e76\u8fbe\u6210\u5171\u8bc6\uff0c\u5728\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u654f\u6377\u5de5\u4f5c\u91cf\u4f30\u7b97\u4e3b\u8981\u4f9d\u8d56\u4e3b\u89c2\u8bc4\u4f30\uff0c\u5bfc\u81f4\u4f30\u7b97\u4e0d\u51c6\u786e\u548c\u4e0d\u4e00\u81f4\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u663e\u793a\u51fa\u826f\u597d\u51c6\u786e\u6027\uff0c\u4f46\u65e0\u6cd5\u89e3\u91ca\u4f30\u7b97\u7ed3\u679c\u6216\u4e0e\u4eba\u7c7b\u56e2\u961f\u6210\u5458\u4e92\u52a8\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u751f\u6210\u4f30\u7b97\uff0c\u8fd8\u80fd\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u548c\u5176\u4ed6\u667a\u80fd\u4f53\u534f\u8c03\u3001\u6c9f\u901a\u548c\u8ba8\u8bba\u4ee5\u8fbe\u6210\u5171\u8bc6\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u6280\u672f\u3002\u4e0e\u8f6f\u4ef6\u5f00\u53d1\u4ece\u4e1a\u8005\u7684\u4eba\u7c7b\u7814\u7a76\u4e5f\u663e\u793a\u51fa\u4e0e\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6781\u5176\u79ef\u6781\u4f53\u9a8c\u3002", "conclusion": "\u8be5LLM-based\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u654f\u6377\u4f30\u7b97\u65b9\u6cd5\u7684\u4e3b\u89c2\u6027\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u4ea4\u4e92\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u534f\u4f5c\u6027\u5f3a\u7684\u4f30\u7b97\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14626", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14626", "abs": "https://arxiv.org/abs/2509.14626", "authors": ["Feiran Qin", "M. M. Abid Naziri", "Hengyu Ai", "Saikat Dutta", "Marcelo d'Amorim"], "title": "Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs", "comment": null, "summary": "Deep Learning (DL) libraries such as PyTorch provide the core components to\nbuild major AI-enabled applications. Finding bugs in these libraries is\nimportant and challenging. Prior approaches have tackled this by performing\neither API-level fuzzing or model-level fuzzing, but they do not use coverage\nguidance, which limits their effectiveness and efficiency. This raises an\nintriguing question: can coverage guided fuzzing (CGF), in particular\nframeworks like LibFuzzer, be effectively applied to DL libraries, and does it\noffer meaningful improvements in code coverage, bug detection, and scalability\ncompared to prior methods?\n  We present the first in-depth study to answer this question. A key challenge\nin applying CGF to DL libraries is the need to create a test harness for each\nAPI that can transform byte-level fuzzer inputs into valid API inputs. To\naddress this, we propose FlashFuzz, a technique that leverages Large Language\nModels (LLMs) to automatically synthesize API-level harnesses by combining\ntemplates, helper functions, and API documentation. FlashFuzz uses a feedback\ndriven strategy to iteratively synthesize and repair harnesses. With this\napproach, FlashFuzz synthesizes harnesses for 1,151 PyTorch and 662 TensorFlow\nAPIs. Compared to state-of-the-art fuzzing methods (ACETest, PathFinder, and\nTitanFuzz), FlashFuzz achieves up to 101.13 to 212.88 percent higher coverage\nand 1.0x to 5.4x higher validity rate, while also delivering 1x to 1182x\nspeedups in input generation. FlashFuzz has discovered 42 previously unknown\nbugs in PyTorch and TensorFlow, 8 of which are already fixed. Our study\nconfirms that CGF can be effectively applied to DL libraries and provides a\nstrong baseline for future testing approaches.", "AI": {"tldr": "FlashFuzz\u662f\u9996\u4e2a\u5c06\u8986\u76d6\u7387\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5(CGF)\u5e94\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u5e93\u7684\u7814\u7a76\uff0c\u901a\u8fc7LLM\u81ea\u52a8\u5408\u6210API\u7ea7\u6d4b\u8bd5\u5de5\u5177\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u8986\u76d6\u7387\u3001\u9519\u8bef\u68c0\u6d4b\u6548\u7387\u548c\u8f93\u5165\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u8986\u76d6\u7387\u5f15\u5bfc\uff0c\u9650\u5236\u4e86\u6d4b\u8bd5\u6548\u679c\u548c\u6548\u7387\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22CGF\u5728DL\u5e93\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u5e76\u89e3\u51b3API\u7ea7\u6d4b\u8bd5\u5de5\u5177\u81ea\u52a8\u751f\u6210\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faFlashFuzz\u6280\u672f\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7ed3\u5408\u6a21\u677f\u3001\u8f85\u52a9\u51fd\u6570\u548cAPI\u6587\u6863\u81ea\u52a8\u5408\u6210API\u7ea7\u6d4b\u8bd5\u5de5\u5177\uff0c\u91c7\u7528\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u7b56\u7565\u6765\u5408\u6210\u548c\u4fee\u590d\u6d4b\u8bd5\u5de5\u5177\u3002", "result": "\u4e3a1,151\u4e2aPyTorch\u548c662\u4e2aTensorFlow API\u5408\u6210\u4e86\u6d4b\u8bd5\u5de5\u5177\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8986\u76d6\u7387\u63d0\u9ad8101.13-212.88%\uff0c\u6709\u6548\u6027\u63d0\u9ad81.0-5.4\u500d\uff0c\u8f93\u5165\u751f\u6210\u901f\u5ea6\u63d0\u53471-1182\u500d\uff0c\u53d1\u73b0\u4e8642\u4e2a\u672a\u77e5\u9519\u8bef\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9eCGF\u53ef\u6709\u6548\u5e94\u7528\u4e8eDL\u5e93\u6d4b\u8bd5\uff0cFlashFuzz\u4e3a\u672a\u6765\u6d4b\u8bd5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5f3a\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86LLM\u5728\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u751f\u6210\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.14740", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14740", "abs": "https://arxiv.org/abs/2509.14740", "authors": ["Andrei-Raoul Morariu", "Andreas Strandberg", "Bogdan Iancu", "Jerker Bjorkqvist"], "title": "Wireless Communication Performance Testing: From Laboratory Environment to Research Vessel", "comment": "5 pages, 4 figures, 2 tables", "summary": "This study investigates signal transmission within a shared spectrum,\nfocusing on measurements conducted both in laboratory and outdoor environments.\nThe objective was to demonstrate how laboratory objects obstructing the line of\nsight can attenuate the signal between a transmitter (Tx) and a receiver (Rx).\nAdditionally, we examined the impact of distance and placement in various\nlocations aboard an electric research boat on signal transmission efficiency.\nThese findings contribute to understanding whether the environmental factors\ninfluence wireless communication in dynamic and obstructed environments.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u548c\u5ba4\u5916\u73af\u5883\u6d4b\u91cf\uff0c\u5206\u6790\u4e86\u5171\u4eab\u9891\u8c31\u4e2d\u4fe1\u53f7\u4f20\u8f93\u7279\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u89c6\u7ebf\u906e\u6321\u7269\u3001\u8ddd\u79bb\u548c\u4f4d\u7f6e\u5bf9\u4fe1\u53f7\u8870\u51cf\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76\u52a8\u6001\u548c\u906e\u6321\u73af\u5883\u4e2d\u73af\u5883\u56e0\u7d20\u5bf9\u65e0\u7ebf\u901a\u4fe1\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5171\u4eab\u9891\u8c31\u573a\u666f\u4e0b\u4fe1\u53f7\u4f20\u8f93\u7684\u53ef\u9760\u6027\u3002", "method": "\u5728\u5b9e\u9a8c\u5ba4\u548c\u5ba4\u5916\u73af\u5883\u4e2d\u8fdb\u884c\u4fe1\u53f7\u4f20\u8f93\u6d4b\u91cf\uff0c\u5206\u6790\u89c6\u7ebf\u906e\u6321\u7269\u5bf9Tx-Rx\u4fe1\u53f7\u7684\u8870\u51cf\u6548\u5e94\uff0c\u5e76\u7814\u7a76\u8ddd\u79bb\u548c\u7535\u52a8\u7814\u7a76\u8239\u4e0a\u4e0d\u540c\u4f4d\u7f6e\u5bf9\u4f20\u8f93\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u5ba4\u7269\u4f53\u906e\u6321\u89c6\u7ebf\u4f1a\u5bfc\u81f4\u4fe1\u53f7\u8870\u51cf\uff0c\u8ddd\u79bb\u548c\u4f4d\u7f6e\u5e03\u7f6e\u663e\u8457\u5f71\u54cd\u4fe1\u53f7\u4f20\u8f93\u6548\u7387\uff0c\u73af\u5883\u56e0\u7d20\u5728\u52a8\u6001\u906e\u6321\u73af\u5883\u4e2d\u5bf9\u65e0\u7ebf\u901a\u4fe1\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u73af\u5883\u56e0\u7d20\uff08\u5305\u62ec\u906e\u6321\u7269\u3001\u8ddd\u79bb\u548c\u4f4d\u7f6e\uff09\u5728\u5171\u4eab\u9891\u8c31\u7684\u65e0\u7ebf\u901a\u4fe1\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u7406\u89e3\u52a8\u6001\u906e\u6321\u73af\u5883\u4e2d\u7684\u901a\u4fe1\u53ef\u9760\u6027\u3002"}}
{"id": "2509.14744", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14744", "abs": "https://arxiv.org/abs/2509.14744", "authors": ["Worawalan Chatlatanagulchai", "Kundjanasith Thonglek", "Brittany Reid", "Yutaro Kashiwa", "Pattara Leelaprute", "Arnon Rungsawang", "Bundit Manaskasemsak", "Hajimu Iida"], "title": "On the Use of Agentic Coding Manifests: An Empirical Study of Claude Code", "comment": null, "summary": "Agentic coding tools receive goals written in natural language as input,\nbreak them down into specific tasks, and write/execute the actual code with\nminimal human intervention. Key to this process are agent manifests,\nconfiguration files (such as Claude.md) that provide agents with essential\nproject context, identity, and operational rules. However, the lack of\ncomprehensive and accessible documentation for creating these manifests\npresents a significant challenge for developers. We analyzed 253 Claude.md\nfiles from 242 repositories to identify structural patterns and common content.\nOur findings show that manifests typically have shallow hierarchies with one\nmain heading and several subsections, with content dominated by operational\ncommands, technical implementation notes, and high-level architecture.", "AI": {"tldr": "\u5206\u6790253\u4e2aClaude.md\u6587\u4ef6\uff0c\u53d1\u73b0\u667a\u80fd\u7f16\u7801\u5de5\u5177\u7684manifest\u6587\u4ef6\u901a\u5e38\u5177\u6709\u6d45\u5c42\u6b21\u7ed3\u6784\uff0c\u4e3b\u8981\u5305\u542b\u64cd\u4f5c\u547d\u4ee4\u3001\u6280\u672f\u5b9e\u73b0\u8bf4\u660e\u548c\u9ad8\u7ea7\u67b6\u6784\u5185\u5bb9", "motivation": "\u667a\u80fd\u7f16\u7801\u5de5\u5177\u9700\u8981manifest\u6587\u4ef6\u63d0\u4f9b\u9879\u76ee\u4e0a\u4e0b\u6587\u3001\u8eab\u4efd\u548c\u64cd\u4f5c\u89c4\u5219\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u7684\u6587\u6863\u6307\u5bfc\u5f00\u53d1\u8005\u521b\u5efa\u8fd9\u4e9b\u914d\u7f6e\u6587\u4ef6", "method": "\u5206\u6790\u4e86242\u4e2a\u4ee3\u7801\u4ed3\u5e93\u4e2d\u7684253\u4e2aClaude.md\u6587\u4ef6\uff0c\u8bc6\u522b\u7ed3\u6784\u6a21\u5f0f\u548c\u5e38\u89c1\u5185\u5bb9", "result": "manifest\u6587\u4ef6\u901a\u5e38\u5177\u6709\u6d45\u5c42\u6b21\u7ed3\u6784\uff08\u4e00\u4e2a\u4e3b\u6807\u9898\u548c\u82e5\u5e72\u5b50\u7ae0\u8282\uff09\uff0c\u5185\u5bb9\u4ee5\u64cd\u4f5c\u547d\u4ee4\u3001\u6280\u672f\u5b9e\u73b0\u8bf4\u660e\u548c\u9ad8\u7ea7\u67b6\u6784\u4e3a\u4e3b", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u521b\u5efa\u6709\u6548\u7684agent manifest\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5b9e\u8df5\u4e2d\u7684\u5e38\u89c1\u6a21\u5f0f\u548c\u5185\u5bb9\u5206\u5e03"}}
{"id": "2509.14745", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14745", "abs": "https://arxiv.org/abs/2509.14745", "authors": ["Miku Watanabe", "Hao Li", "Yutaro Kashiwa", "Brittany Reid", "Hajimu Iida", "Ahmed E. Hassan"], "title": "On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub", "comment": null, "summary": "Large language models (LLMs) are increasingly being integrated into software\ndevelopment processes. The ability to generate code and submit pull requests\nwith minimal human intervention, through the use of autonomous AI agents, is\npoised to become a standard practice. However, little is known about the\npractical usefulness of these pull requests and the extent to which their\ncontributions are accepted in real-world projects. In this paper, we\nempirically study 567 GitHub pull requests (PRs) generated using Claude Code,\nan agentic coding tool, across 157 diverse open-source projects. Our analysis\nreveals that developers tend to rely on agents for tasks such as refactoring,\ndocumentation, and testing. The results indicate that 83.8% of these\nagent-assisted PRs are eventually accepted and merged by project maintainers,\nwith 54.9% of the merged PRs are integrated without further modification. The\nremaining 45.1% require additional changes benefit from human revisions,\nespecially for bug fixes, documentation, and adherence to project-specific\nstandards. These findings suggest that while agent-assisted PRs are largely\nacceptable, they still benefit from human oversight and refinement.", "AI": {"tldr": "\u5bf9567\u4e2a\u7531Claude Code\u751f\u6210\u7684GitHub PR\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b083.8%\u7684AI\u8f85\u52a9PR\u88ab\u63a5\u53d7\u5408\u5e76\uff0c\u5176\u4e2d54.9%\u65e0\u9700\u4fee\u6539\u76f4\u63a5\u5408\u5e76\uff0c45.1%\u9700\u8981\u4eba\u5de5\u4fee\u8ba2", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8981\u4e86\u89e3AI\u751f\u6210\u7684pull requests\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u63a5\u53d7\u7a0b\u5ea6", "method": "\u5b9e\u8bc1\u7814\u7a76157\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u7684567\u4e2a\u7531Claude Code\u751f\u6210\u7684GitHub pull requests\uff0c\u5206\u6790\u5176\u4efb\u52a1\u7c7b\u578b\u3001\u63a5\u53d7\u7387\u548c\u4fee\u6539\u9700\u6c42", "result": "83.8%\u7684AI\u8f85\u52a9PR\u88ab\u63a5\u53d7\u5408\u5e76\uff1b54.9%\u7684\u5408\u5e76PR\u65e0\u9700\u4fee\u6539\uff1b45.1%\u9700\u8981\u4eba\u5de5\u4fee\u8ba2\uff0c\u7279\u522b\u662f\u5728bug\u4fee\u590d\u3001\u6587\u6863\u548c\u9879\u76ee\u6807\u51c6\u9075\u5faa\u65b9\u9762", "conclusion": "AI\u8f85\u52a9\u7684PR\u5927\u90e8\u5206\u53ef\u88ab\u63a5\u53d7\uff0c\u4f46\u4ecd\u9700\u8981\u4eba\u5de5\u76d1\u7763\u548c\u7cbe\u70bc\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u4efb\u52a1\u548c\u9879\u76ee\u7279\u5b9a\u6807\u51c6\u7684\u9075\u5faa\u65b9\u9762"}}
{"id": "2509.14829", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14829", "abs": "https://arxiv.org/abs/2509.14829", "authors": ["Shuo Jin", "Songqiang Chen", "Xiaoyuan Xie", "Shing-Chi Cheung"], "title": "RulER: Automated Rule-Based Semantic Error Localization and Repair for Code Translation", "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "summary": "Automated code translation aims to convert programs between different\nprogramming languages while maintaining their functionality. Due to the\nimperfections of code translation models, the generated translations may\ncontain errors that compromise their reliability. Existing automated debugging\nmethods for code translation rely on code alignments and repair patch templates\nto locate and fix erroneous translations. However, existing methods lack\nreliable references to construct code alignments and design repair patch\ntemplates, which significantly impacts their localization accuracy and repair\neffectiveness. To address these limitations, we reintroduce code translation\nrules and propose a rule-based debugging method for code translation, called\nRulER. RulER automatically derives code translation rules from correct\ntranslations generated by LLMs, enabling the efficient collection of diverse\ntranslation rules. In addition, RulER dynamically combines the existing rules\non expandable nodes like expressions and tokens to further adaptively align\nmore statements. These rules capture clear and detailed structural\ncorrespondences between source and target programming languages. Therefore,\nthey can serve as reliable and reusable references for code alignment and\nrepair template design, enabling RulER to locate and fix translation errors\neffectively. Our evaluation of RulER on Java-to-C++ and Python-to-C++\ntranslations produced by four code translation models demonstrates that RulER\noutperforms state-of-the-art methods, BatFix and TransMap. Our experimental\nresults show that RulER outperformed the best baseline by 20% and 272% in terms\nof error localization rates and repair success rates, respectively. RulER\nexhibits superior repair performance compared to directly prompting LLMs for\npatch generation, demonstrating a promising methodology for extracting and\nleveraging coding knowledge from LLMs.", "AI": {"tldr": "RulER\u662f\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u4ee3\u7801\u7ffb\u8bd1\u8c03\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u4eceLLM\u751f\u6210\u7684\u6b63\u786e\u5b9a\u8bd1\u4e2d\u81ea\u52a8\u63a8\u5bfc\u4ee3\u7801\u7ffb\u8bd1\u89c4\u5219\uff0c\u6709\u6548\u5b9a\u4f4d\u548c\u4fee\u590d\u7ffb\u8bd1\u9519\u8bef\uff0c\u5728\u9519\u8bef\u5b9a\u4f4d\u7387\u548c\u4fee\u590d\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u7ffb\u8bd1\u81ea\u52a8\u8c03\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u9760\u7684\u53c2\u8003\u6765\u6784\u5efa\u4ee3\u7801\u5bf9\u9f50\u548c\u4fee\u590d\u8865\u4e01\u6a21\u677f\uff0c\u5f71\u54cd\u4e86\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u4fee\u590d\u6548\u679c\u3002", "method": "RulER\u4eceLLM\u751f\u6210\u7684\u6b63\u786e\u5b9a\u8bd1\u4e2d\u81ea\u52a8\u63a8\u5bfc\u4ee3\u7801\u7ffb\u8bd1\u89c4\u5219\uff0c\u5e76\u5728\u53ef\u6269\u5c55\u8282\u70b9\u4e0a\u52a8\u6001\u7ec4\u5408\u73b0\u6709\u89c4\u5219\uff0c\u5efa\u7acb\u6e90\u8bed\u8a00\u548c\u76ee\u6807\u8bed\u8a00\u4e4b\u95f4\u7684\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f5c\u4e3a\u4ee3\u7801\u5bf9\u9f50\u548c\u4fee\u590d\u6a21\u677f\u8bbe\u8ba1\u7684\u53ef\u9760\u53c2\u8003\u3002", "result": "\u5728Java\u5230C++\u548cPython\u5230C++\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0cRulER\u5728\u9519\u8bef\u5b9a\u4f4d\u7387\u548c\u4fee\u590d\u6210\u529f\u7387\u4e0a\u5206\u522b\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e8620%\u548c272%\uff0c\u4e14\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528LLM\u751f\u6210\u8865\u4e01\u7684\u65b9\u6cd5\u3002", "conclusion": "RulER\u5c55\u793a\u4e86\u4eceLLMs\u4e2d\u63d0\u53d6\u548c\u5229\u7528\u7f16\u7801\u77e5\u8bc6\u7684\u6709\u524d\u666f\u7684\u65b9\u6cd5\u8bba\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u4ee3\u7801\u7ffb\u8bd1\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2509.14856", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14856", "abs": "https://arxiv.org/abs/2509.14856", "authors": ["Hanyang Guo", "Xunjin Zheng", "Zihan Liao", "Hang Yu", "Peng DI", "Ziyin Zhang", "Hong-Ning Dai"], "title": "CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects", "comment": null, "summary": "Automated code review (CR) is a key application for Large Language Models\n(LLMs), but progress is hampered by a \"reality gap\": existing benchmarks\nevaluate models on isolated sub-tasks using simplified, context-poor data. This\nfails to reflect the holistic context-rich nature of real-world CR. To bridge\nthis gap, we introduce CodeFuse-CR-Bench, the first comprehensiveness-aware\nbenchmark for repository-level CR evaluation. CodeFuse-CR-Bench comprises 601\nhigh-quality instances from 70 Python projects covering nine Pull-Request (PR)\nproblem domains, where each instance provides rich, multi-faceted context\nincluding the associated issue, PR details, and repository state, enabling\nend-to-end evaluation. Beyond superficial metrics, we also propose a novel\nevaluation framework that combines rule-based checks for location and syntax\nwith model-based judgments of review quality. We present the first large-scale\nassessment of state-of-the-art LLMs on this comprehensive CR task. Our results\nestablish crucial baselines and reveal that (1) no single LLM dominates all\naspects of CR; (2) Gemini 2.5 Pro achieves the highest comprehensive\nperformance; and (3) different LLMs exhibit varying robustness to redundant\ncontext. These findings highlight the necessity of holistic, multi-dimensional\nevaluation and provide actionable insights for advancing truly intelligent yet\npractical CR assistants.", "AI": {"tldr": "\u63d0\u51fa\u4e86CodeFuse-CR-Bench\uff0c\u9996\u4e2a\u9762\u5411\u4ee3\u7801\u5ba1\u67e5\u7684\u7efc\u5408\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b601\u4e2a\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u8986\u76d69\u4e2aPR\u95ee\u9898\u57df\uff0c\u63d0\u4f9b\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u771f\u5b9e\u4ee3\u7801\u5ba1\u67e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\"\u73b0\u5b9e\u5dee\u8ddd\"\uff0c\u4ec5\u8bc4\u4f30\u5b64\u7acb\u5b50\u4efb\u52a1\u4e14\u4f7f\u7528\u7b80\u5316\u6570\u636e\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u5ba1\u67e5\u7684\u5b8c\u6574\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7279\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b601\u4e2a\u5b9e\u4f8b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6765\u81ea70\u4e2aPython\u9879\u76ee\uff0c\u63d0\u4f9b\u95ee\u9898\u3001PR\u8be6\u60c5\u548c\u4ed3\u5e93\u72b6\u6001\u7b49\u4e30\u5bcc\u4e0a\u4e0b\u6587\u3002\u63d0\u51fa\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u5b9a\u4f4d\u548c\u8bed\u6cd5\u68c0\u67e5\u4e0e\u57fa\u4e8e\u6a21\u578b\u7684\u5ba1\u67e5\u8d28\u91cf\u8bc4\u4f30\u7684\u65b0\u6846\u67b6\u3002", "result": "\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bc4\u4f30\u53d1\u73b0\uff1a(1)\u6ca1\u6709\u5355\u4e00LLM\u5728\u6240\u6709CR\u65b9\u9762\u90fd\u5360\u4f18\uff1b(2)Gemini 2.5 Pro\u7efc\u5408\u8868\u73b0\u6700\u4f73\uff1b(3)\u4e0d\u540cLLM\u5bf9\u5197\u4f59\u4e0a\u4e0b\u6587\u7684\u9c81\u68d2\u6027\u4e0d\u540c\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8fdb\u884c\u5168\u9762\u3001\u591a\u7ef4\u5ea6\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u63a8\u8fdb\u771f\u6b63\u667a\u80fd\u4e14\u5b9e\u7528\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624b\u63d0\u4f9b\u4e86\u53ef\u884c\u89c1\u89e3\u3002"}}
{"id": "2509.14899", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14899", "abs": "https://arxiv.org/abs/2509.14899", "authors": ["Amine Barrak", "Yosr Fourati", "Michael Olchawa", "Emna Ksontini", "Khalil Zoghlami"], "title": "CARGO: A Framework for Confidence-Aware Routing of Large Language Models", "comment": null, "summary": "As large language models (LLMs) proliferate in scale, specialization, and\nlatency profiles, the challenge of routing user prompts to the most appropriate\nmodel has become increasingly critical for balancing performance and cost. We\nintroduce CARGO (Category-Aware Routing with Gap-based Optimization), a\nlightweight, confidence-aware framework for dynamic LLM selection. CARGO\nemploys a single embedding-based regressor trained on LLM-judged pairwise\ncomparisons to predict model performance, with an optional binary classifier\ninvoked when predictions are uncertain. This two-stage design enables precise,\ncost-aware routing without the need for human-annotated supervision. To capture\ndomain-specific behavior, CARGO also supports category-specific regressors\ntrained across five task groups: mathematics, coding, reasoning, summarization,\nand creative writing. Evaluated on four competitive LLMs (GPT-4o, Claude 3.5\nSonnet, DeepSeek V3, and Perplexity Sonar), CARGO achieves a top-1 routing\naccuracy of 76.4% and win rates ranging from 72% to 89% against individual\nexperts. These results demonstrate that confidence-guided, lightweight routing\ncan achieve expert-level performance with minimal overhead, offering a\npractical solution for real-world, multi-model LLM deployments.", "AI": {"tldr": "CARGO\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684LLM\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5165\u56de\u5f52\u5668\u548c\u53ef\u9009\u5206\u7c7b\u5668\u5b9e\u73b0\u52a8\u6001\u6a21\u578b\u9009\u62e9\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u5728\u56db\u4e2a\u4e3b\u6d41LLM\u4e0a\u8fbe\u523076.4%\u7684top-1\u8def\u7531\u51c6\u786e\u7387\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c4\u6a21\u3001\u4e13\u4e1a\u5316\u548c\u5ef6\u8fdf\u7279\u6027\u4e0a\u7684\u591a\u6837\u5316\uff0c\u5982\u4f55\u5c06\u7528\u6237\u63d0\u793a\u8def\u7531\u5230\u6700\u5408\u9002\u7684\u6a21\u578b\u4ee5\u5e73\u8861\u6027\u80fd\u548c\u6210\u672c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u56de\u5f52\u5668\u8bad\u7ec3LLM\u5224\u65ad\u7684\u6210\u5bf9\u6bd4\u8f83\u6765\u9884\u6d4b\u6a21\u578b\u6027\u80fd\uff0c\u4e0d\u786e\u5b9a\u65f6\u8c03\u7528\u4e8c\u5143\u5206\u7c7b\u5668\u3002\u652f\u6301\u4e94\u4e2a\u4efb\u52a1\u7c7b\u522b\uff08\u6570\u5b66\u3001\u7f16\u7801\u3001\u63a8\u7406\u3001\u6458\u8981\u3001\u521b\u610f\u5199\u4f5c\uff09\u7684\u7279\u5b9a\u9886\u57df\u56de\u5f52\u5668\u3002", "result": "\u5728GPT-4o\u3001Claude 3.5 Sonnet\u3001DeepSeek V3\u548cPerplexity Sonar\u56db\u4e2a\u6a21\u578b\u4e0a\uff0c\u8fbe\u523076.4%\u7684top-1\u8def\u7531\u51c6\u786e\u7387\uff0c\u5bf9\u6297\u5355\u4e2a\u4e13\u5bb6\u7684\u80dc\u7387\u4e3a72%-89%\u3002", "conclusion": "\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u8f7b\u91cf\u7ea7\u8def\u7531\u80fd\u591f\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\u4e13\u5bb6\u7ea7\u6027\u80fd\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u578bLLM\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14931", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.14931", "abs": "https://arxiv.org/abs/2509.14931", "authors": ["Stefano Fossati", "Damian Andrew Tamburri", "Massimiliano Di Penta", "Marco Tonnarelli"], "title": "\"Let it be Chaos in the Plumbing!\" Usage and Efficacy of Chaos Engineering in DevOps Pipelines", "comment": "To be published in the Proceedings of International Conference on\n  Software Maintenance and Evolution 2025", "summary": "Chaos Engineering (CE) has emerged as a proactive method to improve the\nresilience of modern distributed systems, particularly within DevOps\nenvironments. Originally pioneered by Netflix, CE simulates real-world failures\nto expose weaknesses before they impact production. In this paper, we present a\nsystematic gray literature review that investigates how industry practitioners\nhave adopted and adapted CE principles over recent years. Analyzing 50 sources\npublished between 2019 and early 2024, we developed a comprehensive\nclassification framework that extends the foundational CE principles into ten\ndistinct concepts. Our study reveals that while the core tenets of CE remain\ninfluential, practitioners increasingly emphasize controlled experimentation,\nautomation, and risk mitigation strategies to align with the demands of agile\nand continuously evolving DevOps pipelines. Our results enhance the\nunderstanding of how CE is intended and implemented in practice, and offer\nguidance for future research and industrial applications aimed at improving\nsystem robustness in dynamic production environments.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u7070\u8272\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u4e862019-2024\u5e74\u95f450\u4e2a\u6765\u6e90\uff0c\u5c06\u6df7\u6c8c\u5de5\u7a0b\u57fa\u7840\u539f\u5219\u6269\u5c55\u4e3a10\u4e2a\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u884c\u4e1a\u5b9e\u8df5\u4e2d\u5bf9\u53d7\u63a7\u5b9e\u9a8c\u3001\u81ea\u52a8\u5316\u548c\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u7684\u91cd\u89c6\u3002", "motivation": "\u6df7\u6c8c\u5de5\u7a0b\u5df2\u6210\u4e3a\u63d0\u9ad8\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u5f39\u6027\u7684\u4e3b\u52a8\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u884c\u4e1a\u5b9e\u8df5\u8005\u8fd1\u5e74\u6765\u5982\u4f55\u91c7\u7528\u548c\u8c03\u6574\u6df7\u6c8c\u5de5\u7a0b\u539f\u5219\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u7070\u8272\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u67902019\u5e74\u81f32024\u5e74\u521d\u53d1\u5e03\u768450\u4e2a\u6765\u6e90\uff0c\u5f00\u53d1\u4e86\u5168\u9762\u7684\u5206\u7c7b\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6df7\u6c8c\u5de5\u7a0b\u6838\u5fc3\u539f\u5219\u4ecd\u7136\u5177\u6709\u5f71\u54cd\u529b\uff0c\u4f46\u5b9e\u8df5\u8005\u8d8a\u6765\u8d8a\u5f3a\u8c03\u53d7\u63a7\u5b9e\u9a8c\u3001\u81ea\u52a8\u5316\u548c\u98ce\u9669\u7f13\u89e3\u7b56\u7565\uff0c\u4ee5\u9002\u5e94\u654f\u6377\u548c\u6301\u7eed\u6f14\u8fdb\u7684DevOps\u6d41\u7a0b\u9700\u6c42\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u589e\u5f3a\u4e86\u4eba\u4eec\u5bf9\u6df7\u6c8c\u5de5\u7a0b\u5728\u5b9e\u8df5\u4e2d\u5982\u4f55\u8bbe\u8ba1\u548c\u5b9e\u65bd\u7684\u7406\u89e3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u65e8\u5728\u63d0\u9ad8\u52a8\u6001\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u7cfb\u7edf\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.15195", "categories": ["cs.SE", "cs.AI", "cs.CR", "D.4.6; I.2.2; D.2.5"], "pdf": "https://arxiv.org/pdf/2509.15195", "abs": "https://arxiv.org/abs/2509.15195", "authors": ["Max Bazalii", "Marius Fleischer"], "title": "Orion: Fuzzing Workflow Automation", "comment": "11 pages, 3 figures, 3 tables", "summary": "Fuzz testing is one of the most effective techniques for finding software\nvulnerabilities. While modern fuzzers can generate inputs and monitor\nexecutions automatically, the overall workflow, from analyzing a codebase, to\nconfiguring harnesses, to triaging results, still requires substantial manual\neffort. Prior attempts focused on single stages such as harness synthesis or\ninput minimization, leaving researchers to manually connect the pieces into a\ncomplete fuzzing campaign.\n  We introduce Orion, a framework that automates the the manual bottlenecks of\nfuzzing by integrating LLM reasoning with traditional tools, allowing campaigns\nto scale to settings where human effort alone was impractical. Orion uses LLMs\nfor code reasoning and semantic guidance, while relying on deterministic tools\nfor verification, iterative refinement, and tasks that require precision.\nAcross our benchmark suite, Orion reduces human effort by 46-204x depending on\nthe workflow stage, and we demonstrate its effectiveness through the discovery\nof two previously unknown vulnerabilities in the widely used open-source clib\nlibrary.", "AI": {"tldr": "Orion\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408LLM\u63a8\u7406\u4e0e\u4f20\u7edf\u5de5\u5177\uff0c\u5927\u5e45\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u5728clib\u5e93\u4e2d\u53d1\u73b0\u4e24\u4e2a\u672a\u77e5\u6f0f\u6d1e", "motivation": "\u73b0\u4ee3\u6a21\u7cca\u6d4b\u8bd5\u867d\u7136\u80fd\u81ea\u52a8\u751f\u6210\u8f93\u5165\u548c\u76d1\u63a7\u6267\u884c\uff0c\u4f46\u4ece\u4ee3\u7801\u5e93\u5206\u6790\u3001\u914d\u7f6eharness\u5230\u7ed3\u679c\u5206\u7c7b\u7684\u6574\u4e2a\u5de5\u4f5c\u6d41\u7a0b\u4ecd\u9700\u5927\u91cf\u4eba\u5de5\u64cd\u4f5c\uff0c\u73b0\u6709\u7814\u7a76\u53ea\u5173\u6ce8\u5355\u4e2a\u9636\u6bb5", "method": "Orion\u6846\u67b6\u5c06LLM\u7528\u4e8e\u4ee3\u7801\u63a8\u7406\u548c\u8bed\u4e49\u6307\u5bfc\uff0c\u540c\u65f6\u4f9d\u8d56\u786e\u5b9a\u6027\u5de5\u5177\u8fdb\u884c\u9a8c\u8bc1\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u9700\u8981\u7cbe\u786e\u6027\u7684\u4efb\u52a1", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\uff0cOrion\u5c06\u4eba\u5de5\u5de5\u4f5c\u91cf\u51cf\u5c11\u4e8646-204\u500d\uff08\u53d6\u51b3\u4e8e\u5de5\u4f5c\u6d41\u9636\u6bb5\uff09\uff0c\u5e76\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90clib\u5e93\u4e2d\u53d1\u73b0\u4e24\u4e2a\u5148\u524d\u672a\u77e5\u7684\u6f0f\u6d1e", "conclusion": "Orion\u901a\u8fc7\u6574\u5408LLM\u63a8\u7406\u4e0e\u4f20\u7edf\u5de5\u5177\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u6a21\u7cca\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4eba\u5de5\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u53d1\u73b0\u6548\u7387"}}
