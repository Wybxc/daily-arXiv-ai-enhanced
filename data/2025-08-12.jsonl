{"id": "2508.07779", "categories": ["cs.FL", "68Q45, 52C20, 68U05, 68U10", "F.1.1"], "pdf": "https://arxiv.org/pdf/2508.07779", "abs": "https://arxiv.org/abs/2508.07779", "authors": ["Deepalakshmi D", "Lisa Mathew"], "title": "Hexagonal Picture Scanning Automata", "comment": "9 pages, 2 figures, 2 tables", "summary": "Two new classes of finite automata, called General hexagonal Boustrophedon\nfinite automata and General hexagonal returning finite automata operating on\nhexagonal grids, are introduced and analyzed. The work establishes the\ntheoretical foundations for these automata models, examines their computational\nproperties, and investigates the relationships and equivalences between the\nlanguage families they define. The research contributes to the broader\nunderstanding of two-dimensional automata theory by extending classical finite\nautomaton concepts to hexagonal geometric structures with specialized traversal\npatterns."}
{"id": "2508.07174", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07174", "abs": "https://arxiv.org/abs/2508.07174", "authors": ["Rongshuan Geng", "Wantao Ning"], "title": "On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube", "comment": null, "summary": "Fault diameter and wide diameter are two critical parameters for evaluating\ncommunication performance in interconnection networks. They measure the fault\ntolerance and transmission efficiency of networks. The exchanged 3-ary $n$-cube\nis a recently proposed variant of the hypercube, denoted by $E3C(r, s, t)$. In\nthis work, we obtain that the $(2r + 1)$-fault diameter and $(2r + 2)$-wide\ndiameter of $E3C(r, s, t)$ are bounded between $n + 3$ and $n + 5$ for $1 \\leq\nr \\leq s \\leq t$."}
{"id": "2508.06718", "categories": ["cs.SE", "K.6.3; D.2.7"], "pdf": "https://arxiv.org/pdf/2508.06718", "abs": "https://arxiv.org/abs/2508.06718", "authors": ["Daniel Ogenrwot", "John Businge"], "title": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks", "comment": "12 pages, 3 figures", "summary": "While most forks on platforms like GitHub are short-lived and used for social\ncollaboration, a smaller but impactful subset evolve into long-lived forks,\nreferred to here as variants, that maintain independent development\ntrajectories. Integrating bug-fix patches across such divergent variants poses\nchallenges due to structural drift, including refactorings that rename,\nrelocate, or reorganize code elements and obscure semantic correspondence. This\npaper presents an empirical study of patch integration failures in 14 divergent\npair of variants and introduces RePatch, a refactoring-aware integration system\nfor Java repositories. RePatch extends the RefMerge framework, originally\ndesigned for symmetric merges, by supporting asymmetric patch transfer. RePatch\ninverts refactorings in both the source and target to realign the patch\ncontext, applies the patch, and replays the transformations to preserve the\nintent of the variant. In our evaluation of 478 bug-fix pull requests, Git\ncherry-pick fails in 64.4% of cases due to structural misalignments, while\nRePatch successfully integrates 52.8% of the previously failing patches. These\nresults highlight the limitations of syntax-based tools and the need for\nsemantic reasoning in variant-aware patch propagation."}
{"id": "2508.07855", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.07855", "abs": "https://arxiv.org/abs/2508.07855", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "R. Govind", "Samuel Grahn", "Ramanathan S. Thinniyam"], "title": "Checking Consistency of Event-driven Traces", "comment": null, "summary": "Event-driven programming is a popular paradigm where the flow of execution is\ncontrolled by two features: (1) shared memory and (2) sending and receiving of\nmessages between multiple handler threads (just called handler). Each handler\nhas a mailbox (modelled as a queue) for receiving messages, with the constraint\nthat the handler processes its messages sequentially. Executions of messages by\ndifferent handlers may be interleaved. A central problem in this setting is\nchecking whether a candidate execution is consistent with the semantics of\nevent-driven programs. In this paper, we propose an axiomatic semantics for\neventdriven programs based on the standard notion of traces (also known as\nexecution graphs). We prove the equivalence of axiomatic and operational\nsemantics. This allows us to rephrase the consistency problem axiomatically,\nresulting in the event-driven consistency problem: checking whether a given\ntrace is consistent. We analyze the computational complexity of this problem\nand show that it is NP-complete, even when the number of handler threads is\nbounded. We then identify a tractable fragment: in the absence of nested\nposting, where handlers do not post new messages while processing a message,\nconsistency checking can be performed in polynomial time. Finally, we implement\nour approach in a prototype tool and report on experimental results on a wide\nrange of benchmarks."}
{"id": "2508.07207", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07207", "abs": "https://arxiv.org/abs/2508.07207", "authors": ["S. Akshay", "A. R. Balasubramanian", "Supratik Chakraborty", "Georg Zetzsche"], "title": "Presburger Functional Synthesis: Complexity and Tractable Normal Forms", "comment": "Full version of conference paper at KR 2025 (22nd International\n  Conference on Principles of Knowledge Representation and Reasoning)", "summary": "Given a relational specification between inputs and outputs as a logic\nformula, the problem of functional synthesis is to automatically synthesize a\nfunction from inputs to outputs satisfying the relation. Recently, a rich line\nof work has emerged tackling this problem for specifications in different\ntheories, from Boolean to general first-order logic. In this paper, we launch\nan investigation of this problem for the theory of Presburger Arithmetic, that\nwe call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved\nin EXPTIME and provide a matching exponential lower bound. This is unlike the\ncase for Boolean functional synthesis (BFnS), where only conditional\nexponential lower bounds are known. Further, we show that PFnS for one input\nand one output variable is as hard as BFnS in general. We then identify a\nspecial normal form, called PSyNF, for the specification formula that\nguarantees poly-time and poly-size solvability of PFnS. We prove several\nproperties of PSyNF, including how to check and compile to this form, and\nconditions under which any other form that guarantees poly-time solvability of\nPFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic\nnormal form that is easier to check but is exponentially less succinct than\nPSyNF."}
{"id": "2508.06879", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06879", "abs": "https://arxiv.org/abs/2508.06879", "authors": ["Michael Dorner", "Andreas Bauer", "Darja Å mite", "Lukas Thode", "Daniel Mendez", "Ricardo Britto", "Stephan Lukasczyk", "Ehsan Zabardast", "Michael Kormann"], "title": "Quo Vadis, Code Review? Exploring the Future of Code Review", "comment": null, "summary": "Code review has long been a core practice in collaborative software\nengineering. In this research, we explore how practitioners reflect on code\nreview today and what changes they anticipate in the near future. We then\ndiscuss the potential long-term risks of these anticipated changes for the\nevolution of code review and its role in collaborative software engineering."}
{"id": "2508.07304", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07304", "abs": "https://arxiv.org/abs/2508.07304", "authors": ["Fabio Vitali"], "title": "From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses", "comment": null, "summary": "This paper introduces a new family of cognitive modal logics designed to\nformalize conjectural reasoning: a modal system in which cognitive contexts\nextend known facts with hypothetical assumptions to explore their consequences.\nUnlike traditional doxastic and epistemic systems, conjectural logics rely on a\nprinciple, called Axiom C ($\\varphi \\rightarrow \\Box\\varphi$), that ensures\nthat all established facts are preserved across hypothetical layers. While\nAxiom C was dismissed in the past due to its association with modal collapse,\nwe show that the collapse only arises under classical and bivalent assumptions,\nand specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a\nparacomplete semantic framework, grounded in Weak Kleene logic or Description\nLogic, where undefined propositions coexist with modal assertions. This\nprevents the modal collapse and guarantees a layering to distinguish between\nfactual and conjectural statements. Under this framework we define new modal\nsystems, e.g., KC and KDC, and show that they are complete, decidable, and\nrobust under partial knowledge. Finally, we introduce a dynamic operation,\n$\\mathsf{settle}(\\varphi)$, which formalizes the transition from conjecture to\naccepted fact, capturing the event of the update of a world's cognitive state\nthrough the resolution of uncertainty."}
{"id": "2508.06888", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06888", "abs": "https://arxiv.org/abs/2508.06888", "authors": ["Fanyu Wang", "Chetan Arora", "Yonghui Liu", "Kaicheng Huang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Dishan Sambathkumar", "David Lo"], "title": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs", "comment": null, "summary": "Acceptance criteria (ACs) play a critical role in software development by\nclearly defining the conditions under which a software feature satisfies\nstakeholder expectations. However, manually creating accurate, comprehensive,\nand unambiguous acceptance criteria is challenging, particularly in user\ninterface-intensive applications, due to the reliance on domain-specific\nknowledge and visual context that is not always captured by textual\nrequirements alone. To address these challenges, we propose RAGcceptance M2RE,\na novel approach that leverages Retrieval-Augmented Generation (RAG) to\ngenerate acceptance criteria from multi-modal requirements data, including both\ntextual documentation and visual UI information. We systematically evaluated\nour approach in an industrial case study involving an education-focused\nsoftware system used by approximately 100,000 users. The results indicate that\nintegrating multi-modal information significantly enhances the relevance,\ncorrectness, and comprehensibility of the generated ACs. Moreover, practitioner\nevaluations confirm that our approach effectively reduces manual effort,\ncaptures nuanced stakeholder intent, and provides valuable criteria that domain\nexperts may overlook, demonstrating practical utility and significant potential\nfor industry adoption. This research underscores the potential of multi-modal\nRAG techniques in streamlining software validation processes and improving\ndevelopment efficiency. We also make our implementation and a dataset\navailable."}
{"id": "2508.07742", "categories": ["cs.LO", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.07742", "abs": "https://arxiv.org/abs/2508.07742", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Katsumi Inoue", "Robin Jean"], "title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases", "comment": "This is an extended version of a paper appearing at the 22nd\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2025). 24 pages", "summary": "Repair-based semantics have been extensively studied as a means of obtaining\nmeaningful answers to queries posed over inconsistent knowledge bases (KBs).\nWhile several works have considered how to exploit a priority relation between\nfacts to select optimal repairs, the question of how to specify such\npreferences remains largely unaddressed. This motivates us to introduce a\ndeclarative rule-based framework for specifying and computing a priority\nrelation between conflicting facts. As the expressed preferences may contain\nundesirable cycles, we consider the problem of determining when a set of\npreference rules always yields an acyclic relation, and we also explore a\npragmatic approach that extracts an acyclic relation by applying various cycle\nremoval techniques. Towards an end-to-end system for querying inconsistent KBs,\nwe present a preliminary implementation and experimental evaluation of the\nframework, which employs answer set programming to evaluate the preference\nrules, apply the desired cycle resolution techniques to obtain a priority\nrelation, and answer queries under prioritized-repair semantics."}
{"id": "2508.06926", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06926", "abs": "https://arxiv.org/abs/2508.06926", "authors": ["Feng Luo", "Kexing Ji", "Cuiyun Gao", "Shuzheng Gao", "Jia Feng", "Kui Liu", "Xin Xia", "Michael R. Lyu"], "title": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation", "comment": "Accepted in ICSME 25 Industry Track", "summary": "Automated translation of legacy C code into Rust aims to ensure memory safety\nwhile reducing the burden of manual migration. Early approaches in code\ntranslation rely on static rule-based methods, but they suffer from limited\ncoverage due to dependence on predefined rule patterns. Recent works regard the\ntask as a sequence-to-sequence problem by leveraging large language models\n(LLMs). Although these LLM-based methods are capable of reducing unsafe code\nblocks, the translated code often exhibits issues in following Rust rules and\nmaintaining semantic consistency. On one hand, existing methods adopt a direct\nprompting strategy to translate the C code, which struggles to accommodate the\nsyntactic rules between C and Rust. On the other hand, this strategy makes it\ndifficult for LLMs to accurately capture the semantics of complex code. To\naddress these challenges, we propose IRENE, an LLM-based framework that\nIntegrates RulEs aNd sEmantics to enhance translation. IRENE consists of three\nmodules: 1) a rule-augmented retrieval module that selects relevant translation\nexamples based on rules generated from a static analyzer developed by us,\nthereby improving the handling of Rust rules; 2) a structured summarization\nmodule that produces a structured summary for guiding LLMs to enhance the\nsemantic understanding of C code; 3) an error-driven translation module that\nleverages compiler diagnostics to iteratively refine translations. We evaluate\nIRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial\ndataset provided by Huawei) and eight LLMs, focusing on translation accuracy\nand safety."}
{"id": "2508.07963", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07963", "abs": "https://arxiv.org/abs/2508.07963", "authors": ["Javier Esparza", "Vincent Fischer"], "title": "Runtime Verification for LTL in Stochastic Systems", "comment": null, "summary": "Runtime verification encompasses several lightweight techniques for checking\nwhether a system's current execution satisfies a given specification. We focus\non runtime verification for Linear Temporal Logic (LTL). Previous work\ndescribes monitors which produce, at every time step one of three outputs -\ntrue, false, or inconclusive - depending on whether the observed execution\nprefix definitively determines satisfaction of the formula. However, for many\nLTL formulas, such as liveness properties, satisfaction cannot be concluded\nfrom any finite prefix. For these properties traditional monitors will always\noutput inconclusive. In this work, we propose a novel monitoring approach that\nreplaces hard verdicts with probabilistic predictions and an associated\nconfidence score. Our method guarantees eventual correctness of the prediction\nand ensures that confidence increases without bound from that point on."}
{"id": "2508.06942", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06942", "abs": "https://arxiv.org/abs/2508.06942", "authors": ["Zhenchang Xing", "Yang Liu", "Zhuo Cheng", "Qing Huang", "Dehai Zhao", "Daniel Sun", "Chenhua Liu"], "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction", "comment": null, "summary": "With the growing capabilities of large language models (LLMs), they are\nincreasingly applied in areas like intelligent customer service, code\ngeneration, and knowledge management. Natural language (NL) prompts act as the\n``APIs'' for human-LLM interaction. To improve prompt quality, best practices\nfor prompt engineering (PE) have been developed, including writing guidelines\nand templates. Building on this, we propose Controlled NL for Prompt (CNL-P),\nwhich not only incorporates PE best practices but also draws on key principles\nfrom software engineering (SE). CNL-P introduces precise grammar structures and\nstrict semantic norms, further eliminating NL's ambiguity, allowing for a\ndeclarative but structured and accurate expression of user intent. This helps\nLLMs better interpret and execute the prompts, leading to more consistent and\nhigher-quality outputs. We also introduce an NL2CNL-P conversion tool based on\nLLMs, enabling users to write prompts in NL, which are then transformed into\nCNL-P format, thus lowering the learning curve of CNL-P. In particular, we\ndevelop a linting tool that checks CNL-P prompts for syntactic and semantic\naccuracy, applying static analysis techniques to NL for the first time.\nExtensive experiments demonstrate that CNL-P enhances the quality of LLM\nresponses through the novel and organic synergy of PE and SE. We believe that\nCNL-P can bridge the gap between emerging PE and traditional SE, laying the\nfoundation for a new programming paradigm centered around NL."}
{"id": "2508.07084", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.07084", "abs": "https://arxiv.org/abs/2508.07084", "authors": ["Kaveh Shahedi", "Nana Gyambrah", "Heng Li", "Maxime Lamothe", "Foutse Khomh"], "title": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects", "comment": null, "summary": "Performance is a critical quality attribute in software development, yet the\nimpact of method-level code changes on performance evolution remains poorly\nunderstood. While developers often make intuitive assumptions about which types\nof modifications are likely to cause performance regressions or improvements,\nthese beliefs lack empirical validation at a fine-grained level. We conducted a\nlarge-scale empirical study analyzing performance evolution in 15 mature\nopen-source Java projects hosted on GitHub. Our analysis encompassed 739\ncommits containing 1,499 method-level code changes, using Java Microbenchmark\nHarness (JMH) for precise performance measurement and rigorous statistical\nanalysis to quantify both the significance and magnitude of performance\nvariations. We employed bytecode instrumentation to capture method-specific\nexecution metrics and systematically analyzed four key aspects: temporal\nperformance patterns, code change type correlations, developer and complexity\nfactors, and domain-size interactions. Our findings reveal that 32.7% of\nmethod-level changes result in measurable performance impacts, with regressions\noccurring 1.3 times more frequently than improvements. Contrary to conventional\nwisdom, we found no significant differences in performance impact distributions\nacross code change categories, challenging risk-stratified development\nstrategies. Algorithmic changes demonstrate the highest improvement potential\nbut carry substantial regression risk. Senior developers produce more stable\nchanges with fewer extreme variations, while code complexity correlates with\nincreased regression likelihood. Domain-size interactions reveal significant\npatterns, with web server + small projects exhibiting the highest performance\ninstability. Our study provides empirical evidence for integrating automated\nperformance testing into continuous integration pipelines."}
{"id": "2508.07169", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07169", "abs": "https://arxiv.org/abs/2508.07169", "authors": ["Burak YetiÅtiren", "Hong Jin Kang", "Miryung Kim"], "title": "From Noise to Knowledge: Interactive Summaries for Developer Alerts", "comment": null, "summary": "Programmers using bug-finding tools often review their reported warnings one\nby one. Based on the insight that identifying recurring themes and\nrelationships can enhance the cognitive process of sensemaking, we propose\nCLARITY, which supports interpreting tool-generated warnings through\ninteractive inquiry. CLARITY derives summary rules for custom grouping of\nrelated warnings with active feedback. As users mark warnings as interesting or\nuninteresting, CLARITY's rule inference algorithm surfaces common symptoms,\nhighlighting structural similarities in containment, subtyping, invoked\nmethods, accessed fields, and expressions.\n  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java\nprojects. In a within-subject user study with 14 participants, users\narticulated root causes for similar uninteresting warnings faster and with more\nconfidence using CLARITY. We observed significant individual variation in\ndesired grouping, reinforcing the need for customizable sensemaking. Simulation\nshows that with rule-level feedback, only 11.8 interactions are needed on\naverage to align all inferred rules with a simulated user's labels (vs. 17.8\nwithout). Our evaluation suggests that CLARITY's active learning-based\nsummarization enhances interactive warning sensemaking."}
{"id": "2508.07180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07180", "abs": "https://arxiv.org/abs/2508.07180", "authors": ["Zhe Zhang", "Runlin Liu", "Aishan Liu", "Xingyu Liu", "Xiang Gao", "Hailong Sun"], "title": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes", "comment": null, "summary": "As large language models LLMs) become increasingly integrated into software\ndevelopment workflows, rigorously evaluating their performance on complex,\nreal-world code generation tasks has become essential. However, existing\nbenchmarks often suffer from data contamination and limited test rigor,\nconstraining their ability to reveal model failures effectively. To address\nthese, we present CODE2BENCH, a end-to-end pipeline for dynamically\nconstructing robust and contamination-resistant benchmarks from real-world\nGitHub repositories. Specifically, CODE2BENCH introduces three key innovations:\n(1) Automated Dynamism, achieved through periodic ingestion of recent code to\nminimize training data contamination; (2) Scope Graph-based dependency\nanalysis, which enables structured classification of functions into benchmark\ninstances with controlled dependency levels (distinguishing between\nSelf-Contained (SC) tasks for cross-language evaluation and Weakly\nSelf-Contained (WSC) tasks involving permitted library usage); and (3)\nProperty-Based Testing (PBT) for the automated synthesis of rigorous test\nsuites to enable thorough functional verification. Using this pipeline, we\nconstruct CODE2BENCH-2505, the first benchmark derived from 880 recent Python\nprojects spanning diverse domains, comprising 1,163 code generation tasks with\n100% average branch coverage on ground-truth implementations. Extensive\nevaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently\nstruggle with SC tasks requiring complex, non-standard logic and cross-language\ntransfer, while showing relatively stronger performance on WSC tasks in Python.\nOur work introduces a contamination-resistant, language-agnostic methodology\nfor dynamic benchmark construction, offering a principled foundation for the\ncomprehensive and realistic evaluation of LLMs on real-world software\ndevelopment tasks."}
{"id": "2508.07198", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07198", "abs": "https://arxiv.org/abs/2508.07198", "authors": ["Burak YetiÅtiren", "Hong Jin Kang", "Miryung Kim"], "title": "TraceLens: Question-Driven Debugging for Taint Flow Understanding", "comment": null, "summary": "Taint analysis is a security analysis technique used to track the flow of\npotentially dangerous data through an application and its dependent libraries.\nInvestigating why certain unexpected flows appear and why expected flows are\nmissing is an important sensemaking process during end-user taint analysis.\nExisting taint analysis tools often do not provide this end-user debugging\ncapability, where developers can ask why, why-not, and what-if questions about\ndataflows and reason about the impact of configuring sources and sinks, and\nmodels of 3rd-party libraries that abstract permissible and impermissible data\nflows. Furthermore, a tree-view or a list-view used in existing\ntaint-analyzer's visualization makes it difficult to reason about the global\nimpact on connectivity between multiple sources and sinks.\n  Inspired by the insight that sensemaking tool-generated results can be\nsignificantly improved by a QA inquiry process, we propose TraceLens, a first\nend-user question-answer style debugging interface for taint analysis. It\nenables a user to ask why, why-not, and what-if questions to investigate the\nexistence of suspicious flows, the non-existence of expected flows, and the\nglobal impact of third-party library models. TraceLens performs speculative\nwhat-if analysis, to help a user in debugging how different connectivity\nassumptions affect overall results. A user study with 12 participants shows\nthat participants using TraceLens achieved 21% higher accuracy on average,\ncompared to CodeQL. They also reported a 45% reduction in mental demand\n(NASA-TLX) and rated higher confidence in identifying relevant flows using\nTraceLens."}
{"id": "2508.07371", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07371", "abs": "https://arxiv.org/abs/2508.07371", "authors": ["Yi Zhong", "Hongchao Liu", "Di ZHao"], "title": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation", "comment": "16pages,6figures", "summary": "As the complexity of software systems continues to increase, the demand for\nautomated testing and maintenance tools is growing exponentially. To meet this\nurgent need, we propose a new assertion generation method based on Hardware\nDescription Language (HDL). This method combines a lightweight,\nparameter-adjustable large language model (LLM) with the Unsloth platform to\nautomatically generate test cases, thereby significantly reducing training\ncosts without sacrificing accuracy or generalization performance. Empirical\nevaluation shows that our method can efficiently generate assertions that\nstrictly conform to the hardware logic. This framework provides a robust and\nflexible solution to modern software testing and maintenance challenges.\nhttps://github.com/liusu-orange/AutoAssert-1 and\nhttps://gitee.com/OpenBPU/auto-assert1 are the locations of the source code."}
{"id": "2508.07486", "categories": ["cs.SE", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07486", "abs": "https://arxiv.org/abs/2508.07486", "authors": ["Morteza Ziabakhsh", "Kiyan Rezaee", "Sadegh Eskandari", "Seyed Amir Hossein Tabatabaei", "Mohammad M. Ghassemi"], "title": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering", "comment": null, "summary": "Modern software systems are increasingly shifting from monolithic\narchitectures to microservices to enhance scalability, maintainability, and\ndeployment flexibility. Existing microservice extraction methods typically rely\non hard clustering, assigning each software component to a single microservice.\nThis approach often increases inter-service coupling and reduces intra-service\ncohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a\nframework that formulates microservice extraction as a soft clustering problem,\nallowing components to belong probabilistically to multiple microservices. This\napproach is inspired by expert-driven decompositions, where practitioners\nintentionally replicate certain software components across services to reduce\ncommunication overhead. Mo2oM combines deep semantic embeddings with structural\ndependencies extracted from methodcall graphs to capture both functional and\narchitectural relationships. A graph neural network-based soft clustering\nalgorithm then generates the final set of microservices. We evaluate Mo2oM on\nfour open-source monolithic benchmarks and compare it against eight\nstate-of-the-art baselines. Our results demonstrate that Mo2oM achieves\nimprovements of up to 40.97% in structural modularity (balancing cohesion and\ncoupling), 58% in inter-service call percentage (communication overhead),\n26.16% in interface number (modularity and decoupling), and 38.96% in\nnon-extreme distribution (service size balance) across all benchmarks."}
{"id": "2508.07881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07881", "abs": "https://arxiv.org/abs/2508.07881", "authors": ["Henna Tammia", "Benjamin KÃ¤mÃ¤", "Ella Peltonen"], "title": "Adopting Road-Weather Open Data in Route Recommendation Engine", "comment": null, "summary": "Digitraffic, Finland's open road data interface, provides access to\nnationwide road sensors with more than 2,300 real-time attributes from 1,814\nstations. However, efficiently utilizing such a versatile data API for a\npractical application requires a deeper understanding of the data qualities,\npreprocessing phases, and machine learning tools. This paper discusses the\nchallenges of large-scale road weather and traffic data. We go through the\nroad-weather-related attributes from DigiTraffic as a practical example of\nprocesses required to work with such a dataset. In addition, we provide a\nmethodology for efficient data utilization for the target application, a\npersonalized road recommendation engine based on a simple routing application.\nWe validate our solution based on real-world data, showing we can efficiently\nidentify and recommend personalized routes for three different driver profiles."}
{"id": "2508.07935", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07935", "abs": "https://arxiv.org/abs/2508.07935", "authors": ["Jingwen Zhou", "Jieshan Chen", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows", "comment": null, "summary": "Large Language Model (LLM) agentic systems are software systems powered by\nLLMs that autonomously reason, plan, and execute multi-step workflows to\nachieve human goals, rather than merely executing predefined steps. During\nexecution, these workflows frequently encounter exceptions. Existing exception\nhandling solutions often treat exceptions superficially, failing to trace\nexecution-phase exceptions to their reasoning-phase root causes. Furthermore,\ntheir recovery logic is brittle, lacking structured escalation pathways when\ninitial attempts fail. To tackle these challenges, we first present a\ncomprehensive taxonomy of 36 exception types across 12 agent artifacts.\nBuilding on this, we propose SHIELDA (Structured Handling of Exceptions in\nLLM-Driven Agentic Workflows), a modular runtime exception handling framework\nfor LLM agentic workflows. SHIELDA uses an exception classifier to select a\npredefined exception handling pattern from a handling pattern registry. These\npatterns are then executed via a structured handling executor, comprising local\nhandling, flow control, and state recovery, to enable phase-aware recovery by\nlinking exceptions to their root causes and facilitating composable strategies.\nWe validate SHIELDA's effectiveness through a case study on the AutoPR agent,\ndemonstrating effective, cross-phase recovery from a reasoning-induced\nexception."}
{"id": "2508.07966", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07966", "abs": "https://arxiv.org/abs/2508.07966", "authors": ["Philipp Eibl", "Sadra Sabouri", "Souti Chattopadhyay"], "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "comment": null, "summary": "Recent AI code assistants have significantly improved their ability to\nprocess more complex contexts and generate entire codebases based on a textual\ndescription, compared to the popular snippet-level generation. These codebase\nAI assistants (CBAs) can also extend or adapt codebases, allowing users to\nfocus on higher-level design and deployment decisions. While prior work has\nextensively studied the impact of snippet-level code generation, this new class\nof codebase generation models is relatively unexplored. Despite initial\nanecdotal reports of excitement about these agents, they remain less frequently\nadopted compared to snippet-level code assistants. To utilize CBAs better, we\nneed to understand how developers interact with CBAs, and how and why CBAs fall\nshort of developers' needs. In this paper, we explored these gaps through a\ncounterbalanced user study and interview with (n = 16) students and developers\nworking on coding tasks with CBAs. We found that participants varied the\ninformation in their prompts, like problem description (48% of prompts),\nrequired functionality (98% of prompts), code structure (48% of prompts), and\ntheir prompt writing process. Despite various strategies, the overall\nsatisfaction score with generated codebases remained low (mean = 2.8, median =\n3, on a scale of one to five). Participants mentioned functionality as the most\ncommon factor for dissatisfaction (77% of instances), alongside poor code\nquality (42% of instances) and communication issues (25% of instances). We\ndelve deeper into participants' dissatisfaction to identify six underlying\nchallenges that participants faced when using CBAs, and extracted five barriers\nto incorporating CBAs into their workflows. Finally, we surveyed 21 commercial\nCBAs to compare their capabilities with participant challenges and present\ndesign opportunities for more efficient and useful CBAs."}
{"id": "2508.08171", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08171", "abs": "https://arxiv.org/abs/2508.08171", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C", "comment": "14 pages, 6 tables, 1 figure", "summary": "Python has become the dominant language for general-purpose programming, yet\nit lacks robust tools for formal verification. In contrast, programmers working\nin languages such as C benefit from mature model checkers, for example CBMC,\nwhich enable exhaustive symbolic reasoning and fault localisation. The inherent\ncomplexity of Python, coupled with the verbosity and low-level nature of\nexisting transpilers (e.g., Cython), have historically limited the\napplicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large\nLanguage Models (LLMs) for high-level transpilation from Python to C, followed\nby bounded model checking and MaxSAT-based fault localisation in the generated\nC code. PyVeritas enables verification and bug localisation for Python code\nusing existing model checking tools for C. Our empirical evaluation on two\nPython benchmarks demonstrates that LLM-based transpilation can achieve a high\ndegree of accuracy, up to 80--90% for some LLMs, enabling effective development\nenvironment that supports assertion-based verification and interpretable fault\ndiagnosis for small yet non-trivial Python programs."}
