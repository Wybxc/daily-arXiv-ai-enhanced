{"id": "2509.13078", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2509.13078", "abs": "https://arxiv.org/abs/2509.13078", "authors": ["Daichi Aiba", "Masaki Waga", "Hiroya Fujinami", "Koko Muroya", "Shutaro Ouchi", "Naoki Ueda", "Yosuke Yokoyama", "Yuta Wada", "Ichiro Hasuo"], "title": "A Variety of Request-Response Specifications", "comment": "ICTAC 2025", "summary": "We find, motivated by real-world applications, that the well-known\nrequest-response specification comes with multiple variations, and that these\nvariations should be distinguished. As the first main contribution, we\nintroduce a classification of those variations into six types, and present it\nas a decision tree, where a user is led to the type that is suited for their\napplication by answering a couple of questions. Our second main contribution is\nthe formalization of those six types in various formalisms such as temporal\nlogics, grammars, and automata; here, two types out of the six are non-regular\nspecifications and their formalization requires extended formalisms. We also\nsurvey tools for monitoring these specifications to cater for practitioners'\nneeds."}
{"id": "2509.12337", "categories": ["cs.LO", "cs.FL", "math.LO", "03D10, 03B35 (Primary) 68Q05, 68Q45 (Secondary)", "F.1.1; F.4.1; I.2.3; D.2.4; F.4.3"], "pdf": "https://arxiv.org/pdf/2509.12337", "abs": "https://arxiv.org/abs/2509.12337", "authors": ["The bbchallenge Collaboration", "Justin Blanchard", "Daniel Briggs", "Konrad Deka", "Nathan Fenner", "Yannick Forster", "Georgi Georgiev", "Matthew L. House", "Rachel Hunter", "Iijil", "Maja Kądziołka", "Pavel Kropitz", "Shawn Ligocki", "mxdys", "Mateusz Naściszewski", "savask", "Tristan Stérin", "Chris Xu", "Jason Yuen", "Théo Zimmermann"], "title": "Determination of the fifth Busy Beaver value", "comment": "48 pages, 17 figures", "summary": "We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy\nBeaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol\nTuring machine can perform from the all-zero tape before halting, and $S$ was\nhistorically introduced by Tibor Rad\\'o in 1962 as one of the simplest examples\nof an uncomputable function. The proof enumerates $181,385,789$ Turing machines\nwith 5 states and, for each machine, decides whether it halts or not. Our\nresult marks the first determination of a new Busy Beaver value in over 40\nyears and the first Busy Beaver value ever to be formally verified, attesting\nto the effectiveness of massively collaborative online research\n(bbchallenge$.$org)."}
{"id": "2509.12593", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.12593", "abs": "https://arxiv.org/abs/2509.12593", "authors": ["Yimin Zhang", "Mario de Sousa"], "title": "Converting IEC 61131-3 LD into SFC Using Large Language Model: Dataset and Testing", "comment": null, "summary": "In the domain of Programmable Logic Controller (PLC) programming, converting\na Ladder Diagram (LD) into a Sequential Function Chart (SFC) is an inherently\nchallenging problem, primarily due to the lack of domain-specific knowledge and\nthe issue of state explosion in existing algorithms. However, the rapid\ndevelopment of Artificial Intelligence (AI) - especially Large Language Model\n(LLM) - offers a promising new approach.\n  Despite this potential, data-driven approaches in this field have been\nhindered by a lack of suitable datasets. To address this gap, we constructed\nseveral datasets consisting of paired textual representations of SFC and LD\nprograms that conform to the IEC 61131-3 standard.\n  Based on these datasets, we explored the feasibility of automating the LD-SFC\nconversion using LLM. Our preliminary experiments show that a fine-tuned LLM\nmodel achieves up to 91% accuracy on certain dataset, with the lowest observed\naccuracy being 79%, suggesting that with proper training and representation,\nLLMs can effectively support LD-SFC conversion. These early results highlight\nthe viability and future potential of this approach."}
{"id": "2509.12395", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12395", "abs": "https://arxiv.org/abs/2509.12395", "authors": ["Yash Mundhra", "Max Valk", "Maliheh Izadi"], "title": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML", "comment": "Accepted in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering, ASE 2025 (Industry track)", "summary": "Large language models have shown impressive performance in various domains,\nincluding code generation across diverse open-source domains. However, their\napplicability in proprietary industrial settings, where domain-specific\nconstraints and code interdependencies are prevalent, remains largely\nunexplored. We present a case study conducted in collaboration with the\nleveling department at ASML to investigate the performance of LLMs in\ngenerating functional, maintainable code within a closed, highly specialized\nsoftware environment.\n  We developed an evaluation framework tailored to ASML's proprietary codebase\nand introduced a new benchmark. Additionally, we proposed a new evaluation\nmetric, build@k, to assess whether LLM-generated code successfully compiles and\nintegrates within real industrial repositories. We investigate various\nprompting techniques, compare the performance of generic and code-specific\nLLMs, and examine the impact of model size on code generation capabilities,\nusing both match-based and execution-based metrics. The findings reveal that\nprompting techniques and model size have a significant impact on output\nquality, with few-shot and chain-of-thought prompting yielding the highest\nbuild success rates. The difference in performance between the code-specific\nLLMs and generic LLMs was less pronounced and varied substantially across\ndifferent model families."}
{"id": "2509.13006", "categories": ["cs.PL", "cs.MS", "math.OC", "90C05, 90c06, 90c10", "D.3.4; G.4"], "pdf": "https://arxiv.org/pdf/2509.13006", "abs": "https://arxiv.org/abs/2509.13006", "authors": ["Shermin Khosravi", "David Bremner"], "title": "Efficient Compilation of Algorithms into Compact Linear Programs", "comment": "Preliminary version will appear in CASCON 2025", "summary": "Linear Programming (LP) is widely applied in industry and is a key component\nof various other mathematical problem-solving techniques. Recent work\nintroduced an LP compiler translating polynomial-time, polynomial-space\nalgorithms into polynomial-size LPs using intuitive high-level programming\nlanguages, offering a promising alternative to manually specifying each set of\nconstraints through Algebraic Modeling Languages (AMLs). However, the resulting\nLPs, while polynomial in size, are often extremely large, posing challenges for\nexisting LP solvers. In this paper, we propose a novel approach for generating\nsubstantially smaller LPs from algorithms. Our goal is to establish\nminimum-size compact LP formulations for problems in P having natural\nformulations with exponential extension complexities. Our broader vision is to\nenable the systematic generation of Compact Integer Programming (CIP)\nformulations for problems with exponential-size IPs having polynomial-time\nseparation oracles. To this end, we introduce a hierarchical linear pipelining\ntechnique that decomposes nested program structures into synchronized regions\nwith well-defined execution transitions -- functions of compile-time\nparameters. This decomposition allows us to localize LP constraints and\nvariables within each region, significantly reducing LP size without the loss\nof generality, ensuring the resulting LP remains valid for all inputs of size\n$n$. We demonstrate the effectiveness of our method on two benchmark problems\n-- the makespan problem, which has exponential extension complexity, and the\nweighted minimum spanning tree problem -- both of which have exponential-size\nnatural LPs. Our results show up to a $25$-fold reduction in LP size and\nsubstantial improvements in solver performance across both commercial and\nnon-commercial LP solvers."}
{"id": "2509.12421", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12421", "abs": "https://arxiv.org/abs/2509.12421", "authors": ["Hao Li", "Hicham Masri", "Filipe R. Cogo", "Abdul Ali Bangash", "Bram Adams", "Ahmed E. Hassan"], "title": "Understanding Prompt Management in GitHub Repositories: A Call for Best Practices", "comment": null, "summary": "The rapid adoption of foundation models (e.g., large language models) has\ngiven rise to promptware, i.e., software built using natural language prompts.\nEffective management of prompts, such as organization and quality assurance, is\nessential yet challenging. In this study, we perform an empirical analysis of\n24,800 open-source prompts from 92 GitHub repositories to investigate prompt\nmanagement practices and quality attributes. Our findings reveal critical\nchallenges such as considerable inconsistencies in prompt formatting,\nsubstantial internal and external prompt duplication, and frequent readability\nand spelling issues. Based on these findings, we provide actionable\nrecommendations for developers to enhance the usability and maintainability of\nopen-source prompts within the rapidly evolving promptware ecosystem."}
{"id": "2509.13019", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13019", "abs": "https://arxiv.org/abs/2509.13019", "authors": ["Frédéric Fort", "David Nowak", "Vlad Rusu"], "title": "Pleasant Imperative Program Proofs with GallinaC", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Even with the increase of popularity of functional programming, imperative\nprogramming remains a key programming paradigm, especially for programs\noperating at lower levels of abstraction. When such software offers key\ncomponents of a Trusted Computing Base (TCB), e.g. an operating system kernel,\nit becomes desirable to provide mathematical correctness proofs.\n  However, current real-world imperative programming languages possess\n\"expressive\", i.e. overly permissive, semantics. Thus, producing correctness\nproofs of such programs becomes tedious and error-prone, requiring to take care\nof numerous \"administrative\" details. Ideally, a proof-oriented imperative\nlanguage should feature well-behaved semantics while allowing imperative\nidioms.\n  To obtain a high-degree of confidence in the correctness of such a language,\nits tools should be developed inside a proof-assistant such that program proofs\nare machine checked.\n  We present GallinaC, a shallow embedding of a Turing-complete imperative\nlanguage directly inside the functional programming language of the Rocq proof\nassistant, Gallina. In particular, it features a truly generic and unbounded\nwhile loop. Having a functional core means proofs about GallinaC programs may\nuse the same tactics as proofs about pure functional ones.\n  Work on GallinaC is still under progress, but we present first promising\nresults. A prototype implementation has shown the viability of GallinaC with\nthe correctness proof of a list reversal procedure for linked-lists of unknown\nsize. We currently focus on the forward simulation between the GallinaC\nintermediate representation (IR) and Cminor, the entry language of the CompCert\nback-end."}
{"id": "2509.12443", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12443", "abs": "https://arxiv.org/abs/2509.12443", "authors": ["Sparsh Gupta", "Kamalavasan Kamalakkannan", "Maxim Moraru", "Galen Shipman", "Patrick Diehl"], "title": "From Legacy Fortran to Portable Kokkos:An Autonomous Agentic AI Workflow", "comment": null, "summary": "Scientific applications continue to rely on legacy Fortran codebases\noriginally developed for homogeneous, CPU-based systems. As High-Performance\nComputing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many\naccelerators lack native Fortran bindings, creating an urgent need to modernize\nlegacy codes for portability. Frameworks like Kokkos provide performance\nportability and a single-source C++ abstraction, but manual Fortran-to-Kokkos\nporting demands significant expertise and time. Large language models (LLMs)\nhave shown promise in source-to-source code generation, yet their use in fully\nautonomous workflows for translating and optimizing parallel code remains\nlargely unexplored, especially for performance portability across diverse\nhardware.\n  This paper presents an agentic AI workflow where specialized LLM \"agents\"\ncollaborate to translate, validate, compile, run, test, debug, and optimize\nFortran kernels into portable Kokkos C++ programs. Results show the pipeline\nmodernizes a range of benchmark kernels, producing performance-portable Kokkos\ncodes across hardware partitions. Paid OpenAI models such as GPT-5 and\no4-mini-high executed the workflow for only a few U.S. dollars, generating\noptimized codes that surpassed Fortran baselines, whereas open-source models\nlike Llama4-Maverick often failed to yield functional codes.\n  This work demonstrates the feasibility of agentic AI for Fortran-to-Kokkos\ntransformation and offers a pathway for autonomously modernizing legacy\nscientific applications to run portably and efficiently on diverse\nsupercomputers. It further highlights the potential of LLM-driven agentic\nsystems to perform structured, domain-specific reasoning tasks in scientific\nand systems-oriented applications."}
{"id": "2509.13022", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.13022", "abs": "https://arxiv.org/abs/2509.13022", "authors": ["Andrei Nacu", "Dorel Lucanu"], "title": "Navigating the Python Type Jungle", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Python's typing system has evolved pragmatically into a powerful but\ntheoretically fragmented system, with scattered specifications. This paper\nproposes a formalization to address this fragmentation. The central\ncontribution is a formal foundation that uses concepts from type theory to\ndemonstrate that Python's type system can be elegantly described. This work\naims to serve as a crucial first step toward the future development of type\ninference tools."}
{"id": "2509.12466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12466", "abs": "https://arxiv.org/abs/2509.12466", "authors": ["Satwik Ghanta", "Peggy Gregory", "Gul Calikli"], "title": "Perspectives, Needs and Challenges for Sustainable Software Engineering Teams: A FinServ Case Study", "comment": null, "summary": "Sustainable Software Engineering (SSE) is slowly becoming an industry need\nfor reasons including reputation enhancement, improved profits and more\nefficient practices. However, SSE has many definitions, and this is a challenge\nfor organisations trying to build a common and broadly agreed understanding of\nthe term. Although much research effort has gone into identifying general SSE\npractices, there is a gap in understanding the sustainability needs of specific\norganisational contexts, such as financial services, which are highly\ndata-driven, operate under strict regulatory requirements, and handle millions\nof transactions day to day. To address this gap, our research focuses on a\nfinancial services company (FinServCo) that invited us to investigate\nperceptions of sustainability in their IT function: how it could be put into\npractice, who is responsible for it, and what the challenges are. We conducted\nan exploratory qualitative case study using interviews and a focus group with\nsix higher management employees and 16 software engineers comprising various\nexperience levels from junior developers to team leaders. Our study found a\nclear divergence in how sustainability is perceived between organisational\nlevels. Higher management emphasised technical and economic sustainability,\nfocusing on cloud migration and business continuity through data availability.\nIn contrast, developers highlighted human-centric concerns such as workload\nmanagement and stress reduction. Scepticism toward organisational initiatives\nwas also evident, with some developers viewing them as a PR strategy. Many\nparticipants expressed a preference for a dedicated sustainability team,\ndrawing analogies to internal structures for security governance. The\ndisconnect between organisational goals and individual developer needs\nhighlights the importance of context-sensitive, co-designed interventions."}
{"id": "2509.12337", "categories": ["cs.LO", "cs.FL", "math.LO", "03D10, 03B35 (Primary) 68Q05, 68Q45 (Secondary)", "F.1.1; F.4.1; I.2.3; D.2.4; F.4.3"], "pdf": "https://arxiv.org/pdf/2509.12337", "abs": "https://arxiv.org/abs/2509.12337", "authors": ["The bbchallenge Collaboration", "Justin Blanchard", "Daniel Briggs", "Konrad Deka", "Nathan Fenner", "Yannick Forster", "Georgi Georgiev", "Matthew L. House", "Rachel Hunter", "Iijil", "Maja Kądziołka", "Pavel Kropitz", "Shawn Ligocki", "mxdys", "Mateusz Naściszewski", "savask", "Tristan Stérin", "Chris Xu", "Jason Yuen", "Théo Zimmermann"], "title": "Determination of the fifth Busy Beaver value", "comment": "48 pages, 17 figures", "summary": "We prove that $S(5) = 47,176,870$ using the Coq proof assistant. The Busy\nBeaver value $S(n)$ is the maximum number of steps that an $n$-state 2-symbol\nTuring machine can perform from the all-zero tape before halting, and $S$ was\nhistorically introduced by Tibor Rad\\'o in 1962 as one of the simplest examples\nof an uncomputable function. The proof enumerates $181,385,789$ Turing machines\nwith 5 states and, for each machine, decides whether it halts or not. Our\nresult marks the first determination of a new Busy Beaver value in over 40\nyears and the first Busy Beaver value ever to be formally verified, attesting\nto the effectiveness of massively collaborative online research\n(bbchallenge$.$org)."}
{"id": "2509.13128", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13128", "abs": "https://arxiv.org/abs/2509.13128", "authors": ["Raphaël Monat"], "title": "Try-Mopsa: Relational Static Analysis in Your Pocket", "comment": null, "summary": "Static analyzers are complex pieces of software with large dependencies. They\ncan be difficult to install, which hinders adoption and creates barriers for\nstudents learning static analysis. This work introduces Try-Mopsa: a\nscaled-down version of the Mopsa static analysis platform, compiled into\nJavaScript to run purely as a client-side application in web browsers.\nTry-Mopsa provides a responsive interface that works on both desktop and mobile\ndevices. Try-Mopsa features all the core components of Mopsa. In particular, it\nsupports relational numerical domains. We present the interface, changes and\nadaptations required to have a pure JavaScript version of Mopsa. We envision\nTry-Mopsa as a convenient platform for onboarding or teaching purposes."}
{"id": "2509.12491", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12491", "abs": "https://arxiv.org/abs/2509.12491", "authors": ["Veronica Pimenova", "Sarah Fakhoury", "Christian Bird", "Margaret-Anne Storey", "Madeline Endres"], "title": "Good Vibrations? A Qualitative Study of Co-Creation, Communication, Flow, and Trust in Vibe Coding", "comment": "19 pages, 2 figures", "summary": "Vibe coding, a term coined by Andrej Karpathy in February 2025, has quickly\nbecome a compelling and controversial natural language programming paradigm in\nAI-assisted software development. Centered on iterative co-design with an AI\nassistant, vibe coding emphasizes flow and experimentation over strict upfront\nspecification. While initial studies have begun to explore this paradigm, most\nfocus on analyzing code artifacts or proposing theories with limited empirical\nbacking. There remains a need for a grounded understanding of vibe coding as it\nis perceived and experienced by developers. We present the first systematic\nqualitative investigation of vibe coding perceptions and practice. Drawing on\nover 190,000 words from semi-structured interviews, Reddit threads, and\nLinkedIn posts, we characterize what vibe coding is, why and how developers use\nit, where it breaks down, and which emerging practices aim to support it. We\npropose a qualitatively grounded theory of vibe coding centered on\nconversational interaction with AI, co-creation, and developer flow and joy. We\nfind that AI trust regulates movement along a continuum from delegation to\nco-creation and supports the developer experience by sustaining flow. We\nsurface recurring pain points and risks in areas including specification,\nreliability, debugging, latency, code review burden, and collaboration. We also\npresent best practices that have been discovered and shared to mitigate these\nchallenges. We conclude with implications for the future of AI dev tools and\ndirections for researchers investigating vibe coding."}
{"id": "2509.12968", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.12968", "abs": "https://arxiv.org/abs/2509.12968", "authors": ["Marta Kwiatkowska", "Gethin Norman", "David Parker"], "title": "Probabilistic Model Checking: Applications and Trends", "comment": null, "summary": "Probabilistic model checking is an approach to the formal modelling and\nanalysis of stochastic systems. Over the past twenty five years, the number of\ndifferent formalisms and techniques developed in this field has grown\nconsiderably, as has the range of problems to which it has been applied. In\nthis paper, we identify the main application domains in which probabilistic\nmodel checking has proved valuable and discuss how these have evolved over\ntime. We summarise the key strands of the underlying theory and technologies\nthat have contributed to these advances, and highlight examples which\nillustrate the benefits that probabilistic model checking can bring. The aim is\nto inform potential users of these techniques and to guide future developments\nin the field."}
{"id": "2509.13261", "categories": ["cs.PL", "D.3.4"], "pdf": "https://arxiv.org/pdf/2509.13261", "abs": "https://arxiv.org/abs/2509.13261", "authors": ["Noé De Santo", "Stephanie Weirich"], "title": "Rebound: Efficient, Expressive, and Well-Scoped Binding", "comment": "15 pages, 5 figures, 3 tables. To be published in Proceedings of the\n  18th ACM SIGPLAN International Haskell Symposium (Haskell 2025)", "summary": "We introduce the Rebound library that supports well-scoped term\nrepresentations in Haskell and automates the definition of substitution,\nalpha-equivalence, and other operations that work with binding structures. The\nkey idea of our design is the use of first-class environments that map\nvariables to expressions in some new scope. By statically tracking scopes,\nusers of this library gain confidence that they have correctly maintained the\nsubtle invariants that stem from using de Bruijn indices. Behind the scenes,\nRebound uses environments to optimize the application of substitutions, while\nproviding explicit access to these data structures when desired. We demonstrate\nthat this library is expressive by using it to implement a wide range of\nlanguage features with sophisticated uses of binding and several different\noperations that use this abstract syntax. Our examples include pi-forall, a\ntutorial implementation of a type checker for a dependently-typed programming\nlanguage. Finally, we benchmark Rebound to understand its performance\ncharacteristics and find that it produces faster code than competing libraries."}
{"id": "2509.12629", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12629", "abs": "https://arxiv.org/abs/2509.12629", "authors": ["Zhihong Sun", "Jia Li", "Yao Wan", "Chuanyi Li", "Hongyu Zhang", "Zhi jin", "Ge Li", "Hong Liu", "Chen Lyu", "Songlin Hu"], "title": "Ensembling Large Language Models for Code Vulnerability Detection: An Empirical Evaluation", "comment": "24 pages", "summary": "Code vulnerability detection is crucial for ensuring the security and\nreliability of modern software systems. Recently, Large Language Models (LLMs)\nhave shown promising capabilities in this domain. However, notable\ndiscrepancies in detection results often arise when analyzing identical code\nsegments across different training stages of the same model or among\narchitecturally distinct LLMs. While such inconsistencies may compromise\ndetection stability, they also highlight a key opportunity: the latent\ncomplementarity among models can be harnessed through ensemble learning to\ncreate more robust vulnerability detection systems. In this study, we explore\nthe potential of ensemble learning to enhance the performance of LLMs in source\ncode vulnerability detection. We conduct comprehensive experiments involving\nfive LLMs (i.e., DeepSeek-Coder-6.7B, CodeLlama-7B, CodeLlama-13B,\nCodeQwen1.5-7B, and StarCoder2-15B), using three ensemble strategies (i.e.,\nBagging, Boosting, and Stacking). These experiments are carried out across\nthree widely adopted datasets (i.e., Devign, ReVeal, and BigVul). Inspired by\nMixture of Experts (MoE) techniques, we further propose Dynamic Gated Stacking\n(DGS), a Stacking variant tailored for vulnerability detection. Our results\ndemonstrate that ensemble approaches can significantly improve detection\nperformance, with Boosting excelling in scenarios involving imbalanced\ndatasets. Moreover, DGS consistently outperforms traditional Stacking,\nparticularly in handling class imbalance and multi-class classification tasks.\nThese findings offer valuable insights into building more reliable and\neffective LLM-based vulnerability detection systems through ensemble learning."}
{"id": "2509.13018", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2509.13018", "abs": "https://arxiv.org/abs/2509.13018", "authors": ["Ádám Kurucz", "Péter Bereczky", "Dániel Horpácsi"], "title": "On a Dependently Typed Encoding of Matching Logic", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Matching logic is a general formal framework for reasoning about a wide range\nof theories, with particular emphasis on programming language semantics.\nNotably, the intermediate language of the K semantics framework is an extension\nof matching $\\mu$-logic, a sorted, polyadic variant of the logic. Metatheoretic\nreasoning requires the logic to be expressed within a foundational theory;\nopting for a dependently typed one enables well-sortedness in the object theory\nto correspond directly to well-typedness in the host theory. In this paper, we\npresent the first dependently typed definition of matching $\\mu$-logic,\nensuring well-sortedness via sorted contexts encoded in type indices. As a\nresult, ill-sorted syntax elements are unrepresentable, and the semantics of\nwell-sorted elements are guaranteed to lie within the domain of their\nassociated sort."}
{"id": "2509.13026", "categories": ["cs.LO", "cs.PL", "math.CT"], "pdf": "https://arxiv.org/pdf/2509.13026", "abs": "https://arxiv.org/abs/2509.13026", "authors": ["Adriana Balan", "Silviu-George Pantelimon"], "title": "The Hidden Strength of Costrong Functors", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Strong functors and monads are ubiquitous in Computer Science. More recently,\ncomonads have demonstrated their use in structuring context-dependent notions\nof computation. However, the dualisation of ``being strong'' property passed\nsomehow unobserved so far. We argue that ``being costrong'' gives a different\nunderstanding of how functors can interact with monoidal structures. This work\nin progress aims to explore costrong functors and their natural properties,\nwith an eye towards the semantics of computations."}
{"id": "2509.12795", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12795", "abs": "https://arxiv.org/abs/2509.12795", "authors": ["Yihua Chen", "Xingle Que", "Jiashuo Zhang", "Ting Chen", "Guangshun Li", "Jiachi Chen"], "title": "When Large Language Models Meet UAVs: How Far Are We?", "comment": null, "summary": "The integration of unmanned aerial vehicles (UAVs) and large language models\n(LLMs) has emerged as a research direction of growing interest, with the\npotential to address challenges in autonomous decision-making, human-UAV\ninteraction, and real-time adaptability. However, existing studies have\nremained largely in preliminary exploration with a limited understanding of\nreal-world practice, risking a misalignment between academic research and\npractical needs and hindering the translation of results. To examine and\naddress these potential challenges, we conducted an empirical study of 74\nselected papers and 56 public GitHub projects, identified nine task types for\nLLMs in UAV systems, and quantified their distribution. Our findings show that\nacademic research emphasizes theoretical modeling and task optimization with\ndispersed attention across tasks. In contrast, industrial projects focus on\nflight control, task planning, and human-machine interaction, prioritizing\noperability and efficiency. To further capture industry perspectives, we\ndistributed an online questionnaire. We obtained 52 valid responses: 40.4% of\npractitioners have attempted to apply LLMs to UAV tasks. We further identify\nfactors that impede real-world integration, including technological maturity,\nperformance, safety, cost, and other considerations. Finally, we highlight\nchallenges for future development and provide recommendations."}
{"id": "2509.13020", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13020", "abs": "https://arxiv.org/abs/2509.13020", "authors": ["Ioana Leuştean", "Bogdan Macovei"], "title": "Łukasiewicz Logic with Actions for Neural Networks training", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Based on the already known connection between multilayer perceptrons and\nLukasiewicz logic with rational coefficients, we take a step forward in\nanalyzing its training process using a three-sorted hybrid modal logic: a\nmultilayer perceptron is a logical formula; the actions of the training process\nare modal operators; the training process is a sequence of logical deductions.\nUsing the proof assistant and the programming language Lean 4, the algorithmic\nimplementation of the training process is certified by logical proofs."}
{"id": "2509.12798", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.12798", "abs": "https://arxiv.org/abs/2509.12798", "authors": ["Nenad Petrovic", "Lukasz Mazur", "Alois Knoll"], "title": "LLM-Based Approach for Enhancing Maintainability of Automotive Architectures", "comment": null, "summary": "There are many bottlenecks that decrease the flexibility of automotive\nsystems, making their long-term maintenance, as well as updates and extensions\nin later lifecycle phases increasingly difficult, mainly due to long\nre-engineering, standardization, and compliance procedures, as well as\nheterogeneity and numerosity of devices and underlying software components\ninvolved. In this paper, we explore the potential of Large Language Models\n(LLMs) when it comes to the automation of tasks and processes that aim to\nincrease the flexibility of automotive systems. Three case studies towards\nachieving this goal are considered as outcomes of early-stage research: 1)\nupdates, hardware abstraction, and compliance, 2) interface compatibility\nchecking, and 3) architecture modification suggestions. For proof-of-concept\nimplementation, we rely on OpenAI's GPT-4o model."}
{"id": "2509.13026", "categories": ["cs.LO", "cs.PL", "math.CT"], "pdf": "https://arxiv.org/pdf/2509.13026", "abs": "https://arxiv.org/abs/2509.13026", "authors": ["Adriana Balan", "Silviu-George Pantelimon"], "title": "The Hidden Strength of Costrong Functors", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Strong functors and monads are ubiquitous in Computer Science. More recently,\ncomonads have demonstrated their use in structuring context-dependent notions\nof computation. However, the dualisation of ``being strong'' property passed\nsomehow unobserved so far. We argue that ``being costrong'' gives a different\nunderstanding of how functors can interact with monoidal structures. This work\nin progress aims to explore costrong functors and their natural properties,\nwith an eye towards the semantics of computations."}
{"id": "2509.12809", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12809", "abs": "https://arxiv.org/abs/2509.12809", "authors": ["Jinfeng Wen", "Jianshu Zhao", "Zixi Zhu", "Xiaomin Zhang", "Qi Liang", "Ao Zhou", "Shangguang Wang"], "title": "SateLight: A Satellite Application Update Framework for Satellite Computing", "comment": "This paper has been accepted for publication in ASE 2025!", "summary": "Satellite computing is an emerging paradigm that empowers satellites to\nperform onboard processing tasks (i.e., \\textit{satellite applications}),\nthereby reducing reliance on ground-based systems and improving responsiveness.\nHowever, enabling application software updates in this context remains a\nfundamental challenge due to application heterogeneity, limited\nground-to-satellite bandwidth, and harsh space conditions. Existing software\nupdate approaches, designed primarily for terrestrial systems, fail to address\nthese constraints, as they assume abundant computational capacity and stable\nconnectivity.\n  To address this gap, we propose SateLight, a practical and effective\nsatellite application update framework tailored for satellite computing.\nSateLight leverages containerization to encapsulate heterogeneous applications,\nenabling efficient deployment and maintenance. SateLight further integrates\nthree capabilities: (1) a content-aware differential strategy that minimizes\ncommunication data volume, (2) a fine-grained onboard update design that\nreconstructs target applications, and (3) a layer-based fault-tolerant recovery\nmechanism to ensure reliability under failure-prone space conditions.\nExperimental results on a satellite simulation environment with 10\nrepresentative satellite applications demonstrate that SateLight reduces\ntransmission latency by up to 91.18% (average 56.54%) compared to the best\ncurrently available baseline. It also consistently ensures 100% update\ncorrectness across all evaluated applications. Furthermore, a case study on a\nreal-world in-orbit satellite demonstrates the practicality of our approach."}
{"id": "2509.13038", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13038", "abs": "https://arxiv.org/abs/2509.13038", "authors": ["Philippe Balbiani"], "title": "Intuitionistic modal logics: epistemic reasoning with distributed knowledge", "comment": null, "summary": "In this article, we add a diamond to the parametrized box-based propositional\nlanguage of intuitionistic doxastic logic and intuitionistic epistemic logic\nintroduced by Artemov and Protopopescu. The main results of this article are\nthe proofs of completeness with respect to their appropriate relational\nsemantics of the resulting intuitionistic doxastic logic and intuitionistic\nepistemic logic with distributed knowledge."}
{"id": "2509.12973", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.12973", "abs": "https://arxiv.org/abs/2509.12973", "authors": ["Aamer Aljagthami", "Mohammed Banabila", "Musab Alshehri", "Mohammed Kabini", "Mohammad D. Alahmadi"], "title": "Evaluating Large Language Models for Code Translation: Effects of Prompt Language and Prompt Design", "comment": null, "summary": "Large language models (LLMs) have shown promise for automated source-code\ntranslation, a capability critical to software migration, maintenance, and\ninteroperability. Yet comparative evidence on how model choice, prompt design,\nand prompt language shape translation quality across multiple programming\nlanguages remains limited. This study conducts a systematic empirical\nassessment of state-of-the-art LLMs for code translation among C++, Java,\nPython, and C#, alongside a traditional baseline (TransCoder). Using BLEU and\nCodeBLEU, we quantify syntactic fidelity and structural correctness under two\nprompt styles (concise instruction and detailed specification) and two prompt\nlanguages (English and Arabic), with direction-aware evaluation across language\npairs. Experiments show that detailed prompts deliver consistent gains across\nmodels and translation directions, and English prompts outperform Arabic by\n13-15%. The top-performing model attains the highest CodeBLEU on challenging\npairs such as Java to C# and Python to C++. Our evaluation shows that each LLM\noutperforms TransCoder across the benchmark. These results demonstrate the\nvalue of careful prompt engineering and prompt language choice, and provide\npractical guidance for software modernization and cross-language\ninteroperability."}
{"id": "2509.13059", "categories": ["cs.LO", "68P05, 03G10, 03B52"], "pdf": "https://arxiv.org/pdf/2509.13059", "abs": "https://arxiv.org/abs/2509.13059", "authors": ["Yuxu Chen", "Jing Liu", "Lili Shen", "Xiaoye Tang"], "title": "Reducts of fuzzy contexts: Formal concept analysis vs. rough set theory", "comment": "17 pages", "summary": "We postulate the intuitive idea of reducts of fuzzy contexts based on formal\nconcept analysis and rough set theory. For a complete residuated lattice $L$,\nit is shown that reducts of $L$-contexts in formal concept analysis are\ninterdefinable with reducts of $L$-contexts in rough set theory via negation\nif, and only if, $L$ satisfies the law of double negation."}
{"id": "2509.13023", "categories": ["cs.SE", "cs.AI", "I.2.2;D.2.5;D.2.4;D.4.6"], "pdf": "https://arxiv.org/pdf/2509.13023", "abs": "https://arxiv.org/abs/2509.13023", "authors": ["Ştefan-Claudiu Susan", "Andrei Arusoaie", "Dorel Lucanu"], "title": "Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "The high rate of false alarms from static analysis tools and Large Language\nModels (LLMs) complicates vulnerability detection in Solidity Smart Contracts,\ndemanding methods that can formally or empirically prove the presence of\ndefects. This paper introduces a novel detection pipeline that integrates\ncustom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is\ndesigned to reliably detect defects and generate proofs. We currently perform\nexperiments with promising results for seven types of critical defects. We\ndemonstrate the pipeline's efficacy by presenting our findings for three\nvulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control\nPolicies -- that are challenging for current verification solutions, which\noften generate false alarms or fail to detect them entirely. We highlight the\npotential of either symbolic or concrete execution in correctly classifying\nsuch code faults. By chaining these instruments, our method effectively\nvalidates true positives, significantly reducing the manual verification\nburden. Although we identify potential limitations, such as the inconsistency\nand the cost of LLMs, our findings establish a robust framework for combining\nheuristic analysis with formal verification to achieve more reliable and\nautomated smart contract auditing."}
{"id": "2509.13258", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13258", "abs": "https://arxiv.org/abs/2509.13258", "authors": ["Giorgio Bacci", "Adrian Francalanza"], "title": "Proceedings of the Sixteenth International Symposium on Games, Automata, Logics, and Formal Verification", "comment": null, "summary": "This volume contains the proceedings of GandALF 2025, the Sixteenth\nInternational Symposium on Games, Automata, Logics, and Formal Verification.\nGandALF 2025 took place on 16-17th September 2025, in Valletta, Malta. The aim\nof GandALF 2025 is to bring together researchers from academia and industry who\nare actively working in the fields of Games, Automata, Logics, and Formal\nVerification. The idea is to cover an ample spectrum of themes, ranging from\ntheory to applications, and stimulate cross-fertilisation."}
{"id": "2509.13025", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13025", "abs": "https://arxiv.org/abs/2509.13025", "authors": ["Raul Zaharia", "Dragoş Gavriluţ", "Gheorghiţă Mutu"], "title": "GView: A Survey of Binary Forensics via Visual, Semantic, and AI-Enhanced Analysis", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Cybersecurity threats continue to become more sophisticated and diverse in\ntheir artifacts, boosting both their volume and complexity. To overcome those\nchallenges, we present GView, an open-source forensic analysis framework with\nvisual and AI-enhanced reasoning. It started with focus on the practical\ncybersecurity industry. It has evolved significantly, incorporating large\nlanguage models (LLMs) to dynamically enhance reasoning and ease the forensic\nworkflows. This paper surveys both the current state of GView with its\npublished papers alongside those that are in the publishing process. It also\nincludes its innovative use of logical inference through predicates and\ninference rules for both the analyzed documents and the user's actions for\nbetter suggestions. We highlight the extensible architecture, showcasing its\npotential as a bridge between the practical forensics worlds with the academic\nresearch."}
{"id": "2509.13019", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13019", "abs": "https://arxiv.org/abs/2509.13019", "authors": ["Frédéric Fort", "David Nowak", "Vlad Rusu"], "title": "Pleasant Imperative Program Proofs with GallinaC", "comment": "In Proceedings FROM 2025, arXiv:2509.11877", "summary": "Even with the increase of popularity of functional programming, imperative\nprogramming remains a key programming paradigm, especially for programs\noperating at lower levels of abstraction. When such software offers key\ncomponents of a Trusted Computing Base (TCB), e.g. an operating system kernel,\nit becomes desirable to provide mathematical correctness proofs.\n  However, current real-world imperative programming languages possess\n\"expressive\", i.e. overly permissive, semantics. Thus, producing correctness\nproofs of such programs becomes tedious and error-prone, requiring to take care\nof numerous \"administrative\" details. Ideally, a proof-oriented imperative\nlanguage should feature well-behaved semantics while allowing imperative\nidioms.\n  To obtain a high-degree of confidence in the correctness of such a language,\nits tools should be developed inside a proof-assistant such that program proofs\nare machine checked.\n  We present GallinaC, a shallow embedding of a Turing-complete imperative\nlanguage directly inside the functional programming language of the Rocq proof\nassistant, Gallina. In particular, it features a truly generic and unbounded\nwhile loop. Having a functional core means proofs about GallinaC programs may\nuse the same tactics as proofs about pure functional ones.\n  Work on GallinaC is still under progress, but we present first promising\nresults. A prototype implementation has shown the viability of GallinaC with\nthe correctness proof of a list reversal procedure for linked-lists of unknown\nsize. We currently focus on the forward simulation between the GallinaC\nintermediate representation (IR) and Cminor, the entry language of the CompCert\nback-end."}
{"id": "2509.13055", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13055", "abs": "https://arxiv.org/abs/2509.13055", "authors": ["Youngkyoung Kim", "Sanghyeok Park", "Misoo Kim", "Gangho Yoon", "Eunseok Lee", "Simon S. Woo"], "title": "Automating Code Generation for Semiconductor Equipment Control from Developer Utterances with LLMs", "comment": null, "summary": "Semiconductors form the backbone of modern electronics, with their\nmanufacturing and testing relying on highly specialized equipment and\ndomain-specific programming languages. Equipment languages such as the\nAlgorithmic Pattern Generator (ALPG) are critical for precise hardware control\nbut are challenging to program due to their low-level syntax and steep learning\ncurve. While large language models (LLMs) have shown promise in generating\nhigh-level code from natural language, their effectiveness on low-level\nequipment languages remains limited. To address this, we propose Progressive\nKnowledge Enhancement (PKE), a novel multi-stage prompting framework that\nprogressively extracts and activates the latent knowledge within LLMs, guiding\nthem from simple to complex examples without extensive fine-tuning. Empirical\nevaluation on an industrial ALPG dataset shows that PKE significantly\noutperforms standard prompting and surpasses state-of-the-art methods in\ngenerating correct ALPG code, achieving 11.1\\% and 15.2\\% higher exact match\nscores compared to the second-best technique. Further analysis of individual\ncomponents confirms that progressive knowledge extraction based on difficulty\nenhances accuracy. Our study offer a practical approach to boosting LLM\ncapabilities for specialized low-level programming, supporting greater\nproductivity in semiconductor software development."}
{"id": "2509.13103", "categories": ["cs.SE", "D.2"], "pdf": "https://arxiv.org/pdf/2509.13103", "abs": "https://arxiv.org/abs/2509.13103", "authors": ["Santiago Matalonga", "Domenico Amalfitano", "Jean Carlo Rossa Hauck", "Martín Solari", "Guilherme H. Travassos"], "title": "Accelerating Discovery: Rapid Literature Screening with LLMs", "comment": "This version of the manuscript has been submitted to Empirical\n  Software Engieering Journal for consideration", "summary": "Background: Conducting Multi Vocal Literature Reviews (MVLRs) is often time\nand effort-intensive. Researchers must review and filter a large number of\nunstructured sources, which frequently contain sparse information and are\nunlikely to be included in the final study. Our experience conducting an MVLR\non Context-Aware Software Systems (CASS) Testing in the avionics domain\nexemplified this challenge, with over 8,000 highly heterogeneous documents\nrequiring review. Therefore, we developed a Large Language Model (LLM)\nassistant to support the search and filtering of documents. Aims: To develop\nand validate an LLM based tool that can support researchers in performing the\nsearch and filtering of documents for an MVLR without compromising the rigor of\nthe research protocol. Method: We applied sound engineering practices to\ndevelop an on-premises LLM-based tool incorporating Retrieval Augmented\nGeneration (RAG) to process candidate sources. Progress towards the aim was\nquantified using the Positive Percent Agreement (PPA) as the primary metric to\nensure the performance of the LLM based tool. Convenience sampling, supported\nby human judgment and statistical sampling, were used to verify and validate\nthe tool's quality-in-use. Results: The tool currently demonstrates a PPA\nagreement with human researchers of 90% for sources that are not relevant to\nthe study. Development details are shared to support domain-specific adaptation\nof the tool. Conclusions: Using LLM-based tools to support academic researchers\nin rigorous MVLR is feasible. These tools can free valuable time for\nhigher-level, abstract tasks. However, researcher participation remains\nessential to ensure that the tool supports thorough research."}
{"id": "2509.13117", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13117", "abs": "https://arxiv.org/abs/2509.13117", "authors": ["Jukka Ruohonen", "Sani Abdullahi", "Abhishek Tiwari"], "title": "Vulnerability Patching Across Software Products and Software Components: A Case Study of Red Hat's Product Portfolio", "comment": "Submitted to SecITC 2025", "summary": "Motivated by software maintenance and the more recent concept of security\ndebt, the paper presents a time series analysis of vulnerability patching of\nRed Hat's products and components between 1999 and 2024. According to the\nresults based on segmented regression analysis, the amounts of vulnerable\nproducts and components have not been stable; a linear trend describes many of\nthe series well. Nor do the amounts align well with trends characterizing\nvulnerabilities in general. There are also visible breakpoints indicating that\nthe linear trend is not universally applicable and that the growing security\ndebt may be stabilizing."}
{"id": "2509.13134", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13134", "abs": "https://arxiv.org/abs/2509.13134", "authors": ["Talaya Farasat", "Joachim Posegga"], "title": "Optimizing Code Embeddings and ML Classifiers for Python Source Code Vulnerability Detection", "comment": null, "summary": "In recent years, the growing complexity and scale of source code have\nrendered manual software vulnerability detection increasingly impractical. To\naddress this challenge, automated approaches leveraging machine learning and\ncode embeddings have gained substantial attention. This study investigates the\noptimal combination of code embedding techniques and machine learning\nclassifiers for vulnerability detection in Python source code. We evaluate\nthree embedding techniques, i.e., Word2Vec, CodeBERT, and GraphCodeBERT\nalongside two deep learning classifiers, i.e., Bidirectional Long Short-Term\nMemory (BiLSTM) networks and Convolutional Neural Networks (CNN). While CNN\npaired with GraphCodeBERT exhibits strong performance, the BiLSTM model using\nWord2Vec consistently achieves superior overall results. These findings suggest\nthat, despite the advanced architectures of recent models like CodeBERT and\nGraphCodeBERT, classical embeddings such as Word2Vec, when used with\nsequence-based models like BiLSTM, can offer a slight yet consistent\nperformance advantage. The study underscores the critical importance of\nselecting appropriate combinations of embeddings and classifiers to enhance the\neffectiveness of automated vulnerability detection systems, particularly for\nPython source code."}
{"id": "2509.13144", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13144", "abs": "https://arxiv.org/abs/2509.13144", "authors": ["Lingli Cao", "Shanshan Li", "Ying Fan", "Danyang Li", "Chenxing Zhong"], "title": "Towards the Next Generation of Software: Insights from Grey Literature on AI-Native Applications", "comment": null, "summary": "Background: The rapid advancement of large language models (LLMs) has given\nrise to AI-native applications, a new paradigm in software engineering that\nfundamentally redefines how software is designed, developed, and evolved.\nDespite their growing prominence, AI-native applications still lack a unified\nengineering definition and architectural blueprint, leaving practitioners\nwithout systematic guidance for system design, quality assurance, and\ntechnology selection.\n  Objective: This study seeks to establish a comprehensive understanding of\nAI-native applications by identifying their defining characteristics, key\nquality attributes, and typical technology stacks, as well as by clarifying the\nopportunities and challenges they present.\n  Method: We conducted a grey literature review, integrating conceptual\nperspectives retrieved from targeted Google and Bing searches with practical\ninsights derived from leading open-source projects on GitHub. A structured\nprotocol encompassing source selection, quality assessment, and thematic\nanalysis was applied to synthesize findings across heterogeneous sources.\n  Results: We finally identified 106 studies based on the selection criteria.\nThe analysis reveals that AI-native applications are distinguished by two core\npillars: the central role of AI as the system's intelligence paradigm and their\ninherently probabilistic, non-deterministic nature. Critical quality attributes\ninclude reliability, usability, performance efficiency, and AI-specific\nobservability. In addition, a typical technology stack has begun to emerge,\ncomprising LLM orchestration frameworks, vector databases, and AI-native\nobservability platforms. These systems emphasize response quality,\ncost-effectiveness, and outcome predictability, setting them apart from\nconventional software systems.\n  Conclusion: This study is the first to propose a dual-layered engineering\nblueprint..."}
{"id": "2509.13128", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13128", "abs": "https://arxiv.org/abs/2509.13128", "authors": ["Raphaël Monat"], "title": "Try-Mopsa: Relational Static Analysis in Your Pocket", "comment": null, "summary": "Static analyzers are complex pieces of software with large dependencies. They\ncan be difficult to install, which hinders adoption and creates barriers for\nstudents learning static analysis. This work introduces Try-Mopsa: a\nscaled-down version of the Mopsa static analysis platform, compiled into\nJavaScript to run purely as a client-side application in web browsers.\nTry-Mopsa provides a responsive interface that works on both desktop and mobile\ndevices. Try-Mopsa features all the core components of Mopsa. In particular, it\nsupports relational numerical domains. We present the interface, changes and\nadaptations required to have a pure JavaScript version of Mopsa. We envision\nTry-Mopsa as a convenient platform for onboarding or teaching purposes."}
