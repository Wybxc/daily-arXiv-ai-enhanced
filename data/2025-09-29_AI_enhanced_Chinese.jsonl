{"id": "2509.21840", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.21840", "abs": "https://arxiv.org/abs/2509.21840", "authors": ["Aditi Kabra", "Jonathan Laurent", "Sagar Bharadwaj", "Ruben Martins", "Stefan Mitsch", "Andr\u00e9 Platzer"], "title": "Can Large Language Models Autoformalize Kinematics?", "comment": null, "summary": "Autonomous cyber-physical systems like robots and self-driving cars could\ngreatly benefit from using formal methods to reason reliably about their\ncontrol decisions. However, before a problem can be solved it needs to be\nstated. This requires writing a formal physics model of the cyber-physical\nsystem, which is a complex task that traditionally requires human expertise and\nbecomes a bottleneck.\n  This paper experimentally studies whether Large Language Models (LLMs) can\nautomate the formalization process. A 20 problem benchmark suite is designed\ndrawing from undergraduate level physics kinematics problems. In each problem,\nthe LLM is provided with a natural language description of the objects' motion\nand must produce a model in differential game logic (dGL). The model is (1)\nsyntax checked and iteratively refined based on parser feedback, and (2)\nsemantically evaluated by checking whether symbolically executing the dGL\nformula recovers the solution to the original physics problem. A success rate\nof 70% (best over 5 samples) is achieved. We analyze failing cases, identifying\ndirections for future improvement. This provides a first quantitative baseline\nfor LLM-based autoformalization from natural language to a hybrid games logic\nwith continuous dynamics.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5c06\u81ea\u7136\u8bed\u8a00\u7269\u7406\u95ee\u9898\u81ea\u52a8\u5f62\u5f0f\u5316\u4e3a\u5fae\u5206\u535a\u5f08\u903b\u8f91\u6a21\u578b\uff0c\u572820\u4e2a\u57fa\u51c6\u95ee\u9898\u4e2d\u8fbe\u523070%\u6210\u529f\u7387", "motivation": "\u81ea\u4e3b\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u9700\u8981\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u53ef\u9760\u63a8\u7406\u63a7\u5236\u51b3\u7b56\uff0c\u4f46\u624b\u52a8\u6784\u5efa\u7269\u7406\u6a21\u578b\u590d\u6742\u4e14\u8017\u65f6\uff0c\u6210\u4e3a\u74f6\u9888", "method": "\u8bbe\u8ba120\u4e2a\u672c\u79d1\u7269\u7406\u8fd0\u52a8\u5b66\u95ee\u9898\u57fa\u51c6\uff0c\u8ba9LLM\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u5fae\u5206\u535a\u5f08\u903b\u8f91\u6a21\u578b\uff0c\u901a\u8fc7\u8bed\u6cd5\u68c0\u67e5\u548c\u7b26\u53f7\u6267\u884c\u8fdb\u884c\u8fed\u4ee3\u7cbe\u70bc\u548c\u8bed\u4e49\u8bc4\u4f30", "result": "\u57285\u6b21\u91c7\u6837\u4e2d\u7684\u6700\u4f73\u6210\u529f\u7387\u8fbe\u523070%\uff0c\u5206\u6790\u4e86\u5931\u8d25\u6848\u4f8b\u4ee5\u6307\u5bfc\u672a\u6765\u6539\u8fdb", "conclusion": "\u4e3a\u4ece\u81ea\u7136\u8bed\u8a00\u5230\u5177\u6709\u8fde\u7eed\u52a8\u6001\u7684\u6df7\u5408\u535a\u5f08\u903b\u8f91\u7684LLM\u81ea\u52a8\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u9996\u4e2a\u5b9a\u91cf\u57fa\u51c6"}}
{"id": "2509.22236", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.22236", "abs": "https://arxiv.org/abs/2509.22236", "authors": ["Arif Ali AP", "Jasine Babu", "Deepa Sara John"], "title": "A Correct by Construction Fault Tolerant Voter for Input Selection of a Control System", "comment": null, "summary": "Safety-critical systems use redundant input units to improve their\nreliability and fault tolerance. A voting logic is then used to select a\nreliable input from the redundant sources. A fault detection and isolation\nrules help in selecting input units that can participate in voting. This work\ndeals with the formal requirement formulation, design, verification and\nsynthesis of a generic voting unit for an $N$-modular redundant measurement\nsystem used for control applications in avionics systems. The work follows a\ncorrect-by-construction approach, using the Rocq theorem prover.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u822a\u7a7a\u7535\u5b50\u7cfb\u7edf\u4e2dN\u6a21\u5757\u5197\u4f59\u6d4b\u91cf\u7cfb\u7edf\u7684\u901a\u7528\u6295\u7968\u5355\u5143\u7684\u5f62\u5f0f\u5316\u9700\u6c42\u5236\u5b9a\u3001\u8bbe\u8ba1\u3001\u9a8c\u8bc1\u548c\u7efc\u5408\u65b9\u6cd5\u3002", "motivation": "\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4f7f\u7528\u5197\u4f59\u8f93\u5165\u5355\u5143\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u5bb9\u9519\u80fd\u529b\uff0c\u9700\u8981\u6295\u7968\u903b\u8f91\u4ece\u5197\u4f59\u6e90\u4e2d\u9009\u62e9\u53ef\u9760\u8f93\u5165\uff0c\u6545\u969c\u68c0\u6d4b\u548c\u9694\u79bb\u89c4\u5219\u5e2e\u52a9\u9009\u62e9\u53c2\u4e0e\u6295\u7968\u7684\u8f93\u5165\u5355\u5143\u3002", "method": "\u91c7\u7528\u6b63\u786e\u6784\u9020\u65b9\u6cd5\uff0c\u4f7f\u7528Rocq\u5b9a\u7406\u8bc1\u660e\u5668\u8fdb\u884c\u5f62\u5f0f\u5316\u9700\u6c42\u5236\u5b9a\u3001\u8bbe\u8ba1\u3001\u9a8c\u8bc1\u548c\u7efc\u5408\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6295\u7968\u5355\u5143\uff0c\u9002\u7528\u4e8eN\u6a21\u5757\u5197\u4f59\u6d4b\u91cf\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u5b9a\u7406\u8bc1\u660e\u5668\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u4e14\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6295\u7968\u5355\u5143\u8bbe\u8ba1\u3002"}}
{"id": "2509.22533", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.22533", "abs": "https://arxiv.org/abs/2509.22533", "authors": ["Kalonji Kalala", "Iluju Kiringa", "Tet Yeap"], "title": "Specifying an Obligation Taxonomy in the Non-Markovian Situation Calculus", "comment": "The 9th International Joint Conference on Rules and Reasoning\n  (RuleML+RR 2025)", "summary": "Over more than three decades, the Situation Calculus has established itself\nas an elegant, powerful, and concise formalism for specifying dynamical domains\nas well as for reasoning about the effects of actions of those domains both in\nthe world and in the mental state of the modelled agents. Moreover, it has also\nbeen established that the preconditions of a given action and its effects may\nbe determined entirely by the current situation alone, or they may be\ndetermined by past situations as well. When past situations are involved in\ndetermining action preconditions and effects, resulting theories are\nnon-Markovian. Assuming a specification of actions that produce obligations, we\nconsider using non-Markovian control in the Situation Calculus to specify\ndifferent notions of obligations found in the literature. These notions have\nbeen specified using Event Calculus; but, as far as we know, they have never\nbeen specified using the Situation Calculus. The specifications in this paper\nyield intuitive properties that ensure the correctness of the whole endeavour.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u60c5\u5883\u6f14\u7b97\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u63a7\u5236\u6765\u89c4\u8303\u6587\u732e\u4e2d\u7684\u4e0d\u540c\u4e49\u52a1\u6982\u5ff5\uff0c\u8fd9\u4e9b\u6982\u5ff5\u4e4b\u524d\u4ec5\u7528\u4e8b\u4ef6\u6f14\u7b97\u63cf\u8ff0\u8fc7\u3002", "motivation": "\u60c5\u5883\u6f14\u7b97\u4f5c\u4e3a\u63cf\u8ff0\u52a8\u6001\u9886\u57df\u548c\u63a8\u7406\u884c\u52a8\u6548\u679c\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u5df2\u5efa\u7acb\u4e09\u5341\u591a\u5e74\uff0c\u4f46\u6587\u732e\u4e2d\u7684\u4e0d\u540c\u4e49\u52a1\u6982\u5ff5\u4ece\u672a\u7528\u60c5\u5883\u6f14\u7b97\u89c4\u8303\u8fc7\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u60c5\u5883\u6f14\u7b97\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u63a7\u5236\u65b9\u6cd5\uff0c\u8003\u8651\u4ea7\u751f\u4e49\u52a1\u7684\u884c\u52a8\u89c4\u8303\uff0c\u6765\u5b9a\u4e49\u4e0d\u540c\u7684\u4e49\u52a1\u6982\u5ff5\u3002", "result": "\u63d0\u51fa\u7684\u89c4\u8303\u4ea7\u751f\u4e86\u76f4\u89c2\u7684\u5c5e\u6027\uff0c\u786e\u4fdd\u4e86\u6574\u4e2a\u5de5\u4f5c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u6210\u529f\u4f7f\u7528\u60c5\u5883\u6f14\u7b97\u4e2d\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u63a7\u5236\u89c4\u8303\u4e86\u6587\u732e\u4e2d\u7684\u4e0d\u540c\u4e49\u52a1\u6982\u5ff5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.22239", "categories": ["cs.FL", "math.GR", "20F10, 68Q45"], "pdf": "https://arxiv.org/pdf/2509.22239", "abs": "https://arxiv.org/abs/2509.22239", "authors": ["Andrew Duncan", "Murray Elder", "Lisa Frenkel", "Mengfan Lyu"], "title": "Permutation closure for multiple context-free languages", "comment": "20 pages, 5 figures", "summary": "We prove that the \\emph{permutation closure} of a multiple context-free\nlanguage is multiple context-free, which extends work of Okhotin and Sorokin\n[LATA 2020] who showed closure under \\emph{cyclic shift}, and complements work\nof Brandst\\\"adt [1981, RAIRO Inform. Th\\'{e}or.] (resp. Brough \\emph{et al.}\n[2016, Discrete Math. Theor. Comput. Sci.]) who showed the same result for\nregular, context-sensitive, recursively enumerable (resp. EDT0L and ET0L)\nlanguages. In contrast to Okhotin and Sorokin who work with grammars, our proof\nuses restricted tree stack automata due to Denkinger [DLT 2016].", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u591a\u91cd\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u7684\u7f6e\u6362\u95ed\u5305\u4ecd\u7136\u662f\u591a\u91cd\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\uff0c\u6269\u5c55\u4e86Okhotin\u548cSorokin\u5173\u4e8e\u5faa\u73af\u79fb\u4f4d\u95ed\u5305\u7684\u5de5\u4f5c\u3002", "motivation": "\u7814\u7a76\u591a\u91cd\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u5728\u7f6e\u6362\u64cd\u4f5c\u4e0b\u7684\u95ed\u5305\u6027\u8d28\uff0c\u586b\u8865\u8be5\u8bed\u8a00\u7c7b\u5728\u7f6e\u6362\u95ed\u5305\u65b9\u9762\u7684\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u4f7f\u7528Denkinger\u63d0\u51fa\u7684\u53d7\u9650\u6811\u6808\u81ea\u52a8\u673a\u8fdb\u884c\u8bc1\u660e\uff0c\u4e0eOkhotin\u548cSorokin\u57fa\u4e8e\u6587\u6cd5\u7684\u65b9\u6cd5\u4e0d\u540c\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u591a\u91cd\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u5728\u7f6e\u6362\u64cd\u4f5c\u4e0b\u662f\u5c01\u95ed\u7684\u3002", "conclusion": "\u591a\u91cd\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u5177\u6709\u7f6e\u6362\u95ed\u5305\u6027\u8d28\uff0c\u8fd9\u4e3a\u7406\u89e3\u8be5\u8bed\u8a00\u7c7b\u7684\u4ee3\u6570\u7279\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u652f\u6491\u3002"}}
{"id": "2509.21427", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.21427", "abs": "https://arxiv.org/abs/2509.21427", "authors": ["Ying Wang", "Wenjun Mao", "Chong Wang", "Zhenhao Zhou", "Yicheng Zhou", "Wenyun Zhao", "Yiling Lou", "Xin Peng"], "title": "Extracting Conceptual Knowledge to Locate Software Issues", "comment": null, "summary": "Issue localization, which identifies faulty code elements such as files or\nfunctions, is critical for effective bug fixing. While recent LLM-based and\nLLM-agent-based approaches improve accuracy, they struggle in large-scale\nrepositories due to concern mixing, where relevant logic is buried in large\nfunctions, and concern scattering, where related logic is dispersed across\nfiles.\n  To address these challenges, we propose RepoLens, a novel approach that\nabstracts and leverages conceptual knowledge from code repositories. RepoLens\ndecomposes fine-grained functionalities and recomposes them into high-level\nconcerns, semantically coherent clusters of functionalities that guide LLMs. It\noperates in two stages: an offline stage that extracts and enriches conceptual\nknowledge into a repository-wide knowledge base, and an online stage that\nretrieves issue-specific terms, clusters and ranks concerns by relevance, and\nintegrates them into localization workflows via minimally intrusive prompt\nenhancements. We evaluate RepoLens on SWE-Lancer-Loc, a benchmark of 216 tasks\nderived from SWE-Lancer. RepoLens consistently improves three state-of-the-art\ntools, namely AgentLess, OpenHands, and mini-SWE-agent, achieving average gains\nof over 22% in Hit@k and 46% in Recall@k for file- and function-level\nlocalization. It generalizes across models (GPT-4o, GPT-4o-mini, GPT-4.1) with\nHit@1 and Recall@10 gains up to 504% and 376%, respectively. Ablation studies\nand manual evaluation confirm the effectiveness and reliability of the\nconstructed concerns.", "AI": {"tldr": "RepoLens\u901a\u8fc7\u63d0\u53d6\u548c\u5229\u7528\u4ee3\u7801\u4ed3\u5e93\u7684\u6982\u5ff5\u77e5\u8bc6\u6765\u89e3\u51b3\u95ee\u9898\u5b9a\u4f4d\u4e2d\u7684\u5173\u6ce8\u70b9\u6df7\u5408\u548c\u5173\u6ce8\u70b9\u5206\u6563\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709LLM\u5de5\u5177\u5728\u6587\u4ef6\u7ea7\u548c\u51fd\u6570\u7ea7\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u95ee\u9898\u5b9a\u4f4d\u65b9\u6cd5\u5728\u5927\u578b\u4ee3\u7801\u4ed3\u5e93\u4e2d\u9762\u4e34\u5173\u6ce8\u70b9\u6df7\u5408\uff08\u76f8\u5173\u903b\u8f91\u88ab\u57cb\u6ca1\u5728\u5927\u51fd\u6570\u4e2d\uff09\u548c\u5173\u6ce8\u70b9\u5206\u6563\uff08\u76f8\u5173\u903b\u8f91\u5206\u6563\u5728\u4e0d\u540c\u6587\u4ef6\u4e2d\uff09\u7684\u6311\u6218\uff0c\u5bfc\u81f4\u5b9a\u4f4d\u51c6\u786e\u6027\u4e0b\u964d\u3002", "method": "RepoLens\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u79bb\u7ebf\u9636\u6bb5\u63d0\u53d6\u548c\u4e30\u5bcc\u6982\u5ff5\u77e5\u8bc6\u6784\u5efa\u4ed3\u5e93\u8303\u56f4\u7684\u77e5\u8bc6\u5e93\uff1b\u5728\u7ebf\u9636\u6bb5\u68c0\u7d22\u95ee\u9898\u76f8\u5173\u672f\u8bed\uff0c\u5bf9\u5173\u6ce8\u70b9\u8fdb\u884c\u805a\u7c7b\u548c\u6392\u5e8f\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u4fb5\u5165\u5f0f\u7684\u63d0\u793a\u589e\u5f3a\u96c6\u6210\u5230\u5b9a\u4f4d\u5de5\u4f5c\u6d41\u4e2d\u3002", "result": "\u5728SWE-Lancer-Loc\u57fa\u51c6\u6d4b\u8bd5\u7684216\u4e2a\u4efb\u52a1\u4e0a\uff0cRepoLens\u663e\u8457\u63d0\u5347\u4e86AgentLess\u3001OpenHands\u548cmini-SWE-agent\u4e09\u4e2a\u5148\u8fdb\u5de5\u5177\u7684\u6027\u80fd\uff0c\u6587\u4ef6\u7ea7\u548c\u51fd\u6570\u7ea7\u5b9a\u4f4d\u7684Hit@k\u548cRecall@k\u5e73\u5747\u63d0\u5347\u5206\u522b\u8d85\u8fc722%\u548c46%\u3002\u5728\u4e0d\u540c\u6a21\u578b\uff08GPT-4o\u3001GPT-4o-mini\u3001GPT-4.1\uff09\u4e0a\u5747\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RepoLens\u901a\u8fc7\u6982\u5ff5\u77e5\u8bc6\u62bd\u8c61\u548c\u5173\u6ce8\u70b9\u91cd\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u4ed3\u5e93\u4e2d\u7684\u95ee\u9898\u5b9a\u4f4d\u6311\u6218\uff0c\u6784\u5efa\u7684\u5173\u6ce8\u70b9\u88ab\u8bc1\u660e\u662f\u6709\u6548\u548c\u53ef\u9760\u7684\u3002"}}
{"id": "2509.21629", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.21629", "abs": "https://arxiv.org/abs/2509.21629", "authors": ["Anjiang Wei", "Tarun Suresh", "Tianran Sun", "Haoze Wu", "Ke Wang", "Alex Aiken"], "title": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?", "comment": null, "summary": "Program verification relies on loop invariants, yet automatically discovering\nstrong invariants remains a long-standing challenge. We introduce a principled\nframework for evaluating LLMs on invariant synthesis. Our approach uses a\nverifier-based decision procedure with a formal soundness guarantee and\nassesses not only correctness but also the speedup that invariants provide in\nverification. We evaluate 7 state-of-the-art LLMs, and existing LLM-based\nverifiers against the traditional solver UAutomizer. While LLM-based verifiers\nrepresent a promising direction, they do not yet offer a significant advantage\nover UAutomizer. Model capability also proves critical, as shown by sharp\ndifferences in speedups across models, and our benchmark remains an open\nchallenge for current LLMs. Finally, we show that supervised fine-tuning and\nBest-of-N sampling can improve performance: fine-tuning on 3589 instances\nraises the percentage of speedup cases for Qwen3-Coder-480B from 8% to 29.2%,\nand Best-of-N sampling with N=16 improves Claude-sonnet-4 from 8.8% to 22.1%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30LLMs\u5728\u5faa\u73af\u4e0d\u53d8\u5f0f\u5408\u6210\u4e0a\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8bc4\u4f30\u6b63\u786e\u6027\u548c\u9a8c\u8bc1\u901f\u5ea6\u63d0\u5347\u3002\u6d4b\u8bd5\u4e867\u4e2a\u5148\u8fdbLLMs\u548c\u73b0\u6709LLM\u9a8c\u8bc1\u5668\uff0c\u53d1\u73b0\u5b83\u4eec\u5c1a\u672a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6c42\u89e3\u5668UAutomizer\u3002\u76d1\u7763\u5fae\u8c03\u548c\u6700\u4f73N\u91c7\u6837\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7a0b\u5e8f\u9a8c\u8bc1\u4f9d\u8d56\u5faa\u73af\u4e0d\u53d8\u5f0f\uff0c\u4f46\u81ea\u52a8\u53d1\u73b0\u5f3a\u4e0d\u53d8\u5f0f\u4ecd\u662f\u957f\u671f\u6311\u6218\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u4e0d\u53d8\u5f0f\u5408\u6210\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5177\u6709\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u8bc4\u4f30\u4e0d\u53d8\u5f0f\u7684\u6b63\u786e\u6027\u548c\u9a8c\u8bc1\u901f\u5ea6\u63d0\u5347\u3002\u5bf97\u4e2a\u5148\u8fdbLLMs\u548c\u73b0\u6709LLM\u9a8c\u8bc1\u5668\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u4f20\u7edf\u6c42\u89e3\u5668UAutomizer\u6bd4\u8f83\u3002\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u548c\u6700\u4f73N\u91c7\u6837\u7b56\u7565\u3002", "result": "LLM\u9a8c\u8bc1\u5668\u662f\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u5c1a\u672a\u663e\u8457\u4f18\u4e8eUAutomizer\u3002\u6a21\u578b\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4e0d\u540c\u6a21\u578b\u7684\u901f\u5ea6\u63d0\u5347\u5dee\u5f02\u660e\u663e\u3002\u76d1\u7763\u5fae\u8c03\u5c06Qwen3-Coder-480B\u7684\u901f\u5ea6\u63d0\u5347\u6848\u4f8b\u4ece8%\u63d0\u9ad8\u523029.2%\uff0c\u6700\u4f73N\u91c7\u6837(N=16)\u5c06Claude-sonnet-4\u4ece8.8%\u63d0\u5347\u523022.1%\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u4e0d\u53d8\u5f0f\u5408\u6210\u57fa\u51c6\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4f46\u76d1\u7763\u5fae\u8c03\u548c\u91c7\u6837\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002LLM\u9a8c\u8bc1\u5668\u662f\u672a\u6765\u6709\u5e0c\u671b\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.22489", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2509.22489", "abs": "https://arxiv.org/abs/2509.22489", "authors": ["Jaouhar Slimi", "Tristan Le Gall", "Augustin Lemesle"], "title": "Passive Learning of Lattice Automata from Recurrent Neural Networks", "comment": "10 pages, 5 figures. To be published in OVERLAY 2025, 7th\n  International Workshop on Artificial Intelligence and Formal Verification,\n  Logic, Automata, and Synthesis", "summary": "We present a passive automata learning algorithm that can extract automata\nfrom recurrent networks with very large or even infinite alphabets. Our method\ncombines overapproximations from the field of Abstract Interpretation and\npassive automata learning from the field of Grammatical Inference. We evaluate\nour algorithm by first comparing it with the state-of-the-art automata\nextraction algorithm from Recurrent Neural Networks trained on Tomita grammars.\nThen, we extend these experiments to regular languages with infinite alphabets,\nwhich we propose as a novel benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u5177\u6709\u5927\u6216\u65e0\u9650\u5b57\u6bcd\u8868\u7684\u5faa\u73af\u7f51\u7edc\u4e2d\u63d0\u53d6\u81ea\u52a8\u673a\u7684\u88ab\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u62bd\u8c61\u89e3\u91ca\u548c\u8bed\u6cd5\u63a8\u7406\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5177\u6709\u5927\u5b57\u6bcd\u8868\u6216\u65e0\u9650\u5b57\u6bcd\u8868\u7684\u5faa\u73af\u7f51\u7edc\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u8fd9\u7c7b\u60c5\u51b5\u7684\u81ea\u52a8\u673a\u63d0\u53d6\u7b97\u6cd5\u3002", "method": "\u7ed3\u5408\u62bd\u8c61\u89e3\u91ca\u9886\u57df\u7684\u8fc7\u8fd1\u4f3c\u6280\u672f\u548c\u8bed\u6cd5\u63a8\u7406\u9886\u57df\u7684\u88ab\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5728Tomita\u8bed\u6cd5\u4e0a\u4e0e\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5e76\u5728\u63d0\u51fa\u7684\u65e0\u9650\u5b57\u6bcd\u8868\u6b63\u5219\u8bed\u8a00\u65b0\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u6269\u5c55\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u53d6\u5177\u6709\u5927\u6216\u65e0\u9650\u5b57\u6bcd\u8868\u7684\u5faa\u73af\u7f51\u7edc\u4e2d\u7684\u81ea\u52a8\u673a\uff0c\u4e3a\u8fd9\u7c7b\u590d\u6742\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.21533", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.21533", "abs": "https://arxiv.org/abs/2509.21533", "authors": ["Shalini Chakraborty", "Sebastian Baltes"], "title": "Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks", "comment": "3 pages, published in the Proceedings of the 18th International\n  Conference on Cooperative and Human Aspects of Software Engineering (CHASE\n  2025)", "summary": "The IT industry provides supportive pathways such as returnship programs,\ncoding boot camps, and buddy systems for women re-entering their job after a\ncareer break. Academia, however, offers limited opportunities to motivate women\nto return. We propose a diverse multicultural research project investigating\nthe challenges faced by women with software engineering (SE) backgrounds\nre-entering academia or related research roles after a career break. Career\ndisruptions due to pregnancy, immigration status, or lack of flexible work\noptions can significantly impact women's career progress, creating barriers for\nreturning as lecturers, professors, or senior researchers. Although many\ncompanies promote gender diversity policies, such measures are less prominent\nand often under-recognized within academic institutions. Our goal is to explore\nthe specific challenges women encounter when re-entering academic roles\ncompared to industry roles; to understand the institutional perspective,\nincluding a comparative analysis of existing policies and opportunities in\ndifferent countries for women to return to the field; and finally, to provide\nrecommendations that support transparent hiring practices. The research project\nwill be carried out in multiple universities and in multiple countries to\ncapture the diverse challenges and policies that vary by location.", "AI": {"tldr": "\u7814\u7a76\u5973\u6027\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u804c\u4e1a\u4e2d\u65ad\u540e\u91cd\u8fd4\u5b66\u672f\u754c\u9762\u4e34\u7684\u6311\u6218\uff0c\u6bd4\u8f83\u4e0d\u540c\u56fd\u5bb6\u7684\u653f\u7b56\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u652f\u6301\u900f\u660e\u62db\u8058\u5b9e\u8df5\u7684\u5efa\u8bae\u3002", "motivation": "IT\u884c\u4e1a\u4e3a\u5973\u6027\u91cd\u8fd4\u804c\u573a\u63d0\u4f9b\u4e86\u591a\u79cd\u652f\u6301\u9014\u5f84\uff0c\u4f46\u5b66\u672f\u754c\u5728\u8fd9\u65b9\u9762\u673a\u4f1a\u6709\u9650\u3002\u804c\u4e1a\u4e2d\u65ad\uff08\u5982\u6000\u5b55\u3001\u79fb\u6c11\u8eab\u4efd\u3001\u7f3a\u4e4f\u7075\u6d3b\u5de5\u4f5c\u9009\u62e9\uff09\u4e25\u91cd\u5f71\u54cd\u5973\u6027\u804c\u4e1a\u53d1\u5c55\uff0c\u800c\u5b66\u672f\u673a\u6784\u7684\u6027\u522b\u591a\u6837\u6027\u653f\u7b56\u4e0d\u591f\u7a81\u51fa\u3002", "method": "\u5728\u591a\u4e2a\u56fd\u5bb6\u548c\u5927\u5b66\u5f00\u5c55\u591a\u5143\u6587\u5316\u7814\u7a76\u9879\u76ee\uff0c\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u73b0\u6709\u653f\u7b56\u548c\u673a\u4f1a\uff0c\u63a2\u7d22\u5973\u6027\u91cd\u8fd4\u5b66\u672f\u754c\u7684\u7279\u5b9a\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5973\u6027\u91cd\u8fd4\u5b66\u672f\u754c\u6bd4\u91cd\u8fd4\u884c\u4e1a\u9762\u4e34\u66f4\u591a\u969c\u788d\uff0c\u4e0d\u540c\u56fd\u5bb6\u7684\u652f\u6301\u653f\u7b56\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u9700\u8981\u4e3a\u5973\u6027\u91cd\u8fd4\u5b66\u672f\u754c\u63d0\u4f9b\u66f4\u597d\u7684\u652f\u6301\u673a\u5236\uff0c\u5305\u62ec\u900f\u660e\u62db\u8058\u5b9e\u8df5\u548c\u66f4\u5b8c\u5584\u7684\u5236\u5ea6\u653f\u7b56\u3002"}}
{"id": "2509.21793", "categories": ["cs.PL", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.21793", "abs": "https://arxiv.org/abs/2509.21793", "authors": ["Jianhong Zhao", "Everett Hildenbrandt", "Juan Conejero", "Yongwang Zhao"], "title": "Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics", "comment": null, "summary": "Verification proofs encode complete program behavior, yet we discard them\nafter checking correctness. We present compiling by proving, a paradigm that\ntransforms these proofs into optimized execution rules. By constructing\nAll-Path Reachability Proofs through symbolic execution and compiling their\ngraph structure, we consolidate many semantic rewrites into single rules while\npreserving correctness by construction. We implement this as a\nlanguage-agnostic extension to the K framework. Evaluation demonstrates\nperformance improvements across different compilation scopes: opcode-level\noptimizations show consistent speedups, while whole-program compilation\nachieves orders of magnitude greater performance gains.", "AI": {"tldr": "\u63d0\u51fa'\u901a\u8fc7\u8bc1\u660e\u7f16\u8bd1'\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u9a8c\u8bc1\u8bc1\u660e\u8f6c\u5316\u4e3a\u4f18\u5316\u7684\u6267\u884c\u89c4\u5219\uff0c\u901a\u8fc7\u6784\u5efa\u5168\u8def\u5f84\u53ef\u8fbe\u6027\u8bc1\u660e\u5e76\u7f16\u8bd1\u5176\u56fe\u7ed3\u6784\uff0c\u5c06\u591a\u4e2a\u8bed\u4e49\u91cd\u5199\u5408\u5e76\u4e3a\u5355\u4e00\u89c4\u5219\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u786e\u6027\u3002", "motivation": "\u9a8c\u8bc1\u8bc1\u660e\u7f16\u7801\u4e86\u5b8c\u6574\u7684\u7a0b\u5e8f\u884c\u4e3a\uff0c\u4f46\u5728\u68c0\u67e5\u6b63\u786e\u6027\u540e\u901a\u5e38\u88ab\u4e22\u5f03\uff0c\u8fd9\u9020\u6210\u4e86\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u6784\u5efa\u5168\u8def\u5f84\u53ef\u8fbe\u6027\u8bc1\u660e\uff0c\u7f16\u8bd1\u5176\u56fe\u7ed3\u6784\uff0c\u5c06\u591a\u4e2a\u8bed\u4e49\u91cd\u5199\u5408\u5e76\u4e3a\u5355\u4e00\u89c4\u5219\uff0c\u5728K\u6846\u67b6\u4e2d\u5b9e\u73b0\u8bed\u8a00\u65e0\u5173\u7684\u6269\u5c55\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5728\u4e0d\u540c\u7f16\u8bd1\u8303\u56f4\u5185\u90fd\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff1a\u64cd\u4f5c\u7801\u7ea7\u4f18\u5316\u663e\u793a\u4e00\u81f4\u7684\u52a0\u901f\uff0c\u800c\u5168\u7a0b\u5e8f\u7f16\u8bd1\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u66f4\u5927\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u901a\u8fc7\u8bc1\u660e\u7f16\u8bd1\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7a0b\u5e8f\u6267\u884c\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u786e\u6027\u3002"}}
{"id": "2509.21816", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.21816", "abs": "https://arxiv.org/abs/2509.21816", "authors": ["Yuhang Xie", "Jian Mu", "Xiaojun Ma", "Chaoyun Zhang", "Lu Wang", "Mengyu Zhou", "Mugeng Liu", "Si Qin", "Qingwei Lin", "Saravan Rajmohan", "Shi Han", "Dongmei Zhang"], "title": "No More Manual Guides: Automatic and Scalable Generation of High-Quality Excel Tutorials", "comment": null, "summary": "Excel is one of the most widely used productivity tools across domains,\noffering rich functionality but also overwhelming users with its complexity.\nThis creates a persistent demand for tutorials to support effective usage.\nHowever, existing tutorials are manually authored by experts, require frequent\nupdates after each software release, and incur substantial labor costs. Prior\nwork has not achieved fully automated tutorial generation, since existing\nmethods still depend on handcrafted operation sequences or example materials.\nIn this paper, we present the first framework for automatically generating\nExcel tutorials directly from natural language task descriptions. Our framework\nfirst instantiates the task. Then a central component of this framework,\nExecution Agent, plans and executes the solution in Excel, and collects the\nintermediate artifacts required for tutorial construction. These artifacts are\nthen transformed into both structured Excel documents and video demonstrations.\nTo build a comprehensive tutorial corpus, we collected 1,559 task descriptions\nfrom real-world scenarios. In addition, we designed a systematic evaluation\nframework that integrates assessments from both large language models (LLMs)\nand human reviewers. Experimental results show that our framework improves task\nexecution success rates by 8.5% over state-of-the-art baselines. Moreover, the\ngenerated tutorials demonstrate superior readability and instructional\neffectiveness, often approaching or surpassing expert-authored materials.\nImportantly, the automated pipeline eliminates manual labor and reduces time\ncosts to 1/20 of expert authoring, making scalable and high-quality tutorial\ngeneration practical for the first time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u4ece\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u81ea\u52a8\u751f\u6210Excel\u6559\u7a0b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6267\u884c\u4ee3\u7406\u5728Excel\u4e2d\u89c4\u5212\u6267\u884c\u89e3\u51b3\u65b9\u6848\u5e76\u6536\u96c6\u4e2d\u95f4\u4ea7\u7269\uff0c\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u6587\u6863\u548c\u89c6\u9891\u6f14\u793a\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4eba\u5de5\u6210\u672c\u3002", "motivation": "Excel\u529f\u80fd\u590d\u6742\u4f46\u5e7f\u6cdb\u4f7f\u7528\uff0c\u73b0\u6709\u6559\u7a0b\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u7f16\u5199\uff0c\u66f4\u65b0\u6210\u672c\u9ad8\u4e14\u65e0\u6cd5\u6ee1\u8db3\u6301\u7eed\u9700\u6c42\uff0c\u9700\u8981\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6559\u7a0b\u751f\u6210\u3002", "method": "\u6846\u67b6\u9996\u5148\u5b9e\u4f8b\u5316\u4efb\u52a1\uff0c\u7136\u540e\u901a\u8fc7\u6267\u884c\u4ee3\u7406\u5728Excel\u4e2d\u89c4\u5212\u6267\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u6536\u96c6\u4e2d\u95f4\u4ea7\u7269\uff0c\u6700\u540e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u6587\u6863\u548c\u89c6\u9891\u6f14\u793a\u3002", "result": "\u57281559\u4e2a\u771f\u5b9e\u573a\u666f\u4efb\u52a1\u4e0a\u6d4b\u8bd5\uff0c\u4efb\u52a1\u6267\u884c\u6210\u529f\u7387\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u9ad88.5%\uff0c\u751f\u6210\u6559\u7a0b\u7684\u53ef\u8bfb\u6027\u548c\u6559\u5b66\u6548\u679c\u63a5\u8fd1\u6216\u8d85\u8fc7\u4e13\u5bb6\u7f16\u5199\u6750\u6599\uff0c\u65f6\u95f4\u6210\u672c\u964d\u81f3\u4e13\u5bb6\u7f16\u5199\u76841/20\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u9996\u6b21\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cfExcel\u6559\u7a0b\u751f\u6210\uff0c\u6d88\u9664\u4e86\u4eba\u5de5\u52b3\u52a8\uff0c\u4f7f\u5927\u89c4\u6a21\u6559\u7a0b\u751f\u6210\u53d8\u5f97\u5b9e\u7528\u53ef\u884c\u3002"}}
{"id": "2509.22614", "categories": ["cs.PL", "D.3.1; F.3.2; D.3.2; D.3.3"], "pdf": "https://arxiv.org/pdf/2509.22614", "abs": "https://arxiv.org/abs/2509.22614", "authors": ["Dmitri Volkov", "Yafei Yang", "Chung-chieh Shan"], "title": "Committing to the bit: Relational programming with semiring arrays and SAT solving", "comment": "12 pages, for associated repo see\n  https://github.com/sporkl/semiringkanren", "summary": "We propose semiringKanren, a relational programming language where each\nrelation expression denotes a semiring array. We formalize a type system that\nrestricts the arrays to finite size. We then define a semantics that is\nparameterized by the semiring that the arrays draw their elements from. We\ncompile semiringKanren types to bitstring representations. For the Boolean\nsemiring, this compilation enables us to use an SAT solver to run\nsemiringKanren programs efficiently. We compare the performance of\nsemiringKanren and faster miniKanren for solving Sudoku puzzles. Our experiment\nshows that semiringKanren can be a more efficient variant of miniKanren.", "AI": {"tldr": "semiringKanren\u662f\u4e00\u79cd\u5173\u7cfb\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff0c\u5c06\u5173\u7cfb\u8868\u8fbe\u5f0f\u8868\u793a\u4e3a\u534a\u73af\u6570\u7ec4\uff0c\u901a\u8fc7\u7c7b\u578b\u7cfb\u7edf\u9650\u5236\u6570\u7ec4\u5927\u5c0f\u4e3a\u6709\u9650\uff0c\u5e76\u652f\u6301\u53c2\u6570\u5316\u8bed\u4e49\u3002\u901a\u8fc7\u5c06\u7c7b\u578b\u7f16\u8bd1\u4e3a\u4f4d\u4e32\u8868\u793a\uff0c\u5728\u5e03\u5c14\u534a\u73af\u4e0b\u53ef\u4f7f\u7528SAT\u6c42\u89e3\u5668\u9ad8\u6548\u6267\u884c\u7a0b\u5e8f\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5173\u7cfb\u5f0f\u7f16\u7a0b\u8bed\u8a00\u53d8\u4f53\uff0c\u901a\u8fc7\u534a\u73af\u6570\u7ec4\u8868\u793a\u548cSAT\u6c42\u89e3\u5668\u96c6\u6210\u6765\u63d0\u5347miniKanren\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fasemiringKanren\u8bed\u8a00\uff0c\u5b9a\u4e49\u7c7b\u578b\u7cfb\u7edf\u9650\u5236\u6570\u7ec4\u4e3a\u6709\u9650\u5927\u5c0f\uff0c\u53c2\u6570\u5316\u8bed\u4e49\u652f\u6301\u4e0d\u540c\u534a\u73af\uff0c\u5c06\u7c7b\u578b\u7f16\u8bd1\u4e3a\u4f4d\u4e32\u8868\u793a\uff0c\u5728\u5e03\u5c14\u534a\u73af\u4e0b\u4f7f\u7528SAT\u6c42\u89e3\u5668\u6267\u884c\u7a0b\u5e8f\u3002", "result": "\u4e0efaster miniKanren\u5728\u89e3\u51b3\u6570\u72ec\u8c1c\u9898\u4e0a\u7684\u6027\u80fd\u6bd4\u8f83\u663e\u793a\uff0csemiringKanren\u53ef\u4ee5\u6210\u4e3a\u66f4\u9ad8\u6548\u7684miniKanren\u53d8\u4f53\u3002", "conclusion": "semiringKanren\u901a\u8fc7\u534a\u73af\u6570\u7ec4\u8868\u793a\u548cSAT\u6c42\u89e3\u5668\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edfminiKanren\u66f4\u9ad8\u6548\u7684\u5173\u7cfb\u5f0f\u7f16\u7a0b\u3002"}}
{"id": "2509.21881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.21881", "abs": "https://arxiv.org/abs/2509.21881", "authors": ["Chaman Wijesiriwardana", "Prasad Wimalaratne"], "title": "Software Engineering Data Analytics: A Framework Based on a Multi-Layered Abstraction Mechanism", "comment": null, "summary": "This paper presents a concept of a domain-specific framework for software\nanalytics by enabling querying, modeling, and integration of heterogeneous\nsoftware repositories. The framework adheres to a multi-layered abstraction\nmechanism that consists of domain-specific operators. We showcased the\npotential of this approach by employing a case study.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8f6f\u4ef6\u5206\u6790\u7684\u9886\u57df\u7279\u5b9a\u6846\u67b6\uff0c\u652f\u6301\u5f02\u6784\u8f6f\u4ef6\u4ed3\u5e93\u7684\u67e5\u8be2\u3001\u5efa\u6a21\u548c\u96c6\u6210", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f02\u6784\u8f6f\u4ef6\u4ed3\u5e93\u6570\u636e\u96be\u4ee5\u7edf\u4e00\u5206\u6790\u548c\u96c6\u6210\u7684\u95ee\u9898", "method": "\u91c7\u7528\u591a\u5c42\u62bd\u8c61\u673a\u5236\uff0c\u5305\u542b\u9886\u57df\u7279\u5b9a\u64cd\u4f5c\u7b26\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1", "result": "\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6f5c\u529b", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8f6f\u4ef6\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9886\u57df\u7279\u5b9a\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.21891", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.21891", "abs": "https://arxiv.org/abs/2509.21891", "authors": ["Yangtian Zi", "Zixuan Wu", "Aleksander Boruch-Gruszecki", "Jonathan Bell", "Arjun Guha"], "title": "AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans", "comment": null, "summary": "Fine-tuning large language models for code editing has typically relied on\nmining commits and pull requests. The working hypothesis has been that commit\nmessages describe human intent in natural language, and patches to code\ndescribe the changes that implement that intent. However, much of the\npreviously collected data is noisy: commit messages are terse, human-written\ncommits commingle several unrelated edits, and many commits come from simple,\nrule-based bots.\n  The recent adoption of software engineering agents changes this landscape.\nCode changes co-authored by humans and agents tend to be more narrowly scoped\nand focused on clearer goals. Their commit messages, generated by LLMs,\narticulate intent and rationale in much greater detail. Moreover, when these\nchanges land in public repositories, they are implicitly filtered by humans:\nmaintainers discard low-quality commits to their projects.\n  We present AgentPack, a corpus of 1.3M code edits co-authored by Claude Code,\nOpenAI Codex, and Cursor Agent across public GitHub projects up to mid-August\n2025. We describe the identification and curation pipeline, quantify adoption\ntrends of these agents, and analyze the structural properties of the edits.\nFinally, we show that models fine-tuned on AgentPack can outperform models\ntrained on prior human-only commit corpora, highlighting the potential of using\npublic data from software engineering agents to train future code-editing\nmodels.", "AI": {"tldr": "AgentPack\u662f\u4e00\u4e2a\u5305\u542b130\u4e07\u4ee3\u7801\u7f16\u8f91\u7684\u6570\u636e\u96c6\uff0c\u7531Claude Code\u3001OpenAI Codex\u548cCursor Agent\u5728GitHub\u9879\u76ee\u4e2d\u5171\u540c\u521b\u4f5c\uff0c\u7528\u4e8e\u8bad\u7ec3\u4ee3\u7801\u7f16\u8f91\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u63d0\u4ea4\u8bb0\u5f55\u7684\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u566a\u97f3\u95ee\u9898\uff1a\u63d0\u4ea4\u4fe1\u606f\u7b80\u7565\u3001\u4eba\u7c7b\u63d0\u4ea4\u5305\u542b\u591a\u4e2a\u65e0\u5173\u7f16\u8f91\u3001\u8bb8\u591a\u63d0\u4ea4\u6765\u81ea\u7b80\u5355\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u673a\u5668\u4eba\u3002\u800c\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u751f\u6210\u7684\u4ee3\u7801\u53d8\u66f4\u66f4\u52a0\u4e13\u6ce8\uff0c\u63d0\u4ea4\u4fe1\u606f\u66f4\u8be6\u7ec6\uff0c\u4e14\u7ecf\u8fc7\u4eba\u7c7b\u7ef4\u62a4\u8005\u7684\u8d28\u91cf\u8fc7\u6ee4\u3002", "method": "\u6536\u96c6\u622a\u81f32025\u5e748\u6708\u4e2d\u65ec\u7684\u516c\u5171GitHub\u9879\u76ee\u4e2d\u7531Claude Code\u3001OpenAI Codex\u548cCursor Agent\u5171\u540c\u521b\u4f5c\u7684\u4ee3\u7801\u7f16\u8f91\uff0c\u5efa\u7acb\u8bc6\u522b\u548c\u7b5b\u9009\u6d41\u7a0b\uff0c\u5206\u6790\u8fd9\u4e9b\u7f16\u8f91\u7684\u7ed3\u6784\u7279\u6027\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b130\u4e07\u4ee3\u7801\u7f16\u8f91\u7684AgentPack\u8bed\u6599\u5e93\uff0c\u91cf\u5316\u4e86\u8fd9\u4e9b\u4ee3\u7406\u7684\u91c7\u7528\u8d8b\u52bf\uff0c\u5e76\u5206\u6790\u4e86\u7f16\u8f91\u7684\u7ed3\u6784\u7279\u6027\u3002", "conclusion": "\u5728AgentPack\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u80fd\u591f\u4f18\u4e8e\u5728\u4f20\u7edf\u4ec5\u6709\u4eba\u7c7b\u63d0\u4ea4\u8bed\u6599\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u8868\u660e\u5229\u7528\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u516c\u5171\u6570\u636e\u8bad\u7ec3\u672a\u6765\u4ee3\u7801\u7f16\u8f91\u6a21\u578b\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2509.21945", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.21945", "abs": "https://arxiv.org/abs/2509.21945", "authors": ["Pengzhou Chen", "Hongyuan Liang", "Tao Chen"], "title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective", "comment": "This paper is under review", "summary": "To efficiently tune configuration for better system performance (e.g.,\nlatency), many tuners have leveraged a surrogate model to expedite the process\ninstead of solely relying on the profoundly expensive system measurement. As\nsuch, it is naturally believed that we need more accurate models. However, the\nfact of accuracy can lie-a somewhat surprising finding from prior work-has left\nus many unanswered questions regarding what role the surrogate model plays in\nconfiguration tuning. This paper provides the very first systematic exploration\nand discussion, together with a resolution proposal, to disclose the many faces\nof surrogate models for configuration tuning, through the novel perspective of\nfitness landscape analysis. We present a theory as an alternative to accuracy\nfor assessing the model usefulness in tuning, based on which we conduct an\nextensive empirical study involving up to 27,000 cases. Drawing on the above,\nwe propose Model4Tune, an automated predictive tool that estimates which\nmodel-tuner pairs are the best for an unforeseen system without expensive tuner\nprofiling. Our results suggest that Moldel4Tune, as one of the first of its\nkind, performs significantly better than random guessing in 79%-82% of the\ncases. Our results not only shed light on the possible future research\ndirections but also offer a practical resolution that can assist practitioners\nin evaluating the most useful model for configuration tuning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9002\u5e94\u5ea6\u666f\u89c2\u5206\u6790\u7684\u65b0\u89c6\u89d2\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u4e86\u914d\u7f6e\u8c03\u4f18\u4e2d\u4ee3\u7406\u6a21\u578b\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u6a21\u578b\u6709\u7528\u6027\u7684\u66ff\u4ee3\u7406\u8bba\uff0c\u5e76\u5f00\u53d1\u4e86Model4Tune\u5de5\u5177\u6765\u9884\u6d4b\u6700\u4f73\u6a21\u578b-\u8c03\u4f18\u5668\u7ec4\u5408\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u914d\u7f6e\u8c03\u4f18\u9700\u8981\u66f4\u51c6\u786e\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u4f46\u5148\u524d\u7814\u7a76\u53d1\u73b0\u51c6\u786e\u6027\u53ef\u80fd\u5177\u6709\u6b3a\u9a97\u6027\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u4ee3\u7406\u6a21\u578b\u5728\u914d\u7f6e\u8c03\u4f18\u4e2d\u771f\u6b63\u4f5c\u7528\u7684\u7591\u95ee\u3002", "method": "\u91c7\u7528\u9002\u5e94\u5ea6\u666f\u89c2\u5206\u6790\u7684\u65b0\u89c6\u89d2\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u6a21\u578b\u6709\u7528\u6027\u7684\u66ff\u4ee3\u7406\u8bba\uff0c\u5e76\u8fdb\u884c\u4e86\u6d89\u53ca27,000\u4e2a\u6848\u4f8b\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1\u4e86\u81ea\u52a8\u9884\u6d4b\u5de5\u5177Model4Tune\u3002", "result": "Model4Tune\u572879%-82%\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u80fd\u591f\u4e3a\u672a\u89c1\u7cfb\u7edf\u9884\u6d4b\u6700\u4f73\u6a21\u578b-\u8c03\u4f18\u5668\u7ec4\u5408\uff0c\u800c\u65e0\u9700\u6602\u8d35\u7684\u8c03\u4f18\u5668\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u63ed\u793a\u4e86\u672a\u6765\u53ef\u80fd\u7684\u7814\u7a76\u65b9\u5411\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u8bc4\u4f30\u914d\u7f6e\u8c03\u4f18\u4e2d\u6700\u6709\u7528\u7684\u6a21\u578b\u3002"}}
{"id": "2509.22097", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.22097", "abs": "https://arxiv.org/abs/2509.22097", "authors": ["Junkai Chen", "Huihui Huang", "Yunbo Lyu", "Junwen An", "Jieke Shi", "Chengran Yang", "Ting Zhang", "Haoye Tian", "Yikun Li", "Zhenhao Li", "Xin Zhou", "Xing Hu", "David Lo"], "title": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios", "comment": null, "summary": "Large language model (LLM) powered code agents are rapidly transforming\nsoftware engineering by automating tasks such as testing, debugging, and\nrepairing, yet the security risks of their generated code have become a\ncritical concern. Existing benchmarks have offered valuable insights but remain\ninsufficient: they often overlook the genuine context in which vulnerabilities\nwere introduced or adopt narrow evaluation protocols that fail to capture\neither functional correctness or newly introduced vulnerabilities. We therefore\nintroduce SecureAgentBench, a benchmark of 105 coding tasks designed to\nrigorously evaluate code agents' capabilities in secure code generation. Each\ntask includes (i) realistic task settings that require multi-file edits in\nlarge repositories, (ii) aligned contexts based on real-world open-source\nvulnerabilities with precisely identified introduction points, and (iii)\ncomprehensive evaluation that combines functionality testing, vulnerability\nchecking through proof-of-concept exploits, and detection of newly introduced\nvulnerabilities using static analysis. We evaluate three representative agents\n(SWE-agent, OpenHands, and Aider) with three state-of-the-art LLMs (Claude 3.7\nSonnet, GPT-4.1, and DeepSeek-V3.1). Results show that (i) current agents\nstruggle to produce secure code, as even the best-performing one, SWE-agent\nsupported by DeepSeek-V3.1, achieves merely 15.2% correct-and-secure solutions,\n(ii) some agents produce functionally correct code but still introduce\nvulnerabilities, including new ones not previously recorded, and (iii) adding\nexplicit security instructions for agents does not significantly improve secure\ncoding, underscoring the need for further research. These findings establish\nSecureAgentBench as a rigorous benchmark for secure code generation and a step\ntoward more reliable software development with LLMs.", "AI": {"tldr": "SecureAgentBench\u662f\u4e00\u4e2a\u5305\u542b105\u4e2a\u7f16\u7801\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u4e25\u683c\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u5728\u5b89\u5168\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5f53\u524d\u4ee3\u7406\u5728\u751f\u6210\u5b89\u5168\u4ee3\u7801\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u6700\u4f73\u4ee3\u7406\u4e5f\u53ea\u80fd\u8fbe\u523015.2%\u7684\u6b63\u786e\u4e14\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8bc4\u4f30\u4ee3\u7801\u4ee3\u7406\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5f80\u5f80\u5ffd\u7565\u4e86\u6f0f\u6d1e\u5f15\u5165\u7684\u771f\u5b9e\u4e0a\u4e0b\u6587\uff0c\u6216\u91c7\u7528\u72ed\u7a84\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u65e0\u6cd5\u540c\u65f6\u6355\u6349\u529f\u80fd\u6b63\u786e\u6027\u548c\u65b0\u5f15\u5165\u7684\u6f0f\u6d1e\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b105\u4e2a\u7f16\u7801\u4efb\u52a1\u7684SecureAgentBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u4efb\u52a1\u5305\u542b\uff1a(i)\u9700\u8981\u5728\u5927\u4ed3\u5e93\u4e2d\u8fdb\u884c\u591a\u6587\u4ef6\u7f16\u8f91\u7684\u73b0\u5b9e\u4efb\u52a1\u8bbe\u7f6e\uff1b(ii)\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u5f00\u6e90\u6f0f\u6d1e\u7684\u4e0a\u4e0b\u6587\uff1b(iii)\u7ed3\u5408\u529f\u80fd\u6d4b\u8bd5\u3001\u6f0f\u6d1e\u68c0\u67e5\u548c\u9759\u6001\u5206\u6790\u7684\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u4ee3\u8868\u6027\u4ee3\u7406\uff08SWE-agent\u3001OpenHands\u3001Aider\uff09\u548c\u4e09\u4e2a\u6700\u5148\u8fdbLLM\uff08Claude 3.7 Sonnet\u3001GPT-4.1\u3001DeepSeek-V3.1\uff09\u3002\u7ed3\u679c\u663e\u793a\uff1a(i)\u5f53\u524d\u4ee3\u7406\u96be\u4ee5\u751f\u6210\u5b89\u5168\u4ee3\u7801\uff1b(ii)\u67d0\u4e9b\u4ee3\u7406\u751f\u6210\u529f\u80fd\u6b63\u786e\u4f46\u5f15\u5165\u6f0f\u6d1e\u7684\u4ee3\u7801\uff1b(iii)\u6dfb\u52a0\u660e\u786e\u5b89\u5168\u6307\u4ee4\u5bf9\u6539\u5584\u5b89\u5168\u7f16\u7801\u6548\u679c\u4e0d\u663e\u8457\u3002", "conclusion": "SecureAgentBench\u4e3a\u5b89\u5168\u4ee3\u7801\u751f\u6210\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u662f\u8fc8\u5411\u66f4\u53ef\u9760LLM\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e00\u6b65\uff0c\u7a81\u663e\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.22114", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22114", "abs": "https://arxiv.org/abs/2509.22114", "authors": ["Hanzhuo Tan", "Weihao Li", "Xiaolong Tian", "Siyi Wang", "Jiaming Liu", "Jing Li", "Yuqun Zhang"], "title": "SK2Decompile: LLM-based Two-Phase Binary Decompilation from Skeleton to Skin", "comment": null, "summary": "Large Language Models (LLMs) have emerged as a promising approach for binary\ndecompilation. However, the existing LLM-based decompilers still are somewhat\nlimited in effectively presenting a program's source-level structure with its\noriginal identifiers. To mitigate this, we introduce SK2Decompile, a novel\ntwo-phase approach to decompile from the skeleton (semantic structure) to the\nskin (identifier) of programs. Specifically, we first apply a Structure\nRecovery model to translate a program's binary code to an Intermediate\nRepresentation (IR) as deriving the program's \"skeleton\", i.e., preserving\ncontrol flow and data structures while obfuscating all identifiers with generic\nplaceholders. We also apply reinforcement learning to reward the model for\nproducing program structures that adhere to the syntactic and semantic rules\nexpected by compilers. Second, we apply an Identifier Naming model to produce\nmeaningful identifiers which reflect actual program semantics as deriving the\nprogram's \"skin\". We train the Identifier Naming model with a separate\nreinforcement learning objective that rewards the semantic similarity between\nits predictions and the reference code. Such a two-phase decompilation process\nfacilitates advancing the correctness and readability of decompilation\nindependently. Our evaluations indicate that SK2Decompile, significantly\noutperforms the SOTA baselines, achieving 21.6% average re-executability rate\ngain over GPT-5-mini on the HumanEval dataset and 29.4% average R2I improvement\nover Idioms on the GitHub2025 benchmark.", "AI": {"tldr": "SK2Decompile\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u53cd\u7f16\u8bd1\u65b9\u6cd5\uff0c\u5148\u6062\u590d\u7a0b\u5e8f\u7ed3\u6784\uff08\u9aa8\u67b6\uff09\uff0c\u518d\u751f\u6210\u6807\u8bc6\u7b26\uff08\u76ae\u80a4\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53cd\u7f16\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u53cd\u7f16\u8bd1\u5668\u5728\u6709\u6548\u5448\u73b0\u7a0b\u5e8f\u6e90\u4ee3\u7801\u7ed3\u6784\u548c\u539f\u59cb\u6807\u8bc6\u7b26\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u9700\u8981\u6539\u8fdb\u7a0b\u5e8f\u7ed3\u6784\u6062\u590d\u548c\u6807\u8bc6\u7b26\u547d\u540d\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u7ed3\u6784\u6062\u590d\u6a21\u578b\u5c06\u4e8c\u8fdb\u5236\u4ee3\u7801\u8f6c\u6362\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u4fdd\u7559\u63a7\u5236\u6d41\u548c\u6570\u636e\u7ed3\u6784\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u786e\u4fdd\u7b26\u5408\u7f16\u8bd1\u5668\u89c4\u5219\uff1b2) \u6807\u8bc6\u7b26\u547d\u540d\u6a21\u578b\u751f\u6210\u6709\u610f\u4e49\u7684\u6807\u8bc6\u7b26\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "result": "\u5728HumanEval\u6570\u636e\u96c6\u4e0a\u6bd4GPT-5-mini\u5e73\u5747\u91cd\u6267\u884c\u7387\u63d0\u9ad821.6%\uff0c\u5728GitHub2025\u57fa\u51c6\u4e0a\u6bd4Idioms\u5e73\u5747R2I\u6539\u8fdb29.4%\u3002", "conclusion": "SK2Decompile\u901a\u8fc7\u5206\u79bb\u7ed3\u6784\u6062\u590d\u548c\u6807\u8bc6\u7b26\u547d\u540d\u4e24\u4e2a\u9636\u6bb5\uff0c\u72ec\u7acb\u63a8\u8fdb\u53cd\u7f16\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2509.22170", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22170", "abs": "https://arxiv.org/abs/2509.22170", "authors": ["Chengjia Wang", "Lanling Tang", "Ming Yuan", "Jiongchi Yu", "Xiaofei Xie", "Jiajun Bu"], "title": "Leveraging LLM Agents for Automated Video Game Testing", "comment": "17 pages", "summary": "Testing MMORPGs (Massively Multiplayer Online Role-Playing Games) is a\ncritical yet labor-intensive task in game development due to their complexity\nand frequent updating nature. Traditional automated game testing approaches\nstruggle to achieve high state coverage and efficiency in these rich,\nopen-ended environments, while existing LLM-based game-playing approaches are\nlimited to shallow reasoning ability in understanding complex game state-action\nspaces and long-complex tasks. To address these challenges, we propose TITAN,\nan effective LLM-driven agent framework for intelligent MMORPG testing. TITAN\nincorporates four key components to: (1) perceive and abstract high-dimensional\ngame states, (2) proactively optimize and prioritize available actions, (3)\nenable long-horizon reasoning with action trace memory and reflective\nself-correction, and (4) employ LLM-based oracles to detect potential\nfunctional and logic bugs with diagnostic reports.\n  We implement the prototype of TITAN and evaluate it on two large-scale\ncommercial MMORPGs spanning both PC and mobile platforms. In our experiments,\nTITAN achieves significantly higher task completion rates (95%) and bug\ndetection performance compared to existing automated game testing approaches.\nAn ablation study further demonstrates that each core component of TITAN\ncontributes substantially to its overall performance. Notably, TITAN detects\nfour previously unknown bugs that prior testing approaches fail to identify. We\nprovide an in-depth discussion of these results, which offer guidance for new\navenues of advancing intelligent, general-purpose testing systems. Moreover,\nTITAN has been deployed in eight real-world game QA pipelines, underscoring its\npractical impact as an LLM-driven game testing framework.", "AI": {"tldr": "TITAN\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fdMMORPG\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u3001\u52a8\u4f5c\u4f18\u5316\u3001\u957f\u65f6\u7a0b\u63a8\u7406\u548cLLM\u9884\u8a00\u673a\u7b49\u7ec4\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548cbug\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u5316\u6e38\u620f\u6d4b\u8bd5\u65b9\u6cd5\u5728MMORPG\u8fd9\u7c7b\u590d\u6742\u5f00\u653e\u73af\u5883\u4e2d\u96be\u4ee5\u5b9e\u73b0\u9ad8\u72b6\u6001\u8986\u76d6\u7387\u548c\u6548\u7387\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5bf9\u590d\u6742\u6e38\u620f\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u548c\u957f\u590d\u6742\u4efb\u52a1\u7684\u7406\u89e3\u80fd\u529b\u6709\u9650\u3002", "method": "TITAN\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u9ad8\u7ef4\u6e38\u620f\u72b6\u6001\u611f\u77e5\u4e0e\u62bd\u8c61\u3001\u4e3b\u52a8\u4f18\u5316\u548c\u4f18\u5148\u5904\u7406\u53ef\u7528\u52a8\u4f5c\u3001\u5177\u6709\u52a8\u4f5c\u8f68\u8ff9\u8bb0\u5fc6\u548c\u53cd\u601d\u81ea\u6821\u6b63\u7684\u957f\u65f6\u7a0b\u63a8\u7406\u3001\u57fa\u4e8eLLM\u7684\u9884\u8a00\u673a\u68c0\u6d4b\u529f\u80fd\u6027\u548c\u903b\u8f91bug\u3002", "result": "\u5728\u4e24\u4e2a\u5927\u578b\u5546\u4e1aMMORPG\u4e0a\u6d4b\u8bd5\uff0cTITAN\u8fbe\u523095%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0cbug\u68c0\u6d4b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e86\u56db\u4e2a\u5148\u524d\u672a\u77e5\u7684bug\uff0c\u5df2\u5728\u516b\u4e2a\u771f\u5b9e\u6e38\u620fQA\u6d41\u6c34\u7ebf\u4e2d\u90e8\u7f72\u3002", "conclusion": "TITAN\u8bc1\u660e\u4e86LLM\u9a71\u52a8\u667a\u80fd\u6d4b\u8bd5\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3a\u63a8\u8fdb\u901a\u7528\u6d4b\u8bd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.22202", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.22202", "abs": "https://arxiv.org/abs/2509.22202", "authors": ["Lukas Twist", "Jie M. Zhang", "Mark Harman", "Helen Yannakoudakis"], "title": "Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries", "comment": "23 pages, 5 tables", "summary": "Large language models (LLMs) are increasingly used to generate code, yet they\ncontinue to hallucinate, often inventing non-existent libraries. Such library\nhallucinations are not just benign errors: they can mislead developers, break\nbuilds, and expose systems to supply chain threats such as slopsquatting.\nDespite increasing awareness of these risks, little is known about how\nreal-world prompt variations affect hallucination rates. Therefore, we present\nthe first systematic study of how user-level prompt variations impact library\nhallucinations in LLM-generated code. We evaluate six diverse LLMs across two\nhallucination types: library name hallucinations (invalid imports) and library\nmember hallucinations (invalid calls from valid libraries). We investigate how\nrealistic user language extracted from developer forums and how user errors of\nvarying degrees (one- or multi-character misspellings and completely fake\nnames/members) affect LLM hallucination rates. Our findings reveal systemic\nvulnerabilities: one-character misspellings in library names trigger\nhallucinations in up to 26% of tasks, fake library names are accepted in up to\n99% of tasks, and time-related prompts lead to hallucinations in up to 84% of\ntasks. Prompt engineering shows promise for mitigating hallucinations, but\nremains inconsistent and LLM-dependent. Our results underscore the fragility of\nLLMs to natural prompt variation and highlight the urgent need for safeguards\nagainst library-related hallucinations and their potential exploitation.", "AI": {"tldr": "\u7cfb\u7edf\u7814\u7a76\u7528\u6237\u63d0\u793a\u53d8\u5316\u5bf9LLM\u751f\u6210\u4ee3\u7801\u4e2d\u5e93\u5e7b\u89c9\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8f7b\u5fae\u62fc\u5199\u9519\u8bef\u548c\u865a\u5047\u5e93\u540d\u4f1a\u663e\u8457\u589e\u52a0\u5e7b\u89c9\u7387\uff0c\u63d0\u793a\u5de5\u7a0b\u6709\u7f13\u89e3\u4f5c\u7528\u4f46\u4e0d\u7a33\u5b9a\u3002", "motivation": "LLM\u5728\u751f\u6210\u4ee3\u7801\u65f6\u7ecf\u5e38\u4ea7\u751f\u5e93\u5e7b\u89c9\uff08\u53d1\u660e\u4e0d\u5b58\u5728\u7684\u5e93\uff09\uff0c\u8fd9\u4e9b\u5e7b\u89c9\u53ef\u80fd\u8bef\u5bfc\u5f00\u53d1\u8005\u3001\u7834\u574f\u6784\u5efa\u8fc7\u7a0b\u5e76\u5e26\u6765\u4f9b\u5e94\u94fe\u5b89\u5168\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u4e16\u754c\u63d0\u793a\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u5e7b\u89c9\u7387\u7684\u7cfb\u7edf\u6027\u4e86\u89e3\u3002", "method": "\u8bc4\u4f306\u4e2a\u4e0d\u540cLLM\u5728\u4e24\u79cd\u5e7b\u89c9\u7c7b\u578b\u4e0a\u7684\u8868\u73b0\uff1a\u5e93\u540d\u5e7b\u89c9\uff08\u65e0\u6548\u5bfc\u5165\uff09\u548c\u5e93\u6210\u5458\u5e7b\u89c9\uff08\u6709\u6548\u5e93\u4e2d\u7684\u65e0\u6548\u8c03\u7528\uff09\uff0c\u7814\u7a76\u4ece\u5f00\u53d1\u8005\u8bba\u575b\u63d0\u53d6\u7684\u771f\u5b9e\u7528\u6237\u8bed\u8a00\u4ee5\u53ca\u4e0d\u540c\u7a0b\u5ea6\u7528\u6237\u9519\u8bef\uff08\u5355\u5b57\u7b26/\u591a\u5b57\u7b26\u62fc\u5199\u9519\u8bef\u548c\u5b8c\u5168\u865a\u5047\u540d\u79f0/\u6210\u5458\uff09\u5bf9\u5e7b\u89c9\u7387\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u6f0f\u6d1e\uff1a\u5e93\u540d\u4e2d\u5355\u5b57\u7b26\u62fc\u5199\u9519\u8bef\u5728\u9ad8\u8fbe26%\u7684\u4efb\u52a1\u4e2d\u89e6\u53d1\u5e7b\u89c9\uff0c\u865a\u5047\u5e93\u540d\u5728\u9ad8\u8fbe99%\u7684\u4efb\u52a1\u4e2d\u88ab\u63a5\u53d7\uff0c\u65f6\u95f4\u76f8\u5173\u63d0\u793a\u5728\u9ad8\u8fbe84%\u7684\u4efb\u52a1\u4e2d\u5bfc\u81f4\u5e7b\u89c9\u3002\u63d0\u793a\u5de5\u7a0b\u6709\u7f13\u89e3\u4f5c\u7528\u4f46\u4e0d\u4e00\u81f4\u4e14\u4f9d\u8d56\u5177\u4f53LLM\u3002", "conclusion": "LLM\u5bf9\u81ea\u7136\u63d0\u793a\u53d8\u5316\u7684\u8106\u5f31\u6027\u7a81\u51fa\uff0c\u8feb\u5207\u9700\u8981\u9488\u5bf9\u5e93\u76f8\u5173\u5e7b\u89c9\u53ca\u5176\u6f5c\u5728\u5229\u7528\u7684\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u3002"}}
{"id": "2509.22320", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22320", "abs": "https://arxiv.org/abs/2509.22320", "authors": ["Vincenzo De Martino", "Mohammad Amin Zadenoori", "Xavier Franch", "Alessio Ferrari"], "title": "Green Prompt Engineering: Investigating the Energy Impact of Prompt Design in Software Engineering", "comment": null, "summary": "Language Models are increasingly applied in software engineering, yet their\ninference raises growing environmental concerns. Prior work has examined\nhardware choices and prompt length, but little attention has been paid to\nlinguistic complexity as a sustainability factor. This paper introduces Green\nPrompt Engineering, framing linguistic complexity as a design dimension that\ncan influence energy consumption and performance. We conduct an empirical study\non requirement classification using open-source Small Language Models, varying\nthe readability of prompts. Our results reveal that readability affects\nenvironmental sustainability and performance, exposing trade-offs between them.\nFor practitioners, simpler prompts can reduce energy costs without a\nsignificant F1-score loss; for researchers, it opens a path toward guidelines\nand studies on sustainable prompt design within the Green AI agenda.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7eff\u8272\u63d0\u793a\u5de5\u7a0b\u7684\u6982\u5ff5\uff0c\u5c06\u8bed\u8a00\u590d\u6742\u5ea6\u4f5c\u4e3a\u5f71\u54cd\u80fd\u8017\u548c\u6027\u80fd\u7684\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u63d0\u793a\u7684\u53ef\u8bfb\u6027\u4f1a\u5f71\u54cd\u73af\u5883\u53ef\u6301\u7eed\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u5176\u63a8\u7406\u8fc7\u7a0b\u5f15\u53d1\u4e86\u73af\u5883\u62c5\u5fe7\u3002\u73b0\u6709\u7814\u7a76\u5173\u6ce8\u786c\u4ef6\u9009\u62e9\u548c\u63d0\u793a\u957f\u5ea6\uff0c\u4f46\u5f88\u5c11\u5173\u6ce8\u8bed\u8a00\u590d\u6742\u5ea6\u4f5c\u4e3a\u53ef\u6301\u7eed\u6027\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9700\u6c42\u5206\u7c7b\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc7\u6539\u53d8\u63d0\u793a\u7684\u53ef\u8bfb\u6027\u6765\u8bc4\u4f30\u5176\u5bf9\u80fd\u8017\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ef\u8bfb\u6027\u5f71\u54cd\u73af\u5883\u53ef\u6301\u7eed\u6027\u548c\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u4e8c\u8005\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002\u5bf9\u4e8e\u5b9e\u8df5\u8005\uff0c\u66f4\u7b80\u5355\u7684\u63d0\u793a\u53ef\u4ee5\u5728\u4e0d\u660e\u663e\u635f\u5931F1\u5206\u6570\u7684\u60c5\u51b5\u4e0b\u964d\u4f4e\u80fd\u8017\u6210\u672c\u3002", "conclusion": "\u7eff\u8272\u63d0\u793a\u5de5\u7a0b\u4e3a\u7814\u7a76\u4eba\u5458\u5728\u7eff\u8272AI\u8bae\u7a0b\u4e0b\u5236\u5b9a\u53ef\u6301\u7eed\u63d0\u793a\u8bbe\u8ba1\u6307\u5357\u548c\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2509.22337", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22337", "abs": "https://arxiv.org/abs/2509.22337", "authors": ["Haoyu Feng", "Xin Zhang"], "title": "GPU-Accelerated Loopy Belief Propagation for Program Analysis", "comment": null, "summary": "Loopy Belief Propagation (LBP) is a widely used approximate inference\nalgorithm in probabilistic graphical models, with applications in computer\nvision, error correction codes, protein folding, program analysis, etc.\nHowever, LBP faces significant computational challenges when applied to\nlarge-scale program analysis. While GPU (Graphics Processing Unit) parallel\ncomputing provides a promising solution, existing approaches lack support for\nflexible update strategies and have yet to integrate logical constraints with\nGPU acceleration, leading to suboptimal practical performance.\n  This paper presents a GPU-accelerated LBP algorithm for program analysis. To\nsupport the diverse update strategies required by users, we propose a unified\nrepresentation for specifying arbitrary user-defined update strategies, along\nwith a dependency analysis algorithm. Furthermore, building on previous work\nthat leverages the local structure of Horn clauses to simplify message passing,\nwe group messages to minimize warp divergence and better utilize GPU resources.\nExperimental results on datarace analysis over eight real-world Java programs\nshow that our approach achieves an average speedup of $2.14\\times$ over the\nstate-of-the-art sequential approach and $5.56\\times$ over the state-of-the-art\nGPU-based approach, while maintaining high accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7a0b\u5e8f\u5206\u6790\u7684GPU\u52a0\u901fLBP\u7b97\u6cd5\uff0c\u901a\u8fc7\u7edf\u4e00\u8868\u793a\u652f\u6301\u7075\u6d3b\u66f4\u65b0\u7b56\u7565\uff0c\u5e76\u5229\u7528\u6d88\u606f\u5206\u7ec4\u4f18\u5316GPU\u8d44\u6e90\u5229\u7528\uff0c\u5728\u6570\u636e\u7ade\u4e89\u5206\u6790\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u52a0\u901f\u3002", "motivation": "LBP\u5728\u7a0b\u5e8f\u5206\u6790\u4e2d\u9762\u4e34\u5927\u89c4\u6a21\u8ba1\u7b97\u6311\u6218\uff0c\u73b0\u6709GPU\u65b9\u6cd5\u7f3a\u4e4f\u7075\u6d3b\u66f4\u65b0\u7b56\u7565\u652f\u6301\u4e14\u672a\u96c6\u6210\u903b\u8f91\u7ea6\u675f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u8868\u793a\u652f\u6301\u4efb\u610f\u7528\u6237\u5b9a\u4e49\u66f4\u65b0\u7b56\u7565\uff0c\u8fdb\u884c\u4f9d\u8d56\u5206\u6790\uff0c\u5e76\u57fa\u4e8eHorn\u5b50\u53e5\u5c40\u90e8\u7ed3\u6784\u5206\u7ec4\u6d88\u606f\u4ee5\u51cf\u5c11warp\u5206\u6b67\uff0c\u4f18\u5316GPU\u8d44\u6e90\u5229\u7528\u3002", "result": "\u57288\u4e2a\u771f\u5b9eJava\u7a0b\u5e8f\u7684\u6570\u636e\u7ade\u4e89\u5206\u6790\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u6700\u4f18\u987a\u5e8f\u65b9\u6cd5\u5e73\u5747\u52a0\u901f2.14\u500d\uff0c\u76f8\u6bd4\u6700\u4f18GPU\u65b9\u6cd5\u5e73\u5747\u52a0\u901f5.56\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "GPU\u52a0\u901fLBP\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u7a0b\u5e8f\u5206\u6790\u6027\u80fd\uff0c\u652f\u6301\u7075\u6d3b\u66f4\u65b0\u7b56\u7565\u5e76\u4f18\u5316GPU\u8d44\u6e90\u5229\u7528\uff0c\u4e3a\u5927\u89c4\u6a21\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.22379", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.22379", "abs": "https://arxiv.org/abs/2509.22379", "authors": ["Stefano Carlo Lambertenghi", "Mirena Flores Valdez", "Andrea Stocco"], "title": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems", "comment": "In proceedings of the 40th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE '25)", "summary": "Simulation-based testing is a cornerstone of Autonomous Driving System (ADS)\ndevelopment, offering safe and scalable evaluation across diverse driving\nscenarios. However, discrepancies between simulated and real-world behavior,\nknown as the reality gap, challenge the transferability of test results to\ndeployed systems. In this paper, we present a comprehensive empirical study\ncomparing four representative testing modalities: Software-in-the-Loop (SiL),\nVehicle-in-the-Loop (ViL), Mixed-Reality (MR), and full real-world testing.\nUsing a small-scale physical vehicle equipped with real sensors (camera and\nLiDAR) and its digital twin, we implement each setup and evaluate two ADS\narchitectures (modular and end-to-end) across diverse indoor driving scenarios\ninvolving real obstacles, road topologies, and indoor environments. We\nsystematically assess the impact of each testing modality along three\ndimensions of the reality gap: actuation, perception, and behavioral fidelity.\nOur results show that while SiL and ViL setups simplify critical aspects of\nreal-world dynamics and sensing, MR testing improves perceptual realism without\ncompromising safety or control. Importantly, we identify the conditions under\nwhich failures do not transfer across testing modalities and isolate the\nunderlying dimensions of the gap responsible for these discrepancies. Our\nfindings offer actionable insights into the respective strengths and\nlimitations of each modality and outline a path toward more robust and\ntransferable validation of autonomous driving systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u56db\u79cd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u6a21\u5f0f\uff08SiL\u3001ViL\u3001MR\u548c\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\uff09\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u6267\u884c\u3001\u611f\u77e5\u548c\u884c\u4e3a\u4fdd\u771f\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u73b0\u5b9e\u5dee\u8ddd\uff0c\u53d1\u73b0MR\u6d4b\u8bd5\u5728\u63d0\u5347\u611f\u77e5\u771f\u5b9e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5b89\u5168\u548c\u63a7\u5236\u80fd\u529b\u3002", "motivation": "\u6a21\u62df\u6d4b\u8bd5\u4e0e\u771f\u5b9e\u4e16\u754c\u884c\u4e3a\u4e4b\u95f4\u5b58\u5728\u73b0\u5b9e\u5dee\u8ddd\uff0c\u8fd9\u6311\u6218\u4e86\u6d4b\u8bd5\u7ed3\u679c\u5411\u5b9e\u9645\u90e8\u7f72\u7cfb\u7edf\u7684\u53ef\u8f6c\u79fb\u6027\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u6d4b\u8bd5\u6a21\u5f0f\u5728\u73b0\u5b9e\u5dee\u8ddd\u5404\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u914d\u5907\u771f\u5b9e\u4f20\u611f\u5668\u7684\u5c0f\u578b\u7269\u7406\u8f66\u8f86\u53ca\u5176\u6570\u5b57\u5b6a\u751f\uff0c\u5b9e\u73b0\u56db\u79cd\u6d4b\u8bd5\u8bbe\u7f6e\uff08SiL\u3001ViL\u3001MR\u548c\u771f\u5b9e\u6d4b\u8bd5\uff09\uff0c\u5728\u6d89\u53ca\u771f\u5b9e\u969c\u788d\u7269\u3001\u9053\u8def\u62d3\u6251\u548c\u5ba4\u5185\u73af\u5883\u7684\u591a\u6837\u5316\u9a7e\u9a76\u573a\u666f\u4e2d\u8bc4\u4f30\u4e24\u79cdADS\u67b6\u6784\u3002", "result": "SiL\u548cViL\u8bbe\u7f6e\u7b80\u5316\u4e86\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u548c\u611f\u77e5\u7684\u5173\u952e\u65b9\u9762\uff0c\u800cMR\u6d4b\u8bd5\u5728\u4e0d\u5f71\u54cd\u5b89\u5168\u6216\u63a7\u5236\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u611f\u77e5\u771f\u5b9e\u6027\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u6545\u969c\u5728\u4e0d\u540c\u6d4b\u8bd5\u6a21\u5f0f\u95f4\u4e0d\u8f6c\u79fb\u7684\u6761\u4ef6\uff0c\u5e76\u5206\u79bb\u4e86\u5bfc\u81f4\u8fd9\u4e9b\u5dee\u5f02\u7684\u73b0\u5b9e\u5dee\u8ddd\u7ef4\u5ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6bcf\u79cd\u6d4b\u8bd5\u6a21\u5f0f\u7684\u4f18\u7f3a\u70b9\u63d0\u4f9b\u4e86\u53ef\u884c\u89c1\u89e3\uff0c\u5e76\u4e3a\u5b9e\u73b0\u66f4\u7a33\u5065\u548c\u53ef\u8f6c\u79fb\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9a8c\u8bc1\u6307\u660e\u4e86\u8def\u5f84\u3002"}}
{"id": "2509.22420", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.22420", "abs": "https://arxiv.org/abs/2509.22420", "authors": ["Ziyi Zhang", "Devjeet Roy", "Venera Arnaoudova"], "title": "Context-Specific Instruction: A Longitudinal Study on Debugging Skill Acquisition and Retention for Novice Programmers", "comment": "31 pages (25 pages for the paper, rest pages are references and\n  appendix). 4 tables, 7 figures", "summary": "Bug localization is a critical skill, yet novices often lack systematic\napproaches. Prior work tested abstract guidelines and general concrete steps;\nthe impact of context-specific instruction is unclear. We ran an eight-week\nlongitudinal study with four conditions: no instruction (G1), abstract\nguidelines (G2), concrete steps (G3), and our context-specific instruction that\npairs concrete bug-localization steps with problem-specific details (G4).\nForty-four undergraduates participated; 41 completed all five sessions (S1-S5).\nEach session included 2-3 debugging tasks to identify the minimal code element\ncontaining a seeded logical fault. We measured correctness (binary), time to\ncompletion, self-perceived scores (stress, difficulty, satisfaction, and\nstrategy adherence). G4 achieved higher correctness and shorter time to\ncompletion: it reached 80% correctness after one session (vs. 20-44% for other\ngroups) and maintained 80% after three weeks, outperforming all groups (p <\n0.05); its time to completion stabilized at 13-15 minutes in S1, whereas other\ngroups took 2-3 sessions to stabilize at 22-27 minutes. Qualitative responses\nshowed lower stress and higher satisfaction in G4, with participants\ninternalizing strategies via contextual examples. We conclude that\ncontext-specific instruction yields faster skill acquisition and stronger\nretention than abstract guidelines or context-agnostic steps. Even 1-2 sessions\nproduced significant gains, while extended practice optimized and stabilized\nperformance. Integrating contextual examples with abstract principles may\nbridge theory-practice gaps in bug-localization education and provide a more\nequitable path for novices.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u516b\u5468\u7eb5\u5411\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u56db\u79cd\u8c03\u8bd5\u6307\u5bfc\u65b9\u6cd5\uff1a\u65e0\u6307\u5bfc\u3001\u62bd\u8c61\u6307\u5357\u3001\u5177\u4f53\u6b65\u9aa4\u548c\u4e0a\u4e0b\u6587\u7279\u5b9a\u6307\u5bfc\u3002\u7ed3\u679c\u663e\u793a\u4e0a\u4e0b\u6587\u7279\u5b9a\u6307\u5bfc\u5728\u6b63\u786e\u7387\u548c\u5b8c\u6210\u65f6\u95f4\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u53c2\u4e0e\u8005\u80fd\u66f4\u5feb\u638c\u63e1\u6280\u80fd\u5e76\u4fdd\u6301\u957f\u671f\u6548\u679c\u3002", "motivation": "\u65b0\u624b\u5728bug\u5b9a\u4f4d\u65f6\u7f3a\u4e4f\u7cfb\u7edf\u65b9\u6cd5\uff0c\u73b0\u6709\u7814\u7a76\u6d4b\u8bd5\u4e86\u62bd\u8c61\u6307\u5357\u548c\u901a\u7528\u5177\u4f53\u6b65\u9aa4\uff0c\u4f46\u4e0a\u4e0b\u6587\u7279\u5b9a\u6307\u5bfc\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "44\u540d\u672c\u79d1\u751f\u53c2\u4e0e\u516b\u5468\u7eb5\u5411\u7814\u7a76\uff0c\u5206\u4e3a\u56db\u7ec4\uff1a\u65e0\u6307\u5bfc(G1)\u3001\u62bd\u8c61\u6307\u5357(G2)\u3001\u5177\u4f53\u6b65\u9aa4(G3)\u3001\u4e0a\u4e0b\u6587\u7279\u5b9a\u6307\u5bfc(G4)\u3002\u6bcf\u8282\u5305\u542b2-3\u4e2a\u8c03\u8bd5\u4efb\u52a1\uff0c\u6d4b\u91cf\u6b63\u786e\u7387\u3001\u5b8c\u6210\u65f6\u95f4\u3001\u81ea\u6211\u611f\u77e5\u8bc4\u5206\u3002", "result": "G4\u7ec4\u5728\u7b2c\u4e00\u8282\u540e\u8fbe\u523080%\u6b63\u786e\u7387\uff08\u5176\u4ed6\u7ec420-44%\uff09\uff0c\u4e09\u5468\u540e\u4ecd\u4fdd\u630180%\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7ec4(p<0.05)\u3002\u5b8c\u6210\u65f6\u95f4\u7a33\u5b9a\u572813-15\u5206\u949f\uff0c\u800c\u5176\u4ed6\u7ec4\u97002-3\u8282\u624d\u80fd\u7a33\u5b9a\u572822-27\u5206\u949f\u3002G4\u7ec4\u538b\u529b\u66f4\u4f4e\u3001\u6ee1\u610f\u5ea6\u66f4\u9ad8\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u7279\u5b9a\u6307\u5bfc\u6bd4\u62bd\u8c61\u6307\u5357\u6216\u4e0a\u4e0b\u6587\u65e0\u5173\u6b65\u9aa4\u80fd\u66f4\u5feb\u83b7\u5f97\u6280\u80fd\u5e76\u4fdd\u6301\u66f4\u5f3a\u8bb0\u5fc6\u3002\u5c06\u4e0a\u4e0b\u6587\u793a\u4f8b\u4e0e\u62bd\u8c61\u539f\u5219\u7ed3\u5408\u53ef\u5f25\u5408bug\u5b9a\u4f4d\u6559\u80b2\u4e2d\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\uff0c\u4e3a\u65b0\u624b\u63d0\u4f9b\u66f4\u516c\u5e73\u7684\u5b66\u4e60\u8def\u5f84\u3002"}}
{"id": "2509.22431", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22431", "abs": "https://arxiv.org/abs/2509.22431", "authors": ["Zhengyu Chen", "Zhaoyi Meng", "Wenxiang Zhao", "Wansen Wang", "Haoyang Zhao", "Jiahao Zhan", "Jie Cui", "Hong Zhong"], "title": "TreeMind: Automatically Reproducing Android Bug Reports via LLM-empowered Monte Carlo Tree Search", "comment": null, "summary": "Automatically reproducing Android app crashes from textual bug reports is\nchallenging, particularly when the reports are incomplete and the modern UI\nexhibits high combinatorial complexity. Existing approaches based on\nreinforcement learning or large language models (LLMs) exhibit limitations in\nsuch scenarios. They struggle to infer unobserved steps and reconstruct the\nunderlying user action sequences to navigate the vast UI interaction space,\nprimarily due to limited goal-directed reasoning and planning. We present\nTreeMind, a novel technique that integrates LLMs with a customized Monte Carlo\nTree Search (MCTS) algorithm to achieve strategic UI exploration in bug\nreproduction. To the best of our knowledge, this is the first work to combine\nexternal decision-making with LLM semantic reasoning for reliable bug\nreproduction. We formulate the reproduction task as a target-driven search\nproblem, leveraging MCTS as the core planning mechanism to iteratively refine\naction sequences. To enhance MCTS with semantic reasoning, we introduce two\nLLM-guided agents with distinct roles: Expander generates top-k promising\nactions based on the current UI state and exploration history, while Simulator\nestimates the likelihood that each action leads toward successful reproduction.\nBy incorporating multi-modal UI inputs and advanced prompting techniques,\nTreeMind conducts feedback-aware navigation that identifies missing but\nessential user actions and incrementally reconstructs the reproduction paths.\nWe evaluate TreeMind on a dataset of 93 real-world Android bug reports from\nthree widely-used benchmarks. Experimental results show that it significantly\noutperforms four state-of-the-art baselines in reproduction success rate. A\nreal-world case study indicates that integrating LLM reasoning with MCTS-based\nplanning is a compelling direction for automated bug reproduction.", "AI": {"tldr": "TreeMind\u7ed3\u5408LLM\u4e0e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u901a\u8fc7\u6218\u7565\u6027\u7684UI\u63a2\u7d22\u6765\u81ea\u52a8\u590d\u73b0Android\u5e94\u7528\u5d29\u6e83\uff0c\u5728\u771f\u5b9ebug\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u6216LLM\u7684\u65b9\u6cd5\u5728\u590d\u73b0\u4e0d\u5b8c\u6574bug\u62a5\u544a\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u96be\u4ee5\u63a8\u65ad\u672a\u89c2\u5bdf\u6b65\u9aa4\u5e76\u5bfc\u822a\u590d\u6742\u7684UI\u4ea4\u4e92\u7a7a\u95f4\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u76ee\u6807\u5bfc\u5411\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002", "method": "\u5c06\u590d\u73b0\u4efb\u52a1\u5efa\u6a21\u4e3a\u76ee\u6807\u9a71\u52a8\u7684\u641c\u7d22\u95ee\u9898\uff0c\u96c6\u6210LLM\u4e0e\u5b9a\u5236\u5316MCTS\u7b97\u6cd5\uff1aExpander\u4ee3\u7406\u57fa\u4e8e\u5f53\u524dUI\u72b6\u6001\u751f\u6210top-k\u6709\u524d\u666f\u52a8\u4f5c\uff0cSimulator\u4ee3\u7406\u8bc4\u4f30\u6bcf\u4e2a\u52a8\u4f5c\u5bfc\u5411\u6210\u529f\u590d\u73b0\u7684\u53ef\u80fd\u6027\u3002", "result": "\u572893\u4e2a\u771f\u5b9eAndroid bug\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTreeMind\u5728\u590d\u73b0\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u56db\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5c06LLM\u63a8\u7406\u4e0eMCTS\u89c4\u5212\u76f8\u7ed3\u5408\u662f\u5b9e\u73b0\u81ea\u52a8\u5316bug\u590d\u73b0\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u901a\u8fc7\u53cd\u9988\u611f\u77e5\u5bfc\u822a\u80fd\u591f\u8bc6\u522b\u7f3a\u5931\u7684\u5173\u952e\u7528\u6237\u64cd\u4f5c\u5e76\u9010\u6b65\u91cd\u5efa\u590d\u73b0\u8def\u5f84\u3002"}}
{"id": "2509.22530", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.22530", "abs": "https://arxiv.org/abs/2509.22530", "authors": ["Baijun Cheng", "Kailong Wang", "Ling Shi", "Haoyu Wang", "Peng Di", "Yao Guo", "Ding Li", "Xiangqun Chen"], "title": "Boosting Pointer Analysis With Large Language Model-Enhanced Allocation Function Detection", "comment": null, "summary": "Pointer analysis is foundational for many static analysis tasks, yet its\neffectiveness is often hindered by imprecise modeling of heap allocations,\nparticularly in C/C++ programs where user-defined allocation functions (AFs)\nare pervasive. Existing approaches largely overlook these custom allocators,\nleading to coarse aliasing and reduced analysis precision. In this paper, we\npresent AFD, a novel technique that enhances pointer analysis by automatically\nidentifying and modeling custom allocation functions. AFD employs a hybrid\napproach: it uses value-flow analysis to detect straightforward wrappers and\nleverages Large Language Models (LLMs) to reason about more complex allocation\npatterns with side effects. This targeted enhancement enables precise modeling\nof heap objects at each call site, achieving context-sensitivity-like benefits\nwithout the associated overhead. We evaluate AFD on 15 real-world C projects,\nidentifying over 600 custom AFs. Integrating AFD into a baseline pointer\nanalysis yields a 26x increase in modeled heap objects and a 39% reduction in\nalias set sizes, with only 1.4x runtime overhead. Furthermore, our enhanced\nanalysis improves indirect call resolution and uncovers 17 previously\nundetected memory bugs. These results demonstrate that precise modeling of\ncustom allocation functions offers a scalable and practical path to improving\npointer analysis in large software systems.", "AI": {"tldr": "AFD\u901a\u8fc7\u81ea\u52a8\u8bc6\u522b\u548c\u5efa\u6a21\u81ea\u5b9a\u4e49\u5206\u914d\u51fd\u6570\u6765\u63d0\u5347\u6307\u9488\u5206\u6790\u7cbe\u5ea6\uff0c\u7ed3\u5408\u503c\u6d41\u5206\u6790\u548cLLM\u5904\u7406\u590d\u6742\u5206\u914d\u6a21\u5f0f\uff0c\u572815\u4e2a\u771f\u5b9eC\u9879\u76ee\u4e2d\u8bc6\u522b600+\u81ea\u5b9a\u4e49\u5206\u914d\u51fd\u6570\uff0c\u4f7f\u5806\u5bf9\u8c61\u5efa\u6a21\u589e\u52a026\u500d\uff0c\u522b\u540d\u96c6\u5927\u5c0f\u51cf\u5c1139%\uff0c\u4ec5\u5e26\u67651.4\u500d\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u6307\u9488\u5206\u6790\u65b9\u6cd5\u5927\u591a\u5ffd\u7565C/C++\u7a0b\u5e8f\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u5206\u914d\u51fd\u6570\uff0c\u5bfc\u81f4\u522b\u540d\u5206\u6790\u7c97\u7cd9\u548c\u5206\u6790\u7cbe\u5ea6\u964d\u4f4e\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u4f7f\u7528\u503c\u6d41\u5206\u6790\u68c0\u6d4b\u7b80\u5355\u5305\u88c5\u5668\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5177\u6709\u526f\u4f5c\u7528\u7684\u590d\u6742\u5206\u914d\u6a21\u5f0f\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u5806\u5bf9\u8c61\u5efa\u6a21\u3002", "result": "\u572815\u4e2a\u771f\u5b9eC\u9879\u76ee\u4e2d\u8bc6\u522b600+\u81ea\u5b9a\u4e49\u5206\u914d\u51fd\u6570\uff0c\u5806\u5bf9\u8c61\u5efa\u6a21\u589e\u52a026\u500d\uff0c\u522b\u540d\u96c6\u5927\u5c0f\u51cf\u5c1139%\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u4ec51.4\u500d\uff0c\u5e76\u53d1\u73b017\u4e2a\u5148\u524d\u672a\u68c0\u6d4b\u5230\u7684\u5185\u5b58\u9519\u8bef\u3002", "conclusion": "\u7cbe\u786e\u5efa\u6a21\u81ea\u5b9a\u4e49\u5206\u914d\u51fd\u6570\u4e3a\u6539\u8fdb\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u6307\u9488\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u5b9e\u7528\u7684\u8def\u5f84\u3002"}}
