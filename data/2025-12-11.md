<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 10]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Llama-based source code vulnerability detection: Prompt engineering vs Fine tuning](https://arxiv.org/abs/2512.09006)
*Dyna Soumhane Ouchebara,Stéphane Dupont*

Main category: cs.SE

TL;DR: 研究探索使用Llama-3.1 8B大语言模型进行源代码漏洞检测，测试了多种微调和提示工程技术，发现微调对任务解决至关重要，双微调表现良好，但提示工程效果不佳。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发周期加速，软件漏洞数量持续增加，自动化漏洞检测变得至关重要。研究旨在探索当前性能最强的大语言模型在源代码漏洞检测任务中的表现，并应用最先进技术提升其效果。

Method: 使用Llama-3.1 8B开源模型，从BigVul和PrimeVul数据集中提取源代码样本。探索了多种微调设置（包括提出的双微调方法）和提示工程技术，还测试了较少研究的测试时微调方法，以及检索增强生成作为示例选择技术。

Result: 微调对解决漏洞检测任务至关重要；提出的双微调方法表现良好；Llama模型在漏洞检测方面具有潜力；提示工程效果不佳；检索增强生成作为示例选择技术表现相对较好。

Conclusion: 研究部分回答了研究问题，但仍有许多问题待解决，为未来工作提供了多个方向。强调了微调的重要性，展示了双微调的有效性，以及Llama模型在源代码漏洞检测任务中的潜力。

Abstract: The significant increase in software production, driven by the acceleration of development cycles over the past two decades, has led to a steady rise in software vulnerabilities, as shown by statistics published yearly by the CVE program. The automation of the source code vulnerability detection (CVD) process has thus become essential, and several methods have been proposed ranging from the well established program analysis techniques to the more recent AI-based methods. Our research investigates Large Language Models (LLMs), which are considered among the most performant AI models to date, for the CVD task. The objective is to study their performance and apply different state-of-the-art techniques to enhance their effectiveness for this task. We explore various fine-tuning and prompt engineering settings. We particularly suggest one novel approach for fine-tuning LLMs which we call Double Fine-tuning, and also test the understudied Test-Time fine-tuning approach. We leverage the recent open-source Llama-3.1 8B, with source code samples extracted from BigVul and PrimeVul datasets. Our conclusions highlight the importance of fine-tuning to resolve the task, the performance of Double tuning, as well as the potential of Llama models for CVD. Though prompting proved ineffective, Retrieval augmented generation (RAG) performed relatively well as an example selection technique. Overall, some of our research questions have been answered, and many are still on hold, which leaves us many future work perspectives. Code repository is available here: https://github.com/DynaSoumhaneOuchebara/Llama-based-vulnerability-detection.

</details>


### [2] [Evolving Excellence: Automated Optimization of LLM-based Agents](https://arxiv.org/abs/2512.09108)
*Paul Brookes,Vardan Voskanyan,Rafail Giavrimis,Matthew Truscott,Mina Ilieva,Chrystalla Pavlou,Alexandru Staicu,Manal Adham,Will Evers- Hood,Jingzhi Gong,Kejia Zhang,Matvey Fedoseev,Vishal Sharma,Roman Bauer,Zheng Wang,Hema Nair,Wei Jie,Tianhua Xu,Aurora Constantin,Leslie Kanthan,Michail Basios*

Main category: cs.SE

TL;DR: ARTEMIS是一个无需代码的进化优化平台，通过语义感知的遗传算子联合优化AI代理配置，在多个代理系统上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的AI代理系统在自动化复杂工作流程方面潜力巨大，但通常由于次优配置（如提示词、工具描述、参数等需要数周手动调优）而表现不佳。现有优化方法要么过于复杂，要么孤立处理组件，忽略了关键相互依赖关系。

Method: ARTEMIS是一个无需代码的进化优化平台，通过语义感知的遗传算子联合优化代理配置。给定基准脚本和自然语言目标，它能自动发现可配置组件，从执行日志中提取性能信号，并在无需架构修改的情况下进化配置。

Result: 在四个代表性代理系统上评估：1) ALE Agent在AtCoder Heuristic Contest上接受率提升13.6%；2) Mini-SWE Agent在SWE-Perf上性能显著提升10.1%；3) CrewAI Agent在Math Odyssey上评估所需token数显著减少36.9%；4) 基于较小开源模型(Qwen2.5-7B)的MathTales-Teacher Agent在GSM8K上准确率提升22%，证明ARTEMIS能优化商业和本地模型代理。

Conclusion: ARTEMIS提供了一种无需代码的进化优化方法，能够有效联合优化AI代理配置，显著提升性能，适用于商业和开源模型，解决了现有优化方法的复杂性和孤立性问题。

Abstract: Agentic AI systems built on large language models (LLMs) offer significant potential for automating complex workflows, from software development to customer support. However, LLM agents often underperform due to suboptimal configurations; poorly tuned prompts, tool descriptions, and parameters that typically require weeks of manual refinement. Existing optimization methods either are too complex for general use or treat components in isolation, missing critical interdependencies.
  We present ARTEMIS, a no-code evolutionary optimization platform that jointly optimizes agent configurations through semantically-aware genetic operators. Given only a benchmark script and natural language goals, ARTEMIS automatically discovers configurable components, extracts performance signals from execution logs, and evolves configurations without requiring architectural modifications.
  We evaluate ARTEMIS on four representative agent systems: the \emph{ALE Agent} for competitive programming on AtCoder Heuristic Contest, achieving a \textbf{$13.6\%$ improvement} in acceptance rate; the \emph{Mini-SWE Agent} for code optimization on SWE-Perf, with a statistically significant \textbf{10.1\% performance gain}; and the \emph{CrewAI Agent} for cost and mathematical reasoning on Math Odyssey, achieving a statistically significant \textbf{$36.9\%$ reduction} in the number of tokens required for evaluation. We also evaluate the \emph{MathTales-Teacher Agent} powered by a smaller open-source model (Qwen2.5-7B) on GSM8K primary-level mathematics problems, achieving a \textbf{22\% accuracy improvement} and demonstrating that ARTEMIS can optimize agents based on both commercial and local models.

</details>


### [3] [TritonForge: Profiling-Guided Framework for Automated Triton Kernel Optimization](https://arxiv.org/abs/2512.09196)
*Haonan Li,Keyu Man,Partha Kanuparthy,Hanning Chen,Wei Sun,Sreen Tallam,Chenguang Zhu,Kevin Zhu,Zhiyun Qian*

Main category: cs.SE

TL;DR: TritonForge是一个基于性能剖析的自动化Triton GPU内核优化框架，通过集成内核分析、运行时剖析和迭代代码转换，实现GPU内核的自动化性能优化，最高可获得5倍性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管Triton DSL简化了GPU内核开发，但要达到专家级性能仍需深厚的GPU架构知识和低层性能权衡理解，这一过程仍然劳动密集且困难。

Method: TritonForge采用剖析引导的框架，集成内核分析、运行时剖析和迭代代码转换。系统利用LLM辅助代码推理和转换，但保持模块化和模型无关性。通过数据驱动的剖析反馈识别性能瓶颈，提出针对性代码修改并自动评估其影响。

Result: 在不同类型的内核和GPU架构上，TritonForge相比基线实现最高可获得5倍性能提升，平均成功率为1.76倍（即76%的性能提升）。

Conclusion: TritonForge为自动化GPU性能优化研究提供了基础框架，通过系统化的剖析引导优化流程，显著降低了高性能GPU内核优化的门槛。

Abstract: High-performance GPU kernel optimization remains a critical yet labor-intensive task in modern machine learning workloads. Although Triton, a domain-specific language for GPU programming, enables developers to write efficient kernels with concise code, achieving expert-level performance still requires deep understanding of GPU architectures and low-level performance trade-offs. We present TritonForge, a profiling-guided framework for automated Triton kernel optimization. TritonForge integrates kernel analysis, runtime profiling, and iterative code transformation to streamline the optimization process. By incorporating data-driven feedback from profiling results, the system identifies performance bottlenecks, proposes targeted code modifications, and evaluates their impact automatically. While our prototype leverages large language models (LLMs) to assist in code reasoning and transformation, the framework remains modular and model-agnostic. Across diverse kernel types and GPU architectures, TritonForge achieves up to 5x performance improvement over baseline implementations and on average 1.76x of the cases are successful, providing a foundation for future research in automated GPU performance optimization.

</details>


### [4] [Bug Priority Change Prediction: An Exploratory Study on Apache Software](https://arxiv.org/abs/2512.09216)
*Guangzong Cai,Zengyang Li,Peng Liang,Ran Mo,Hui Liu,Yutao Ma*

Main category: cs.SE

TL;DR: 提出基于缺陷修复演化特征和类别不平衡处理策略的两阶段缺陷优先级变更预测方法，在32个Apache项目中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 缺陷优先级在修复过程中可能发生变化，但手动评估依赖主观判断且繁琐，容易导致错误变更，影响及时修复。目前缺乏缺陷优先级变更预测的研究。

Method: 将缺陷生命周期分为报告阶段和修复阶段，为每个阶段构建优先级变更预测模型。采用缺陷修复演化特征和类别不平衡处理策略来提高预测性能。

Result: 报告阶段模型的F1-score达到0.798，修复阶段模型的F1-weighted和F1-macro分别为0.712和0.613。不同项目间性能差异较大但整体表现良好，各优先级级别的预测性能相对一致且较高。

Conclusion: 提出的缺陷修复演化特征和类别不平衡处理策略能有效提升优先级变更预测模型的性能，方法在不同项目中具有适用性，且能稳定预测各优先级级别的变更。

Abstract: Bug fixing is a critical activity in the software development process. In issue tracking systems such as JIRA, each bug report is assigned a priority level to indicate the urgency and importance level of the bug. The priority may change during the bug fixing process, indicating that the urgency and importance level of the bug will change with the bug fixing. However, manually evaluating priority changes for bugs is a tedious process that heavily relies on the subjective judgment of developers and project managers, leading to incorrect priority changes and thus hindering timely bug fixes. Given the lack of research on bug priority change prediction, we propose a novel two-phase bug report priority change prediction method based on bug fixing evolution features and class imbalance handling strategy. Specifically, we divided the bug lifecycle into two phases: bug reporting and bug fixing, and constructed bug priority change prediction models for each phase. To evaluate the performance of our method, we conducted experiments on a bug dataset constructed from 32 non-trivial Apache projects. The experimental results show that our proposed bug fixing evolution features and the adopted class imbalance handling strategy can effectively improve the performance of prediction models. The F1-score of the prediction model constructed for the bug reporting phase reached 0.798, while the F1-weighted and F1-macro of the prediction model constructed for the bug fixing phase were 0.712 and 0.613, respectively. Furthermore, we explored the cross-project applicability of our prediction models and their performance at different priority levels. The findings indicate large variations in model performance across different projects, although the overall scores remain decent. Meanwhile, the predictive performance across various priority levels remained relatively consistently high.

</details>


### [5] [SWEnergy: An Empirical Study on Energy Efficiency in Agentic Issue Resolution Frameworks with SLMs](https://arxiv.org/abs/2512.09543)
*Arihant Tripathy,Ch Pavan Harshit,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 研究评估了四种基于小语言模型（SLM）的自主软件工程代理框架的性能和能效，发现当前框架架构是能耗的主要驱动因素，但由于SLM推理能力有限，大部分能耗被浪费在无成效的推理循环中。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自主软件工程代理依赖大型专有模型，难以本地部署，这引发了对小语言模型的兴趣。但SLM在复杂代理框架中用于自动化问题解决的实际效果和效率仍不清楚，需要评估在资源受限环境下的可行性。

Method: 在固定硬件上对四种领先的代理框架（SWE-Agent、OpenHands、Mini SWE Agent、AutoCodeRover）使用两种SLM（Gemma-3 4B、Qwen-3 1.7B）进行控制性评估。在SWE-bench Verified Mini基准上测量150次运行的能量消耗、持续时间、令牌使用和内存使用。

Result: 框架架构是能耗的主要驱动因素：能耗最高的AutoCodeRover（Gemma）比最低的OpenHands（Gemma）平均多消耗9.4倍能量。但任务解决率接近零，表明当前框架与SLM配对时，大量能量被浪费在无成效的推理循环中。SLM的有限推理能力是成功的主要瓶颈，而框架设计是效率的主要瓶颈。

Conclusion: 当前为强大LLM设计的代理框架无法与SLM高效协作。框架架构是能耗的主要驱动因素，但由于SLM推理能力有限，这些能量大部分被浪费。可行的低能耗解决方案需要从被动编排转向能够主动管理SLM弱点的架构设计。

Abstract: Context. LLM-based autonomous agents in software engineering rely on large, proprietary models, limiting local deployment. This has spurred interest in Small Language Models (SLMs), but their practical effectiveness and efficiency within complex agentic frameworks for automated issue resolution remain poorly understood.
  Goal. We investigate the performance, energy efficiency, and resource consumption of four leading agentic issue resolution frameworks when deliberately constrained to using SLMs. We aim to assess the viability of these systems for this task in resource-limited settings and characterize the resulting trade-offs.
  Method. We conduct a controlled evaluation of four leading agentic frameworks (SWE-Agent, OpenHands, Mini SWE Agent, AutoCodeRover) using two SLMs (Gemma-3 4B, Qwen-3 1.7B) on the SWE-bench Verified Mini benchmark. On fixed hardware, we measure energy, duration, token usage, and memory over 150 runs per configuration.
  Results. We find that framework architecture is the primary driver of energy consumption. The most energy-intensive framework, AutoCodeRover (Gemma), consumed 9.4x more energy on average than the least energy-intensive, OpenHands (Gemma). However, this energy is largely wasted. Task resolution rates were near-zero, demonstrating that current frameworks, when paired with SLMs, consume significant energy on unproductive reasoning loops. The SLM's limited reasoning was the bottleneck for success, but the framework's design was the bottleneck for efficiency.
  Conclusions. Current agentic frameworks, designed for powerful LLMs, fail to operate efficiently with SLMs. We find that framework architecture is the primary driver of energy consumption, but this energy is largely wasted due to the SLMs' limited reasoning. Viable low-energy solutions require shifting from passive orchestration to architectures that actively manage SLM weaknesses.

</details>


### [6] [Explainable Verification of Hierarchical Workflows Mined from Event Logs with Shapley Values](https://arxiv.org/abs/2512.09562)
*Radoslaw Klimek,Jakub Blazowski*

Main category: cs.SE

TL;DR: 将工作流挖掘转换为逻辑规范，使用定理证明器分析属性，并应用Shapley值量化工作流元素的贡献，实现可解释的工作流分析


<details>
  <summary>Details</summary>
Motivation: 工作流挖掘能从事件日志中发现分层过程树，但现有方法无法解释为什么模型满足或违反逻辑属性，以及各个元素如何影响整体行为

Method: 1) 将挖掘的工作流转换为逻辑规范；2) 使用自动定理证明器分析可满足性、活性和安全性等属性；3) 应用合作博弈论中的Shapley值来归因工作流元素并量化其贡献

Result: 在基准数据集上的实验表明，该方法能识别关键节点、揭示冗余结构、暴露有害模式，为可解释的工作流分析提供了新方向

Conclusion: 该方法为软件工程实践提供了直接支持，可用于合规检查、流程优化、冗余减少，并为下一代过程挖掘工具的设计奠定了基础

Abstract: Workflow mining discovers hierarchical process trees from event logs, but it remains unclear why such models satisfy or violate logical properties, or how individual elements contribute to overall behavior. We propose to translate mined workflows into logical specifications and analyze properties such as satisfiability, liveness, and safety with automated theorem provers. On this basis, we adapt Shapley values from cooperative game theory to attribute outcomes to workflow elements and quantify their contributions. Experiments on benchmark datasets show that this combination identifies critical nodes, reveals redundancies, and exposes harmful structures. This outlines a novel direction for explainable workflow analysis with direct relevance to software engineering practice, supporting compliance checks, process optimization, redundancy reduction, and the design of next-generation process mining tools.

</details>


### [7] [Model management to support systems engineering workflows using ontology-based knowledge graphs](https://arxiv.org/abs/2512.09596)
*Arkadiusz Ryś,Lucas Lima,Joeri Exelmans,Dennis Janssens,Hans Vangheluwe*

Main category: cs.SE

TL;DR: 提出一个基于本体的框架来管理CPS工作流执行产生的建模工件，通过知识图谱支持系统工程的存储、版本控制、查询和推理。


<details>
  <summary>Details</summary>
Motivation: 随着系统工程从文档中心转向基于模型的方法，数字资产增多带来存储和访问等问题。CPS涉及多领域专家使用不同形式化方法执行复杂工作流，存储这些工作流知识可以减少开发工作量，支持可重复性和数据推理。

Method: 使用OML（本体建模语言）形式化定义工作流概念、相关形式化和工件，构建包含系统工程数据的知识图谱。开发工具支持工作流设计、执行、工件存储，包括版本控制、查询和推理功能，隐藏直接操作知识图谱的复杂性。

Result: 在真实世界的传动系统智能传感器系统开发场景中应用该框架。结果显示，该方案不仅帮助系统工程师解决了存储和版本控制等基本困难，还减少了访问相关信息的时间，并能从知识图谱中推理出新知识。

Conclusion: 提出的基于本体的框架有效管理了CPS工作流执行产生的建模工件，通过知识图谱支持系统工程的数据管理、查询和推理，在实际应用中验证了其价值。

Abstract: System engineering has been shifting from document-centric to model-based approaches, where assets are becoming more and more digital. Although digitisation conveys several benefits, it also brings several concerns (e.g., storage and access) and opportunities. In the context of Cyber- Physical Systems (CPS), we have experts from various domains executing complex workflows and manipulating models in a plethora of different formalisms, each with their own methods, techniques and tools. Storing knowledge on these workflows can reduce considerable effort during system development not only to allow their repeatability and replicability but also to access and reason on data generated by their execution. In this work, we propose a framework to manage modelling artefacts generated from workflow executions. The basic workflow concepts, related formalisms and artefacts are formally defined in an ontology specified in OML (Ontology Modelling Language). This ontology enables the construction of a knowledge graph that contains system engineering data to which we can apply reasoning. We also developed several tools to support system engineering during the design of workflows, their enactment, and artefact storage, considering versioning, querying and reasoning on the stored data. These tools also hide the complexity of manipulating the knowledge graph directly. Finally, we have applied our proposed framework in a real-world system development scenario of a drivetrain smart sensor system. Results show that our proposal not only helped the system engineer with fundamental difficulties like storage and versioning but also reduced the time needed to access relevant information and new knowledge that can be inferred from the knowledge graph.

</details>


### [8] [LogICL: Distilling LLM Reasoning to Bridge the Semantic Gap in Cross-Domain Log Anomaly Detection](https://arxiv.org/abs/2512.09627)
*Jingwei Ye,Zhi Wang,Chenbin Su,Jieshuai Yang,Jiayi Ding,Chunbo Liu,Ge Chu*

Main category: cs.SE

TL;DR: LogICL：一个将大语言模型推理能力蒸馏到轻量级编码器的框架，用于跨域日志异常检测，解决冷启动问题并超越表面词汇相似性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型需要大量资源和标注数据，在目标域日志稀缺时存在冷启动问题。现有跨域方法依赖表面词汇相似性，难以捕捉结构差异下的潜在语义等价性。

Method: 提出LogICL框架：1）训练时构建delta矩阵衡量基于最大边际相关性的演示样本相对于零样本推理的效用；2）编码器通过多目标损失优化：ICL引导项、最大均值差异域对齐、监督对比损失；3）推理时编码器基于语义相似性和delta分数检索推理感知演示，使用冻结LLM进行思维链上下文学习。

Result: 在少样本和零样本跨域基准测试中达到最先进性能，通过可视化和案例研究证实能超越表面词汇相似性，有效捕捉潜在语义等价性，实现快速部署。

Conclusion: LogICL通过将LLM推理能力蒸馏到轻量级编码器，解决了跨域日志异常检测中的冷启动问题，能够捕捉潜在语义等价性，在异构系统中实现准确且可解释的检测。

Abstract: Effective log anomaly detection is critical to sustaining reliability in large-scale IT infrastructures. Transformer-based models require substantial resources and labeled data, exacerbating the cold-start problem in target domains where logs are scarce. Existing cross-domain methods leverage source logs but struggle with generalization due to reliance on surface lexical similarity, failing to capture latent semantic equivalence amid structural divergences. To address this, we propose LogICL, a framework distilling Large Language Model (LLM) reasoning into a lightweight encoder for cross-domain anomaly detection. During training, LogICL constructs a delta matrix measuring the utility of demonstrations selected via Maximal Marginal Relevance relative to zero-shot inference. The encoder is optimized via a multi-objective loss comprising an ICL-Guided term that aligns representations based on reasoning assistance utility, maximum mean discrepancy for domain alignment, and supervised contrastive loss. At inference, the optimized encoder retrieves reasoning-aware demonstrations using semantic similarity and delta scores, enabling frozen-LLM in-context learning with Chain-of-Thought for accurate and interpretable detection. Experiments on few-shot and zero-shot cross-domain benchmarks confirm LogICL achieves state-of-the-art performance across heterogeneous systems. Further analysis via visualizations and case studies confirms LogICL bridges the semantic gap beyond surface lexical similarity, effectively capturing latent semantic equivalence for rapid deployment.

</details>


### [9] [Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis](https://arxiv.org/abs/2512.09679)
*Naizhu Jin,Zhong Li,Guang Yang,Tian Zhang,Qingkai Zeng*

Main category: cs.SE

TL;DR: 本文通过信息论视角系统研究CoT提示在代码生成中的有效性，发现结构化CoT方法在减少token使用的同时显著提升性能，且效果受语言类型系统和模型容量影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成上表现优异，但Chain-of-Thought提示机制的有效性仍不明确。本文旨在通过系统实证和信息论研究，揭示CoT在神经代码生成中的作用机制。

Method: 使用条件互信息I(Y;C|X)作为概念框架，评估五种CoT范式（Zero-Shot、Zero-Shot CoT、Self-Planning、Structured CoT、Reasoning-CoT），在六个Python基准、一个包含12种编程语言的多语言基准以及六个7B到480B参数的模型上进行实验。

Result: 外部引导的CoT持续优于直接生成，结构化方法平均提升Pass@1 5-12%，同时比反思推理使用更少token。CoT效果取决于语言类型系统和模型容量，推理质量至关重要：高质量结构化CoT比轻量级替代方案准确率显著更高。

Conclusion: 研究结果为基于模型容量、语言特性和任务复杂度选择CoT策略提供实用指导，强调结构化CoT在代码生成中的优势及其对推理质量的依赖性。

Abstract: Large language models (LLMs) achieve strong performance on code generation, but the mechanisms by which Chain-of-Thought (CoT) prompting helps remain unclear. We present a systematic empirical and information-theoretic study of CoT effectiveness in neural code generation, evaluating five paradigms (Zero-Shot, Zero-Shot CoT, Self-Planning, Structured CoT, Reasoning-CoT) across six Python benchmarks, a multilingual benchmark with 12 programming languages, and six models from 7B to 480B parameters, using conditional mutual information $I(Y;C|X)$ as a conceptual lens. Our results show that externally guided CoT consistently outperforms direct generation, with structured methods improving Pass@1 by 5--12\% on average while using substantially fewer tokens than reflective reasoning, and that CoT benefits depend on language type systems and model capacity. We further find that reasoning \emph{quality} is critical: high-quality structured CoT from strong generators yields significantly higher accuracy than lightweight alternatives with the same template, whereas naive Zero-Shot CoT can even degrade performance. These findings provide practical guidance for choosing CoT strategies based on model capacity, language characteristics, and task complexity.

</details>


### [10] [Quantifying Uncertainty in Machine Learning-Based Pervasive Systems: Application to Human Activity Recognition](https://arxiv.org/abs/2512.09775)
*Vladimir Balditsyn,Philippe Lalanda,German Vega,Stéphanie Chollet*

Main category: cs.SE

TL;DR: 该论文提出了一种量化机器学习系统不确定性的方法，通过整合多种技术来评估模型预测在运行时的相关性，并在人类活动识别领域进行了验证。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统与传统软件不同，它们通过训练数据而非手动编码开发，导致其操作边界不确定且无法保证完全无错误。当前缺乏有效量化ML系统不确定性的方法，这在实际应用中存在风险。

Method: 提出将一组选定的技术进行适配和联合使用，以在运行时评估模型预测的相关性。这些方法应用于高度异构和动态变化的人类活动识别领域。

Result: 研究结果表明该方法具有相关性，能够有效量化不确定性。详细讨论了该方法为领域专家提供的辅助作用。

Conclusion: 量化机器学习系统的不确定性是必要的，提出的方法在人类活动识别领域验证了其有效性，能够为领域专家提供有价值的决策支持。

Abstract: The recent convergence of pervasive computing and machine learning has given rise to numerous services, impacting almost all areas of economic and social activity. However, the use of AI techniques precludes certain standard software development practices, which emphasize rigorous testing to ensure the elimination of all bugs and adherence to well-defined specifications. ML models are trained on numerous high-dimensional examples rather than being manually coded. Consequently, the boundaries of their operating range are uncertain, and they cannot guarantee absolute error-free performance. In this paper, we propose to quantify uncertainty in ML-based systems. To achieve this, we propose to adapt and jointly utilize a set of selected techniques to evaluate the relevance of model predictions at runtime. We apply and evaluate these proposals in the highly heterogeneous and evolving domain of Human Activity Recognition (HAR). The results presented demonstrate the relevance of the approach, and we discuss in detail the assistance provided to domain experts.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [11] [Simple Modal Types for Functional Reactive Programming](https://arxiv.org/abs/2512.09412)
*Patrick Bahr*

Main category: cs.PL

TL;DR: 提出一种新的函数响应式编程语言，采用简化的模态类型系统，在保证因果性、生产性和无空间泄漏的同时，减少对程序的限制，提高表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的FRP语言虽然通过模态类型系统保证了程序的因果性、生产性和无空间泄漏，但往往对程序施加过多限制，降低了语言的表达能力。需要一种既能保证关键操作属性，又能允许更多程序通过类型检查的解决方案。

Method: 通过改变信号的语义，将信号建模为受"later"类型模态严格控制的可变引用。这种受控的可变性使得类型系统能够安全地允许更多程序通过类型检查，同时支持更高效的原位更新。

Result: 开发出新的FRP语言，其模态类型系统比之前的系统更简化，限制更少，但仍能保证因果性、生产性和无空间泄漏。新语义使语言更具表达力，同时支持函数式编程风格下的高效更新。

Conclusion: 通过重新设计信号的语义，实现了简化的模态类型系统，在保持FRP关键操作属性的同时，提高了语言的表达能力和效率，为函数响应式编程提供了更实用的解决方案。

Abstract: Functional reactive programming (FRP) is a declarative programming paradigm for implementing reactive programs at a high level of abstraction. It applies functional programming principles to construct and manipulate time-varying values, also known as signals. However, for this programming paradigm to work in practice, an FRP language must ensure that programs are causal, productive, and free from space leaks. Over the past fifteen years, several modal type systems to enforce these operational properties have been developed.
  We present a new FRP language with a significantly simplified modal type system that imposes fewer restrictions than previous modal FRP languages while still guaranteeing the central operational properties of causality, productivity, and absence of space leaks. The key enabling idea is to alter the semantics of signals so that the type system can safely allow more programs to type-check, which also makes the language more expressive. With this new semantics, signals are modelled as mutable references whose mutability is tightly controlled by the 'later' type modality. This disciplined form of mutability also enables more efficient in-place updates of signals, all while preserving a functional programming style.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [A Modular Lean 4 Framework for Confluence and Strong Normalization of Lambda Calculi with Products and Sums](https://arxiv.org/abs/2512.09280)
*Arthur Ramos,Anjolina Oliveira,Ruy de Queiroz,Tiago de Veras*

Main category: cs.LO

TL;DR: Metatheory 是一个用于 Lean 4 的编程语言基础库，提供了模块化的框架来证明抽象重写系统的合流性，包含三种经典证明技术，并在六个案例研究中实例化。


<details>
  <summary>Details</summary>
Motivation: 为 Lean 4 提供一个全面的合流性和归一化框架，填补当前在形式化编程语言基础方面的空白。

Method: 使用模块化框架，结合三种经典证明技术（菱形性质、Newman 引理、Hindley-Rosen 引理），在六个案例研究中实例化，包括无类型 lambda 演算、组合逻辑、项重写系统等。

Result: 实现了完全机械化的定理证明（零公理或 sorry 语句），提供了完整的 de Bruijn 替换基础设施证明，并通过逻辑关系展示了强归一化。

Conclusion: 这是 Lean 4 中第一个全面的合流性和归一化框架，为编程语言基础的形式化验证提供了重要工具。

Abstract: We present Metatheory, a comprehensive library for programming language foundations in Lean 4. The library features a modular framework for proving confluence of abstract rewriting systems using three classical proof techniques: the diamond property, Newmans lemma, and the Hindley-Rosen lemma. These are instantiated across six case studies including untyped lambda calculus, combinatory logic, term rewriting, simply typed lambda calculus, and STLC with products and sums. All theorems are fully mechanized with zero axioms or sorry statements. We provide complete proofs of de Bruijn substitution infrastructure and demonstrate strong normalization via logical relations. To our knowledge, this is the first comprehensive confluence and normalization framework for Lean 4.

</details>


### [13] [Nominal Type Theory by Nullary Internal Parametricity](https://arxiv.org/abs/2512.09464)
*Antoine Van Muylder,Andreas Nuyts,Dominique Devriese*

Main category: cs.LO

TL;DR: 本文提出了一种基于零元内部参数化类型理论的新型名义框架，通过引入名称类型和名称归纳原理，实现了通用名称抽象、名义模式匹配等功能，解决了现有名义框架中存在的问题。


<details>
  <summary>Details</summary>
Motivation: 现有名义框架中，存在名称抽象类型的两种表示方式：存在量化和全称量化。存在量化表示允许模式匹配但类型规则复杂，全称量化表示类型规则简单但失去模式匹配能力。本文旨在开发一种既能保持全称量化的简洁性，又能恢复模式匹配能力的名义框架。

Method: 扩展零元内部参数化类型理论，添加名称类型和新的名称归纳原理，构建名义数据类型。利用零元参数化特性恢复名义模式匹配能力，并通过合成Kripke参数化作为主要示例。

Result: 成功构建了一个合法的名义框架，包含：通用名称抽象、名义模式匹配、新鲜度类型构造子、名称交换和局部作用域操作，以及（非原始的）存在名称抽象。展示了如何利用零元参数化恢复名义模式匹配。

Conclusion: 通过扩展零元内部参数化类型理论，本文开发了一个功能完整的名义框架，既保持了全称名称抽象的简洁性，又恢复了模式匹配能力，为语言语法表示提供了新的理论基础。

Abstract: There are many ways to represent the syntax of a language with binders. In particular, nominal frameworks are metalanguages that feature (among others) name abstraction types, which can be used to specify the type of binders. The resulting syntax representation (nominal data types) makes alpha-equivalent terms equal, and features a name-invariant induction principle. It is known that name abstraction types can be presented either as existential or universal quantification on names. On the one hand, nominal frameworks use the existential presentation for practical reasoning since the user is allowed to match on a name-term pattern where the name is bound in the term. However inference rules for existential name abstraction are cumbersome to specify/implement because they must keep track of information about free and bound names at the type level. On the other hand, universal name abstractions are easier to specify since they are treated not as pairs, but as functions consuming fresh names. Yet the ability to pattern match on such functions is seemingly lost. In this work we show that this ability and others are recovered in a type theory consisting of (1) nullary ($0$-ary) internally parametric type theory (nullary PTT) (2) a type of names and a novel name induction principle (3) nominal data types. This extension of nullary PTT can act as a legitimate nominal framework. Indeed it has universal name abstractions, nominal pattern matching, a freshness type former, name swapping and local-scope operations and (non primitive) existential name abstractions. We illustrate how term-relevant nullary parametricity is used to recover nominal pattern matching. Our main example involves synthetic Kripke parametricity.

</details>


### [14] [Two-Variable Logic for Hierarchically Partitioned and Ordered Data](https://arxiv.org/abs/2512.09508)
*Oskar Fiuk,Emanuel Kieronski,Vincent Michielini*

Main category: cs.LO

TL;DR: FO2逻辑在不同层次结构约束下的可满足性问题：带线性序和等价关系链的FO2是NExpTime完全的；无线性序版本具有指数模型性质；带嵌套全预序链的FO2也是NExpTime完全的，但加入后继关系后复杂度升至ExpSpace完全；带两个独立嵌套等价关系链的FO2不可判定。


<details>
  <summary>Details</summary>
Motivation: 研究层次化结构化数据建模下的两变量一阶逻辑（FO2），探索在不同语义约束下的计算复杂性，为数据库理论、形式验证等领域提供理论基础。

Method: 1. 扩展FO2为带线性序和等价关系链的逻辑，分析其有限可满足性问题
2. 研究无线性序的弱化版本，证明其指数模型性质
3. 扩展FO2为带嵌套全预序链的逻辑，分析其复杂性
4. 研究加入预序后继关系后的复杂度变化
5. 研究带两个独立嵌套等价关系链的FO2的可判定性

Result: 1. FO2+线性序+等价关系链的有限可满足性是NExpTime完全的
2. 无线性序版本具有指数模型性质
3. FO2+嵌套全预序链的有限可满足性也是NExpTime完全的
4. 加入预序后继关系后复杂度升至ExpSpace完全
5. FO2+两个独立嵌套等价关系链是不可判定的

Conclusion: 层次结构约束对FO2的计算复杂性有显著影响：线性序和等价关系链的加入保持NExpTime完全性，但预序后继关系使复杂度升至ExpSpace完全，而两个独立嵌套等价关系链则导致不可判定性，揭示了层次化数据建模中不同约束的复杂性边界。

Abstract: We study Two-Variable First-Order Logic, FO2, under semantic constraints that model hierarchically structured data. Our first logic extends FO2 with a linear order < and a chain of increasingly coarser equivalence relations E_1, E_2, ... . We show that its finite satisfiability problem is NExpTime-complete. We also demonstrate that a weaker variant of this logic without the linear order enjoys the exponential model property. Our second logic extends FO2 with a chain of nested total preorders. We prove that its finite satisfiability problem is also NExpTime-complete.However, we show that the complexity increases to ExpSpace-complete once access to the successor relations of the preorders is allowed. Our last result is the undecidability of FO2 with two independent chains of nested equivalence relations.

</details>


### [15] [Towards Language Model Guided TLA+ Proof Automation](https://arxiv.org/abs/2512.09758)
*Yuhao Zhou,Stavros Tripakis*

Main category: cs.LO

TL;DR: 提出一种基于提示的LLM方法，用于TLA+定理证明中的层次分解，通过生成规范化声明分解而非完整证明来减少语法错误，并在119个定理基准测试中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: TLA+形式化定理证明虽然能提供严格的系统规范保证，但构建证明需要大量专业知识和努力。尽管大语言模型在自动化基于策略的定理证明器（如Lean）方面显示出潜力，但由于TLA+证明系统独特的层次化证明结构，直接应用这些方法面临重大挑战。

Method: 提出基于提示的方法，利用LLM指导复杂证明义务的层次分解为更简单的子声明，同时依赖符号证明器进行验证。关键见解是约束LLM生成规范化的声明分解而非完整证明，从而显著减少语法错误。

Result: 在包含119个定理的基准测试套件中（改编自（1）已建立的数学集合和（2）分布式协议的归纳证明），该方法始终优于基线方法。

Conclusion: 该方法通过结合LLM的层次分解能力和符号证明器的验证，有效解决了TLA+定理证明自动化的挑战，为形式化验证提供了新的自动化途径。

Abstract: Formal theorem proving with TLA+ provides rigorous guarantees for system specifications, but constructing proofs requires substantial expertise and effort. While large language models have shown promise in automating proofs for tactic-based theorem provers like Lean, applying these approaches directly to TLA+ faces significant challenges due to the unique hierarchical proof structure of the TLA+ proof system. We present a prompt-based approach that leverages LLMs to guide hierarchical decomposition of complex proof obligations into simpler sub-claims, while relying on symbolic provers for verification. Our key insight is to constrain LLMs to generate normalized claim decompositions rather than complete proofs, significantly reducing syntax errors. We also introduce a benchmark suite of 119 theorems adapted from (1) established mathematical collections and (2) inductive proofs of distributed protocols. Our approach consistently outperforms baseline methods across the benchmark suite.

</details>
