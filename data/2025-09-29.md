<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?](https://arxiv.org/abs/2509.21629)
*Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken*

Main category: cs.PL

TL;DR: 提出了一个评估LLMs在循环不变式合成上的框架，使用基于验证器的决策过程，评估正确性和验证速度提升。测试了7个先进LLMs和现有LLM验证器，发现它们尚未显著优于传统求解器UAutomizer。监督微调和最佳N采样可提升性能。


<details>
  <summary>Details</summary>
Motivation: 程序验证依赖循环不变式，但自动发现强不变式仍是长期挑战。需要系统评估LLMs在不变式合成中的能力。

Method: 使用基于验证器的决策过程，具有形式化正确性保证，评估不变式的正确性和验证速度提升。对7个先进LLMs和现有LLM验证器进行测试，并与传统求解器UAutomizer比较。采用监督微调和最佳N采样策略。

Result: LLM验证器是有前景的方向，但尚未显著优于UAutomizer。模型能力至关重要，不同模型的速度提升差异明显。监督微调将Qwen3-Coder-480B的速度提升案例从8%提高到29.2%，最佳N采样(N=16)将Claude-sonnet-4从8.8%提升到22.1%。

Conclusion: 当前LLMs在不变式合成基准上仍面临挑战，但监督微调和采样策略能显著提升性能。LLM验证器是未来有希望的研究方向。

Abstract: Program verification relies on loop invariants, yet automatically discovering
strong invariants remains a long-standing challenge. We introduce a principled
framework for evaluating LLMs on invariant synthesis. Our approach uses a
verifier-based decision procedure with a formal soundness guarantee and
assesses not only correctness but also the speedup that invariants provide in
verification. We evaluate 7 state-of-the-art LLMs, and existing LLM-based
verifiers against the traditional solver UAutomizer. While LLM-based verifiers
represent a promising direction, they do not yet offer a significant advantage
over UAutomizer. Model capability also proves critical, as shown by sharp
differences in speedups across models, and our benchmark remains an open
challenge for current LLMs. Finally, we show that supervised fine-tuning and
Best-of-N sampling can improve performance: fine-tuning on 3589 instances
raises the percentage of speedup cases for Qwen3-Coder-480B from 8% to 29.2%,
and Best-of-N sampling with N=16 improves Claude-sonnet-4 from 8.8% to 22.1%.

</details>


### [2] [Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics](https://arxiv.org/abs/2509.21793)
*Jianhong Zhao,Everett Hildenbrandt,Juan Conejero,Yongwang Zhao*

Main category: cs.PL

TL;DR: 提出'通过证明编译'的新范式，将验证证明转化为优化的执行规则，通过构建全路径可达性证明并编译其图结构，将多个语义重写合并为单一规则，同时保持正确性。


<details>
  <summary>Details</summary>
Motivation: 验证证明编码了完整的程序行为，但在检查正确性后通常被丢弃，这造成了资源浪费。

Method: 通过符号执行构建全路径可达性证明，编译其图结构，将多个语义重写合并为单一规则，在K框架中实现语言无关的扩展。

Result: 评估显示在不同编译范围内都实现了性能提升：操作码级优化显示一致的加速，而全程序编译实现了数量级更大的性能增益。

Conclusion: 通过证明编译是一种有效的优化方法，能够显著提升程序执行性能，同时保持正确性。

Abstract: Verification proofs encode complete program behavior, yet we discard them
after checking correctness. We present compiling by proving, a paradigm that
transforms these proofs into optimized execution rules. By constructing
All-Path Reachability Proofs through symbolic execution and compiling their
graph structure, we consolidate many semantic rewrites into single rules while
preserving correctness by construction. We implement this as a
language-agnostic extension to the K framework. Evaluation demonstrates
performance improvements across different compilation scopes: opcode-level
optimizations show consistent speedups, while whole-program compilation
achieves orders of magnitude greater performance gains.

</details>


### [3] [Committing to the bit: Relational programming with semiring arrays and SAT solving](https://arxiv.org/abs/2509.22614)
*Dmitri Volkov,Yafei Yang,Chung-chieh Shan*

Main category: cs.PL

TL;DR: semiringKanren是一种关系式编程语言，将关系表达式表示为半环数组，通过类型系统限制数组大小为有限，并支持参数化语义。通过将类型编译为位串表示，在布尔半环下可使用SAT求解器高效执行程序。


<details>
  <summary>Details</summary>
Motivation: 开发一种更高效的关系式编程语言变体，通过半环数组表示和SAT求解器集成来提升miniKanren的性能。

Method: 提出semiringKanren语言，定义类型系统限制数组为有限大小，参数化语义支持不同半环，将类型编译为位串表示，在布尔半环下使用SAT求解器执行程序。

Result: 与faster miniKanren在解决数独谜题上的性能比较显示，semiringKanren可以成为更高效的miniKanren变体。

Conclusion: semiringKanren通过半环数组表示和SAT求解器集成，实现了比传统miniKanren更高效的关系式编程。

Abstract: We propose semiringKanren, a relational programming language where each
relation expression denotes a semiring array. We formalize a type system that
restricts the arrays to finite size. We then define a semantics that is
parameterized by the semiring that the arrays draw their elements from. We
compile semiringKanren types to bitstring representations. For the Boolean
semiring, this compilation enables us to use an SAT solver to run
semiringKanren programs efficiently. We compare the performance of
semiringKanren and faster miniKanren for solving Sudoku puzzles. Our experiment
shows that semiringKanren can be a more efficient variant of miniKanren.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [Can Large Language Models Autoformalize Kinematics?](https://arxiv.org/abs/2509.21840)
*Aditi Kabra,Jonathan Laurent,Sagar Bharadwaj,Ruben Martins,Stefan Mitsch,André Platzer*

Main category: cs.LO

TL;DR: 研究大型语言模型能否将自然语言物理问题自动形式化为微分博弈逻辑模型，在20个基准问题中达到70%成功率


<details>
  <summary>Details</summary>
Motivation: 自主网络物理系统需要形式化方法来可靠推理控制决策，但手动构建物理模型复杂且耗时，成为瓶颈

Method: 设计20个本科物理运动学问题基准，让LLM将自然语言描述转换为微分博弈逻辑模型，通过语法检查和符号执行进行迭代精炼和语义评估

Result: 在5次采样中的最佳成功率达到70%，分析了失败案例以指导未来改进

Conclusion: 为从自然语言到具有连续动态的混合博弈逻辑的LLM自动形式化提供了首个定量基准

Abstract: Autonomous cyber-physical systems like robots and self-driving cars could
greatly benefit from using formal methods to reason reliably about their
control decisions. However, before a problem can be solved it needs to be
stated. This requires writing a formal physics model of the cyber-physical
system, which is a complex task that traditionally requires human expertise and
becomes a bottleneck.
  This paper experimentally studies whether Large Language Models (LLMs) can
automate the formalization process. A 20 problem benchmark suite is designed
drawing from undergraduate level physics kinematics problems. In each problem,
the LLM is provided with a natural language description of the objects' motion
and must produce a model in differential game logic (dGL). The model is (1)
syntax checked and iteratively refined based on parser feedback, and (2)
semantically evaluated by checking whether symbolically executing the dGL
formula recovers the solution to the original physics problem. A success rate
of 70% (best over 5 samples) is achieved. We analyze failing cases, identifying
directions for future improvement. This provides a first quantitative baseline
for LLM-based autoformalization from natural language to a hybrid games logic
with continuous dynamics.

</details>


### [5] [A Correct by Construction Fault Tolerant Voter for Input Selection of a Control System](https://arxiv.org/abs/2509.22236)
*Arif Ali AP,Jasine Babu,Deepa Sara John*

Main category: cs.LO

TL;DR: 本文提出了一种用于航空电子系统中N模块冗余测量系统的通用投票单元的形式化需求制定、设计、验证和综合方法。


<details>
  <summary>Details</summary>
Motivation: 安全关键系统使用冗余输入单元来提高可靠性和容错能力，需要投票逻辑从冗余源中选择可靠输入，故障检测和隔离规则帮助选择参与投票的输入单元。

Method: 采用正确构造方法，使用Rocq定理证明器进行形式化需求制定、设计、验证和综合。

Result: 开发了一个通用的投票单元，适用于N模块冗余测量系统。

Conclusion: 通过形式化方法和定理证明器，实现了可靠且经过验证的投票单元设计。

Abstract: Safety-critical systems use redundant input units to improve their
reliability and fault tolerance. A voting logic is then used to select a
reliable input from the redundant sources. A fault detection and isolation
rules help in selecting input units that can participate in voting. This work
deals with the formal requirement formulation, design, verification and
synthesis of a generic voting unit for an $N$-modular redundant measurement
system used for control applications in avionics systems. The work follows a
correct-by-construction approach, using the Rocq theorem prover.

</details>


### [6] [Specifying an Obligation Taxonomy in the Non-Markovian Situation Calculus](https://arxiv.org/abs/2509.22533)
*Kalonji Kalala,Iluju Kiringa,Tet Yeap*

Main category: cs.LO

TL;DR: 本文使用情境演算中的非马尔可夫控制来规范文献中的不同义务概念，这些概念之前仅用事件演算描述过。


<details>
  <summary>Details</summary>
Motivation: 情境演算作为描述动态领域和推理行动效果的形式化方法已建立三十多年，但文献中的不同义务概念从未用情境演算规范过，本文旨在填补这一空白。

Method: 采用情境演算中的非马尔可夫控制方法，考虑产生义务的行动规范，来定义不同的义务概念。

Result: 提出的规范产生了直观的属性，确保了整个工作的正确性。

Conclusion: 成功使用情境演算中的非马尔可夫控制规范了文献中的不同义务概念，验证了该方法的有效性。

Abstract: Over more than three decades, the Situation Calculus has established itself
as an elegant, powerful, and concise formalism for specifying dynamical domains
as well as for reasoning about the effects of actions of those domains both in
the world and in the mental state of the modelled agents. Moreover, it has also
been established that the preconditions of a given action and its effects may
be determined entirely by the current situation alone, or they may be
determined by past situations as well. When past situations are involved in
determining action preconditions and effects, resulting theories are
non-Markovian. Assuming a specification of actions that produce obligations, we
consider using non-Markovian control in the Situation Calculus to specify
different notions of obligations found in the literature. These notions have
been specified using Event Calculus; but, as far as we know, they have never
been specified using the Situation Calculus. The specifications in this paper
yield intuitive properties that ensure the correctness of the whole endeavour.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Extracting Conceptual Knowledge to Locate Software Issues](https://arxiv.org/abs/2509.21427)
*Ying Wang,Wenjun Mao,Chong Wang,Zhenhao Zhou,Yicheng Zhou,Wenyun Zhao,Yiling Lou,Xin Peng*

Main category: cs.SE

TL;DR: RepoLens通过提取和利用代码仓库的概念知识来解决问题定位中的关注点混合和关注点分散问题，显著提升了现有LLM工具在文件级和函数级定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的问题定位方法在大型代码仓库中面临关注点混合（相关逻辑被埋没在大函数中）和关注点分散（相关逻辑分散在不同文件中）的挑战，导致定位准确性下降。

Method: RepoLens采用两阶段方法：离线阶段提取和丰富概念知识构建仓库范围的知识库；在线阶段检索问题相关术语，对关注点进行聚类和排序，并通过最小侵入式的提示增强集成到定位工作流中。

Result: 在SWE-Lancer-Loc基准测试的216个任务上，RepoLens显著提升了AgentLess、OpenHands和mini-SWE-agent三个先进工具的性能，文件级和函数级定位的Hit@k和Recall@k平均提升分别超过22%和46%。在不同模型（GPT-4o、GPT-4o-mini、GPT-4.1）上均表现出良好泛化能力。

Conclusion: RepoLens通过概念知识抽象和关注点重构有效解决了代码仓库中的问题定位挑战，构建的关注点被证明是有效和可靠的。

Abstract: Issue localization, which identifies faulty code elements such as files or
functions, is critical for effective bug fixing. While recent LLM-based and
LLM-agent-based approaches improve accuracy, they struggle in large-scale
repositories due to concern mixing, where relevant logic is buried in large
functions, and concern scattering, where related logic is dispersed across
files.
  To address these challenges, we propose RepoLens, a novel approach that
abstracts and leverages conceptual knowledge from code repositories. RepoLens
decomposes fine-grained functionalities and recomposes them into high-level
concerns, semantically coherent clusters of functionalities that guide LLMs. It
operates in two stages: an offline stage that extracts and enriches conceptual
knowledge into a repository-wide knowledge base, and an online stage that
retrieves issue-specific terms, clusters and ranks concerns by relevance, and
integrates them into localization workflows via minimally intrusive prompt
enhancements. We evaluate RepoLens on SWE-Lancer-Loc, a benchmark of 216 tasks
derived from SWE-Lancer. RepoLens consistently improves three state-of-the-art
tools, namely AgentLess, OpenHands, and mini-SWE-agent, achieving average gains
of over 22% in Hit@k and 46% in Recall@k for file- and function-level
localization. It generalizes across models (GPT-4o, GPT-4o-mini, GPT-4.1) with
Hit@1 and Recall@10 gains up to 504% and 376%, respectively. Ablation studies
and manual evaluation confirm the effectiveness and reliability of the
constructed concerns.

</details>


### [8] [Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks](https://arxiv.org/abs/2509.21533)
*Shalini Chakraborty,Sebastian Baltes*

Main category: cs.SE

TL;DR: 研究女性软件工程师在职业中断后重返学术界面临的挑战，比较不同国家的政策差异，并提出支持透明招聘实践的建议。


<details>
  <summary>Details</summary>
Motivation: IT行业为女性重返职场提供了多种支持途径，但学术界在这方面机会有限。职业中断（如怀孕、移民身份、缺乏灵活工作选择）严重影响女性职业发展，而学术机构的性别多样性政策不够突出。

Method: 在多个国家和大学开展多元文化研究项目，通过比较分析现有政策和机会，探索女性重返学术界的特定挑战。

Result: 研究发现女性重返学术界比重返行业面临更多障碍，不同国家的支持政策存在显著差异。

Conclusion: 需要为女性重返学术界提供更好的支持机制，包括透明招聘实践和更完善的制度政策。

Abstract: The IT industry provides supportive pathways such as returnship programs,
coding boot camps, and buddy systems for women re-entering their job after a
career break. Academia, however, offers limited opportunities to motivate women
to return. We propose a diverse multicultural research project investigating
the challenges faced by women with software engineering (SE) backgrounds
re-entering academia or related research roles after a career break. Career
disruptions due to pregnancy, immigration status, or lack of flexible work
options can significantly impact women's career progress, creating barriers for
returning as lecturers, professors, or senior researchers. Although many
companies promote gender diversity policies, such measures are less prominent
and often under-recognized within academic institutions. Our goal is to explore
the specific challenges women encounter when re-entering academic roles
compared to industry roles; to understand the institutional perspective,
including a comparative analysis of existing policies and opportunities in
different countries for women to return to the field; and finally, to provide
recommendations that support transparent hiring practices. The research project
will be carried out in multiple universities and in multiple countries to
capture the diverse challenges and policies that vary by location.

</details>


### [9] [No More Manual Guides: Automatic and Scalable Generation of High-Quality Excel Tutorials](https://arxiv.org/abs/2509.21816)
*Yuhang Xie,Jian Mu,Xiaojun Ma,Chaoyun Zhang,Lu Wang,Mengyu Zhou,Mugeng Liu,Si Qin,Qingwei Lin,Saravan Rajmohan,Shi Han,Dongmei Zhang*

Main category: cs.SE

TL;DR: 提出了首个从自然语言任务描述自动生成Excel教程的框架，通过执行代理在Excel中规划执行解决方案并收集中间产物，自动生成结构化文档和视频演示，显著降低了人工成本。


<details>
  <summary>Details</summary>
Motivation: Excel功能复杂但广泛使用，现有教程依赖专家手动编写，更新成本高且无法满足持续需求，需要实现完全自动化的教程生成。

Method: 框架首先实例化任务，然后通过执行代理在Excel中规划执行解决方案，收集中间产物，最后转化为结构化文档和视频演示。

Result: 在1559个真实场景任务上测试，任务执行成功率比现有最优方法提高8.5%，生成教程的可读性和教学效果接近或超过专家编写材料，时间成本降至专家编写的1/20。

Conclusion: 该自动化框架首次实现了可扩展的高质量Excel教程生成，消除了人工劳动，使大规模教程生成变得实用可行。

Abstract: Excel is one of the most widely used productivity tools across domains,
offering rich functionality but also overwhelming users with its complexity.
This creates a persistent demand for tutorials to support effective usage.
However, existing tutorials are manually authored by experts, require frequent
updates after each software release, and incur substantial labor costs. Prior
work has not achieved fully automated tutorial generation, since existing
methods still depend on handcrafted operation sequences or example materials.
In this paper, we present the first framework for automatically generating
Excel tutorials directly from natural language task descriptions. Our framework
first instantiates the task. Then a central component of this framework,
Execution Agent, plans and executes the solution in Excel, and collects the
intermediate artifacts required for tutorial construction. These artifacts are
then transformed into both structured Excel documents and video demonstrations.
To build a comprehensive tutorial corpus, we collected 1,559 task descriptions
from real-world scenarios. In addition, we designed a systematic evaluation
framework that integrates assessments from both large language models (LLMs)
and human reviewers. Experimental results show that our framework improves task
execution success rates by 8.5% over state-of-the-art baselines. Moreover, the
generated tutorials demonstrate superior readability and instructional
effectiveness, often approaching or surpassing expert-authored materials.
Importantly, the automated pipeline eliminates manual labor and reduces time
costs to 1/20 of expert authoring, making scalable and high-quality tutorial
generation practical for the first time.

</details>


### [10] [Software Engineering Data Analytics: A Framework Based on a Multi-Layered Abstraction Mechanism](https://arxiv.org/abs/2509.21881)
*Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 提出了一种用于软件分析的领域特定框架，支持异构软件仓库的查询、建模和集成


<details>
  <summary>Details</summary>
Motivation: 为了解决异构软件仓库数据难以统一分析和集成的问题

Method: 采用多层抽象机制，包含领域特定操作符，并通过案例研究验证

Result: 展示了该方法的潜力

Conclusion: 该框架为软件分析提供了有效的领域特定解决方案

Abstract: This paper presents a concept of a domain-specific framework for software
analytics by enabling querying, modeling, and integration of heterogeneous
software repositories. The framework adheres to a multi-layered abstraction
mechanism that consists of domain-specific operators. We showcased the
potential of this approach by employing a case study.

</details>


### [11] [AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans](https://arxiv.org/abs/2509.21891)
*Yangtian Zi,Zixuan Wu,Aleksander Boruch-Gruszecki,Jonathan Bell,Arjun Guha*

Main category: cs.SE

TL;DR: AgentPack是一个包含130万代码编辑的数据集，由Claude Code、OpenAI Codex和Cursor Agent在GitHub项目中共同创作，用于训练代码编辑模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于提交记录的训练数据存在噪音问题：提交信息简略、人类提交包含多个无关编辑、许多提交来自简单的基于规则的机器人。而软件工程代理生成的代码变更更加专注，提交信息更详细，且经过人类维护者的质量过滤。

Method: 收集截至2025年8月中旬的公共GitHub项目中由Claude Code、OpenAI Codex和Cursor Agent共同创作的代码编辑，建立识别和筛选流程，分析这些编辑的结构特性。

Result: 构建了包含130万代码编辑的AgentPack语料库，量化了这些代理的采用趋势，并分析了编辑的结构特性。

Conclusion: 在AgentPack上微调的模型能够优于在传统仅有人类提交语料上训练的模型，表明利用软件工程代理的公共数据训练未来代码编辑模型具有巨大潜力。

Abstract: Fine-tuning large language models for code editing has typically relied on
mining commits and pull requests. The working hypothesis has been that commit
messages describe human intent in natural language, and patches to code
describe the changes that implement that intent. However, much of the
previously collected data is noisy: commit messages are terse, human-written
commits commingle several unrelated edits, and many commits come from simple,
rule-based bots.
  The recent adoption of software engineering agents changes this landscape.
Code changes co-authored by humans and agents tend to be more narrowly scoped
and focused on clearer goals. Their commit messages, generated by LLMs,
articulate intent and rationale in much greater detail. Moreover, when these
changes land in public repositories, they are implicitly filtered by humans:
maintainers discard low-quality commits to their projects.
  We present AgentPack, a corpus of 1.3M code edits co-authored by Claude Code,
OpenAI Codex, and Cursor Agent across public GitHub projects up to mid-August
2025. We describe the identification and curation pipeline, quantify adoption
trends of these agents, and analyze the structural properties of the edits.
Finally, we show that models fine-tuned on AgentPack can outperform models
trained on prior human-only commit corpora, highlighting the potential of using
public data from software engineering agents to train future code-editing
models.

</details>


### [12] [Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective](https://arxiv.org/abs/2509.21945)
*Pengzhou Chen,Hongyuan Liang,Tao Chen*

Main category: cs.SE

TL;DR: 本文通过适应度景观分析的新视角，首次系统性地探讨了配置调优中代理模型的作用，提出了评估模型有用性的替代理论，并开发了Model4Tune工具来预测最佳模型-调优器组合。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为配置调优需要更准确的代理模型，但先前研究发现准确性可能具有欺骗性，这引发了对代理模型在配置调优中真正作用的疑问。

Method: 采用适应度景观分析的新视角，提出了评估模型有用性的替代理论，并进行了涉及27,000个案例的广泛实证研究，开发了自动预测工具Model4Tune。

Result: Model4Tune在79%-82%的情况下显著优于随机猜测，能够为未见系统预测最佳模型-调优器组合，而无需昂贵的调优器分析。

Conclusion: 研究不仅揭示了未来可能的研究方向，还提供了实用的解决方案，帮助从业者评估配置调优中最有用的模型。

Abstract: To efficiently tune configuration for better system performance (e.g.,
latency), many tuners have leveraged a surrogate model to expedite the process
instead of solely relying on the profoundly expensive system measurement. As
such, it is naturally believed that we need more accurate models. However, the
fact of accuracy can lie-a somewhat surprising finding from prior work-has left
us many unanswered questions regarding what role the surrogate model plays in
configuration tuning. This paper provides the very first systematic exploration
and discussion, together with a resolution proposal, to disclose the many faces
of surrogate models for configuration tuning, through the novel perspective of
fitness landscape analysis. We present a theory as an alternative to accuracy
for assessing the model usefulness in tuning, based on which we conduct an
extensive empirical study involving up to 27,000 cases. Drawing on the above,
we propose Model4Tune, an automated predictive tool that estimates which
model-tuner pairs are the best for an unforeseen system without expensive tuner
profiling. Our results suggest that Moldel4Tune, as one of the first of its
kind, performs significantly better than random guessing in 79%-82% of the
cases. Our results not only shed light on the possible future research
directions but also offer a practical resolution that can assist practitioners
in evaluating the most useful model for configuration tuning.

</details>


### [13] [SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios](https://arxiv.org/abs/2509.22097)
*Junkai Chen,Huihui Huang,Yunbo Lyu,Junwen An,Jieke Shi,Chengran Yang,Ting Zhang,Haoye Tian,Yikun Li,Zhenhao Li,Xin Zhou,Xing Hu,David Lo*

Main category: cs.SE

TL;DR: SecureAgentBench是一个包含105个编码任务的基准测试，用于严格评估代码代理在安全代码生成方面的能力。评估结果显示当前代理在生成安全代码方面表现不佳，即使最佳代理也只能达到15.2%的正确且安全解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估代码代理生成代码的安全性方面存在不足，往往忽略了漏洞引入的真实上下文，或采用狭窄的评估协议，无法同时捕捉功能正确性和新引入的漏洞。

Method: 设计了包含105个编码任务的SecureAgentBench基准测试，每个任务包含：(i)需要在大仓库中进行多文件编辑的现实任务设置；(ii)基于真实世界开源漏洞的上下文；(iii)结合功能测试、漏洞检查和静态分析的综合评估。

Result: 评估了三个代表性代理（SWE-agent、OpenHands、Aider）和三个最先进LLM（Claude 3.7 Sonnet、GPT-4.1、DeepSeek-V3.1）。结果显示：(i)当前代理难以生成安全代码；(ii)某些代理生成功能正确但引入漏洞的代码；(iii)添加明确安全指令对改善安全编码效果不显著。

Conclusion: SecureAgentBench为安全代码生成建立了一个严格的基准测试，是迈向更可靠LLM软件开发的一步，突显了进一步研究的必要性。

Abstract: Large language model (LLM) powered code agents are rapidly transforming
software engineering by automating tasks such as testing, debugging, and
repairing, yet the security risks of their generated code have become a
critical concern. Existing benchmarks have offered valuable insights but remain
insufficient: they often overlook the genuine context in which vulnerabilities
were introduced or adopt narrow evaluation protocols that fail to capture
either functional correctness or newly introduced vulnerabilities. We therefore
introduce SecureAgentBench, a benchmark of 105 coding tasks designed to
rigorously evaluate code agents' capabilities in secure code generation. Each
task includes (i) realistic task settings that require multi-file edits in
large repositories, (ii) aligned contexts based on real-world open-source
vulnerabilities with precisely identified introduction points, and (iii)
comprehensive evaluation that combines functionality testing, vulnerability
checking through proof-of-concept exploits, and detection of newly introduced
vulnerabilities using static analysis. We evaluate three representative agents
(SWE-agent, OpenHands, and Aider) with three state-of-the-art LLMs (Claude 3.7
Sonnet, GPT-4.1, and DeepSeek-V3.1). Results show that (i) current agents
struggle to produce secure code, as even the best-performing one, SWE-agent
supported by DeepSeek-V3.1, achieves merely 15.2% correct-and-secure solutions,
(ii) some agents produce functionally correct code but still introduce
vulnerabilities, including new ones not previously recorded, and (iii) adding
explicit security instructions for agents does not significantly improve secure
coding, underscoring the need for further research. These findings establish
SecureAgentBench as a rigorous benchmark for secure code generation and a step
toward more reliable software development with LLMs.

</details>


### [14] [SK2Decompile: LLM-based Two-Phase Binary Decompilation from Skeleton to Skin](https://arxiv.org/abs/2509.22114)
*Hanzhuo Tan,Weihao Li,Xiaolong Tian,Siyi Wang,Jiaming Liu,Jing Li,Yuqun Zhang*

Main category: cs.SE

TL;DR: SK2Decompile是一个两阶段反编译方法，先恢复程序结构（骨架），再生成标识符（皮肤），显著提升了反编译的正确性和可读性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的反编译器在有效呈现程序源代码结构和原始标识符方面存在限制，需要改进程序结构恢复和标识符命名的准确性。

Method: 采用两阶段方法：1) 结构恢复模型将二进制代码转换为中间表示，保留控制流和数据结构，使用强化学习确保符合编译器规则；2) 标识符命名模型生成有意义的标识符，使用强化学习奖励语义相似性。

Result: 在HumanEval数据集上比GPT-5-mini平均重执行率提高21.6%，在GitHub2025基准上比Idioms平均R2I改进29.4%。

Conclusion: SK2Decompile通过分离结构恢复和标识符命名两个阶段，独立推进反编译的正确性和可读性，显著优于现有最先进方法。

Abstract: Large Language Models (LLMs) have emerged as a promising approach for binary
decompilation. However, the existing LLM-based decompilers still are somewhat
limited in effectively presenting a program's source-level structure with its
original identifiers. To mitigate this, we introduce SK2Decompile, a novel
two-phase approach to decompile from the skeleton (semantic structure) to the
skin (identifier) of programs. Specifically, we first apply a Structure
Recovery model to translate a program's binary code to an Intermediate
Representation (IR) as deriving the program's "skeleton", i.e., preserving
control flow and data structures while obfuscating all identifiers with generic
placeholders. We also apply reinforcement learning to reward the model for
producing program structures that adhere to the syntactic and semantic rules
expected by compilers. Second, we apply an Identifier Naming model to produce
meaningful identifiers which reflect actual program semantics as deriving the
program's "skin". We train the Identifier Naming model with a separate
reinforcement learning objective that rewards the semantic similarity between
its predictions and the reference code. Such a two-phase decompilation process
facilitates advancing the correctness and readability of decompilation
independently. Our evaluations indicate that SK2Decompile, significantly
outperforms the SOTA baselines, achieving 21.6% average re-executability rate
gain over GPT-5-mini on the HumanEval dataset and 29.4% average R2I improvement
over Idioms on the GitHub2025 benchmark.

</details>


### [15] [Leveraging LLM Agents for Automated Video Game Testing](https://arxiv.org/abs/2509.22170)
*Chengjia Wang,Lanling Tang,Ming Yuan,Jiongchi Yu,Xiaofei Xie,Jiajun Bu*

Main category: cs.SE

TL;DR: TITAN是一个基于LLM的智能MMORPG测试框架，通过状态感知、动作优化、长时程推理和LLM预言机等组件，显著提升了任务完成率和bug检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动化游戏测试方法在MMORPG这类复杂开放环境中难以实现高状态覆盖率和效率，现有LLM方法对复杂游戏状态-动作空间和长复杂任务的理解能力有限。

Method: TITAN包含四个核心组件：高维游戏状态感知与抽象、主动优化和优先处理可用动作、具有动作轨迹记忆和反思自校正的长时程推理、基于LLM的预言机检测功能性和逻辑bug。

Result: 在两个大型商业MMORPG上测试，TITAN达到95%的任务完成率，bug检测性能优于现有方法，发现了四个先前未知的bug，已在八个真实游戏QA流水线中部署。

Conclusion: TITAN证明了LLM驱动智能测试系统的有效性，为推进通用测试系统提供了新方向，具有实际应用价值。

Abstract: Testing MMORPGs (Massively Multiplayer Online Role-Playing Games) is a
critical yet labor-intensive task in game development due to their complexity
and frequent updating nature. Traditional automated game testing approaches
struggle to achieve high state coverage and efficiency in these rich,
open-ended environments, while existing LLM-based game-playing approaches are
limited to shallow reasoning ability in understanding complex game state-action
spaces and long-complex tasks. To address these challenges, we propose TITAN,
an effective LLM-driven agent framework for intelligent MMORPG testing. TITAN
incorporates four key components to: (1) perceive and abstract high-dimensional
game states, (2) proactively optimize and prioritize available actions, (3)
enable long-horizon reasoning with action trace memory and reflective
self-correction, and (4) employ LLM-based oracles to detect potential
functional and logic bugs with diagnostic reports.
  We implement the prototype of TITAN and evaluate it on two large-scale
commercial MMORPGs spanning both PC and mobile platforms. In our experiments,
TITAN achieves significantly higher task completion rates (95%) and bug
detection performance compared to existing automated game testing approaches.
An ablation study further demonstrates that each core component of TITAN
contributes substantially to its overall performance. Notably, TITAN detects
four previously unknown bugs that prior testing approaches fail to identify. We
provide an in-depth discussion of these results, which offer guidance for new
avenues of advancing intelligent, general-purpose testing systems. Moreover,
TITAN has been deployed in eight real-world game QA pipelines, underscoring its
practical impact as an LLM-driven game testing framework.

</details>


### [16] [Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries](https://arxiv.org/abs/2509.22202)
*Lukas Twist,Jie M. Zhang,Mark Harman,Helen Yannakoudakis*

Main category: cs.SE

TL;DR: 系统研究用户提示变化对LLM生成代码中库幻觉的影响，发现轻微拼写错误和虚假库名会显著增加幻觉率，提示工程有缓解作用但不稳定。


<details>
  <summary>Details</summary>
Motivation: LLM在生成代码时经常产生库幻觉（发明不存在的库），这些幻觉可能误导开发者、破坏构建过程并带来供应链安全风险，但缺乏对真实世界提示变化如何影响幻觉率的系统性了解。

Method: 评估6个不同LLM在两种幻觉类型上的表现：库名幻觉（无效导入）和库成员幻觉（有效库中的无效调用），研究从开发者论坛提取的真实用户语言以及不同程度用户错误（单字符/多字符拼写错误和完全虚假名称/成员）对幻觉率的影响。

Result: 发现系统性漏洞：库名中单字符拼写错误在高达26%的任务中触发幻觉，虚假库名在高达99%的任务中被接受，时间相关提示在高达84%的任务中导致幻觉。提示工程有缓解作用但不一致且依赖具体LLM。

Conclusion: LLM对自然提示变化的脆弱性突出，迫切需要针对库相关幻觉及其潜在利用的安全保障措施。

Abstract: Large language models (LLMs) are increasingly used to generate code, yet they
continue to hallucinate, often inventing non-existent libraries. Such library
hallucinations are not just benign errors: they can mislead developers, break
builds, and expose systems to supply chain threats such as slopsquatting.
Despite increasing awareness of these risks, little is known about how
real-world prompt variations affect hallucination rates. Therefore, we present
the first systematic study of how user-level prompt variations impact library
hallucinations in LLM-generated code. We evaluate six diverse LLMs across two
hallucination types: library name hallucinations (invalid imports) and library
member hallucinations (invalid calls from valid libraries). We investigate how
realistic user language extracted from developer forums and how user errors of
varying degrees (one- or multi-character misspellings and completely fake
names/members) affect LLM hallucination rates. Our findings reveal systemic
vulnerabilities: one-character misspellings in library names trigger
hallucinations in up to 26% of tasks, fake library names are accepted in up to
99% of tasks, and time-related prompts lead to hallucinations in up to 84% of
tasks. Prompt engineering shows promise for mitigating hallucinations, but
remains inconsistent and LLM-dependent. Our results underscore the fragility of
LLMs to natural prompt variation and highlight the urgent need for safeguards
against library-related hallucinations and their potential exploitation.

</details>


### [17] [Green Prompt Engineering: Investigating the Energy Impact of Prompt Design in Software Engineering](https://arxiv.org/abs/2509.22320)
*Vincenzo De Martino,Mohammad Amin Zadenoori,Xavier Franch,Alessio Ferrari*

Main category: cs.SE

TL;DR: 本文提出了绿色提示工程的概念，将语言复杂度作为影响能耗和性能的设计维度，通过实证研究发现提示的可读性会影响环境可持续性和性能表现。


<details>
  <summary>Details</summary>
Motivation: 语言模型在软件工程中的应用日益增多，但其推理过程引发了环境担忧。现有研究关注硬件选择和提示长度，但很少关注语言复杂度作为可持续性因素。

Method: 使用开源小型语言模型进行需求分类的实证研究，通过改变提示的可读性来评估其对能耗和性能的影响。

Result: 研究发现可读性影响环境可持续性和性能，揭示了二者之间的权衡关系。对于实践者，更简单的提示可以在不明显损失F1分数的情况下降低能耗成本。

Conclusion: 绿色提示工程为研究人员在绿色AI议程下制定可持续提示设计指南和研究开辟了新路径。

Abstract: Language Models are increasingly applied in software engineering, yet their
inference raises growing environmental concerns. Prior work has examined
hardware choices and prompt length, but little attention has been paid to
linguistic complexity as a sustainability factor. This paper introduces Green
Prompt Engineering, framing linguistic complexity as a design dimension that
can influence energy consumption and performance. We conduct an empirical study
on requirement classification using open-source Small Language Models, varying
the readability of prompts. Our results reveal that readability affects
environmental sustainability and performance, exposing trade-offs between them.
For practitioners, simpler prompts can reduce energy costs without a
significant F1-score loss; for researchers, it opens a path toward guidelines
and studies on sustainable prompt design within the Green AI agenda.

</details>


### [18] [GPU-Accelerated Loopy Belief Propagation for Program Analysis](https://arxiv.org/abs/2509.22337)
*Haoyu Feng,Xin Zhang*

Main category: cs.SE

TL;DR: 本文提出了一种用于程序分析的GPU加速LBP算法，通过统一表示支持灵活更新策略，并利用消息分组优化GPU资源利用，在数据竞争分析中实现了显著加速。


<details>
  <summary>Details</summary>
Motivation: LBP在程序分析中面临大规模计算挑战，现有GPU方法缺乏灵活更新策略支持且未集成逻辑约束，导致性能不佳。

Method: 提出统一表示支持任意用户定义更新策略，进行依赖分析，并基于Horn子句局部结构分组消息以减少warp分歧，优化GPU资源利用。

Result: 在8个真实Java程序的数据竞争分析实验中，相比最优顺序方法平均加速2.14倍，相比最优GPU方法平均加速5.56倍，同时保持高精度。

Conclusion: GPU加速LBP算法能有效提升程序分析性能，支持灵活更新策略并优化GPU资源利用，为大规模程序分析提供高效解决方案。

Abstract: Loopy Belief Propagation (LBP) is a widely used approximate inference
algorithm in probabilistic graphical models, with applications in computer
vision, error correction codes, protein folding, program analysis, etc.
However, LBP faces significant computational challenges when applied to
large-scale program analysis. While GPU (Graphics Processing Unit) parallel
computing provides a promising solution, existing approaches lack support for
flexible update strategies and have yet to integrate logical constraints with
GPU acceleration, leading to suboptimal practical performance.
  This paper presents a GPU-accelerated LBP algorithm for program analysis. To
support the diverse update strategies required by users, we propose a unified
representation for specifying arbitrary user-defined update strategies, along
with a dependency analysis algorithm. Furthermore, building on previous work
that leverages the local structure of Horn clauses to simplify message passing,
we group messages to minimize warp divergence and better utilize GPU resources.
Experimental results on datarace analysis over eight real-world Java programs
show that our approach achieves an average speedup of $2.14\times$ over the
state-of-the-art sequential approach and $5.56\times$ over the state-of-the-art
GPU-based approach, while maintaining high accuracy.

</details>


### [19] [A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems](https://arxiv.org/abs/2509.22379)
*Stefano Carlo Lambertenghi,Mirena Flores Valdez,Andrea Stocco*

Main category: cs.SE

TL;DR: 本文通过实证研究比较了四种自动驾驶系统测试模式（SiL、ViL、MR和真实世界测试），评估了它们在执行、感知和行为保真度三个维度上的现实差距，发现MR测试在提升感知真实性的同时保持了安全和控制能力。


<details>
  <summary>Details</summary>
Motivation: 模拟测试与真实世界行为之间存在现实差距，这挑战了测试结果向实际部署系统的可转移性。需要系统评估不同测试模式在现实差距各维度上的表现。

Method: 使用配备真实传感器的小型物理车辆及其数字孪生，实现四种测试设置（SiL、ViL、MR和真实测试），在涉及真实障碍物、道路拓扑和室内环境的多样化驾驶场景中评估两种ADS架构。

Result: SiL和ViL设置简化了真实世界动态和感知的关键方面，而MR测试在不影响安全或控制的情况下提高了感知真实性。研究识别了故障在不同测试模式间不转移的条件，并分离了导致这些差异的现实差距维度。

Conclusion: 研究结果为每种测试模式的优缺点提供了可行见解，并为实现更稳健和可转移的自动驾驶系统验证指明了路径。

Abstract: Simulation-based testing is a cornerstone of Autonomous Driving System (ADS)
development, offering safe and scalable evaluation across diverse driving
scenarios. However, discrepancies between simulated and real-world behavior,
known as the reality gap, challenge the transferability of test results to
deployed systems. In this paper, we present a comprehensive empirical study
comparing four representative testing modalities: Software-in-the-Loop (SiL),
Vehicle-in-the-Loop (ViL), Mixed-Reality (MR), and full real-world testing.
Using a small-scale physical vehicle equipped with real sensors (camera and
LiDAR) and its digital twin, we implement each setup and evaluate two ADS
architectures (modular and end-to-end) across diverse indoor driving scenarios
involving real obstacles, road topologies, and indoor environments. We
systematically assess the impact of each testing modality along three
dimensions of the reality gap: actuation, perception, and behavioral fidelity.
Our results show that while SiL and ViL setups simplify critical aspects of
real-world dynamics and sensing, MR testing improves perceptual realism without
compromising safety or control. Importantly, we identify the conditions under
which failures do not transfer across testing modalities and isolate the
underlying dimensions of the gap responsible for these discrepancies. Our
findings offer actionable insights into the respective strengths and
limitations of each modality and outline a path toward more robust and
transferable validation of autonomous driving systems.

</details>


### [20] [Context-Specific Instruction: A Longitudinal Study on Debugging Skill Acquisition and Retention for Novice Programmers](https://arxiv.org/abs/2509.22420)
*Ziyi Zhang,Devjeet Roy,Venera Arnaoudova*

Main category: cs.SE

TL;DR: 本研究通过八周纵向实验比较了四种调试指导方法：无指导、抽象指南、具体步骤和上下文特定指导。结果显示上下文特定指导在正确率和完成时间上显著优于其他方法，参与者能更快掌握技能并保持长期效果。


<details>
  <summary>Details</summary>
Motivation: 新手在bug定位时缺乏系统方法，现有研究测试了抽象指南和通用具体步骤，但上下文特定指导的影响尚不明确。

Method: 44名本科生参与八周纵向研究，分为四组：无指导(G1)、抽象指南(G2)、具体步骤(G3)、上下文特定指导(G4)。每节包含2-3个调试任务，测量正确率、完成时间、自我感知评分。

Result: G4组在第一节后达到80%正确率（其他组20-44%），三周后仍保持80%，显著优于其他组(p<0.05)。完成时间稳定在13-15分钟，而其他组需2-3节才能稳定在22-27分钟。G4组压力更低、满意度更高。

Conclusion: 上下文特定指导比抽象指南或上下文无关步骤能更快获得技能并保持更强记忆。将上下文示例与抽象原则结合可弥合bug定位教育中的理论与实践差距，为新手提供更公平的学习路径。

Abstract: Bug localization is a critical skill, yet novices often lack systematic
approaches. Prior work tested abstract guidelines and general concrete steps;
the impact of context-specific instruction is unclear. We ran an eight-week
longitudinal study with four conditions: no instruction (G1), abstract
guidelines (G2), concrete steps (G3), and our context-specific instruction that
pairs concrete bug-localization steps with problem-specific details (G4).
Forty-four undergraduates participated; 41 completed all five sessions (S1-S5).
Each session included 2-3 debugging tasks to identify the minimal code element
containing a seeded logical fault. We measured correctness (binary), time to
completion, self-perceived scores (stress, difficulty, satisfaction, and
strategy adherence). G4 achieved higher correctness and shorter time to
completion: it reached 80% correctness after one session (vs. 20-44% for other
groups) and maintained 80% after three weeks, outperforming all groups (p <
0.05); its time to completion stabilized at 13-15 minutes in S1, whereas other
groups took 2-3 sessions to stabilize at 22-27 minutes. Qualitative responses
showed lower stress and higher satisfaction in G4, with participants
internalizing strategies via contextual examples. We conclude that
context-specific instruction yields faster skill acquisition and stronger
retention than abstract guidelines or context-agnostic steps. Even 1-2 sessions
produced significant gains, while extended practice optimized and stabilized
performance. Integrating contextual examples with abstract principles may
bridge theory-practice gaps in bug-localization education and provide a more
equitable path for novices.

</details>


### [21] [TreeMind: Automatically Reproducing Android Bug Reports via LLM-empowered Monte Carlo Tree Search](https://arxiv.org/abs/2509.22431)
*Zhengyu Chen,Zhaoyi Meng,Wenxiang Zhao,Wansen Wang,Haoyang Zhao,Jiahao Zhan,Jie Cui,Hong Zhong*

Main category: cs.SE

TL;DR: TreeMind结合LLM与蒙特卡洛树搜索，通过战略性的UI探索来自动复现Android应用崩溃，在真实bug报告数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习或LLM的方法在复现不完整bug报告时存在局限，难以推断未观察步骤并导航复杂的UI交互空间，主要由于缺乏目标导向的推理和规划能力。

Method: 将复现任务建模为目标驱动的搜索问题，集成LLM与定制化MCTS算法：Expander代理基于当前UI状态生成top-k有前景动作，Simulator代理评估每个动作导向成功复现的可能性。

Result: 在93个真实Android bug报告数据集上的实验表明，TreeMind在复现成功率上显著优于四种最先进的基线方法。

Conclusion: 将LLM推理与MCTS规划相结合是实现自动化bug复现的有前景方向，通过反馈感知导航能够识别缺失的关键用户操作并逐步重建复现路径。

Abstract: Automatically reproducing Android app crashes from textual bug reports is
challenging, particularly when the reports are incomplete and the modern UI
exhibits high combinatorial complexity. Existing approaches based on
reinforcement learning or large language models (LLMs) exhibit limitations in
such scenarios. They struggle to infer unobserved steps and reconstruct the
underlying user action sequences to navigate the vast UI interaction space,
primarily due to limited goal-directed reasoning and planning. We present
TreeMind, a novel technique that integrates LLMs with a customized Monte Carlo
Tree Search (MCTS) algorithm to achieve strategic UI exploration in bug
reproduction. To the best of our knowledge, this is the first work to combine
external decision-making with LLM semantic reasoning for reliable bug
reproduction. We formulate the reproduction task as a target-driven search
problem, leveraging MCTS as the core planning mechanism to iteratively refine
action sequences. To enhance MCTS with semantic reasoning, we introduce two
LLM-guided agents with distinct roles: Expander generates top-k promising
actions based on the current UI state and exploration history, while Simulator
estimates the likelihood that each action leads toward successful reproduction.
By incorporating multi-modal UI inputs and advanced prompting techniques,
TreeMind conducts feedback-aware navigation that identifies missing but
essential user actions and incrementally reconstructs the reproduction paths.
We evaluate TreeMind on a dataset of 93 real-world Android bug reports from
three widely-used benchmarks. Experimental results show that it significantly
outperforms four state-of-the-art baselines in reproduction success rate. A
real-world case study indicates that integrating LLM reasoning with MCTS-based
planning is a compelling direction for automated bug reproduction.

</details>


### [22] [Boosting Pointer Analysis With Large Language Model-Enhanced Allocation Function Detection](https://arxiv.org/abs/2509.22530)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Peng Di,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: AFD通过自动识别和建模自定义分配函数来提升指针分析精度，结合值流分析和LLM处理复杂分配模式，在15个真实C项目中识别600+自定义分配函数，使堆对象建模增加26倍，别名集大小减少39%，仅带来1.4倍运行时开销。


<details>
  <summary>Details</summary>
Motivation: 现有指针分析方法大多忽略C/C++程序中普遍存在的用户自定义分配函数，导致别名分析粗糙和分析精度降低。

Method: 采用混合方法：使用值流分析检测简单包装器，利用大语言模型推理具有副作用的复杂分配模式，实现精确的堆对象建模。

Result: 在15个真实C项目中识别600+自定义分配函数，堆对象建模增加26倍，别名集大小减少39%，运行时开销仅1.4倍，并发现17个先前未检测到的内存错误。

Conclusion: 精确建模自定义分配函数为改进大型软件系统中的指针分析提供了可扩展且实用的路径。

Abstract: Pointer analysis is foundational for many static analysis tasks, yet its
effectiveness is often hindered by imprecise modeling of heap allocations,
particularly in C/C++ programs where user-defined allocation functions (AFs)
are pervasive. Existing approaches largely overlook these custom allocators,
leading to coarse aliasing and reduced analysis precision. In this paper, we
present AFD, a novel technique that enhances pointer analysis by automatically
identifying and modeling custom allocation functions. AFD employs a hybrid
approach: it uses value-flow analysis to detect straightforward wrappers and
leverages Large Language Models (LLMs) to reason about more complex allocation
patterns with side effects. This targeted enhancement enables precise modeling
of heap objects at each call site, achieving context-sensitivity-like benefits
without the associated overhead. We evaluate AFD on 15 real-world C projects,
identifying over 600 custom AFs. Integrating AFD into a baseline pointer
analysis yields a 26x increase in modeled heap objects and a 39% reduction in
alias set sizes, with only 1.4x runtime overhead. Furthermore, our enhanced
analysis improves indirect call resolution and uncovers 17 previously
undetected memory bugs. These results demonstrate that precise modeling of
custom allocation functions offers a scalable and practical path to improving
pointer analysis in large software systems.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [23] [Permutation closure for multiple context-free languages](https://arxiv.org/abs/2509.22239)
*Andrew Duncan,Murray Elder,Lisa Frenkel,Mengfan Lyu*

Main category: cs.FL

TL;DR: 本文证明了多重上下文无关语言的置换闭包仍然是多重上下文无关的，扩展了Okhotin和Sorokin关于循环移位闭包的工作。


<details>
  <summary>Details</summary>
Motivation: 研究多重上下文无关语言在置换操作下的闭包性质，填补该语言类在置换闭包方面的理论空白。

Method: 使用Denkinger提出的受限树栈自动机进行证明，与Okhotin和Sorokin基于文法的方法不同。

Result: 成功证明了多重上下文无关语言在置换操作下是封闭的。

Conclusion: 多重上下文无关语言具有置换闭包性质，这为理解该语言类的代数特性提供了重要理论支撑。

Abstract: We prove that the \emph{permutation closure} of a multiple context-free
language is multiple context-free, which extends work of Okhotin and Sorokin
[LATA 2020] who showed closure under \emph{cyclic shift}, and complements work
of Brandst\"adt [1981, RAIRO Inform. Th\'{e}or.] (resp. Brough \emph{et al.}
[2016, Discrete Math. Theor. Comput. Sci.]) who showed the same result for
regular, context-sensitive, recursively enumerable (resp. EDT0L and ET0L)
languages. In contrast to Okhotin and Sorokin who work with grammars, our proof
uses restricted tree stack automata due to Denkinger [DLT 2016].

</details>


### [24] [Passive Learning of Lattice Automata from Recurrent Neural Networks](https://arxiv.org/abs/2509.22489)
*Jaouhar Slimi,Tristan Le Gall,Augustin Lemesle*

Main category: cs.FL

TL;DR: 提出一种从具有大或无限字母表的循环网络中提取自动机的被动自动机学习算法，结合抽象解释和语法推理技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理具有大字母表或无限字母表的循环网络，需要开发能够处理这类情况的自动机提取算法。

Method: 结合抽象解释领域的过近似技术和语法推理领域的被动自动机学习方法。

Result: 在Tomita语法上与传统方法对比，并在提出的无限字母表正则语言新基准上进行了扩展实验验证。

Conclusion: 该算法能够有效提取具有大或无限字母表的循环网络中的自动机，为这类复杂场景提供了可行的解决方案。

Abstract: We present a passive automata learning algorithm that can extract automata
from recurrent networks with very large or even infinite alphabets. Our method
combines overapproximations from the field of Abstract Interpretation and
passive automata learning from the field of Grammatical Inference. We evaluate
our algorithm by first comparing it with the state-of-the-art automata
extraction algorithm from Recurrent Neural Networks trained on Tomita grammars.
Then, we extend these experiments to regular languages with infinite alphabets,
which we propose as a novel benchmark.

</details>
