<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [The Impact of Large Language Models (LLMs) on Code Review Process](https://arxiv.org/abs/2508.11034)
*Antonio Collante,Samuel Abedu,SayedHassan Khatoonabadi,Ahmad Abdellatif,Ebube Alor,Emad Shihab*

Main category: cs.SE

TL;DR: 研究探讨了GPT在GitHub代码审查流程中的影响，发现其能显著减少解决时间，优化各阶段性能，并帮助开发者。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在软件开发中广泛应用，但其在代码审查各阶段的具体效果尚未充分研究。

Method: 通过半自动化方法筛选GPT辅助的PR，并运用统计模型（如多元线性回归和Mann-Whitney U检验）进行分析。

Result: GPT辅助的PR中位解决时间减少60%，审查时间减少33%，等待时间减少87%。

Conclusion: GPT能显著提升代码审查效率，为团队提供实用建议。

Abstract: Large language models (LLMs) have recently gained prominence in the field of
software development, significantly boosting productivity and simplifying
teamwork. Although prior studies have examined task-specific applications, the
phase-specific effects of LLM assistance on the efficiency of code review
processes remain underexplored. This research investigates the effect of GPT on
GitHub pull request (PR) workflows, with a focus on reducing resolution time,
optimizing phase-specific performance, and assisting developers. We curated a
dataset of 25,473 PRs from 9,254 GitHub projects and identified GPT-assisted
PRs using a semi-automated heuristic approach that combines keyword-based
detection, regular expression filtering, and manual verification until
achieving 95% labeling accuracy. We then applied statistical modeling,
including multiple linear regression and Mann-Whitney U test, to evaluate
differences between GPT-assisted and non-assisted PRs, both at the overall
resolution level and across distinct review phases. Our research has revealed
that early adoption of GPT can substantially boost the effectiveness of the PR
process, leading to considerable time savings at various stages. Our findings
suggest that GPT-assisted PRs reduced median resolution time by more than 60%
(9 hours compared to 23 hours for non-assisted PRs). We discovered that
utilizing GPT can reduce the review time by 33% and the waiting time before
acceptance by 87%. Analyzing a sample dataset of 300 GPT-assisted PRs, we
discovered that developers predominantly use GPT for code optimization (60%),
bug fixing (26%), and documentation updates (12%). This research sheds light on
the impact of the GPT model on the code review process, offering actionable
insights for software teams seeking to enhance workflows and promote seamless
collaboration.

</details>


### [2] [Diffusion is a code repair operator and generator](https://arxiv.org/abs/2508.11110)
*Mukul Singh,Gust Verbruggen,Vu Le,Sumit Gulwani*

Main category: cs.SE

TL;DR: 论文探讨了如何利用预训练的代码扩散模型进行最后一英里修复，通过添加噪声或生成训练数据来优化代码片段。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用扩散模型在代码生成后期阶段的特性，解决最后一英里修复问题，以提高代码质量和效率。

Method: 通过添加噪声并恢复扩散过程，或从扩散过程中采样生成训练数据，评估其在Python、Excel和PowerShell中的应用。

Result: 实验验证了扩散模型在最后一英里修复中的有效性，并分析了其在不同领域的性能。

Conclusion: 代码扩散模型在最后一英里修复任务中具有潜力，可生成高效训练数据并优化代码修复过程。

Abstract: Code diffusion models generate code by iteratively removing noise from the
latent representation of a code snippet. During later steps of the diffusion
process, when the code snippet has almost converged, differences between
discrete representations of these snippets look like last-mile repairs applied
to broken or incomplete code. We evaluate the extent to which this resemblance
can be exploited to leverage pre-trained code diffusion models for the problem
of last-mile repair by considering two applications with significant potential.
First, we can leverage the diffusion model for last-mile repair by adding noise
to a broken code snippet and resuming the diffusion process. Second, we can
leverage the diffusion model to generate arbitrary amount of training data for
last-mile repair tasks (that are computationally more efficient) by sampling an
intermediate program (input) and the final program (output) from the diffusion
process. We perform experiments on 3 domains (Python, Excel and PowerShell) to
evaluate applications, as well as analyze properties.

</details>


### [3] [AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities](https://arxiv.org/abs/2508.11126)
*Huanting Wang,Jingzhi Gong,Huawei Zhang,Zheng Wang*

Main category: cs.SE

TL;DR: AI代理编程是一种新兴范式，利用大语言模型自主规划、执行并与外部工具交互，完成复杂软件开发任务。本文综述了其范围、技术基础及研究挑战。


<details>
  <summary>Details</summary>
Motivation: 定义AI代理编程的范畴，巩固其技术基础，并识别开放研究挑战，以推动该领域发展。

Method: 提出代理行为和系统架构的分类法，分析核心技术（如规划、记忆管理、工具集成等），并评估现有基准和方法。

Result: 总结了AI代理编程的关键挑战（如长上下文处理、持久记忆缺失、安全性和对齐问题）及改进机会。

Conclusion: 本文为下一代智能可信AI编码代理的研究和开发提供了基础，并展望了未来方向。

Abstract: AI agentic programming is an emerging paradigm in which large language models
(LLMs) autonomously plan, execute, and interact with external tools like
compilers, debuggers, and version control systems to iteratively perform
complex software development tasks. Unlike conventional code generation tools,
agentic systems are capable of decomposing high-level goals, coordinating
multi-step processes, and adapting their behavior based on intermediate
feedback. These capabilities are transforming the software development
practice. As this emerging field evolves rapidly, there is a need to define its
scope, consolidate its technical foundations, and identify open research
challenges. This survey provides a comprehensive and timely review of AI
agentic programming. We introduce a taxonomy of agent behaviors and system
architectures, and examine core techniques including planning, memory and
context management, tool integration, and execution monitoring. We also analyze
existing benchmarks and evaluation methodologies used to assess coding agent
performance. Our study identifies several key challenges, including limitations
in handling long context, a lack of persistent memory across tasks, and
concerns around safety, alignment with user intent, and collaboration with
human developers. We discuss emerging opportunities to improve the reliability,
adaptability, and transparency of agentic systems. By synthesizing recent
advances and outlining future directions, this survey aims to provide a
foundation for research and development in building the next generation of
intelligent and trustworthy AI coding agents.

</details>


### [4] [From Feedback to Failure: Automated Android Performance Issue Reproduction](https://arxiv.org/abs/2508.11147)
*Zhengquan Li,Zhenhao Li,Zishuo Ding*

Main category: cs.SE

TL;DR: RevPerf是一个利用Google Play应用评论检测移动应用性能问题的工具，通过丰富评论内容并执行命令复现问题，成功率达70%。


<details>
  <summary>Details</summary>
Motivation: 移动应用性能问题在开发环境中难以检测，影响用户体验，需要一种更有效的方法来复现和诊断这些问题。

Method: RevPerf利用Google Play评论，通过提示工程丰富评论内容，生成并执行命令复现问题，同时监测Android日志、GUI变化和系统资源使用。

Result: 实验结果显示，RevPerf在构建的数据集上复现性能问题的成功率为70%。

Conclusion: RevPerf提供了一种有效的方法来复现移动应用性能问题，有助于开发者在早期发现和解决问题。

Abstract: Mobile application performance is a vital factor for user experience. Yet,
performance issues are notoriously difficult to detect within development
environments, where their manifestations are often less conspicuous and
diagnosis proves more challenging. To address this limitation, we propose
RevPerf, an advanced performance issue reproduction tool that leverages app
reviews from Google Play to acquire pertinent information. RevPerf employs
relevant reviews and prompt engineering to enrich the original review with
performance issue details. An execution agent is then employed to generate and
execute commands to reproduce the issue. After executing all necessary steps,
the system incorporates multifaceted detection methods to identify performance
issues by monitoring Android logs, GUI changes, and system resource utilization
during the reproduction process. Experimental results demonstrate that our
proposed framework achieves a 70\% success rate in reproducing performance
issues on the dataset we constructed and manually validated.

</details>


### [5] [PTMPicker: Facilitating Efficient Pretrained Model Selection for Application Developers](https://arxiv.org/abs/2508.11179)
*Pei Liu,Terry Zhuo,Jiawei Deng,Zhenchang Xing,Qinghua Lu,Xiaoning Du,Hongyu Zhan*

Main category: cs.SE

TL;DR: 论文提出PTMPicker，通过结构化模板和嵌入相似性计算，帮助用户更准确地选择预训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于关键词的模型搜索方法难以全面捕捉用户意图，尤其是在考虑偏差缓解、硬件要求或许可证合规性等因素时。

Method: 定义结构化模板表示模型和用户需求，计算嵌入相似性评估功能属性，使用提示评估特殊约束。

Result: 在合成数据集上，PTMPicker成功为85%的请求在前10候选中找到合适模型。

Conclusion: PTMPicker有效解决了预训练模型选择问题，提升了搜索准确性和用户体验。

Abstract: The rapid emergence of pretrained models (PTMs) has attracted significant
attention from both Deep Learning (DL) researchers and downstream application
developers. However, selecting appropriate PTMs remains challenging because
existing methods typically rely on keyword-based searches in which the keywords
are often derived directly from function descriptions. This often fails to
fully capture user intent and makes it difficult to identify suitable models
when developers also consider factors such as bias mitigation, hardware
requirements, or license compliance. To address the limitations of
keyword-based model search, we propose PTMPicker to accurately identify
suitable PTMs. We first define a structured template composed of common and
essential attributes for PTMs and then PTMPicker represents both candidate
models and user-intended features (i.e., model search requests) in this unified
format. To determine whether candidate models satisfy user requirements, it
computes embedding similarities for function-related attributes and uses
well-crafted prompts to evaluate special constraints such as license compliance
and hardware requirements. We scraped a total of 543,949 pretrained models from
Hugging Face to prepare valid candidates for selection. PTMPicker then
represented them in the predefined structured format by extracting their
associated descriptions. Guided by the extracted metadata, we synthesized a
total of 15,207 model search requests with carefully designed prompts, as no
such search requests are readily available. Experiments on the curated PTM
dataset and the synthesized model search requests show that PTMPicker can help
users effectively identify models,with 85% of the sampled requests successfully
locating appropriate PTMs within the top-10 ranked candidates.

</details>


### [6] [ORFuzz: Fuzzing the "Other Side" of LLM Safety -- Testing Over-Refusal](https://arxiv.org/abs/2508.11222)
*Haonan Zhang,Dongxia Wang,Yi Liu,Kexin Chen,Jiashui Wang,Xinlei Ying,Long Liu,Wenhai Wang*

Main category: cs.SE

TL;DR: 论文提出了ORFuzz，首个用于检测和分析大型语言模型（LLM）过度拒绝问题的进化测试框架，显著提升了测试覆盖率和效果。


<details>
  <summary>Details</summary>
Motivation: 当前测试LLM过度拒绝行为的方法存在缺陷，如基准测试不完善和测试生成能力有限，影响了LLM的可靠性和可用性。

Method: ORFuzz整合了三个核心组件：安全类别感知的种子选择、基于推理LLM的自适应变异优化，以及人类对齐的评判模型OR-Judge。

Result: ORFuzz生成的过度拒绝实例率（6.98%）是现有方法的两倍以上，并创建了ORFuzzSet基准测试集，覆盖10种LLM，平均拒绝率达63.56%。

Conclusion: ORFuzz和ORFuzzSet为开发更可靠的LLM系统提供了自动化测试框架和社区资源。

Abstract: Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously
rejecting benign queries due to overly conservative safety measures - a
critical functional flaw that undermines their reliability and usability.
Current methods for testing this behavior are demonstrably inadequate,
suffering from flawed benchmarks and limited test generation capabilities, as
highlighted by our empirical user study. To the best of our knowledge, this
paper introduces the first evolutionary testing framework, ORFuzz, for the
systematic detection and analysis of LLM over-refusals. ORFuzz uniquely
integrates three core components: (1) safety category-aware seed selection for
comprehensive test coverage, (2) adaptive mutator optimization using reasoning
LLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge
model validated to accurately reflect user perception of toxicity and refusal.
Our extensive evaluations demonstrate that ORFuzz generates diverse, validated
over-refusal instances at a rate (6.98% average) more than double that of
leading baselines, effectively uncovering vulnerabilities. Furthermore,
ORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly
transferable test cases that achieves a superior 63.56% average over-refusal
rate across 10 diverse LLMs, significantly outperforming existing datasets.
ORFuzz and ORFuzzSet provide a robust automated testing framework and a
valuable community resource, paving the way for developing more reliable and
trustworthy LLM-based software systems.

</details>


### [7] [Hallucination in LLM-Based Code Generation: An Automotive Case Study](https://arxiv.org/abs/2508.11257)
*Marc Pavel,Nenad Petrovic,Lukasz Mazur,Vahid Zolfaghari,Fengjunjie Pan,Alois Knoll*

Main category: cs.SE

TL;DR: 论文研究了大型语言模型（LLMs）在代码生成中的幻觉问题，特别是在汽车领域。通过案例研究评估了不同提示复杂度下模型的性能，发现现有模型存在高频率的错误，仅少数模型在丰富上下文的提示下能生成正确代码。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码生成中表现出潜力，但幻觉问题限制了其实际应用，尤其是在安全关键的汽车领域。

Method: 通过案例研究评估了GPT-4.1、Codex和GPT-4o等模型在不同提示复杂度下的表现，包括简单提示、带VSS上下文的提示和带代码骨架的提示。

Result: 现有模型在简单提示下表现不佳，仅GPT-4.1和GPT-4o在丰富上下文的提示下能生成正确代码。

Conclusion: 需开发有效的缓解技术，以确保LLM生成代码的安全性和可靠性，特别是在安全关键领域。

Abstract: Large Language Models (LLMs) have shown significant potential in automating
code generation tasks offering new opportunities across software engineering
domains. However, their practical application remains limited due to
hallucinations - outputs that appear plausible but are factually incorrect,
unverifiable or nonsensical. This paper investigates hallucination phenomena in
the context of code generation with a specific focus on the automotive domain.
A case study is presented that evaluates multiple code LLMs for three different
prompting complexities ranging from a minimal one-liner prompt to a prompt with
Covesa Vehicle Signal Specifications (VSS) as additional context and finally to
a prompt with an additional code skeleton. The evaluation reveals a high
frequency of syntax violations, invalid reference errors and API knowledge
conflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the
evaluated models, only GPT-4.1 and GPT-4o were able to produce a correct
solution when given the most context-rich prompt. Simpler prompting strategies
failed to yield a working result, even after multiple refinement iterations.
These findings highlight the need for effective mitigation techniques to ensure
the safe and reliable use of LLM generated code, especially in safety-critical
domains such as automotive software systems.

</details>


### [8] [Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning](https://arxiv.org/abs/2508.11305)
*Xin Wang,Zhenhao Li,Zishuo Ding*

Main category: cs.SE

TL;DR: 论文提出了一种全面的日志代码缺陷分类法，构建了真实缺陷数据集，并评估了大型语言模型（LLMs）在检测日志缺陷中的表现。实验表明，LLMs在仅基于源代码时表现不佳，但加入适当知识后可提升10.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 日志代码缺陷可能导致日志误读，现有研究缺乏系统性分析，且LLMs在此领域的潜力尚未充分探索。

Method: 提出七种日志缺陷模式的分类法，构建包含164个真实缺陷的数据集，并设计自动化框架评估LLMs的检测能力。

Result: LLMs仅基于源代码检测缺陷表现不佳，但加入缺陷模式详细场景后准确率提升10.9%。

Conclusion: 研究为开发者提供了避免常见缺陷的指导，并为改进LLMs在日志缺陷检测中的推理能力奠定了基础。

Abstract: Logging code is written by developers to capture system runtime behavior and
plays a vital role in debugging, performance analysis, and system monitoring.
However, defects in logging code can undermine the usefulness of logs and lead
to misinterpretations. Although prior work has identified several logging
defect patterns and provided valuable insights into logging practices, these
studies often focus on a narrow range of defect patterns derived from limited
sources (e.g., commit histories) and lack a systematic and comprehensive
analysis. Moreover, large language models (LLMs) have demonstrated promising
generalization and reasoning capabilities across a variety of code-related
tasks, yet their potential for detecting logging code defects remains largely
unexplored.
  In this paper, we derive a comprehensive taxonomy of logging code defects,
which encompasses seven logging code defect patterns with 14 detailed
scenarios. We further construct a benchmark dataset, \dataset, consisting of
164 developer-verified real-world logging defects. Then we propose an automated
framework that leverages various prompting strategies and contextual
information to evaluate LLMs' capability in detecting and reasoning logging
code defects. Experimental results reveal that LLMs generally struggle to
accurately detect and reason logging code defects based on the source code
only. However, incorporating proper knowledge (e.g., detailed scenarios of
defect patterns) can lead to 10.9\% improvement in detection accuracy. Overall,
our findings provide actionable guidance for practitioners to avoid common
defect patterns and establish a foundation for improving LLM-based reasoning in
logging code defect detection.

</details>


### [9] [TRACY: Benchmarking Execution Efficiency of LLM-Based Code Translation](https://arxiv.org/abs/2508.11468)
*Zhihao Gong,Zeyu Sun,Dong Huang,Qingyuan Liang,Jie M. Zhang,Dan Hao*

Main category: cs.SE

TL;DR: TRACY是首个评估LLM翻译代码执行效率的基准测试，通过两阶段流程构建，发现顶级LLM在效率上表现不佳，需同时优化正确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在代码翻译中忽视了执行效率，TRACY旨在填补这一空白。

Method: 采用LLM驱动的两阶段流程：生成压力测试和效率导向任务筛选，构建包含1,011任务的基准。

Result: 26个LLM评估显示，顶级模型在效率上表现不佳，算法缺陷和资源处理不当是主要原因。

Conclusion: 未来代码翻译需同时优化正确性和效率。

Abstract: Automatic code translation is a fundamental task in modern software
development. While the advent of Large Language Models (LLMs) has significantly
improved the correctness of code translation, the critical dimension of
execution efficiency remains overlooked. To address this gap, we introduce
TRACY, the first comprehensive benchmark designed to evaluate the execution
efficiency of LLM-translated code. TRACY is constructed through an LLM-driven
two-stage pipeline: an initial stage generates a suite of stress tests to
amplify performance differences, followed by an efficiency-oriented task
pruning stage that isolates the efficiency-distinguishing tasks. The resulting
benchmark comprises 1,011 code translation tasks across C++, Java, and Python,
each accompanied by an average of 22.1 verified reference translations and 10
computationally demanding tests. Our extensive evaluation of 26 representative
LLMs reveals that even top-tier LLMs struggle to consistently produce efficient
code translations. For instance, Claude-4-think, the leading model for
correctness, ranks eighth overall when time efficiency is taken into account,
surpassed by several smaller open-source models. We further pinpoint that
algorithmic flaws and improper resource handling are the most detrimental,
causing a median time slowdown of 5.6$\times$ and memory increase of
12.0$\times$, respectively. Our work underscores the necessity of jointly
optimizing for correctness and efficiency in future LLM-based code translation.

</details>


### [10] [Temporal Network Analysis of Microservice Architectural Degradation](https://arxiv.org/abs/2508.11571)
*Alexander Bakhtin*

Main category: cs.SE

TL;DR: 论文探讨了从微服务系统中获取时间网络并进行分析的挑战，指出目前获取的数据规模有限（7个时间实例和42个微服务），限制了分析方法的应用。


<details>
  <summary>Details</summary>
Motivation: 研究微服务架构的时间依赖性网络，利用网络科学方法分析其动态变化。

Method: 通过追踪微服务系统的架构变化或部署监控，构建时间网络。

Result: 目前获取的最完整时间网络仅包含7个时间实例和42个微服务，数据规模限制了分析深度。

Conclusion: 未来需要更大规模的数据以支持更全面的时间网络分析。

Abstract: Microservice architecture can be modeled as a network of microservices making
calls to each other, commonly known as the service dependency graph. Network
Science can provide methods to study such networks. In particular, temporal
network analysis is a branch of Network Science that analyzes networks evolving
with time. In microservice systems, temporal networks can arise if we examine
the architecture of the system across releases or monitor a deployed system
using tracing.
  In this research summary paper, I discuss the challenges in obtaining
temporal networks from microservice systems and analyzing them with the
temporal network methods. In particular, the most complete temporal network
that we could obtain contains 7 time instances and 42 microservices, which
limits the potential analysis that could be applied.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [Characterizing NC1 with Typed Monoids](https://arxiv.org/abs/2508.11019)
*Anuj Dawar,Aidan T. Evans*

Main category: cs.LO

TL;DR: 该论文扩展了Krebs等人（2007）的工作，通过引入一种逻辑扩展和量化方法，将NC1复杂性类表征为一类特定逻辑表达的语言。


<details>
  <summary>Details</summary>
Motivation: 扩展代数自动机理论方法，以表征超越TC0的复杂性类NC1。

Method: 通过扩展一阶逻辑并仅使用一元量词，结合有限幺半群乘法量词的替换，实现NC1的表征。

Result: 证明了NC1可以通过特定逻辑表达，并解决了Lautemann等人（2001）的问题。

Conclusion: 该研究不仅表征了NC1，还扩展了Bojańczyk等人（2019）的解释方法，具有独立意义。

Abstract: Krebs et al. (2007) gave a characterization of the complexity class TC0 as
the class of languages recognized by a certain class of typed monoids. The
notion of typed monoid was introduced to extend methods of algebraic automata
theory to infinite monoids and hence characterize classes beyond the regular
languages. We advance this line of work beyond TC0 by giving a characterization
of NC1. This is obtained by first showing that NC1 can be defined as the
languages expressible in an extension of first-order logic using only unary
quantifiers over regular languages. The expressibility result is a consequence
of a general result showing that finite monoid multiplication quantifiers of
higher dimension can be replaced with unary quantifiers in the context of
interpretations over strings, which also answers a question of Lautemann et al.
(2001). We establish this collapse result for a much more general class of
interpretations using results on interpretations due to Boja\'nczyk et al.
(2019), which may be of independent interest.

</details>


### [12] [Automating the Derivation of Unification Algorithms: A Case Study in Deductive Program Synthesis](https://arxiv.org/abs/2508.11136)
*Richard Waldinger*

Main category: cs.LO

TL;DR: 本文研究了自动推导统一算法的程序合成方法，通过定理证明生成满足规格的程序，并验证其正确性。


<details>
  <summary>Details</summary>
Motivation: 统一算法是程序合成研究的重要目标，但完全自动推导仍具挑战性。本文旨在通过定理证明方法实现自动合成。

Method: 采用演绎程序合成方法，将编程任务转化为定理证明问题，并在适当的公理领域理论中进行证明。

Result: 成功生成了一个三参数统一算法，能够处理环境替换并输出最一般幂等统一器。

Conclusion: 带环境的三参数算法比传统两参数版本更高效且易于自动合成。

Abstract: The unification algorithm has long been a target for program synthesis
research, but a fully automatic derivation remains a research goal. In
deductive program synthesis, computer programming is phrased as a task in
theorem proving; a declarative specification is expressed in logical form and
presented to an automatic theorem prover, and a program meeting the
specification is extracted from the proof. The correctness of the program is
supported by the proof, which also provides an explanation of how the program
works. The proof is conducted in an appropriate axiomatic subject-domain
theory, which defines the concepts in the specification and the constructs in
the target programming language and provides the background knowledge necessary
to connect them.
  For the unification proof, we generalize and automate the manual proof
presented in Manna and Waldinger [1981]. The new program unifies two given
symbolic expressions (s-expressions) relative to a given "environment"
substitution. The proof establishes the existence of an output substitution
that is a most-general idempotent unifier of the given expressions and is an
"extension" of the environment substitution. If no such substitution exists and
the expressions are not unifiable, the program is to produce a failure
indicator.
  Initially the environment substitution is the empty substitution, which makes
no replacements at all; during execution of recursive calls, the environment
substitution records the replacements that have been found so far. Our own
unification algorithm employs an environment, and such algorithms appear in the
literature [e.g., Luger and Stubblefield, 1997]. We suspect, in addition to
being more efficient, the three-argument algorithm with an environment is
easier to synthesize automatically than the two-argument version from the
Manna-Waldinger paper.

</details>


### [13] [Encoding and Reasoning About Arrays in Set Theory](https://arxiv.org/abs/2508.11447)
*Maximiliano Cristiá,Gianfranco Rossi*

Main category: cs.LO

TL;DR: 将数组编码为函数，再进一步编码为有序对集合，通过集合论片段实现数组程序规范，并扩展了{log}工具的决策过程。


<details>
  <summary>Details</summary>
Motivation: 将数组推理转化为集合推理，统一语言和求解器处理集合、函数和数组。

Method: 定义集合论片段，编码数组为函数和有序对集合，扩展{log}工具的决策过程。

Result: 实现了数组与{log}的无缝集成，支持集合、函数和数组的统一推理。

Conclusion: 通过集合论方法成功扩展了{log}工具，使其支持数组推理。

Abstract: We encode arrays as functions which, in turn, are encoded as sets of ordered
pairs. The set cardinality of each of these functions coincides with the length
of the array it is representing. Then we define a fragment of set theory that
is used to give the specifications of a non-trivial class of programs with
arrays. In this way, array reasoning becomes set reasoning. Furthermore, a
decision procedure for this fragment is also provided and implemented as part
of the {log} (read 'setlog') tool. {log} is a constraint logic programming
language and satisfiability solver where sets and binary relations are
first-class citizens. The tool already implements a few decision procedures for
different fragments of set theory. In this way, arrays are seamlessly
integrated into {log} thus allowing users to reason about sets, functions and
arrays all in the same language and with the same solver. The decision
procedure presented in this paper is an extension of decision procedures
defined in earlier works not supporting arrays.

</details>


### [14] [Interpolation in Classical Propositional Logic](https://arxiv.org/abs/2508.11449)
*Patrick Koopmann,Christoph Wernhard,Frank Wolter*

Main category: cs.LO

TL;DR: 论文介绍了经典命题逻辑中的Craig插值及相关概念，提出了四种计算插值的方法，并讨论了插值大小与电路复杂度的联系。


<details>
  <summary>Details</summary>
Motivation: 研究经典命题逻辑中的插值问题，探索不同方法计算插值并分析其性质。

Method: 通过量词消去、析取范式公式、从归结或表推演中提取四种方法计算插值。

Result: 提出了四种有效的插值计算方法，并分析了插值大小与电路复杂度的关系。

Conclusion: 论文为经典命题逻辑中的插值问题提供了多种解决方案，并揭示了其与电路复杂度的联系。

Abstract: We introduce Craig interpolation and related notions such as uniform
interpolation, Beth definability, and theory decomposition in classical
propositional logic. We present four approaches to computing interpolants: via
quantifier elimination, from formulas in disjunctive normal form, and by
extraction from resolution or tableau refutations. We close with a discussion
of the size of interpolants and links to circuit complexity.

</details>


### [15] [Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations](https://arxiv.org/abs/2508.11515)
*Qipeng Kuang,Václav Kůla,Ondřej Kuželka,Yuanhong Wang,Yuyi Wang*

Main category: cs.LO

TL;DR: 本文研究了加权一阶模型计数问题（WFOMC）在二变量片段（FO²）中扩展两个关系的复杂性，发现某些扩展会导致问题变为#P₁-难，而其他扩展仍可在多项式时间内求解。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注单关系上的公理扩展，缺乏对多关系公理扩展复杂性的理解。本文旨在填补这一空白。

Method: 探索了FO²和C²片段在两种关系公理扩展下的复杂性，包括负结果（#P₁-难）和正结果（多项式时间算法）。

Result: 发现FO²扩展两个线性序关系或两个无环关系时为#P₁-难，而C²扩展线性序关系及其两个后继关系时仍可在多项式时间内求解。

Conclusion: 多关系公理扩展的复杂性边界不同于单关系扩展，为WFOMC问题的理论研究提供了新视角。

Abstract: The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the
weighted sum of models of a given first-order logic sentence over a given
domain. The boundary between fragments for which WFOMC can be computed in
polynomial time relative to the domain size lies between the two-variable
fragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It is
known that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-time
algorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$,
possibly extended by certain axioms such as the linear order axiom, the
acyclicity axiom, and the connectedness axiom. All existing research has
concentrated on extending the fragment with axioms on a single distinguished
relation, leaving a gap in understanding the complexity boundary of axioms on
multiple relations. In this study, we explore the extension of the two-variable
fragment by axioms on two relations, presenting both negative and positive
results. We show that WFOMC for $\text{FO}^2$ with two linear order relations
and $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard.
Conversely, we provide an algorithm in time polynomial in the domain size for
WFOMC of $\text{C}^2$ with a linear order relation, its successor relation and
another successor relation.

</details>


### [16] [Robust Topology and the Hausdorff-Smyth Monad on Metric Spaces over Continuous Quantales](https://arxiv.org/abs/2508.11623)
*Francesco Dagnino,Amin Farjudian Eugenio Moggi*

Main category: cs.LO

TL;DR: 论文定义了基于连续量子的度量空间类别，提出了广义开球拓扑和鲁棒拓扑，并证明了所有拓扑均可由量子值度量生成，为定量分析不精确性和鲁棒性提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 为计算和物理系统中的不精确性和鲁棒性提供定量分析的理论基础。

Method: 定义了一个基于连续量子的度量空间类别，引入广义开球拓扑和鲁棒拓扑，并构建了Hausdorff-Smyth单子。

Result: 证明了所有拓扑均可由量子值度量生成，且鲁棒拓扑与Hausdorff-Smyth单子的开球拓扑一致。

Conclusion: 该框架为广泛的计算和物理系统中的定量分析提供了理论基础。

Abstract: We define a (preorder-enriched) category $\mathsf{Met}$ of quantale-valued
metric spaces and uniformly continuous maps, with the essential requirement
that the quantales are continuous. For each object $(X,d,Q)$ in this category,
where $X$ is the carrier set, $Q$ is a continuous quantale, and $d: X \times X
\to Q$ is the metric, we consider a topology $\tau_d$ on $X$, which generalizes
the open ball topology, and a topology $\tau_{d,R}$ on the powerset
$\mathsf{P}(X)$, called the robust topology, which captures robustness with
respect to small perturbations of parameters. We define a (preorder-enriched)
monad $\mathsf{P}_S$ on $\mathsf{Met}$, called the Hausdorff-Smyth monad, which
captures the robust topology, in the sense that the open ball topology of the
object $\mathsf{P}_S(X,d,Q)$ coincides with the robust topology $\tau_{d,R}$
for the object $(X,d,Q)$. We prove that every topology arises from a
quantale-valued metric. As such, our framework provides a foundation for
quantitative reasoning about imprecision and robustness in a wide range of
computational and physical systems.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [17] [Generic Reduction-Based Interpreters (Extended Version)](https://arxiv.org/abs/2508.11297)
*Casper Bach*

Main category: cs.PL

TL;DR: 本文提出利用泛型编程技术减少基于规约的解释器中的样板代码。


<details>
  <summary>Details</summary>
Motivation: 传统基于规约的解释器需要大量样板代码，增加了实现复杂度。

Method: 应用泛型编程技术优化代码结构。

Result: 减少了样板代码，提高了开发效率。

Conclusion: 泛型编程能有效简化基于规约的解释器实现。

Abstract: Reduction-based interpreters are traditionally defined in terms of a one-step
reduction function which systematically decomposes a term into a potential
redex and context, contracts the redex, and recomposes it to construct the new
term to be further reduced. While implementing such interpreters follows a
systematic recipe, they often require interpreter engineers to write a
substantial amount of code -- much of it boilerplate. In this paper, we apply
well-known techniques from generic programming to reduce boilerplate code in
reduction-based interpreters.

</details>


### [18] [Towards Efficient Hash Maps in Functional Array Languages](https://arxiv.org/abs/2508.11443)
*William Henrich Due,Martin Elsman,Troels Henriksen*

Main category: cs.PL

TL;DR: 论文提出了一种数据并行的两级静态无冲突哈希映射实现方法，基于Fredman等人的构建方法，并通过功能化和平坦化实现。讨论了在功能数组语言中提供灵活、多态和抽象接口的挑战，特别是动态大小键的问题。算法在Futhark中实现，GPU性能优于传统树/搜索方法，但比cuCollections库慢。分析了性能差异的原因，并探讨了功能数组语言模型的扩展可能性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决功能数组语言中哈希映射的灵活性和性能问题，特别是动态大小键的处理，同时探索数据并行实现的潜力。

Method: 通过功能化Fredman等人的构建方法并平坦化，实现两级静态无冲突哈希映射。在Futhark中实现，并对比GPU性能。

Result: 实现的哈希映射性能优于传统方法，但比cuCollections库慢。性能差异部分源于Futhark编译器的限制，部分源于数据并行编程模型的表达不足。

Conclusion: 功能数组语言模型可能需要扩展以解决性能问题，同时保持其抽象和灵活性。

Abstract: We present a systematic derivation of a data-parallel implementation of
two-level, static and collision-free hash maps, by giving a functional
formulation of the Fredman et al. construction, and then flattening it. We
discuss the challenges of providing a flexible, polymorphic, and abstract
interface to hash maps in a functional array language, with particular
attention paid to the problem of dynamically sized keys, which we address by
associating each hash map with an arbitrary context. The algorithm is
implemented in Futhark, and the achieved GPU execution performance is compared
on simple benchmark problems. We find that our hash maps outperform
conventional tree/search-based approaches. Furthermore, our implementation is
compared against the state-of-the-art cuCollections library, which is
significantly faster for hash map construction, and to a lesser degree for
lookups. We explain to which extent the performance difference is due to
low-level code generation limitation in the Futhark compiler, and to which
extent it can be attributed to the data-parallel programming vocabulary not
providing the constructs necessary to express the equivalent of the algorithms
used by cuCollections. We end by reflecting to which extent the functional
array language programming model could, or should, be extended to address these
weaknesses.

</details>
