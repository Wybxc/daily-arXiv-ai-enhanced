<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 4]
- [cs.FL](#cs.FL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 35]
- [cs.PL](#cs.PL) [Total: 5]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Structural Separation and Semantic Incompatibility in the P vs. NP Problem: Computational Complexity Analysis with Construction Defining Functionality](https://arxiv.org/abs/2509.22995)
*Yumiko Nishiyama*

Main category: cs.LO

TL;DR: 本文提出CDF框架，将SAT视为NP复杂性的结构原型而非仅仅是NP完全性的代表，认为3SAT的句法结构是导致NP问题语义爆炸和计算难解性的根源。


<details>
  <summary>Details</summary>
Motivation: 传统上SAT仅被视为NP完全问题的基准，但作者认为SAT本身的句法结构可能是NP类型复杂性的来源，这为P vs NP问题提供了新的视角。

Method: 提出CDF框架，从结构角度分析SAT特别是3SAT的句法特征，探讨其如何诱导计算难解性。

Result: 发现3SAT的递归和非局部构造可能定义了可解与难解问题的边界，SAT不仅是NP完全性的度量标准，更是NP复杂性的结构原型。

Conclusion: P vs NP问题不仅根植于计算资源限制，还深植于问题句法的生成原则，3SAT捕获了定义可解与难解问题边界的递归和非局部构造。

Abstract: The Boolean satisfiability problem (SAT) holds a central place in
computational complexity theory as the first shown NP-complete problem. Due to
this role, SAT is often used as the benchmark for polynomial-time reductions:
if a problem can be reduced to SAT, it is at least as hard as SAT, and hence
considered NP-complete. However, the CDF framework offers a structural
inversion of this traditional view. Rather than treating SAT as merely a
representative of NP-completeness, we investigate whether the syntactic
structure of SAT itself -- especially in its 3SAT form -- is the source of
semantic explosion and computational intractability observed in NP problems. In
other words, SAT is not just the yardstick of NP-completeness, but may be the
structural archetype that induces NP-type complexity. This reframing suggests
that the P vs NP question is deeply rooted not only in computational resource
limits, but in the generative principles of problem syntax, with 3SAT capturing
the recursive and non-local constructions that define the boundary between
tractable and intractable problems.

</details>


### [2] [Proceedings Twentieth International Symposium on Logical and Semantic Frameworks with Applications](https://arxiv.org/abs/2509.23739)
*Haniel Barbosa,Christophe Ringeissen*

Main category: cs.LO

TL;DR: LSFA 2025研讨会论文集，聚焦逻辑和语义框架的理论与实践结合


<details>
  <summary>Details</summary>
Motivation: 汇集理论家和实践者，促进新技术和成果的交流，从理论角度推动创新，从实践角度获得实施和应用的反馈

Method: 通过研讨会形式组织学术交流，涵盖证明与类型理论、等式推导与重写系统、自动推理和并发理论等领域

Result: 成功举办了第20届LSFA研讨会，形成了包含相关研究成果的论文集

Conclusion: LSFA系列研讨会为逻辑和语义框架领域的研究者提供了重要的交流平台，促进了理论与实践的融合

Abstract: This volume contains the proceedings of the 20th Workshop on Logical and
Semantic Frameworks with Applications (LSFA 2025), which was held in Brasilia,
the capital of Brazil, from October 7 to October 8, 2025.
  The aim of the LSFA series of workshops is bringing together theoreticians
and practitioners to promote new techniques and results, from the theoretical
side, and feedback on the implementation and use of such techniques and
results, from the practical side. LSFA includes areas such as proof and type
theory, equational deduction and rewriting systems, automated reasoning and
concurrency theory.

</details>


### [3] [The Complexity of Defining and Separating Fixpoint Formulae in Modal Logic](https://arxiv.org/abs/2509.24583)
*Jean Christoph Jung,Jędrzej Kołodziejski*

Main category: cs.LO

TL;DR: 本文研究了模态不动点公式的模态可分性问题，即在给定两个模态不动点公式φ和φ'时，判断是否存在一个模态公式ψ使得φ蕴含ψ且ψ蕴含¬φ'。


<details>
  <summary>Details</summary>
Motivation: 研究模态可分性及其特例模态可定义性在不同模型类上的复杂性，包括任意模型、有限模型、树和出度有界模型。特别关注模态逻辑在出度有界模型上不满足Craig插值性质的情况。

Method: 通过复杂性分析研究模态可分性问题，考虑不同模型类（单词、无限制模型、二元模型、出度有界模型）上的计算复杂性，并研究插值存在性作为模态可分性的特例。

Result: 模态可分性在单词模型上是PSpace完全的，在无限制和二元模型上是ExpTime完全的，在出度有界模型（d≥3）上是TwoExpTime完全的。插值存在性问题是coNExpTime完全的。

Conclusion: 模态可分性在不同模型类上表现出不同的计算复杂性，出度有界模型的情况与其他情况有根本性差异。本文还提供了构造分离器的有效算法，并研究了带分级模态的扩展情况。

Abstract: Modal separability for modal fixpoint formulae is the problem to decide for
two given modal fixpoint formulae $\varphi,\varphi'$ whether there is a modal
formula $\psi$ that separates them, in the sense that $\varphi\models\psi$ and
$\psi\models\neg\varphi'$. We study modal separability and its special case
modal definability over various classes of models, such as arbitrary models,
finite models, trees, and models of bounded outdegree. Our main results are
that modal separability is PSpace-complete over words, that is, models of
outdegree $\leq 1$, ExpTime-complete over unrestricted and over binary models,
and TwoExpTime-complete over models of outdegree bounded by some $d\geq 3$.
Interestingly, this latter case behaves fundamentally different from the other
cases also in that modal logic does not enjoy the Craig interpolation property
over this class. Motivated by this we study also the induced interpolant
existence problem as a special case of modal separability, and show that it is
coNExpTime-complete and thus harder than validity in the logic. Besides
deciding separability, we also provide algorithms for the effective
construction of separators. Finally, we consider in a case study the extension
of modal fixpoint formulae by graded modalities and investigate separability by
modal formulae and graded modal formulae.

</details>


### [4] [Generalization of Variadic Structures with Binders: A Tool for Structural Code Comparison](https://arxiv.org/abs/2509.25023)
*Alexander Baumgartner,Temur Kutsia*

Main category: cs.LO

TL;DR: 提出了一种新颖的反统一算法，用于泛化带有绑定器的可变参数结构，作为结构代码比较的灵活工具。


<details>
  <summary>Details</summary>
Motivation: 解决代码比较中的关键挑战：过度强调绑定变量名称、难以处理代码片段中的插入或删除操作。

Method: 结合名义技术处理变量绑定，支持可变参数表达式，区分原子和两种变量类型（项变量和树篱变量），使用可参数化的刚性函数控制相似性标准。

Result: 算法能够计算最佳泛化，最大程度保留结构相似性同时抽象系统差异，提供重构原始表达式和量化结构差异的详细信息。

Conclusion: 该框架不仅适用于代码相似性检测，还可广泛应用于需要精确比较可变参数和绑定器丰富表示的场景。

Abstract: This paper introduces a novel anti-unification algorithm for the
generalization of variadic structures with binders, designed as a flexible tool
for structural code comparison. By combining nominal techniques for handling
variable binding with support for variadic expressions (common in abstract
syntax trees and programming languages), the approach addresses key challenges
such as overemphasis on bound variable names and difficulty handling insertions
or deletions in code fragments. The algorithm distinguishes between atoms and
two kinds of variables (term and hedge variables) to compute best
generalizations that maximally preserve structural similarities while
abstracting systematic differences. It also provides detailed information to
reconstruct original expressions and quantify structural differences. This
information can be useful in tasks like code clone detection, refactoring, and
program analysis. By introducing a parametrizable rigidity function, the
technique offers fine-grained control over similarity criteria and reduces
nondeterminism, enabling flexible adaptation to practical scenarios where
trivial similarities should be discounted. Although demonstrated primarily in
the context of code similarity detection, this framework is broadly applicable
wherever precise comparison of variadic and binder-rich representations is
required.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [5] [The Role of Logic and Automata in Understanding Transformers](https://arxiv.org/abs/2509.24024)
*Anthony W. Lin,Pablo Barcelo*

Main category: cs.FL

TL;DR: 本文回顾了近年来关于transformer能力的研究进展，重点探讨了逻辑和自动机理论在理解transformer能力方面的作用，并提出了几个交叉领域的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 尽管transformer架构催生了强大的大语言模型，但我们对transformer能力的理解仍然有限。本文旨在通过逻辑和自动机理论来回答"transformer能做什么"这个核心问题。

Method: 采用逻辑、自动机和电路复杂性理论来分析transformer的能力边界，通过理论框架来理解transformer的表示和计算能力。

Result: 研究表明逻辑和自动机理论在理解transformer能力方面发挥着关键作用，为分析transformer的计算能力提供了理论基础。

Conclusion: transformer能力的研究仍处于早期阶段，逻辑、自动机、验证和transformer的交叉领域存在多个重要的开放性问题需要进一步探索。

Abstract: The advent of transformers has in recent years led to powerful and
revolutionary Large Language Models (LLMs). Despite this, our understanding on
the capability of transformers is still meager. In this invited contribution,
we recount the rapid progress in the last few years to the question of what
transformers can do. In particular, we will see the integral role of logic and
automata (also with some help from circuit complexity) in answering this
question. We also mention several open problems at the intersection of logic,
automata, verification and transformers.

</details>


### [6] [One-sided Hom shifts](https://arxiv.org/abs/2509.24754)
*Marie-Pierre Béal,Alexi Block Gorman*

Main category: cs.FL

TL;DR: 证明了有限型单边移位与Hom移位共轭的可判定性，以及有限型树移位与Hom树移位共轭的可判定性


<details>
  <summary>Details</summary>
Motivation: 研究移位系统之间的共轭关系，特别是有限型移位与Hom移位之间的等价性问题

Method: 使用Williams的单边移位理论作为证明工具

Result: 证明了有限型单边移位与Hom移位共轭的可判定性，以及有限型树移位与Hom树移位共轭的可判定性

Conclusion: 通过Williams理论成功建立了有限型移位与Hom移位之间共轭关系的可判定性

Abstract: We prove that it is decidable whether a one-sided shift of finite type is
conjugate to a one-sided Hom-shift, and whether a tree-shift of finite type is
conjugate to a Hom tree-shift. The proof uses Williams's theory for one-sided
shifts

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [A benchmark for vericoding: formally verified program synthesis](https://arxiv.org/abs/2509.22908)
*Sergiu Bursuc,Theodore Ehrenborg,Shaowei Lin,Lacramioara Astefanoaei,Ionel Emilian Chiosa,Jure Kukovec,Alok Singh,Oliver Butterley,Adem Bizid,Quinn Dougherty,Miranda Zhao,Max Tan,Max Tegmark*

Main category: cs.SE

TL;DR: 提出了目前最大的形式化验证代码生成基准测试，包含12,504个形式化规范，测试LLM从形式化规范生成已验证代码的能力。


<details>
  <summary>Details</summary>
Motivation: 对比验证编码（从形式化规范生成已验证代码）与氛围编码（从自然语言描述生成可能包含错误的代码），评估LLM在形式化验证代码生成方面的能力。

Method: 构建包含12,504个形式化规范的基准测试集，涵盖Dafny、Verus/Rust和Lean三种语言，其中6,174个是新问题。使用现成的LLM进行测试。

Result: 验证编码成功率：Lean为27%，Verus/Rust为44%，Dafny为82%。添加自然语言描述不会显著改善性能。过去一年中，纯Dafny验证的进展从68%提升到96%。

Conclusion: 验证编码在形式化验证代码生成方面表现出色，特别是在Dafny中，LLM的进展显著提升了验证能力。基准测试和结果已公开分享。

Abstract: We present and test the largest benchmark for vericoding, LLM-generation of
formally verified code from formal specifications - in contrast to vibe coding,
which generates potentially buggy code from a natural language description. Our
benchmark contains 12,504 formal specifications, with 3,029 in Dafny, 2,334 in
Verus/Rust and 7,141 in Lean. Of these, 6,174 are new unseen problems. We find
vericoding success rates of 27% in Lean, 44% in Verus/Rust and 82% in Dafny
using off-the-shelf LLMs. Adding natural-language descriptions does not
significantly improve performance. We also find that LLM progress has improved
progress on pure Dafny verification from 68% to 96% over the past year. The
benchmark and vericoding results are shared at
https://github.com/Beneficial-AI-Foundation/vericoding-benchmark

</details>


### [8] [Towards Human-interpretable Explanation in Code Clone Detection using LLM-based Post Hoc Explainer](https://arxiv.org/abs/2509.22978)
*Teeradaj Racharak,Chaiyong Ragkhitwetsagul,Chayanee Junplong,Akara Supratak*

Main category: cs.SE

TL;DR: 该论文提出了一种利用大型语言模型（如ChatGPT-4）作为后置解释器的方法，来解释基于机器学习的代码克隆检测器的预测结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于机器学习的代码克隆检测器虽然能准确识别语义克隆，但通常作为黑盒运行，缺乏对决策过程的解释。现有的后置解释技术要么需要白盒访问权限，要么计算成本高昂。

Method: 利用大型语言模型的上下文学习能力来解释GraphCodeBERT等代码克隆检测器的预测结果，通过降低温度参数来提高解释准确性。

Result: 该方法作为后置解释器表现良好，正确解释率达到98%，良好解释率达到95%。但LLM提供的解释和代码行示例在某些情况下才有用。

Conclusion: 这项研究为未来在各种软件工程任务中使用LLM作为后置解释器开辟了道路，并指出了需要进一步改进的方向。

Abstract: Recent studies highlight various machine learning (ML)-based techniques for
code clone detection, which can be integrated into developer tools such as
static code analysis. With the advancements brought by ML in code
understanding, ML-based code clone detectors could accurately identify and
classify cloned pairs, especially semantic clones, but often operate as black
boxes, providing little insight into the decision-making process. Post hoc
explainers, on the other hand, aim to interpret and explain the predictions of
these ML models after they are made, offering a way to understand the
underlying mechanisms driving the model's decisions. However, current post hoc
techniques require white-box access to the ML model or are computationally
expensive, indicating a need for advanced post hoc explainers. In this paper,
we propose a novel approach that leverages the in-context learning capabilities
of large language models to elucidate the predictions made by the ML-based code
clone detectors. We perform a study using ChatGPT-4 to explain the code clone
results inferred by GraphCodeBERT. We found that our approach is promising as a
post hoc explainer by giving the correct explanations up to 98% and offering
good explanations 95% of the time. However, the explanations and the code line
examples given by the LLM are useful in some cases. We also found that lowering
the temperature to zero helps increase the accuracy of the explanation. Lastly,
we list the insights that can lead to further improvements in future work. This
study paves the way for future studies in using LLMs as a post hoc explainer
for various software engineering tasks.

</details>


### [9] [Agentic Specification Generator for Move Programs](https://arxiv.org/abs/2509.24515)
*Yu-Fu Fu,Meng Xu,Taesoo Kim*

Main category: cs.SE

TL;DR: MSG是一个为Move智能合约设计的自动化规范生成工具，展示了LLM在非主流编程语言中的强大代码理解和生成能力，能够为84%的测试函数生成可验证规范，并识别专家遗漏的条款。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规范生成工具主要关注主流编程语言如C、Java和Solidity，而新兴且面向验证的语言如Move尚未得到充分探索，因此需要专门针对Move生态系统的规范生成工具。

Method: 采用基于代理的模块化设计，明确利用规范语言特性，并整合验证工具链的反馈机制。

Result: 成功为84%的测试Move函数生成可验证规范，识别出专家遗漏的条款，相比传统设计生成57%更多可验证条款，整合验证反馈后生成的可验证规范增加30%。

Conclusion: LLM在非主流语言中仍表现出强大的代码理解和生成能力，模块化设计和验证工具链反馈能显著提升规范生成质量，MSG为新兴语言生态系统提供了有效的规范生成解决方案。

Abstract: While LLM-based specification generation is gaining traction, existing tools
primarily focus on mainstream programming languages like C, Java, and even
Solidity, leaving emerging and yet verification-oriented languages like Move
underexplored. In this paper, we introduce MSG, an automated specification
generation tool designed for Move smart contracts. MSG aims to highlight key
insights that uniquely present when applying LLM-based specification generation
to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust
code comprehension and generation capabilities even for non-mainstream
languages. MSG successfully generates verifiable specifications for 84% of
tested Move functions and even identifies clauses previously overlooked by
experts. Additionally, MSG shows that explicitly leveraging specification
language features through an agentic, modular design improves specification
quality substantially (generating 57% more verifiable clauses than conventional
designs). Incorporating feedback from the verification toolchain further
enhances the effectiveness of MSG, leading to a 30% increase in generated
verifiable specifications.

</details>


### [10] [The Matthew Effect of AI Programming Assistants: A Hidden Bias in Software Evolution](https://arxiv.org/abs/2509.23261)
*Fei Gu,Zi Liang,Hongzong LI,Jiahao MA*

Main category: cs.SE

TL;DR: 研究发现AI辅助编程存在马太效应：编程语言或框架越流行，LLM生成代码的成功率越高，这可能会强化现有工具生态的集中化趋势。


<details>
  <summary>Details</summary>
Motivation: 探索AI辅助编程对软件工程迭代动态的广泛影响，特别是LLM驱动的开发如何与软件生态系统相互作用。

Method: 在数千个算法编程任务和数百个框架选择任务上进行大规模实验，系统研究AI辅助编程与软件生态系统的交互。

Result: 发现明显的马太效应：编程语言或框架越流行，LLM生成代码的成功率越高，AI系统可能强化现有流行度层级。

Conclusion: AI辅助编程可能加速向主导工具收敛，阻碍多样性和创新，这对编程生态系统的未来发展具有重要影响。

Abstract: AI-assisted programming is rapidly reshaping software development, with large
language models (LLMs) enabling new paradigms such as vibe coding and agentic
coding. While prior works have focused on prompt design and code generation
quality, the broader impact of LLM-driven development on the iterative dynamics
of software engineering remains underexplored. In this paper, we conduct
large-scale experiments on thousands of algorithmic programming tasks and
hundreds of framework selection tasks to systematically investigate how
AI-assisted programming interacts with the software ecosystem. Our analysis
reveals \textbf{a striking Matthew effect: the more popular a programming
language or framework, the higher the success rate of LLM-generated code}. The
phenomenon suggests that AI systems may reinforce existing popularity
hierarchies, accelerating convergence around dominant tools while hindering
diversity and innovation. We provide a quantitative characterization of this
effect and discuss its implications for the future evolution of programming
ecosystems.

</details>


### [11] [Code Arcades: 3d Visualization of Classes, Dependencies and Software Metrics](https://arxiv.org/abs/2509.23297)
*Anthony Savidis,Christos Vasilopoulos*

Main category: cs.SE

TL;DR: 论文提出了一种可配置的软件可视化方法，通过灵活分组机制、多粒度软件指标和交互式可视化引擎，提升源代码理解和分析能力。


<details>
  <summary>Details</summary>
Motivation: 软件可视化旨在通过图形化表示软件制品来增强对源代码的理解、分析和维护，但现有方法在灵活性和多层级视角方面存在不足。

Method: 引入可配置分组机制支持基于任意关系的代码元素组织；结合细粒度和粗粒度软件指标提供多层级系统属性视角；开发交互式可视化引擎支持动态调整渲染属性。

Result: 该方法提供了更适应和深入的源代码理解途径，能够识别结构模式、检测复杂性热点，并推断难以直接从源代码文本感知的系统行为。

Conclusion: 提出的三个创新点——可配置分组、多粒度指标和交互式可视化——共同构成了一个更灵活和富有洞察力的软件可视化框架，有助于大规模系统的理解和维护。

Abstract: Software visualization seeks to represent software artifacts graphical-ly in
two or three dimensions, with the goal of enhancing comprehension, anal-ysis,
maintenance, and evolution of the source code. In this context, visualiza-tions
employ graphical forms such as dependency structures, treemaps, or time-lines
that incorporate repository histories. These visualizations allow software
engineers to identify structural patterns, detect complexity hotspots, and
infer system behaviors that are difficult to perceive directly from source
text. By adopting metaphor-based approaches, visualization tools provide
macroscopic overviews while enabling focused inspection of specific program
elements, thus offering an accessible means of understanding large-scale
systems. The contri-bution of our work lies in three areas. First, we introduce
a configurable group-ing mechanism that supports flexible organization of code
elements based on arbitrary relationships. Second, we combine fine-grained and
coarse-grained software metrics to provide a multi-level perspective on system
properties. Third, we present an interactive visualization engine that allows
developers to dynamically adjust rendering attributes. Collectively, these
advances provide a more adaptable and insightful approach to source code
comprehension.

</details>


### [12] [Methods for evaluating software accessibility](https://arxiv.org/abs/2509.23469)
*Mykola Kuz,Ivan Yaremiy,Hanna Yaremii,Mykola Pikuliak,Ihor Lazarovych,Mykola Kozlenko,Denys Vekeryk*

Main category: cs.SE

TL;DR: 开发了基于分类和数学模型的软件可访问性评估方法，针对ISO/IEC 25023和WCAG标准，提出了比标准化方法更详细实用的可访问性评估方法，并在大学网站上进行了应用分析。


<details>
  <summary>Details</summary>
Motivation: 现有可访问性评估方法过于通用，未能考虑不同用户类别的具体需求及其与数字系统的独特交互方式，需要开发更详细的指标定义方法来评估软件交互质量。

Method: 构建分类和数学模型，开发基于此的软件可访问性评估方法，特别是针对"可用性"质量特征中的"可访问性"子特性进行评估。

Result: 成功分析了Vasyl Stefanyk Precarpathian国立大学网站主要页面对视觉障碍人士的可访问性，并提出了具体的改进建议。

Conclusion: 提出的方法比标准化方法更详细和实用，是创建包容性数字环境的关键步骤，能够为网站可访问性提供具体改进建议。

Abstract: The development and enhancement of methods for evaluating software
accessibility is a relevant challenge in modern software engineering, as
ensuring equal access to digital services is a key factor in improving their
efficiency and inclusivity. The increasing digitalization of society
necessitates the creation of software that complies with international
accessibility standards such as ISO/IEC 25023 and WCAG. Adhering to these
standards helps eliminate barriers to software use for individuals with diverse
physical, sensory, and cognitive needs. Despite advancements in regulatory
frameworks, existing accessibility evaluation methodologies are often
generalized and fail to account for the specific needs of different user
categories or the unique ways they interact with digital systems. This
highlights the need for the development of new, more detailed methods for
defining metrics that influence the quality of user interaction with software
products. Building a classification and mathematical model and developing
accessibility assessment methods for software based on it. A method for
assessing the quality subcharacteristic "Accessibility", which is part of the
"Usability" quality characteristic, has been developed. This enabled the
analysis of a website's inclusivity for individuals with visual impairments,
and the formulation of specific recommendations for further improvements, which
is a crucial step toward creating an inclusive digital environment. Comparing
to standardized approaches, a more detailed and practically oriented
accessibility assessment methodology has been proposed. Using this methodology,
an analysis of the accessibility of the main pages of Vasyl Stefanyk
Precarpathian National University's website was conducted, and improvements
were suggested to enhance its inclusivity.

</details>


### [13] [Improving the Efficiency of LLM Agent Systems through Trajectory Reduction](https://arxiv.org/abs/2509.23586)
*Yuan-An Xiao,Pengfei Gao,Chao Peng,Yingfei Xiong*

Main category: cs.SE

TL;DR: 提出AgentDiet方法，通过识别和移除多轮LLM代理系统中无用、冗余和过期的信息，显著减少输入令牌数量（39.9%~59.7%）和计算成本（21.1%~35.9%），同时保持代理性能不变。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多轮代理系统在软件工程任务中越来越流行，但随着轨迹不断增长导致输入令牌计算成本过高，效率问题被忽视。本文旨在解决代理系统的效率问题。

Method: 通过分析现有代理轨迹，发现无用、冗余和过期信息普遍存在，设计AgentDiet方法自动识别和移除这些浪费信息。

Result: 在两个LLM和两个基准测试上的评估显示，AgentDiet能减少39.9%~59.7%的输入令牌，或21.1%~35.9%的最终计算成本，同时保持代理性能不变。

Conclusion: 轨迹减少是代理系统一个有前景的研究方向，AgentDiet方法简单有效，能显著提升代理系统的效率。

Abstract: Multi-turn agent systems based on Large Language Models (LLMs) have been
increasingly popular for software engineering tasks. While LLM agents show
decent effectiveness, the high computational cost of input tokens due to the
ever-growing trajectory remains an efficiency concern for their applications.
Efficiency is largely neglected in existing studies and agent products, and
this paper fills the gap by introducing an inference-time trajectory reduction
approach to reduce the cost of agents.
  Through analyzing existing agent trajectories, we demonstrate that useless,
redundant, and expired information is widespread in all trajectories, which can
be identified and reduced without harming the agent's performance. We then
design a simple yet effective trajectory reduction approach, AgentDiet, which
automatically removes such waste information. We implement AgentDiet on a
top-performing coding agent, and the evaluation on two LLMs and two benchmarks
shows that AgentDiet can reduce input tokens by 39.9% ~ 59.7%, or the final
computational cost by 21.1% ~ 35.9%, while maintaining the same agent
performance. This indicates that trajectory reduction is a promising direction
for agent systems.

</details>


### [14] [Similarity-Based Assessment of Computational Reproducibility in Jupyter Notebooks](https://arxiv.org/abs/2509.23645)
*A S M Shahadat Hossain,Colin Brown,David Koop,Tanu Malik*

Main category: cs.SE

TL;DR: 提出基于相似度的可重现性指数(SRI)，用于评估Jupyter Notebook的计算可重现性。SRI使用针对不同Python对象类型的相似度度量来比较重新运行输出与原始输出，为每个生成输出的单元格提供定量评分和定性分析。


<details>
  <summary>Details</summary>
Motivation: Jupyter Notebook虽然便于运行和共享计算实验，但由于随机性、库版本变化或计算环境差异等因素，重新运行可能无法获得一致结果，因此需要一种评估计算可重现性的方法。

Method: 开发基于相似度度量的SRI指标，针对不同类型的Python对象使用专门的相似度计算方法，比较重新运行输出与原始输出，为每个单元格提供[0,1]范围的定量评分和定性分析。

Result: 通过案例研究展示了SRI在Jupyter Notebook集合中的应用，证明各种相似度度量可以有效量化计算可重现性。

Conclusion: SRI提供了一种系统化评估Jupyter Notebook计算可重现性的方法，能够识别和量化重新运行结果与原始结果之间的差异。

Abstract: Computational reproducibility refers to obtaining consistent results when
rerunning an experiment. Jupyter Notebook, a web-based computational notebook
application, facilitates running, publishing, and sharing computational
experiments along with their results. However, rerunning a Jupyter Notebook may
not always generate identical results due to various factors, such as
randomness, changes in library versions, or variations in the computational
environment. This paper introduces the Similarity-based Reproducibility Index
(SRI) -- a metric for assessing the reproducibility of results in Jupyter
Notebooks. SRI employs novel methods developed based on similarity metrics
specific to different types of Python objects to compare rerun outputs against
original outputs. For every cell generating an output in a rerun notebook, SRI
reports a quantitative score in the range [0, 1] as well as some qualitative
insights to assess reproducibility. The paper also includes a case study in
which the proposed metric is applied to a set of Jupyter Notebooks,
demonstrating how various similarity metrics can be leveraged to quantify
computational reproducibility.

</details>


### [15] [PAT-Agent: Autoformalization for Model Checking](https://arxiv.org/abs/2509.23675)
*Xinyue Zuo,Yifan Zhang,Hongshu Wang,Yufan Cai,Zhe Hou,Jing Sun,Jin Song Dong*

Main category: cs.SE

TL;DR: PAT-Agent是一个端到端框架，结合LLMs的生成能力和形式验证的严谨性，实现自然语言自动形式化和形式模型修复，帮助非专家用户构建可验证的形式模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自动化形式方法方面有潜力，但由于规范语言的复杂性、输出幻觉风险以及自然语言与形式逻辑之间的语义鸿沟，将其应用于形式验证仍具挑战性。

Method: 采用规划LLM提取关键建模元素并生成详细计划，然后指导代码生成LLM合成语法正确且语义忠实的正式模型，使用PAT模型检查器验证代码，并通过修复循环迭代修正模型。

Result: 在40个系统上的实验结果表明，PAT-Agent始终优于基线方法，实现了高验证成功率和卓越效率。消融研究确认了规划和修复组件的重要性。

Conclusion: PAT-Agent通过结合LLMs和形式验证，有效解决了自然语言自动形式化的挑战，用户研究表明该界面易于使用，即使对于形式方法经验有限的用户也能支持有效的形式建模。

Abstract: Recent advances in large language models (LLMs) offer promising potential for
automating formal methods. However, applying them to formal verification
remains challenging due to the complexity of specification languages, the risk
of hallucinated output, and the semantic gap between natural language and
formal logic. We introduce PAT-Agent, an end-to-end framework for natural
language autoformalization and formal model repair that combines the generative
capabilities of LLMs with the rigor of formal verification to automate the
construction of verifiable formal models. In PAT-Agent, a Planning LLM first
extracts key modeling elements and generates a detailed plan using semantic
prompts, which then guides a Code Generation LLM to synthesize syntactically
correct and semantically faithful formal models. The resulting code is verified
using the Process Analysis Toolkit (PAT) model checker against user-specified
properties, and when discrepancies occur, a Repair Loop is triggered to
iteratively correct the model using counterexamples. To improve flexibility, we
built a web-based interface that enables users, particularly non-FM-experts, to
describe, customize, and verify system behaviors through user-LLM interactions.
Experimental results on 40 systems show that PAT-Agent consistently outperforms
baselines, achieving high verification success with superior efficiency. The
ablation studies confirm the importance of both planning and repair components,
and the user study demonstrates that our interface is accessible and supports
effective formal modeling, even for users with limited formal methods
experience.

</details>


### [16] [Satellite: Detecting and Analyzing Smart Contract Vulnerabilities caused by Subcontract Misuse](https://arxiv.org/abs/2509.23679)
*Zeqin Liao,Yuhong Nan,Zixu Gao,Henglong Liang,Sicheng Hao,Jiajing Wu,Zibin Zheng*

Main category: cs.SE

TL;DR: Satellite是一个用于检测智能合约中子合约误用漏洞的字节码级静态分析框架，通过迁移学习恢复继承方法，进行细粒度方法级比较，能够有效识别SMV漏洞。


<details>
  <summary>Details</summary>
Motivation: 智能合约开发者普遍重用子合约以提高开发效率，但这种重用可能会意外引入漏洞。由于智能合约通常编译为字节码，类级信息和语义被完全模糊化，自动检测这类问题面临独特挑战。

Method: Satellite采用迁移学习方法恢复继承方法，提取细粒度方法级特征并进行方法级比较，识别子合约的重用部分，根据SMV类型总结漏洞指标。

Result: 在包含58个真实攻击SMV和56个SOTA研究SMV模式的数据集上，Satellite表现出良好性能，精确率达到84.68%，召回率达到92.11%。在10,011个真实智能合约中成功识别14个新的未知SMV，影响总价值201,358美元的数字资产。

Conclusion: Satellite是一个有效的字节码级静态分析框架，能够成功检测智能合约中的子合约误用漏洞，在真实场景中表现出良好的检测能力。

Abstract: Developers of smart contracts pervasively reuse subcontracts to improve
development efficiency. Like any program language, such subcontract reuse may
unexpectedly include, or introduce vulnerabilities to the end-point smart
contract. Unfortunately, automatically detecting such issues poses several
unique challenges. Particularly, in most cases, smart contracts are compiled as
bytecode, whose class-level information (e.g., inheritance, virtual function
table), and even semantics (e.g., control flow and data flow) are fully
obscured as a single smart contract after compilation.
  In this paper, we propose Satellite, a new bytecode-level static analysis
framework for subcontract misuse vulnerability (SMV) detection in smart
contracts. Satellite incorporates a series of novel designs to enhance its
overall effectiveness.. Particularly, Satellite utilizes a transfer learning
method to recover the inherited methods, which are critical for identifying
subcontract reuse in smart contracts. Further, Satellite extracts a set of
fine-grained method-level features and performs a method-level comparison, for
identifying the reuse part of subcontract in smart contracts. Finally,
Satellite summarizes a set of SMV indicators according to their types, and
hence effectively identifies SMVs. To evaluate Satellite, we construct a
dataset consisting of 58 SMVs derived from real-world attacks and collect
additional 56 SMV patterns from SOTA studies. Experiment results indicate that
Satellite exhibits good performance in identifying SMV, with a precision rate
of 84.68% and a recall rate of 92.11%. In addition, Satellite successfully
identifies 14 new/unknown SMV over 10,011 real-world smart contracts, affecting
a total amount of digital assets worth 201,358 USD.

</details>


### [17] [Influence-Guided Concolic Testing of Transformer Robustness](https://arxiv.org/abs/2509.23806)
*Chih-Duo Hong,Yu Wang,Yao-Chen Chang,Fang Yu*

Main category: cs.SE

TL;DR: 提出了一种基于影响力引导的concolic测试方法，用于Transformer分类器，通过SHAP估计路径谓词对模型输出的影响来指导搜索，并实现了支持现代架构的SMT求解器兼容语义。


<details>
  <summary>Details</summary>
Motivation: 传统concolic测试在深度神经网络中交替进行具体执行和约束求解，但需要更有效的搜索策略来处理Transformer模型的复杂性。

Method: 使用SHAP-based影响力估计对路径谓词进行排序，开发了纯Python的多头自注意力语义以支持SMT求解，并引入轻量级调度启发式方法来控制约束增长。

Result: 在紧凑型Transformer上的白盒研究中，影响力引导方法比FIFO基线更高效地找到标签翻转输入，并在深层网络中保持稳定进展。通过SHAP-based关键决策路径分析揭示了跨攻击共享的紧凑决策逻辑。

Conclusion: 影响力信号为符号探索提供了有用的搜索偏置，求解器友好的注意力语义与轻量级调度相结合，使concolic测试对当代Transformer模型变得可行，具有调试和模型审计的潜在价值。

Abstract: Concolic testing for deep neural networks alternates concrete execution with
constraint solving to search for inputs that flip decisions. We present an
{influence-guided} concolic tester for Transformer classifiers that ranks path
predicates by SHAP-based estimates of their impact on the model output. To
enable SMT solving on modern architectures, we prototype a solver-compatible,
pure-Python semantics for multi-head self-attention and introduce practical
scheduling heuristics that temper constraint growth on deeper models. In a
white-box study on compact Transformers under small $L_0$ budgets, influence
guidance finds label-flip inputs more efficiently than a FIFO baseline and
maintains steady progress on deeper networks. Aggregating successful attack
instances with a SHAP-based critical decision path analysis reveals recurring,
compact decision logic shared across attacks. These observations suggest that
(i) influence signals provide a useful search bias for symbolic exploration,
and (ii) solver-friendly attention semantics paired with lightweight scheduling
make concolic testing feasible for contemporary Transformer models, offering
potential utility for debugging and model auditing.

</details>


### [18] [Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models](https://arxiv.org/abs/2509.23812)
*Dianshu Liao,Xin Yin,Shidong Pan,Chao Ni,Zhenchang Xing,Xiaoyu Sun*

Main category: cs.SE

TL;DR: 提出了一个路径敏感的单元测试生成框架JUnitGenie，结合代码知识和LLM语义能力，相比现有方法显著提高了分支和行覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有单元测试生成方法存在路径不敏感问题，无法处理深层控制流结构，导致覆盖率不足。需要结合代码知识和LLM能力来改进测试生成。

Method: 从Java项目中提取代码知识，将其转化为结构化提示来指导LLM生成高覆盖率的单元测试。

Result: 在10个真实Java项目的2,258个复杂方法上评估，JUnitGenie相比启发式和LLM基线方法，分支和行覆盖率分别平均提高29.60%和31.00%，并能发现真实bug。

Conclusion: JUnitGenie通过路径敏感的方法有效提升了单元测试生成的质量和覆盖率，证明了结合代码知识与LLM语义能力的有效性。

Abstract: Unit testing is essential for software quality assurance, yet writing and
maintaining tests remains time-consuming and error-prone. To address this
challenge, researchers have proposed various techniques for automating unit
test generation, including traditional heuristic-based methods and more recent
approaches that leverage large language models (LLMs). However, these existing
approaches are inherently path-insensitive because they rely on fixed
heuristics or limited contextual information and fail to reason about deep
control-flow structures. As a result, they often struggle to achieve adequate
coverage, particularly for deep or complex execution paths. In this work, we
present a path-sensitive framework, JUnitGenie, to fill this gap by combining
code knowledge with the semantic capabilities of LLMs in guiding context-aware
unit test generation. After extracting code knowledge from Java projects,
JUnitGenie distills this knowledge into structured prompts to guide the
generation of high-coverage unit tests. We evaluate JUnitGenie on 2,258 complex
focal methods from ten real-world Java projects. The results show that
JUnitGenie generates valid tests and improves branch and line coverage by
29.60% and 31.00% on average over both heuristic and LLM-based baselines. We
further demonstrate that the generated test cases can uncover real-world bugs,
which were later confirmed and fixed by developers.

</details>


### [19] [SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation](https://arxiv.org/abs/2509.23824)
*Zhifan Ye,Jiachi Chen,Zhenzhe Shao,Lingfeng Bao,Xiaohu Yang,Zhongxin Liu*

Main category: cs.SE

TL;DR: SolContractEval是首个Solidity智能合约级别的代码生成基准测试，包含124个真实链上合约任务，通过动态交易重放评估6个主流LLM，发现Claude-3.7-Sonnet表现最佳但整体仍落后于通用编程语言。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估主要关注孤立函数和合成输入，无法评估真实世界合约开发能力，且Solidity在LLM训练数据中占比小，具有版本敏感语法和有限灵活性，需要专门的评估基准。

Method: 构建SolContractEval基准，包含124个来自真实链上合约的任务，涵盖9个主要领域，每个任务包含完整上下文依赖、结构化合约框架和简洁任务提示，由经验开发者独立标注和交叉验证，并开发基于历史交易重放的动态评估框架。

Result: Claude-3.7-Sonnet表现最佳，但所有模型在类级生成任务上表现不如通用编程语言；模型在标准模式任务上表现更好，但在复杂逻辑和跨合约依赖方面表现较差；对Solidity特定特性和上下文依赖理解有限。

Conclusion: 需要专门针对Solidity的LLM优化，当前模型在真实世界智能合约生成方面仍有显著局限性，特别是在处理复杂逻辑和跨合约依赖方面。

Abstract: The rise of blockchain has brought smart contracts into mainstream use,
creating a demand for smart contract generation tools. While large language
models (LLMs) excel at generating code in general-purpose languages, their
effectiveness on Solidity, the primary language for smart contracts, remains
underexplored. Solidity constitutes only a small portion of typical LLM
training data and differs from general-purpose languages in its
version-sensitive syntax and limited flexibility. These factors raise concerns
about the reliability of existing LLMs for Solidity code generation.
Critically, existing evaluations, focused on isolated functions and synthetic
inputs, fall short of assessing models' capabilities in real-world contract
development.
  To bridge this gap, we introduce SolContractEval, the first contract-level
benchmark for Solidity code generation. It comprises 124 tasks drawn from real
on-chain contracts across nine major domains. Each task input, consisting of
complete context dependencies, a structured contract framework, and a concise
task prompt, is independently annotated and cross-validated by experienced
developers. To enable precise and automated evaluation of functional
correctness, we also develop a dynamic evaluation framework based on historical
transaction replay. Building on SolContractEval, we perform a systematic
evaluation of six mainstream LLMs. We find that Claude-3.7-Sonnet achieves the
highest overall performance, though evaluated models underperform relative to
their capabilities on class-level generation tasks in general-purpose
programming languages. Second, current models perform better on tasks that
follow standard patterns but struggle with complex logic and inter-contract
dependencies. Finally, they exhibit limited understanding of Solidity-specific
features and contextual dependencies.

</details>


### [20] [HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-based Fuzzing](https://arxiv.org/abs/2509.23835)
*Yukai Zhao,Menghan Wu,Xing Hu,Xin Xia*

Main category: cs.SE

TL;DR: HFUZZER是一个基于短语的模糊测试框架，用于检测LLM在代码生成中的包幻觉问题，能比传统方法发现更多独特的幻觉包。


<details>
  <summary>Details</summary>
Motivation: LLM在代码生成中面临包幻觉的安全风险，可能被恶意利用进行软件供应链攻击，需要专门的测试方法来检测和防御这种风险。

Method: 采用基于短语的模糊测试技术，从包信息或编码任务中提取短语，引导模型生成更多样化的编码任务，从而提高测试覆盖率和相关性。

Result: 在所有测试的LLM中都触发了包幻觉，相比变异模糊测试框架，发现了2.60倍更多的独特幻觉包，在GPT-4o中发现了46个独特幻觉包。

Conclusion: LLM不仅在代码生成中存在包幻觉，在环境配置辅助时也会出现，HFUZZER能有效检测这类安全问题。

Abstract: Large Language Models (LLMs) are widely used for code generation, but they
face critical security risks when applied to practical production due to
package hallucinations, in which LLMs recommend non-existent packages. These
hallucinations can be exploited in software supply chain attacks, where
malicious attackers exploit them to register harmful packages. It is critical
to test LLMs for package hallucinations to mitigate package hallucinations and
defend against potential attacks. Although researchers have proposed testing
frameworks for fact-conflicting hallucinations in natural language generation,
there is a lack of research on package hallucinations. To fill this gap, we
propose HFUZZER, a novel phrase-based fuzzing framework to test LLMs for
package hallucinations. HFUZZER adopts fuzzing technology and guides the model
to infer a wider range of reasonable information based on phrases, thereby
generating enough and diverse coding tasks. Furthermore, HFUZZER extracts
phrases from package information or coding tasks to ensure the relevance of
phrases and code, thereby improving the relevance of generated tasks and code.
We evaluate HFUZZER on multiple LLMs and find that it triggers package
hallucinations across all selected models. Compared to the mutational fuzzing
framework, HFUZZER identifies 2.60x more unique hallucinated packages and
generates more diverse tasks. Additionally, when testing the model GPT-4o,
HFUZZER finds 46 unique hallucinated packages. Further analysis reveals that
for GPT-4o, LLMs exhibit package hallucinations not only during code generation
but also when assisting with environment configuration.

</details>


### [21] [Learning-Based Testing for Deep Learning: Enhancing Model Robustness with Adversarial Input Prioritization](https://arxiv.org/abs/2509.23961)
*Sheikh Md Mushfiqur Rahman,Nasir Eisty*

Main category: cs.SE

TL;DR: 提出了一种结合学习型测试与假设和变异测试的方法，用于优先处理深度神经网络中的对抗性测试用例，以提高故障检测效率和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于覆盖率或置信度的测试优先级方法在有效识别最具故障揭示能力的输入方面存在不足，限制了其在关键应用中的实际效果。

Method: 选择具有高故障暴露可能性的对抗性输入子集，不依赖特定架构特征或形式验证，使其能够适应各种深度神经网络。

Result: 所提出的LBT方法在优先处理故障揭示输入和加速故障检测方面持续优于基线方法，能显著更快地发现所有潜在故障。

Conclusion: 该方法不仅提高了故障检测能力，还保持了输入多样性并为模型重新训练提供有效指导，进一步增强了鲁棒性，成为现实应用中对抗性测试优先级的有力实用解决方案。

Abstract: Context: Deep Neural Networks (DNNs) are increasingly deployed in critical
applications, where resilience against adversarial inputs is paramount.
However, whether coverage-based or confidence-based, existing test
prioritization methods often fail to efficiently identify the most
fault-revealing inputs, limiting their practical effectiveness. Aims: This
project aims to enhance fault detection and model robustness in DNNs by
integrating Learning-Based Testing (LBT) with hypothesis and mutation testing
to efficiently prioritize adversarial test cases. Methods: Our method selects a
subset of adversarial inputs with a high likelihood of exposing model faults,
without relying on architecture-specific characteristics or formal
verification, making it adaptable across diverse DNNs. Results: Our results
demonstrate that the proposed LBT method consistently surpasses baseline
approaches in prioritizing fault-revealing inputs and accelerating fault
detection. By efficiently organizing test permutations, it uncovers all
potential faults significantly faster across various datasets, model
architectures, and adversarial attack techniques. Conclusion: Beyond improving
fault detection, our method preserves input diversity and provides effective
guidance for model retraining, further enhancing robustness. These advantages
establish our approach as a powerful and practical solution for adversarial
test prioritization in real-world DNN applications.

</details>


### [22] [SandCell: Sandboxing Rust Beyond Unsafe Code](https://arxiv.org/abs/2509.24032)
*Jialun Zhang,Merve Gülmez,Thomas Nyman,Gang Tan*

Main category: cs.SE

TL;DR: SandCell是一个在Rust中实现灵活轻量级隔离的系统，利用现有语法边界来沙箱化组件，最小化注解工作量，并提供高效的数据传输技术。


<details>
  <summary>Details</summary>
Motivation: Rust通过unsafe关键字绕过内存安全限制会引入风险，现有隔离方法边界固定，无法支持需要同时沙箱化安全和不安全代码的表达性策略。

Method: 利用现有语法边界，允许程序员以最小注解工作量指定要沙箱化的组件，实现细粒度隔离控制，并引入新技术最小化沙箱间数据传输开销。

Result: 评估显示SandCell能有效防止各种Rust应用中的漏洞，同时保持合理的性能开销。

Conclusion: SandCell为Rust提供了灵活轻量的隔离机制，能够保护安全代码免受不安全代码漏洞的影响。

Abstract: Rust is a modern systems programming language that ensures memory safety by
enforcing ownership and borrowing rules at compile time. While the unsafe
keyword allows programmers to bypass these restrictions, it introduces
significant risks. Various approaches for isolating unsafe code to protect safe
Rust from vulnerabilities have been proposed, yet these methods provide only
fixed isolation boundaries and do not accommodate expressive policies that
require sandboxing both safe and unsafe code. This paper presents SandCell for
flexible and lightweight isolation in Rust by leveraging existing syntactic
boundaries. SandCell allows programmers to specify which components to sandbox
with minimal annotation effort, enabling fine-grained control over isolation.
The system also introduces novel techniques to minimize overhead when
transferring data between sandboxes. Our evaluation demonstrates SandCell's
effectiveness in preventing vulnerabilities across various Rust applications
while maintaining reasonable performance overheads.

</details>


### [23] [PerfBench: Can Agents Resolve Real-World Performance Bugs?](https://arxiv.org/abs/2509.24091)
*Spandan Garg,Roshanak Zilouchian Moghaddam*

Main category: cs.SE

TL;DR: PerfBench是一个包含81个真实世界性能bug修复任务的基准测试，用于评估软件工程代理在修复非功能性性能问题方面的能力，填补了现有基准测试主要关注功能正确性的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注功能正确性，无法评估代理在识别和解决非功能性性能问题方面的能力，而性能bug难以检测和修复，需要专门的评估方法。

Method: 开发了PerfBench基准测试，包含从GitHub上流行的.NET仓库中提取的81个真实性能bug修复任务，采用新颖的评估框架让代理生成自己的性能基准测试，并通过比较开发者和代理修复的执行指标来验证修复效果。

Result: 当前最先进的编码代理在性能优化任务上表现不佳，基线OpenHands代理成功率仅为约3%。开发的OpenHands-Perf-Agent通过集成性能感知工具和指令，将成功率提升至约20%。

Conclusion: 通过为代理提供适当的基准测试指令和工具，可以显著提高其性能修复能力，但仍需进一步改进。PerfBench为推进代理在修复性能问题方面的能力提供了具有挑战性的测试集。

Abstract: Performance bugs are inefficiencies in software that waste computational
resources without causing functional failures, making them particularly
challenging to detect and fix. While recent advances in Software Engineering
agents have shown promise in automated bug fixing, existing benchmarks
primarily focus on functional correctness and fail to evaluate agents'
abilities to identify and resolve non-functional issues like performance bugs.
We introduce PerfBench, a benchmark comprising 81 real-world performance
bug-fixing tasks from popular .NET repositories on GitHub. Unlike existing
benchmarks that rely on pre-existing test suites, PerfBench features a novel
evaluation harness that allows agents to generate their own performance
benchmarks and validates fixes by comparing execution metrics collected for
developer fix and agent fix. Each task in PerfBench is derived from actual
developer fixes linked to performance-related issues, which are then verified
by human experts, ensuring real-world relevance. Our evaluation reveals that
current state-of-the-art coding agents struggle with performance optimization
tasks, with baseline OpenHands agent achieving only a ~3% success rate on our
benchmark. We develop OpenHands-Perf-Agent, which incorporates
performance-aware tooling and instructions and achieves a ~20% success rate on
the benchmark. We show that by ensuring the agent has proper instructions to
benchmark its changes and tooling for benchmark output processing, we can
improve the agent performance significantly, but room for improvement still
remains. PerfBench provides a challenging test set for furthering the
capabilities of agents in fixing performance issues.

</details>


### [24] [TENET: Leveraging Tests Beyond Validation for Code Generation](https://arxiv.org/abs/2509.24148)
*Yiran Hu,Nan Jiang,Shanchao Liang,Yi Wu,Lin Tan*

Main category: cs.SE

TL;DR: TENET是一个在TDD环境下为复杂真实仓库生成函数的LLM代理，通过测试套件选择、代码检索和基于反馈的迭代优化，显著提升了代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 在vibe coding时代，开发者越来越多地通过指定高层意图将代码编写委托给大语言模型，TDD变得更为重要，因为测试用例作为可执行规范，能明确定义和验证预期功能。但面临测试套件选择、上下文检索和测试反馈利用三大挑战。

Method: TENET包含三个组件：(1)新颖的测试工具机制，选择简洁测试套件以最大化目标使用场景的多样性；(2)定制的代理工具集，执行高效的相关代码检索和交互式调试；(3)基于反思的优化工作流，迭代分析失败、补充上下文并应用代码优化。

Result: TENET在RepoCod和RepoEval基准测试上分别达到69.08%和81.77%的Pass@1，比最佳代理基线分别高出9.49和2.17个百分点。

Conclusion: 这是首个在仓库级上下文下研究测试驱动代码生成的工作，检验了测试套件的不同方面如何影响TDD设置下LLM代理的性能。

Abstract: Test-Driven Development (TDD) is a widely adopted software engineering
practice that requires developers to create and execute tests alongside code
implementation, ensuring that software behavior is continuously validated and
refined. In the era of vibe coding, where developers increasingly delegate code
writing to large language models (LLMs) by specifying high-level intentions,
TDD becomes even more crucial, as test cases serve as executable specifications
that explicitly define and verify intended functionality beyond what
natural-language descriptions and code context can convey. While vibe coding
under TDD is promising, there are three main challenges: (1) selecting a small
yet effective test suite to improve the generation accuracy and control the
execution workload, (2) retrieving context such as relevant code effectively,
and (3) systematically using test feedback for effective code refinement. To
address these challenges, we introduce TENET, an LLM agent for generating
functions in complex real-world repositories under the TDD setting. TENET
features three components: (1) a novel test harness mechanism that selects a
concise test suite to maximize diversity of target usage scenarios; (2) a
tailored agent toolset that performs efficient retrieval of relevant code with
interactive debugging; and (3) a reflection-based refinement workflow that
iteratively analyzes failures, replenishes context, and applies code
refinement. TENET achieves 69.08% and 81.77% Pass@1 on RepoCod and RepoEval
benchmarks, outperforming the best agentic baselines by 9.49 and 2.17
percentage points, respectively. In addition, this is the first study of
test-driven code generation with repository-level context, examining how
different aspects of test suites affect the performance of LLM agents under the
TDD setting.

</details>


### [25] [Metamorphic Testing for Audio Content Moderation Software](https://arxiv.org/abs/2509.24215)
*Wenxuan Wang,Yongjiang Wu,Junyuan Zhang,Shuqing Li,Yun Peng,Wenting Chen,Shuai Wang,Michael R. Lyu*

Main category: cs.SE

TL;DR: 提出了MTAM，一种用于音频内容审核软件的蜕变测试框架，通过定义14种蜕变关系生成能绕过检测的有害音频测试用例，在商业和学术模型测试中发现了显著错误率。


<details>
  <summary>Details</summary>
Motivation: 音频平台被滥用于传播有害内容，现有审核工具容易被恶意行为者通过轻微修改音频（如改变音调、插入噪音）绕过，且对抗性输入的防御效果研究不足。

Method: MTAM框架定义了14种蜕变关系（音频特征型和启发式扰动），应用于有害音频内容生成测试用例，这些测试用例保持有害性但更可能逃避检测。

Result: 测试5个商业文本内容审核软件和1个学术模型，MTAM在Gladia、Assembly AI、Baidu、Nextdata、Tencent上的错误发现率分别达到38.6%、18.3%、35.1%、16.7%、51.1%，在学术模型上达到45.7%。

Conclusion: MTAM能有效发现音频内容审核软件的漏洞，现有审核系统在面对经过微妙修改的有害音频时存在显著安全风险。

Abstract: The rapid growth of audio-centric platforms and applications such as WhatsApp
and Twitter has transformed the way people communicate and share audio content
in modern society. However, these platforms are increasingly misused to
disseminate harmful audio content, such as hate speech, deceptive
advertisements, and explicit material, which can have significant negative
consequences (e.g., detrimental effects on mental health). In response,
researchers and practitioners have been actively developing and deploying audio
content moderation tools to tackle this issue. Despite these efforts, malicious
actors can bypass moderation systems by making subtle alterations to audio
content, such as modifying pitch or inserting noise. Moreover, the
effectiveness of modern audio moderation tools against such adversarial inputs
remains insufficiently studied. To address these challenges, we propose MTAM, a
Metamorphic Testing framework for Audio content Moderation software.
Specifically, we conduct a pilot study on 2000 audio clips and define 14
metamorphic relations across two perturbation categories: Audio Features-Based
and Heuristic perturbations. MTAM applies these metamorphic relations to toxic
audio content to generate test cases that remain harmful while being more
likely to evade detection. In our evaluation, we employ MTAM to test five
commercial textual content moderation software and an academic model against
three kinds of toxic content. The results show that MTAM achieves up to 38.6%,
18.3%, 35.1%, 16.7%, and 51.1% error finding rates (EFR) when testing
commercial moderation software provided by Gladia, Assembly AI, Baidu,
Nextdata, and Tencent, respectively, and it obtains up to 45.7% EFR when
testing the state-of-the-art algorithms from the academy.

</details>


### [26] [Comparing Open-Source and Commercial LLMs for Domain-Specific Analysis and Reporting: Software Engineering Challenges and Design Trade-offs](https://arxiv.org/abs/2509.24344)
*Theo Koraag,Niklas Wagner,Felix Dobslaw,Lucas Gren*

Main category: cs.SE

TL;DR: 本研究探索了开源和商业LLMs在财务报告分析和评论生成中的应用，通过设计科学研究方法开发了两个系统，发现LLMs在财务报告自动化方面具有强大潜力，但集成面临显著挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在复杂自然语言处理方面实现了自动化，但在金融等特定领域的研究仍然有限，本研究旨在探索LLMs在财务报告分析中的实际应用。

Method: 采用设计科学研究方法，通过迭代设计评估了两个LLM系统：一个使用本地开源模型的多智能体工作流，另一个使用商业GPT-4o模型，并通过专家评估进行验证。

Result: LLMs在财务报告任务自动化方面表现出强大潜力，但集成面临重大挑战。云模型提供更好的流畅性和可用性但存在数据隐私问题，本地开源模型提供更好的数据控制但需要更多工程努力。

Conclusion: LLMs在财务报告自动化方面具有强大潜力，但成功集成需要仔细关注架构、提示设计和系统可靠性，通过定制验证机制和工程策略来平衡准确性、控制和合规性。

Abstract: Context: Large Language Models (LLMs) enable automation of complex natural
language processing across domains, but research on domain-specific
applications like Finance remains limited. Objectives: This study explored
open-source and commercial LLMs for financial report analysis and commentary
generation, focusing on software engineering challenges in implementation.
Methods: Using Design Science Research methodology, an exploratory case study
iteratively designed and evaluated two LLM-based systems: one with local
open-source models in a multi-agent workflow, another using commercial GPT-4o.
Both were assessed through expert evaluation of real-world financial reporting
use cases. Results: LLMs demonstrated strong potential for automating financial
reporting tasks, but integration presented significant challenges. Iterative
development revealed issues including prompt design, contextual dependency, and
implementation trade-offs. Cloud-based models offered superior fluency and
usability but raised data privacy and external dependency concerns. Local
open-source models provided better data control and compliance but required
substantially more engineering effort for reliability and usability.
Conclusion: LLMs show strong potential for financial reporting automation, but
successful integration requires careful attention to architecture, prompt
design, and system reliability. Implementation success depends on addressing
domain-specific challenges through tailored validation mechanisms and
engineering strategies that balance accuracy, control, and compliance.

</details>


### [27] [Efficient Decomposition Identification of Deterministic Finite Automata from Examples](https://arxiv.org/abs/2509.24347)
*Junjie Meng,Jie An,Yong Li,Andrea Turrini,Fanjiang Xu,Naijun Zhan,Miaomiao Zhang*

Main category: cs.SE

TL;DR: 提出了基于3值DFA的DFA分解识别新框架，替代传统的APTA方法，显著提升了Pareto最优和状态最优DFA分解问题的求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统DFA学习方法产生的大型单一DFA缺乏简洁性和互操作性，现有DFA分解方法基于APTA的SAT编码存在可扩展性限制。

Method: 使用3值DFA直接从未标记示例中推导，替代冗余的APTA，改进SAT编码以减少变量数量。

Result: 实验结果表明，基于3DFA的方法在Pareto最优DFA分解上获得显著效率提升，并为状态最优DFA分解提供了可扩展解决方案。

Conclusion: 3DFA框架有效解决了DFA分解识别中的可扩展性问题，为复杂系统行为的模块化建模提供了高效工具。

Abstract: The identification of deterministic finite automata (DFAs) from labeled
examples is a cornerstone of automata learning, yet traditional methods focus
on learning monolithic DFAs, which often yield a large DFA lacking simplicity
and interoperability. Recent work addresses these limitations by exploring DFA
decomposition identification problems (DFA-DIPs), which model system behavior
as intersections of multiple DFAs, offering modularity for complex tasks.
However, existing DFA-DIP approaches depend on SAT encodings derived from
Augmented Prefix Tree Acceptors (APTAs), incurring scalability limitations due
to their inherent redundancy.
  In this work, we advance DFA-DIP research through studying two variants: the
traditional Pareto-optimal DIP and the novel states-optimal DIP, which
prioritizes a minimal number of states. We propose a novel framework that
bridges DFA decomposition with recent advancements in automata representation.
One of our key innovations replaces APTA with 3-valued DFA (3DFA) derived
directly from labeled examples. This compact representation eliminates
redundancies of APTA, thus drastically reducing variables in the improved SAT
encoding. Experimental results demonstrate that our 3DFA-based approach
achieves significant efficiency gains for the Pareto-optimal DIP while enabling
a scalable solution for the states-optimal DIP.

</details>


### [28] [Walk the Talk: Is Your Log-based Software Reliability Maintenance System Really Reliable?](https://arxiv.org/abs/2509.24352)
*Minghua He,Tong Jia,Chiming Duan,Pei Xiao,Lingzhe Zhang,Kangjin Wang,Yifan Wu,Ying Li,Gang Huang*

Main category: cs.SE

TL;DR: 提出FaithLog系统，通过因果引导注意力机制和对抗一致性学习，解决现有日志异常检测方法缺乏可解释性的问题，提升诊断可信度。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的日志异常检测方法缺乏可解释性，导致服务提供商无法理解检测过程，阻碍在实际生产环境中的部署和信任。

Method: 设计因果引导注意力机制和对抗一致性学习，提出FaithLog系统来确保异常检测的诊断可信度。

Result: 在两个公共数据集和一个工业数据集上的评估表明，该方法在诊断可信度方面达到了最先进的性能。

Conclusion: FaithLog系统通过提升诊断可信度，解决了日志异常检测方法的可解释性问题，有助于在实际生产环境中获得服务提供商的信任和部署。

Abstract: Log-based software reliability maintenance systems are crucial for sustaining
stable customer experience. However, existing deep learning-based methods
represent a black box for service providers, making it impossible for providers
to understand how these methods detect anomalies, thereby hindering trust and
deployment in real production environments. To address this issue, this paper
defines a trustworthiness metric, diagnostic faithfulness, for models to gain
service providers' trust, based on surveys of SREs at a major cloud provider.
We design two evaluation tasks: attention-based root cause localization and
event perturbation. Empirical studies demonstrate that existing methods perform
poorly in diagnostic faithfulness. Consequently, we propose FaithLog, a
faithful log-based anomaly detection system, which achieves faithfulness
through a carefully designed causality-guided attention mechanism and
adversarial consistency learning. Evaluation results on two public datasets and
one industrial dataset demonstrate that the proposed method achieves
state-of-the-art performance in diagnostic faithfulness.

</details>


### [29] [United We Stand: Towards End-to-End Log-based Fault Diagnosis via Interactive Multi-Task Learning](https://arxiv.org/abs/2509.24364)
*Minghua He,Chiming Duan,Pei Xiao,Tong Jia,Siyu Yu,Lingzhe Zhang,Weijie Hong,Jin Han,Yifan Wu,Ying Li,Gang Huang*

Main category: cs.SE

TL;DR: 提出Chimera方法，通过异常检测和根因定位之间的双向交互与知识转移，实现端到端的日志故障诊断。


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法采用任务独立方式，无法在数据形式和诊断目标上连接异常检测与根因定位，导致诊断偏差累积、依赖昂贵监控数据、忽视任务协作关系三大问题。

Method: 基于交互式多任务学习，在数据、特征和诊断结果三个层面精心设计异常检测与根因定位的交互策略，在统一端到端框架内实现两个子任务的交互。

Result: 在两个公共数据集和一个工业数据集上的评估显示，Chimera在异常检测和根因定位上均优于现有方法，分别提升2.92%-5.00%和19.01%-37.09%，并已成功部署到工业云平台。

Conclusion: Chimera通过双向交互和知识转移实现了端到端故障诊断，解决了现有方法的局限性，在实际工业环境中验证了其有效性。

Abstract: Log-based fault diagnosis is essential for maintaining software system
availability. However, existing fault diagnosis methods are built using a
task-independent manner, which fails to bridge the gap between anomaly
detection and root cause localization in terms of data form and diagnostic
objectives, resulting in three major issues: 1) Diagnostic bias accumulates in
the system; 2) System deployment relies on expensive monitoring data; 3) The
collaborative relationship between diagnostic tasks is overlooked. Facing this
problems, we propose a novel end-to-end log-based fault diagnosis method,
Chimera, whose key idea is to achieve end-to-end fault diagnosis through
bidirectional interaction and knowledge transfer between anomaly detection and
root cause localization. Chimera is based on interactive multi-task learning,
carefully designing interaction strategies between anomaly detection and root
cause localization at the data, feature, and diagnostic result levels, thereby
achieving both sub-tasks interactively within a unified end-to-end framework.
Evaluation on two public datasets and one industrial dataset shows that Chimera
outperforms existing methods in both anomaly detection and root cause
localization, achieving improvements of over 2.92% - 5.00% and 19.01% - 37.09%,
respectively. It has been successfully deployed in production, serving an
industrial cloud platform.

</details>


### [30] [Agentic Services Computing](https://arxiv.org/abs/2509.24380)
*Shuiguang Deng,Hailiang Zhao,Ziqi Wang,Guanjie Cheng,Peng Chen,Wenzhuo Qian,Zhiwei Ling,Jianwei Yin,Albert Y. Zomaya,Schahram Dustdar*

Main category: cs.SE

TL;DR: 本文提出了Agentic Service Computing（ASC）新范式，将服务重新构想为智能、自适应、社会嵌入的实体，并构建了基于生命周期的框架和四个核心研究维度。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的智能代理正在推动服务计算从静态请求-响应功能向动态、目标导向、自主的多代理生态系统转型，需要新的计算范式来适应这一变革。

Method: 提出了基于生命周期的ASC框架，包含设计、部署、运营和演进四个核心阶段，并系统分析了四个研究维度：感知与环境建模、自主决策与任务执行、多代理协作与组织、评估与可信度。

Result: 研究发现智能服务不是简单组装而是编排的：上下文感知支持稳健部署，自主推理支持实时操作，协作结构通过交互涌现演进，可信度是贯穿整个生命周期的关键要求。

Conclusion: 通过整合传统服务计算原则与基于LLM的多代理系统进展，为ASC建立了全面前瞻的基础，为开发自适应、可问责、以人为本的智能服务提供了统一参考。

Abstract: The rise of LLM-powered agents is driving a fundamental transformation in
services computing: from static, request-response functions to dynamic,
goal-oriented, and autonomous multi-agent ecosystems. In response to this
shift, we introduce Agentic Service Computing (ASC), a new paradigm that
reimagines services as intelligent, self-adaptive, and socially embedded
entities. This comprehensive survey presents a lifecycle-driven framework for
ASC, structured around four core phases: Design, Deployment, Operation, and
Evolution. We systematically analyze ASC through four foundational research
dimensions: (1) Perception, Context, and Environment Modeling, (2) Autonomous
Decision-Making and Task Execution, (3) Multi-Agent Collaboration and
Organization, and (4) Evaluation, Value Alignment, and Trustworthiness. We
examine how these dimensions are instantiated, integrated, and continuously
adapted across the service lifecycle. Our synthesis reveals that agentic
services are not merely assembled but orchestrated: contextual awareness
enables robust deployment; autonomous reasoning supports real-time operation;
collaborative structures emerge and evolve through interaction; and
trustworthiness must be upheld as a cross-cutting, lifelong imperative. We
further identify and discuss emerging trends shaping the future of ASC. By
integrating classical principles of services computing with advances in
LLM-based multi-agent systems, this work establishes a holistic and
forward-looking foundation for ASC. It provides a unified reference for
researchers and practitioners aiming to develop adaptive, accountable, and
human-centered intelligent services.

</details>


### [31] [Unit Test Update through LLM-Driven Context Collection and Error-Type-Aware Refinement](https://arxiv.org/abs/2509.24419)
*Yuanhe Zhang,Zhiquan Yang,Shengyi Pan,Zhongxin Liu*

Main category: cs.SE

TL;DR: TESTUPDATER是一个基于LLM的自动化单元测试更新方法，能够实时响应生产代码变化，同时修复和增强单元测试，通过上下文分析、逐步提示和迭代优化机制显著提高测试更新的正确性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化测试维护方法主要关注修复损坏的测试，忽略了增强现有测试以验证新功能的需求，且依赖基于规则的上下文收集，缺乏验证机制，难以处理复杂代码变更且生成测试用例的正确性较低。

Method: TESTUPDATER首先利用LLM分析代码变更并识别相关上下文，然后通过精心设计的提示逐步指导LLM处理各类代码变更和引入新依赖，实现测试修复和增强，最后引入错误类型感知的迭代优化机制执行更新后的测试并修复失败。

Result: 在新建基准UPDATES4J上的实验结果显示，TESTUPDATER实现了94.4%的编译通过率和86.7%的测试通过率，分别比最先进方法SYNTER高出15.9%和20.0%，同时在分支覆盖率和行覆盖率上分别高出12.9%和15.2%。

Conclusion: TESTUPDATER通过结合LLM的上下文分析能力和迭代优化机制，有效解决了自动化测试维护中的复杂代码变更处理问题，显著提高了测试更新的正确性和覆盖率，为实时单元测试更新提供了可行方案。

Abstract: Unit testing is critical for ensuring software quality and software system
stability. The current practice of manually maintaining unit tests suffers from
low efficiency and the risk of delayed or overlooked fixes. Therefore, an
automated approach is required to instantly update unit tests, with the
capability to both repair and enhance unit tests. However, existing automated
test maintenance methods primarily focus on repairing broken tests, neglecting
the scenario of enhancing existing tests to verify new functionality.
Meanwhile, due to their reliance on rule-based context collection and the lack
of verification mechanisms, existing approaches struggle to handle complex code
changes and often produce test cases with low correctness. To address these
challenges, we propose TESTUPDATER, a novel LLM based approach that enables
automated just-in-time test updates in response to production code changes.
TESTUPDATER first leverages the LLM to analyze code changes and identify
relevant context, which it then extracts and filters. Then, through carefully
designed prompts, TESTUPDATER guides the LLM step by step to handle various
types of code changes and introduce new dependencies, enabling both test repair
and enhancement. Finally, we introduce an error-type-aware iterative refinement
mechanism that executes the LLM-updated tests and repairs failures, which
significantly improves the overall correctness of test updates. Since existing
test repair datasets lack scenarios of test enhancement, we further construct a
new benchmark, UPDATES4J, with 195 real-world samples from 7 projects.
Experimental results show that TESTUPDATER achieves a compilation pass rate of
94.4% and a test pass rate of 86.7%, outperforming the state-of-the-art method
SYNTER by 15.9% and 20.0%, respectively. Furthermore, TESTUPDATER exhibits
12.9% higher branch coverage and 15.2% greater line coverage than SYNTER.

</details>


### [32] [Towards Shift-Up: A Framework and a Prestudy on High-Value Activities in GenAI Native Software Development](https://arxiv.org/abs/2509.24485)
*Vlad Stirbu,Mateen Ahmed Abbasi,Teerath Das,Jesse Haimi,Niko Iljin,Pyry Kotilainen,Petrus Lipsanen,Niko Mäkitalo,Maiju Sipilä,Venla Veijalainen,Tommi Mikkonen*

Main category: cs.SE

TL;DR: 提出了一个名为"shift-up"的GenAI原生开发框架，帮助软件团队专注于高价值工作，同时获得GenAI支持


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具正在改变软件工程，基于用户提示的专门代理正在取代人类开发者，需要新的开发框架来适应这一变化

Method: 提出了shift-up框架，并通过初步研究测试了这些想法与当前GenAI工具的集成

Result: 提出了一个初步的框架概念，并进行了初步验证

Conclusion: 提出了未来研究目标，以更详细地研究shift-up框架

Abstract: Generative AI (GenAI) has significantly influenced software engineering.
Associated tools have created a shift in software engineering, where
specialized agents, based on user-provided prompts, are replacing human
developers. In this paper, we propose a framework for GenAI native development
that we call \textit{shift-up}, which helps software teams focus on high-value
work while being supported by GenAI. Furthermore, we also present a preliminary
study testing these ideas with current GenAI tools. Towards the end of the
paper, we propose future research goals to study shift-up in more detail.

</details>


### [33] [JSProtect: A Scalable Obfuscation Framework for Mini-Games in WeChat](https://arxiv.org/abs/2509.24498)
*Zhihao Li,Chaozheng Wang,Zongjie Li,Xinyong Peng,Zelin Su,Qun Xia,Haochuan Lu,Ting Xiong,Man Ho Lam,Shuzheng Gao,Yuchong Xie,Cuiyun Gao,Shuai Wang,Yuetang Deng,Huafeng Ma*

Main category: cs.SE

TL;DR: JSProtect是一个针对微信小游戏生态的高吞吐量并行混淆框架，解决了现有JavaScript混淆工具在大规模应用中的处理时间长、运行时性能下降和代码膨胀问题。


<details>
  <summary>Details</summary>
Motivation: 微信小游戏生态系统面临知识产权盗窃问题，现有JavaScript混淆工具无法应对大规模应用，存在处理时间过长、运行时性能严重下降和代码体积不可持续膨胀等根本性限制。

Method: 提出了JSProtect框架，核心是并行感知范围分析(PASA)算法，实现两个关键优化：用于多核处理的独立代码分区和积极重用短标识符的独立命名空间管理。

Result: JSProtect能在几分钟内处理20MB代码库，保持100%语义等价性，将代码膨胀控制在仅20%，而基线工具超过1000%。同时保持接近原生的运行时性能，对静态分析工具和大语言模型提供优越的安全有效性。

Conclusion: 这项工作为工业级JavaScript保护提出了新范式，有效平衡了强大安全性与高性能和可扩展性。

Abstract: The WeChat mini-game ecosystem faces rampant intellectual property theft to
other platforms via secondary development, yet existing JavaScript obfuscation
tools are ill-equipped for large-scale applications, suffering from prohibitive
processing times, severe runtime performance degradation, and unsustainable
code size inflation. This paper introduces JSProtect, a high-throughput
parallelized obfuscation framework designed to overcome these fundamental
limitations. At the core of our framework is the Parallel-Aware Scope Analysis
(PASA) algorithm, which enables two key optimizations: independent code
partitioning for multi-core processing and independent namespace management
that aggressively reuses short identifiers to combat code bloat. Our evaluation
demonstrates that JSProtectprocesses 20MB codebases in minutes, maintaining
100\% semantic equivalence while controlling code size inflation to as low as
20\% compared to over 1,000\% with baseline tools. Furthermore, it preserves
near-native runtime performance and provides superior security effectiveness
against both static analysis tools and large language models. This work
presents a new paradigm for industrial-scale JavaScript protection that
effectively balances robust security with high performance and scalability.

</details>


### [34] [SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code](https://arxiv.org/abs/2509.24507)
*Qinglin Wang,Zhihong Sun,Ruyun Wang,Tao Huang,Zhi Jin,Ge Li,Chen Lyu*

Main category: cs.SE

TL;DR: SemGuard是一个语义评估器驱动的框架，通过在LLM解码过程中进行实时、行级语义监督，显著降低语义错误率并提高代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的代码中语义错误（程序能编译但行为错误）占多数，后修复方法存在延迟、依赖不完整测试套件和错误定位问题。需要在代码生成过程中早期注入语义信号来阻止错误传播。

Method: 构建SemDiff数据集进行细粒度标注，训练语义评估器嵌入LLM解码器，对部分代码进行实时语义监督，检测到偏差时回滚到错误行并指导重新生成。

Result: 在四个基准测试中，SemGuard始终优于最先进基线方法。在SemDiff上相比ROCODE降低19.86%语义错误率，在LiveCodeBench上使用CodeLlama-7B将Pass@1提升48.92%。

Conclusion: SemGuard展示了模型和语言无关的有效性，能够在不执行程序或需要测试用例的情况下，通过实时语义监督显著提升代码生成质量。

Abstract: Large Language Models (LLMs) can translate natural language requirements into
code, yet empirical analyses of representative models reveal that semantic
errors-programs that compile but behave incorrectly-constitute the majority of
observed faults (e.g., >60% on DeepSeek-Coder-6.7B and QwenCoder-7B). Post-hoc
repair pipelines detect such faults only after execution, incurring latency,
relying on incomplete test suites, and often mis-localizing the defect. Since
semantic drift originates in the autoregressive decoding process, intervening
while the code is being generated is a direct way to stop error propagation.
Constrained-decoding approaches such as ROCODE attempt this, but still wait
until the entire program runs to obtain feedback and use entropy heuristics
that do not truly capture semantics. A more effective solution must inject
semantic signals-early and precisely-into the decoding process.We present
SemGuard, a semantic-evaluator-driven framework that performs real-time,
line-level semantic supervision. To train the evaluator, we build SemDiff, the
first dataset with fine-grained annotations that mark the exact line where a
correct and an incorrect implementation diverge. The evaluator, once embedded
in the LLM's decoder, flags deviations on partial code, rolls back to the
faulty line, and guides regeneration-without executing the program or requiring
test cases. Across four benchmarks, SemGuard consistently outperforms
state-of-the-art baselines. It lowers the semantic error rate by 19.86% on
SemDiff relative to ROCODE, and lifts Pass@1 by 48.92% on the real-world
LiveCodeBench with CodeLlama-7B. Similar gains hold for StarCoder2-7B on MBPP
and for DeepSeekCoder-6.7B on the Java benchmark SemDiff-Java, demonstrating
model- and language-agnostic effectiveness.

</details>


### [35] [Bridging Developer Instructions and Code Completion Through Instruction-Aware Fill-in-the-Middle Paradigm](https://arxiv.org/abs/2509.24637)
*Zhensu Sun,Chengran Yang,Chao Peng,Pengfei Gao,Xiaoning Du,Li Li,David Lo*

Main category: cs.SE

TL;DR: 提出了IFIM方法，通过指令微调增强代码补全模型，使其能有效利用开发者提供的自然语言指令，同时保持原有的补全能力。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLM在代码补全时难以有效利用开发者意图的自然语言说明，而传统指令微调会损害填充中间任务性能。

Method: IFIM方法在传统FIM训练目标基础上，在输入中显式加入指令部分，让模型学习从(前缀、指令、后缀)三元组中生成代码。

Result: 在HumanEval-infilling基准上，Pass@1分数从84.6%提升到93.6%，且不影响无指令时的原始FIM性能。

Conclusion: IFIM成功解决了指令跟随与代码填充能力之间的权衡问题，显著提升了代码补全模型对开发者意图的理解能力。

Abstract: Large Language Models (LLMs) have significantly advanced code completion, yet
they often fail when the developer's intent is underspecified in the code
context. To address this, developers usually add natural language instructions
(e.g., comments) into the code context to clarify their intent. However,
existing code LLMs applied for code completion systems merely undergo a
fill-in-the-middle (FIM) pre-training, which struggles to leverage this
information effectively due to the lack of instruction-like training data.
Existing instruction-tuning techniques, which improve instruction-following in
general code generation, paradoxically degrade FIM performance, forcing a
trade-off between instruction-following and infilling capabilities. To address
this gap, we introduce Instruction-aware Fill-in-the-Middle (IFIM), an
instruction-tuning method specifically designed to enhance FIM code completion
models. IFIM extends the conventional FIM training objective by incorporating
an explicit instruction section into the input, enabling the model to learn
from (prefix, instruction, suffix) triplets. This approach allows the model to
effectively leverage developer-provided directives while preserving its core
completion abilities when no instructions are present. To facilitate this, we
constructed a large-scale dataset by using GPT-4o to generate concise,
intent-focused instructions for code infilling examples. We evaluated IFIM by
applying it to two popular base models, Deepseek-Coder and Qwen2.5-Coder, on
the benchmarks derived from HumanEval-infilling and RepoMasterEval. The results
demonstrate that IFIM significantly improves instruction-following
capabilities, boosting the Pass@1 score from 84.6% to 93.6% on
HumanEval-infilling. Moreover, this enhancement does not compromise the models'
original performance on FIM code completion tasks with no instructions
provided.

</details>


### [36] [CoTune: Co-evolutionary Configuration Tuning](https://arxiv.org/abs/2509.24694)
*Gangda Xiong,Tao Chen*

Main category: cs.SE

TL;DR: CoTune是一个通过协同进化方法自动调整系统配置的工具，它能够有效处理复杂的性能需求，避免传统调优器忽略需求信息或简单将需求作为目标导致的收敛问题。


<details>
  <summary>Details</summary>
Motivation: 现有调优器设计大多忽略了复杂性能需求的存在，只是简单假设性能越好越优，这会浪费需求中的有价值信息，也可能消耗大量资源来追求收益很小的目标。

Method: CoTune通过协同进化方法，创建一个辅助性能需求与配置共同进化，当目标性能需求变得无效或误导时，辅助需求能够提供帮助，使调优既能被需求引导又能抵抗其负面影响。

Result: 在162个测试案例（9个系统和18个需求）中，CoTune显著优于现有调优器，在90%的案例中排名第一（其他调优器仅为0%-35%），整体性能提升高达2.9倍，且效率更高。

Conclusion: CoTune通过协同进化方法有效解决了性能需求引导的配置调优问题，在保持高效率和鲁棒性的同时实现了显著的性能改进。

Abstract: To automatically tune configurations for the best possible system performance
(e.g., runtime or throughput), much work has been focused on designing
intelligent heuristics in a tuner. However, existing tuner designs have mostly
ignored the presence of complex performance requirements (e.g., the latency
shall ideally be 2 seconds), but simply assume that better performance is
always more preferred. This would not only waste valuable information in a
requirement but might also consume extensive resources to tune for a goal with
little gain. Yet, prior studies have shown that simply incorporating the
requirement as a tuning objective is problematic since the requirement might be
too strict, harming convergence; or its highly diverse satisfactions might lead
to premature convergence. In this paper, we propose CoTune, a tool that takes
the information of a given target performance requirement into account through
co-evolution. CoTune is unique in the sense that it creates an auxiliary
performance requirement to be co-evolved with the configurations, which assists
the target performance requirement when it becomes ineffective or even
misleading, hence allowing the tuning to be guided by the requirement while
being robust to its harm. Experiment results on 162 cases (nine systems and 18
requirements) reveal that CoTune considerably outperforms existing tuners,
ranking as the best for 90% cases (against the 0%--35% for other tuners) with
up to 2.9x overall improvements, while doing so under a much better efficiency.

</details>


### [37] [Large language models for behavioral modeling: A literature survey](https://arxiv.org/abs/2509.24782)
*Muhammad Laiq*

Main category: cs.SE

TL;DR: 该研究对使用大语言模型进行行为建模的现有研究进行了系统性综述，重点关注用例图和序列图的自动生成。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏关于LLMs在行为建模应用方面的综述研究，需要为未来研究方向提供指导，并帮助从业者和教育者了解LLMs在行为建模辅助方面的有效性。

Method: 通过术语搜索筛选并确定了14个相关的主要研究，对这些研究进行了系统分析。

Result: 分析发现LLMs在自动生成用例图和序列图方面显示出有前景的结果，但当前文献大多缺乏专家评估且主要使用GPT系列模型。

Conclusion: 未来研究应评估更广泛的LLMs用于行为建模，并让领域专家参与评估LLMs的输出质量。

Abstract: In recent years, large language models (LLMs) have been extensively utilized
for behavioral modeling, for example, to automatically generate sequence
diagrams. However, no overview of this work has been published yet. Such an
overview will help identify future research directions and inform practitioners
and educators about the effectiveness of LLMs in assisting behavioral modeling.
This study aims to provide an overview of the existing research on the use of
LLMs for behavioral modeling, particularly focusing on use case and sequence
diagrams. Through a term-based search, we filtered and identified 14 relevant
primary studies. Our analysis of the selected primary studies reveals that LLMs
have demonstrated promising results in automatically generating use case and
sequence diagrams. In addition, we found that most of the current literature
lacks expert-based evaluations and has mainly used GPT-based models. Therefore,
future work should evaluate a broader range of LLMs for behavioral modeling and
involve domain experts to evaluate the output of LLMs.

</details>


### [38] [Evaluating SAP Joule for Code Generation](https://arxiv.org/abs/2509.24828)
*Joshua Heisler,Johannes Reisinger,Andreas Fischer*

Main category: cs.SE

TL;DR: 本文评估了SAP Joule在JavaScript代码生成方面的能力，在HumanEval-X基准测试中获得了80.49%的严格准确率，在29个模型中排名第五。


<details>
  <summary>Details</summary>
Motivation: SAP发布了专有的生成模型SAP Joule，虽然主要不是针对SAP特定的ABAP代码生成，但可用于JavaScript等常见语言。本文旨在首次比较评估SAP Joule的代码生成能力。

Method: 使用HumanEval-X JavaScript基准测试，将SAP Joule与总共29个其他模型进行比较评估。

Result: SAP Joule在评估中获得了80.49%的严格准确率，在所有模型中排名第五。

Conclusion: 这是对SAP Joule代码生成能力的首次比较评估，表明该模型在JavaScript代码生成方面具有竞争力。

Abstract: SAP has released its own proprietary generative model SAP Joule, intended for
various generative tasks, including serving as a code assistant for software
engineers. While Joule is yet not focused on SAP-specific ABAP code generation,
it can be used for other common languages, including Javascript. This paper
compares SAP Joules Javascript coding capabilities against a total of 29 other
models using the HumanEval-X Javascript benchmark. SAP Joule achieves a strict
accuracy of 80.49% as the fifth best model in our evaluation. To the best of
our knowledge, this is the first comparative evaluation of SAP Joule code
generation capabilities.

</details>


### [39] [DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via Repetitive Pattern](https://arxiv.org/abs/2509.24975)
*Lekang Yang,Yuetong Liu,Yitong Zhang,Jia Li*

Main category: cs.SE

TL;DR: DiffTester是一个针对扩散语言模型在单元测试生成中的加速框架，通过识别测试代码中的重复结构模式，在保持测试质量的同时提高生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在单元测试生成中逐token生成效率低下，而扩散LLM虽然支持并行生成，但在效率和质量之间存在明显权衡。

Method: 通过抽象语法树分析动态识别单元测试中的重复结构模式，自适应增加每步生成的token数量而不影响输出质量。

Result: 在三个基准测试和两种代表性模型上的实验表明，DiffTester在保持测试覆盖率的同时实现了显著加速，且在不同dLLM和编程语言上具有良好的泛化性。

Conclusion: DiffTester为软件开发中的高效单元测试生成提供了实用且可扩展的解决方案。

Abstract: Software development relies heavily on extensive unit testing, which makes
the efficiency of automated Unit Test Generation (UTG) particularly important.
However, most existing LLMs generate test cases one token at a time in each
forward pass, which leads to inefficient UTG. Recently, diffusion LLMs (dLLMs)
have emerged, offering promising parallel generation capabilities and showing
strong potential for efficient UTG. Despite this advantage, their application
to UTG is still constrained by a clear trade-off between efficiency and test
quality, since increasing the number of tokens generated in each step often
causes a sharp decline in the quality of test cases. To overcome this
limitation, we present DiffTester, an acceleration framework specifically
tailored for dLLMs in UTG. The key idea of DiffTester is that unit tests
targeting the same focal method often share repetitive structural patterns. By
dynamically identifying these common patterns through abstract syntax tree
analysis during generation, DiffTester adaptively increases the number of
tokens produced at each step without compromising the quality of the output. To
enable comprehensive evaluation, we extend the original TestEval benchmark,
which was limited to Python, by introducing additional programming languages
including Java and C++. Extensive experiments on three benchmarks with two
representative models show that DiffTester delivers significant acceleration
while preserving test coverage. Moreover, DiffTester generalizes well across
different dLLMs and programming languages, providing a practical and scalable
solution for efficient UTG in software development. Code and data are publicly
available at https://github.com/wellbeingyang/DLM4UTG-open .

</details>


### [40] [Large Language Models for Software Testing: A Research Roadmap](https://arxiv.org/abs/2509.25043)
*Cristian Augusto,Antonia Bertolino,Guglielmo De Angelis,Francesca Lonetti,Jesús Morán*

Main category: cs.SE

TL;DR: 本文对基于大语言模型（LLM）的软件测试研究现状进行了系统梳理，提供了该领域的路线图，分类整理了现有贡献，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM在软件测试领域展现出巨大潜力，吸引了大量研究者，但缺乏对该领域进展和趋势的结构化概览。

Method: 采用半系统文献综述方法，收集相关文章并将其映射到主要类别，分析当前状态和开放挑战。

Result: 提供了LLM在软件测试领域的现状概览，包括测试代码生成、文档总结等应用，识别了主要研究方向和挑战。

Conclusion: LLM将对整个软件测试领域产生长期影响，需要系统化的研究路线图来指导未来发展。

Abstract: Large Language Models (LLMs) are starting to be profiled as one of the most
significant disruptions in the Software Testing field.
  Specifically, they have been successfully applied in software testing tasks
such as generating test code, or summarizing documentation.
  This potential has attracted hundreds of researchers, resulting in dozens of
new contributions every month, hardening researchers to
  stay at the forefront of the wave. Still, to the best of our knowledge, no
prior work has provided a structured vision of the progress
  and most relevant research trends in LLM-based testing. In this article, we
aim to provide a roadmap that illustrates its current state,
  grouping the contributions into different categories, and also sketching the
most promising and active research directions for the field.
  To achieve this objective, we have conducted a semi-systematic literature
review, collecting articles and mapping them into the most
  prominent categories, reviewing the current and ongoing status, and analyzing
the open challenges of LLM-based software testing.
  Lastly, we have outlined several expected long-term impacts of LLMs over the
whole software testing field.

</details>


### [41] [Towards Reliable Generation of Executable Workflows by Foundation Models](https://arxiv.org/abs/2509.25117)
*Sogol Masoumzadeh,Keheliya Gallaba,Dayi Lin,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 该论文提出了一个利用静态分析反馈来检测和修复FM生成的DSL工作流缺陷的框架，包括首个专门为此设计的静态分析器Timon和基于FM的修复工具Pumbaa。


<details>
  <summary>Details</summary>
Motivation: 基础模型生成DSL工作流时存在高缺陷率（87.27%），需要自动化方法来提高工作流生成的准确性和可靠性。

Method: 开发了首个FM生成DSL工作流的静态分析器Timon来识别9类缺陷，并利用基于FM的工具Pumbaa结合Timon的反馈来修复缺陷。

Result: 研究发现FM生成的DSL工作流中缺陷普遍存在，静态分析能有效识别多种缺陷类型，结合反馈机制可以成功修复这些缺陷。

Conclusion: 通过系统性的缺陷检测和修复，该工作为实现从自然语言需求可靠自动生成可执行工作流迈出了关键一步。

Abstract: Recent advancements in Foundation Models (FMs) have demonstrated significant
progress in comprehending complex natural language to perform intricate tasks.
Successfully executing these tasks often requires orchestrating calls to FMs
alongside other software components. However, manually decomposing a task into
a coherent sequence of smaller, logically aggregated steps, commonly referred
to as workflows, demands considerable effort and specialized domain knowledge.
While FMs can assist in generating such workflows specified in domain-specific
languages (DSLs), achieving accuracy and reliability in this process remains a
challenge.
  This work introduces a framework that leverages static analysis feedback to
enable FMs to detect and repair defects in the DSL-based workflows they
generate. We begin by presenting the first-ever taxonomy of incidences of
defects in FM-generated DSL workflows, categorizing them into 18 distinct
types. Furthermore, we observe a high prevalence of defects across FM-generated
DSL workflows, with 87.27% of the studied instances containing at least one
defect. This, in turn, emphasizes the magnitude of the problem in practice and
underscores the necessity for implementing mitigation strategies. Following
this, we demonstrate that nine types of these defects can be effectively
identified through static analysis of the workflows. For this purpose, we
develop Timon, the first-of-its-kind static analyzer specifically designed for
FM-generated DSL workflows. Finally, we show that by incorporating feedback
from Timon, we can guide Pumbaa, an FM-based tool, to repair the detected
defect incidences. By systematically detecting and repairing defects, our work
provides a crucial step towards the reliable and automated generation of
executable workflows from natural language requirements.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [42] [Efficient Cost Bounds with Linear Maps](https://arxiv.org/abs/2509.22982)
*David M Kahn,Jan Hoffmann,Thomas Reps,Jessie Grosen*

Main category: cs.PL

TL;DR: 提出了一种使用线性映射表示成本无关类型的新方法，通过矩阵不等式解决成本界限推理问题，显著提高了类型推断效率


<details>
  <summary>Details</summary>
Motivation: 现有的自动摊销资源分析(AARA)中，成本无关类型的推断效率低下，且现有启发式方法仅适用于多项式成本界限，无法处理指数级界限

Method: 使用线性映射来表示函数的成本无关类型，通过矩阵不等式进行代数推理，利用现成的线性规划工具求解

Result: 原型实现表明，在线性映射适用的情况下，类型推断效率比现有最先进算法呈指数级提升

Conclusion: 线性映射方法为AARA提供了更高效的类型推断方案，能够处理多项式和非多项式成本界限，显著提升了分析效率

Abstract: The Automatic Amortized Resource Analysis (AARA) derives program-execution
cost bounds using types. To do so, AARA often makes use of cost-free types,
which are critical for the composition of types and cost bounds. However,
inferring cost-free types using the current state-of-the-art algorithm is
expensive due to recursive dependence on additional cost-free types.
Furthermore, that algorithm uses a heuristic only applicable to polynomial cost
bounds, and not, e.g., exponential bounds. This paper presents a new approach
to these problems by representing the cost-free types of a function in a new
way: with a linear map, which can stand for infinitely many cost-free types.
Such maps enable an algebraic flavor of reasoning about cost bounds (including
non-polynomial bounds) via matrix inequalities. These inequalities can be
solved with off-the-shelf linear-programming tools for many programs, so that
types can always be efficiently checked and often be efficiently inferred. An
experimental evaluation with a prototype implementation shows that-when it is
applicable-the inference of linear maps is exponentially more efficient than
the state-of-the-art algorithm.

</details>


### [43] [Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification](https://arxiv.org/abs/2509.23061)
*Xu Xu,Xin Li,Xingwei Qu,Jie Fu,Binhang Yuan*

Main category: cs.PL

TL;DR: DafnyCOMP是一个用于评估大语言模型在Dafny中组合式规范生成能力的基准测试，专注于多函数交互程序，发现LLMs在组合任务上表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单函数任务，缺乏对多函数交互和数据依赖的组合式规范的评估，需要衡量LLMs在跨组件推理方面的能力。

Method: 构建包含300个自动合成的多函数程序的基准测试，评估多个最先进的LLM家族在组合式规范生成任务上的表现。

Result: LLMs在单函数验证上表现良好，但在组合任务上性能急剧下降，分析显示存在跨函数推理的系统性失败，包括脆弱规范、实现与证明不对齐和不稳定推理等问题。

Conclusion: DafnyCOMP提供了一个诊断工具，用于衡量LLMs在可靠、可验证和组合式代码生成方面的进展。

Abstract: We introduce DafnyCOMP, a benchmark for evaluating large language models
(LLMs) on compositional specification generation in Dafny. Unlike prior
benchmarks that focus on single-function tasks, DafnyCOMP targets programs
composed of multiple interacting functions with data dependencies, requiring
reasoning across component boundaries. The benchmark consists of 300
automatically synthesized multi-function programs. We evaluate several
state-of-the-art LLM families and find that, while they perform well on
single-function verification, their performance drops sharply on compositional
tasks. Analysis reveals systematic failures in cross-functional reasoning,
including fragile specifications, misalignment between implementations and
proofs, and unstable reasoning. DafnyCOMP thus provides a diagnostic tool for
measuring progress toward reliable, verifiable, and compositional code
generation with LLMs.

</details>


### [44] [Fine-Grained Reasoning About Container-Internal Pointers with Logical Pinning](https://arxiv.org/abs/2509.23229)
*Yawen Guan,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 提出了逻辑钉扎（logical pinning）方法，允许在分离逻辑中跟踪容器内部指针，解决了传统方法难以验证暴露内部指针的容器API的问题。


<details>
  <summary>Details</summary>
Motivation: 传统分离逻辑隐藏容器内部指针以实现模块化，但难以验证那些临时暴露内部指针的容器API和使用这些API的程序。

Method: 通过推广魔杖操作符，开发了轻量级的借用模型，允许在逻辑层面选择性跟踪容器内部指针，同时保持与大多数分离逻辑变体的兼容性。

Result: 验证了具有代表性的指针操作程序，推导出更精确的容器规范，证明该方法能够包含已知证明模式、简化复杂证明，并支持传统规范不支持的程序模式推理。

Conclusion: 逻辑钉扎是一个实用的方法，能够有效解决容器内部指针跟踪问题，所有结果已在Rocq证明助手中使用CFML库进行了机械化验证。

Abstract: Most separation logics hide container-internal pointers for modularity. This
makes it difficult to specify container APIs that temporarily expose those
pointers to the outside, and to verify programs that use these APIs. We present
logical pinning, a lightweight borrowing model for sequential programs that
allows users to selectively track container-internal pointers at the logical
level. Our model generalizes the magic-wand operator, making it easy to write
and prove precise specifications, including pointer-stability properties.
Because it only changes how representation predicates and specifications are
written, our approach is compatible with most separation logic variants. We
demonstrate the practicality of logical pinning by verifying small but
representative pointer-manipulating programs, and deriving more precise
versions of common container specifications. In doing so, we show that our
approach subsumes some well-known proof patterns, simplifies some complex
proofs, and enables reasoning about program patterns not supported by
traditional specifications. All of our results are mechanized in the Rocq proof
assistant, using the CFML library.

</details>


### [45] [From Affine to Polynomial: Synthesizing Loops with Branches via Algebraic Geometry](https://arxiv.org/abs/2509.25114)
*Erdenebayar Bayarmagnai,Fatemeh Mohammadi,Rémi Prébet*

Main category: cs.PL

TL;DR: 本文提出了一种从多项式不变量合成循环的新方法，允许循环具有多项式更新映射、不等式守卫条件和任意形式的多项式不变量。


<details>
  <summary>Details</summary>
Motivation: 现有的循环合成方法只能从多项式不变量合成无守卫条件的仿射循环，这限制了方法的通用性。本文旨在解决更一般的问题。

Method: 使用代数几何工具设计算法，计算多项式方程组，其解对应所有满足给定不变量的非确定性分支循环。对于特定类型的不变量，提出了更高效的算法。

Result: 将循环合成问题转化为求解有理数域上多元多项式系统的问题，并通过SMT求解器实现软件工具。

Conclusion: 本文的方法扩展了循环合成的适用范围，能够处理更复杂的循环结构和不变条件，为程序验证提供了更强大的工具。

Abstract: Ensuring software correctness remains a fundamental challenge in formal
program verification. One promising approach relies on finding polynomial
invariants for loops. Polynomial invariants are properties of a program loop
that hold before and after each iteration. Generating such invariants is a
crucial task in loop analysis, but it is undecidable in the general case.
Recently, an alternative approach to this problem has emerged, focusing on
synthesizing loops from invariants. However, existing methods only synthesize
affine loops without guard conditions from polynomial invariants. In this
paper, we address a more general problem, allowing loops to have polynomial
update maps with a given structure, inequations in the guard condition, and
polynomial invariants of arbitrary form.
  We use algebraic geometry tools to design and implement an algorithm that
computes a finite set of polynomial equations whose solutions correspond to all
nondeterministic branching loops satisfying the given invariants. Furthermore,
we introduce a new class of invariants for which we present a significantly
more efficient algorithm. In other words, we reduce the problem of synthesizing
loops to find solutions of multivariate polynomial systems with rational
entries. This final step is handled in our software using an SMT solver.

</details>


### [46] [Guard Analysis and Safe Erasure Gradual Typing: a Type System for Elixir](https://arxiv.org/abs/2408.14345)
*Giuseppe Castagna,Guillaume Duboc*

Main category: cs.PL

TL;DR: 为Elixir语言设计了一个结合渐进类型和语义子类型的新型类型系统，无需修改编译流程即可实现精确、可靠的静态类型分析


<details>
  <summary>Details</summary>
Motivation: Elixir作为动态类型函数式语言日益流行，但缺乏静态类型支持。需要开发一个既保持语言动态特性又能提供静态类型安全性的系统

Method: 采用渐进类型与语义子类型相结合的方法，引入"强函数"概念和细粒度的守卫分析技术，通过运行时检查确保类型安全性

Result: 成功构建了Elixir的类型系统理论基础，并集成到语言新版本中，在大型工业代码库中验证了有效性

Conclusion: 该工作为Elixir提供了实用的类型系统，在保持兼容性和性能的同时实现了类型安全性和表达力

Abstract: We formalize a new type system for Elixir, a dynamically typed functional
programming language of growing popularity that runs on the Erlang virtual
machine. Our system combines gradual typing with semantic subtyping to enable
precise, sound, and practical static type analysis, without requiring any
changes to Elixir's compilation pipeline or runtime. Type soundness is ensured
by leveraging runtime checks -- both implicit, from the Erlang VM, and
explicit, via developer-written guards.
  Central to our approach are two key innovations: the notion of "strong
functions", which can be assigned precise types even when applied to inputs
that may fall outside their intended domain; and a fine-grained analysis of
guards that enables accurate type refinement for case expressions and guarded
function definitions. While type information is erased before execution and not
used by the compiler, our "safe erasure" gradual typing strategy maintains
soundness and expressiveness without compromising compatibility or performance.
This work lays the theoretical foundation for Elixir's new type system,
outlines its integration into recent versions of the language, and demonstrates
its effectiveness on large-scale industrial codebases.

</details>
