<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 5]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Formal Verification of a Token Sale Launchpad: A Compositional Approach in Dafny](https://arxiv.org/abs/2510.24798)
*Evgeny Ukhanov*

Main category: cs.LO

TL;DR: 本文使用Dafny编程语言和验证系统对代币销售启动平台的核心逻辑进行了形式化验证，证明了关键安全属性和生命周期逻辑的正确性。


<details>
  <summary>Details</summary>
Motivation: 去中心化金融系统和智能合约的普及凸显了软件正确性的重要性，此类系统中的漏洞可能导致灾难性财务损失，形式化验证可以提供数学确定性。

Method: 采用组合式自底向上的验证策略，从证明基本非线性整数算术属性开始，逐步构建验证复杂业务逻辑，包括资产转换、基于时间的折扣和封顶销售退款机制。

Result: 成功证明了封顶销售中退款永远不会超过用户原始存款金额，财务计算中的精度损失严格有界，并验证了完整的生命周期逻辑。

Conclusion: 这项工作为应用严格验证技术构建高保证金融软件提供了一个全面的案例研究。

Abstract: The proliferation of decentralized financial (DeFi) systems and smart
contracts has underscored the critical need for software correctness. Bugs in
such systems can lead to catastrophic financial losses. Formal verification
offers a path to achieving mathematical certainty about software behavior. This
paper presents the formal verification of the core logic for a token sale
launchpad, implemented and proven correct using the Dafny programming language
and verification system. We detail a compositional, bottom-up verification
strategy, beginning with the proof of fundamental non-linear integer arithmetic
properties, and building upon them to verify complex business logic, including
asset conversion, time-based discounts, and capped-sale refund mechanics. The
principal contributions are the formal proofs of critical safety and lifecycle
properties. Most notably, we prove that refunds in a capped sale can never
exceed the user's original deposit amount, and that the precision loss in
round-trip financial calculations is strictly bounded. Furthermore, we verify
the complete lifecycle logic, including user withdrawals under various sale
mechanics and the correctness of post-sale token allocation, vesting, and
claiming. This work serves as a comprehensive case study in applying rigorous
verification techniques to build high-assurance financial software.

</details>


### [2] [On syntactic concept lattice models for the Lambek calculus and infinitary action logic](https://arxiv.org/abs/2510.24853)
*Stepan L. Kuznetsov*

Main category: cs.LO

TL;DR: 本文扩展了Lambek演算的语法概念格语义到包含Kleene迭代的无穷动作逻辑，证明了强完备性，并讨论了包含常量时的相关问题。


<details>
  <summary>Details</summary>
Motivation: Lambek演算的语言学应用需要形式语言代数语义，但添加额外操作会破坏完备性。Wurm提出的语法概念格语义可以缓解此问题，本文旨在将此语义扩展到包含Kleene迭代的无穷动作逻辑。

Method: 扩展Wurm的语法概念格语义到无穷动作逻辑，证明强完备性，并研究包含常量（零、单位、顶）时的问题。

Result: 成功证明了无穷动作逻辑在语法概念格语义下的强完备性，获得了有趣的推论，并加强了Wurm关于包含常量的结果。

Conclusion: 语法概念格语义可以成功扩展到无穷动作逻辑，保持强完备性，为包含Kleene迭代的Lambek演算提供了合适的语义基础。

Abstract: The linguistic applications of the Lambek calculus suggest its semantics over
algebras of formal languages. A straightforward approach to construct such
semantics indeed yields a brilliant completeness theorem (Pentus 1995).
However, extending the calculus with extra operations ruins completeness. In
order to mitigate this issue, Wurm (2017) introduced a modification of this
semantics, namely, models over syntactic concept lattices (SCLs). We extend
this semantics to the infinitary extension of the Lambek calculus with Kleene
iteration (infinitary action logic), prove strong completeness and some
interesting corollaries. We also discuss issues arising with constants - zero,
unit, top - and provide some strengthenings of Wurm's results towards including
these constants into the systems involved.

</details>


### [3] [Kleene Algebrae, Kleene Modules, and Morita Equivalence](https://arxiv.org/abs/2510.24993)
*Luke Serafin*

Main category: cs.LO

TL;DR: 研究Kleene代数中的Kleene模和Morita等价性，探索环论中的强大概念在Kleene代数背景下的应用潜力


<details>
  <summary>Details</summary>
Motivation: 模块和Morita等价的概念在环论研究中具有基础性地位，这些概念可以自然扩展到半环，并专门化到Kleene代数。作者希望研究Kleene模和Kleene代数的Morita等价，探索环论背景下的强大工具在这个新背景下是否同样有效

Method: 将环论中的模块和Morita等价概念扩展到半环，然后专门化到Kleene代数框架中

Result: 论文提出了Kleene模和Kleene代数Morita等价的概念框架

Conclusion: 通过将环论中的核心概念扩展到Kleene代数，有望在这个新背景下获得类似环论中的强大分析工具

Abstract: Modules and the notion of Morita equivalence are foundational to the
classical study of rings. These concepts extend naturally to semirings and then
specialize to Kleene algebrae, and my goal is to investigate Kleene modules and
Morita equivalence of Kleene algebrae in the hope that some of the power seen
in the context of rings may be found in this new context as well.

</details>


### [4] [A proof-theoretic approach to uniform interpolation property of multi-agent modal logic](https://arxiv.org/abs/2510.25394)
*Youan Su*

Main category: cs.LO

TL;DR: 本文扩展了Bílková (2007)的系统，通过纯语法方法在多智能体模态逻辑K_n、KD_n和KT_n中建立了均匀插值性质，并提供了计算均匀插项的直接算法。


<details>
  <summary>Details</summary>
Motivation: 虽然已有语义方法在多模态逻辑中建立了均匀插值性质，但缺乏证明论方法。本文旨在通过纯语法方法填补这一空白。

Method: 扩展Bílková (2007)的系统，提出纯语法算法来计算均匀插项公式，并展示了不使用二阶量词的直接论证方法。

Result: 成功在多智能体模态逻辑K_n、KD_n和KT_n中建立了均匀插值性质，提供了计算均匀插项的有效算法。

Conclusion: 本文证明了多模态逻辑中均匀插值性质的语法可证性，为命题变量量化提供了建模方法，并展示了不使用二阶量词的直接证明途径。

Abstract: Uniform interpolation property (UIP) is a strengthening of Craig
interpolation property. It was first established by Pitts(1992) based on a pure
proof-theoretic method. UIP in multi-modal $\mathbf{K_n}$, $\mathbf{KD_n}$ and
$\mathbf{KT_n}$ logic have been established by semantic approaches, however, a
proof-theoretic approach is still lacking. B\'ilkov\'a (2007) develops the
method in Pitts (1992) to show UIP in classical modal logic $\mathbf{K}$ and
$\mathbf{KT}$. This paper further extends B\'ilkov\'a (2007)'s systems to
establish the UIP in multi-agent modal logic $\mathbf{K_n}$, $\mathbf{KD_n}$
and $\mathbf{KT_n}$. A purely syntactic algorithm is presented to determine a
uniform interpolant formula. It is also shown that quantification over
propositional variables can be modeled by UIP in these systems. Furthermore, a
direct argument to establish UIP without using second-order quantifiers is also
presented.

</details>


### [5] [Proceedings of the 12th Workshop on Horn Clauses for Verification and Synthesis](https://arxiv.org/abs/2510.25468)
*Emanuele De Angelis,Florian Frohn*

Main category: cs.LO

TL;DR: 这是HCVS 2025研讨会论文集，包含验证和合成领域的研究成果


<details>
  <summary>Details</summary>
Motivation: 收集和整理第12届Horn子句验证与合成研讨会的学术论文，促进该领域的研究交流

Method: 通过研讨会形式收集相关论文，经过审稿和修订后汇编成论文集

Result: 成功出版了包含HCVS 2025研讨会论文的正式论文集

Conclusion: 该论文集为Horn子句在验证和合成领域的研究提供了重要的学术资源

Abstract: This volume contains the post-proceedings of the 12th Workshop on Horn
Clauses for Verification and Synthesis (HCVS 2025), which took place in Zagreb,
Croatia, on July 22, 2025, as affiliated workshop of the 37th International
Conference on Computer Aided Verification (CAV 2025).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Beyond Function-Level Search: Repository-Aware Dual-Encoder Code Retrieval with Adversarial Verification](https://arxiv.org/abs/2510.24749)
*Aofan Liu,Shiyuan Song,Haoxuan Li,Cehao Yang,Yiyan Qi*

Main category: cs.SE

TL;DR: 提出了RepoAlign-Bench基准和ReflectCode模型，用于解决代码库级别的代码检索问题，在变更请求驱动场景下实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代代码库日益复杂，需要能够理解跨组件变更意图的检索系统，而传统的函数级搜索范式缺乏这种能力。

Method: 提出ReflectCode模型，采用对抗性反射增强的双塔架构，包含解耦的代码编码器和文档编码器，通过大语言模型引导的反射动态整合语法模式、函数依赖和语义扩展意图。

Result: 在Top-5准确率上提升12.2%，在召回率上提升7.1%，优于现有最先进基线方法。

Conclusion: 为上下文感知的代码检索开辟了新方向，从函数中心匹配转向整体代码库级推理。

Abstract: The escalating complexity of modern codebases has intensified the need for
retrieval systems capable of interpreting cross-component change intents, a
capability fundamentally absent in conventional function-level search
paradigms. While recent studies have improved the alignment between natural
language queries and code snippets, retrieving contextually relevant code for
specific change requests remains largely underexplored. To address this gap, we
introduce RepoAlign-Bench, the first benchmark specifically designed to
evaluate repository-level code retrieval under change request driven scenarios,
encompassing 52k annotated instances. This benchmark shifts the retrieval
paradigm from function-centric matching to holistic repository-level reasoning.
Furthermore, we propose ReflectCode, an adversarial reflection augmented
dual-tower architecture featuring disentangled code_encoder and doc_encoder
components. ReflectCode dynamically integrates syntactic patterns, function
dependencies, and semantic expansion intents through large language model
guided reflection. Comprehensive experiments demonstrate that ReflectCode
achieves 12.2% improvement in Top-5 Accuracy and 7.1% in Recall over
state-of-the-art baselines, establishing a new direction for context-aware code
retrieval.

</details>


### [7] [Compiler.next: A Search-Based Compiler to Power the AI-Native Future of Software Engineering](https://arxiv.org/abs/2510.24799)
*Filipe R. Cogo,Gustavo A. Oliva,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: Compiler.next是一个基于搜索的新型编译器，旨在实现AI原生软件系统的无缝演进，通过将人类编写的意图自动转换为工作软件，优化认知架构并在准确性、成本和延迟之间找到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助软件工程工具存在认知过载、工具集成效率低和AI副驾驶能力有限等问题，需要新的范式来降低软件开发的技术门槛，实现可扩展、适应性强且可靠的AI驱动软件。

Method: 提出Compiler.next编译器架构，采用搜索驱动的方法，动态优化认知架构组件（如提示词、基础模型配置和系统参数），在多目标间寻找最优解。

Result: 论文概述了Compiler.next的架构，并将其定位为软件工程3.0时代的基石，为完全自动化、搜索驱动的软件开发奠定基础。

Conclusion: Compiler.next为民主化软件开发提供了愿景，通过降低非专家的技术门槛，促进更快的创新和更高效的AI驱动系统发展。

Abstract: The rapid advancement of AI-assisted software engineering has brought
transformative potential to the field of software engineering, but existing
tools and paradigms remain limited by cognitive overload, inefficient tool
integration, and the narrow capabilities of AI copilots. In response, we
propose Compiler.next, a novel search-based compiler designed to enable the
seamless evolution of AI-native software systems as part of the emerging
Software Engineering 3.0 era. Unlike traditional static compilers,
Compiler.next takes human-written intents and automatically generates working
software by searching for an optimal solution. This process involves dynamic
optimization of cognitive architectures and their constituents (e.g., prompts,
foundation model configurations, and system parameters) while finding the
optimal trade-off between several objectives, such as accuracy, cost, and
latency. This paper outlines the architecture of Compiler.next and positions it
as a cornerstone in democratizing software development by lowering the
technical barrier for non-experts, enabling scalable, adaptable, and reliable
AI-powered software. We present a roadmap to address the core challenges in
intent compilation, including developing quality programming constructs,
effective search heuristics, reproducibility, and interoperability between
compilers. Our vision lays the groundwork for fully automated, search-driven
software development, fostering faster innovation and more efficient AI-driven
systems.

</details>


### [8] [A Roadmap for Tamed Interactions with Large Language Models](https://arxiv.org/abs/2510.24819)
*Vincenzo Scotti,Jan Keim,Tobias Hey,Andreas Metzger,Anne Koziolek,Raffaela Mirandola*

Main category: cs.SE

TL;DR: 提出一种领域特定语言LSL（LLM Scripting Language）来解决LLM应用中的可靠性问题，通过编程化控制LLM输出、强制执行交互结构，并与验证、验证和可解释性集成。


<details>
  <summary>Details</summary>
Motivation: 当前LLM应用虽然令人印象深刻，但其不可靠性（如产生错误或幻觉内容）阻碍了在自动化工作流中的采用。软件工程工具可以用于定义LLM输出的约束，提供更强的生成内容保证。

Method: 开发一种领域特定语言（DSL）LSL，用于脚本化与LLM的交互，控制LLM输出、强制执行交互结构，并与验证、验证和可解释性方面集成。

Result: 提出了LSL的愿景，旨在使LLM交互可编程化，并与训练或实现解耦，以解决当前LLM软件在可靠性、鲁棒性和可信性方面的不足。

Conclusion: LSL可能是改进基于AI的应用的关键，通过提供编程化控制和验证机制，解决当前LLM应用中的碎片化问题和可靠性挑战。

Abstract: We are witnessing a bloom of AI-powered software driven by Large Language
Models (LLMs). Although the applications of these LLMs are impressive and
seemingly countless, their unreliability hinders adoption. In fact, the
tendency of LLMs to produce faulty or hallucinated content makes them
unsuitable for automating workflows and pipelines. In this regard, Software
Engineering (SE) provides valuable support, offering a wide range of formal
tools to specify, verify, and validate software behaviour. Such SE tools can be
applied to define constraints over LLM outputs and, consequently, offer
stronger guarantees on the generated content. In this paper, we argue that the
development of a Domain Specific Language (DSL) for scripting interactions with
LLMs using an LLM Scripting Language (LSL) may be key to improve AI-based
applications. Currently, LLMs and LLM-based software still lack reliability,
robustness, and trustworthiness, and the tools or frameworks to cope with these
issues suffer from fragmentation. In this paper, we present our vision of LSL.
With LSL, we aim to address the limitations above by exploring ways to control
LLM outputs, enforce structure in interactions, and integrate these aspects
with verification, validation, and explainability. Our goal is to make LLM
interaction programmable and decoupled from training or implementation.

</details>


### [9] [VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus](https://arxiv.org/abs/2510.25015)
*Chuyue Sun,Yican Sun,Daneshvar Amrollahi,Ethan Zhang,Shuvendu Lahiri,Shan Lu,David Dill,Clark Barrett*

Main category: cs.SE

TL;DR: VeriStruct是一个扩展AI辅助自动验证的框架，从单函数验证扩展到Verus中的复杂数据结构模块验证，通过规划模块系统生成抽象、类型不变量、规范和证明代码。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLMs经常误解Verus注释语法和验证特定语义的问题，以及将AI辅助验证从单函数扩展到复杂数据结构模块的需求。

Method: 使用规划模块协调生成抽象、类型不变量、规范和证明代码，在提示中嵌入语法指导，并包含修复阶段自动纠正注释错误。

Result: 在11个Rust数据结构模块的评估中，VeriStruct成功验证了10个模块，总共验证了128个函数中的129个（99.2%）。

Conclusion: 这些结果代表了向自动AI辅助形式验证目标迈出的重要一步。

Abstract: We introduce VeriStruct, a novel framework that extends AI-assisted automated
verification from single functions to more complex data structure modules in
Verus. VeriStruct employs a planner module to orchestrate the systematic
generation of abstractions, type invariants, specifications, and proof code. To
address the challenge that LLMs often misunderstand Verus' annotation syntax
and verification-specific semantics, VeriStruct embeds syntax guidance within
prompts and includes a repair stage to automatically correct annotation errors.
In an evaluation on eleven Rust data structure modules, VeriStruct succeeds on
ten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in
total. These results represent an important step toward the goal of automatic
AI-assisted formal verification.

</details>


### [10] [Towards Human-AI Synergy in Requirements Engineering: A Framework and Preliminary Study](https://arxiv.org/abs/2510.25016)
*Mateen Ahmed Abbasi,Petri Ihantola,Tommi Mikkonen,Niko Mäkitalo*

Main category: cs.SE

TL;DR: 提出HARE-SM模型，将AI驱动分析与人工监督结合，改进需求工程流程，强调伦理AI使用。


<details>
  <summary>Details</summary>
Motivation: 传统需求工程依赖劳动密集型手动流程，容易出错且复杂。AI方法（特别是LLMs、NLP和生成式AI）可提供变革性解决方案，但面临算法偏见、可解释性不足和伦理问题。

Method: 采用多阶段研究方法：准备需求工程数据集、微调AI模型、设计协作式人机工作流程。提出HARE-SM概念框架，集成AI分析与人工监督。

Result: 建立了概念框架和早期原型实现，为在协作环境中应用智能数据科学技术处理半结构化和非结构化需求工程数据提供了研究议程和实用设计方向。

Conclusion: HARE-SM模型通过结合AI能力和人类监督，能够改进需求工程的获取、分析和验证过程，同时确保AI使用的透明性、可解释性和偏见缓解。

Abstract: The future of Requirements Engineering (RE) is increasingly driven by
artificial intelligence (AI), reshaping how we elicit, analyze, and validate
requirements. Traditional RE is based on labor-intensive manual processes prone
to errors and complexity. AI-powered approaches, specifically large language
models (LLMs), natural language processing (NLP), and generative AI, offer
transformative solutions and reduce inefficiencies. However, the use of AI in
RE also brings challenges like algorithmic bias, lack of explainability, and
ethical concerns related to automation. To address these issues, this study
introduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that
integrates AI-driven analysis with human oversight to improve requirements
elicitation, analysis, and validation. The model emphasizes ethical AI use
through transparency, explainability, and bias mitigation. We outline a
multi-phase research methodology focused on preparing RE datasets, fine-tuning
AI models, and designing collaborative human-AI workflows. This preliminary
study presents the conceptual framework and early-stage prototype
implementation, establishing a research agenda and practical design direction
for applying intelligent data science techniques to semi-structured and
unstructured RE data in collaborative environments.

</details>


### [11] [Automating Benchmark Design](https://arxiv.org/abs/2510.25039)
*Amanda Dsouza,Harit Vishwakarma,Zhengyang Qi,Justin Bauer,Derek Pham,Thomas Walshe,Armin Parchami,Frederic Sala,Paroma Varma*

Main category: cs.SE

TL;DR: BeTaL是一个利用LLM自动化设计动态基准测试的框架，通过参数化基准模板和LLM推理来高效创建具有目标属性（如难度和真实性）的基准测试。


<details>
  <summary>Details</summary>
Motivation: 传统手工制作的静态基准测试很快会过时，而动态基准测试虽然能随模型发展而演进，但创建和持续更新的成本很高。

Method: BeTaL框架参数化基准模板的关键设计选择，使用LLM推理参数空间，以成本效益的方式获得目标属性。

Result: 在三个任务和多个目标难度级别上的广泛评估显示，BeTaL生成的基准测试更接近期望难度，平均偏差从5.3%到13.2%，比基线方法提高了2-4倍。

Conclusion: BeTaL能够有效自动化动态基准测试的设计过程，显著提高了基准测试与目标难度的匹配度。

Abstract: The rapid progress and widespread deployment of LLMs and LLM-powered agents
has outpaced our ability to evaluate them. Hand-crafted, static benchmarks are
the primary tool for assessing model capabilities, but these quickly become
saturated. In contrast, dynamic benchmarks evolve alongside the models they
evaluate, but are expensive to create and continuously update. To address these
challenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a
framework that leverages environment design principles to automate the process
of dynamic benchmark design. BeTaL works by parameterizing key design choices
in base benchmark templates and uses LLMs to reason through the resulting
parameter space to obtain target properties (such as difficulty and realism) in
a cost-efficient manner. We validate this approach on its ability to create
benchmarks with desired difficulty levels. Using BeTaL, we create two new
benchmarks and extend a popular agentic benchmark $\tau$-bench. Extensive
evaluation on these three tasks and multiple target difficulty levels shows
that BeTaL produces benchmarks much closer to the desired difficulty, with
average deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the
baselines.

</details>


### [12] [Same Same But Different: Preventing Refactoring Attacks on Software Plagiarism Detection](https://arxiv.org/abs/2510.25057)
*Robin Maisch,Larissa Schmid,Timur Sağlam,Nils Niehues*

Main category: cs.SE

TL;DR: 提出了一种基于代码属性图和图变换的新框架，用于增强现有抄袭检测系统对抗重构式混淆攻击的能力


<details>
  <summary>Details</summary>
Motivation: 编程教育中的抄袭检测面临日益复杂的混淆技术挑战，特别是自动重构式攻击。现有系统对基本混淆有抵抗力，但难以应对保持程序行为的结构性修改

Method: 使用代码属性图和图变换技术构建可扩展框架，增强现有最先进检测器对抗重构式混淆的能力

Result: 在真实学生提交代码上的综合评估显示，该框架显著提高了对混淆抄袭代码的检测能力，测试包括算法和AI驱动的混淆攻击

Conclusion: 该框架有效提升了抄袭检测系统对抗重构式混淆攻击的鲁棒性

Abstract: Plagiarism detection in programming education faces growing challenges due to
increasingly sophisticated obfuscation techniques, particularly automated
refactoring-based attacks. While code plagiarism detection systems used in
education practice are resilient against basic obfuscation, they struggle
against structural modifications that preserve program behavior, especially
caused by refactoring-based obfuscation. This paper presents a novel and
extensible framework that enhances state-of-the-art detectors by leveraging
code property graphs and graph transformations to counteract refactoring-based
obfuscation. Our comprehensive evaluation of real-world student submissions,
obfuscated using both algorithmic and AI-based obfuscation attacks,
demonstrates a significant improvement in detecting plagiarized code.

</details>


### [13] [Adaptive Proof Refinement with LLM-Guided Strategy Selection](https://arxiv.org/abs/2510.25103)
*Minghai Lu,Zhe Zhou,Danning Xie,Songlin Jia,Benjamin Delaware,Tianyi Zhang*

Main category: cs.SE

TL;DR: Adapt是一个新颖的证明精炼框架，使用LLM引导的决策器动态选择适合的精炼策略，在定理证明中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 形式化验证需要大量人工努力，LLM在证明生成中经常产生错误证明，现有方法使用固定的精炼策略无法根据具体问题动态调整。

Method: 引入Adapt框架，利用LLM引导的决策器根据证明助手状态和错误证明上下文动态选择合适的精炼策略。

Result: 在两个基准测试中，Adapt比最佳基线分别多证明了16.63%和18.58%的定理，并在五个不同LLM上展示了通用性。

Conclusion: Adapt框架通过动态策略选择显著提高了定理证明性能，具有很好的通用性和组件有效性。

Abstract: Formal verification via theorem proving enables the expressive specification
and rigorous proof of software correctness, but it is difficult to scale due to
the significant manual effort and expertise required. While Large Language
Models (LLMs) show potential in proof generation, they frequently produce
incorrect proofs on the first attempt and require additional strategies for
iterative refinement. However, existing approaches employ fixed refinement
strategies and cannot dynamically choose an effective strategy based on the
particular issues in a generated proof, which limits their performance. To
overcome this limitation, we introduce Adapt, a novel proof refinement
framework that leverages an LLM-guided decision-maker to dynamically select a
suitable refinement strategy according to the state of the proof assistant and
available context of an incorrect proof. We evaluate Adapt on two benchmarks
against four existing methods and find that it significantly outperforms the
best baseline on both by proving 16.63% and 18.58% more theorems, respectively.
Furthermore, we demonstrate Adapt's generalizability by evaluating it across
five different LLMs. We also conduct ablation studies to measure the
contribution of each component and compare the trade-offs of alternative
decision-maker designs.

</details>


### [14] [Automated Program Repair Based on REST API Specifications Using Large Language Models](https://arxiv.org/abs/2510.25148)
*Katsuki Yamagishi,Norihiro Yoshida,Erina Makihara,Katsuro Inoue*

Main category: cs.SE

TL;DR: dcFix是一种自动检测和修复REST API误用的方法，通过识别不符合规范的代码片段，结合API规范生成提示，利用大语言模型自动生成修复代码。


<details>
  <summary>Details</summary>
Motivation: 开发者在测试阶段才能发现REST API规范违反问题，错误信息缺乏细节导致调试困难，需要反复试错。

Method: 识别不符合API规范的代码片段，将其与相关API规范整合到提示中，利用大语言模型生成修正后的代码。

Result: 评估显示dcFix能准确检测API误用，并且在修复效果上优于基线方法（基线方法在提示中不包含代码片段不符合规范的信息）。

Conclusion: dcFix方法能有效检测和自动修复REST API误用问题，通过结合代码片段和API规范信息，显著提升了修复效果。

Abstract: Many cloud services provide REST API accessible to client applications.
However, developers often identify specification violations only during
testing, as error messages typically lack the detail necessary for effective
diagnosis. Consequently, debugging requires trial and error. This study
proposes dcFix, a method for detecting and automatically repairing REST API
misuses in client programs. In particular, dcFix identifies non-conforming code
fragments, integrates them with the relevant API specifications into prompts,
and leverages a Large Language Model (LLM) to produce the corrected code. Our
evaluation demonstrates that dcFix accurately detects misuse and outperforms
the baseline approach, in which prompts to the LLM omit any indication of code
fragments non conforming to REST API specifications.

</details>


### [15] [Optimizing Knowledge Utilization for Multi-Intent Comment Generation with Large Language Models](https://arxiv.org/abs/2510.25195)
*Shuochuan Li,Zan Wang,Xiaoning Du,Zhuo Wu,Jiuqiao Yu,Junjie Chen*

Main category: cs.SE

TL;DR: KUMIC是一个基于上下文学习的多意图代码注释生成框架，通过检索机制和思维链优化，显著提升了代码注释生成的质量。


<details>
  <summary>Details</summary>
Motivation: 传统代码注释生成的通用概述无法满足开发者的多样化需求，开发者需要实现洞察而用户需要使用说明，这凸显了多意图注释生成的必要性。

Method: KUMIC框架基于上下文学习，利用检索机制获取高质量演示示例，并通过思维链引导LLMs关注与特定意图对齐的代码语句，构建从代码到意图特定语句再到注释的映射知识链。

Result: 实验结果显示KUMIC在BLEU、METEOR、ROUGE-L和SBERT指标上分别比最先进基线方法提升了14.49%、22.41%、20.72%和12.94%。

Conclusion: KUMIC通过优化知识利用和构建映射知识链，有效解决了LLMs在多意图注释生成中难以建立正确关系的问题，显著提升了生成质量。

Abstract: Code comment generation aims to produce a generic overview of a code snippet,
helping developers understand and maintain code. However, generic summaries
alone are insufficient to meet the diverse needs of practitioners; for example,
developers expect the implementation insights to be presented in an untangled
manner, while users seek clear usage instructions. This highlights the
necessity of multi-intent comment generation. With the widespread adoption of
Large Language Models (LLMs) for code-related tasks, these models have been
leveraged to tackle the challenge of multi-intent comment generation. Despite
their successes, state-of-the-art LLM-based approaches often struggle to
construct correct relationships among intents, code, and comments within a
smaller number of demonstration examples. To mitigate this issue, we propose a
framework named KUMIC for multi-intent comment generation. Built upon
in-context learning, KUMIC leverages Chain-of-Thought (CoT) to optimize
knowledge utilization for LLMs to generate intent-specific comments.
Specifically, KUMIC first designs a retrieval mechanism to obtain similar
demonstration examples, which exhibit high code-comment consistency. Then,
KUMIC leverages CoT to guide LLMs to focus on statements facilitating the
derivation of code comments aligned with specific intents. In this context,
KUMIC constructs a mapping knowledge chain, linking code to intent-specific
statements to comments, which enables LLMs to follow similar reasoning steps
when generating the desired comments. We conduct extensive experiments to
evaluate KUMIC, and the results demonstrate that KUMIC outperforms
state-of-the-art baselines by 14.49\%, 22.41\%, 20.72\%, and 12.94\% in terms
of BLEU, METEOR, ROUGE-L, and SBERT, respectively.

</details>


### [16] [TECS/Rust-OE: Optimizing Exclusive Control in Rust-based Component Systems for Embedded Devices](https://arxiv.org/abs/2510.25242)
*Nao Yoshimura,Hiroshi Oyama,Takuya Azumi*

Main category: cs.SE

TL;DR: TECS/Rust-OE是一个内存安全的基于组件的开发框架，通过利用调用流和实时OS的独占控制机制，解决了TECS/Rust框架中因过度独占控制导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式系统规模和复杂度的增加，确保系统可靠性（特别是安全性）需要选择合适的编程语言。现有的TECS/Rust框架因使用静态可变变量和过度独占控制导致性能下降。

Method: 提出TECS/Rust-OE框架，利用调用流和实时OS的独占控制机制，在保持可重用性的同时优化性能。基于组件描述自动生成Rust代码。

Result: 评估显示优化的独占控制减少了开销，生成的代码具有高可重用性。

Conclusion: TECS/Rust-OE框架成功解决了TECS/Rust的性能问题，在保持内存安全的同时实现了更好的性能和可重用性。

Abstract: The diversification of functionalities and the development of the IoT are
making embedded systems larger and more complex in structure. Ensuring system
reliability, especially in terms of security, necessitates selecting an
appropriate programming language. As part of existing research, TECS/Rust has
been proposed as a framework that combines Rust and component-based development
(CBD) to enable scalable system design and enhanced reliability. This framework
represents system structures using static mutable variables, but excessive
exclusive controls applied to ensure thread safety have led to performance
degradation. This paper proposes TECS/Rust-OE, a memory-safe CBD framework
utilizing call flows to address these limitations. The proposed Rust code
leverages real-time OS exclusive control mechanisms, optimizing performance
without compromising reusability. Rust code is automatically generated based on
component descriptions. Evaluations demonstrate reduced overhead due to
optimized exclusion control and high reusability of the generated code.

</details>


### [17] [TECS/Rust: Memory-safe Component Framework for Embedded Systems](https://arxiv.org/abs/2510.25270)
*Nao Yoshimura,Hiroshi Oyama,Takuya Azumi*

Main category: cs.SE

TL;DR: 本文提出了TECS/Rust框架，这是一个基于Rust语言的嵌入式系统组件框架，旨在解决C语言在组件化开发中的内存安全问题，同时保持开发灵活性。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式系统复杂度的增加，基于组件的开发(CBD)成为解决方案，但C语言存在内存安全问题。需要一种既能保持CBD灵活性又能确保内存安全的框架。

Method: 开发了基于Rust的TECS框架，利用Rust的编译时内存安全特性（生命周期和借用检查），自动化生成CBD组件的Rust代码，并支持与实时操作系统的集成。

Result: 生成的代码占实际代码的很大比例，与不使用该框架的代码相比，执行时间差异极小，表明框架引入的开销可以忽略不计。

Conclusion: TECS/Rust框架成功地将Rust的内存安全特性引入嵌入式系统组件开发，在保证安全性的同时保持了性能效率。

Abstract: As embedded systems grow in complexity and scale due to increased functional
diversity, component-based development (CBD) emerges as a solution to
streamline their architecture and enhance functionality reuse. CBD typically
utilizes the C programming language for its direct hardware access and
low-level operations, despite its susceptibility to memory-related issues. To
address these concerns, this paper proposes TECS/Rust, a Rust-based framework
specifically designed for TECS, which is a component framework for embedded
systems. It leverages Rust's compile-time memory-safe features, such as
lifetime and borrowing, to mitigate memory vulnerabilities common with C. The
proposed framework not only ensures memory safety but also maintains the
flexibility of CBD, automates Rust code generation for CBD components, and
supports efficient integration with real-time operating systems. An evaluation
of the amount of generated code indicates that the code generated by this paper
framework accounts for a large percentage of the actual code. Compared to code
developed without the proposed framework, the difference in execution time is
minimal, indicating that the overhead introduced by the proposed framework is
negligible.

</details>


### [18] [Understanding the Characteristics of LLM-Generated Property-Based Tests in Exploring Edge Cases](https://arxiv.org/abs/2510.25297)
*Hidetake Tanaka,Haruto Tanaka,Kazumasa Shimari,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 本研究比较了基于属性的测试(PBT)和基于示例的测试(EBT)在检测LLM生成代码边缘案例方面的效果，发现两者结合能显著提高缺陷检测率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中生成代码的普及，确保LLM生成代码的质量变得重要。传统的基于示例的测试方法经常遗漏边缘案例。

Method: 分析了16个HumanEval问题，使用Claude-4-sonnet生成PBT和EBT测试代码，比较两者在检测边缘案例方面的效果。

Result: 单独使用PBT或EBT时，缺陷检测率为68.75%，但两者结合后检测率提升至81.25%。PBT擅长检测性能问题和边缘案例，EBT擅长检测特定边界条件和特殊模式。

Conclusion: 结合PBT和EBT的混合方法可以提高LLM生成代码的可靠性，为LLM代码生成的测试策略提供指导。

Abstract: As Large Language Models (LLMs) increasingly generate code in software
development, ensuring the quality of LLM-generated code has become important.
Traditional testing approaches using Example-based Testing (EBT) often miss
edge cases -- defects that occur at boundary values, special input patterns, or
extreme conditions. This research investigates the characteristics of
LLM-generated Property-based Testing (PBT) compared to EBT for exploring edge
cases. We analyze 16 HumanEval problems where standard solutions failed on
extended test cases, generating both PBT and EBT test codes using
Claude-4-sonnet. Our experimental results reveal that while each method
individually achieved a 68.75\% bug detection rate, combining both approaches
improved detection to 81.25\%. The analysis demonstrates complementary
characteristics: PBT effectively detects performance issues and edge cases
through extensive input space exploration, while EBT effectively detects
specific boundary conditions and special patterns. These findings suggest that
a hybrid approach leveraging both testing methods can improve the reliability
of LLM-generated code, providing guidance for test generation strategies in
LLM-based code generation.

</details>


### [19] [Dissect-and-Restore: AI-based Code Verification with Transient Refactoring](https://arxiv.org/abs/2510.25406)
*Changjie Wang,Mariano Scazzariello,Anoud Alshnaka,Roberto Guanciale,Dejan Kostić,Marco Chiesa*

Main category: cs.SE

TL;DR: Prometheus是一个AI辅助的自动代码验证系统，通过模块化重构将复杂程序分解为可验证的小组件，然后重新组合构建原始程序的证明，显著提高了AI在形式化验证中的效果。


<details>
  <summary>Details</summary>
Motivation: 形式化验证对于构建可靠软件系统至关重要，但需要专业知识编写规范、处理复杂证明义务和学习注释，使得验证成本比实现高一个数量级。现代AI系统虽然能识别数学证明模式和理解自然语言，但如何有效整合到形式化验证过程中仍是一个挑战。

Method: 采用分解-重组工作流：首先将复杂程序逻辑（如嵌套循环）分解为更小、可验证的组件；验证这些组件后重新组合构建原始程序证明。通过结构化分解复杂引理为可验证子引理来指导证明搜索，当自动化工具不足时，用户可提供轻量级自然语言指导。

Result: 评估显示，临时应用模块化重构显著提高了AI验证单个组件的效果：在精选数据集中成功验证86%的任务（基线为68%）；随着规范复杂性增加，验证率从30%提升到69%；集成复杂程序证明大纲时，从25%提升到87%。

Conclusion: Prometheus系统通过模块化重构和AI辅助，有效解决了形式化验证中的复杂性挑战，显著提高了验证成功率和效率，特别是在处理复杂规范和程序时表现突出。

Abstract: Formal verification is increasingly recognized as a critical foundation for
building reliable software systems. However, the need for specialized expertise
to write precise specifications, navigate complex proof obligations, and learn
annotations often makes verification an order of magnitude more expensive than
implementation. While modern AI systems can recognize patterns in mathematical
proofs and interpret natural language, effectively integrating them into the
formal verification process remains an open challenge. We present Prometheus, a
novel AI-assisted system that facilitates automated code verification with
current AI capabilities in conjunction with modular software engineering
principles (e.g., modular refactoring). Our approach begins by decomposing
complex program logic, such as nested loops, into smaller, verifiable
components. Once verified, these components are recomposed to construct a proof
of the original program. This decomposition-recomposition workflow is
non-trivial. Prometheus addresses this by guiding the proof search through
structured decomposition of complex lemmas into smaller, verifiable sub-lemmas.
When automated tools are insufficient, users can provide lightweight natural
language guidance to steer the proof process effectively. Our evaluation
demonstrates that transiently applying modular restructuring to the code
substantially improves the AI's effectiveness in verifying individual
components. This approach successfully verifies 86% of tasks in our curated
dataset, compared to 68% for the baseline. Gains are more pronounced with
increasing specification complexity, improving from 30% to 69%, and when
integrating proof outlines for complex programs, from 25% to 87%.

</details>


### [20] [What Challenges Do Developers Face in AI Agent Systems? An Empirical Study on Stack Overflow](https://arxiv.org/abs/2510.25423)
*Ali Asgari,Annibale Panichella,Pouria Derakhshanfar,Mitchell Olsthoorn*

Main category: cs.SE

TL;DR: 该论文通过分析Stack Overflow上AI代理开发者的讨论，识别了77个技术挑战，涵盖运行时集成、依赖管理、编排复杂性和评估可靠性等7个主要领域，并量化了问题的流行度和难度。


<details>
  <summary>Details</summary>
Motivation: AI代理系统虽然前景广阔，但开发者在构建、部署和维护过程中面临持续且未被充分探索的挑战，需要系统性地识别这些挑战以提供更好的开发者支持。

Method: 通过标签扩展和过滤构建挑战分类法，应用LDA-MALLET进行主题建模，手动验证和标记主题，并量化主题流行度和难度。

Result: 识别出7个主要领域的77个技术挑战，量化了问题的流行度和解决难度，追踪了从2021到2025年AI代理开发的工具和编程语言演变。

Conclusion: 研究结果为从业者、研究人员和教育工作者提供了关于AI代理可靠性和开发者支持的具体指导，有助于改进AI代理系统的开发和维护。

Abstract: AI agents have rapidly gained popularity across research and industry as
systems that extend large language models with additional capabilities to plan,
use tools, remember, and act toward specific goals. Yet despite their promise,
developers face persistent and often underexplored challenges when building,
deploying, and maintaining these emerging systems. To identify these
challenges, we study developer discussions on Stack Overflow, the world's
largest developer-focused Q and A platform with about 60 million questions and
answers and 30 million users. We construct a taxonomy of developer challenges
through tag expansion and filtering, apply LDA-MALLET for topic modeling, and
manually validate and label the resulting themes. Our analysis reveals seven
major areas of recurring issues encompassing 77 distinct technical challenges
related to runtime integration, dependency management, orchestration
complexity, and evaluation reliability. We further quantify topic popularity
and difficulty to identify which issues are most common and hardest to resolve,
map the tools and programming languages used in agent development, and track
their evolution from 2021 to 2025 in relation to major AI model and framework
releases. Finally, we present the implications of our results, offering
concrete guidance for practitioners, researchers, and educators on agent
reliability and developer support.

</details>


### [21] [Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies](https://arxiv.org/abs/2510.25506)
*Florian Angermeir,Maximilian Amougou,Mark Kreitz,Andreas Bauer,Matthias Linhuber,Davide Fucci,Fabiola Moyón C.,Daniel Mendez,Tony Gorschek*

Main category: cs.SE

TL;DR: 分析了ICSE 2024和ASE 2024会议上86篇LLM相关研究的可复现性，发现仅18篇提供了研究构件且使用OpenAI模型，其中仅5篇适合复现，但没有一篇能完全复现结果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在学术界和工业界的广泛应用，进行LLM实证研究面临可复现性挑战。需要了解当前LLM研究的可复现程度及阻碍因素。

Method: 选取ICSE 2024和ASE 2024会议上86篇LLM相关文章，筛选出18篇提供研究构件并使用OpenAI模型的研究进行复现尝试。

Result: 18篇研究中仅5篇适合复现，其中2篇部分可复现，3篇不可复现，没有一篇能完全复现原始结果。

Conclusion: 当前LLM研究的可复现性状况堪忧，需要更严格的研究构件评估和更稳健的研究设计来确保未来发表成果的可复现价值。

Abstract: Large Language Models have gained remarkable interest in industry and
academia. The increasing interest in LLMs in academia is also reflected in the
number of publications on this topic over the last years. For instance, alone
78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.
Conducting empirical studies with LLMs remains challenging and raises questions
on how to achieve reproducible results, for both other researchers and
practitioners. One important step towards excelling in empirical research on
LLMs and their application is to first understand to what extent current
research results are eventually reproducible and what factors may impede
reproducibility. This investigation is within the scope of our work. We
contribute an analysis of the reproducibility of LLM-centric studies, provide
insights into the factors impeding reproducibility, and discuss suggestions on
how to improve the current state. In particular, we studied the 86 articles
describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86
articles, 18 provided research artefacts and used OpenAI models. We attempted
to replicate those 18 studies. Of the 18 studies, only five were fit for
reproduction. For none of the five studies, we were able to fully reproduce the
results. Two studies seemed to be partially reproducible, and three studies did
not seem to be reproducible. Our results highlight not only the need for
stricter research artefact evaluations but also for more robust study designs
to ensure the reproducible value of future publications.

</details>


### [22] [Fuzz Smarter, Not Harder: Towards Greener Fuzzing with GreenAFL](https://arxiv.org/abs/2510.25665)
*Ayse Irmak Ercevik,Aidan Dakhama,Melane Navaratnarajah,Yazhuo Cao,Leo Fernandes*

Main category: cs.SE

TL;DR: GreenAFL是一个能量感知的模糊测试框架，通过将功耗纳入模糊测试启发式算法，在保持覆盖率的同时减少自动化测试的环境影响。


<details>
  <summary>Details</summary>
Motivation: 现有的灰盒模糊测试方法如AFL++主要关注覆盖率最大化，而没有考虑探索不同执行路径的能量成本。持续模糊测试活动消耗大量计算资源并产生显著的碳足迹。

Method: GreenAFL对传统模糊测试工作流进行了两个关键修改：能量感知的语料库最小化（在减少初始语料库时考虑功耗）和能量引导的启发式算法（将变异导向高覆盖率、低能量的输入）。

Result: 消融研究表明，当至少使用一种修改时，能实现最高覆盖率和最低能量使用。

Conclusion: 将能量消耗纳入模糊测试启发式算法可以有效减少环境影响，同时保持测试覆盖率。

Abstract: Fuzzing has become a key search-based technique for software testing, but
continuous fuzzing campaigns consume substantial computational resources and
generate significant carbon footprints. Existing grey-box fuzzing approaches
like AFL++ focus primarily on coverage maximisation, without considering the
energy costs of exploring different execution paths. This paper presents
GreenAFL, an energy-aware framework that incorporates power consumption into
the fuzzing heuristics to reduce the environmental impact of automated testing
whilst maintaining coverage. GreenAFL introduces two key modifications to
traditional fuzzing workflows: energy-aware corpus minimisation considering
power consumption when reducing initial corpora, and energy-guided heuristics
that direct mutation towards high-coverage, low-energy inputs. We conduct an
ablation study comparing vanilla AFL++, energy-based corpus minimisation, and
energy-based heuristics to evaluate the individual contributions of each
component. Results show that highest coverage, and lowest energy usage is
achieved whenever at least one of our modifications is used.

</details>


### [23] [A Configuration-First Framework for Reproducible, Low-Code Localization](https://arxiv.org/abs/2510.25692)
*Tim Strnad,Blaž Bertalanič,Carolina Fortuna*

Main category: cs.SE

TL;DR: 提出了LOCALIZE框架，一个用于无线电定位的低代码配置优先框架，通过声明式配置和标准化工作流实现可复现的机器学习实验。


<details>
  <summary>Details</summary>
Motivation: 机器学习在无线电定位服务中应用日益广泛，但现有工具难以同时满足低编码工作量、默认可复现性和内置可扩展性这三个关键需求。

Method: 采用配置优先方法，实验通过人类可读的配置文件声明，工作流编排器运行从数据准备到报告的标准化流水线，所有工件（数据集、模型、指标、报告）都进行版本控制。

Result: 与普通Jupyter笔记本基线相比，该框架减少了编写工作量，同时保持了相当的运行时和内存行为；使用蓝牙低功耗数据集的实验表明，随着数据量增长（1倍到10倍），编排开销保持有界。

Conclusion: 该框架使基于机器学习的可复现定位实验变得实用、易访问且可扩展。

Abstract: Machine learning is increasingly permeating radio-based localization
services. To keep results credible and comparable, everyday workflows should
make rigorous experiment specification and exact repeatability the default,
without blocking advanced experimentation. However, in practice, researchers
face a three-way gap that could be filled by a framework that offers (i) low
coding effort for end-to-end studies, (ii) reproducibility by default including
versioned code, data, and configurations, controlled randomness, isolated runs,
and recorded artifacts, and (iii) built-in extensibility so new models,
metrics, and stages can be added with minimal integration effort. Existing
tools rarely deliver all three for machine learning in general and localization
workflows in particular. In this paper we introduce LOCALIZE, a low-code,
configuration-first framework for radio localization in which experiments are
declared in human-readable configuration, a workflow orchestrator runs
standardized pipelines from data preparation to reporting, and all artifacts,
such as datasets, models, metrics, and reports, are versioned. The
preconfigured, versioned datasets reduce initial setup and boilerplate,
speeding up model development and evaluation. The design, with clear extension
points, allows experts to add components without reworking the infrastructure.
In a qualitative comparison and a head-to-head study against a plain Jupyter
notebook baseline, we show that the framework reduces authoring effort while
maintaining comparable runtime and memory behavior. Furthermore, using a
Bluetooth Low Energy dataset, we show that scaling across training data (1x to
10x) keeps orchestration overheads bounded as data grows. Overall, the
framework makes reproducible machine-learning-based localization
experimentation practical, accessible, and extensible.

</details>


### [24] [Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents](https://arxiv.org/abs/2510.25694)
*Jiayi Kuang,Yinghui Li,Xin Zhang,Yangning Li,Di Yin,Xing Sun,Ying Shen,Philip S. Yu*

Main category: cs.SE

TL;DR: Enconda-bench是一个环境配置诊断基准，提供过程级轨迹评估，用于分析LLM代理在环境设置中的细粒度能力，包括规划、错误诊断、反馈驱动修复等环节。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估端到端的构建/测试成功率，无法揭示代理在何处以及为何成功或失败，环境配置仍然是软件工程中的瓶颈。

Method: 通过注入真实的README错误自动构建任务实例，在Docker中进行验证，结合过程级分析和端到端可执行性评估代理能力。

Result: 评估表明，代理能够定位错误，但难以将反馈转化为有效修正，限制了端到端性能。

Conclusion: Enconda-bench是首个为环境配置提供过程级内部能力评估的框架，为改进软件工程代理提供了可操作的见解。

Abstract: Large language model-based agents show promise for software engineering, but
environment configuration remains a bottleneck due to heavy manual effort and
scarce large-scale, high-quality datasets. Existing benchmarks assess only
end-to-end build/test success, obscuring where and why agents succeed or fail.
We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,
which provides process-level trajectory assessment of fine-grained agent
capabilities during environment setup-planning, perception-driven error
diagnosis, feedback-driven repair, and action to execute final environment
configuration. Our task instances are automatically constructed by injecting
realistic README errors and are validated in Docker for scalable, high-quality
evaluation. Enconda-bench combines process-level analysis with end-to-end
executability to enable capability assessments beyond aggregate success rates.
Evaluations across state-of-the-art LLMs and agent frameworks show that while
agents can localize errors, they struggle to translate feedback into effective
corrections, limiting end-to-end performance. To our knowledge, Enconda-bench
is the first framework to provide process-level internal capability assessment
for environment configuration, offering actionable insights for improving
software engineering agents.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [25] [Have a thing? Reasoning around recursion with dynamic typing in grounded arithmetic](https://arxiv.org/abs/2510.25369)
*Elliot Bobrow,Bryan Ford,Stefan Milenković*

Main category: cs.PL

TL;DR: GA是一种允许直接表达任意递归定义的形式推理基础，通过调整传统推理规则使非终止计算无害地表示无语义值，避免逻辑悖论。


<details>
  <summary>Details</summary>
Motivation: 经典逻辑和直觉主义逻辑传统无法直接表达任意一般递归函数而不导致不一致性，需要一种能安全处理非终止计算的形式推理基础。

Method: 引入基础算术(GA)，调整传统推理规则，使非终止计算项表示无语义值；通过"动态类型"或符号反向执行来证明递归函数的终止性。

Result: GA允许直接表达任意递归定义，一旦证明函数终止，逻辑推理可还原为经典规则；在Isabelle/HOL中已验证其无量化片段的一致性。

Conclusion: GA展示了将任意递归定义的表达自由融入形式系统的可行性，是迈向实用计算推理的重要第一步。

Abstract: Neither the classical nor intuitionistic logic traditions are
perfectly-aligned with the purpose of reasoning about computation, in that
neither logical tradition can normally permit the direct expression of
arbitrary general-recursive functions without inconsistency. We introduce
grounded arithmetic or GA, a minimalistic but nonetheless powerful foundation
for formal reasoning that allows the direct expression of arbitrary recursive
definitions. GA adjusts the traditional inference rules such that terms that
express nonterminating computations harmlessly denote no semantic value (i.e.,
"bottom") instead of leading into logical paradox or inconsistency. Recursive
functions may be proven terminating in GA essentially by "dynamically typing"
terms, or equivalently, symbolically reverse-executing the computations they
denote via GA's inference rules. Once recursive functions have been proven
terminating, logical reasoning about their results reduce to the familiar
classical rules. A mechanically-checked consistency proof in Isabelle/HOL
exists for the basic quantifier-free fragment of GA. Quantifiers may be added
atop this foundation as ordinary computations, whose inference rules are thus
admissible and do not introduce new inconsistency risks. While GA is only a
first step towards richly-typed grounded deduction practical for everyday use
in manual or automated computational reasoning, it shows the promise that the
expressive freedom of arbitrary recursive definition can in principle be
incorporated into formal systems.

</details>


### [26] [The Singularity Theory of Concurrent Programs: A Topological Characterization and Detection of Deadlocks and Livelocks](https://arxiv.org/abs/2510.25112)
*Di Zhang*

Main category: cs.PL

TL;DR: 提出并发程序分析与验证的新范式——奇点理论，将并发程序执行空间建模为分支拓扑空间，使用代数拓扑工具检测死锁和活锁等并发异常。


<details>
  <summary>Details</summary>
Motivation: 建立并发程序验证的几何拓扑基础，超越传统模型检测的局限性，避免穷举所有状态。

Method: 将程序执行空间建模为分支拓扑空间，状态为点，状态转移为路径；使用同伦群和同调群等代数拓扑工具定义并发拓扑不变量。

Result: 能够系统性地检测和分类死锁（吸引子）和活锁（不可收缩环）等并发"奇点"。

Conclusion: 为并发程序验证提供了几何拓扑基础的新范式，能够有效识别并发异常而无需遍历所有状态。

Abstract: This paper introduces a novel paradigm for the analysis and verification of
concurrent programs -- the Singularity Theory. We model the execution space of
a concurrent program as a branched topological space, where program states are
points and state transitions are paths. Within this framework, we characterize
deadlocks as attractors and livelocks as non-contractible loops in the
execution space. By employing tools from algebraic topology, particularly
homotopy and homology groups, we define a series of concurrent topological
invariants to systematically detect and classify these concurrent
"singularities" without exhaustively traversing all states. This work aims to
establish a geometric and topological foundation for concurrent program
verification, transcending the limitations of traditional model checking.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [27] [Systems of Graph Formulas and their Equivalence to Alternating Graph Automata](https://arxiv.org/abs/2510.25260)
*Frank Drewes,Berthold Hoffmann,Mark Minas*

Main category: cs.FL

TL;DR: 本文介绍了一种带有变量的图公式系统，用于指定图属性，并证明其与交替图自动机具有相同的表达能力。


<details>
  <summary>Details</summary>
Motivation: 图建模在计算机科学中具有基础性作用，需要发展能够表达图属性的形式化方法，特别是能够处理递归的逻辑系统。

Method: 引入了包含变量的图公式系统，扩展了之前的图公式概念，并提供了图公式系统与交替图自动机之间的双向转换。

Result: 证明了图公式系统与交替图自动机在指定图语言方面具有相同的表达能力，建立了自动机理论和逻辑方法之间的桥梁。

Conclusion: 交替图自动机可以通过基于逻辑的公式系统自然表示，这统一了图语言规范的自动机理论和逻辑方法。

Abstract: Graph-based modeling plays a fundamental role in many areas of computer
science. In this paper, we introduce systems of graph formulas with variables
for specifying graph properties; this notion generalizes the graph formulas
introduced in earlier work by incorporating recursion. We show that these
formula systems have the same expressive power as alternating graph automata, a
computational model that extends traditional finite-state automata to graphs,
and allows both existential and universal states. In particular, we provide a
bidirectional translation between formula systems and alternating graph
automata, proving their equivalence in specifying graph languages. This result
implies that alternating graph automata can be naturally represented using
logic-based formulations, thus bridging the gap between automata-theoretic and
logic-based approaches to graph language specification.

</details>
