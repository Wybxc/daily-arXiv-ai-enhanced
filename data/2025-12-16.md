<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 30]
- [cs.LO](#cs.LO) [Total: 4]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Probabilistic Programming Meets Automata Theory: Exact Inference using Weighted Automata](https://arxiv.org/abs/2512.13185)
*Dominik Geißler,Tobias Winkler*

Main category: cs.FL

TL;DR: 使用加权自动机对离散概率程序进行精确推理，通过将程序变量分布编码为加权自动机来实现


<details>
  <summary>Details</summary>
Motivation: 概率程序在机器学习和自主系统建模中有广泛应用，需要分析数值属性如概率和期望，其中后验分布是特别重要的定量属性

Method: 使用加权自动机（有限自动机的推广）对受限类别的离散概率程序进行精确推理，将程序变量分布编码为加权自动机，程序语义对应自动机理论构造

Result: 提出了一种基于加权自动机的方法，能够对离散概率程序进行精确推理，处理可能具有无限支持的分布

Conclusion: 加权自动机为概率程序的精确推理提供了有效的框架，通过自动机理论构造对应程序语义，能够处理复杂的分布计算问题

Abstract: Probabilistic programs encode stochastic models as ordinary-looking programs with primitives for sampling numbers from predefined distributions and conditioning. Their applications include, among many others, machine learning and modeling of autonomous systems. The analysis of probabilistic programs is often quantitative - it involves reasoning about numerical properties like probabilities and expectations. A particularly important quantitative property of probabilistic programs is their posterior distribution, i.e., the distribution over possible outputs for a given input (or prior) distribution. Computing the posterior distribution exactly is known as exact inference. We present our current research using weighted automata, a generalization of the well-known finite automata, for performing exact inference in a restricted class of discrete probabilistic programs. This is achieved by encoding distributions over program variables - possibly with infinite support - as certain weighted automata. The semantics of our programming language then corresponds to common automata-theoretic constructions, such as product, concatenation, and others.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Vibe Coding in Practice: Flow, Technical Debt, and Guidelines for Sustainable Use](https://arxiv.org/abs/2512.11922)
*Muhammad Waseem,Aakash Ahmad,Kai-Kristian Kemell,Jussi Rasku,Sami Lahti,Kalle Mäkelä,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: Vibe Coding (VC) 是一种由生成式AI辅助的软件开发方式，通过自然语言提示生成代码，虽然能快速构建MVP，但会导致技术债务积累，需要在流程效率和技术债务之间权衡。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在软件开发中的应用日益普及，Vibe Coding成为快速原型开发和MVP构建的有效工具。然而，这种看似无缝的代码生成过程可能带来隐藏的技术债务风险，包括架构不一致、安全漏洞和维护负担增加等问题。本文旨在分析VC带来的流程效率与技术债务之间的权衡问题。

Method: 基于多个内部开发的MVP项目的实践经验，结合对近期行业报告的回顾，分析VC带来的流程债务权衡。识别当前模型、平台和硬件限制如何导致这些问题，并提出相应的对策措施。

Result: 研究发现VC在实现快速代码生成的同时，会积累技术债务，主要源于流程层面的弱点、模型训练数据的偏差、缺乏明确的设计原理，以及过度追求快速生成而非人工驱动的迭代开发。这些问题导致架构不一致、安全漏洞和维护开销增加。

Conclusion: 需要采取对策来缓解VC带来的技术债务问题，包括改进模型训练、优化开发流程、加强人工审查等，以推动更可持续的Vibe Coding实践。这为研究和实践提供了方向，帮助实现AI辅助开发的长期可持续性。

Abstract: Vibe Coding (VC) is a form of software development assisted by generative AI, in which developers describe the intended functionality or logic via natural language prompts, and the AI system generates the corresponding source code. VC can be leveraged for rapid prototyping or developing the Minimum Viable Products (MVPs); however, it may introduce several risks throughout the software development life cycle. Based on our experience from several internally developed MVPs and a review of recent industry reports, this article analyzes the flow-debt tradeoffs associated with VC. The flow-debt trade-off arises when the seamless code generation occurs, leading to the accumulation of technical debt through architectural inconsistencies, security vulnerabilities, and increased maintenance overhead. These issues originate from process-level weaknesses, biases in model training data, a lack of explicit design rationale, and a tendency to prioritize quick code generation over human-driven iterative development. Based on our experiences, we identify and explain how current model, platform, and hardware limitations contribute to these issues, and propose countermeasures to address them, informing research and practice towards more sustainable VC approaches.

</details>


### [3] [Fine-tuned LLM-based Code Migration Framework](https://arxiv.org/abs/2512.13515)
*Oleg Grynets,Vasyl Lyashkevych,Dmytro Baran,Maksym Orliansky,Taras Zelenyy,Markiian Leshchyshyn*

Main category: cs.SE

TL;DR: 该研究提出了一种基于微调大语言模型的自动化代码库迁移框架，专注于解决SQL系统从Oracle PL/SQL到PostgreSQL的转换挑战，通过迭代迁移流程显著降低语法错误率并提升特征对齐。


<details>
  <summary>Details</summary>
Motivation: 传统SQL系统迁移面临语法映射、存储过程/触发器/视图转换等复杂挑战，需要高效、精确且可扩展的自动化解决方案来替代传统人工迁移方法。

Method: 提出集成微调大语言模型的框架，结合传统软件工程技术，采用迭代迁移流程，包括SQL特征自动检测、半监督错误分析、领域专家反馈集成，并在微调与提示工程之间取得平衡。

Result: 框架显著降低语法错误率，提升迁移迭代中的特征对齐，通过数据集采样实现持续改进，增强了工作流效率，证明微调在迁移过程中起关键作用。

Conclusion: 该研究展示了基于大语言模型的自动化迁移框架在SQL系统转换中的有效性，通过精细的微调策略和系统化工作流，为现代数据库转型提供了精确、高效且可扩展的解决方案。

Abstract: The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.

</details>


### [4] [A Systematic Mapping Study on Risks and Vulnerabilities in Software Containers](https://arxiv.org/abs/2512.11940)
*Maha Sroor,Teerath Das,Rahul Mohanani,Tommi Mikkonen*

Main category: cs.SE

TL;DR: 该论文通过系统映射研究分析了软件容器系统的安全风险、漏洞、实践和工具，提出了分类法并提供了缓解技术。


<details>
  <summary>Details</summary>
Motivation: 软件容器虽广泛应用但存在重大安全担忧，而软件工程研究缺乏对容器系统开发部署中风险、漏洞、安全实践和工具的综述性、聚合性和组织性知识。

Method: 基于129篇选定的一手研究进行系统映射研究，探索和组织软件容器系统安全问题的现有知识，使用新分类法对容器生命周期中的风险漏洞进行分类。

Result: 识别了容器生命周期中的关键风险和漏洞，分析了原因和影响，提供了缓解技术列表，并聚合了安全实践和工具以改善容器系统整体安全性。

Conclusion: 研究揭示了软件容器系统安全问题的现状，强调未来软件工程研究需要关注增强容器系统安全性的实践，并制定有效的缓解策略以全面解决现有风险和漏洞。

Abstract: Software containers are widely adopted for developing and deploying software applications. Despite their popularity, major security concerns arise during container development and deployment. Software Engineering (SE) research literature reveals a lack of reviewed, aggregated, and organized knowledge of risks, vulnerabilities, security practices, and tools in container-based systems development and deployment. Therefore, we conducted a Systematic Mapping Study (SMS) based on 129 selected primary studies to explore and organize existing knowledge on security issues in software container systems. Data from the primary studies enabled us to identify critical risks and vulnerabilities across the container life-cycle and categorize them using a novel taxonomy. Additionally, the findings highlight the causes and implications and provide a list of mitigation techniques to overcome these risks and vulnerabilities. Furthermore, we provide an aggregation of security practices and tools that can help support and improve the overall security of container systems. This study offers critical insights into the current landscape of security issues within software container systems. Our analysis highlights the need for future SE research to focus on security enhancement practices that strengthen container systems and develop effective mitigation strategies to comprehensively address existing risks and vulnerabilities.

</details>


### [5] [Evidence-Driven Decision Support for AI Model Selection in Research Software Engineering](https://arxiv.org/abs/2512.11984)
*Alireza Joonbakhsh,Alireza Rostami,AmirMohammad Kamalinia,Ali Nazeri,Farshad Khunjush,Bedir Tekinerdogan,Siamak Farshidi*

Main category: cs.SE

TL;DR: 提出一个基于证据的AI模型选择框架ModelSelect，将模型选择视为多准则决策问题，通过知识图谱和自动化数据收集提供可解释、可复现的推荐。


<details>
  <summary>Details</summary>
Motivation: AI模型和方法的快速扩散给研究软件工程师和研究人员带来了挑战，他们需要在复杂研究流程中选择、集成和维护合适的模型。当前模型选择往往依赖零散的元数据和个体经验，这种临时性方法会损害可复现性、透明度和研究软件质量。

Method: 将AI模型选择概念化为多准则决策问题，提出基于证据的决策支持框架ModelSelect，集成自动化数据收集管道、结构化知识图谱和多准则决策原则。采用设计科学研究方法，通过50个真实案例研究和与领先生成AI系统的对比实验进行实证验证。

Result: ModelSelect产生可靠、可解释、可复现的推荐，与专家推理高度一致。在案例研究中，框架在模型和库推荐任务上实现了高覆盖率和强理由对齐，与生成AI助手性能相当，同时提供更好的可追溯性和一致性。

Conclusion: 通过将AI模型选择构建为多准则决策问题，为研究软件工程中的透明和可复现决策支持建立了严谨基础。该框架为将经验证据集成到AI模型推荐过程中提供了可扩展和可解释的途径，最终提高了研究软件决策的质量和鲁棒性。

Abstract: The rapid proliferation of artificial intelligence (AI) models and methods presents growing challenges for research software engineers and researchers who must select, integrate, and maintain appropriate models within complex research workflows. Model selection is often performed in an ad hoc manner, relying on fragmented metadata and individual expertise, which can undermine reproducibility, transparency, and overall research software quality.
  This work proposes a structured and evidence-driven approach to support AI model selection that aligns with both technical and contextual requirements. We conceptualize AI model selection as a Multi-Criteria Decision-Making (MCDM) problem and introduce an evidence-based decision-support framework that integrates automated data collection pipelines, a structured knowledge graph, and MCDM principles. Following the Design Science Research methodology, the proposed framework (ModelSelect) is empirically validated through 50 real-world case studies and comparative experiments against leading generative AI systems.
  The evaluation results show that ModelSelect produces reliable, interpretable, and reproducible recommendations that closely align with expert reasoning. Across the case studies, the framework achieved high coverage and strong rationale alignment in both model and library recommendation tasks, performing comparably to generative AI assistants while offering superior traceability and consistency.
  By framing AI model selection as an MCDM problem, this work establishes a rigorous foundation for transparent and reproducible decision support in research software engineering. The proposed framework provides a scalable and explainable pathway for integrating empirical evidence into AI model recommendation processes, ultimately improving the quality and robustness of research software decision-making.

</details>


### [6] [Re-opening open-source science through AI assisted development](https://arxiv.org/abs/2512.11993)
*Ling-Hong Hung,Ka Yee Yeung*

Main category: cs.SE

TL;DR: AI团队主导的STAR-Flex项目成功分叉STAR代码库，添加1.6万行C++代码以支持10x Flex数据处理，成为首个开源Flex数据处理软件


<details>
  <summary>Details</summary>
Motivation: 开源科学软件因代码复杂而难以修改，限制了社区参与和功能扩展。需要一种方法让社区能够审查和验证AI生成的代码，重新开放科学软件给社区贡献

Method: 采用AI代理团队（由单个人类领导）快速稳健地修改大型代码库。通过案例研究STAR-Flex，分叉STAR代码库，添加1.6万行C++代码，同时保持原有全部功能

Result: 成功创建了STAR-Flex，这是首个支持10x Flex数据的开源处理软件，作为NIH资助的MorPHiC联盟项目的一部分完成

Conclusion: AI代理团队能够有效解决复杂科学软件难以修改的问题，重新开放科学软件给社区审查和验证，展示了AI在代码修改和科学软件发展中的潜力

Abstract: Open-source scientific software is effectively closed to modification by its complexity. With recent advances in technology, an agentic AI team led by a single human can now rapidly and robustly modify large codebases and re-open science to the community which can review and vet the AI generated code. We demonstrate this with a case study, STAR-Flex, which is an open source fork of STAR, adding 16,000 lines of C++ code to add the ability to process 10x Flex data, while maintaining full original function. This is the first open-source processing software for Flex data and was written as part of the NIH funded MorPHiC consortium.

</details>


### [7] [A Reference Architecture for Embedding Quantum Software Into Enterprise Systems](https://arxiv.org/abs/2512.12009)
*Marc Uphues,Sebastian Thöne,Herbert Kuchen*

Main category: cs.SE

TL;DR: 提出一个模块化参考架构，用于将量子软件嵌入企业系统，通过松耦合服务实现量子无关和量子特定任务，形成可执行的BPMN管道


<details>
  <summary>Details</summary>
Motivation: 量子计算能为企业系统解决计算密集型问题提供性能提升，但企业软件架构需要考虑与量子计算服务协作时的特定特性和质量属性

Method: 设计模块化参考架构，包含松耦合的分布式服务，实现量子无关和量子特定任务，通过可执行的BPMN模型编排这些服务形成稳定可重用的管道

Result: 提出的参考架构在两个解决运筹学组合挑战的案例研究中进行了演示和评估

Conclusion: 该参考架构为企业系统集成量子软件提供了可行的解决方案，通过模块化设计和BPMN编排实现了稳定可重用的量子计算集成管道

Abstract: Quantum computing promises a remarkable performance boost for certain applications, including computational intensive problems addressed by enterprise systems. However, software architectures of enterprise systems must consider specific characteristics and quality attributes when collaborating with quantum computing services. Hence, this paper presents a modular reference architecture for embedding quantum software into enterprise systems. Its building blocks consist of loosely coupled and distributed services that implement both quantum-independent and quantum-specific tasks. Although these services either depend on the business domain or the selected quantum algorithm, their orchestration forms a stable and reusable pipeline, specified as an executable BPMN model. For demonstration and evaluation purposes, the proposed reference architecture is utilized in two case studies addressing combinatorial challenges from the field of operations research.

</details>


### [8] [Hyper model checking for high-level relational models](https://arxiv.org/abs/2512.12024)
*Nuno Macedo,Hugo Pacheco*

Main category: cs.SE

TL;DR: 扩展Alloy的Pardinus后端以支持超属性的自动验证，提出HyperPardinus工具


<details>
  <summary>Details</summary>
Motivation: 现有高级规范语言缺乏对超属性的支持，而超属性对安全和并发验证至关重要。Alloy适合早期设计验证但不原生支持超属性验证。

Method: 扩展Pardinus（Alloy的时序逻辑后端）为HyperPardinus，利用现有低级超属性模型检查器，在关系模型上自动验证超属性，并保守扩展Alloy支持超属性规范和验证。

Result: HyperPardinus能够建模和发现具有交替量词的复杂超属性的（反）示例，能够处理相关领域的重要场景。

Conclusion: 提出的方法使工程师能够在早期设计阶段验证超属性，填补了高级规范语言在超属性验证方面的空白。

Abstract: Many properties related to security or concurrency must be encoded as so-called hyperproperties, temporal properties that allow reasoning about multiple traces of a system. However, despite recent advances on model checking hyperproperties, there is still a lack of higher-level specification languages that can effectively support software engineering practitioners in verifying properties of this class at early stages of system design.
  Alloy is a lightweight formal method with a high-level specification language that is supported by automated analysis procedures, making it particularly well-suited for the verification of design models at early development stages. It does not natively support, however, the verification of hyperproperties.
  This work proposes HyperPardinus, a new model finding procedure that extends Pardinus -- the temporal logic backend of the Alloy language -- to automatically verify hyperproperties over relational models by relying on existing low-level model checkers for hyperproperties. It then conservatively extends Alloy to support the specification and automatic verification of hyperproperties over design models, as well as the visualization of (counter-)examples at a higher-level of abstraction. Evaluation shows that our approach enables modeling and finding (counter-)examples for complex hyperproperties with alternating quantifiers, making it feasible to address relevant scenarios from the state of the art.

</details>


### [9] [Instruction-Tuning Open-Weight Language Models for BPMN Model Generation](https://arxiv.org/abs/2512.12063)
*Gökberk Çelikmasat,Atay Özgövde,Fatma Başak Aydemir*

Main category: cs.SE

TL;DR: InstruBPM：通过指令微调开源大语言模型，从自然语言描述直接生成高质量BPMN流程模型，降低建模成本并保护隐私


<details>
  <summary>Details</summary>
Motivation: 领域模型对软件工程至关重要，但实践者常因建模耗时且需要专业知识而跳过建模。需要一种成本效益高且保护隐私的方法来自动生成流程模型。

Method: 提出InstruBPM方法：准备文本-图表配对数据，使用参数高效微调和量化技术对开源大语言模型进行指令微调，支持本地部署。通过文本/代码相似度、结构保真度、规范符合性和专家评审等多角度评估。

Result: 微调后的紧凑模型在所有基线模型中表现最佳，在序列和结构指标上均优于未微调的开源模型和强大的专有模型。生成的图表基本遵循BPMN最佳实践，可作为减少建模工作量的有用起点。

Conclusion: 指令微调相比未微调基线提高了结构准确性和鲁棒性，减少了对复杂提示工程的依赖。该方法为高质量BPMN模型生成提供了成本效益高且保护隐私的解决方案。

Abstract: Domain models are central to software engineering, as they enable a shared understanding, guide implementation, and support automated analyses and model-driven development. Yet, despite these benefits, practitioners often skip modeling because it is time-consuming and demands scarce expertise. We address this barrier by investigating whether open-weight large language models, adapted via instruction tuning, can generate high-quality BPMN process models directly from natural language descriptions in a cost-effective and privacy-preserving way. We introduce InstruBPM, a reproducible approach that prepares paired text-diagram data and instruction tunes an open source large language model with parameter-efficient fine-tuning and quantization for on-prem deployment. We evaluate the tuned model through complementary perspectives: (i) text/code similarity using BLEU, ROUGE-L, and METEOR, (ii) structural fidelity using Relative Graph Edit Distance, (iii) guidelines conformance using external tool checks, and (iv) a small expert review. Using a curated subset of a multi-domain BPMN dataset, we compare the tuned model with untuned open-weight baselines and strong proprietary models under consistent prompting regimes. Our compact tuned model outperforms all baselines across sequence and structural metrics while requiring substantially fewer resources; guideline analysis and expert feedback further indicate that the generated diagrams largely follow BPMN best practices and are useful starting points that reduce modeling effort. Overall, instruction tuning improves structural accuracy and robustness compared to untuned baselines and reduces reliance on heavy prompt scaffolding. We publicly share the trained models and scripts to support reproducibility and further research.

</details>


### [10] [Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context](https://arxiv.org/abs/2512.12117)
*Jahidul Arafat*

Main category: cs.SE

TL;DR: 论文提出混合检索系统，结合稀疏匹配、密集嵌入和代码结构图扩展，解决LLM代码理解中的引用幻觉问题，在30个Python仓库上实现92%的引用准确率和零幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码理解中存在引用幻觉问题，生成看似合理但事实错误的源代码引用，这是可靠开发者辅助工具的关键障碍。现有系统主要依赖纯文本相似性，忽略了代码结构中的跨文件架构依赖关系。

Method: 开发混合检索系统，结合BM25稀疏匹配、BGE密集嵌入和Neo4j图扩展（通过导入关系）。系统采用轻量级结构推理，通过代码结构发现跨文件证据，实现可验证的引用基础代码理解。

Result: 在30个Python仓库的180个开发者查询评估中，系统达到92%的引用准确率和零幻觉。混合检索比单模式基线提高14-18个百分点，在62%的架构查询中发现了纯文本相似性遗漏的跨文件证据。

Conclusion: 应将引用基础生成作为代码理解系统的架构原则。跨文件证据发现对引用完整性贡献最大，但常被忽视。混合检索结合文本相似性和代码结构能有效解决引用幻觉问题。

Abstract: Large language models have become essential tools for code comprehension, enabling developers to query unfamiliar codebases through natural language interfaces. However, LLM hallucination, generating plausible but factually incorrect citations to source code, remains a critical barrier to reliable developer assistance. This paper addresses the challenges of achieving verifiable, citation grounded code comprehension through hybrid retrieval and lightweight structural reasoning. Our work is grounded in systematic evaluation across 30 Python repositories with 180 developer queries, comparing retrieval modalities, graph expansion strategies, and citation verification mechanisms. We find that challenges of citation accuracy arise from the interplay between sparse lexical matching, dense semantic similarity, and cross file architectural dependencies. Among these, cross file evidence discovery is the largest contributor to citation completeness, but it is largely overlooked because existing systems rely on pure textual similarity without leveraging code structure. We advocate for citation grounded generation as an architectural principle for code comprehension systems and demonstrate this need by achieving 92 percent citation accuracy with zero hallucinations. Specifically, we develop a hybrid retrieval system combining BM25 sparse matching, BGE dense embeddings, and Neo4j graph expansion via import relationships, which outperforms single mode baselines by 14 to 18 percentage points while discovering cross file evidence missed by pure text similarity in 62 percent of architectural queries.

</details>


### [11] [Training Versatile Coding Agents in Synthetic Environments](https://arxiv.org/abs/2512.12216)
*Yiqi Zhu,Apurva Gandhi,Graham Neubig*

Main category: cs.SE

TL;DR: SWE-Playground：一个通过语言模型和智能体从头生成项目和任务的合成环境管道，用于训练多功能编码智能体，相比现有方法更灵活且支持更广泛的软件工程任务。


<details>
  <summary>Details</summary>
Motivation: 现有软件工程智能体训练方法存在两个主要限制：1）依赖GitHub仓库等现有资源，灵活性有限；2）主要关注问题解决任务，无法覆盖软件工程师需要处理的各种任务类型。

Method: 提出SWE-Playground管道，使用强大的语言模型和智能体从头合成生成项目和任务，无需依赖外部数据源。该方法支持生成单元测试、从头实现库等多种编码任务。

Result: 在三个不同基准测试上验证了方法的有效性。结果表明，SWE-Playground生成的轨迹具有密集的训练信号，使智能体能够用比先前工作显著更少的轨迹达到可比较的性能。

Conclusion: SWE-Playground提供了一种灵活、通用的软件工程智能体训练方法，能够生成多样化的编码任务环境，相比依赖现有资源的方法具有更好的扩展性和适应性。

Abstract: Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.

</details>


### [12] [Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction](https://arxiv.org/abs/2512.12224)
*Maaz Khan,Gul Sher Khan,Ahsan Raza,Pir Sami Ullah,Abdul Ali Bangash*

Main category: cs.SE

TL;DR: 提出一种基于LLM的集群引导匿名化技术，用于JIT缺陷预测数据，在保持预测准确性的同时显著提升隐私保护水平。


<details>
  <summary>Details</summary>
Motivation: 机器学习在JIT缺陷预测中的使用增加引发了对软件分析数据隐私泄露的担忧。现有的匿名化方法（如表格转换和图扰动）往往忽略软件指标之间的上下文依赖关系，导致隐私-效用权衡不理想。

Method: 提出集群引导的匿名化技术：1）将提交按特征分组为集群；2）使用LLM为每个提交集群生成上下文感知的参数配置，定义alpha-beta比率和变更混合分布用于匿名化。

Result: 在六个项目（Cassandra、Flink、Groovy、Ignite、OpenStack、Qt）上的评估显示，该方法达到隐私级别2（IPR≥80%），相比四种最先进的基于图的匿名化基线，隐私保护提升18-25%，同时保持可比的F1分数。

Conclusion: LLM可以作为自适应匿名化引擎，当提供集群特定的统计信息时，能够实现上下文敏感且隐私保护的软件分析，而不损害预测准确性。

Abstract: The increasing use of machine learning (ML) for Just-In-Time (JIT) defect prediction raises concerns about privacy leakage from software analytics data. Existing anonymization methods, such as tabular transformations and graph perturbations, often overlook contextual dependencies among software metrics, leading to suboptimal privacy-utility tradeoffs. Leveraging the contextual reasoning of Large Language Models (LLMs), we propose a cluster-guided anonymization technique that preserves contextual and statistical relationships within JIT datasets. Our method groups commits into feature-based clusters and employs an LLM to generate context-aware parameter configurations for each commit cluster, defining alpha-beta ratios and churn mixture distributions used for anonymization. Our evaluation on six projects (Cassandra, Flink, Groovy, Ignite, OpenStack, and Qt) shows that our LLM-based approach achieves privacy level 2 (IPR >= 80 percent), improving privacy by 18 to 25 percent over four state-of-the-art graph-based anonymization baselines while maintaining comparable F1 scores. Our results demonstrate that LLMs can act as adaptive anonymization engines when provided with cluster-specific statistical information about similar data points, enabling context-sensitive and privacy-preserving software analytics without compromising predictive accuracy.

</details>


### [13] [Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo](https://arxiv.org/abs/2512.12314)
*Anatoly A. Krasnovsky*

Main category: cs.SE

TL;DR: 论文提出了一种基于分布式追踪和蒙特卡洛模拟的微服务韧性模型，直接从OpenTelemetry追踪数据推导服务依赖图，并评估端点可用性。


<details>
  <summary>Details</summary>
Motivation: 当前微服务韧性模型大多需要手动构建且定制化程度高，缺乏自动化、基于实际追踪数据的系统性评估方法。

Method: 从原始OpenTelemetry追踪数据推导服务依赖图，添加端点特定的成功谓词，引入异步语义处理Kafka边缘（非阻塞），使用蒙特卡洛模拟估计端点可用性，并通过GitHub Actions工作流自动执行混沌实验验证。

Result: 模型能够准确重现整体可用性退化曲线，异步语义对Kafka边缘的预测可用性影响极小（约10^-5），表明对于该案例研究，简单的连接性模型已足够，无需显式建模异步依赖。

Conclusion: 对于即时HTTP可用性评估，基于追踪发现的连接性模型已足够准确，无需复杂的异步依赖建模，这简化了微服务韧性评估的复杂性。

Abstract: While distributed tracing and chaos engineering are becoming standard for microservices, resilience models remain largely manual and bespoke. We revisit a trace-discovered connectivity model that derives a service dependency graph from traces and uses Monte Carlo simulation to estimate endpoint availability under fail-stop service failures. Compared to earlier work, we (i) derive the graph directly from raw OpenTelemetry traces, (ii) attach endpoint-specific success predicates, and (iii) add a simple asynchronous semantics that treats Kafka edges as non-blocking for immediate HTTP success. We apply this model to the OpenTelemetry Demo ("Astronomy Shop") using a GitHub Actions workflow that discovers the graph, runs simulations, and executes chaos experiments that randomly kill microservices in a Docker Compose deployment. Across the studied failure fractions, the model reproduces the overall availability degradation curve, while asynchronous semantics for Kafka edges change predicted availabilities by at most about 10^(-5) (0.001 percentage points). This null result suggests that for immediate HTTP availability in this case study, explicitly modeling asynchronous dependencies is not warranted, and a simpler connectivity-only model is sufficient.

</details>


### [14] [The Role of AI in Modern Penetration Testing](https://arxiv.org/abs/2512.12326)
*J. Alexander Curtis,Nasir U. Eisty*

Main category: cs.SE

TL;DR: 本文通过系统文献综述分析了AI在渗透测试中的应用现状，发现RL是主要研究方向（占77%），AI在发现和利用阶段表现突出，但实际应用有限且面临灵活性不足等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统渗透测试依赖人工、耗时且难以扩展，随着系统复杂度增加，需要更高效、可扩展的测试方法。AI技术有望自动化渗透测试过程，提高效率和效果。

Method: 采用系统文献综述方法，从主要学术数据库中筛选分析了58篇同行评审研究，系统评估AI在渗透测试各阶段的应用现状。

Result: 研究发现：1）AI辅助渗透测试仍处早期阶段；2）77%的研究聚焦强化学习；3）AI在发现和利用阶段表现最佳；4）实际应用有限但前景可期（如ESA的PenBox）；5）当前模型灵活性不足，侦察和后利用阶段发展不充分；6）LLM应用研究相对较少。

Conclusion: AI在渗透测试中展现出巨大潜力，特别是在自动化重复任务、优化攻击策略和漏洞识别方面。未来研究方向包括提高模型灵活性、加强侦察和后利用阶段研究，以及探索LLM在渗透测试中的应用。

Abstract: Penetration testing is a cornerstone of cybersecurity, traditionally driven by manual, time-intensive processes. As systems grow in complexity, there is a pressing need for more scalable and efficient testing methodologies. This systematic literature review examines how Artificial Intelligence (AI) is reshaping penetration testing, analyzing 58 peer-reviewed studies from major academic databases. Our findings reveal that while AI-assisted pentesting is still in its early stages, notable progress is underway, particularly through Reinforcement Learning (RL), which was the focus of 77% of the reviewed works. Most research centers on the discovery and exploitation phases of pentesting, where AI shows the greatest promise in automating repetitive tasks, optimizing attack strategies, and improving vulnerability identification. Real-world applications remain limited but encouraging, including the European Space Agency's PenBox and various open-source tools. These demonstrate AI's potential to streamline attack path analysis, analyze complex network topology, and reduce manual workload. However, challenges persist: current models often lack flexibility and are underdeveloped for the reconnaissance and post-exploitation phases of pentesting. Applications involving Large Language Models (LLMs) remain relatively under-researched, pointing to a promising direction for future exploration. This paper offers a critical overview of AI's current and potential role in penetration testing, providing valuable insights for researchers, practitioners, and organizations aiming to enhance security assessments through advanced automation or looking for gaps in existing research.

</details>


### [15] [ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs](https://arxiv.org/abs/2512.12507)
*Jaid Monwar Chowdhury,Ahmad Farhan Shahriar Chowdhury,Humayra Binte Monwar,Mahmuda Naznin*

Main category: cs.SE

TL;DR: ATLAS是一个用于C/C++代码分析的Python工具，能生成控制流图、数据流图和抽象语法树的多视图代码表示，支持多文件项目和非编译代码。


<details>
  <summary>Details</summary>
Motivation: 传统编程分析技术在处理现代复杂软件系统时存在不足，特别是对于C/C++语言，其扁平语法层次、指针别名、多级间接引用、typedef类型混淆和函数指针调用等问题阻碍了准确的静态分析。机器学习和大语言模型虽然提供有前景的解决方案，但受限于其对数据的解释方式，无法充分捕捉代码中复杂的远程结构关系和依赖。

Method: ATLAS是一个基于Python的命令行接口工具，具有以下功能：(1) 生成语句级控制流图和类型感知的数据流图，捕捉整个程序的函数间依赖；(2) 支持包含多个文件的完整C/C++项目；(3) 既能处理可编译代码也能处理不可编译代码；(4) 使用抽象语法树、控制流图和数据流图生成统一的多视图代码表示。

Result: ATLAS通过保留代码的基本结构和语义信息，为改进下游软件工程和基于机器学习的程序理解任务提供了实用基础。该工具已开源并提供视频演示。

Conclusion: ATLAS解决了C/C++代码分析中的关键挑战，通过生成多视图代码表示来捕捉代码的复杂结构关系和依赖，为软件工程任务和机器学习应用提供了更好的代码理解基础。

Abstract: The growing complexity of modern software systems has highlighted the shortcomings of traditional programming analysis techniques, particularly for Software Engineering (SE) tasks. While machine learning and Large Language Models (LLMs) offer promising solutions, their effectiveness is limited by the way they interpret data. Unlike natural language, source code meaning is defined less by token adjacency and more by complex, long-range, and structural relationships and dependencies. This limitation is especially pronounced for C and C++, where flatter syntactic hierarchies, pointer aliasing, multi-level indirection, typedef-based type obfuscation, and function-pointer calls hinder accurate static analysis. To address these challenges, this paper introduces ATLAS, a Python-based Command-Line Interface (CLI) that (i) generates statement-level Control Flow Graphs (CFG) and type-aware Data Flow Graphs (DFG) that capture inter-functional dependencies for the entire program; (ii) has the ability to work on entire C and C++ projects comprising multiple files; (iii) works on both compilable and non-compilable code and (iv) produces a unified multi-view code representation using Abstract Syntax Trees (AST), CFG and DFG. By preserving essential structural and semantic information, ATLAS provides a practical foundation for improving downstream SE and machine-learning-based program understanding. Video demonstration: https://youtu.be/RACWQe5ELwY Tool repository: https://github.com/jaid-monwar/ATLAS-code-representation-tool

</details>


### [16] [Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?](https://arxiv.org/abs/2512.12536)
*Arastoo Zibaeirad,Marco Vieira*

Main category: cs.SE

TL;DR: DVDR-LLM是一个集成多个大语言模型的框架，用于软件漏洞检测与修复，相比单个模型能提升10-12%的检测准确率，但对多文件漏洞的召回率和F1分数提升更显著。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在识别复杂漏洞和生成修复方案时存在困难，需要探索集成多个模型是否能减少错误率并提升性能。

Method: 提出DVDR-LLM集成框架，结合多个不同大语言模型的输出，通过设定模型间的一致性阈值来聚合结果。

Result: DVDR-LLM比单个模型平均性能提高10-12%的检测准确率，代码复杂度越高提升越明显；对多文件漏洞，召回率提升18%，F1分数提升11.8%。但存在权衡：验证任务中减少误报的同时，检测任务中增加了漏报。

Conclusion: 集成多个LLM能显著提升漏洞检测与修复性能，但需要根据具体安全场景谨慎选择模型间的一致性阈值，以平衡误报和漏报的权衡。

Abstract: Large Language Models (LLMs) are increasingly being studied for Software Vulnerability Detection (SVD) and Repair (SVR). Individual LLMs have demonstrated code understanding abilities, but they frequently struggle when identifying complex vulnerabilities and generating fixes.
  This study presents DVDR-LLM, an ensemble framework that combines outputs from diverse LLMs to determine whether aggregating multiple models reduces error rates. Our evaluation reveals that DVDR-LLM achieves 10-12% higher detection accuracy compared to the average performance of individual models, with benefits increasing as code complexity grows. For multi-file vulnerabilities, the ensemble approach demonstrates significant improvements in recall (+18%) and F1 score (+11.8%) over individual models. However, the approach raises measurable trade-offs: reducing false positives in verification tasks while simultaneously increasing false negatives in detection tasks, requiring careful decision on the required level of agreement among the LLMs (threshold) for increased performance across different security contexts.
  Artifact: https://github.com/Erroristotle/DVDR_LLM

</details>


### [17] [Assessing the Capability of Android Dynamic Analysis Tools to Combat Anti-Runtime Analysis Techniques](https://arxiv.org/abs/2512.12551)
*Dewen Suo,Lei Xue,Weihao Huang,Runze Tan,Guozi Sun*

Main category: cs.SE

TL;DR: 现有Android动态分析工具在对抗反运行时分析技术方面存在严重不足，需要更强大的解决方案


<details>
  <summary>Details</summary>
Motivation: Android应用数量快速增长，但恶意应用采用反运行时分析技术阻碍了安全专业人员使用动态分析工具有效分析恶意行为，这对平台安全构成严重威胁

Method: 对广泛使用的Android动态分析工具进行全面的实证研究，评估它们绕过各种反运行时分析技术的能力

Result: 研究发现现有动态分析工具在对抗反运行时分析机制方面存在关键性缺陷，效果有限

Conclusion: 需要改进方法来对抗反运行时分析技术，这对推进软件安全和动态分析领域发展至关重要

Abstract: As the dominant mobile operating system, Android continues to attract a substantial influx of new applications each year. However, this growth is accompanied by increased attention from malicious actors, resulting in a significant rise in security threats to the Android ecosystem. Among these threats, the adoption of Anti-Runtime Analysis (ARA) techniques by malicious applications poses a serious challenge, as it hinders security professionals from effectively analyzing malicious behaviors using dynamic analysis tools. ARA technologies are designed to prevent the dynamic examination of applications, thus complicating efforts to ensure platform security. This paper presents a comprehensive empirical study that assesses the ability of widely-used Android dynamic analysis tools to bypass various ARA techniques. Our findings reveal a critical gap in the effectiveness of existing dynamic analysis tools to counter ARA mechanisms, highlighting an urgent need for more robust solutions. This work provides valuable insights into the limitations of existing tools and highlights the need for improved methods to counteract ARA technologies, thus advancing the field of software security and dynamic analysis.

</details>


### [18] [SHERLOCK: A Deep Learning Approach To Detect Software Vulnerabilities](https://arxiv.org/abs/2512.12593)
*Saadh Jawwadh,Guhanathan Poravi*

Main category: cs.SE

TL;DR: 使用卷积神经网络(CNN)检测软件漏洞，在函数级别成功识别多种漏洞类型，对特定CWE类别表现优异，但数据集标准化不足影响部分漏洞检测可靠性。


<details>
  <summary>Details</summary>
Motivation: 软件在各领域应用日益广泛，软件漏洞可能导致安全漏洞、数据盗窃等严重后果。传统静态和动态分析技术在检测多种漏洞方面效果有限，需要更有效的检测方法。

Method: 采用深度学习中的卷积神经网络(CNN)方法，将标记化的源代码作为输入，使用5折交叉验证训练和评估模型。

Result: Sherlock系统在函数级别成功检测多种漏洞，对CWE-199、CWE-120和CWE-Other表现特别优异，整体准确率高，真阳性和真阴性值显著。但对某些漏洞检测可靠性不足，主要原因是缺乏标准化数据集。

Conclusion: 相比现有技术，提出的深度学习方法有潜力显著提高软件漏洞检测的准确性。未来研究方向包括建立标准化数据集以提高检测可靠性。

Abstract: The increasing reliance on software in various applications has made the problem of software vulnerability detection more critical. Software vulnerabilities can lead to security breaches, data theft, and other negative outcomes. Traditional software vulnerability detection techniques, such as static and dynamic analysis, have been shown to be ineffective at detecting multiple vulnerabilities.
  To address this issue, this study employed a deep learning approach, specifically Convolutional Neural Networks (CNN), to solve the software vulnerability detection problem. A 5-split cross-validation approach was used to train and evaluate the CNN model, which takes tokenized source code as input.
  The findings indicated that Sherlock successfully detected multiple vulnerabilities at the function level, and its performance was particularly strong for CWE-199, CWE-120, and CWE-Other, with an overall high accuracy rate and significant true positive and true negative values. However, the performance was less reliable for some vulnerabilities due to the lack of a standardized dataset which will be a future research direction. The results suggest that compared to current techniques, the proposed deep learning approach has the potential to substantially enhance the accuracy of software vulnerability detection.

</details>


### [19] [A Systematic Analysis of Higher Education on Software Engineering in the Netherlands](https://arxiv.org/abs/2512.12650)
*Bastiaan Heeren,Fabiano Dalpiaz,Mazyar Seraj,Roberto Verdecchia,Vadim Zaytsev*

Main category: cs.SE

TL;DR: 该研究对荷兰10所大学的207门软件工程课程进行分析，基于SWEBOK知识领域，揭示了本科和硕士阶段的知识覆盖模式、知识领域聚类关系，并识别了代表性不足的领域。


<details>
  <summary>Details</summary>
Motivation: 软件工程教育者需要持续改进课程和项目。了解当前软件工程高等教育的实践现状，可以帮助教育者批判性评估自己的课程，通过基准测试进行微调，最终提升课程质量。

Method: 采用众包分析方法，研究荷兰10所大学的207门软件工程课程。基于SWEBOK知识领域进行课程映射，通过同质化和内部一致性改进阶段优化映射过程，随后进行数据分析。

Result: 1. 本科阶段最常覆盖的知识领域是"构建与编程"；2. 部分知识领域在本科和硕士阶段同等覆盖，而更高级的知识领域几乎只在硕士阶段覆盖；3. 识别出三个紧密耦合的知识领域集群；4. 荷兰大学普遍均匀覆盖所有知识领域，少数偏差反映了机构研究优势；5. 识别出代表性不足的领域如软件工程经济学。

Conclusion: 研究结果揭示了关键知识领域之间的相关性及其在促进综合学习方面的潜力。邀请其他研究者使用该方法分析各自地区的软件工程教育项目，以便在全球范围内进行对比。

Abstract: Software engineering educators strive to continuously improve their courses and programs. Understanding the current state of practice of software engineering higher education can empower educators to critically assess their courses, fine-tune them by benchmarking against observed practices, and ultimately enhance their curricula. In this study, we aim to provide an encompassing analysis of higher education on software engineering by considering the higher educational offering of an entire European country, namely the Netherlands. We leverage a crowd-sourced analysis process by considering 10 Dutch universities and 207 university courses. The courses are analysed via knowledge areas adopted from the SWEBOK. The mapping process is refined via homogenisation and internal consistency improvement phases, and is followed by a data analysis phase. Given its fundamental nature, Construction and Programming is the most covered knowledge area at Bachelor level. Other knowledge areas are equally covered at Bachelor and Master level (e.g., software engineering models), while more advanced ones are almost exclusively covered at Master level. We identify three clusters of tightly coupled knowledge areas: (i) requirements, architecture, and design, (ii) testing, verification, and security, and (iii) process-oriented and DevOps topics. Dutch universities generally cover all knowledge areas uniformly, with minor deviations reflecting institutional research strengths. Our results highlight correlations among key knowledge areas and their potential for enhancing integrated learning. We also identify underrepresented areas, such as software engineering economics, which educators may consider including in curricula. We invite researchers to use our research method in their own geographical region, in order to contrast software engineering education programs across the globe.

</details>


### [20] [Attributes to Support the Formulation of Practically Relevant Research Problems in Software Engineering](https://arxiv.org/abs/2512.12699)
*Anrafel Fernandes Pereira,Maria Teresa Baldassarre,Daniel Mendez,Jürgen Börstler,Nauman bin Ali,Rahul Mohanani,Darja Smite,Stefan Biffl,Rogardt Heldal,Davide Falessi,Daniel Graziotin,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 论文提出了软件工程研究中问题制定的七个关键属性，并通过研讨会验证其重要性和完整性，以改善学术研究与工业需求的对接。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究中，良好制定的研究问题对实践相关性至关重要，但缺乏早期阶段的系统指导。现有文献中识别出的七个属性需要验证其重要性和完整性，并学习如何应用。

Method: 在ISERN 2024会议上，与42位资深软件工程研究人员进行研讨会。使用"问题愿景板"展示七个属性，参与者分组讨论、提供书面反馈，并完成问卷调查评估属性的重要性、完整性和改进建议。

Result: 研究结果确认了七个属性在制定面向工业的研究问题中的重要性。定性反馈展示了如何实际应用这些属性，并提出了改进建议，如在影响/后果中加入财务标准（如ROI），在证据中考虑可行性和约束条件。

Conclusion: 结果重申了七个属性在支持反思性和情境感知问题制定中的重要性。根据具体研究情境调整这些属性的使用，有助于改善学术研究与工业需求的对齐。

Abstract: [Background] A well-formulated research problem is essential for achieving practical relevance in Software Engineering (SE), yet there is a lack of structured guidance in this early phase. [Aims] Our goal is to introduce and evaluate seven attributes identified in the SE literature as relevant for formulating research problems (practical problem, context, implications/impacts, practitioners, evidence, objective, and research questions) in terms of their perceived importance and completeness, and learn how they can be applied. [Method] We conducted a workshop with 42 senior SE researchers during the ISERN 2024 meeting. The seven attributes were presented using a Problem Vision board filled with a research example. Participants discussed attributes in groups, shared written feedback, and individually completed a survey assessing their importance, completeness, and suggestions for improvement. [Results] The findings confirm the importance of the seven attributes in the formulation of industry-oriented research problems. Qualitative feedback illustrated how they can be applied in practice and revealed suggestions to refine them, such as incorporating financial criteria (e.g., ROI) into implications/impacts and addressing feasibility and constraints under evidence. [Conclusion] The results reaffirm the importance of the seven attributes in supporting a reflective and context-aware problem formulation. Adapting their use to specific research contexts can help to improve the alignment between academic research and industry needs.

</details>


### [21] [Towards AI Agents Supported Research Problem Formulation](https://arxiv.org/abs/2512.12719)
*Anrafel Fernandes Pereira,Maria Teresa Baldassarre,Daniel Mendez,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文探讨使用AI代理支持软件工程研究者在研究早期阶段（问题表述）的工作，基于精益研究启动框架，通过描述性评估展示AI如何帮助预填问题属性、对齐利益相关者视角、精炼研究问题等。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究中，表述不当的研究问题会因未能反映工业实践的复杂性而损害研究的实际相关性。研究者需要在研究早期阶段更好地表述研究问题，以确保研究的实践价值。

Method: 基于精益研究启动框架，以已发表的机器学习代码可维护性研究为参考，开发了一个描述性评估场景，展示AI代理如何集成到LRI中支持研究者。具体包括预填问题属性、对齐利益相关者视角、精炼研究问题、模拟多视角评估和支持决策制定。

Result: 描述性评估表明，AI代理支持能够丰富协作讨论，增强对研究问题的价值、可行性和适用性的批判性反思。AI代理集成到LRI中被认为有前景，能够支持情境感知和实践导向的研究问题表述。

Conclusion: 虽然将AI代理集成到LRI中的愿景被认为有前景，能够支持情境感知和实践导向的研究问题表述，但仍需要实证验证来确认和完善AI代理在问题表述中的集成。

Abstract: Poorly formulated research problems can compromise the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence agents to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a published study on code maintainability in machine learning as a reference, we developed a descriptive evaluation of a scenario illustrating how AI agents, integrated into LRI, can support SE researchers by pre filling problem attributes, aligning stakeholder perspectives, refining research questions, simulating multiperspective assessments, and supporting decision making. The descriptive evaluation of the scenario suggests that AI agent support can enrich collaborative discussions and enhance critical reflection on the value, feasibility, and applicability of the research problem. Although the vision of integrating AI agents into LRI was perceived as promising to support the context aware and practice oriented formulation of research problems, empirical validation is needed to confirm and refine the integration of AI agents into problem formulation.

</details>


### [22] [Temporal HAL-API Dependencies as a Gateway to Formal Embedded Software Development](https://arxiv.org/abs/2512.12788)
*Manuel Bentele,Andreas Podelski,Axel Sikora,Bernd Westphal*

Main category: cs.SE

TL;DR: THADs（时序HAL-API依赖）是嵌入式软件中一类有用的正确性属性，通过程序注解指定，可通过软件模型检查自动验证，在通用属性和应用特定属性之间提供了平衡点。


<details>
  <summary>Details</summary>
Motivation: 在工业嵌入式软件开发中，需要在无需规范努力的通用属性（通常通过静态分析解决）和需要完整形式化方法的应用特定属性之间找到平衡点，以促进形式化方法更广泛、更经济地应用。

Method: 使用程序注解来指定THADs，然后通过软件模型检查技术自动验证这些时序依赖关系。

Result: THADs能够捕获嵌入式软件中有趣的正确性属性类别，规范工作适中，验证可自动化，在规范努力和验证能力之间提供了良好的平衡。

Conclusion: THADs有潜力成为工业嵌入式软件开发中更广泛、更经济地使用形式化方法的入口点，在通用属性和应用特定属性之间提供了理想的中间地带。

Abstract: Temporal HAL-API Dependencies (THADs) can be useful to capture an interesting class of correctness properties in embedded software development. They demand a moderate effort for specification (which can be done via program annotations) and verification (which can be done automatically via software model checking). In this sense, they have the potential to form an interesting sweet spot between generic properties (that demand virtually no specification effort, and that are typically addressed by static analysis) and application-specific properties as addressed by full-fledged formal methods. Thus, they may form a gateway to wider and more economic use of formal methods in industrial embedded software development.

</details>


### [23] [Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams](https://arxiv.org/abs/2512.12965)
*Thayssa Rocha,Luciano Teran,Marcelle Mota,Cleidson de Souza,Kiev Gama,Gustavo Pinto*

Main category: cs.SE

TL;DR: 远程工作为残障人士参与软件开发团队带来新机遇与挑战，研究发现团队成员对残障同事面临的日常困难认知有限，需要改进无障碍工具、沟通策略和适应性管理方法。


<details>
  <summary>Details</summary>
Motivation: 随着科技行业远程和混合工作模式的普及，研究远程工作如何影响残障人士在混合能力软件开发团队中的体验，探索远程环境中出现的独特挑战和应对策略。

Method: 采用混合方法：1）在线问卷调查收集软件开发团队中残障人士、领导和同事的体验数据；2）对14名自认为残障的软件开发者进行结构化访谈（包括6名自闭症人士、6名肢体残疾者和2名聋人/重听者）；3）结合定量数据和定性编码分析开放式问卷回答与访谈记录。

Result: 研究发现：尽管残障团队成员面临各种障碍，但他们的同事和领导对这些维持远程协作的日常挑战认知有限。这揭示了在无障碍工具、沟通策略和适应性管理方法方面存在改进机会。

Conclusion: 远程工作为残障人士参与软件开发团队创造了新机会，但需要系统性改进来确保真正的包容性。研究强调了提高团队对残障同事挑战认知的重要性，并指出了在工具、沟通和管理实践方面的具体改进方向。

Abstract: The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.

</details>


### [24] [A Decision Support Framework for Blockchain Pattern Selection Based on Soft Goals](https://arxiv.org/abs/2512.13239)
*Eddy Kiomba Kambilo,Nicolas Herbaut,Irina Rychkova,Carine Souveyet*

Main category: cs.SE

TL;DR: 提出BC-TEAEM框架，结合区块链模式本体和领域无关软目标，通过多准则决策方法支持系统架构师选择区块链模式，确保业务目标与技术设计的对齐。


<details>
  <summary>Details</summary>
Motivation: 区块链技术在各行业应用日益广泛，但区块链解决方案在带来积极影响的同时也引入约束和潜在负面效应，可能破坏业务战略。区块链模式多样且缺乏标准化框架将业务目标与技术设计决策关联，使得模式选择对系统架构师成为复杂任务。

Method: 提出区块链技术感知的企业建模(BC-TEAEM)决策支持框架，结合区块链模式本体和领域无关软目标，采用多准则决策方法。框架聚焦领域专家和技术专家的互动，通过迭代捕获和精化偏好，系统化支持区块链模式选择。开发了原型决策支持工具。

Result: 通过制药公司供应链追溯系统的案例研究验证了框架的适用性，展示了BC-TEAEM在实际应用中的有效性。

Conclusion: BC-TEAEM框架能够解决区块链模式选择的复杂性，确保业务目标与技术设计的对齐和可追溯性，为系统架构师提供实用的决策支持。

Abstract: Blockchain technology is gaining momentum across many sectors. Whereas blockchain solutions have important positive effects on the business domain, they also introduce constraints and may cause delayed or unforeseen negative effects, undermining business strategies. The diversity of blockchain patterns and lack of standardized frameworks linking business goals to technical design decisions make pattern selection a complex task for system architects. To address this challenge, we propose Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM), a decision support framework that combines ontologies of blockchain patterns and domain-independent soft goals with a multi-criteria decision-making approach. The framework focuses on the interplay between a domain expert and a technical expert to ensure alignment and traceability. By iteratively capturing and refining preferences, BC-TEAEM supports systematic selection of blockchain patterns. We develop a prototype decision support tool implementing our method and validate it through a case study of a pharmaceutical company's supply chain traceability system, demonstrating the framework's applicability. %a supply chain traceability case study.

</details>


### [25] [UCRBench: Benchmarking LLMs on Use Case Recovery](https://arxiv.org/abs/2512.13360)
*Shuyuan Xiao,Yiran Zhang,Weisong Sun,Xiaohong Chen,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: 论文提出了代码对齐的用例基准，用于评估LLM从源代码生成用例的能力，发现LLM在重构系统功能方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有用例基准稀缺且可能与实际系统行为不一致，这限制了LLM在从源代码生成用例方面的严格评估。

Method: 通过手动验证九个真实软件项目的用户目标和子功能用例，构建代码对齐的用例基准，并提出分层评估协议（参与者正确性、名称准确性、路径保真度、行为覆盖率）。

Result: LLM能够部分重构系统功能，但性能在不同项目间差异显著，在领域特定系统和多模块系统中表现较差，存在高遗漏率且难以在聚合子功能时保持一致的抽象层次。

Conclusion: LLM在用例逆向工程方面既有潜力也有当前局限性，特别是在处理复杂系统和保持抽象一致性方面需要改进。

Abstract: Use cases are widely employed to specify functional requirements, yet existing benchmarks are scarce and face the risk of being misaligned with actual system behavior, similarly limiting the rigorous evaluation of large language models (LLMs) in generating use cases from source code. We address this gap by introducing code-aligned use case benchmarks, constructed through manual validation of both user-goal and subfunction use cases across nine real-world software projects. Using this benchmark, we conduct the first systematic study of LLMs and propose a hierarchical evaluation protocol that assesses actor correctness, name accuracy, path fidelity, and behavioral coverage. The results show that while LLMs can partially reconstruct system functionality, their performance varies significantly across projects, with particularly noticeable shortcomings in domain-specific and multi-module systems. The models also exhibit high omission rates and struggle to maintain consistent abstraction when aggregating subfunctions into user-goal use cases, highlighting both the potential and current limitations of LLM-based use case reverse engineering.

</details>


### [26] [PSALM: applying Proportional SAmpLing strategy in Metamorphic testing](https://arxiv.org/abs/2512.13414)
*Zenghui Zhou,Pak-Lok Poon,Zheng Zheng,Xiao-Yi Zhang*

Main category: cs.SE

TL;DR: PSALM将比例抽样策略(PSS)适配到蜕变测试中，为源测试用例选择和蜕变组选择提供理论保证，在理论上不劣于随机选择，并在实践中优于现有策略。


<details>
  <summary>Details</summary>
Motivation: 蜕变测试的故障检测效果不仅取决于蜕变关系，还受源测试用例和蜕变组选择的影响。虽然已有大量研究关注蜕变关系的设计、生成和验证，但源测试用例选择和蜕变组选择的系统方法仍未被充分探索。传统测试中的比例抽样策略(PSS)有强理论保证，但其假设不能直接应用于蜕变测试。

Method: 提出PSALM方法，将比例抽样策略(PSS)适配到蜕变测试中，同时处理源测试用例选择和蜕变组选择。形式化证明PSALM在任何划分下都不劣于随机选择，并识别了源测试用例选择和蜕变组选择效果相同的条件。

Result: 在8个被测程序和184个变异体上的实证研究表明，结果与理论分析一致，PSALM通常比现有选择策略(如ART和MT-ART)更有效。

Conclusion: PSALM为蜕变测试提供了一个理论基础坚实且实际有效的选择策略，填补了源测试用例和蜕变组选择方法的研究空白。

Abstract: Metamorphic testing (MT) alleviates the oracle problem by checking metamorphic relations (MRs) across multiple test executions. The fault detection effectiveness of MT is influenced not only by the choice and quality of MRs, but also by how source test cases and metamorphic groups (MGs) are selected. While substantial research has focused on designing, generating, and validating MRs, systematic methods for source test case selection and MG selection remain largely unexplored. Although the Proportional Sampling Strategy (PSS) provides strong theoretical guarantees in traditional testing, its assumptions cannot be directly applied in MT due to differences in selection domains, test units, and failure distributions. This paper proposes PSALM, an adaptation of PSS to MT for both source test case selection and MG selection. We formally prove that PSALM is never inferior to random selection regardless of how the source test case and MG domains are partitioned. We further identify the conditions under which applying PSALM to source test case selection and MG selection yields identical effectiveness. A comprehensive empirical study on eight subject programs and 184 mutants shows that the results are consistent with our theoretical analysis and that PSALM generally performs more effectively than existing selection strategies such as ART and MT-ART. These results demonstrate that PSALM provides a theoretically grounded and practically effective selection strategy for MT.

</details>


### [27] [QMon: Monitoring the Execution of Quantum Circuits with Mid-Circuit Measurement and Reset](https://arxiv.org/abs/2512.13422)
*Ning Ma,Jianjun Zhao,Foutse Khomh,Shaukat Ali,Heng Li*

Main category: cs.SE

TL;DR: QMON：一种利用中间电路测量和重置操作来监控量子电路内部状态的方法，同时保持原始运行时行为，用于调试和错误检测。


<details>
  <summary>Details</summary>
Motivation: 量子电路具有不可克隆定理和测量诱导坍缩等独特性质，使得直接观察或复制其状态变得困难，这给量子电路的调试和运行时监控带来了挑战。

Method: QMON通过在开发者指定的位置插入监控操作符，利用中间电路测量和重置操作来监控量子状态概率，同时保持原始电路行为。

Result: 在154个量子电路上的实验表明，所有电路在插桩后都保持了预期功能，QMON成功检测并定位了各种编程错误，虽然监控覆盖范围受限于量子纠缠等特性，但能有效检测错误且对原始状态干扰极小。

Conclusion: QMON有助于开发更健壮可靠的量子软件，为量子计算领域的成熟提供实用工具。

Abstract: Unlike classical software, where logging and runtime tracing can effectively reveal internal execution status, quantum circuits possess unique properties, such as the no-cloning theorem and measurement-induced collapse, that prevent direct observation or duplication of their states. These characteristics make it especially challenging to monitor the execution of quantum circuits, complicating essential tasks such as debugging and runtime monitoring. This paper presents QMON, a practical methodology that leverages mid-circuit measurements and reset operations to monitor the internal states of quantum circuits while preserving their original runtime behavior. QMON enables the instrumentation of monitoring operators at developer-specified locations within the circuit, allowing comparisons between expected and observed quantum-state probabilities at those locations. We evaluated QMON by analyzing its impact on circuit behavior, monitoring coverage, and effectiveness in bug localization. Experimental results involving 154 quantum circuits show that all circuits preserve their intended functionality after instrumentation and that QMON successfully detects and localizes various programming errors. Although monitoring coverage is limited by the need to preserve delicate quantum properties, such as entanglement, QMON effectively detects errors while introducing no or negligible disturbance to the original quantum states. QMON facilitates the development of more robust and reliable quantum software as the field continues to mature.

</details>


### [28] [From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents](https://arxiv.org/abs/2512.13438)
*Dezhi Ran,Zhi Gong,Yuzhe Guo,Mengzhou Wu,Yuan Cao,Haochuan Lu,Hengyu Zhang,Xia Zeng,Gang Cao,Liangchao Yao,Yuetang Deng,Wei Yang,Tao Xie*

Main category: cs.SE

TL;DR: UIFormer：首个自动化UI表示优化框架，通过合成UI转换程序减少LLM代理在UI导航中的token消耗48.7%-55.8%，同时保持或提升性能


<details>
  <summary>Details</summary>
Motivation: LLM代理在自动化UI导航（如UI测试和AI助手）中效率低下，低效的UI表示成为关键性能瓶颈。传统程序合成方法缺乏布尔预言机来验证语义正确性，且需要处理大型复杂UI树并生成长组合转换程序，搜索空间巨大且易出错。

Method: 1. 使用领域特定语言（DSL）限制程序空间，捕获UI特定操作；2. 基于LLM的迭代优化，结合正确性和效率奖励，实现效率-完整性协同优化；3. 作为轻量级插件，应用转换程序与现有LLM代理无缝集成。

Result: 在Android和Web平台的三个UI导航基准测试中，使用五种LLM，UIFormer实现48.7%到55.8%的token减少，运行时开销最小，同时保持或提升代理性能。在微信的实际工业部署验证了其实际影响。

Conclusion: UIFormer通过约束优化和结构化分解复杂合成任务，成功解决了UI表示优化的两大挑战，显著提升了LLM代理在UI导航中的效率，具有实际工业应用价值。

Abstract: While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.

</details>


### [29] [A Data Annotation Requirements Representation and Specification (DARS)](https://arxiv.org/abs/2512.13444)
*Yi Peng,Hina Saeeda,Hans-Martin Heyn,Jennifer Horkoff,Eric Knauss,Fredrick Warg*

Main category: cs.SE

TL;DR: DARS框架：针对AI系统中数据标注需求的特定表示方法，包括标注协商卡和基于场景的标注规范，旨在解决数据标注中的完整性、准确性和一致性错误。


<details>
  <summary>Details</summary>
Motivation: 随着AI赋能的网络物理系统兴起，数据标注成为关键但常被忽视的过程。现有需求工程研究探索了AI系统及其数据需求的表示，但行业访谈显示数据标注及其相关需求带来独特挑战，需要专门的标注需求表示方法。

Method: 提出数据标注需求表示与规范（DARS）框架，包括：1）标注协商卡，用于对齐利益相关者的目标和约束；2）基于场景的标注规范，用于表达原子化且可验证的数据标注需求。通过汽车感知案例和18种真实世界数据标注错误类型的映射进行评估。

Result: 评估结果表明，DARS能够缓解完整性、准确性和一致性标注错误的根本原因。该框架提高了使用数据标注的安全关键系统的可靠性。

Conclusion: 通过将DARS集成到需求工程中，这项工作改进了依赖数据标注的安全关键系统的可靠性，并展示了工程框架必须如何演进以适应当今智能信息系统的数据依赖组件。

Abstract: With the rise of AI-enabled cyber-physical systems, data annotation has become a critical yet often overlooked process in the development of these intelligent information systems. Existing work in requirements engineering (RE) has explored how requirements for AI systems and their data can be represented. However, related interviews with industry professionals show that data annotations and their related requirements introduce distinct challenges, indicating a need for annotation-specific requirement representations. We propose the Data Annotation Requirements Representation and Specification (DARS), including an Annotation Negotiation Card to align stakeholders on objectives and constraints, and a Scenario-Based Annotation Specification to express atomic and verifiable data annotation requirements. We evaluate DARS with an automotive perception case related to an ongoing project, and a mapping against 18 real-world data annotation error types. The results suggest that DARS mitigates root causes of completeness, accuracy, and consistency annotation errors. By integrating DARS into RE, this work improves the reliability of safety-critical systems using data annotations and demonstrates how engineering frameworks must evolve for data-dependent components of today's intelligent information systems.

</details>


### [30] [Mapping of the system of software-related emissions and shared responsibilities](https://arxiv.org/abs/2512.13474)
*Laura Partanen,Antti Sipila,Md Sanaul Haque,Jari Porras*

Main category: cs.SE

TL;DR: 该研究通过系统映射方法，识别ICT领域软件相关碳排放的主要来源和利益相关者责任，以支持欧盟气候法规合规和巴黎协定目标实现。


<details>
  <summary>Details</summary>
Motivation: ICT行业是全球温室气体排放的重要贡献者，且环境影响持续扩大。为达成巴黎协定将全球升温限制在1.5°C的目标，并满足欧盟CSRD和CSDD等法规要求，需要提高对软件相关排放的认识和理解。

Method: 采用全面的系统映射方法，分析ICT领域碳排放和能源消耗的主要来源，并识别软件生命周期中各利益相关方的关键责任。

Result: 研究识别了ICT领域碳排放和能源消耗的主要来源，并明确了软件生命周期中各利益相关方应承担的关键责任，为行业减排提供了系统框架。

Conclusion: 该研究通过系统映射增强了ICT行业对软件相关排放的认识，为满足欧盟法规要求和实现气候目标提供了重要工具，强调了利益相关方在整个软件生命周期中的责任分配。

Abstract: The global climate is experiencing a rapid and unprecedented warming trend. The ICT sector is a notable contributor to global greenhouse gas emissions, with its environmental impact continuing to expand. Addressing this issue is vital for achieving the objectives of the Paris Agreement, particularly the goal of limiting global temperature rise to 1.5°C. At the European Union level, regulatory measures such as the CSRD and the CSDD impose obligations on companies, including those within the ICT sector, to recognize and mitigate their environmental footprint. This study provides a comprehensive system mapping aimed at enhancing the awareness and understanding of software-related emissions and the corresponding responsibilities borne by the ICT sector. The mapping identifies the primary sources of carbon emissions and energy consumption within the ICT domain while also outlining the key responsibilities of the stakeholders accountable throughout the software lifecycle.

</details>


### [31] [How Low Can You Go? The Data-Light SE Challenge](https://arxiv.org/abs/2512.13524)
*Kishan Kumar Ganguly,Tim Menzies*

Main category: cs.SE

TL;DR: 该论文挑战了软件工程研究中依赖大数据集和计算密集型优化器的假设，发现对于许多SE任务，仅需少量标签的简单方法就能达到接近最佳结果的90%性能。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究普遍假设进展依赖于大数据集和计算密集型优化器，但这一假设缺乏严格验证。作者质疑这种"大数据依赖"是否必要，特别是考虑到实际工程中往往需要快速、低成本的指导而非缓慢、详尽的优化。

Method: 1) 对数十个SE优化问题进行实证研究，包括软件配置、性能调优、云计算优化、决策建模等；2) 使用简单方法如多样性采样、最小贝叶斯学习器、随机探测；3) 提出数据轻量挑战的数学形式化；4) 开发轻量级基线算法；5) 在公开数据上测试轻量方法的适用条件。

Result: 仅需几十个标签，简单方法就能达到最佳报告结果的近90%性能，且与SMAC、TPE、DEHB等先进优化器表现相当。这些结果足以满足许多工程需求，特别是需要快速、成本效益指导的场景。

Conclusion: 许多SE任务可能更适合轻量级方法，这些方法需要更少的标签和计算资源。作者提出"数据轻量挑战"问题，并提供了数学形式化、基线算法和实证结果，为大规模研究该问题奠定了基础。

Abstract: Much of software engineering (SE) research assumes that progress depends on massive datasets and CPU-intensive optimizers. Yet has this assumption been rigorously tested?
  The counter-evidence presented in this paper suggests otherwise: across dozens of optimization problems from recent SE literature, including software configuration and performance tuning, cloud and systems optimization, project and process-level decision modeling, behavioral analytics, financial risk modeling, project health prediction, reinforcement learning tasks, sales forecasting, and software testing, even with just a few dozen labels, very simple methods (e.g. diversity sampling, a minimal Bayesian learner, or random probes) achieve near 90% of the best reported results. Further, these simple methods perform just as well as more state-of-the-the-art optimizers like SMAC, TPE, DEHB etc. While some tasks would require better outcomes and more sampling, these results seen after a few dozen samples would suffice for many engineering needs (particularly when the goal is rapid and cost-efficient guidance rather than slow and exhaustive optimization).
  Our results highlight that some SE tasks may be better served by lightweight approaches that demand fewer labels and far less computation. We hence propose the data-light challenge: when will a handful of labels suffice for SE tasks? To enable a large-scale investigation of this issue, we contribute (1) a mathematical formalization of labeling, (2) lightweight baseline algorithms, and (3) results on public-domain data showing the conditions under which lightweight methods excel or fail.
  For the purposes of open science, our scripts and data are online at https://github.com/KKGanguly/NEO .

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [32] [Layered Monoidal Theories](https://arxiv.org/abs/2512.12139)
*Leo Lobski*

Main category: cs.LO

TL;DR: 本文提出分层幺半理论，将多个幺半理论及其转换整合到同一弦图中，并应用于逆合成分析的形式化


<details>
  <summary>Details</summary>
Motivation: 传统幺半理论虽然提供了直观的图形语法，但无法在同一图中混合多个理论。本文旨在扩展幺半理论，使其能够处理多个抽象层次的信息流，同时保持数学精确性和语义可解释性

Method: 1. 定义三种分层幺半理论变体，为每种生成递归语法，构建与opfibration、fibration和deflation语义的自由-遗忘伴随函子
2. 将化学逆合成过程形式化为三个抽象层次：反应、反应方案和断键规则，证明它们之间的函子关系
3. 将逆合成分析嵌入特定分层幺半理论中

Result: 1. 建立了分层幺半理论的数学框架，支持多理论混合的弦图表示
2. 证明了化学逆合成三个层次间的紧密联系：反应由反应方案生成，断键规则到反应存在函子翻译
3. 证明了断键规则到反应的翻译是完备、可靠且通用的，使断键规则成为具有反应语义的形式语法

Conclusion: 分层幺半理论为多抽象层次系统提供了统一的图形形式化框架，成功应用于化学逆合成分析，建立了数学严谨性与化学直觉之间的桥梁

Abstract: In the first part, we develop layered monoidal theories - a generalisation of monoidal theories combining descriptions of a system at several levels. Via their representation as string diagrams, monoidal theories provide a graphical syntax with a visually intuitive notions of information flow and composition. Layered monoidal theories allow mixing several monoidal theories (together with translations between them) within the same string diagram, while retaining mathematical precision and semantic interpretability. We define three flavours of layered monoidal theories, provide a recursively generated syntax for each, and construct a free-forgetful adjunction with respect to three closely related semantics: opfibrations, fibrations and deflations. We motivate the general theory by providing several examples from existing literature.
  In the second part, we develop a formal approach to retrosynthesis - the process of backwards reaction search in synthetic chemistry. Chemical processes are treated at three levels of abstraction: (1) (formal) reactions encode all chemically feasible combinatorial rearrangements of molecules, (2) reaction schemes encode transformations applicable to 'patches' of molecules (including the functional groups), and (3) disconnection rules encode local chemical rewrite rules applicable to a single bond or atom at a time. We show that the three levels are tightly linked: the reactions are generated by the reaction schemes, while there is a functorial translation from the disconnection rules to the reactions. Moreover, the translation from the disconnection rules to the reactions is shown to be sound, complete and universal - allowing one to treat the disconnection rules as a formal syntax with the semantics provided by the reactions. We tie together the two parts by providing a formalisation of retrosynthesis within a certain layered monoidal theory.

</details>


### [33] [An STREL-based Formulation of Spatial Resilience in Cyber-Physical Systems](https://arxiv.org/abs/2512.12511)
*Zeyu Zhang,Hongkai Chen,Nicola Paoletti,Shan Lin,Scott A. Smolka*

Main category: cs.LO

TL;DR: 提出一个用于网络物理系统空间弹性的形式化框架，基于SREL逻辑，通过空间弹性规范(SpaRS)和空间弹性值(SpaRV)函数量化系统的恢复能力和持久性。


<details>
  <summary>Details</summary>
Motivation: 空间弹性对网络物理系统至关重要，但目前缺乏广泛认可的形式化处理方法。需要建立统一的框架来形式化地描述和量化空间弹性。

Method: 基于STREL的空间片段SREL构建形式化框架，定义空间弹性规范(SpaRS)及其原子谓词S-atom，引入空间弹性值(SpaRV)函数进行量化语义分析，并设计算法评估SpaRV。

Result: 建立了完整的空间弹性形式化框架，证明了SpaRV函数相对于SREL布尔语义的完备性和正确性，并通过两个案例研究验证了方法的实用性。

Conclusion: 提出的框架为网络物理系统的空间弹性提供了形式化规范和量化分析方法，填补了该领域的形式化处理空白，具有实际应用价值。

Abstract: Resiliency is the ability of a system to quickly recover from a violation (recoverability) and avoid future violations for as long as possible (durability). In the spatial setting, recoverability and durability (now known as persistency) are measured in units of distance. Like its temporal counterpart, spatial resiliency is of fundamental importance for Cyber-Physical Systems (CPS) and yet, to date, there is no widely agreed-upon formal treatment of spatial resiliency. We present a formal framework for reasoning about spatial resiliency in CPS. Our framework is based on the spatial fragment of STREL, which we refer to as SREL. In this framework, spatial resiliency is given a syntactic characterization in the form of a Spatial Resiliency Specification (SpaRS). An atomic predicate of SpaRS is called an S-atom. Given an arbitrary SREL formula $\varphi$, distance bounds $d_1, d_2$, the S-atom of $\varphi$, $S_{d_1, d_2} (\varphi)$, is the SREL formula $\neg\varphi R_{[0,d_1]} (\varphi R_{[d_2, +\infty)}\varphi)$, specifying that recovery from a violation of $\varphi$ occurs within distance $d_1$ (recoverability), and subsequently that $\varphi$ be maintained along a route for a distance greater than $d_2$ (persistency). S-atoms can be combined using spatial STREL operators, allowing one to express composite resiliency specifications. We define a quantitative semantics for SpaRS in the form of a Spatial Resilience Value (SpaRV) function $σ$ and prove its soundness and completeness w.r.t. SREL's Boolean semantics. The $σ$-value for $S_{d_1,d_2}(\varphi)$ is a set of non-dominated (rec, per) pairs, quantifying recoverability and persistency, given that some routes may offer better recoverability while others better persistency. In addition, we design algorithms to evaluate SpaRV for SpaRS formulas. Finally, two case studies demonstrate the practical utility of our approach.

</details>


### [34] [Cargo Sherlock: An SMT-Based Checker for Software Trust Costs](https://arxiv.org/abs/2512.12553)
*Muhammad Hassnain,Anirudh Basu,Ethan Ng,Caleb Stanford*

Main category: cs.LO

TL;DR: 提出一个结合形式化验证与人类因素的信任量化框架Cargo Sherlock，用于检测Rust生态系统的供应链攻击


<details>
  <summary>Details</summary>
Motivation: 开源软件生态系统面临供应链攻击威胁，现有方法要么过于形式化（忽略实际信任因素），要么过于依赖主观判断（缺乏形式化验证）

Method: 1. 构建一阶关系模型表示软件依赖关系；2. 基于最小信任问题形式化信任成本计算；3. 实现Cargo Sherlock工具，结合SMT求解器和信任指标（下载量、作者数等）

Result: Cargo Sherlock能有效检测合成生成的供应链攻击、已知的typosquatting攻击和AI维护的crates问题，且能扩展到依赖众多的Rust crate

Conclusion: 该框架成功融合了形式化验证与实用信任指标，为开源软件依赖信任评估提供了可扩展的解决方案

Abstract: Supply chain attacks threaten open-source software ecosystems. This paper proposes a formal framework for quantifying trust in third-party software dependencies that is both formally checkable - formalized in satisfiability modulo theories (SMT) - while at the same time incorporating human factors, like the number of downloads, authors, and other metadata that are commonly used to identify trustworthy software in practice. We use data from both software analysis tools and metadata to build a first-order relational model of software dependencies; to obtain an overall "trust cost" combining these factors, we propose a formalization based on the minimum trust problem which asks for the minimum cost of a set of assumptions which can be used to prove that the code is safe. We implement these ideas in Cargo Sherlock, targeted for Rust libraries (crates), incorporating a list of candidate assumptions motivated by quantifiable trust metrics identified in prior work. Our evaluation shows that Cargo Sherlock can be used to identify synthetically generated supply chain attacks and known incidents involving typosquatted and poorly AI-maintained crates, and that its performance scales to Rust crates with many dependencies.

</details>


### [35] [Argumentative Reasoning with Language Models on Non-factorized Case Bases](https://arxiv.org/abs/2512.12656)
*Wachara Fungwacharakorn,May Myo Zin,Ha-Thanh Nguyen,Yuntao Kong,Ken Satoh*

Main category: cs.LO

TL;DR: 本文提出AAM-CBR框架，利用语言模型在非因子化案例库上进行案例推理，通过抽象论证扩展传统方法，无需预处理历史案例，提高了灵活性和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 传统案例推理方法需要将历史案例因子化，这限制了灵活性并可能泄露隐私。作者希望探索语言模型能否直接在非因子化的案例库上进行案例推理。

Method: 提出AAM-CBR框架，扩展抽象论证的案例推理方法。语言模型负责确定案例覆盖范围并根据新案例提取因子，实现因子化推理而无需暴露或预处理历史案例。

Result: 在合成信用卡申请数据集上的实验表明，AAM-CBR仅在当新案例包含更丰富因子集时优于单提示基线方法。语言模型能处理有限数量的因子，但随着因子数量增加面临挑战。

Conclusion: 语言模型与符号推理的集成（如AAM-CBR所实现）对于有效处理涉及多因子的案例至关重要，这为复杂案例推理提供了有前景的方向。

Abstract: In this paper, we investigate how language models can perform case-based reasoning (CBR) on non-factorized case bases. We introduce a novel framework, argumentative agentic models for case-based reasoning (AAM-CBR), which extends abstract argumentation for case-based reasoning (AA-CBR). Unlike traditional approaches that require factorization of previous cases, AAM-CBR leverages language models to determine case coverage and extract factors based on new cases. This enables factor-based reasoning without exposing or preprocessing previous cases, thus improving both flexibility and privacy. We also present initial experiments to assess AAM-CBR performance by comparing the proposed framework with a baseline that uses a single-prompt approach to incorporate both new and previous cases. The experiments are conducted based on a synthetic credit card application dataset. The result shows that AAM-CBR surpasses the baseline only when the new case contains a richer set of factors. The finding indicates that language models can handle case-based reasoning with a limited number of factors, but face challenges as the number of factors increase. Consequently, integrating symbolic reasoning with language models, as implemented in AAM-CBR, is crucial for effectively handling cases involving many factors.

</details>
