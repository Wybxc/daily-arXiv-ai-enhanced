<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 30]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.FL](#cs.FL) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Injecting Sustainability in Software Architecture: A Rapid Review](https://arxiv.org/abs/2512.00106)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 该研究通过混合方法实证研究，结合文献综述和焦点小组，探讨如何在软件架构中系统性地整合可持续性，并提出了五个实用建议。


<details>
  <summary>Details</summary>
Motivation: 可持续性已从新兴关注点发展为软件设计、开发和运营中的基本责任。研究旨在探索如何将可持续性系统性地整合到现有的软件工程实践中，特别是软件架构层面。

Method: 采用混合方法实证研究：1）对二次研究进行快速文献综述，识别软件架构中嵌入可持续性的挑战和机遇；2）组织从业者焦点小组，丰富和比较这些发现。

Result: 基于文献和行业综合，研究得出了五个具体可行的要点，旨在为软件架构师提供指导，并帮助行业合作伙伴将可持续性关注整合到架构实践中。

Conclusion: 通过学术界与工业界的合作，该研究为在软件架构中系统性地整合可持续性提供了实证基础和实践指导，有助于推动可持续软件工程的发展。

Abstract: Sustainability has evolved from an emerging concern into a fundamental responsibility in software design, development, and operation. Research increasingly explores how sustainability can be systematically integrated into existing software engineering practices. Building on an industry-academia collaboration, we contribute to this discourse by conducting a mixed-method empirical study. We combine a rapid review of secondary studies with a focus group of practitioners. The review identifies challenges and opportunities in embedding sustainability in software architecture, while the focus group enriches and compares these findings. Based on the literature and industry synthesis, we derive five tangible takeaways to inform architects working in the field, and to guide our industry partners in the integration of sustainability concerns in architecture practices.

</details>


### [2] [Generating Verifiable CoT from Execution-Traces](https://arxiv.org/abs/2512.00127)
*Shailja Thakur,Vaibhav Saxena,Rohan Kulkarni,Shivdeep Singh,Parameswaran Selvam,Hima Patel,Hiroshi Kanayama*

Main category: cs.SE

TL;DR: 该论文提出了一种基于程序执行轨迹的代码推理方法，通过将代码执行过程转化为自然语言推理步骤，确保推理的正确性，从而解决传统CoT方法中推理步骤可能逻辑错误的问题。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在代码推理任务中使用的合成训练数据存在严重缺陷：推理步骤通常是教师模型生成的看似合理但未经验证的解释，而非代码实际执行过程的准确描述。这导致模型学习到表面合理但逻辑错误的推理模式。

Method: 提出执行基础的方法：1）通过代码插桩捕获程序的动态执行轨迹；2）将这些经过验证的执行轨迹叙述为自然语言推理步骤。这种方法确保每个推理步骤都反映程序实际计算过程，从源头上消除逻辑幻觉。

Result: 在代码推理任务（CruxEval和LiveCodeBench-Exec的前向推理，CruxEval-Input的后向推理）以及HumanEval的代码生成和解释任务上，使用双向轨迹基础数据训练的模型取得了显著改进：输出预测提升高达30分，输入预测提升28分，同时改善了代码解释和生成能力。

Conclusion: 可验证的推理从根本上增强了模型能力，执行基础的CoT生成方法能够确保推理步骤的正确性，为语言模型的代码推理提供了更可靠的基础。

Abstract: Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.
  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT

</details>


### [3] [Asm2SrcEval: Evaluating Large Language Models for Assembly-to-Source Code Translation](https://arxiv.org/abs/2512.00134)
*Parisa Hamedi,Hamed Jelodar,Samita Bai,Mohammad Meymani,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.SE

TL;DR: 该论文首次对5种最先进的大语言模型在汇编到源代码翻译任务上进行了全面评估，使用多种指标衡量性能，揭示了模型在文本相似度、困惑度和推理速度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 汇编到源代码翻译是逆向工程、网络安全和软件维护中的关键任务，但目前缺乏系统性的基准来评估大语言模型在此问题上的表现。

Method: 使用5种最先进的大语言模型，采用多样化的评估指标：词汇相似度（BLEU、ROUGE、METEOR）、语义对齐（BERTScore）、流畅度（困惑度）和效率（预测时间）。

Result: 结果显示了明确的权衡：某些模型在文本相似度指标上表现出色，而其他模型则展现出更低的困惑度或更快的推理时间。定性分析揭示了控制流恢复和标识符重建等挑战。

Conclusion: 该基准为程序翻译中当前大语言模型的优势和局限性提供了可操作的见解，为未来研究在现实应用中结合准确性和效率奠定了基础。

Abstract: Assembly-to-source code translation is a critical task in reverse engineering, cybersecurity, and software maintenance, yet systematic benchmarks for evaluating large language models on this problem remain scarce. In this work, we present the first comprehensive evaluation of five state-of-the-art large language models on assembly-to-source translation. We assess model performance using a diverse set of metrics capturing lexical similarity (BLEU, ROUGE, and METEOR), semantic alignment (BERTScore), fluency (Perplexity), and efficiency (time prediction). Our results reveal clear trade-offs: while certain models excel in text similarity metrics, others demonstrate lower perplexity or faster inference times. We further provide qualitative analyses of typical model successes and failure cases, highlighting challenges such as control flow recovery and identifier reconstruction. Taken together, our benchmark offers actionable insights into the strengths and limitations of current large language models for program translation, establishing a foundation for future research in combining accuracy with efficiency for real-world applications.

</details>


### [4] [Demystifying Errors in LLM Reasoning Traces: An Empirical Study of Code Execution Simulation](https://arxiv.org/abs/2512.00215)
*Mohammad Abdollahi,Khandaker Rifah Tasnia,Soumit Kanti Saha,Jinqiu Yang,Song Wang,Hadi Hemmati*

Main category: cs.SE

TL;DR: 该研究首次对推理大语言模型的运行时行为进行实证分析，发现模型在程序输出预测上准确率可达85-98%，但推理过程中存在九类错误，工具增强推理可纠正58%的计算错误。


<details>
  <summary>Details</summary>
Motivation: 理解程序的运行时推理行为对于可靠的代码生成、调试和自动推理至关重要。虽然大语言模型能准确预测程序输出，但先前研究主要关注输出准确性，将推理过程视为黑盒，对其推理轨迹的结构和失败模式知之甚少。

Method: 从HumanEval Plus和LiveCodeBench中整理包含427个代码片段的基准测试集，每个片段测试三种输入类型（常规、边界、无效），每个片段选择12个输入值并配以真实执行结果。评估四个最先进的推理大语言模型，分析产生的推理轨迹并开发包含九类推理错误的分类法。

Result: 模型在不同输入类型上的准确率达到85%-98%，但推理过程中存在九类推理错误。通过工具增强推理方法，以计算错误类别为例，实验显示该方法能纠正58%的此类错误。

Conclusion: 该研究首次系统分析了推理大语言模型的运行时行为，揭示了其推理过程中的错误模式，并展示了工具支持在改进LLM推理方面的潜力，为未来提升代码生成和自动推理的可靠性提供了重要见解。

Abstract: Understanding a program's runtime reasoning behavior, meaning how intermediate states and control flows lead to final execution results, is essential for reliable code generation, debugging, and automated reasoning. Although large language models (LLMs) can accurately predict program outputs, most prior work has focused on output accuracy and performance, treating reasoning as a black box. As a result, little is known about the structure or failure modes of their reasoning traces. To address this gap, we conduct the first empirical study on runtime behavior inference with reasoning LLMs, aiming to uncover and characterize errors in their reasoning traces. We curate a benchmark from HumanEval Plus and LiveCodeBench, containing 427 code snippets. For each snippet, we test three input types: regular, edge, and invalid. Twelve input values are selected per snippet, each paired with its ground-truth execution result. We evaluate four state-of-the-art reasoning LLMs. Our results show that these models reach accuracies between 85 percent and 98 percent across input types. We also analyze the produced reasoning traces and develop a taxonomy with nine categories of inference errors. Finally, we explore tool-augmented reasoning. Using failures in the Computation Errors category as a case study, our experiments show that this approach corrects 58 percent of such errors, demonstrating the potential of tool support for improving LLM reasoning.

</details>


### [5] [CodeFlowLM: Incremental Just-In-Time Defect Prediction with Pretrained Language Models and Exploratory Insights into Defect Localization](https://arxiv.org/abs/2512.00231)
*Monique Louise Monteiro,George G. Cabral,Adriano L. I. OLiveira*

Main category: cs.SE

TL;DR: CodeFlowLM是一个用于即时软件缺陷预测的增量学习框架，利用预训练语言模型解决概念漂移、类别不平衡和验证延迟问题，在缺陷预测和定位任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统在线学习器在即时软件缺陷预测中面临概念漂移、类别不平衡和验证延迟等挑战，需要更有效的增量学习方法来适应不断演化的软件环境。

Method: 提出CodeFlowLM框架，采用持续微调策略，使用编码器-解码器PLMs（如CodeT5+和UniXCoder），并与增量基线BORB进行比较。同时将分析扩展到即时缺陷定位，评估GPT-5、Claude Sonnet 4.5等LLMs与基于注意力的模型。

Result: CodeFlowLM在G-Mean指标上获得高达68%的提升，证明其在演化软件环境中的优越适应性和鲁棒性。GPT-5在Recall@20%和Effort@20%指标上表现相当且更稳定，但基于注意力的方法在细粒度排名指标上仍有优势。

Conclusion: CodeFlowLM显著推进了增量JIT-SDP的技术水平，展示了在演化软件环境中的优越适应性和鲁棒性。LLMs在缺陷定位中展现出潜力，但也存在保守偏差、上下文信息不足和数据集标注问题等局限性。

Abstract: This work introduces CodeFlowLM, an incremental learning framework for Just-In-Time Software Defect Prediction (JIT-SDP) that leverages pre-trained language models (PLMs). Unlike traditional online learners, CodeFlowLM employs continual fine-tuning to address concept drift, class imbalance, and verification latency without retraining from scratch. We evaluated encoder-only and encoder-decoder PLMs (notably CodeT5+ and UniXCoder) in JIT-SDP scenarios within and between projects, comparing them with the incremental baseline BORB. The results show that CodeFlowLM achieves up to 68% G-Mean gains, confirming its superior adaptability and robustness in evolving software environments. We further extend the analysis to Just-in-Time Defect Localization (JIT-DL), benchmarking Large Language Models (LLMs) such as GPT-5, Claude Sonnet 4.5, and Gemini 2.5 Pro against attention-based models. GPT-5 delivers comparable performance for Recall@20% and Effort@20% with higher stability, although attention-based methods retain an advantage in fine-grained ranking metrics (Top-k, IFA). A qualitative error analysis reveals that most false positives arise from (1) human-like conservative bias, (2) insufficient contextual information in diff-based prompts, and (3) potential dataset mislabeling in JIT-Defects4J. These findings highlight both the promise and the current limitations of LLM reasoning in defect localization. False negatives occur in smaller proportions. Overall, CodeFlowLM significantly advances the state of the art in incremental JIT-SDP, demonstrating superior adaptability and robustness in evolving software environments. Furthermore, our exploratory analysis of LLMs in JIT-DL not only benchmarks their performance against established attention-based models but also provides critical insights into the current limitations of prompt-based defect reasoning.

</details>


### [6] [ng-reactive-lint: Smarter Linting for Angular Apps](https://arxiv.org/abs/2512.00250)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.SE

TL;DR: ng-reactive-lint：针对Angular应用的确定性静态分析工具，专门检测Observables、Signals和变更检测中的性能反模式，能显著减少不必要的变更检测周期和内存使用。


<details>
  <summary>Details</summary>
Motivation: Angular应用中响应式编程的微妙误用（Observables、Signals、变更检测）常导致难以诊断的性能问题。尽管Angular 17引入了统一的signal-first模型，但企业代码库仍大量依赖遗留RxJS模式，导致不可预测的更新流、内存泄漏和过多的变更周期。

Method: 开发ng-reactive-lint工具，这是一个确定性静态分析工具，能够理解Angular的组件语义、生命周期钩子、模板绑定和响应式模式。与通用ESLint或RxJS插件不同，它执行框架感知分析来检测高影响力的反模式，并提供可操作、上下文特定的修复建议。

Result: 在五个大型真实项目中的评估显示：不必要的变更检测周期最多减少三倍，峰值内存使用最多降低75%。

Conclusion: 该工具为大规模采用现代Angular响应式编程提供了实用、自动化的路径，能够有效解决企业代码库中的性能问题。

Abstract: Reactivity is central to Angular applications, yet subtle misuse of Observables, Signals, and change-detection often leads to performance regressions that are difficult to diagnose. Although Angular 17 introduced a unified, signal-first model, most enterprise codebases still rely heavily on legacy RxJS patterns that create unpredictable update flows, memory leaks, and excessive change cycles. To address these issues, we developed ng-reactive-lint, a deterministic static analysis tool that understands Angular's component semantics, lifecycle hooks, template bindings, and reactivity patterns. Unlike generic ESLint or RxJS plugins, ng-reactive-lint performs framework-aware analysis to detect high-impact anti-patterns and provide actionable, context-specific fixes. Evaluation across five large real-world projects showed reductions of up to threefold in unnecessary change detection cycles and up to 75% lower peak memory usage. The tool offers a practical, automated path to adopting modern Angular reactivity at scale.

</details>


### [7] [Progressive Code Integration for Abstractive Bug Report Summarization](https://arxiv.org/abs/2512.00325)
*Shaira Sadia Karim,Abrar Mahmud Rahim,Lamia Alam,Ishmam Tashdeed,Lutfun Nahar Lota,Md. Abu Raihan M. Kamal,Md. Azam Hossain*

Main category: cs.SE

TL;DR: 提出渐进式代码集成框架，利用LLM结合文本和代码信息生成bug报告摘要，解决现有方法忽略代码片段和上下文限制的问题


<details>
  <summary>Details</summary>
Motivation: 现有bug报告摘要方法通常依赖表面文本特征，导致摘要不完整或冗余，且经常忽略相关的代码片段，而代码对准确缺陷诊断至关重要

Method: 提出渐进式代码集成框架，逐步将长代码片段与文本内容结合，克服标准LLM上下文窗口限制，生成语义丰富的摘要

Result: 在四个基准数据集上使用八个LLM评估，管道比抽取式基线提升7.5%-58.2%，性能与最先进的抽象方法相当

Conclusion: 联合利用文本和代码信息能显著增强bug理解，渐进式代码集成框架有效解决了现有方法的局限性

Abstract: Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.

</details>


### [8] [Framework-Aware Code Generation with API Knowledge Graph-Constructed Data: A Study on HarmonyOS](https://arxiv.org/abs/2512.00380)
*Mingwei Liu,Zheng Pei,Yanlin Wang,Zihao Wang,Zikang Li,Enci Lin,Xin Peng,Zibin Zheng*

Main category: cs.SE

TL;DR: APIKG4SYN框架利用API知识图谱为低资源框架（如HarmonyOS）构建API导向的问答对数据集，通过微调显著提升LLM的代码生成准确率


<details>
  <summary>Details</summary>
Motivation: 在低资源软件框架（如HarmonyOS）中，大型语言模型由于预训练阶段缺乏对这些环境的充分接触，代码生成性能较差。即使像GPT-4o这样的先进商业模型，在没有适配的情况下也无法可靠生成正确代码，因为它们不熟悉特定框架的API和语法。

Method: 提出APIKG4SYN框架，利用API知识图谱构建API导向的问答对数据集，无需可执行代码。框架整合单API和多API知识，其中多API知识通过不确定性估计驱动的蒙特卡洛树搜索获取，为微调LLM创建多样且信息丰富的数据集。

Result: 以HarmonyOS为案例研究，建立了首个HarmonyOS代码生成基准。实验结果显示，使用APIKG4SYN微调Qwen模型将pass@1准确率提升至25.00%，而基线GPT模型仅为17.59%。

Conclusion: API导向的数据显著提升了LLM在低资源软件开发场景中的性能，证明了针对特定框架API知识进行数据增强的有效性。

Abstract: In the context of software frameworks with limited resources (such as HarmonyOS), large language models (LLMs) often exhibit poor code generation performance because they lack sufficient exposure to such environments during pre-training. Although LLMs can usually maintain correct logical structures across programming languages, they frequently struggle when dealing with framework-specific APIs or syntax, resulting in errors. This indicates that while pre-training equips LLMs with general algorithmic capabilities, they remain unfamiliar with the distinctive syntax and API usage of underrepresented frameworks. As a result, even advanced commercial models like GPT-4o cannot reliably generate correct code without prior adaptation. To address this issue, we propose APIKG4SYN, a framework designed to exploit API knowledge graphs for the construction of API-oriented question-code pairs, specifically tailored for low-resource frameworks without requiring executable code. APIKG4SYN integrates both single-API and multi-API knowledge, where the latter is derived through uncertainty estimation (UE)-driven Monte Carlo Tree Search (MCTS), enabling the creation of a diverse and informative dataset for fine-tuning LLMs. Using HarmonyOS as a case study, we build the first benchmark for HarmonyOS code generation. Experimental results show that fine-tuning Qwen with APIKG4SYN raises pass@1 accuracy to 25.00%, compared with 17.59% for the baseline GPT model. These results confirm that API-oriented data significantly enhance LLM performance in low-resource software development scenarios.

</details>


### [9] [Bias Testing and Mitigation in Black Box LLMs using Metamorphic Relations](https://arxiv.org/abs/2512.00556)
*Sina Salimian,Gias Uddin,Sumon Biswas,Henry Leung*

Main category: cs.SE

TL;DR: 提出基于蜕变关系的统一框架，通过语义等价变换检测和缓解LLM中的隐藏社会偏见，相比现有工具多发现14%偏见，微调后安全响应率从54.7%提升至88.9%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型广泛部署引发了对输出中微妙社会偏见的担忧，现有防护措施在处理间接或上下文复杂的偏见诱导提示时经常失效

Method: 提出基于蜕变测试的统一框架，引入六种新颖的蜕变关系，将直接偏见诱导输入转换为语义等价但对抗性更强的变体，用于系统偏见评估和针对性缓解

Result: 使用六个最先进的LLM和BiasAsker基准的385个问题，蜕变关系相比现有工具多揭示14%隐藏偏见；使用原始和蜕变样本微调后，安全响应率从54.7%提升至88.9%

Conclusion: 蜕变关系作为改进对话AI公平性的实用机制，能够有效检测和缓解LLM中的隐藏社会偏见

Abstract: The widespread deployment of Large Language Models (LLMs) has intensified concerns about subtle social biases embedded in their outputs. Existing guardrails often fail when faced with indirect or contextually complex bias-inducing prompts. To address these limitations, we propose a unified framework for both systematic bias evaluation and targeted mitigation. Our approach introduces six novel Metamorphic Relations (MRs) that, based on metamorphic testing principles, transform direct bias-inducing inputs into semantically equivalent yet adversarially challenging variants. These transformations enable an automated method for exposing hidden model biases: when an LLM responds inconsistently or unfairly across MR-generated variants, the underlying bias becomes detectable. We further show that the same MRs can be used to generate diverse bias-inducing samples for fine-tuning, directly linking the testing process to mitigation. Using six state-of-the-art LLMs - spanning open-source and proprietary models - and a representative subset of 385 questions from the 8,978-item BiasAsker benchmark covering seven protected groups, our MRs reveal up to 14% more hidden biases compared to existing tools. Moreover, fine-tuning with both original and MR-mutated samples significantly enhances bias resiliency, increasing safe response rates from 54.7% to over 88.9% across models. These results highlight metamorphic relations as a practical mechanism for improving fairness in conversational AI.

</details>


### [10] [SAGE: Semantic-Aware Gray-Box Game Regression Testing with Large Language Models](https://arxiv.org/abs/2512.00560)
*Jinyu Cai,Jialong Li,Nianyu Li,Zhenyu Mao,Mingyue Zhang,Kenji Tei*

Main category: cs.SE

TL;DR: SAGE：面向灰盒游戏环境的语义感知回归测试框架，通过LLM引导的强化学习自动生成测试用例，语义多目标优化精简测试套件，以及基于更新日志的语义分析优先选择相关测试，显著降低测试成本并提升缺陷检测能力。


<details>
  <summary>Details</summary>
Motivation: 现代实时服务游戏快速迭代需要回归测试，但现有方法在灰盒环境下存在严重局限：测试用例构建依赖人工、测试套件冗余增长、缺乏有效测试优先级机制，导致测试成本过高、自动化不足、缺陷检测不充分。

Method: 1. LLM引导的强化学习进行目标导向探索，自动生成多样化基础测试套件；2. 基于语义的多目标优化，平衡成本、覆盖率和稀有性，将测试套件精炼为紧凑高价值子集；3. 基于LLM的更新日志语义分析，优先选择与版本变更最相关的测试用例。

Result: 在Overcooked Plus和Minecraft两个代表性环境中评估，相比自动化基准和人工记录测试用例，SAGE在所有环境中都实现了更优的缺陷检测能力，同时显著降低了执行成本，并展现出对版本更新的强适应性。

Conclusion: SAGE框架有效解决了灰盒游戏环境中的回归测试挑战，通过语义感知方法实现了高效的测试生成、维护和选择，为现代实时服务游戏的快速迭代提供了实用的回归测试解决方案。

Abstract: The rapid iteration cycles of modern live-service games make regression testing indispensable for maintaining quality and stability. However, existing regression testing approaches face critical limitations, especially in common gray-box settings where full source code access is unavailable: they heavily rely on manual effort for test case construction, struggle to maintain growing suites plagued by redundancy, and lack efficient mechanisms for prioritizing relevant tests. These challenges result in excessive testing costs, limited automation, and insufficient bug detection. To address these issues, we propose SAGE, a semanticaware regression testing framework for gray-box game environments. SAGE systematically addresses the core challenges of test generation, maintenance, and selection. It employs LLM-guided reinforcement learning for efficient, goal-oriented exploration to automatically generate a diverse foundational test suite. Subsequently, it applies a semantic-based multi-objective optimization to refine this suite into a compact, high-value subset by balancing cost, coverage, and rarity. Finally, it leverages LLM-based semantic analysis of update logs to prioritize test cases most relevant to version changes, enabling efficient adaptation across iterations. We evaluate SAGE on two representative environments, Overcooked Plus and Minecraft, comparing against both automated baselines and human-recorded test cases. Across all environments, SAGE achieves superior bug detection with significantly lower execution cost, while demonstrating strong adaptability to version updates.

</details>


### [11] [Enhancing Analogy-Based Software Effort Estimation with Firefly Algorithm Optimization](https://arxiv.org/abs/2512.00571)
*Tarun Chintada,Uday Kiran Cheera*

Main category: cs.SE

TL;DR: 本研究提出了一种结合萤火虫算法与类比估算的FAABE模型，用于提高软件项目估算精度，在多个公开数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 类比估算方法虽然简单有效，但缺乏可靠估算的最优方法，且对于与历史项目差异较大的新软件项目，估算精度可能不足。

Method: 提出FAABE模型，将萤火虫算法与类比估算相结合，并使用特征选择技术来提高预测效率。在五个公开数据集上进行测试。

Result: 实验结果显示，与传统模型相比，FAABE模型在多种误差指标上均有显著提升，证明了萤火虫-类比集成方法的有效性。

Conclusion: FAABE模型能够有效提高软件项目估算的准确性，为类比估算方法提供了优化方案。

Abstract: Analogy-Based Estimation (ABE) is a popular method for non-algorithmic estimation due to its simplicity and effectiveness. The Analogy-Based Estimation (ABE) model was proposed by researchers, however, no optimal approach for reliable estimation was developed. Achieving high accuracy in the ABE might be challenging for new software projects that differ from previous initiatives. This study (conducted in June 2024) proposes a Firefly Algorithm-guided Analogy-Based Estimation (FAABE) model that combines FA with ABE to improve estimation accuracy. The FAABE model was tested on five publicly accessible datasets: Cocomo81, Desharnais, China, Albrecht, Kemerer and Maxwell. To improve prediction efficiency, feature selection was used. The results were measured using a variety of evaluation metrics; various error measures include MMRE, MAE, MSE, and RMSE. Compared to conventional models, the experimental results show notable increases in prediction precision, demonstrating the efficacy of the Firefly-Analogy ensemble.

</details>


### [12] [Large Language Models for Software Engineering: A Reproducibility Crisis](https://arxiv.org/abs/2512.00651)
*Mohammed Latif Siddiq,Arvin Islam-Gomes,Natalie Sekerak,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 首次对LLM软件工程研究进行大规模可复现性实证研究，分析640篇论文发现可复现性气味普遍存在，评估徽章不能保证执行保真度，提出可复现性成熟度模型。


<details>
  <summary>Details</summary>
Motivation: 可复现性是科学进步的基石，但LLM软件工程研究的可复现性现状仍不清楚。需要系统评估该领域的可复现性实践，了解问题所在并提出改进方案。

Method: 系统挖掘分析2017-2025年间640篇顶级SE、ML、NLP会议论文，从出版物、仓库和文档中提取结构化元数据。基于七个气味类别（代码执行、数据、文档、环境工具、版本控制、模型、访问法律）手动标注所有论文和关联工件。

Result: 发现工件可用性、环境规范、版本控制严谨性和文档清晰度存在持续差距。评估徽章通常只表示工件存在，但不能保证执行保真度或长期可复现性。近年来虽有改进但问题依然存在。

Conclusion: 提出可操作建议缓解可复现性气味，引入可复现性成熟度模型，超越二元工件认证，实现多维渐进式可复现性严谨度评估。

Abstract: Reproducibility is a cornerstone of scientific progress, yet its state in large language model (LLM)-based software engineering (SE) research remains poorly understood. This paper presents the first large-scale, empirical study of reproducibility practices in LLM-for-SE research. We systematically mined and analyzed 640 papers published between 2017 and 2025 across premier software engineering, machine learning, and natural language processing venues, extracting structured metadata from publications, repositories, and documentation. Guided by four research questions, we examine (i) the prevalence of reproducibility smells, (ii) how reproducibility has evolved over time, (iii) whether artifact evaluation badges reliably reflect reproducibility quality, and (iv) how publication venues influence transparency practices. Using a taxonomy of seven smell categories: Code and Execution, Data, Documentation, Environment and Tooling, Versioning, Model, and Access and Legal, we manually annotated all papers and associated artifacts. Our analysis reveals persistent gaps in artifact availability, environment specification, versioning rigor, and documentation clarity, despite modest improvements in recent years and increased adoption of artifact evaluation processes at top SE venues. Notably, we find that badges often signal artifact presence but do not consistently guarantee execution fidelity or long-term reproducibility. Motivated by these findings, we provide actionable recommendations to mitigate reproducibility smells and introduce a Reproducibility Maturity Model (RMM) to move beyond binary artifact certification toward multi-dimensional, progressive evaluation of reproducibility rigor.

</details>


### [13] [Code Comments for Quantum Software Development Kits: An Empirical Study on Qiskit](https://arxiv.org/abs/2512.00766)
*Zenghui Zhou,Yuechen Li,Yi Cai,Jinlong Wen,Xiaohan Yu,Zheng Zheng,Beibei Yin*

Main category: cs.SE

TL;DR: CC4Q是首个量子计算代码注释数据集，包含9677个代码注释对和21970个句子级注释单元，通过实证研究揭示了量子软件与经典软件代码注释的关键差异。


<details>
  <summary>Details</summary>
Motivation: 量子计算SDK使程序员能够开发量子软件，但量子力学的非直观性给理解带来挑战。代码注释作为自然语言解释对开发维护很重要，但缺乏系统研究和指导。

Method: 基于最流行的量子SDK Qiskit构建CC4Q数据集，包含大量人工标注的注释单元。验证经典程序开发者意图分类的适用性，并提出考虑量子特定知识的新分类法。

Result: 从三个维度全面解读代码注释：注释结构与覆盖率、开发者意图、相关量子主题。发现量子与经典软件代码注释的关键差异，并勾勒出量子软件开发相关的量子特定知识。

Conclusion: CC4Q是首个量子计算代码注释数据集，为量子软件开发提供有价值的见解和指导，填补了该领域的研究空白。

Abstract: Quantum computing is gaining attention from academia and industry. With the quantum Software Development Kits (SDKs), programmers can develop quantum software to explore the power of quantum computing. However, programmers may face challenges in understanding quantum software due to the non-intuitive quantum mechanics. To facilitate software development and maintenance, code comments offered in quantum SDKs serve as a natural language explanation of program functionalities and logical flows. Despite their importance, scarce research systematically reports their value and provides constructive guidelines for programmers. To address this gap, our paper focuses on Qiskit, one of the most popular quantum SDKs, and presents CC4Q, the first dataset of code comments for quantum computing. CC4Q incorporates 9677 code comment pairs and 21970 sentence-level code comment units, the latter of which involve heavy human annotation. Regarding the annotation, we validate the applicability of the developer-intent taxonomy used in classical programs, and also propose a new taxonomy considering quantum-specific knowledge. We conduct an empirical study comprehensively interpreting code comments from three perspectives: comment structure and coverage, developers' intentions, and associated quantum topics. Our findings uncover key differences in code comments between classical and quantum software, and also outline quantum-specific knowledge relevant to quantum software development.

</details>


### [14] [FC-ADL: Efficient Microservice Anomaly Detection and Localisation Through Functional Connectivity](https://arxiv.org/abs/2512.00844)
*Giles Winchester,George Parisis,Luc Berthouze*

Main category: cs.SE

TL;DR: FC-ADL：基于功能连接性的微服务异常检测与定位方法，通过高效表征微服务指标间时变依赖关系变化，实现可扩展的异常检测和根因定位


<details>
  <summary>Details</summary>
Motivation: 微服务架构虽然带来了模块化和独立性，但也引入了服务集成和系统管理的操作复杂性，使得快速准确的异常检测和定位变得困难。现有方法要么缺乏对时变依赖关系的显式建模，要么因依赖计算昂贵的因果推理而难以扩展到大规模实际部署。

Method: 提出FC-ADL（功能连接性异常检测与定位）方法，基于神经科学中的功能连接性概念，高效表征微服务指标间时变依赖关系的变化，实现端到端的可扩展异常检测和根因定位，避免了因果和多变量方法的显著开销。

Result: 该方法在各种故障场景下实现了顶级的检测和定位性能，优于现有最先进方法。通过应用于阿里巴巴极大规模的真实微服务部署，证明了其可扩展性。

Conclusion: FC-ADL通过高效表征微服务指标间的时变依赖关系变化，提供了一种可扩展的异常检测和根因定位方法，能够应对大规模微服务部署的挑战，避免了传统因果推理方法的计算开销。

Abstract: Microservices have transformed software architecture through the creation of modular and independent services. However, they introduce operational complexities in service integration and system management that makes swift and accurate anomaly detection and localisation challenging. Despite the complex, dynamic, and interconnected nature of microservice architectures, prior works that investigate metrics for anomaly detection rarely include explicit information about time-varying interdependencies. And whilst prior works on fault localisation typically do incorporate information about dependencies between microservices, they scale poorly to real world large-scale deployments due to their reliance on computationally expensive causal inference. To address these challenges we propose FC-ADL, an end-to-end scalable approach for detecting and localising anomalous changes from microservice metrics based on the neuroscientific concept of functional connectivity. We show that by efficiently characterising time-varying changes in dependencies between microservice metrics we can both detect anomalies and provide root cause candidates without incurring the significant overheads of causal and multivariate approaches. We demonstrate that our approach can achieve top detection and localisation performance across a wide degree of different fault scenarios when compared to state-of-the-art approaches. Furthermore, we illustrate the scalability of our approach by applying it to Alibaba's extremely large real-world microservice deployment.

</details>


### [15] [The Software Infrastructure Attitude Scale (SIAS): A Questionnaire Instrument for Measuring Professionals' Attitudes Toward Technical and Sociotechnical Infrastructure](https://arxiv.org/abs/2512.00855)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Amin Milani Fard,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Hera Arif,Gianisa Adisaputri,Kelly Garcés,Anielle S. L. Andrade,Eyram Amedzor,Bimpe Ayoola,Keisha Gaspard-Chickoree,Arazoo Hoseyni*

Main category: cs.SE

TL;DR: 开发并验证了一个用于测量软件工程中技术和社会技术基础设施态度的心理测量量表


<details>
  <summary>Details</summary>
Motivation: 软件工程研究需要社会技术研究，因此需要定制化的心理测量量表来测量对技术和社会技术基础设施的态度

Method: 基于基础设施理论、态度理论和心理测量研究，定义目标构念并生成量表项目。对225名软件专业人员施测，采用分样本设计：一半进行探索性因子分析，另一半进行验证性因子分析，全样本进行效度检验

Result: EFA支持双因子结构（技术和社会技术基础设施），解释65%总方差；CFA确认模型拟合优度良好。量表具有良好的表面效度、内容效度、收敛效度、标准关联效度和区分效度

Conclusion: 该量表是测量软件工程中技术和社会技术基础设施态度的有效工具，有助于将心理测量严谨性整合到实证和行为软件工程研究中

Abstract: Context: Recent software engineering (SE) research has highlighted the need for sociotechnical research, implying a demand for customized psychometric scales. Objective: We define the concepts of technical and sociotechnical infrastructure in software engineering, and develop and validate a psychometric scale that measures attitudes toward them. Method: Grounded in theories of infrastructure, attitudes, and prior work on psychometric measurement, we defined the target constructs and generated scale items. The scale was administered to 225 software professionals and evaluated using a split sample. We conducted an exploratory factor analysis (EFA) on one half of the sample to uncover the underlying factor structure and performed a confirmatory factor analysis (CFA) on the other half to validate the structure. Further analyses with the whole sample assessed face, criterion-related, and discriminant validity. Results: EFA supported a two-factor structure (technical and sociotechnical infrastructure), accounting for 65% of the total variance with strong loadings. CFA confirmed excellent model fit. Face and content validity were supported by the item content reflecting cognitive, affective, and behavioral components. Both subscales were correlated with job satisfaction, perceived autonomy, and feedback from the job itself, supporting convergent validity. Regression analysis supported criterion-related validity, while the Heterotrait-Monotrait ratio of correlations (HTMT), the Fornell-Larcker criterion, and model comparison all supported discriminant validity. Discussion: The resulting scale is a valid instrument for measuring attitudes toward technical and sociotechnical infrastructure in software engineering research. Our work contributes to ongoing efforts to integrate psychological measurement rigor into empirical and behavioral software engineering research.

</details>


### [16] [The AI Attribution Paradox: Transparency as Social Strategy in Open-Source Software Development](https://arxiv.org/abs/2512.00867)
*Obada Kraishan*

Main category: cs.SE

TL;DR: 开发者使用AI编程助手时面临"AI归属悖论"：虽然95.2%的提交使用了AI，但只有29.5%明确披露，不同工具披露率差异巨大（Claude 80.5% vs Copilot 9.0%）。明确披露会引发适度审查，但工具选择对社区接受度影响更大20-30倍。


<details>
  <summary>Details</summary>
Motivation: 研究AI编程助手在软件开发中的透明度与归属实践，探讨开发者如何在承认AI协助和管理社区审查之间进行战略平衡，理解"AI归属悖论"现象。

Method: 分析2023-2025年间14,300个GitHub提交，涵盖7,393个仓库，研究8个主要AI工具的归属策略和社区响应，进行时间序列分析追踪规范演变。

Result: AI使用广泛（95.2%提交），但归属策略差异大：仅29.5%明确披露，工具间差异显著（Claude 80.5% vs Copilot 9.0%）。明确披露引发适度审查（多23%问题和21%评论），但工具选择对接受度预测影响大20-30倍。社区情绪中立，归属规范快速演变：明确归属从2024年初接近0%增至2025年末40%。

Conclusion: AI归属是战略沟通而非简单透明度，反映了算法问责和技术转型期间的规范形成。研究对开发者披露决策、平台归属机制设计和AI增强协作工作的新兴实践研究具有启示意义。

Abstract: AI coding assistants have transformed software development, raising questions about transparency and attribution practices. We examine the "AI attribution paradox": how developers strategically balance acknowledging AI assistance with managing community scrutiny. Analyzing 14,300 GitHub commits across 7,393 repositories from 2023-2025, we investigated attribution strategies and community responses across eight major AI tools. Results reveal widespread AI usage (95.2% of commits) but strategic attribution: only 29.5% employ explicit disclosure, with dramatic tool variation (Claude 80.5% versus Copilot 9.0%). Explicit attribution triggers modest scrutiny (23% more questions and 21% more comments) but tool choice matters 20-30 times more for predicting reception. Community sentiment remains neutral regardless of attribution type, suggesting curiosity rather than hostility. Temporal analyses show rapid norm evolution: explicit attribution increased from near-zero in early 2024 to 40% by late 2025, indicating community adaptation. These findings illuminate attribution as strategic communication rather than simple transparency, advancing understanding of algorithmic accountability and norm formation during technological transitions. We discuss implications for developers navigating disclosure decisions, platforms designing attribution mechanisms, and researchers studying emergent practices in AI-augmented collaborative work.

</details>


### [17] [Staying or Leaving? How Job Satisfaction, Embeddedness and Antecedents Predict Turnover Intentions of Software Professionals](https://arxiv.org/abs/2512.00869)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Hera Arif,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Gianisa Adisaputri*

Main category: cs.SE

TL;DR: 研究发现软件专业人员的工作满意度和工作嵌入度与离职意向显著负相关，而工作生活平衡无直接影响。工作生活平衡和工作质量是工作满意度的最强前因，组织公平是工作嵌入度的最强预测因子。


<details>
  <summary>Details</summary>
Motivation: 软件行业自愿离职现象普遍，增加了招聘和入职成本，并带来组织知识和隐性知识流失的风险。本研究旨在探讨工作满意度、工作生活平衡、工作嵌入度及其前因变量（包括工作质量、人格特质、对技术和社交技术基础设施的态度、组织公平感知）如何影响软件专业人员的离职意向。

Method: 采用地理多样化的横断面调查，收集了224名软件专业人员的数据，使用偏最小二乘结构方程模型（PLS-SEM）进行分析。模型包含反射性和形成性构念，基于职业心理学和软件工程文献检验了15个假设。

Result: 工作满意度和工作嵌入度与软件专业人员的离职意向显著负相关，而工作生活平衡没有直接影响。工作满意度的最强前因是工作生活平衡和工作质量，组织公平是工作嵌入度的最强预测因子。模型对关键结果变量的解释力显著高于先前在软件开发背景下的研究。

Conclusion: 提高工作满意度和工作嵌入度是保留软件专业人员的关键。通过提升工作质量、支持工作生活平衡和确保高组织公平可以间接降低离职意向。研究强调了心理因素（如工作满意度、工作嵌入度）和组织因素（如组织公平、工作质量）在理解软件专业人员离职意向中的重要性。

Abstract: Context: Voluntary turnover is common in the software industry, increasing recruitment and onboarding costs and the risk of losing organizational and tacit knowledge. Objective: This study investigates how job satisfaction, work-life balance, job embeddedness, and their antecedents, including job quality, personality traits, attitudes toward technical and sociotechnical infrastructure, and perceptions of organizational justice, relate to software professionals' turnover intentions. Method: We conducted a geographically diverse cross-sectional survey of software professionals (N = 224) and analyzed the data using partial least squares structural equation modeling (PLS-SEM). Our model includes both reflective and formative constructs and tests 15 hypotheses grounded in occupational psychology and software engineering literature. Results: Job satisfaction and embeddedness were significantly negatively associated with software professionals' turnover intentions, while work-life balance showed no direct effect. The strongest antecedents for job satisfaction were work-life balance and job quality, while organizational justice was the strongest predictor of job embeddedness. Discussion: The resulting PLS-SEM model has considerably higher explanatory power for key outcome variables than previous work conducted in the software development context, highlighting the importance of both psychological (e.g., job satisfaction, job embeddedness) and organizational (e.g., organizational justice, job quality) factors in understanding turnover intentions of software professionals. Our results imply that improving job satisfaction and job embeddedness is the key to retaining software professionals. In turn, enhancing job quality, supporting work-life balance, and ensuring high organizational justice can improve job satisfaction and embeddedness, indirectly reducing turnover intentions.

</details>


### [18] [Neural Variable Name Repair: Learning to Rename Identifiers for Readability](https://arxiv.org/abs/2512.01141)
*Muhammad Yousuf,Akshat Bagade,Chhittebbayi Penugonda,Maanas Baraya*

Main category: cs.SE

TL;DR: 基于Llama 3.1-8B构建的变量名修复系统，通过微调、LoRA适配器和重排序器，显著提升C++代码中变量名的修复准确率。


<details>
  <summary>Details</summary>
Motivation: 实际开发中，变量名常常过于通用或误导性，且函数缺乏文档，这降低了代码可读性，增加了bug风险，也阻碍了人类和LLM对代码的理解。因此需要自动修复变量名的工具。

Method: 1) 从BigCode的The Stack数据集中解析C++函数，用占位符替换单个标识符，以原始名称作为监督信号；2) 在Llama 3.1-8B基础上构建管道：包含预热和dropout调度、LoRA适配器、以及基于双编码器的重排序器对top-k候选进行重排。

Result: 在200个C++函数的测试集上：零样本Llama 3.1基线达到6.1%精确匹配；最佳LoRA微调模型达到43.1%精确匹配、50.2% Top-5命中率和82.03部分匹配分数；双编码器重排序器进一步提升了选择质量。

Conclusion: 任务特定微调加重排序是实用标识符修复工具的有效方法，显著优于零样本基线，为代码理解和维护提供了实用工具。

Abstract: Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode's The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.

</details>


### [19] [Beyond Greenfield: AI-Driven Productivity in Documentation and Brownfield Engineering](https://arxiv.org/abs/2512.01155)
*Krishna Kumaar Sharma*

Main category: cs.SE

TL;DR: D3框架：针对遗留系统工程的LLM辅助工作流，通过双代理提示架构（Builder生成、Reviewer评审）提升任务清晰度、文档质量和生产力


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注新开发或合成任务，缺乏针对遗留系统、不完整文档和碎片化架构知识的复杂环境的结构化工作流

Method: 提出Discover-Define-Deliver（D3）框架，采用角色分离提示策略和双代理架构（Builder生成候选输出，Reviewer提供结构化评审），通过52名软件从业者的探索性调查验证

Result: 参与者报告加权平均生产力提升26.9%，约77%参与者认知负荷降低，83%在Define阶段返工减少，任务清晰度、文档质量和认知负荷均有改善

Conclusion: 结构化LLM工作流在遗留系统工程中具有潜力，但结果基于自我报告而非受控实验，需要未来进行受控评估验证

Abstract: Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and reduced rework for 83% during the Define phase. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.

</details>


### [20] [LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost](https://arxiv.org/abs/2512.01232)
*Donghao Huang,Shila Chew,Anna Dutkiewicz,Zhaoxia Wang*

Main category: cs.SE

TL;DR: LLM-as-a-Judge (LAJ) 框架用于评估 Gherkin 验收测试，在 20 种模型配置上进行了全面分析，发现小模型（GPT-4o Mini）在准确性、可靠性和成本方面表现最佳，相比 GPT-5 实现了 78 倍成本降低。


<details>
  <summary>Details</summary>
Motivation: 大规模评估软件测试覆盖率仍然是 QA 流程中的瓶颈，需要一种生产就绪的、基于评分标准的框架来评估 Gherkin 验收测试，并提供结构化 JSON 输出。

Method: 提出了 LLM-as-a-Judge (LAJ) 框架，这是一个基于评分标准的评估系统。在 20 种模型配置（GPT-4、GPT-5 和开源模型）上对 100 个专家标注的脚本进行了 5 轮测试（共 500 次评估），引入了评估完成率 (ECR@1) 来量化首次尝试成功率。

Result: GPT-4o Mini 获得了最佳准确性（6.07 MAAE）、高可靠性（96.6% ECR@1）和低成本（每千次 1.01 美元），相比 GPT-5（高推理）实现了 78 倍成本降低且准确性更高。推理效果因模型系列而异：GPT-5 受益于增加推理（有可预测的准确性-成本权衡），而开源模型随着推理增加在所有维度上表现下降。成本范围达到 175 倍（每千次 0.45-78.96 美元）。

Conclusion: 小模型可以超越大模型，在软件测试评估中实现更好的准确性、可靠性和成本效益。推理效果具有模型依赖性，GPT-5 受益于更多推理而开源模型则相反。研究发布了数据集、框架和代码以支持可重复性和部署。

Abstract: Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.

</details>


### [21] [LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM](https://arxiv.org/abs/2512.01356)
*Yuxin Zhang,Yuxia Zhang,Zeyu Sun,Yanjie Jiang,Hui Liu*

Main category: cs.SE

TL;DR: LAURA：基于LLM的代码审查生成框架，通过审查知识增强和上下文感知，显著提升ChatGPT-4o和DeepSeek v3生成代码审查评论的质量


<details>
  <summary>Details</summary>
Motivation: 随着软件规模和复杂性的快速增长，代码审查已成为开发过程的瓶颈，因为其耗时、知识密集且缺乏经验丰富的开发者。现有自动代码审查方法主要依赖历史代码变更和审查评论，但忽略了代码变更上下文和先验审查知识等关键信息。

Method: 提出LAURA框架，集成审查范例检索、上下文增强和系统指导三个组件，增强ChatGPT-4o和DeepSeek v3生成代码审查评论的能力。同时构建了高质量数据集以解决现有数据集中大量低质量审查的问题。

Result: 实验结果显示，LAURA分别为ChatGPT-4o和DeepSeek v3生成完全正确或至少对开发者有帮助的审查评论的比例达到42.2%和40.4%，显著优于现有最先进基线方法。消融研究证实LAURA所有组件都对提升评论质量有积极贡献。

Conclusion: LAURA框架通过整合审查知识增强和上下文感知，有效提升了LLM生成代码审查评论的质量，为解决代码审查瓶颈问题提供了有效解决方案。

Abstract: Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.

</details>


### [22] [BackportBench: A Multilingual Benchmark for Automated Backporting of Patches](https://arxiv.org/abs/2512.01396)
*Zhiqing Zhong,Jiaming Huang,Pinjia He*

Main category: cs.SE

TL;DR: BackportBench：首个全面的补丁回移植基准测试套件，包含202个多语言补丁回移植问题，用于评估自动化回移植技术。研究发现基于代理的方法优于传统补丁移植方法，尤其在需要逻辑和结构变更的场景。


<details>
  <summary>Details</summary>
Motivation: 软件项目快速演进，但用户常因升级困难而继续使用存在漏洞的旧版本。手动回移植安全补丁耗时且易错，现有自动化技术效果不明确，缺乏全面评估基准。

Method: 提出BackportBench基准套件，包含来自PyPI、Maven、npm的202个多语言补丁回移植问题，每个都有可执行的Docker环境和相关测试用例。使用该基准评估现有补丁移植方法和基于LLM的技术。

Result: 基于代理的方法在性能上优于传统补丁移植方法，特别是在需要逻辑和结构变更的案例中。但不同编程语言的性能表现存在差异。

Conclusion: BackportBench为自动化回移植技术的开发和评估提供了首个全面基准。研究结果为未来自动化回移植工作的研究者和软件从业者提供了重要启示。

Abstract: Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics.
  To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.

</details>


### [23] [Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report](https://arxiv.org/abs/2512.01523)
*Pankaj Jalote,Y. Raghu Reddy,Vasudeva Varma*

Main category: cs.SE

TL;DR: 多机构在线协作教学实验：利用疫情后在线教学普及的优势，在软件工程高级主题中开展跨机构研究级课程，并邀请行业专家参与。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情使在线教学成为常态，这为多机构协作教学创造了机会。许多小型机构可能缺乏足够的师资或研究生来开设研究级课程，特别是在软件工程等应用领域。同时，行业对先进软件工程技术有需求，愿意参与教学。

Method: 在两所机构之间联合开设"AI in Software Engineering"在线研究级课程，并积极邀请行业专家参与教学和互动。采用多机构协作的在线教学模式。

Result: 成功实施了跨机构在线协作教学实验，获得了教师和学生的积极反馈。行业专家的参与丰富了课程内容，为学生提供了实践视角。

Conclusion: 这种协作教学模式可推广到计算机科学其他应用领域，特别适合小型机构联合开设研究级课程。在线平台降低了协作门槛，行业参与增强了课程的实用性和吸引力。

Abstract: Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled "AI in Software Engineering" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.

</details>


### [24] [OpenDORS: A dataset of openly referenced open research software](https://arxiv.org/abs/2512.01570)
*Stephan Druskat,Lars Grunske*

Main category: cs.SE

TL;DR: 该论文提出了一个包含134,352个开源研究软件项目和134,154个源代码仓库的大规模数据集，用于支持研究软件工程（RSE）的实证研究。


<details>
  <summary>Details</summary>
Motivation: 研究软件在学术研究中扮演着越来越重要的角色，但缺乏对研究软件及其开发的大规模研究。为了支持这类研究，需要构建一个全面的研究软件数据集。

Method: 从开放获取文献中收集并关联研究软件项目和源代码仓库，构建包含134,352个独特开源研究软件项目的数据集，并为122,425个仓库提供版本、许可证、编程语言等元数据。

Result: 成功创建了一个大规模的研究软件数据集，包含项目与文献的引用关系，以及详细的软件元数据，为研究软件实践的分析提供了基础。

Conclusion: 该数据集为研究软件工程领域的实证研究提供了重要资源，有助于更好地理解研究软件实践，推动研究软件工程的发展。

Abstract: In many academic disciplines, software is created during the research process or for a research purpose. The crucial role of software for research is increasingly acknowledged. The application of software engineering to research software has been formalized as research software engineering, to create better software that enables better research. Despite this, large-scale studies of research software and its development are still lacking. To enable such studies, we present a dataset of 134,352 unique open research software projects and 134,154 source code repositories referenced in open access literature. Each dataset record identifies the referencing publication and lists source code repositories of the software project. For 122,425 source code repositories, the dataset provides metadata on latest versions, license information, programming languages and descriptive metadata files. We summarize the distributions of these features in the dataset and describe additional software metadata that extends the dataset in future work. Finally, we suggest examples of research that could use the dataset to develop a better understanding of research software practice in RSE research.

</details>


### [25] [GPTrace: Effective Crash Deduplication Using LLM Embeddings](https://arxiv.org/abs/2512.01609)
*Patrick Herter,Vincent Ahlrichs,Ridvan Açilan,Julian Horsch*

Main category: cs.SE

TL;DR: GPTrace使用大语言模型嵌入向量对崩溃数据进行聚类，显著提升崩溃去重效果


<details>
  <summary>Details</summary>
Motivation: 模糊测试会产生大量崩溃输入，其中许多共享相同底层漏洞，现有基于堆栈跟踪的重复检测方法效果不佳，需要更有效的去重方案

Method: 利用大语言模型计算崩溃相关数据源的嵌入向量，然后通过聚类算法进行相似性评估和去重

Result: 在14个目标程序的30多万个崩溃输入、50个真实标签上评估，GPTrace相比手工堆栈跟踪比较方法和现有先进方法都有明显改进

Conclusion: GPTrace通过大语言模型嵌入和聚类算法，为崩溃去重提供了更灵活有效的解决方案

Abstract: Fuzzing is a highly effective method for uncovering software vulnerabilities, but analyzing the resulting data typically requires substantial manual effort. This is amplified by the fact that fuzzing campaigns often find a large number of crashing inputs, many of which share the same underlying bug. Crash deduplication is the task of finding such duplicate crashing inputs and thereby reducing the data that needs to be examined. Many existing deduplication approaches rely on comparing stack traces or other information that is collected when a program crashes. Although various metrics for measuring the similarity of such pieces of information have been proposed, many do not yield satisfactory deduplication results. In this work, we present GPTrace, a deduplication workflow that leverages a large language model to evaluate the similarity of various data sources associated with crashes by computing embedding vectors and supplying those as input to a clustering algorithm. We evaluate our approach on over 300 000 crashing inputs belonging to 50 ground truth labels from 14 different targets. The deduplication results produced by GPTrace show a noticeable improvement over hand-crafted stack trace comparison methods and even more complex state-of-the-art approaches that are less flexible.

</details>


### [26] [When High-Performance Computing Meets Software Testing: Distributed Fuzzing using MPI](https://arxiv.org/abs/2512.01617)
*Pierciro Caliandro,Matteo Ciccaglione,Alessandro Pellegrini*

Main category: cs.SE

TL;DR: MPI同步技术应用于分布式模糊测试，相比传统文件系统同步方法显著提升性能，减少通信延迟，提高覆盖率进展，解决覆盖停滞问题


<details>
  <summary>Details</summary>
Motivation: 传统分布式模糊测试使用文件系统进行节点间同步，通信延迟高，效率低下。需要更高效的同步机制来提升分布式模糊测试的性能和可扩展性

Method: 将MPI（消息传递接口）同步技术集成到分布式模糊测试框架中，使用轻量级MPI原语进行节点间通信，协调输入语料库交换，减少通信延迟

Result: 在标准基准测试中，MPI同步方法从模糊测试早期阶段就显示出更好的覆盖率进展，有效解决覆盖停滞问题，能够持续探索复杂和深层的执行路径

Conclusion: MPI同步方法显著提升了分布式模糊测试的可扩展性和有效性，特别适合集成到CI/CD流水线中，在软件开发各阶段提供高效的模糊测试能力

Abstract: This paper explores the integration of MPI-based synchronization techniques into distributed fuzzing frameworks, highlighting possible substantial performance improvements compared to traditional filesystem-based synchronization methods. By employing lightweight MPI primitives, reductions in communication latency are achieved, facilitating more efficient data exchanges across distributed fuzzing nodes. Experimental results obtained over standard benchmarks demonstrate enhanced coverage progression from the early stages of the fuzzing process, which could be beneficial if fuzzing is employed in CI/CD pipelines at any stage of software development. Furthermore, the coordinated exchange of input corpora among clusters of fuzzers effectively addresses coverage stagnation, enabling a sustained exploration of complex and deep execution paths. Overall, the adoption of MPI-based synchronization approaches shows promising potential for significantly enhancing the scalability and efficacy of distributed fuzz testing.

</details>


### [27] [Package Dashboard: A Cross-Ecosystem Framework for Dual-Perspective Analysis of Software Packages](https://arxiv.org/abs/2512.01630)
*Ziheng Liu,Runzhi He,Minghui Zhou*

Main category: cs.SE

TL;DR: Package Dashboard是一个跨生态系统的软件供应链分析框架，通过整合包元数据、漏洞信息和上游社区健康指标，提供统一的双视角风险评估平台，帮助开发者发现传统工具忽略的风险。


<details>
  <summary>Details</summary>
Motivation: 现有软件供应链分析工具存在局限性：通常只针对单一生态系统，且孤立地评估软件制品或社区活动。这种碎片化迫使开发者手动整合分散的数据，影响了风险评估的有效性。

Method: 开发Package Dashboard框架，整合包元数据、漏洞信息和上游社区健康指标，结合依赖解析和仓库分析，提供统一的供应链分析平台。该框架支持跨生态系统分析。

Result: 通过对5个Linux发行版的374,000个包进行大规模研究，证明了该框架不仅能发现传统漏洞和许可证冲突，还能识别被忽视的风险，如存档或无法访问的仓库。

Conclusion: Package Dashboard提供了统一的风险视图，为开发者和DevSecOps工程师提供可操作的见解，增强了开源生态系统的透明度、可信度和可追溯性。该工具已开源并提供在线版本。

Abstract: Software supply chain attacks have revealed blind spots in existing SCA tools, which are often limited to a single ecosystem and assess either software artifacts or community activity in isolation. This fragmentation across tools and ecosystems forces developers to manually reconcile scattered data, undermining risk assessments. We present Package Dashboard, a cross-ecosystem framework that provides a unified platform for supply chain analysis, enabling a holistic, dual-perspective risk assessment by integrating package metadata, vulnerability information, and upstream community health metrics. By combining dependency resolution with repository analysis, it reduces cognitive load and improves traceability. Demonstrating the framework's versatility, a large-scale study of 374,000 packages across five Linux distributions shows its ability to uncover not only conventional vulnerabilities and license conflicts but also overlooked risks such as archived or inaccessible repositories. Ultimately, Package Dashboard provides a unified view of risk, equipping developers and DevSecOps engineers with actionable insights to strengthen the transparency, trustworthiness, and traceability of open-source ecosystems. Package Dashboard is publicly available at https://github.com/n19htfall/PackageDashboard, and a demonstration video can be found at https://youtu.be/y9ncftP8KPQ. Besides, the online version is available at https://pkgdash.osslab-pku.org.

</details>


### [28] [MIT Lincoln Laboratory: A Case Study on Improving Software Support for Research Projects](https://arxiv.org/abs/2512.01649)
*Daniel Strassler,Gabe Elkin,Curran Schiefelbein,Daniel Herring,Ian Jessen,David Johnson,Santiago A. Paredes,Tod Shannon,Jim Flavin*

Main category: cs.SE

TL;DR: 林肯实验室研究如何改善研究软件开发效率与文化，提出通过工具集中化、人才匹配和利益相关者参与等建议来增强软件工程影响力。


<details>
  <summary>Details</summary>
Motivation: 软件在复杂系统开发和原型设计中作用日益重要，林肯实验室希望改进软件工程的效率和文化，以更好地支持其任务执行。

Method: 国土保护与空中交通管制部门进行内部研究，分析研究软件开发面临的挑战，识别加强文化和执行力的方法。

Result: 研究发现分为三类：影响软件开发活动的项目属性、集中化带来的潜在效率、改善软件从业人员配置和文化的机会。

Conclusion: 研究提出可操作建议：集中化和标准化软件支持工具、建立人才需求匹配数据库、创建软件利益相关者小组以持续改进。

Abstract: Software plays an ever increasing role in complex system development and prototyping, and in recent years, MIT Lincoln Laboratory has sought to improve both the effectiveness and culture surrounding software engineering in execution of its mission. The Homeland Protection and Air Traffic Control Division conducted an internal study to examine challenges to effective and efficient research software development, and to identify ways to strengthen both the culture and execution for greater impact on our mission. Key findings of this study fell into three main categories: project attributes that influence how software development activities must be conducted and managed, potential efficiencies from centralization, opportunities to improve staffing and culture with respect to software practitioners. The study delivered actionable recommendations, including centralizing and standardizing software support tooling, developing a common database to help match the right software talent and needs to projects, and creating a software stakeholder panel to assist with continued improvement.

</details>


### [29] [Generating REST API Tests With Descriptive Names](https://arxiv.org/abs/2512.01690)
*Philip Garrett,Juan P. Galeotti,Andrea Arcuri,Alexander Poth,Olsi Rrjolli*

Main category: cs.SE

TL;DR: 提出三种确定性技术为REST API测试生成描述性名称，规则方法在清晰度上媲美GPT-4o等先进LLM，显著优于GPT-3.5，工业案例证实可提升测试套件可读性


<details>
  <summary>Details</summary>
Motivation: 自动生成的API测试用例通常使用非描述性名称（如test0, test1），降低了可读性，影响理解和维护。需要为REST API测试自动生成描述性名称的方法

Method: 提出三种确定性技术生成REST API测试名称，共比较八种技术（包括规则启发式和LLM方法）。使用EvoMaster为9个开源API生成10个测试用例，通过两项调查（最多39人）和工业案例研究（大众汽车）进行实证评估

Result: 规则方法在确定性方法中获得最高清晰度评分，与Gemini和GPT-4o等先进LLM表现相当，显著优于GPT-3.5。工业案例中开发者确认描述性名称提高了测试套件可读性

Conclusion: 轻量级确定性技术可作为计算昂贵且安全敏感的LLM方法的有效替代方案，为自动化系统级测试命名提供了实用方法，使API测试生成更开发者友好

Abstract: Automated test generation has become a key technique for ensuring software quality, particularly in modern API-based architectures. However, automatically generated test cases are typically assigned non-descriptive names (e.g., test0, test1), which reduces their readability and hinders their usefulness during comprehension and maintenance. In this work, we present three novel deterministic techniques to generate REST API test names. We then compare eight techniques in total for generating descriptive names for REST API tests automatically produced by the fuzzer EvoMaster, using 10 test cases generated for 9 different open-source APIs. The eight techniques include rule-based heuristics and large language model (LLM)-based approaches. Their effectiveness was empirically evaluated through two surveys (involving up to 39 people recruited via LinkedIn). Our results show that a rule-based approach achieves the highest clarity ratings among deterministic methods, performs on par with state-of-the-art LLM-based models such as Gemini and GPT-4o, and significantly outperforms GPT-3.5.
  To further evaluate the practical impact of our results, an industrial case study was carried out with practitioners who actively use EvoMaster at Volkswagen AG. A developer questionnaire was then carried out based on the use of EvoMaster on four different APIs by four different users, for a total of 74 evaluated test cases. Feedback from practitioners further confirms that descriptive names produced by this approach improve test suite readability.
  These findings highlight that lightweight, deterministic techniques can serve as effective alternatives to computationally expensive and security-sensitive LLM-based approaches for automated system-level test naming, providing a practical step toward more developer-friendly API test generation.

</details>


### [30] [An Empirical Study of Agent Developer Practices in AI Agent Frameworks](https://arxiv.org/abs/2512.01939)
*Yanlin Wang,Xinyi Xu,Jiachi Chen,Tingting Bi,Wenchao Gu,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文首次对基于大语言模型的智能体框架进行实证研究，通过分析11,910个开发者讨论，从五个维度比较了十大框架的实际表现，揭示了框架间的显著差异，并为未来框架设计和开发者选择提供了见解。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，智能体框架快速发展，但实际应用效果和如何影响开发过程仍缺乏深入研究。开发者面临选择困难（超过80%难以找到适合需求的框架），且不同框架存在相似问题，需要系统性分析来改进框架设计和帮助开发者决策。

Method: 收集了十大智能体框架的11,910个开发者讨论，通过实证研究方法分析真实开发体验。从五个维度进行比较：开发效率、功能抽象、学习成本、性能优化、可维护性（包括框架本身和基于框架构建的智能体的更新扩展能力）。

Result: 比较分析显示不同框架在满足开发者需求方面存在显著差异。识别了各框架在五个维度上的优势和不足，揭示了智能体框架生态系统的现状和问题。

Conclusion: 研究为LLM驱动的智能体框架生态系统提供了一系列发现和启示，为未来基于LLM的智能体框架设计和开发者选择提供了有价值的见解，有助于改进框架设计和提升开发体验。

Abstract: The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [31] [Strong Normalization for the Safe Fragment of a Minimal Rewrite System: A Triple-Lexicographic Proof and a Conjecture on the Unprovability of Full Termination for Any Relational Operator-Only TRS](https://arxiv.org/abs/2512.00081)
*Moses Rahnama*

Main category: cs.LO

TL;DR: 提出一个仅含运算符的极小项重写系统，通过新颖的三重字典序度量证明强正规化，并展示简单度量方法对含项复制规则的系统必然失败。


<details>
  <summary>Details</summary>
Motivation: 研究自指系统终止性证明的基本限制，探索仅含运算符的项重写系统中终止性证明的内在局限性，特别是针对能够编码有序数据的系统。

Method: 构建仅含7个构造子和8个归约规则的极小系统，使用结合阶段位、多集序和序数排名的三重字典序度量，机械验证强正规化证明，并通过临界对分析验证局部合流性。

Result: 成功证明受保护片段的强正规化，获得经过认证的正规化器，展示加法计数器、多项式解释和单比特标志等简单度量方法对含项复制规则的系统必然失败。

Conclusion: 提出猜想：任何"关系型"（能够进行有序计算）的仅含运算符TRS，其全系统终止性无法通过内部可定义的方法证明，这揭示了自指系统终止性证明的基本结构限制。

Abstract: We present a minimal operator-only term rewriting system with seven constructors and eight reduction rules. Our main contribution is a mechanically-verified proof of strong normalization for a guarded fragment using a novel triple-lexicographic measure combining a phase bit, multiset ordering (Dershowitz-Manna), and ordinal ranking. From strong normalization, we derive a certified normalizer with proven totality and soundness. Assuming local confluence (verified through critical pair analysis), Newman's Lemma yields confluence and therefore unique normal forms for the safe fragment. We establish impossibility results showing that simpler measures, such as additive counters, polynomial interpretations, and single-bit flags, provably fail for rules with term duplication. The work demonstrates fundamental limitations in termination proving for self-referential systems. We state a conjecture: no relational operator-only TRS can have its full-system termination proved by internally definable methods. Here "relational" is equivalent to "capable of ordered computation" - systems with a recursor enabling iteration over successors, comparison, or sequential counting. Such recursors necessarily redistribute step arguments across recursive calls, defeating all additive termination measures. This structural limitation applies to any TRS expressive enough to encode ordered data. All theorems have been formally verified in a proof assistant. The formal development is available to program committee members and referees upon request for purposes of peer review.

</details>


### [32] [Compositional Inference for Bayesian Networks and Causality](https://arxiv.org/abs/2512.00209)
*Bart Jacobs,Márk Széles,Dario Stein*

Main category: cs.LO

TL;DR: 本文提出在概率推理的弦图中添加"移除规则"，用于删除归一化框，从而支持组合式推理，应用于贝叶斯网络、因果推理和反事实分析。


<details>
  <summary>Details</summary>
Motivation: 概率推理中的归一化操作与其他操作交互不佳，阻碍了组合式推理的发展。虽然弦图已能表示条件化（通过弯曲线和归一化框），但需要更完整的规则来支持推理过程的组合性。

Method: 在弦图形式体系中添加移除规则，允许删除归一化框。该规则与现有组合规则结合，形成完整的组合推理技术，通过图形示例展示其在贝叶斯网络、因果推理和反事实分析中的应用。

Result: 建立了包含移除规则的弦图形式体系，支持概率推理的组合性。通过图形示例展示了该技术能够有效处理贝叶斯网络推理、因果推理和反事实分析等复杂推理任务。

Conclusion: 添加移除规则使弦图形式体系更加完整，为概率推理提供了强大的组合工具，特别适用于贝叶斯网络、因果推理和反事实分析等复杂推理场景。

Abstract: Inference is a fundamental reasoning technique in probability theory. When applied to a large joint distribution, it involves updating with evidence (conditioning) in one or more components (variables) and computing the outcome in other components. When the joint distribution is represented by a Bayesian network, the network structure may be exploited to proceed in a compositional manner -- with great benefits. However, the main challenge is that updating involves (re)normalisation, making it an operation that interacts badly with other operations.
  String diagrams are becoming popular as a graphical technique for probabilistic (and quantum) reasoning. Conditioning has appeared in string diagrams, in terms of a disintegration, using bent wires and shaded (or dashed) normalisation boxes. It has become clear that such normalisation boxes do satisfy certain compositional rules. This paper takes a decisive step in this development by adding a removal rule to the formalism, for the deletion of shaded boxes. Via this removal rule one can get rid of shaded boxes and terminate an inference argument. This paper illustrates via many (graphical) examples how the resulting compositional inference technique can be used for Bayesian networks, causal reasoning and counterfactuals.

</details>


### [33] [A Hierarchy of Supermartingales for $ω$-Regular Verification](https://arxiv.org/abs/2512.00270)
*Satoshi Kura,Hiroshi Unno*

Main category: cs.LO

TL;DR: 提出三种新型上鞅证书用于验证ω-正则性质的几乎必然满足性：广义Streett上鞅、分布值Streett上鞅和进展测度上鞅，证明比现有Streett上鞅更强大，并提供合成算法和工具实现。


<details>
  <summary>Details</summary>
Motivation: 现有Streett上鞅在验证马尔可夫链的ω-正则性质时能力有限，需要更强大的证书形式来验证更广泛的几乎必然满足性问题。

Method: 基于马尔可夫链关于Streett条件的正递归和零递归的最小不动点特征，提出三种新型上鞅：广义Streett上鞅及其词典序扩展、分布值Streett上鞅、进展测度上鞅及其词典序扩展。

Result: 证明新证书严格比Streett上鞅更强大，广义Streett上鞅对正递归完备，分布值Streett上鞅对零递归完备，提供了合成词典序进展测度上鞅的可靠且相对完备算法。

Conclusion: 新提出的上鞅证书显著扩展了ω-正则性质验证能力，分布值Streett上鞅理论上是最强大的证书，工具实现成功验证了现有方法无法处理的案例。

Abstract: We propose new supermartingale-based certificates for verifying almost sure satisfaction of $ω$-regular properties: (1) generalised Streett supermartingales (GSSMs) and their lexicographic extension (LexGSSMs), (2) distribution-valued Streett supermartingales (DVSSMs), and (3) progress-measure supermartingales (PMSMs) and their lexicographic extension (LexPMSMs). GSSMs, LexGSSMs, and DVSSMs are derived from least-fixed point characterisations of positive recurrence and null recurrence of Markov chains with respect to given Streett conditions; and PMSMs and LexPMSMs are probabilistic extensions of parity progress measures. We study the hierarchy among these certificates and existing certificates, namely Streett supermartingales, by comparing the classes of problems that can be verified by each type of certificates. Notably, we show that our certificates are strictly more powerful than Streett supermartingales. We also prove completeness of GSSMs for positive recurrence and of DVSSMs for null recurrence: DVSSMs are, in theory, the most powerful certificates in the sense that for any Markov chain that almost surely satisfies a given $ω$-regular property, there exists a DVSSM certifying it. We provide a sound and relatively complete algorithm for synthesising LexPMSMs, the second most powerful certificates in the hierarchy. We have implemented a prototype tool based on this algorithm, and our experiments show that our tool can successfully synthesise certificates for various examples including those that cannot be certified by existing supermartingales.

</details>


### [34] [Reasoning about Quality in Hyperproperties](https://arxiv.org/abs/2512.00500)
*Samuel Graepler,Benjamin Monmege,Jean-Marc Talbot*

Main category: cs.LO

TL;DR: 论文提出在HyperLTL中引入定性推理，允许公式在[0,1]区间取值，以处理严格安全属性在实际系统中难以满足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有超属性规范（如HyperLTL）要求严格的系统安全属性，但实际系统往往无法完全满足这些严格要求，导致模型检查失效。需要一种能够量化评估属性满足程度的机制。

Method: 受Almagor等人对LTL定性推理工作的启发，将HyperLTL扩展为具有[0,1]区间取值的定性版本，考虑命题质量（规范满足程度）或时序质量（规范何时满足）。

Result: 证明了近似模型检查问题的可判定性，以及多个大型片段的模型检查可行性。

Conclusion: 通过引入定性推理到HyperLTL中，为超属性规范提供了更实用的评估框架，能够处理实际系统中难以完全满足严格安全要求的情况。

Abstract: Hyperproperties allow one to specify properties of systems that inherently involve not single executions of the system, but several of them at once: observational determinism and non-inference are two examples of such properties used to study the security of systems. Logics like HyperLTL have been studied in the past to model check hyperproperties of systems. However, most of the time, requiring strict security properties is actually ineffective as systems do not meet such requirements. To overcome this issue, we introduce qualitative reasoning in HyperLTL, inspired by a similar work on LTL by Almagor, Boker and Kupferman where a formula has a value in the interval [0, 1], obtained by considering either a propositional quality (how much the specification is satisfied), or a temporal quality (when the specification is satisfied). We show decidability of the approximated model checking problem, as well as the model checking of large fragments.

</details>


### [35] [Computational Paths Form a Weak ω-Groupoid](https://arxiv.org/abs/2512.00657)
*Arthur F. Ramos,Tiago M. L. de Veras,Ruy J. G. B. de Queiroz,Anjolina G. de Oliveira*

Main category: cs.LO

TL;DR: 该论文证明计算路径（computational paths）在任意类型上构成弱ω-群胚，提供了完全显式的相干性数据，并在Lean 4中形式化验证。


<details>
  <summary>Details</summary>
Motivation: 虽然Lumsdaine和van den Berg-Garner证明了Martin-Löf类型论中的类型具有弱ω-群胚结构，但他们的证明依赖恒等类型的抽象性质，缺乏相干性见证的具体计算内容。本文旨在为计算路径（一种基于LNDEQ-TRS重写系统的等式替代表述）建立类似结果，提供完全显式的相干性数据。

Method: 使用计算路径作为等式表述，其中见证是来自LNDEQ-TRS重写系统的显式重写序列。定义了所有维度上的群胚操作（恒等、复合、逆），并通过具体重写推导而非抽象存在性证明来见证相干性定律。利用重写系统的规范化算法推导出维度≥3的收缩性。

Result: 证明了计算路径在任意类型上形成弱ω-群胚，具有完全显式的相干性数据：1）所有维度的n-细胞塔；2）由重写规则构建的显式五边形和三角形相干性；3）维度≥3的收缩性，确保所有平行高维细胞连通。整个构造已在Lean 4中形式化验证。

Conclusion: 计算路径提供了弱ω-群胚结构的显式计算实现，将高阶范畴结构建立在具体计算内容之上。与先前抽象证明相比，本文方法提供了完全显式的相干性见证，并通过机器验证确保了正确性。

Abstract: Lumsdaine (2010) and van den Berg-Garner (2011) proved that types in Martin-Löf type theory carry the structure of weak ω-groupoids. Their proofs, while foundational, rely on abstract properties of the identity type without providing explicit computational content for coherence witnesses. We establish an analogous result for computational paths -- an alternative formulation of equality where witnesses are explicit sequences of rewrites from the LNDEQ-TRS term rewriting system. Our main result is that computational paths on any type form a weak ω-groupoid with fully explicit coherence data. The groupoid operations -- identity, composition, and inverse -- are defined at every dimension, and the coherence laws (associativity, unit laws, inverse laws) are witnessed by concrete rewrite derivations rather than abstract existence proofs. The construction provides: (i) a proper tower of n-cells for all dimensions, with 2-cells as derivations between paths and higher cells mediating between lower-dimensional witnesses; (ii) explicit pentagon and triangle coherences built from the rewrite rules; and (iii) contractibility at dimensions $\geq 3$, ensuring all parallel higher cells are connected. The contractibility property is derived from the normalization algorithm of the rewrite system, grounding the higher-dimensional structure in concrete computational content. The entire construction has been formalized in Lean 4, providing machine-checked verification of the weak ω-groupoid structure.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [36] [A Word Sampler for Well-Typed Functions](https://arxiv.org/abs/2512.01036)
*Breandan Considine*

Main category: cs.PL

TL;DR: 提出一种用于简单类型一阶函数式编程语言的精确采样器，能够从有限自动机定义的语言中均匀无放回地采样随机函数


<details>
  <summary>Details</summary>
Motivation: 需要从类型良好的函数集合中均匀采样随机函数，以支持程序分析、测试生成等应用

Method: 通过固定参数可归约性，将语法导向的类型系统归约为上下文无关文法，同时保持类型安全性和完整性

Result: 实现了从有限自动机定义的语言中均匀无放回采样随机函数，保留了形式语言的稳健元理论

Conclusion: 该方法成功地将类型系统与形式语言理论相结合，为程序采样提供了理论基础和实用工具

Abstract: We describe an exact sampler for a simply-typed, first-order functional programming language. Given an acyclic finite automaton, $α_{\varnothing}$, it samples a random function uniformly without replacement from well-typed functions in $\mathcal{L}(α_{\varnothing})$. This is achieved via a fixed-parameter tractable reduction from a syntax-directed type system to a context-free grammar, preserving type soundness and completeness w.r.t. $\mathcal{L}(α_{\varnothing})$, while retaining the robust metatheory of formal languages.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [37] [Unconditional Time and Space Complexity Lower Bounds for Intersection Non-Emptiness](https://arxiv.org/abs/2512.00297)
*Michael Wehar*

Main category: cs.FL

TL;DR: 本文重新研究了确定性有限自动机（DFA）交集非空问题的已知下界，通过条件复杂度下界强化和无条件下界证明，探讨了该问题的计算复杂性及其对复杂性理论的影响。


<details>
  <summary>Details</summary>
Motivation: 重新研究DFA交集非空问题的计算复杂性下界，旨在深化对该问题难度的理解，并探索其在复杂性理论中的更广泛意义。

Method: 1. 强化Kasai和Iwata（1985）的条件时间复杂性下界；2. 应用Williams（2025）关于确定性时间空间高效模拟的突破性成果，证明无条件时间复杂性下界；3. 分析固定数量DFA的交集非空问题在固定多项式时间复杂性类中的计算难度可能带来的影响。

Result: 1. 强化了条件时间复杂性下界：除非存在更高效的NL算法，否则交集非空问题无法更高效求解；2. 证明了无条件时间复杂性下界：Ω(n²/(log³(n)·loglog²(n)))；3. 揭示了如果固定数量DFA的交集非空问题在固定多项式时间类中计算困难，将导致PTIME ⊆ DSPACE(n^c)和PSPACE = EXPTIME等复杂性理论结果。

Conclusion: DFA交集非空问题具有显著的计算复杂性，其下界研究不仅深化了对该特定问题的理解，还揭示了与更广泛复杂性理论问题的深刻联系，特别是通过Williams的最新成果获得了无条件下界，并为复杂性类之间的关系提供了新的视角。

Abstract: We reinvestigate known lower bounds for the Intersection Non-Emptiness Problem for Deterministic Finite Automata (DFA's). We first strengthen conditional time complexity lower bounds from T. Kasai and S. Iwata (1985) which showed that Intersection Non-Emptiness is not solvable more efficiently unless there exist more efficient algorithms for non-deterministic logarithmic space ($\texttt{NL}$). Next, we apply a recent breakthrough from R. Williams (2025) on the space efficient simulation of deterministic time to show an unconditional $Ω(\frac{n^2}{\log^3(n) \log\log^2(n)})$ time complexity lower bound for Intersection Non-Emptiness. Finally, we consider implications that would follow if Intersection Non-Emptiness for a fixed number of DFA's is computationally hard for a fixed polynomial time complexity class. These implications include $\texttt{PTIME} \subseteq \texttt{DSPACE}(n^c)$ for some $c \in \mathbb{N}$ and $\texttt{PSPACE} = \texttt{EXPTIME}$.

</details>


### [38] [Counting and Sampling Traces in Regular Languages](https://arxiv.org/abs/2512.00314)
*Alexis de Colnet,Kuldeep S. Meel,Umang Mathur*

Main category: cs.FL

TL;DR: 研究在正则语言中计数和采样Mazurkiewicz迹的问题，针对有界模型检验和并发程序测试的应用场景


<details>
  <summary>Details</summary>
Motivation: 该研究受到有界模型检验中部分序约简和并发程序测试方法的驱动，需要估计约简后的状态空间大小，并进行部分序感知的随机探索

Method: 首先证明计数问题对确定性自动机也是#P难的，然后证明该问题对NFA和DFA都属于#P类。主要算法贡献是开发了FPRAS近似计数算法和FPAUS近似均匀采样算法

Result: 证明了计数问题的复杂性特征，并设计了高效的随机近似算法：FPRAS能以高概率提供指定精度的近似计数，FPAUS能生成接近均匀分布的迹样本

Conclusion: 该工作为Mazurkiewicz迹的计数和采样问题提供了完整的复杂性分析和实用算法，为有界模型检验和并发程序测试提供了有效的工具

Abstract: In this work, we study the problems of counting and sampling Mazurkiewicz traces that a regular language touches. Fix an alphabet $Σ$ and an independence relation $\mathbb{I} \subseteq Σ\times Σ$. The input consists of a regular language $L \subseteq Σ^*$, given by a finite automaton with $m$ states, and a natural number $n$ (in unary). For the counting problem, the goal is to compute the number of Mazurkiewicz traces (induced by $\mathbb{I}$) that intersect the $n^\text{th}$ slice $L_n = L \cap Σ^n$, i.e., traces that admit at least one linearization in $L_n$. For the sampling problem, the goal is to output a trace drawn from a distribution that is approximately uniform over all such traces. These tasks are motivated by bounded model checking with partial-order reduction, where an \emph{a priori} estimate of the reduced state space is valuable, and by testing methods for concurrent programs that use partial-order-aware random exploration.
  We first show that the counting problem is #P-hard even when $L$ is accepted by a deterministic automaton, in sharp contrast to counting words of a DFA, which is polynomial-time solvable. We then prove that the problem lies in #P for both NFAs and DFAs, irrespective of whether $L$ is trace-closed. Our main algorithmic contributions are a \emph{fully polynomial-time randomized approximation scheme} (FPRAS) that, with high probability, approximates the desired count within a prescribed accuracy, and a \emph{fully polynomial-time almost uniform sampler} (FPAUS) that generates traces whose distribution is provably close to uniform.

</details>


### [39] [Tahr: The Generative Attribute Grammar Framework](https://arxiv.org/abs/2512.01872)
*Matteo Ciccaglione,Pierciro Caliandro,Alessandro Pellegrini*

Main category: cs.FL

TL;DR: Tahr是一个属性文法框架，可将文法规范转换为可编程的软件构件，支持算法测试、语言翻译和文本生成。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够将属性文法规范自动转换为可编程软件构件的框架，以支持文法操作测试、语言翻译和文本生成，解决传统文法处理工具在程序化使用方面的限制。

Method: Tahr框架允许用户指定属性文法，然后自动生成相应的软件构件。框架处理文法歧义问题，并能有效利用歧义进行文本生成。通过组织化的架构支持文法操作和翻译功能。

Result: 通过将MIPS程序翻译为x86架构和自定义虚拟机的等效程序，验证了Tahr框架的正确性和实用性，展示了其在语言翻译方面的实际应用能力。

Conclusion: Tahr框架成功实现了属性文法到可编程构件的自动转换，支持文法操作测试和语言翻译，特别是在处理歧义文法方面具有优势，为文本生成和程序翻译提供了有效工具。

Abstract: In this article, we present Tahr, a framework that allows taking attribute grammar specifications and generating a set of software artefacts that can be used programmatically to operate on text compliant with the grammars. Tahr can be used as an algorithmic workbench to test different manipulations of attribute grammars and support translation between different languages out of the box. We describe the framework's organisation, how the user can specify an attribute grammar, and the generated software artefacts. We also discuss how Tahr deals with ambiguous grammar specifications, and how this ambiguity can be effectively exploited when using attribute grammars for text generation. We test the correctness of Tahr by showing the practical possibility of translating MIPS programs into their corresponding equivalents for x86 architectures and a custom virtual machine.

</details>


### [40] [Bounded treewidth, multiple context-free grammars, and downward closures](https://arxiv.org/abs/2512.01973)
*C. Aiswarya,Pascal Baumann,Prakash Saivasan,Lia Schütze,Georg Zetzsche*

Main category: cs.FL

TL;DR: 该论文揭示了MSO可定义有界特殊树宽系统与多上下文无关语言之间的等价关系，并利用此连接为这类系统提供了最优的下闭包计算算法。


<details>
  <summary>Details</summary>
Motivation: 多下推自动机的可达性问题在递归程序静态分析中有重要应用，但这些问题不可判定。虽然有界树宽提供了可判定的近似方法，但这些系统的字语言（执行对应的动作序列）仍未被充分理解。

Method: 研究MSO可定义有界特殊树宽系统，揭示其与计算语言学中的多上下文无关语言之间的等价关系。利用这种连接为这类系统设计下闭包计算算法。

Result: 证明了MSO可定义有界特殊树宽系统的字语言恰好是多上下文无关语言。基于此连接，为这类系统提供了最优的下闭包计算算法。

Conclusion: 该工作建立了形式语言理论与程序验证之间的重要桥梁，使得在动态生成MSO可定义有界特殊树宽进程的程序中，安全性验证的复杂度与顺序递归进程情况相同。

Abstract: The reachability problem in multi-pushdown automata (MPDA) has many applications in static analysis of recursive programs. An example is safety verification of multi-threaded recursive programs with shared memory. Since these problems are undecidable, the literature contains many decidable (and efficient) underapproximations of MPDA.
  A uniform framework that captures many of these underapproximations is that of bounded treewidth (tw): To each execution of the MPDA, we associate a graph; then we consider the subset of all graphs that have a wt at most $k$, for some constant $k$. In fact, bounding tw is a generic approach to obtain classes of systems with decidable reachability, even beyond MPDA underapproximations. The resulting systems are also called MSO-definable bounded-tw systems.
  While bounded tw is a powerful tool for reachability and similar types of analysis, the word languages (i.e. action sequences corresponding to executions) of these systems remain far from understood.
  For the slight restriction of bounded special tw, or "bounded-stw" (which is equivalent to bounded tw on MPDA, and even includes all bounded-tw systems studied in the literature), this work reveals a connection with multiple context-free languages (MCFL), a concept from computational linguistics. We show that the word languages of MSO-definable bounded-stw systems are exactly the MCFL.
  We exploit this connection to provide an optimal algorithm for computing downward closures (dcl) for MSO-definable bounded-stw systems. Computing dcl is a notoriously difficult task that has many applications in the verification of complex systems: As an example application, we show that in programs with dynamic spawning of MSO-definable bounded-stw processes, safety verification has the same complexity as in the case of processes with sequential recursive processes.

</details>
