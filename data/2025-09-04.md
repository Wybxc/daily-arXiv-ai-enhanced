<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Semantically Reflected Programs](https://arxiv.org/abs/2509.03318)
*Eduard Kamburjan,Vidar Norstein Klungre,Yuanwei Qu,Rudolf Schlatte,Egor V. Kostylev,Martin Giese,Einar Broch Johnsen*

Main category: cs.PL

TL;DR: 该论文通过语义提升程序来解决结构知识和行为知识形式化之间的二分法，建立程序与知识图谱之间的直观连接，将程序状态转换为知识图谱并在编程语言中提供语义反射层。


<details>
  <summary>Details</summary>
Motivation: 知识图谱和本体论能有效表示系统的个体和通用知识，而编程语言专注于描述系统演化，两者之间存在形式化方法的二分法。论文旨在通过语义提升来弥合这一差距。

Method: 引入面向对象编程语言的语义提升技术，将执行程序的状态转换为知识图谱，并在编程语言内部提供语义反射层。基于小型编程语言SMOL进行形式化，包括操作语义、类型正确性和运行时程序查询的虚拟化。

Result: 开发了语义提升和语义反射的形式化框架，通过地质建模案例研究展示了技术的应用，并提供了开源的语言实现。

Conclusion: 语义提升和语义反射技术成功连接了程序执行和知识表示，使程序员能够在程序中利用应用领域的知识，为解决结构-行为知识二分法提供了有效方案。

Abstract: This paper addresses the dichotomy between the formalization of structural
and the formalization of behavioral knowledge by means of semantically lifted
programs, which explore an intuitive connection between programs and knowledge
graphs. While knowledge graphs and ontologies are eminently useful to represent
formal knowledge about a system's individuals and universals, programming
languages are designed to describe the system's evolution. To address this
dichotomy, we introduce a semantic lifting of the program states of an
executing program into a knowledge graph, for an object-oriented programming
language. The resulting graph is exposed as a semantic reflection layer within
the programming language, allowing programmers to leverage knowledge of the
application domain in their programs. In this paper, we formalize semantic
lifting and semantic reflection for a small programming language, SMOL, explain
the operational aspects of the language, and consider type correctness and
virtualisation for runtime program queries through the semantic reflection
layer. We illustrate semantic lifting and semantic reflection through a case
study of geological modelling and discuss different applications of the
technique. The language implementation is open source and available online.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [2] [Store Languages of Turing Machines and Counter Machines](https://arxiv.org/abs/2509.02828)
*Noah Friesen,Oscar H. Ibarra,Jozef Jirásek,Ian McQuillan*

Main category: cs.FL

TL;DR: 有限访问非确定性图灵机的存储语言是正则语言，增强版本可由反转有界计数器接受，在验证和容错领域有应用


<details>
  <summary>Details</summary>
Motivation: 研究有限访问图灵机及其扩展模型的存储语言性质，探索其在形式验证、容错系统和语言理论中的应用价值

Method: 分析一类特殊的图灵机模型——单向非确定性有限访问图灵机(fvNTM)，证明其存储语言的正则性，并扩展到带反转有界计数器的增强版本

Result: 证明了所有fvNTM的存储语言都是正则语言；增强版fvNTM的存储语言可由仅含反转有界计数器的机器接受；给出了在验证、容错和右商问题中的应用

Conclusion: 有限访问条件保证了存储语言的正则性，这一结果为复杂系统验证提供了新的理论工具，并揭示了存储语言与机器计算能力之间的深刻联系

Abstract: The store language of an automaton is the set of store configurations (state
and store contents, but not the input) that can appear as an intermediate step
in an accepting computation. A one-way nondeterministic finite-visit Turing
machine (fvNTM) is a Turing machine with a one-way read-only input tape, and a
single worktape, where there is some number $k$ such that in every accepting
computation, each worktape cell is visited at most $k$ times. We show that the
store language of every fvNTM is a regular language. Furthermore, we show that
the store language of every fvNTM augmented by reversal-bounded counters can be
accepted by a machine with only reversal-bounded counters and no worktape.
Several applications are given to problems in the areas of verification and
fault tolerance, and to the study of right quotients. We also continue the
investigation of the store languages of one-way and two-way machine models
where we present some conditions under which their store languages are
recursive or non-recursive.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems](https://arxiv.org/abs/2509.02860)
*Connor Wojtak,Darek Gajewski,Tomas Cerny*

Main category: cs.SE

TL;DR: 通过静态重构微服务源码为形式系统模型，利用SMT约束满足求解器进行形式验证，解决微服务系统在分布式开发中的维护性和可靠性问题


<details>
  <summary>Details</summary>
Motivation: 微服务系统在分布式开发和持续集成中容易出现沟通不良和实现不兼容问题，影响系统维护性和可靠性

Method: 静态重构微服务源码为形式系统模型，生成SMT约束集合进行形式验证，支持多种跨切关注点

Result: 提出了一种可扩展的方法论，能够验证系统架构关注点，并考虑安全策略等其他关注点

Conclusion: 该方法论通过形式化验证有效解决微服务系统的维护性和可靠性挑战，为未来扩展和评估基础了方向

Abstract: Microservice systems are becoming increasingly adopted due to their
scalability, decentralized development, and support for continuous integration
and delivery (CI/CD). However, this decentralized development by separate teams
and continuous evolution can introduce miscommunication and incompatible
implementations, undermining system maintainability and reliability across
aspects from security policy to system architecture. We propose a novel
methodology that statically reconstructs microservice source code into a formal
system model. From this model, a Satisfiability Modulo Theories (SMT)
constraint set can be derived, enabling formal verification. Our methodology is
extensible, supporting software verification across multiple cross-cutting
concerns. We focus on applying the methodology to verify the system
architecture concern, presenting formal reasoning to validate the methodology's
correctness and applicability for this concern. Additional concerns such as
security policy implementation are considered. Future directions are
established to extend and evaluate the methodology.

</details>


### [4] [Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations](https://arxiv.org/abs/2509.03093)
*Fatih Pehlivan,Arçin Ülkü Ergüzen,Sahand Moslemi Yengejeh,Mayasah Lami,Anil Koyuncu*

Main category: cs.SE

TL;DR: 本文提出了一种基于提示工程的LLM评估方法，用于检测多语言代码库中的SOLID原则违反情况，发现GPT-4o Mini表现最佳但仍有挑战，提示策略对检测准确率有显著影响。


<details>
  <summary>Details</summary>
Motivation: 传统静态分析方法难以检测语义设计缺陷（如SOLID原则违反），现有解决方案通常只关注单个原则或特定语言，缺乏跨所有五个原则和多语言代码库的检测能力。

Method: 构建包含240个手动验证代码示例的新基准数据集，测试四种不同的提示策略（零样本、少样本、思维链等），评估四种领先LLM模型在检测五个SOLID原则违反方面的能力。

Result: GPT-4o Mini明显优于其他模型，但在DIP等挑战性原则方面仍有困难；提示策略对准确率有显著影响，但没有单一最佳策略；检测准确率受语言特性和代码复杂度影响较大。

Conclusion: 有效的AI驱动设计分析需要根据具体设计上下文匹配合适的模型和提示策略，而非单一最佳模型，展示了LLM通过AI辅助代码分析支持可维护性的潜力。

Abstract: Traditional static analysis methods struggle to detect semantic design flaws,
such as violations of the SOLID principles, which require a strong
understanding of object-oriented design patterns and principles. Existing
solutions typically focus on individual SOLID principles or specific
programming languages, leaving a gap in the ability to detect violations across
all five principles in multi-language codebases. This paper presents a new
approach: a methodology that leverages tailored prompt engineering to assess
LLMs on their ability to detect SOLID violations across multiple languages. We
present a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,
and GPT-4o Mini-on their ability to detect violations of all five SOLID
principles. For this evaluation, we construct a new benchmark dataset of 240
manually validated code examples. Using this dataset, we test four distinct
prompt strategies inspired by established zero-shot, few-shot, and
chain-of-thought techniques to systematically measure their impact on detection
accuracy. Our emerging results reveal a stark hierarchy among models, with
GPT-4o Mini decisively outperforming others, yet even struggles with
challenging principles like DIP. Crucially, we show that prompt strategy has a
dramatic impact, but no single strategy is universally best; for instance, a
deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE
prompt is superior for DIP violations. Across all experiments, detection
accuracy is heavily influenced by language characteristics and degrades sharply
with increasing code complexity. These initial findings demonstrate that
effective, AI-driven design analysis requires not a single best model, but a
tailored approach that matches the right model and prompt to the specific
design context, highlighting the potential of LLMs to support maintainability
through AI-assisted code analysis.

</details>


### [5] [AI Safety Assurance in Electric Vehicles: A Case Study on AI-Driven SOC Estimation](https://arxiv.org/abs/2509.03270)
*Martin Skoglund,Fredrik Warg,Aria Mirzai,Anders Thorsen,Karl Lundgren,Peter Folkesson,Bastian Havers-zulka*

Main category: cs.SE

TL;DR: 本文探讨了如何结合ISO 26262和ISO/PAS 8800标准对电动汽车中AI组件进行独立安全评估，以AI驱动的电池SOC估计为例，通过故障注入实验测试鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车中AI技术的应用给功能安全保证带来新挑战，传统评估方法无法有效评估AI功能，需要发展新的标准和实践方法。

Method: 结合ISO 26262和ISO/PAS 8800标准，采用故障注入实验方法，系统性地引入扰动传感器输入来评估AI组件的鲁棒性。

Result: 识别了扩展评估方法中独立评估的关键特征，成功对AI驱动的电池SOC估计组件进行了鲁棒性测试。

Conclusion: 通过整合现有功能安全标准和新发布的AI安全标准，可以建立有效的AI组件独立评估框架，为电动汽车AI功能的安全保证提供可行方案。

Abstract: Integrating Artificial Intelligence (AI) technology in electric vehicles (EV)
introduces unique challenges for safety assurance, particularly within the
framework of ISO 26262, which governs functional safety in the automotive
domain. Traditional assessment methodologies are not geared toward evaluating
AI-based functions and require evolving standards and practices. This paper
explores how an independent assessment of an AI component in an EV can be
achieved when combining ISO 26262 with the recently released ISO/PAS 8800,
whose scope is AI safety for road vehicles. The AI-driven State of Charge (SOC)
battery estimation exemplifies the process. Key features relevant to the
independent assessment of this extended evaluation approach are identified. As
part of the evaluation, robustness testing of the AI component is conducted
using fault injection experiments, wherein perturbed sensor inputs are
systematically introduced to assess the component's resilience to input
variance.

</details>


### [6] [VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities](https://arxiv.org/abs/2509.03331)
*Weizhe Wang,Wei Ma,Qiang Hu,Yao Zhang,Jianfei Sun,Bin Wu,Yang Liu,Guangquan Xu,Lingxiao Jiang*

Main category: cs.SE

TL;DR: VulnRepairEval是一个基于PoC漏洞利用的LLM漏洞修复评估框架，发现现有LLM在真实漏洞修复中表现不佳（最佳模型仅修复21.7%的漏洞），暴露了安全应用中的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞修复数据集主要依赖表面验证而非基于漏洞利用的验证，导致在安全敏感应用中高估了LLM的性能表现。

Method: 构建了包含23个Python CVE真实漏洞实例的基准测试集，使用容器化评估管道进行可重现的差分评估，要求修复成功后原始漏洞利用必须失效。

Result: 评估12个流行LLM发现性能显著不足，最佳模型仅成功修复5/23个实例（21.7%）。失败分析显示主要问题是不精确的漏洞识别和包含语法/语义错误的补丁。

Conclusion: 提出了严格的实用评估框架，强调需要真实反映现实世界漏洞利用场景的评估协议，现有LLM在漏洞修复方面仍有重大挑战。

Abstract: The adoption of Large Language Models (LLMs) for automated software
vulnerability patching has shown promising outcomes on carefully curated
evaluation sets. Nevertheless, existing datasets predominantly rely on
superficial validation methods rather than exploit-based verification, leading
to overestimated performance in security-sensitive applications. This paper
introduces VulnRepairEval, an evaluation framework anchored in functional
Proof-of-Concept (PoC) exploits. Our framework delivers a comprehensive,
containerized evaluation pipeline that enables reproducible differential
assessment, where repair success requires the original exploit to fail
execution against the modified code. The benchmark construction involved
extensive data curation: we processed over 400 CVEs and approximately 2,500
potential sources to extract a collection of authentic vulnerability instances
(23 Python CVEs) amenable to automated testing with working PoCs. Through
VulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and
observe a significant performance deficit: even the top-performing model
successfully addresses merely 5/23 instances (about 21.7%), exposing critical
weaknesses in security-focused applications. Our failure analysis reveals that
most unsuccessful attempts stem from imprecise vulnerability identification and
patches containing syntactic or semantic errors. Enhanced prompting strategies
and multi-agent approaches yield minimal improvements, with overall
effectiveness remaining largely unaffected. This work contributes a stringent,
practical evaluation framework for LLM-driven vulnerability remediation and
underscores the necessity for assessment protocols that authentically reflect
real-world exploitation scenarios.

</details>


### [7] [The Impact of Critique on LLM-Based Model Generation from Natural Language: The Case of Activity Diagrams](https://arxiv.org/abs/2509.03463)
*Parham Khamsepour,Mark Cole,Ish Ashraf,Sandeep Puri,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: LADEX是一个基于LLM的迭代式生成-评价-优化流程，用于从自然语言描述中提取活动图。研究表明，结合算法结构检查和LLM语义检查的方法效果最佳，平均正确率达到86.37%，完整性达到88.56%。


<details>
  <summary>Details</summary>
Motivation: 解决从自然语言描述自动生成模型时的两个关键问题：结构正确性（符合格式规则）和语义对齐性（准确反映源文本意图）。现有方法需要改进生成质量。

Method: 提出LADEX管道，使用LLM驱动的critique-refine循环。结构检查可通过算法或LLM执行，语义对齐检查始终由LLM执行。设计了五个消融变体来研究不同组件的影响。

Result: 实验表明：1）critique-refine循环相比单次生成显著改善质量；2）算法结构检查比纯LLM检查平均提高正确率17.81%和完整性13.24%；3）结合算法结构检查和LLM语义检查的方法效果最佳。

Conclusion: LADEX证明了迭代优化流程的有效性，算法和LLM结合的混合方法在活动图生成任务中表现最优，平均只需不到5次LLM调用即可获得高质量结果。

Abstract: Large Language Models (LLMs) show strong potential for automating the
generation of models from natural-language descriptions. A common approach is
an iterative generate-critique-refine loop, where candidate models are
produced, evaluated, and updated based on detected issues. This process needs
to address: (1) structural correctness - compliance with well-formedness rules
- and (2) semantic alignment - accurate reflection of the intended meaning in
the source text. We present LADEX (LLM-based Activity Diagram Extractor), a
pipeline for deriving activity diagrams from natural-language process
descriptions using an LLM-driven critique-refine process. Structural checks in
LADEX can be performed either algorithmically or by an LLM, while alignment
checks are always performed by an LLM. We design five ablated variants of LADEX
to study: (i) the impact of the critique-refine loop itself, (ii) the role of
LLM-based semantic checks, and (iii) the comparative effectiveness of
algorithmic versus LLM-based structural checks.
  To evaluate LADEX, we compare the generated activity diagrams with
expert-created ground truths using trace-based operational semantics. This
enables automated measurement of correctness and completeness. Experiments on
two datasets indicate that: (1) the critique-refine loop improves structural
validity, correctness, and completeness compared to single-pass generation; (2)
algorithmic structural checks eliminate inconsistencies that LLM-based checks
fail to detect, improving correctness by an average of 17.81% and completeness
by 13.24% over LLM-only checks; and (3) combining algorithmic structural checks
with LLM-based semantic checks, implemented using the reasoning-focused O4
Mini, achieves the best overall performance - yielding average correctness of
up to 86.37% and average completeness of up to 88.56% - while requiring fewer
than five LLM calls on average.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [8] [Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning](https://arxiv.org/abs/2509.02958)
*Kaustuv Mukherji,Jaikrishna Manojkumar Patil,Dyuman Aditya,Paulo Shakarian,Devendra Parkar,Lahari Pokala,Clark Dorman,Gerardo I. Simari*

Main category: cs.LO

TL;DR: LAT Logic是GAPs的扩展，结合时间推理和开放世界语义，通过下格结构支持非马尔可夫关系和高效推理。


<details>
  <summary>Details</summary>
Motivation: 为了解决动态不确定环境中开放世界时间推理的需求，结合高效演绎过程和时间逻辑编程。

Method: 扩展GAPs，引入时间推理和下格注释结构，支持Skolem化过程实现高效接地，提供模块化设计和机器级优化。

Result: 在多智能体模拟和知识图谱任务中实现3个数量级加速和5个数量级内存减少，在强化学习环境中实现3个数量级更快模拟和26%胜率提升。

Conclusion: LAT Logic作为统一可扩展框架，在动态不确定环境中具有强大的开放世界时间推理潜力。

Abstract: We introduce Lattice Annotated Temporal (LAT) Logic, an extension of
Generalized Annotated Logic Programs (GAPs) that incorporates temporal
reasoning and supports open-world semantics through the use of a lower lattice
structure. This logic combines an efficient deduction process with temporal
logic programming to support non-Markovian relationships and open-world
reasoning capabilities. The open-world aspect, a by-product of the use of the
lower-lattice annotation structure, allows for efficient grounding through a
Skolemization process, even in domains with infinite or highly diverse
constants.
  We provide a suite of theoretical results that bound the computational
complexity of the grounding process, in addition to showing that many of the
results on GAPs (using an upper lattice) still hold with the lower lattice and
temporal extensions (though different proof techniques are required). Our
open-source implementation, PyReason, features modular design, machine-level
optimizations, and direct integration with reinforcement learning environments.
Empirical evaluations across multi-agent simulations and knowledge graph tasks
demonstrate up to three orders of magnitude speedup and up to five orders of
magnitude memory reduction while maintaining or improving task performance.
Additionally, we evaluate LAT Logic's value in reinforcement learning
environments as a non-Markovian simulator, achieving up to three orders of
magnitude faster simulation with improved agent performance, including a 26%
increase in win rate due to capturing richer temporal dependencies. These
results highlight LAT Logic's potential as a unified, extensible framework for
open-world temporal reasoning in dynamic and uncertain environments. Our
implementation is available at: pyreason.syracuse.edu.

</details>
