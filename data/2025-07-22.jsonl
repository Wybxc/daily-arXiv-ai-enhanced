{"id": "2507.14650", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "pdf": "https://arxiv.org/pdf/2507.14650", "abs": "https://arxiv.org/abs/2507.14650", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part I): checking Individual Fairness and Intersectionality", "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of individual fairness and\nintersectionality in probabilistic classifiers. Their interpretation is\nobtained by formulating specific conditions for the application of the\nstructural rule of Weakening. Such restrictions are given by causal labels used\nto check for conditional independence between protected and target variables."}
{"id": "2507.14655", "categories": ["cs.LO", "I.2.3, I.2.4", "F.4"], "pdf": "https://arxiv.org/pdf/2507.14655", "abs": "https://arxiv.org/abs/2507.14655", "authors": ["Leonardo Ceragioli", "Giuseppe Primiero"], "title": "A Proof System with Causal Labels (Part II): checking Counterfactual Fairness", "comment": null, "summary": "In this article we propose an extension to the typed natural deduction\ncalculus TNDPQ to model verification of counterfactual fairness in\nprobabilistic classifiers. This is obtained formulating specific structural\nconditions for causal labels and checking that evaluation is robust under their\nvariation."}
{"id": "2507.14949", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.14949", "abs": "https://arxiv.org/abs/2507.14949", "authors": ["Philippe Balbiani", "Olivier Gasquet"], "title": "PSPACE-completeness of bimodal transitive weak-density logic", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.11238", "summary": "Windows have been introduce in \\cite{BalGasq25} as a tool for designing\npolynomial algorithms to check satisfiability of a bimodal logic of\nweak-density. In this paper, after revisiting the ``folklore'' case of bimodal\n$\\K4$ already treated in \\cite{Halpern} but which is worth a fresh review, we\nshow that windows allow to polynomially solve the satisfiability problem when\nadding transitivity to weak-density, by mixing algorithms for bimodal K\ntogether with windows-approach. The conclusion is that both satisfiability and\nvalidity are PSPACE-complete for these logics."}
{"id": "2507.14956", "categories": ["cs.LO", "03B45, 68Q17", "F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.14956", "abs": "https://arxiv.org/abs/2507.14956", "authors": ["Olivier Gasquet"], "title": "PSPACE-completeness of Grammar logics of bounded density", "comment": null, "summary": "We introduce the family of multi-modal logics of bounded density and with a\ntableau-like approach using finite \\emph{windows} which were introduced in\n\\cite{BalGasq25}, we prove that their satisfiability problem is\nPSPACE-complete. As a side effect, the monomodal logic of density is shown to\nbe in para-PSPACE."}
{"id": "2507.14403", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.14403", "abs": "https://arxiv.org/abs/2507.14403", "authors": ["Sarunas Kalade", "Graham Schelle"], "title": "NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers", "comment": null, "summary": "Neural processing units (NPUs) are gaining prominence in power-sensitive\ndevices like client devices, with AI PCs being defined by their inclusion of\nthese specialized processors. Running AI workloads efficiently on these devices\nrequires libraries of optimized kernels. Creating efficient kernels demands\nexpertise in domain-specific C++ with vector intrinsics and in-depth knowledge\nof the target architecture. Unlike GPU programming, which has had years to\nmature, NPU programming is new, with smaller and more fragmented developer\ncommunities across hardware platforms. This fragmentation poses a challenge\nwhen utilizing LLMs to assist in writing NPU kernels, as domain-specific\noptimized code examples are underrepresented in LLM pre-training data.\n  In this paper we introduce NPUEval -- a benchmark for writing and evaluating\nNPU kernels, consisting of 102 common operators for machine learning workloads.\nWe evaluate LLM generated code on actual hardware based on both functional\ncorrectness and vectorization efficiency using open source compiler tools\ntargeting the AMD NPU. We evaluate a range of state-of-the-art LLMs with a mix\nof proprietary and open-weight models. Latest reasoning models like DeepSeek\nR1, show promising results achieving out-of-the-box 50%+ vectorization on\nselect kernels. However, the average score across the entire dataset remains\nroughly 10% even with compiler feedback and vectorized kernel examples --\nshowing that this is a challenging dataset even for frontier models. The\ndataset and evaluation code will be released with a permissive open source\nlicense, providing an essential benchmark for advancing research in code\ngeneration and NPU kernel optimization."}
{"id": "2507.14256", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14256", "abs": "https://arxiv.org/abs/2507.14256", "authors": ["Jakub Walczak", "Piotr Tomalak", "Artur Laskowski"], "title": "Impact of Code Context and Prompting Strategies on Automated Unit Test Generation with Modern General-Purpose Large Language Models", "comment": null, "summary": "Generative AI is gaining increasing attention in software engineering, where\ntesting remains an indispensable reliability mechanism. According to the widely\nadopted testing pyramid, unit tests constitute the majority of test cases and\nare often schematic, requiring minimal domain expertise. Automatically\ngenerating such tests under the supervision of software engineers can\nsignificantly enhance productivity during the development phase of the software\nlifecycle.\n  This paper investigates the impact of code context and prompting strategies\non the quality and adequacy of unit tests generated by various large language\nmodels (LLMs) across several families. The results show that including\ndocstrings notably improves code adequacy, while further extending context to\nthe full implementation yields definitely smaller gains. Notably, the\nchain-of-thought prompting strategy -- applied even to 'reasoning' models --\nachieves the best results, with up to 96.3\\% branch coverage, a 57\\% average\nmutation score, and near-perfect compilation success rate. Among the evaluated\nmodels, M5 (Gemini 2.5 Pro) demonstrated superior performance in both mutation\nscore and branch coverage being still in top in terms of compilation success\nrate.\n  All the code and resulting test suites are publicly available at\nhttps://github.com/peetery/LLM-analysis."}
{"id": "2507.14526", "categories": ["cs.FL", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.14526", "abs": "https://arxiv.org/abs/2507.14526", "authors": ["Evgenii Vinarskii", "Jakub Ruszil", "Adam Roman", "Natalia Kushik"], "title": "Studying homing and synchronizing sequences for Timed Finite State Machines with output delays", "comment": null, "summary": "The paper introduces final state identification (synchronizing and homing)\nsequences for Timed Finite State Machines (TFSMs) with output delays and\ninvestigates their properties. We formally define the notions of homing\nsequences (HSs) and synchronizing sequences (SSs) for these TFSMs and\ndemonstrate that several properties that hold for untimed machines do not\nnecessarily apply to timed ones. Furthermore, we explore the applicability of\nvarious approaches for deriving SSs and HSs for Timed FSMs with output delays,\nsuch as truncated successor tree-based and FSM abstraction-based methods.\nCorrespondingly, we identify the subclasses of TFSMs for which these approaches\ncan be directly applied and those for which other methods are required.\nAdditionally, we evaluate the complexity of existence check and derivation of\n(shortest) HSs / SSs for TFSMs with output delays."}
{"id": "2507.15117", "categories": ["cs.LO", "math.LO", "03B45", "F.4.0"], "pdf": "https://arxiv.org/pdf/2507.15117", "abs": "https://arxiv.org/abs/2507.15117", "authors": ["Alfredo Burrieza", "Fernando Soler-Toscano", "Antonio Yuste-Ginel"], "title": "A meta-modal logic for bisimulations", "comment": "24 pages", "summary": "We propose a modal study of the notion of bisimulation. Our contribution is\ntwofold. First, we extend the basic modal language with a new modality [b],\nwhose intended meaning is universal quantification over all states that are\nbisimilar to the current one. We show that bisimulations are definable in this\nobject language. Second, we provide a sound and complete axiomatisation of the\nclass of all pairs of Kripke models linked by bisimulations."}
{"id": "2507.14471", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.14471", "abs": "https://arxiv.org/abs/2507.14471", "authors": ["Logan Kenwright", "Partha Roop", "Nathan Allen", "Călin Caşcaval", "Avinash Malik"], "title": "Timetide: A programming model for logically synchronous distributed systems", "comment": "25 Pages, 21 Figures", "summary": "Massive strides in deterministic models have been made using synchronous\nlanguages. They are mainly focused on centralised applications, as the\ntraditional approach is to compile away the concurrency. Time triggered\nlanguages such as Giotto and Lingua Franca are suitable for distribution albeit\nthat they rely on expensive physical clock synchronisation, which is both\nexpensive and may suffer from scalability. Hence, deterministic programming of\ndistributed systems remains challenging. We address the challenges of\ndeterministic distribution by developing a novel multiclock semantics of\nsynchronous programs. The developed semantics is amenable to seamless\ndistribution. Moreover, our programming model, Timetide, alleviates the need\nfor physical clock synchronisation by building on the recently proposed logical\nsynchrony model for distributed systems. We discuss the important aspects of\ndistributing computation, such as network communication delays, and explore the\nformal verification of Timetide programs. To the best of our knowledge,\nTimetide is the first multiclock synchronous language that is both amenable to\ndistribution and formal verification without the need for physical clock\nsynchronisation or clock gating."}
{"id": "2507.14330", "categories": ["cs.SE", "D.2.1; D.2.4; D.2.10; F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.14330", "abs": "https://arxiv.org/abs/2507.14330", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Leveraging LLMs for Formal Software Requirements -- Challenges and Prospects", "comment": "Submitted to Overlay2025 - 7th International Workshop on Artificial\n  Intelligence and fOrmal VERification, Logic, Automata, and sYnthesis. [under\n  review]", "summary": "Software correctness is ensured mathematically through formal verification,\nwhich involves the resources of generating formal requirement specifications\nand having an implementation that must be verified. Tools such as\nmodel-checkers and theorem provers ensure software correctness by verifying the\nimplementation against the specification. Formal methods deployment is\nregularly enforced in the development of safety-critical systems e.g.\naerospace, medical devices and autonomous systems. Generating these\nspecifications from informal and ambiguous natural language requirements\nremains the key challenge. Our project, VERIFAI^{1}, aims to investigate\nautomated and semi-automated approaches to bridge this gap, using techniques\nfrom Natural Language Processing (NLP), ontology-based domain modelling,\nartefact reuse, and large language models (LLMs). This position paper presents\na preliminary synthesis of relevant literature to identify recurring challenges\nand prospective research directions in the generation of verifiable\nspecifications from informal requirements."}
{"id": "2507.15310", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2507.15310", "abs": "https://arxiv.org/abs/2507.15310", "authors": ["Martin Kutrib", "Andreas Malcher", "Matthias Wendlandt"], "title": "Input-Driven Pushdown Automata with Translucent Input Letters", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "Input-driven pushdown automata with translucent input letters are\ninvestigated. Here, the use of translucent input letters means that the input\nis processed in several sweeps and that, depending on the current state of the\nautomaton, some input symbols are visible and can be processed, whereas some\nother symbols are invisible, and may be processed in another sweep.\nAdditionally, the returning mode as well as the non-returning mode are\nconsidered, where in the former mode a new sweep must start after processing a\nvisible input symbol. Input-driven pushdown automata differ from traditional\npushdown automata by the fact that the actions on the pushdown store (push,\npop, nothing) are dictated by the input symbols. We obtain the result that the\ninput-driven nondeterministic model is computationally stronger than the\ndeterministic model both in the returning mode and in the non-returning mode,\nwhereas it is known that the deterministic and the nondeterministic model are\nequivalent for input-driven pushdown automata without translucency. It also\nturns out that the non-returning model is computationally stronger than the\nreturning model both in the deterministic and nondeterministic case.\nFurthermore, we investigate the closure properties of the language families\nintroduced under the Boolean operations. We obtain a complete picture in the\ndeterministic case, whereas in the nondeterministic case the language families\nare shown to be not closed under complementation. Finally, we look at\ndecidability questions and obtain the non-semidecidability of the questions of\nuniversality, inclusion, equivalence, and regularity in the nondeterministic\ncase."}
{"id": "2507.15147", "categories": ["cs.LO", "cs.FL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15147", "abs": "https://arxiv.org/abs/2507.15147", "authors": ["Yiqi Zhao", "Xinyi Yu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "comment": null, "summary": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy."}
{"id": "2507.15007", "categories": ["cs.PL", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.15007", "abs": "https://arxiv.org/abs/2507.15007", "authors": ["Sayed Mahbub Hasan Amiri", "Md. Mainul Islam", "Mohammad Shakhawat Hossen", "Sayed Majhab Hasan Amiri", "Mohammad Shawkat Ali Mamun", "Sk. Humaun Kabir", "Naznin Akter"], "title": "Hear Your Code Fail, Voice-Assisted Debugging for Python", "comment": "35 pages, 20 figures", "summary": "This research introduces an innovative voice-assisted debugging plugin for\nPython that transforms silent runtime errors into actionable audible\ndiagnostics. By implementing a global exception hook architecture with pyttsx3\ntext-to-speech conversion and Tkinter-based GUI visualization, the solution\ndelivers multimodal error feedback through parallel auditory and visual\nchannels. Empirical evaluation demonstrates 37% reduced cognitive load (p<0.01,\nn=50) compared to traditional stack-trace debugging, while enabling 78% faster\nerror identification through vocalized exception classification and\ncontextualization. The system achieves sub-1.2 second voice latency with under\n18% CPU overhead during exception handling, vocalizing error types and\nconsequences while displaying interactive tracebacks with documentation deep\nlinks. Criteria validate compatibility across Python 3.7+ environments on\nWindows, macOS, and Linux platforms. Needing only two lines of integration\ncode, the plugin significantly boosts availability for aesthetically impaired\ndesigners and supports multitasking workflows through hands-free error medical\ndiagnosis. Educational applications show particular promise, with pilot studies\nindicating 45% faster debugging skill acquisition among novice programmers.\nFuture development will incorporate GPT-based repair suggestions and real-time\nmultilingual translation to further advance auditory debugging paradigms. The\nsolution represents a fundamental shift toward human-centric error diagnostics,\nbridging critical gaps in programming accessibility while establishing new\nstandards for cognitive efficiency in software development workflows."}
{"id": "2507.14396", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14396", "abs": "https://arxiv.org/abs/2507.14396", "authors": ["Carey Lai Zheng Hui", "Johnson Britto Jessia Esther Leena", "Kumuthini Subramanian", "Zhao Chenyu", "Shubham Rajeshkumar Jariwala"], "title": "Developing Shared Vocabulary System For Collaborative Software Engineering", "comment": "16 pages, including appendix", "summary": "Effective communication is a critical factor in successful software\nengineering collaboration. However, communication gaps remain a persistent\nchallenge, often leading to misunderstandings, inefficiencies, and defects.\nThis research investigates the technical factors contributing to such\nmisunderstandings and explores the measurable benefits of establishing shared\nvocabulary systems within software documentation and codebases. Using a Design\nScience Research (DSR) framework, the study was structured into three iterative\nphases: problem identification, method development, and empirical validation.\nThe problem identification phase involved thematic analysis of communication\ndata and semi-structured interviews, revealing key factors such as ambiguous\nmessaging, misalignment in documentation, inconsistent code review feedback,\nand API integration miscommunication. Grounded Theory principles were employed\nto design a structured methodology for collaborative vocabulary development.\nEmpirical validation through controlled experiments demonstrated that while\ninitial adoption introduced overhead, the shared vocabulary system\nsignificantly improved information density, documentation clarity, and\ncollaboration efficiency over time. Findings offer actionable insights for\nimproving communication practices in software engineering, while also\nidentifying limitations and directions for future research."}
{"id": "2507.15312", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2507.15312", "abs": "https://arxiv.org/abs/2507.15312", "authors": ["Marvin Ködding", "Bianca Truthe"], "title": "Idefix-Closed Languages and Their Application in Contextual Grammars", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "In this paper, we continue the research on the power of contextual grammars\nwith selection languages from subfamilies of the family of regular languages.\nWe investigate infix-, prefix-, and suffix-closed languages (referred to as\nidefix-closed languages) and compare such language families to some other\nsubregular families of languages (finite, monoidal, nilpotent, combinational,\n(symmetric) definite, ordered, non-counting, power-separating, commutative,\ncircular, union-free, star, and comet languages). Further, we compare the\nfamilies of the hierarchies obtained for external and internal contextual\ngrammars with the language families defined by these new types for the\nselection. In this way, we extend the existing hierarchies by new language\nfamilies. Moreover, we solve an open problem regarding internal contextual\ngrammars with suffix-closed selection languages."}
{"id": "2507.15415", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.15415", "abs": "https://arxiv.org/abs/2507.15415", "authors": ["Florent Ferrari", "Emmanuel Hainry", "Romain Péchoux", "Mário Silva"], "title": "Quantum Programming in Polylogarithmic Time", "comment": null, "summary": "Polylogarithmic time delineates a relevant notion of feasibility on several\nclassical computational models such as Boolean circuits or parallel random\naccess machines. As far as the quantum paradigm is concerned, this notion\nyields the complexity class FBQPOLYLOG of functions approximable in\npolylogarithmic time with a quantum random-access Turing machine. We introduce\na quantum programming language with first-order recursive procedures, which\nprovides the first programming-language-based characterization of FBQPOLYLOG.\nEach program computes a function in FBQPOLYLOG (soundness) and, conversely,\neach function of this complexity class is computed by a program (completeness).\nWe also provide a compilation strategy from programs to uniform families of\nquantum circuits of polylogarithmic depth and polynomial size, whose set of\ncomputed functions is known as QNC, and recover the well-known separation\nresult FBQPOLYLOG $\\subsetneq$ QNC."}
{"id": "2507.15017", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.15017", "abs": "https://arxiv.org/abs/2507.15017", "authors": ["Xuran Cai", "Liqian Chen", "Hongfei Fu"], "title": "Invariant Generation for Floating-Point Programs via Constraint Solving", "comment": null, "summary": "In numeric-intensive computations, it is well known that the execution of\nfloating-point programs is imprecise as floating point arithmetics (e.g.,\naddition, subtraction, multiplication, division, etc.) incurs rounding errors.\nAlbeit the rounding error is small for every single floating-point operation,\nthe aggregation of such error in multiple operations may be dramatic and cause\ncatastrophic program failures. Therefore, to ensure the correctness of\nfloating-point programs, the effect of floating point error needs to be\ncarefully taken into account. In this work, we consider the invariant\ngeneration for floating point programs, whose aim is to generate tight\ninvariants under the perturbation of floating point errors. Our main\ncontribution is a theoretical framework on how to apply constraint solving\nmethods to address the invariant generation problem. In our framework, we\npropose a novel combination between the first-order differential\ncharacterization by FPTaylor (TOPLAS 2018) and constraint solving methods,\naiming to reduce the computational burden of constraint solving. Moreover, we\ndevise two polynomial invariant generation algorithms to instantiate the\nframework. The first algorithm is applicable to a wide range of floating-point\noperations but requires an initial (coarse) invariant as external input, while\nthe second does not require an initial invariant but is limited to polynomial\nprograms. Furthermore, we show how conditional branches, a difficult issue in\nfloating-point analysis, can be handled in our framework. Experimental results\nshow that our algorithms outperform SOTA approaches in both the time efficiency\nand the precision of the generated invariants over a variety of benchmarks."}
{"id": "2507.14423", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14423", "abs": "https://arxiv.org/abs/2507.14423", "authors": ["Mootez Saad", "Hao Li", "Tushar Sharma", "Ahmed E. Hassan"], "title": "On the Effect of Token Merging on Pre-trained Models for Code", "comment": null, "summary": "Tokenization is a fundamental component of language models for code. It\ninvolves breaking down the input into units that are later passed to the\nlanguage model stack to learn high-dimensional representations used in various\ncontexts, from classification to generation. However, the output of these\ntokenizers is often longer than that traditionally used in compilers and\ninterpreters. This could result in undesirable effects, such as increased\ncomputational overhead. In this work, we investigate the effect of merging the\nhidden representations of subtokens that belong to the same semantic unit, such\nas subtokens that form a single identifier. We propose two strategies: one\nbased on averaging the representations and another that leverages a\nlearning-based approach. Both methods can be seamlessly integrated with\nexisting language models for code. We conduct experiments using six language\nmodels for code: CodeBERT, GraphCodeBERT, UniXCoder, CdoeT5, CodeT5+ (220M),\nand CodeT5+ (770M), across three software engineering tasks: vulnerability\ndetection, code classification, and code translation. Results show that these\nstrategies can reduce the number of floating-point operations by $1\\%$ to\n$19\\%$. Regarding downstream performance, the most significant degradation was\nobserved in the vulnerability detection task, where the F1 score decreased by\n$1.82$ points compared to the baseline. In contrast, for code translation, we\nobserved an improvement of $2.47$ points in CodeBLEU. This work contributes to\nthe broader effort of improving language models for code across multiple\ndimensions, including both computational efficiency and downstream performance."}
{"id": "2507.15313", "categories": ["cs.FL", "G.2.1:F.2.2"], "pdf": "https://arxiv.org/pdf/2507.15313", "abs": "https://arxiv.org/abs/2507.15313", "authors": ["Abhishek Krishnamoorthy", "Robinson Thamburaj", "Durairaj Gnanaraj Thomas"], "title": "On a Generalization of the Christoffel Tree: Epichristoffel Trees", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "Sturmian words form a family of one-sided infinite words over a binary\nalphabet that are obtained as a discretization of a line with an irrational\nslope starting from the origin. A finite version of this class of words called\nChristoffel words has been extensively studied for their interesting\nproperties. It is a class of words that has a geometric and an algebraic\ndefinition, making it an intriguing topic of study for many mathematicians.\nRecently, a generalization of Christoffel words for an alphabet with 3 letters\nor more, called epichristoffel words, using episturmian morphisms has been\nstudied, and many of the properties of Christoffel words have been shown to\ncarry over to epichristoffel words; however, many properties are not shared by\nthem as well. In this paper, we introduce the notion of an epichristoffel tree,\nwhich proves to be a useful tool in determining a subclass of epichristoffel\nwords that share an important property of Christoffel words, which is the\nability to factorize an epichristoffel word as a product of smaller\nepichristoffel words. We also use the epichristoffel tree to present some\ninteresting results that help to better understand epichristoffel words."}
{"id": "2507.15420", "categories": ["cs.LO", "E.1; F.4.1; I.2.4; K.5.1"], "pdf": "https://arxiv.org/pdf/2507.15420", "abs": "https://arxiv.org/abs/2507.15420", "authors": ["Robert David", "Albin Ahmeti", "Geni Bushati", "Amar Tauqeer", "Anna Fensel"], "title": "A SHACL-based Data Consistency Solution for Contract Compliance Verification", "comment": "Extended version of the short paper published at OPAL workshop (ESWC\n  2025 Workshops and Tutorials Joint Proceedings). See\n  https://ceur-ws.org/Vol-3977/OPAL2025-1.pdf", "summary": "In recent years, there have been many developments for GDPR-compliant data\naccess and sharing based on consent. For more complex data sharing scenarios,\nwhere consent might not be sufficient, many parties rely on contracts. Before a\ncontract is signed, it must undergo the process of contract negotiation within\nthe contract lifecycle, which consists of negotiating the obligations\nassociated with the contract. Contract compliance verification (CCV) provides a\nmeans to verify whether a contract is GDPR-compliant, i.e., adheres to legal\nobligations and there are no violations. The rise of knowledge graph (KG)\nadoption, enabling semantic interoperability using well-defined semantics,\nallows CCV to be applied on KGs. In the scenario of different participants\nnegotiating obligations, there is a need for data consistency to ensure that\nCCV is done correctly. Recent work introduced the automated contracting tool\n(ACT), a KG-based and ODRL-employing tool for GDPR CCV, which was developed in\nthe Horizon 2020 project smashHit (https://smashhit.eu). Although the tool\nreports violations with respect to obligations, it had limitations in verifying\nand ensuring compliance, as it did not use an interoperable semantic formalism,\nsuch as SHACL, and did not support users in resolving data inconsistencies. In\nthis work, we propose a novel approach to overcome these limitations of ACT. We\nsemi-automatically resolve CCV inconsistencies by providing repair strategies,\nwhich automatically propose (optimal) solutions to the user to re-establish\ndata consistency and thereby support them in managing GDPR-compliant contract\nlifecycle data. We have implemented the approach, integrated it into ACT and\ntested its correctness and performance against basic CCV consistency\nrequirements."}
{"id": "2507.15277", "categories": ["cs.PL", "D.3.4"], "pdf": "https://arxiv.org/pdf/2507.15277", "abs": "https://arxiv.org/abs/2507.15277", "authors": ["Robert Hochgraf", "Sreepathi Pai"], "title": "A Few Fit Most: Improving Performance Portability of SGEMM on GPUs using Multi-Versioning", "comment": "13 pages, 8 figures", "summary": "Hand-optimizing linear algebra kernels for different GPU devices and\napplications is complex and labor-intensive. Instead, many developers use\nautomatic performance tuning (autotuning) to achieve high performance on a\nvariety of devices. However, autotuning \"overfits\", and must be redone if any\npart of the environment changes, such as if the device or input characteristics\nchange.\n  In most non-trivial cases, a single compute kernel cannot maintain\nnear-optimal performance across all environments. Changing the kernel to\nspecialize it to the current execution environment is possible, but on GPUs,\nruntime tuning and compilation can be expensive.\n  In this work, we use multi-versioning -- producing several variants of the\nsame code -- as a way to generate performance portable code. We describe a\nframework called portability tuning that can automatically generate\nmulti-versioned code whose performance is portable, requiring no retuning.\n  We evaluate our framework on a dataset of execution times for GEMM kernels\nfrom the CLBlast linear algebra library. We find our portability tuning\ntechniques outperform CLBlast's default kernels -- often approaching within 10%\nof the theoretical maximum performance -- despite CLBlast using autotuning\ntechniques. Further, we find that our generated programs generalize well to new\nand unseen devices, matching the performance of autotuning without ever\nportability tuning for those devices."}
{"id": "2507.14547", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14547", "abs": "https://arxiv.org/abs/2507.14547", "authors": ["Noman Ahmad", "Ruoyu Su", "Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Architectural Degradation: Definition, Motivations, Measurement and Remediation Approaches", "comment": null, "summary": "Architectural degradation, also known as erosion, decay, or aging, impacts\nsystem quality, maintainability, and adaptability. Although widely\nacknowledged, current literature shows fragmented definitions, metrics, and\nremediation strategies. Our study aims to unify understanding of architectural\ndegradation by identifying its definitions, causes, metrics, tools, and\nremediation approaches across academic and gray literature. We conducted a\nmultivocal literature review of 108 studies extracting definitions, causes,\nmetrics, measurement approaches, tools, and remediation strategies. We\ndeveloped a taxonomy encompassing architectural, code, and process debt to\nexplore definition evolution, methodological trends, and research gaps.\nArchitectural degradation has shifted from a low-level issue to a\nsocio-technical concern. Definitions now address code violations, design drift,\nand structural decay. Causes fall under architectural (e.g., poor\ndocumentation), code (e.g., hasty fixes), and process debt (e.g., knowledge\nloss). We identified 54 metrics and 31 measurement techniques, focused on\nsmells, cohesion/coupling, and evolution. Yet, most tools detect issues but\nrarely support ongoing or preventive remediation. Degradation is both technical\nand organizational. While detection is well-studied, continuous remediation\nremains lacking. Our study reveals missed integration between metrics, tools,\nand repair logic, urging holistic, proactive strategies for sustainable\narchitecture."}
{"id": "2507.15314", "categories": ["cs.FL", "F.4.3; H.5.5"], "pdf": "https://arxiv.org/pdf/2507.15314", "abs": "https://arxiv.org/abs/2507.15314", "authors": ["Jozef Makiš", "Alexander Meduna", "Zbyněk Křivka"], "title": "Orchestration of Music by Grammar Systems", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "This application-oriented study concerns computational musicology, which\nmakes use of grammar systems. We define multi-generative rule-synchronized\nscattered-context grammar systems (without erasing rules) and demonstrates how\nto simultaneously make the arrangement of a musical composition for performance\nby a whole orchestra, consisting of several instruments. Primarily, an\norchestration like this is illustrated by examples in terms of classical music.\nIn addition, the orchestration of jazz compositions is sketched as well. The\nstudy concludes its discussion by suggesting five open problem areas related to\nthis way of orchestration."}
{"id": "2507.15689", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15689", "abs": "https://arxiv.org/abs/2507.15689", "authors": ["Jean Christoph Jung", "Jędrzej Kołodziejski", "Frank Wolter"], "title": "Computation of Interpolants for Description Logic Concepts in Hard Cases", "comment": null, "summary": "While the computation of Craig interpolants for description logics (DLs) with\nthe Craig Interpolation Property (CIP) is well understood, very little is known\nabout the computation and size of interpolants for DLs without CIP or if one\naims at interpolating concepts in a weaker DL than the DL of the input ontology\nand concepts. In this paper, we provide the first elementary algorithms\ncomputing (i) ALC-interpolants between ALC-concepts under ALCH-ontologies and\n(ii) ALC-interpolants between ALCQ-concepts under ALCQ-ontologies. The\nalgorithms are based on recent decision procedures for interpolant existence.\nWe also observe that, in contrast, uniform (possibly depth restricted)\ninterpolants might be of non-elementary size."}
{"id": "2507.15530", "categories": ["cs.PL", "cs.LO", "F.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2507.15530", "abs": "https://arxiv.org/abs/2507.15530", "authors": ["Shing Hin Ho", "Nicolas Wu", "Azalea Raad"], "title": "Bayesian Separation Logic", "comment": null, "summary": "Bayesian probabilistic programming languages (BPPLs) let users denote\nstatistical models as code while the interpreter infers the posterior\ndistribution. The semantics of BPPLs are usually mathematically complex and\nunable to reason about desirable properties such as expected values and\nindependence of random variables. To reason about these properties in a\nnon-Bayesian setting, probabilistic separation logics such as PSL and Lilac\ninterpret separating conjunction as probabilistic independence of random\nvariables. However, no existing separation logic can handle Bayesian updating,\nwhich is the key distinguishing feature of BPPLs.\n  To close this gap, we introduce Bayesian separation logic (BaSL), a\nprobabilistic separation logic that gives semantics to BPPL. We prove an\ninternal version of Bayes' theorem using a result in measure theory known as\nthe Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model\nprobabilistic programming concepts such as Bayesian updating, unnormalised\ndistribution, conditional distribution, soft constraint, conjugate prior and\nimproper prior while maintaining modularity via the frame rule. The model of\nBaSL is based on a novel instantiation of Kripke resource monoid via\n$\\sigma$-finite measure spaces over the Hilbert cube, and the semantics of\nHoare triple is compatible with an existing denotational semantics of BPPL\nbased on the category of $s$-finite kernels. Using BaSL, we then prove\nproperties of statistical models such as the expected value of Bayesian coin\nflip, correlation of random variables in the collider Bayesian network, and the\nposterior distributions of the burglar alarm model, a parameter estimation\nalgorithm, and the Gaussian mixture model."}
{"id": "2507.14554", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14554", "abs": "https://arxiv.org/abs/2507.14554", "authors": ["Ruoyu Su", "Noman ahmad", "Matteo Esposito", "Andrea Janes", "Davide Taibi", "Valentina Lenarduzzi"], "title": "Emerging Trends in Software Architecture from the Practitioners Perspective: A Five Year Review", "comment": null, "summary": "Software architecture plays a central role in the design, development, and\nmaintenance of software systems. With the rise of cloud computing,\nmicroservices, and containers, architectural practices have diversified.\nUnderstanding these shifts is vital. This study analyzes software architecture\ntrends across eight leading industry conferences over five years. We\ninvestigate the evolution of software architecture by analyzing talks from top\npractitioner conferences, focusing on the motivations and contexts driving\ntechnology adoption. We analyzed 5,677 talks from eight major industry\nconferences, using large language models and expert validation to extract\ntechnologies, their purposes, and usage contexts. We also explored how\ntechnologies interrelate and fit within DevOps and deployment pipelines. Among\n450 technologies, Kubernetes, Cloud Native, Serverless, and Containers dominate\nby frequency and centrality. Practitioners present technology mainly related to\ndeployment, communication, AI, and observability. We identify five technology\ncommunities covering automation, coordination, cloud AI, monitoring, and\ncloud-edge. Most technologies span multiple DevOps stages and support hybrid\ndeployment. Our study reveals that a few core technologies, like Kubernetes and\nServerless, dominate the contemporary software architecture practice. These are\nmainly applied in later DevOps stages, with limited focus on early phases like\nplanning and coding. We also show how practitioners frame technologies by\npurpose and context, reflecting evolving industry priorities. Finally, we\nobserve how only research can provide a more holistic lens on architectural\ndesign, quality, and evolution."}
{"id": "2507.15315", "categories": ["cs.FL", "F.1.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2507.15315", "abs": "https://arxiv.org/abs/2507.15315", "authors": ["František Mráz", "Friedrich Otto"], "title": "On Repetitive Finite Automata with Translucent Words", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "We introduce and study the repetitive variants of the deterministic and the\nnondeterministic finite automaton with translucent words (DFAwtw and NFAwtw).\nOn seeing the right sentinel, a repetitive NFAwtw need not halt immediately,\naccepting or rejecting, but it may change into another state and continue with\nits computation. We establish that a repetitive DFAwtw already accepts a\nlanguage that is not even semi-linear, which shows that the property of being\nrepetitive increases the expressive capacity of the DFAwtw and the NFAwtw\nconsiderably."}
{"id": "2507.15530", "categories": ["cs.PL", "cs.LO", "F.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2507.15530", "abs": "https://arxiv.org/abs/2507.15530", "authors": ["Shing Hin Ho", "Nicolas Wu", "Azalea Raad"], "title": "Bayesian Separation Logic", "comment": null, "summary": "Bayesian probabilistic programming languages (BPPLs) let users denote\nstatistical models as code while the interpreter infers the posterior\ndistribution. The semantics of BPPLs are usually mathematically complex and\nunable to reason about desirable properties such as expected values and\nindependence of random variables. To reason about these properties in a\nnon-Bayesian setting, probabilistic separation logics such as PSL and Lilac\ninterpret separating conjunction as probabilistic independence of random\nvariables. However, no existing separation logic can handle Bayesian updating,\nwhich is the key distinguishing feature of BPPLs.\n  To close this gap, we introduce Bayesian separation logic (BaSL), a\nprobabilistic separation logic that gives semantics to BPPL. We prove an\ninternal version of Bayes' theorem using a result in measure theory known as\nthe Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model\nprobabilistic programming concepts such as Bayesian updating, unnormalised\ndistribution, conditional distribution, soft constraint, conjugate prior and\nimproper prior while maintaining modularity via the frame rule. The model of\nBaSL is based on a novel instantiation of Kripke resource monoid via\n$\\sigma$-finite measure spaces over the Hilbert cube, and the semantics of\nHoare triple is compatible with an existing denotational semantics of BPPL\nbased on the category of $s$-finite kernels. Using BaSL, we then prove\nproperties of statistical models such as the expected value of Bayesian coin\nflip, correlation of random variables in the collider Bayesian network, and the\nposterior distributions of the burglar alarm model, a parameter estimation\nalgorithm, and the Gaussian mixture model."}
{"id": "2507.15596", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15596", "abs": "https://arxiv.org/abs/2507.15596", "authors": ["Jaeseo Lee", "Kyungmin Bae"], "title": "Formal Analysis of Networked PLC Controllers Interacting with Physical Environments", "comment": "To appear in Proceedings of the Static Analysis Symposium (SAS) 2025", "summary": "Programmable Logic Controllers (PLCs) are widely used in industrial\nautomation to control physical systems. As PLC applications become increasingly\ncomplex, ensuring their correctness is crucial. Existing formal verification\ntechniques focus on individual PLC programs in isolation, often neglecting\ninteractions with physical environments and network communication between\ncontrollers. This limitation poses significant challenges in analyzing\nreal-world industrial systems, where continuous dynamics and communication\ndelays play a critical role. In this paper, we present a unified formal\nframework that integrates discrete PLC semantics, networked communication, and\ncontinuous physical behaviors. To mitigate state explosion, we apply partial\norder reduction, significantly reducing the number of explored states while\nmaintaining correctness. Our framework enables precise analysis of PLC-driven\nsystems with continuous dynamics and networked communication."}
{"id": "2507.14558", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14558", "abs": "https://arxiv.org/abs/2507.14558", "authors": ["Bin Duan", "Tarek Mahmud", "Meiru Che", "Yan Yan", "Naipeng Dong", "Dan Dongseong Kim", "Guowei Yang"], "title": "Harnessing LLMs for Document-Guided Fuzzing of OpenCV Library", "comment": null, "summary": "The combination of computer vision and artificial intelligence is\nfundamentally transforming a broad spectrum of industries by enabling machines\nto interpret and act upon visual data with high levels of accuracy. As the\nbiggest and by far the most popular open-source computer vision library, OpenCV\nlibrary provides an extensive suite of programming functions supporting\nreal-time computer vision. Bugs in the OpenCV library can affect the downstream\ncomputer vision applications, and it is critical to ensure the reliability of\nthe OpenCV library. This paper introduces VISTAFUZZ, a novel technique for\nharnessing large language models (LLMs) for document-guided fuzzing of the\nOpenCV library. VISTAFUZZ utilizes LLMs to parse API documentation and obtain\nstandardized API information. Based on this standardized information, VISTAFUZZ\nextracts constraints on individual input parameters and dependencies between\nthese. Using these constraints and dependencies, VISTAFUZZ then generates new\ninput values to systematically test each target API. We evaluate the\neffectiveness of VISTAFUZZ in testing 330 APIs in the OpenCV library, and the\nresults show that VISTAFUZZ detected 17 new bugs, where 10 bugs have been\nconfirmed, and 5 of these have been fixed."}
{"id": "2507.15316", "categories": ["cs.FL", "cs.DM", "cs.DS", "F.1.1;F.4.3;F.1.3"], "pdf": "https://arxiv.org/pdf/2507.15316", "abs": "https://arxiv.org/abs/2507.15316", "authors": ["Benedek Nagy"], "title": "A Myhill-Nerode Type Characterization of 2detLIN Languages", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "Linear automata are automata with two reading heads starting from the two\nextremes of the input, are equivalent to 5' -> 3' Watson-Crick (WK) finite\nautomata. The heads read the input in opposite directions and the computation\nfinishes when the heads meet. These automata accept the class LIN of linear\nlanguages. The deterministic counterpart of these models, on the one hand, is\nless expressive, as only a proper subset of LIN, the class 2detLIN is accepted;\nand on the other hand, they are also equivalent in the sense of the class of\nthe accepted languages. Now, based on these automata models, we characterize\nthe class of 2detLIN languages with a Myhill-Nerode type of equivalence\nclasses. However, as these automata may do the computation of both the prefix\nand the suffix of the input, we use prefix-suffix pairs in our classes.\nAdditionally, it is proven that finitely many classes in the characterization\nmatch with the 2detLIN languages, but we have some constraints on the used\nprefix-suffix pairs, i.e., the characterization should have the property to be\ncomplete and it must not have any crossing pairs."}
{"id": "2507.15596", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.15596", "abs": "https://arxiv.org/abs/2507.15596", "authors": ["Jaeseo Lee", "Kyungmin Bae"], "title": "Formal Analysis of Networked PLC Controllers Interacting with Physical Environments", "comment": "To appear in Proceedings of the Static Analysis Symposium (SAS) 2025", "summary": "Programmable Logic Controllers (PLCs) are widely used in industrial\nautomation to control physical systems. As PLC applications become increasingly\ncomplex, ensuring their correctness is crucial. Existing formal verification\ntechniques focus on individual PLC programs in isolation, often neglecting\ninteractions with physical environments and network communication between\ncontrollers. This limitation poses significant challenges in analyzing\nreal-world industrial systems, where continuous dynamics and communication\ndelays play a critical role. In this paper, we present a unified formal\nframework that integrates discrete PLC semantics, networked communication, and\ncontinuous physical behaviors. To mitigate state explosion, we apply partial\norder reduction, significantly reducing the number of explored states while\nmaintaining correctness. Our framework enables precise analysis of PLC-driven\nsystems with continuous dynamics and networked communication."}
{"id": "2507.15843", "categories": ["cs.PL", "D.3.1; F.3.1; F.3.2; D.2.4"], "pdf": "https://arxiv.org/pdf/2507.15843", "abs": "https://arxiv.org/abs/2507.15843", "authors": ["Beniamino Accattoli", "Dan Ghica", "Giulio Guerrieri", "Cláudio Belo Lourenço", "Claudio Sacerdoti Coen"], "title": "Closure Conversion, Flat Environments, and the Complexity of Abstract Machines", "comment": null, "summary": "Closure conversion is a program transformation at work in compilers for\nfunctional languages to turn inner functions into global ones, by building\nclosures pairing the transformed functions with the environment of their free\nvariables. Abstract machines rely on similar and yet different concepts of\nclosures and environments.\n  In this paper, we study the relationship between the two approaches. We adopt\na very simple {\\lambda}-calculus with tuples as source language and study\nabstract machines for both the source language and the target of closure\nconversion. Moreover, we focus on the simple case of flat\nclosures/environments, that is, with no sharing of environments. We provide\nthree contributions.\n  Firstly, a new simple proof technique for the correctness of closure\nconversion, inspired by abstract machines.\n  Secondly, we show how the closure invariants of the target language allow us\nto design a new way of handling environments in abstract machines, not\nsuffering the shortcomings of other styles.\n  Thirdly, we study the machines from the point of view of time complexity,\nadapting analyses by Accattoli and co-authors. We show that closure conversion\ndecreases various dynamic costs while increasing the size of the initial code.\nDespite these changes, the overall complexity of the machines before and after\nclosure conversion turns out to be the same."}
{"id": "2507.14594", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14594", "abs": "https://arxiv.org/abs/2507.14594", "authors": ["Weiwei Xu", "Hengzhi Ye", "Kai Gao", "Minghui Zhou"], "title": "A first look at License Variants in the PyPI Ecosystem", "comment": null, "summary": "Open-source licenses establish the legal foundation for software reuse, yet\nlicense variants, including both modified standard licenses and custom-created\nalternatives, introduce significant compliance complexities. Despite their\nprevalence and potential impact, these variants are poorly understood in modern\nsoftware systems, and existing tools do not account for their existence,\nleading to significant challenges in both effectiveness and efficiency of\nlicense analysis. To fill this knowledge gap, we conduct a comprehensive\nempirical study of license variants in the PyPI ecosystem. Our findings show\nthat textual variations in licenses are common, yet only 2% involve substantive\nmodifications. However, these license variants lead to significant compliance\nissues, with 10.7% of their downstream dependencies found to be\nlicense-incompatible.\n  Inspired by our findings, we introduce LV-Parser, a novel approach for\nefficient license variant analysis leveraging diff-based techniques and large\nlanguage models, along with LV-Compat, an automated pipeline for detecting\nlicense incompatibilities in software dependency networks. Our evaluation\ndemonstrates that LV-Parser achieves an accuracy of 0.936 while reducing\ncomputational costs by 30%, and LV-Compat identifies 5.2 times more\nincompatible packages than existing methods with a precision of 0.98.\n  This work not only provides the first empirical study into license variants\nin software packaging ecosystem but also equips developers and organizations\nwith practical tools for navigating the complex landscape of open-source\nlicensing."}
{"id": "2507.15317", "categories": ["cs.FL", "F.1.1;F.1.2;F.4.2;F.4.3"], "pdf": "https://arxiv.org/pdf/2507.15317", "abs": "https://arxiv.org/abs/2507.15317", "authors": ["Benedek Nagy", "Walaa Yasin"], "title": "On some Classes of Reversible 2-head Automata", "comment": "In Proceedings NCMA 2025, arXiv:2507.14082", "summary": "Deterministic 2-head finite automata which are machines that process an input\nword from both ends are analyzed for their ability to perform reversible\ncomputations. This implies that the automata are backward deterministic,\nenabling unique forward and backward computation. We explore the computational\npower of such automata, discovering that, while some regular languages cannot\nbe accepted by these machines, they are capable of accepting some\ncharacteristic linear languages, e.g., the language of palindromes.\nAdditionally, we prove that restricted variants, i.e., both 1-limited\nreversible 2-head finite automata and complete reversible 2-head finite\nautomata are less powerful and they form a proper hierarchy. In the former, in\neach computation step exactly one input letter is being processed, i.e., only\none of the heads can read a letter. These automata are also characterized by\nputting their states to classes based on the head(s) used to reach and to leave\nthe state. In the complete reversible 2-head finite automata, it is required\nthat any input can be fully read by the automaton. The accepted families are\nalso compared to the classes generated by left deterministic linear grammars."}
{"id": "2502.15441", "categories": ["cs.SE", "cs.AI", "cs.FL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2502.15441", "abs": "https://arxiv.org/abs/2502.15441", "authors": ["Yang Hong", "Shan Jiang", "Yulei Fu", "Sarfraz Khurshid"], "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas", "comment": null, "summary": "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software."}
{"id": "2507.14687", "categories": ["cs.SE", "68Q60, 03B70", "D.2.5"], "pdf": "https://arxiv.org/pdf/2507.14687", "abs": "https://arxiv.org/abs/2507.14687", "authors": ["Robin Lee", "Youngho Nam"], "title": "An Efficient Algorithm for Generating Minimal Unique-Cause MC/DC Test cases for Singular Boolean Expressions", "comment": "10 pages, 5 figures", "summary": "Modified Condition/Decision Coverage (MC/DC) is a mandatory structural\ncoverage criterion for ensuring the reliability and safety of critical systems.\nWhile its strictest form, Unique-Cause MC/DC, offers the highest assurance,\nresearch on its efficient test generation has been lacking. This gap is\nparticularly significant, as an analysis of large-scale avionics systems shows\nthat 99.7% of all conditional decisions are, in fact, Singular Boolean\nExpressions (SBEs) the ideal structure for applying Unique-Cause MC/DC. This\npaper proposes 'Robin's Rule', a deterministic algorithm that directly\nconstructs a minimal test set of N + 1 cases to guarantee 100% Unique-Cause\nMC/DC for SBEs with N conditions, without generating a full truth table. To\nvalidate our approach, we constructed a benchmark by reformulating the TCAS-II\nspecifications into SBEs and verified the results using an industry-standard,\ncertified commercial tool. The results confirm that our method consistently\nachieves 100% coverage with the theoretical minimum number of tests and is more\nefficient than the commercial tool. This work provides a practical and provably\noptimal solution for verifying safety-critical systems, ensuring both rigor and\nefficiency."}
{"id": "2507.15733", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2507.15733", "abs": "https://arxiv.org/abs/2507.15733", "authors": ["Dietrich Kuske"], "title": "The theory of reachability in trace-pushdown systems", "comment": null, "summary": "We consider pushdown systems that store, instead of a single word, a\nMazurkiewicz trace on its stack. These systems are special cases of valence\nautomata over graph monoids and subsume multi-stack systems. We identify a\nclass of such systems that allow to decide the first-order theory of their\nconfiguration graph with reachability.\n  This result complements results by D'Osualdo, Meyer, and Zetzsche (namely the\ndecidability for arbitrary pushdown systems under a severe restriction on the\ndependence alphabet)."}
{"id": "2507.15415", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.15415", "abs": "https://arxiv.org/abs/2507.15415", "authors": ["Florent Ferrari", "Emmanuel Hainry", "Romain Péchoux", "Mário Silva"], "title": "Quantum Programming in Polylogarithmic Time", "comment": null, "summary": "Polylogarithmic time delineates a relevant notion of feasibility on several\nclassical computational models such as Boolean circuits or parallel random\naccess machines. As far as the quantum paradigm is concerned, this notion\nyields the complexity class FBQPOLYLOG of functions approximable in\npolylogarithmic time with a quantum random-access Turing machine. We introduce\na quantum programming language with first-order recursive procedures, which\nprovides the first programming-language-based characterization of FBQPOLYLOG.\nEach program computes a function in FBQPOLYLOG (soundness) and, conversely,\neach function of this complexity class is computed by a program (completeness).\nWe also provide a compilation strategy from programs to uniform families of\nquantum circuits of polylogarithmic depth and polynomial size, whose set of\ncomputed functions is known as QNC, and recover the well-known separation\nresult FBQPOLYLOG $\\subsetneq$ QNC."}
{"id": "2507.14716", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14716", "abs": "https://arxiv.org/abs/2507.14716", "authors": ["Shahidul Islam", "Ashik Aowal", "Md Sharif Uddin", "Shaiful Chowdhury"], "title": "HistoryFinder: Advancing Method-Level Source Code History Generation with Accurate Oracles and Enhanced Algorithm", "comment": null, "summary": "Reconstructing a method's change history efficiently and accurately is\ncritical for many software engineering tasks, including maintenance,\nrefactoring, and comprehension. Despite the availability of method history\ngeneration tools such as CodeShovel and CodeTracker, existing evaluations of\ntheir effectiveness are limited by inaccuracies in the ground truth oracles\nused. In this study, we systematically construct two new oracles -- the\ncorrected CodeShovel oracle and a newly developed HistoryFinder oracle -- by\ncombining automated analysis with expert-guided manual validation. We also\nintroduce HistoryFinder, a new method history generation tool designed to\nimprove not only the accuracy and completeness of method change histories but\nalso to offer competitive runtime performance. Through extensive evaluation\nacross 400 methods from 40 open-source repositories, we show that HistoryFinder\nconsistently outperforms CodeShovel, CodeTracker, IntelliJ, and Git-based\nbaselines in terms of precision, recall, and F1 score. Moreover, HistoryFinder\nachieves competitive runtime performance, offering the lowest mean and median\nexecution times among all the research-based tools.\n  While Git-based tools exhibit the fastest runtimes, this efficiency comes at\nthe cost of significantly lower precision and recall -- leaving HistoryFinder\nas the best overall choice when both accuracy and efficiency are important. To\nfacilitate adoption, we provide a web interface, CLI, and Java library for\nflexible usage."}
{"id": "2502.15441", "categories": ["cs.SE", "cs.AI", "cs.FL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2502.15441", "abs": "https://arxiv.org/abs/2502.15441", "authors": ["Yang Hong", "Shan Jiang", "Yulei Fu", "Sarfraz Khurshid"], "title": "On the Effectiveness of Large Language Models in Writing Alloy Formulas", "comment": null, "summary": "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software."}
{"id": "2507.14735", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14735", "abs": "https://arxiv.org/abs/2507.14735", "authors": ["Vladyslav Bulhakov", "Giordano d'Aloisio", "Claudio Di Sipio", "Antinisca Di Marco", "Davide Di Ruscio"], "title": "Investigating the Role of LLMs Hyperparameter Tuning and Prompt Engineering to Support Domain Modeling", "comment": "Accepted at 51st Euromicro Conference Series on Software Engineering\n  and Advanced Applications (SEAA)", "summary": "The introduction of large language models (LLMs) has enhanced automation in\nsoftware engineering tasks, including in Model Driven Engineering (MDE).\nHowever, using general-purpose LLMs for domain modeling has its limitations.\nOne approach is to adopt fine-tuned models, but this requires significant\ncomputational resources and can lead to issues like catastrophic forgetting.\n  This paper explores how hyperparameter tuning and prompt engineering can\nimprove the accuracy of the Llama 3.1 model for generating domain models from\ntextual descriptions. We use search-based methods to tune hyperparameters for a\nspecific medical data model, resulting in a notable quality improvement over\nthe baseline LLM. We then test the optimized hyperparameters across ten diverse\napplication domains.\n  While the solutions were not universally applicable, we demonstrate that\ncombining hyperparameter tuning with prompt engineering can enhance results\nacross nearly all examined domain models."}
{"id": "2507.15147", "categories": ["cs.LO", "cs.FL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.15147", "abs": "https://arxiv.org/abs/2507.15147", "authors": ["Yiqi Zhao", "Xinyi Yu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies", "comment": null, "summary": "Multi-agent systems (MASs) consisting of a number of autonomous agents that\ncommunicate, coordinate, and jointly sense the environment to achieve complex\nmissions can be found in a variety of applications such as robotics, smart\ncities, and internet-of-things applications. Modeling and monitoring MAS\nrequirements to guarantee overall mission objectives, safety, and reliability\nis an important problem. Such requirements implicitly require reasoning about\ndiverse sensing and communication modalities between agents, analysis of the\ndependencies between agent tasks, and the spatial or virtual distance between\nagents. To capture such rich MAS requirements, we model agent interactions via\nmultiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic\nwith Graph Operators (STL-GO). The key innovation in STL-GO are graph operators\nthat enable us to reason about the number of agents along either the incoming\nor outgoing edges of the underlying interaction graph that satisfy a given\nproperty of interest; for example, the requirement that an agent should sense\nat least two neighboring agents whose task graphs indicate the ability to\ncollaborate. We then propose novel distributed monitoring conditions for\nindividual agents that use only local information to determine whether or not\nan STL-GO specification is satisfied. We compare the expressivity of STL-GO\nagainst existing spatio-temporal logic formalisms, and demonstrate the utility\nof STL-GO and our distributed monitors in a bike-sharing and a multi-drone case\nstudy."}
{"id": "2507.14770", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14770", "abs": "https://arxiv.org/abs/2507.14770", "authors": ["Manaal Basha", "Ivan Beschastnikh", "Gema Rodriguez-Perez", "Cleidson R. B. de Souza"], "title": "Toward Inclusive AI-Driven Development: Exploring Gender Differences in Code Generation Tool Interactions", "comment": "ESEM 2025 Registered Reports", "summary": "Context: The increasing reliance on Code Generation Tools (CGTs), such as\nWindsurf and GitHub Copilot, are revamping programming workflows and raising\ncritical questions about fairness and inclusivity. While CGTs offer potential\nproductivity enhancements, their effectiveness across diverse user groups have\nnot been sufficiently investigated. Objectives: We hypothesize that developers'\ninteractions with CGTs vary based on gender, influencing task outcomes and\ncognitive load, as prior research suggests that gender differences can affect\ntechnology use and cognitive processing. Methods: The study will employ a\nmixed-subjects design with 54 participants, evenly divided by gender for a\ncounterbalanced design. Participants will complete two programming tasks\n(medium to hard difficulty) with only CGT assistance and then with only\ninternet access. Task orders and conditions will be counterbalanced to mitigate\norder effects. Data collection will include cognitive load surveys, screen\nrecordings, and task performance metrics such as completion time, code\ncorrectness, and CGT interaction behaviors. Statistical analyses will be\nconducted to identify statistically significant differences in CGT usage.\nExpected Contributions: Our work can uncover gender differences in CGT\ninteraction and performance among developers. Our findings can inform future\nCGT designs and help address usability and potential disparities in interaction\npatterns across diverse user groups. Conclusion: While results are not yet\navailable, our proposal lays the groundwork for advancing fairness,\naccountability, transparency, and ethics (FATE) in CGT design. The outcomes are\nanticipated to contribute to inclusive AI practices and equitable tool\ndevelopment for all users."}
{"id": "2507.14776", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14776", "abs": "https://arxiv.org/abs/2507.14776", "authors": ["Kimia Tasnia", "Alexander Garcia", "Tasnuva Farheen", "Sazadur Rahman"], "title": "VeriOpt: PPA-Aware High-Quality Verilog Generation via Multi-Role LLMs", "comment": "9 pages, 7 figures, Accepted for ICCAD 2025, Munich, Germany", "summary": "The rapid adoption of large language models(LLMs) in hardware design has\nprimarily focused on generating functionally correct Verilog code, overlooking\ncritical Power Performance-Area(PPA) metrics essential for industrial-grade\ndesigns. To bridge this gap, we propose VeriOpt, a novel framework that\nleverages role-based prompting and PPA-aware optimization to enable LLMs to\nproduce high-quality, synthesizable Verilog. VeriOpt structures LLM\ninteractions into specialized roles (e.g., Planner, Programmer, Reviewer,\nEvaluator) to emulate human design workflows, while integrating PPA constraints\ndirectly into the prompting pipeline. By combining multi-modal feedback (e.g.,\nsynthesis reports, timing diagrams) with PPA aware prompting, VeriOpt achieves\nPPA-efficient code generation without sacrificing functional correctness.\nExperimental results demonstrate up to 88% reduction in power, 76% reduction in\narea and 73% improvement in timing closure compared to baseline LLM-generated\nRTL, validated using industry standard EDA tools. At the same time achieves 86%\nsuccess rate in functionality evaluation. Our work advances the\nstate-of-the-art AI-driven hardware design by addressing the critical gap\nbetween correctness and quality, paving the way for reliable LLM adoption in\nproduction workflows."}
{"id": "2507.14791", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.14791", "abs": "https://arxiv.org/abs/2507.14791", "authors": ["Yang Liu", "Li Zhang", "Fang Liu", "Zhuohang Wang", "Donglin Wei", "Zhishuo Yang", "Kechi Zhang", "Jia Li", "Lin Shi"], "title": "Enhancing Repository-Level Code Generation with Call Chain-Aware Multi-View Context", "comment": null, "summary": "Repository-level code generation aims to generate code within the context of\na specified repository. Existing approaches typically employ\nretrieval-augmented generation (RAG) techniques to provide LLMs with relevant\ncontextual information extracted from the repository. However, these approaches\noften struggle with effectively identifying truly relevant contexts that\ncapture the rich semantics of the repository, and their contextual perspectives\nremains narrow. Moreover, most approaches fail to account for the structural\nrelationships in the retrieved code during prompt construction, hindering the\nLLM's ability to accurately interpret the context. To address these issues, we\npropose RepoScope, which leverages call chain-aware multi-view context for\nrepository-level code generation. RepoScope constructs a Repository Structural\nSemantic Graph (RSSG) and retrieves a comprehensive four-view context,\nintegrating both structural and similarity-based contexts. We propose a novel\ncall chain prediction method that utilizes the repository's structural\nsemantics to improve the identification of callees in the target function.\nAdditionally, we present a structure-preserving serialization algorithm for\nprompt construction, ensuring the coherence of the context for the LLM.\nNotably, RepoScope relies solely on static analysis, eliminating the need for\nadditional training or multiple LLM queries, thus ensuring both efficiency and\ngeneralizability. Evaluation on widely-used repository-level code generation\nbenchmarks (CoderEval and DevEval) demonstrates that RepoScope outperforms\nstate-of-the-art methods, achieving up to a 36.35% relative improvement in\npass@1 scores. Further experiments emphasize RepoScope's potential to improve\ncode generation across different tasks and its ability to integrate effectively\nwith existing approaches."}
{"id": "2507.14969", "categories": ["cs.SE", "D.2.1"], "pdf": "https://arxiv.org/pdf/2507.14969", "abs": "https://arxiv.org/abs/2507.14969", "authors": ["Sai Zhang", "Zhenchang Xing", "Jieshan Chen", "Dehai Zhao", "Zizhong Zhu", "Xiaowang Zhang", "Zhiyong Feng", "Xiaohong Li"], "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review", "comment": null, "summary": "The vision of End-User Software Engineering (EUSE) is to empower\nnon-professional users with full control over the software development\nlifecycle. It aims to enable users to drive generative software development\nusing only natural language requirements. However, since end-users often lack\nknowledge of software engineering, their requirement descriptions are\nfrequently ambiguous, raising significant challenges to generative software\ndevelopment. Although existing approaches utilize structured languages like\nGherkin to clarify user narratives, they still struggle to express the causal\nlogic between preconditions and behavior actions. This paper introduces\nRequireCEG, a requirement elicitation and self-review agent that embeds\ncausal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture.\nRequireCEG first uses a feature tree to analyze user narratives hierarchically,\nclearly defining the scope of software components and their system behavior\nrequirements. Next, it constructs the self-healing CEGs based on the elicited\nrequirements, capturing the causal relationships between atomic preconditions\nand behavioral actions. Finally, the constructed CEGs are used to review and\noptimize Gherkin scenarios, ensuring consistency between the generated Gherkin\nrequirements and the system behavior requirements elicited from user\nnarratives. To evaluate our method, we created the RGPair benchmark dataset and\nconducted extensive experiments. It achieves an 87% coverage rate and raises\ndiversity by 51.88%."}
{"id": "2507.15003", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15003", "abs": "https://arxiv.org/abs/2507.15003", "authors": ["Hao Li", "Haoxiang Zhang", "Ahmed E. Hassan"], "title": "The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering", "comment": null, "summary": "The future of software engineering--SE 3.0--is unfolding with the rise of AI\nteammates: autonomous, goal-driven systems collaborating with human developers.\nAmong these, autonomous coding agents are especially transformative, now\nactively initiating, reviewing, and evolving code at scale. This paper\nintroduces AIDev, the first large-scale dataset capturing how such agents\noperate in the wild. Spanning over 456,000 pull requests by five leading\nagents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across\n61,000 repositories and 47,000 developers, AIDev provides an unprecedented\nempirical foundation for studying autonomous teammates in software development.\n  Unlike prior work that has largely theorized the rise of AI-native software\nengineering, AIDev offers structured, open data to support research in\nbenchmarking, agent readiness, optimization, collaboration modeling, and AI\ngovernance. The dataset includes rich metadata on PRs, authorship, review\ntimelines, code changes, and integration outcomes--enabling exploration beyond\nsynthetic benchmarks like SWE-bench. For instance, although agents often\noutperform humans in speed, their PRs are accepted less frequently, revealing a\ntrust and utility gap. Furthermore, while agents accelerate code\nsubmission--one developer submitted as many PRs in three days as they had in\nthree years--these are structurally simpler (via code complexity metrics).\n  We envision AIDev as a living resource: extensible, analyzable, and ready for\nthe SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev\nenables a new generation of research into AI-native workflows and supports\nbuilding the next wave of symbiotic human-AI collaboration. The dataset is\npublicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.\n  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering\nAgent"}
{"id": "2507.15025", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15025", "abs": "https://arxiv.org/abs/2507.15025", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Andre Schamschurko", "Sven Kirchner", "Fengjunjie Pan", "Chengdng Wu", "Nils Purschke", "Aleksei Velsh", "Krzysztof Lebioda", "Yinglei Song", "Yi Zhang", "Lukasz Mazur", "Alois Knoll"], "title": "Survey of GenAI for Automotive Software Development: From Requirements to Executable Code", "comment": "Conference paper accepted for GACLM 2025", "summary": "Adoption of state-of-art Generative Artificial Intelligence (GenAI) aims to\nrevolutionize many industrial areas by reducing the amount of human\nintervention needed and effort for handling complex underlying processes.\nAutomotive software development is considered to be a significant area for\nGenAI adoption, taking into account lengthy and expensive procedures, resulting\nfrom the amount of requirements and strict standardization. In this paper, we\nexplore the adoption of GenAI for various steps of automotive software\ndevelopment, mainly focusing on requirements handling, compliance aspects and\ncode generation. Three GenAI-related technologies are covered within the\nstate-of-art: Large Language Models (LLMs), Retrieval Augmented Generation\n(RAG), Vision Language Models (VLMs), as well as overview of adopted prompting\ntechniques in case of code generation. Additionally, we also derive a\ngeneralized GenAI-aided automotive software development workflow based on our\nfindings from this literature review. Finally, we include a summary of a survey\noutcome, which was conducted among our automotive industry partners regarding\nthe type of GenAI tools used for their daily work activities."}
{"id": "2507.15157", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15157", "abs": "https://arxiv.org/abs/2507.15157", "authors": ["Giovanni Quattrocchi", "Liliana Pasquale", "Paola Spoletini", "Luciano Baresi"], "title": "Can LLMs Generate User Stories and Assess Their Quality?", "comment": null, "summary": "Requirements elicitation is still one of the most challenging activities of\nthe requirements engineering process due to the difficulty requirements\nanalysts face in understanding and translating complex needs into concrete\nrequirements. In addition, specifying high-quality requirements is crucial, as\nit can directly impact the quality of the software to be developed. Although\nautomated tools allow for assessing the syntactic quality of requirements,\nevaluating semantic metrics (e.g., language clarity, internal consistency)\nremains a manual and time-consuming activity. This paper explores how LLMs can\nhelp automate requirements elicitation within agile frameworks, where\nrequirements are defined as user stories (US). We used 10 state-of-the-art LLMs\nto investigate their ability to generate US automatically by emulating customer\ninterviews. We evaluated the quality of US generated by LLMs, comparing it with\nthe quality of US generated by humans (domain experts and students). We also\nexplored whether and how LLMs can be used to automatically evaluate the\nsemantic quality of US. Our results indicate that LLMs can generate US similar\nto humans in terms of coverage and stylistic quality, but exhibit lower\ndiversity and creativity. Although LLM-generated US are generally comparable in\nquality to those created by humans, they tend to meet the acceptance quality\ncriteria less frequently, regardless of the scale of the LLM model. Finally,\nLLMs can reliably assess the semantic quality of US when provided with clear\nevaluation criteria and have the potential to reduce human effort in\nlarge-scale assessments."}
{"id": "2507.15181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15181", "abs": "https://arxiv.org/abs/2507.15181", "authors": ["Yinglong Zou", "Juan Zhai", "Chunrong Fang", "Yanzhou Mu", "Jiawei Liu", "Zhenyu Chen"], "title": "Deep Learning Framework Testing via Heuristic Guidance Based on Multiple Model Measurements", "comment": null, "summary": "Deep learning frameworks serve as the foundation for developing and deploying\ndeep learning applications. To enhance the quality of deep learning frameworks,\nresearchers have proposed numerous testing methods using deep learning models\nas test inputs. However, existing methods predominantly measure model bug\ndetection effectiveness as heuristic indicators, presenting three critical\nlimitations: Firstly, existing methods fail to quantitatively measure model's\noperator combination variety, potentially missing critical operator\ncombinations that could trigger framework bugs. Secondly, existing methods\nneglect measuring model execution time, resulting in the omission of numerous\nmodels potential for detecting more framework bugs within limited testing time.\nThirdly, existing methods overlook correlation between different model\nmeasurements, relying simply on single-indicator heuristic guidance without\nconsidering their trade-offs. To overcome these limitations, we propose DLMMM,\nthe first deep learning framework testing method to include multiple model\nmeasurements into heuristic guidance and fuse these measurements to achieve\ntheir trade-off. DLMMM firstly quantitatively measures model's bug detection\nperformance, operator combination variety, and model execution time. After\nthat, DLMMM fuses the above measurements based on their correlation to achieve\ntheir trade-off. To further enhance testing effectiveness, DLMMM designs\nmulti-level heuristic guidance for test input model generation."}
{"id": "2507.15188", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.15188", "abs": "https://arxiv.org/abs/2507.15188", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Cultural Impact on Requirements Engineering Activities: Bangladeshi Practitioners' View", "comment": null, "summary": "Requirements Engineering (RE) is one of the most interaction-intensive phases\nof software development. This means that RE activities might be especially\nimpacted by stakeholders' national culture. Software development projects\nincreasingly have a very diverse range of stakeholders. To future-proof RE\nactivities, we need to help RE practitioners avoid misunderstandings and\nconflicts that might arise from not understanding potential Cultural Influences\n(CIs). Moreover, an awareness of CIs supports diversity and inclusion in the IT\nprofession. Bangladesh has a growing IT sector with some unique socio-cultural\ncharacteristics, and has been largely overlooked in this research field. In\nthis study, we aim to investigate how the RE process is adopted in the context\nof Bangladeshi culture and what cultural influences impact overall RE\nactivities."}
{"id": "2507.15197", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.15197", "abs": "https://arxiv.org/abs/2507.15197", "authors": ["Chowdhury Shahriar Muzammel", "Maria Spichkova", "James Harland"], "title": "Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?", "comment": null, "summary": "In requirements engineering (RE), personas are now being used to represent\nuser expectations and needs. This systematic mapping study (SMS) aims to\nexplore the most recent studies and to cover recent changes in trends,\nespecially related to the recent evolution of Generative AI approaches. Our SMS\ncovers the period between April 2023 and April 2025. We identified 22 relevant\npublications and analysed persona representation, construction, validation, as\nwell as RE activities covered by personas. We identified that a number of\nstudies applied AI-based solutions for persona construction and validation. We\nobserved that template-based personas are becoming more popular nowadays. We\nalso observed an increase in the proportion of studies covering validation\naspects."}
{"id": "2507.15224", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15224", "abs": "https://arxiv.org/abs/2507.15224", "authors": ["Yibo He", "Shuoran Zhao", "Jiaming Huang", "Yingjie Fu", "Hao Yu", "Cunjian Huang", "Tao Xie"], "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation", "comment": null, "summary": "SIMD (Single Instruction Multiple Data) instructions and their compiler\nintrinsics are widely supported by modern processors to accelerate\nperformance-critical tasks. SIMD intrinsic programming, a trade-off between\ncoding productivity and high performance, is widely used in the development of\nmainstream performance-critical libraries and daily computing tasks. Large\nLanguage Models (LLMs), which have demonstrated strong and comprehensive\ncapabilities in code generation, show promise in assisting programmers with the\nchallenges of SIMD intrinsic programming. However, existing code-generation\nbenchmarks focus on only scalar code, and it is unclear how LLMs perform in\ngenerating vectorized code using SIMD intrinsics. To fill this gap, we propose\nSimdBench, the first code benchmark specifically designed for SIMD-intrinsic\ncode generation, comprising 136 carefully crafted tasks and targeting five\nrepresentative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86\nAdvanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM\nScalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a\nsystematic evaluation (measuring both correctness and performance) of 18\nrepresentative LLMs on SimdBench, resulting in a series of novel and insightful\nfindings. Our evaluation results demonstrate that LLMs exhibit a universal\ndecrease in pass@k during SIMD-intrinsic code generation compared to\nscalar-code generation. Our in-depth analysis highlights promising directions\nfor the further advancement of LLMs in the challenging domain of SIMD-intrinsic\ncode generation. SimdBench is fully open source at\nhttps://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader\nresearch community."}
{"id": "2507.15226", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15226", "abs": "https://arxiv.org/abs/2507.15226", "authors": ["Changguo Jia", "Yi Zhan", "Tianqi Zhao", "Hengzhi Ye", "Minghui Zhou"], "title": "Code Clone Detection via an AlphaFold-Inspired Framework", "comment": null, "summary": "Code clone detection, which aims to identify functionally equivalent code\nfragments, plays a critical role in software maintenance and vulnerability\nanalysis. Substantial methods have been proposed to detect code clones, but\nthey fall short in capturing code semantics or relying on language-specific\nanalyzers. Inspired by the remarkable success of AlphaFold in predicting\nthree-dimensional protein structures from protein sequences, in this paper, we\nleverage AlphaFold for code clone detection based on the insight that protein\nsequences and token sequences share a common linear sequential structure. In\nparticular, we propose AlphaCC, which represents code fragments as token\nsequences to ensure multi-language applicability and adapts AlphaFold's\nsequence-to-structure modeling capability to infer code semantics. The pipeline\nof AlphaCC goes through three steps. First, AlphaCC transforms each input code\nfragment into a token sequence and, motivated by AlphaFold's use of multiple\nsequence alignment (MSA) to enhance contextual understanding, constructs an MSA\nfrom lexically similar token sequences. Second, AlphaCC adopts a modified\nattention-based encoder based on AlphaFold to model dependencies within and\nacross token sequences. Finally, unlike AlphaFold's protein structure\nprediction task, AlphaCC computes similarity scores between token sequences\nthrough a late interaction strategy and performs binary classification to\ndetermine code clone pairs. Comprehensive evaluations on three language-diverse\ndatasets demonstrate AlphaCC's applicability across multiple programming\nlanguages. On two semantic clone detection datasets, it consistently\noutperforms all baselines, showing strong semantic understanding. Moreover,\nAlphaCC maintains competitive efficiency, enabling practical usage in\nlarge-scale clone detection tasks."}
{"id": "2507.15241", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15241", "abs": "https://arxiv.org/abs/2507.15241", "authors": ["Vikram Nitin", "Baishakhi Ray", "Roshanak Zilouchian Moghaddam"], "title": "FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents", "comment": null, "summary": "Despite the critical threat posed by software security vulnerabilities,\nreports are often incomplete, lacking the proof-of-vulnerability (PoV) tests\nneeded to validate fixes and prevent regressions. These tests are crucial not\nonly for ensuring patches work, but also for helping developers understand how\nvulnerabilities can be exploited. Generating PoV tests is a challenging\nproblem, requiring reasoning about the flow of control and data through deeply\nnested levels of a program.\n  We present FaultLine, an LLM agent workflow that uses a set of carefully\ndesigned reasoning steps, inspired by aspects of traditional static and dynamic\nprogram analysis, to automatically generate PoV test cases. Given a software\nproject with an accompanying vulnerability report, FaultLine 1) traces the flow\nof an input from an externally accessible API (\"source\") to the \"sink\"\ncorresponding to the vulnerability, 2) reasons about the conditions that an\ninput must satisfy in order to traverse the branch conditions encountered along\nthe flow, and 3) uses this reasoning to generate a PoV test case in a\nfeedback-driven loop. FaultLine does not use language-specific static or\ndynamic analysis components, which enables it to be used across programming\nlanguages.\n  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100\nknown vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine\nis able to generate PoV tests for 16 projects, compared to just 9 for CodeAct\n2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine\nrepresents a 77% relative improvement over the state of the art. Our findings\nsuggest that hierarchical reasoning can enhance the performance of LLM agents\non PoV test generation, but the problem in general remains challenging. We make\nour code and dataset publicly available in the hope that it will spur further\nresearch in this area."}
{"id": "2507.15251", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15251", "abs": "https://arxiv.org/abs/2507.15251", "authors": ["Boyang Yang", "Luyao Ren", "Xin Yin", "Jiadong Ren", "Haoye Tian", "Shunfu Jin"], "title": "Input Reduction Enhanced LLM-based Program Repair", "comment": null, "summary": "Large Language Models (LLMs) have shown great potential in Automated Program\nRepair (APR). Test inputs, being crucial for reasoning the root cause of\nfailures, are always included in the prompt for LLM-based APR. Unfortunately,\nLLMs struggle to retain key information in long prompts. When the test inputs\nare extensive in the prompt, this may trigger the \"lost-in-the-middle\" issue,\ncompromising repair performance. To address this, we propose ReduceFix, an\nLLM-based APR approach with a built-in component that automatically reduces\ntest inputs while retaining their failure-inducing behavior. ReduceFix prompts\nan LLM to generate a reducer that minimizes failure-inducing test inputs\nwithout human effort, and then feeds the reduced failure-inducing inputs to\nguide patch generation.\n  For targeted evaluation, we constructed LFTBench, the first long-input APR\nbenchmark with 200 real bugs from 20 programming tasks, each paired with a\nfailure-inducing input whose median size is 1 MB. On this benchmark, ReduceFix\nshrinks inputs by 89.1% on average and improves overall pass@10 by up to 53.8%\nrelative to a prompt that includes the original test, and by 17.6% compared\nwith omitting the test entirely. Adding the same reduction step to ChatRepair\nincreases its fix rate by 21.3% without other changes. Ablation studies further\nhighlight the impact of input length and compressed failure information on\nrepair success. These results underscore that automatically reducing failing\ninputs is a practical and powerful complement to LLM-based APR, significantly\nimproving its scalability and effectiveness."}
{"id": "2507.15296", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15296", "abs": "https://arxiv.org/abs/2507.15296", "authors": ["Qian Xiong", "Yuekai Huang", "Ziyou Jiang", "Zhiyuan Chang", "Yujia Zheng", "Tianhao Li", "Mingyang Li"], "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems", "comment": null, "summary": "The emergence of the tool agent paradigm has broadened the capability\nboundaries of the Large Language Model (LLM), enabling it to complete more\ncomplex tasks. However, the effectiveness of this paradigm is limited due to\nthe issue of parameter failure during its execution. To explore this phenomenon\nand propose corresponding suggestions, we first construct a parameter failure\ntaxonomy in this paper. We derive five failure categories from the invocation\nchain of a mainstream tool agent. Then, we explore the correlation between\nthree different input sources and failure categories by applying 15 input\nperturbation methods to the input. Experimental results show that parameter\nname hallucination failure primarily stems from inherent LLM limitations, while\nissues with input sources mainly cause other failure patterns. To improve the\nreliability and effectiveness of tool-agent interactions, we propose\ncorresponding improvement suggestions, including standardizing tool return\nformats, improving error feedback mechanisms, and ensuring parameter\nconsistency."}
{"id": "2507.15343", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15343", "abs": "https://arxiv.org/abs/2507.15343", "authors": ["Kechi Zhang", "Ge Li", "Jia Li", "Huangzhao Zhang", "Yihong Dong", "Jia Li", "Jingjing Xu", "Zhi Jin"], "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model", "comment": "currently under development", "summary": "The Transformer architecture has emerged as a landmark advancement within the\nbroad field of artificial intelligence, effectively catalyzing the advent of\nlarge language models (LLMs). However, despite its remarkable capabilities and\nthe substantial progress it has facilitated, the Transformer architecture still\nhas some limitations. One such intrinsic limitation is its inability to\neffectively capture the Chomsky hierarchy, such as regular expressions or\ndeterministic context-free grammars. Drawing inspiration from pushdown\nautomata, which efficiently resolve deterministic context-free grammars using\nstacks, we propose StackTrans to address the aforementioned issue within LLMs.\nUnlike previous approaches that modify the attention computation, StackTrans\nexplicitly incorporates hidden state stacks between Transformer layers. This\ndesign maintains compatibility with existing frameworks like flash-attention.\nSpecifically, our design features stack operations -- such as pushing and\npopping hidden states -- that are differentiable and can be learned in an\nend-to-end manner. Our comprehensive evaluation spans benchmarks for both\nChomsky hierarchies and large-scale natural languages. Across these diverse\ntasks, StackTrans consistently outperforms standard Transformer models and\nother baselines. We have successfully scaled StackTrans up from 360M to 7B\nparameters. In particular, our from-scratch pretrained model StackTrans-360M\noutperforms several larger open-source LLMs with 2-3x more parameters,\nshowcasing its superior efficiency and reasoning capability."}
{"id": "2507.15599", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.15599", "abs": "https://arxiv.org/abs/2507.15599", "authors": ["Manatsawin Hanmongkolchai"], "title": "Applying the Chinese Wall Reverse Engineering Technique to Large Language Model Code Editing", "comment": null, "summary": "Large language models for code (Code LLM) are increasingly utilized in\nprogramming environments. Despite their utility, the training datasets for top\nLLM remain undisclosed, raising concerns about potential copyright violations.\nSome models, such as Pleias and Comma put emphasis on data curation and\nlicenses, however, with limited training data these models are not competitive\nand only serve as proof of concepts. To improve the utility of these models, we\npropose an application of the \"Chinese Wall\" technique, inspired by the reverse\nengineering technique of the same name -- a high quality model is used to\ngenerate detailed instructions for a weaker model. By doing so, a weaker but\nethically aligned model may be used to perform complicated tasks that,\notherwise, can only be completed by more powerful models. In our evaluation,\nwe've found that this technique improves Comma v0.1 1T's performance in\nCanItEdit benchmark by over 66%, and Starcoder2 Instruct by roughly 20%\ncompared to when running the same model on the benchmark alone. The practical\napplication of this technique today, however, may be limited due to the lack of\nmodels trained on public domain content without copyright restrictions."}
{"id": "2507.15624", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15624", "abs": "https://arxiv.org/abs/2507.15624", "authors": ["Yusuf Sulistyo Nugroho", "Ganno Tribuana Kurniaji", "Syful Islam", "Mohammed Humayun Kabir", "Vanesya Aura Ardity", "Md. Kamal Uddin"], "title": "Hot Topics and Common Challenges: an Empirical Study of React Discussions on Stack Overflow", "comment": "6 pages, 4 figures, 4 tables, conference paper", "summary": "React is a JavaScript library used to build user interfaces for single-page\napplications. Although recent studies have shown the popularity and advantages\nof React in web development, the specific challenges users face remain unknown.\nThus, this study aims to analyse the React-related questions shared on Stack\nOverflow. The study utilizes an exploratory data analysis to investigate the\nmost frequently discussed keywords, error classification, and user\nreputation-based errors, which is the novelty of this work. The results show\nthe top eight most frequently used keywords on React-related questions, namely,\ncode, link, vir, href, connect, azure, windows, and website. The error\nclassification of questions from the sample shows that algorithmic error is the\nmost frequent issue faced by all groups of users, where mid-reputation users\ncontribute the most, accounting for 55.77%. This suggests the need for the\ncommunity to provide guidance materials in solving algorithm-related problems.\nWe expect that the results of this study will provide valuable insight into\nfuture research to support the React community during the early stages of\nimplementation, facilitating their ability to effectively overcome challenges\nto adoption."}
{"id": "2507.15663", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15663", "abs": "https://arxiv.org/abs/2507.15663", "authors": ["Giordano d'Aloisio", "Tosin Fadahunsi", "Jay Choy", "Rebecca Moussa", "Federica Sarro"], "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models", "comment": null, "summary": "Background: Text-to-image generation models are widely used across numerous\ndomains. Among these models, Stable Diffusion (SD) - an open-source\ntext-to-image generation model - has become the most popular, producing over 12\nbillion images annually. However, the widespread use of these models raises\nconcerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the\nenvironment, we introduce SustainDiffusion, a search-based approach designed to\nenhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters\nand prompt structures that can reduce gender and ethnic bias in generated\nimages while also lowering the energy consumption required for image\ngeneration. Importantly, SustainDiffusion maintains image quality comparable to\nthat of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion,\ntesting it against six different baselines using 56 different prompts. Our\nresults demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%,\nethnic bias by 59%, and energy consumption (calculated as the sum of CPU and\nGPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are\nconsistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social\nand environmental sustainability of text-to-image generation models is possible\nwithout fine-tuning or changing the model's architecture."}
{"id": "2507.15666", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15666", "abs": "https://arxiv.org/abs/2507.15666", "authors": ["Igor Turkin", "Lina Volobuieva", "Andriy Chukhray", "Oleksandr Liubimov"], "title": "Modeling CubeSat Storage Battery Discharge: Equivalent Circuit Versus Machine Learning Approaches", "comment": "13 pages, 15 figures", "summary": "The subject of the article is the study and comparison of two approaches to\nmodelling the battery discharge of a CubeSat satellite: analytical using\nequivalent circuit and machine learning. The article aims to make a reasoned\nchoice of the approach to modelling the battery discharge of a CubeSat\nsatellite. Modelling the battery discharge of a satellite will enable the\nprediction of the consequences of disconnecting the autonomous power system and\nensure the fault tolerance of equipment in orbit. Therefore, the selected study\nis relevant and promising. This study focuses on the analysis of CubeSat\nsatellite data, based explicitly on orbital data samples of the power system,\nwhich include data available at the time of the article publication. The\ndataset contains data on the voltage, current, and temperature of the battery\nand solar panels attached to the five sides of the satellite. In this context,\ntwo approaches are considered: analytical modelling based on physical laws and\nmachine learning, which uses empirical data to create a predictive model.\nResults: A comparative analysis of the modeling results reveals that the\nequivalent circuit approach has the advantage of transparency, as it identifies\npossible parameters that facilitate understanding of the relationships.\nHowever, the model is less flexible to environmental changes or non-standard\nsatellite behavior. The machine learning model demonstrated more accurate\nresults, as it can account for complex dependencies and adapt to actual\nconditions, even when they deviate from theoretical assumptions."}
{"id": "2507.15671", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15671", "abs": "https://arxiv.org/abs/2507.15671", "authors": ["Jinyao Guo", "Chengpeng Wang", "Dominic Deluca", "Jinjie Liu", "Zhuo Zhang", "Xiangyu Zhang"], "title": "BugScope: Learn to Find Bugs Like Human", "comment": "19 pages, 2 figure, 6 tables, 4 listings", "summary": "Detecting software bugs remains a fundamental challenge due to the extensive\ndiversity of real-world defects. Traditional static analysis tools often rely\non symbolic workflows, which restrict their coverage and hinder adaptability to\ncustomized bugs with diverse anti-patterns. While recent advances incorporate\nlarge language models (LLMs) to enhance bug detection, these methods continue\nto struggle with sophisticated bugs and typically operate within limited\nanalysis contexts. To address these challenges, we propose BugScope, an\nLLM-driven multi-agent system that emulates how human auditors learn new bug\npatterns from representative examples and apply that knowledge during code\nauditing. Given a set of examples illustrating both buggy and non-buggy\nbehaviors, BugScope synthesizes a retrieval strategy to extract relevant\ndetection contexts via program slicing and then constructs a tailored detection\nprompt to guide accurate reasoning by the LLM. Our evaluation on a curated\ndataset of 40 real-world bugs drawn from 21 widely-used open-source projects\ndemonstrates that BugScope achieves 87.04% precision and 90.00% recall,\nsurpassing state-of-the-art industrial tools by 0.44 in F1 score. Further\ntesting on large-scale open-source systems, including the Linux kernel,\nuncovered 141 previously unknown bugs, of which 78 have been fixed and 7\nconfirmed by developers, highlighting BugScope's substantial practical impact."}
{"id": "2507.15822", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.15822", "abs": "https://arxiv.org/abs/2507.15822", "authors": ["Li Huang", "Ilgiz Mustafin", "Marco Piccioni", "Alessandro Schena", "Reto Weber", "Bertrand Meyer"], "title": "Do AI models help produce verified bug fixes?", "comment": null, "summary": "Among areas of software engineering where AI techniques -- particularly,\nLarge Language Models -- seem poised to yield dramatic improvements, an\nattractive candidate is Automatic Program Repair (APR), the production of\nsatisfactory corrections to software bugs. Does this expectation materialize in\npractice? How do we find out, making sure that proposed corrections actually\nwork? If programmers have access to LLMs, how do they actually use them to\ncomplement their own skills?\n  To answer these questions, we took advantage of the availability of a\nprogram-proving environment, which formally determines the correctness of\nproposed fixes, to conduct a study of program debugging with two randomly\nassigned groups of programmers, one with access to LLMs and the other without,\nboth validating their answers through the proof tools. The methodology relied\non a division into general research questions (Goals in the Goal-Query-Metric\napproach), specific elements admitting specific answers (Queries), and\nmeasurements supporting these answers (Metrics). While applied so far to a\nlimited sample size, the results are a first step towards delineating a proper\nrole for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the\nuse of AI for debugging and APR. The contributions also include: a detailed\nmethodology for experiments in the use of LLMs for debugging, which other\nprojects can reuse; a fine-grain analysis of programmer behavior, made possible\nby the use of full-session recording; a definition of patterns of use of LLMs,\nwith 7 distinct categories; and validated advice for getting the best of LLMs\nfor debugging and Automatic Program Repair."}
{"id": "2507.15828", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15828", "abs": "https://arxiv.org/abs/2507.15828", "authors": ["Mauro Marcelino", "Marcos Alves", "Bianca Trinkenreich", "Bruno Cartaxo", "Sérgio Soares", "Simone D. J. Barbosa", "Marcos Kalinowski"], "title": "Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering", "comment": "ESEM 2025 Registered Report with an IPA (In Principle Acceptance) for\n  the Empirical Software Engineering journal", "summary": "[Context] An evidence briefing is a concise and objective transfer medium\nthat can present the main findings of a study to software engineers in the\nindustry. Although practitioners and researchers have deemed Evidence Briefings\nuseful, their production requires manual labor, which may be a significant\nchallenge to their broad adoption. [Goal] The goal of this registered report is\nto describe an experimental protocol for evaluating LLM-generated evidence\nbriefings for secondary studies in terms of content fidelity, ease of\nunderstanding, and usefulness, as perceived by researchers and practitioners,\ncompared to human-made briefings. [Method] We developed an RAG-based LLM tool\nto generate evidence briefings. We used the tool to automatically generate two\nevidence briefings that had been manually generated in previous research\nefforts. We designed a controlled experiment to evaluate how the LLM-generated\nbriefings compare to the human-made ones regarding perceived content fidelity,\nease of understanding, and usefulness. [Results] To be reported after the\nexperimental trials. [Conclusion] Depending on the experiment results."}
{"id": "2507.15831", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.15831", "abs": "https://arxiv.org/abs/2507.15831", "authors": ["Sergey Titov", "Konstantin Grotov", "Cristina Sarasua", "Yaroslav Golubev", "Dhivyabharathi Ramasamy", "Alberto Bacchelli", "Abraham Bernstein", "Timofey Bryksin"], "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development Time", "comment": "32 pages, 6 figures", "summary": "In software engineering, numerous studies have focused on the analysis of\nfine-grained logs, leading to significant innovations in areas such as\nrefactoring, security, and code completion. However, no similar studies have\nbeen conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we\n(1) introduce a toolset for collecting code changes in Jupyter notebooks during\ndevelopment time; (2) use it to collect more than 100 hours of work related to\na data analysis task and a machine learning task (carried out by 20 developers\nwith different levels of expertise), resulting in a dataset containing 2,655\ncells and 9,207 cell executions; and (3) use this dataset to investigate the\ndynamic nature of the notebook development process and the changes that take\nplace in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the\ncells between executions and found that a significant number of these changes\nwere relatively small fixes and code iteration modifications. This suggests\nthat notebooks are used not only as a development and exploration tool but also\nas a debugging tool. We report a number of other insights and propose potential\nfuture research directions on the novel data."}
