<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Empathy Guidelines for Improving Practitioner Well-being & Software Engineering Practices](https://arxiv.org/abs/2508.03846)
*Hashini Gunatilake,John Grundy,Rashina Hoda,Ingo Mueller*

Main category: cs.SE

TL;DR: 论文提出了17条可操作的共情指南，帮助软件工程团队改善沟通与决策，并提供了可视化优先级框架。


<details>
  <summary>Details</summary>
Motivation: 共情在软件工程中被忽视，但其对团队合作、沟通和决策至关重要。

Method: 基于先前研究，提出17条共情指南，并通过实践案例、挑战及应对策略验证其可行性。

Result: 开发了可视化优先级框架，帮助团队根据重要性、易实施性和采纳意愿分类指南。

Conclusion: 共情指南为软件工程实践提供了灵活实用的建议，推动从原则到可持续行动的转变。

Abstract: Empathy is a powerful yet often overlooked element in software engineering
(SE), supporting better teamwork, smoother communication, and effective
decision-making. In our previous study, we identified a range of practitioner
strategies for fostering empathy in SE contexts. Building on these insights,
this paper introduces 17 actionable empathy guidelines designed to support
practitioners, teams, and organisations. We also explore how these guidelines
can be implemented in practice by examining real-world applications,
challenges, and strategies to overcome them shared by software practitioners.
To support adoption, we present a visual prioritisation framework that
categorises the guidelines based on perceived importance, ease of
implementation, and willingness to adopt. The findings offer practical and
flexible suggestions for integrating empathy into everyday SE work, helping
teams move from principles to sustainable action.

</details>


### [2] [Evaluating Software Supply Chain Security in Research Software](https://arxiv.org/abs/2508.03856)
*Richard Hegewald,Rebecca Beyer*

Main category: cs.SE

TL;DR: 研究软件安全性普遍较弱，平均得分3.5/10，需改进签名发布和分支保护等关键实践。


<details>
  <summary>Details</summary>
Motivation: 研究软件的安全性对科学结果的完整性和可重复性至关重要，但目前研究不足。

Method: 使用OpenSSF Scorecard分析了3,248个高质量研究软件仓库。

Result: 平均安全得分仅为3.5/10，关键实践如签名发布和分支保护实施率低。

Conclusion: 提出了低成本的改进建议，以提升研究软件安全性并减少对科学完整性的威胁。

Abstract: The security of research software is essential for ensuring the integrity and
reproducibility of scientific results. However, research software security is
still largely unexplored. Due to its dependence on open source components and
distributed development practices, research software is particularly vulnerable
to supply chain attacks. This study analyses 3,248 high-quality, largely
peer-reviewed research software repositories using the OpenSSF Scorecard. We
find a generally weak security posture with an average score of 3.5/10.
Important practices, such as signed releases and branch protection, are rarely
implemented. Finally, we present actionable, low-effort recommendations that
can help research teams improve software security and mitigate potential
threats to scientific integrity.

</details>


### [3] [From App Features to Explanation Needs: Analyzing Correlations and Predictive Potential](https://arxiv.org/abs/2508.03881)
*Martin Obaidi,Kushtrim Qengaj,Jakob Droste,Hannah Deters,Marc Herrmann,Jil Klünder,Elisa Schmid,Kurt Schneider*

Main category: cs.SE

TL;DR: 研究发现，应用属性与用户解释需求之间的关联较弱，仅特定属性（如应用版本、评论数量和星级）有中等相关性。回归模型预测能力有限，解释需求高度依赖上下文，需结合用户反馈。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过应用属性预测用户解释需求，以支持早期开发和大规模需求挖掘。

Method: 分析了4,495条应用评论的黄金标准数据集，进行相关性分析和线性回归建模，并在495条手动标注评论上验证。

Result: 相关性分析显示弱关联，回归模型预测能力有限。安全与隐私、系统行为类别预测潜力略高，交互和用户界面最难预测。

Conclusion: 解释需求高度依赖上下文，无法仅通过应用元数据精确推断，需结合用户反馈设计用户中心软件。

Abstract: In today's digitized world, software systems must support users in
understanding both how to interact with a system and why certain behaviors
occur. This study investigates whether explanation needs, classified from user
reviews, can be predicted based on app properties, enabling early consideration
during development and large-scale requirements mining. We analyzed a gold
standard dataset of 4,495 app reviews enriched with metadata (e.g., app
version, ratings, age restriction, in-app purchases). Correlation analyses
identified mostly weak associations between app properties and explanation
needs, with moderate correlations only for specific features such as app
version, number of reviews, and star ratings. Linear regression models showed
limited predictive power, with no reliable forecasts across configurations.
Validation on a manually labeled dataset of 495 reviews confirmed these
findings. Categories such as Security & Privacy and System Behavior showed
slightly higher predictive potential, while Interaction and User Interface
remained most difficult to predict. Overall, our results highlight that
explanation needs are highly context-dependent and cannot be precisely inferred
from app metadata alone. Developers and requirements engineers should therefore
supplement metadata analysis with direct user feedback to effectively design
explainable and user-centered software systems.

</details>


### [4] [A Human Centric Requirements Engineering Framework for Assessing Github Copilot Output](https://arxiv.org/abs/2508.03922)
*Soroush Heydari*

Main category: cs.SE

TL;DR: 论文研究了GitHub Copilot如何满足人类需求，提出了以人为中心的评估框架，分析了其适应性和协作效果。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架多关注技术层面，忽视了AI编程助手在软件开发中的人类因素需求。

Method: 通过分析GitHub Copilot的聊天界面交互，测量其适应性和协作能力，建立评估框架。

Result: 提出了明确的评估指标，并讨论了测试结果及其对未来自动化编程中人类需求分析的启示。

Conclusion: 强调了以人为中心的评估在AI编程助手开发中的重要性。

Abstract: The rapid adoption of Artificial Intelligence(AI) programming assistants such
as GitHub Copilot introduces new challenges in how these software tools address
human needs. Many existing evaluation frameworks address technical aspects such
as code correctness and efficiency, but often overlook crucial human factors
that affect the successful integration of AI assistants in software development
workflows. In this study, I analyzed GitHub Copilot's interaction with users
through its chat interface, measured Copilot's ability to adapt explanations
and code generation to user expertise levels, and assessed its effectiveness in
facilitating collaborative programming experiences. I established a
human-centered requirements framework with clear metrics to evaluate these
qualities in GitHub Copilot chat. I discussed the test results and their
implications for future analysis of human requirements in automated
programming.

</details>


### [5] [Analyzing Prominent LLMs: An Empirical Study of Performance and Complexity in Solving LeetCode Problems](https://arxiv.org/abs/2508.03931)
*Everton Guimaraes,Nathalia Nascimento,Chandan Shivalingaiah,Asish Nelapati*

Main category: cs.SE

TL;DR: 该研究对四种大型语言模型（ChatGPT、Copilot、Gemini和DeepSeek）在150道LeetCode题目上的表现进行了系统比较，评估了它们在执行时间、内存使用和算法复杂度上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在软件开发中的广泛应用，对其性能进行系统比较以优化实际应用至关重要。

Method: 研究通过生成Java和Python的解决方案，在易、中、难三个难度级别的LeetCode题目上对四种模型进行基准测试。

Result: ChatGPT在执行时间和内存使用上表现一致高效，Copilot和DeepSeek在任务复杂度增加时表现不稳定，Gemini在简单任务上有效但难度增加时需要更多尝试。

Conclusion: 研究结果提供了每种模型的优势和局限性，为开发者选择适合特定编码任务的模型提供了指导。

Abstract: Large Language Models (LLMs) like ChatGPT, Copilot, Gemini, and DeepSeek are
transforming software engineering by automating key tasks, including code
generation, testing, and debugging. As these models become integral to
development workflows, a systematic comparison of their performance is
essential for optimizing their use in real world applications. This study
benchmarks these four prominent LLMs on one hundred and fifty LeetCode problems
across easy, medium, and hard difficulties, generating solutions in Java and
Python. We evaluate each model based on execution time, memory usage, and
algorithmic complexity, revealing significant performance differences. ChatGPT
demonstrates consistent efficiency in execution time and memory usage, while
Copilot and DeepSeek show variability as task complexity increases. Gemini,
although effective on simpler tasks, requires more attempts as problem
difficulty rises. Our findings provide actionable insights into each model's
strengths and limitations, offering guidance for developers selecting LLMs for
specific coding tasks and providing insights on the performance and complexity
of GPT-like generated solutions.

</details>


### [6] [Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code](https://arxiv.org/abs/2508.03949)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: 论文研究了代码语言模型压缩技术（如剪枝、量化和知识蒸馏）在对抗攻击下的鲁棒性，发现压缩模型在性能上接近原始模型，但在对抗攻击下鲁棒性显著降低。


<details>
  <summary>Details</summary>
Motivation: Transformer-based代码语言模型的高计算成本和环境影响阻碍了其应用，压缩技术虽能缓解这些问题，但其在对抗场景下的鲁棒性影响尚不明确。

Method: 通过评估三种代码语言模型在三种软件分析任务中的压缩版本，使用六种评估指标和四种经典对抗攻击，分析压缩策略对鲁棒性的影响。

Result: 压缩模型在性能上与原始模型相当，但在对抗攻击下鲁棒性显著降低，揭示了模型大小与鲁棒性之间的权衡。

Conclusion: 研究强调需进一步探索平衡计算效率和鲁棒性的压缩策略，以确保代码语言模型在安全关键应用中的可靠部署。

Abstract: Transformer-based language models for code have shown remarkable performance
in various software analytics tasks, but their adoption is hindered by high
computational costs, slow inference speeds, and substantial environmental
impact. Model compression techniques such as pruning, quantization, and
knowledge distillation have gained traction in addressing these challenges.
However, the impact of these strategies on the robustness of compressed
language models for code in adversarial scenarios remains poorly understood.
Understanding how these compressed models behave under adversarial attacks is
essential for their safe and effective deployment in real-world applications.
To bridge this knowledge gap, we conduct a comprehensive evaluation of how
common compression strategies affect the adversarial robustness of compressed
models. We assess the robustness of compressed versions of three widely used
language models for code across three software analytics tasks, using six
evaluation metrics and four commonly used classical adversarial attacks. Our
findings indicate that compressed models generally maintain comparable
performance to their uncompressed counterparts. However, when subjected to
adversarial attacks, compressed models exhibit significantly reduced
robustness. These results reveal a trade-off between model size reduction and
adversarial robustness, underscoring the need for careful consideration when
deploying compressed models in security-critical software applications. Our
study highlights the need for further research into compression strategies that
strike a balance between computational efficiency and adversarial robustness,
which is essential for deploying reliable language models for code in
real-world software applications.

</details>


### [7] [Experimental Analysis of Productive Interaction Strategy with ChatGPT: User Study on Function and Project-level Code Generation Tasks](https://arxiv.org/abs/2508.04125)
*Sangwon Hyun,Hyunjun Kim,Jinhyuk Jang,Hyojin Choi,M. Ali Babar*

Main category: cs.SE

TL;DR: 论文研究了大型语言模型（LLM）在软件工程任务中的应用，重点关注了超出函数级别的复杂工作流程，并提出了提升代码生成效率的指导原则和错误分类。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注函数级别的软件工程实践，而忽略了更复杂的类级别和多类依赖问题，因此需要填补这一研究空白。

Method: 设计了包含两个项目级基准任务的实验，通过36名参与者的用户研究，分析其与GPT助手的交互行为和屏幕记录。

Result: 研究发现15个交互特征中有3个显著影响代码生成效率，提出了5条提升效率的指导原则，并分类了29种运行时和逻辑错误及其缓解方案。

Conclusion: 研究为复杂软件工程任务中的人机交互提供了实用指导，并扩展了现有研究的范围。

Abstract: The application of Large Language Models (LLMs) is growing in the productive
completion of Software Engineering tasks. Yet, studies investigating the
productive prompting techniques often employed a limited problem space,
primarily focusing on well-known prompting patterns and mainly targeting
function-level SE practices. We identify significant gaps in real-world
workflows that involve complexities beyond class-level (e.g., multi-class
dependencies) and different features that can impact Human-LLM Interactions
(HLIs) processes in code generation. To address these issues, we designed an
experiment that comprehensively analyzed the HLI features regarding the code
generation productivity. Our study presents two project-level benchmark tasks,
extending beyond function-level evaluations. We conducted a user study with 36
participants from diverse backgrounds, asking them to solve the assigned tasks
by interacting with the GPT assistant using specific prompting patterns. We
also examined the participants' experience and their behavioral features during
interactions by analyzing screen recordings and GPT chat logs. Our statistical
and empirical investigation revealed (1) that three out of 15 HLI features
significantly impacted the productivity in code generation; (2) five primary
guidelines for enhancing productivity for HLI processes; and (3) a taxonomy of
29 runtime and logic errors that can occur during HLI processes, along with
suggested mitigation plans.

</details>


### [8] [EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation](https://arxiv.org/abs/2508.04295)
*Chaofan Wang,Tingrui Yu,Jie Wang,Dong Chen,Wenrui Zhang,Yuling Shi,Xiaodong Gu,Beijun Shen*

Main category: cs.SE

TL;DR: EvoC2Rust是一个自动化框架，用于将整个C项目转换为等效的Rust项目，结合了规则和LLM方法的优势，显著提升了翻译的准确性和代码安全性。


<details>
  <summary>Details</summary>
Motivation: Rust的编译时安全性使其适合安全关键系统，但现有C到Rust的转换方法在小规模程序上表现有限，无法满足大规模项目的需求。

Method: EvoC2Rust采用骨架引导的翻译策略，分为三个阶段：分解C项目、增量翻译函数和修复编译错误，结合LLM和静态分析。

Result: 在开源基准和工业项目上，EvoC2Rust在语法和语义准确性上分别提升了17.24%和14.32%，代码安全性提高了96.79%。

Conclusion: EvoC2Rust在大规模C到Rust转换中表现出色，适用于复杂代码库和长函数。

Abstract: Rust's compile-time safety guarantees make it ideal for safety-critical
systems, creating demand for translating legacy C codebases to Rust. While
various approaches have emerged for this task, they face inherent trade-offs:
rule-based solutions face challenges in meeting code safety and idiomaticity
requirements, while LLM-based solutions often fail to generate semantically
equivalent Rust code, due to the heavy dependencies of modules across the
entire codebase. Recent studies have revealed that both solutions are limited
to small-scale programs. In this paper, we propose EvoC2Rust, an automated
framework for converting entire C projects to equivalent Rust ones. EvoC2Rust
employs a skeleton-guided translation strategy for project-level translation.
The pipeline consists of three evolutionary stages: 1) it first decomposes the
C project into functional modules, employs a feature-mapping-enhanced LLM to
transform definitions and macros and generates type-checked function stubs,
which form a compilable Rust skeleton; 2) it then incrementally translates the
function, replacing the corresponding stub placeholder; 3) finally, it repairs
compilation errors by integrating LLM and static analysis. Through evolutionary
augmentation, EvoC2Rust combines the advantages of both rule-based and
LLM-based solutions. Our evaluation on open-source benchmarks and six
industrial projects demonstrates EvoC2Rust's superior performance in
project-level C-to-Rust translation. On average, it achieves 17.24% and 14.32%
improvements in syntax and semantic accuracy over the LLM-based approaches,
along with a 96.79% higher code safety rate than the rule-based tools. At the
module level, EvoC2Rust reaches 92.25% compilation and 89.53% test pass rates
on industrial projects, even for complex codebases and long functions.

</details>


### [9] [Vanilla-Converter: A Tool for Converting Camunda 7 BPMN Models into Camunda 8 Models](https://arxiv.org/abs/2508.04352)
*Dragana Sunaric,Charlotte Verbruggen,Dominik Bork*

Main category: cs.SE

TL;DR: Vanilla-Converter是一个命令行工具，用于自动化将BPMN模型从Camunda 7迁移到Camunda 8，支持多种BPMN元素并生成转换日志。


<details>
  <summary>Details</summary>
Motivation: 由于Camunda 7和8之间存在根本差异，手动迁移复杂且耗时，因此开发自动化工具以简化迁移过程。

Method: Vanilla-Converter通过自动化转换过程，支持广泛的BPMN元素，并生成转换日志，详细记录自动更改和剩余手动任务。

Result: 通过三个实际工业案例验证，工具成功将Camunda 7模型转换为有效且可执行的Camunda 8模型。

Conclusion: Vanilla-Converter有效解决了Camunda 7到8的迁移问题，显著减少了手动工作量。

Abstract: As organizations prepare for the end-of-life of Camunda 7, manual migration
remains complex due to fundamental differences between the two platforms. We
present Vanilla-Converter, a command-line tool that facilitates the migration
of BPMN models from Camunda 7 to Camunda 8. Vanilla-Converter automates the
transformation process, supports a wide range of BPMN elements, and produces a
transformed model and a detailed transformation log indicating automatic
changes and remaining manual conversion tasks. The tool's effectiveness is
demonstrated through three case studies with real industrially used Camunda 7
models, confirming its ability to convert these models into valid and
executable Camunda 8 models.

</details>


### [10] [Breaking New Ground in Software Defect Prediction: Introducing Practical and Actionable Metrics with Superior Predictive Power for Enhanced Decision-Making](https://arxiv.org/abs/2508.04408)
*Carlos Andrés Ramírez Cataño,Makoto Itoh*

Main category: cs.SE

TL;DR: 论文提出了一种基于开发者编码习惯的软件缺陷预测方法，通过人类因素理论设计新指标，性能优于现有代码和历史指标，并提升了模型的可解释性和实用性。


<details>
  <summary>Details</summary>
Motivation: 软件缺陷的根源常归因于人为错误，但现有研究多关注代码指标，而忽略非软件指标。本文探索开发者编码习惯对缺陷预测的作用。

Method: 提出一个框架选择预测指标，比较新指标与现有最佳代码和历史指标的性能，并分析各指标的重要性。

Result: 新指标在21个大型开源项目中表现优于现有指标，提升了预测性能、可解释性和实用性。

Conclusion: 基于人类错误框架的系统性方法显著推进了软件缺陷预测领域，为实践者提供了可操作的预测工具。

Abstract: Software defect prediction using code metrics has been extensively researched
over the past five decades. However, prediction harnessing non-software metrics
is under-researched. Considering that the root cause of software defects is
often attributed to human error, human factors theory might offer key
forecasting metrics for actionable insights. This paper explores automated
software defect prediction at the method level based on the developers' coding
habits. First, we propose a framework for deciding the metrics to conduct
predictions. Next, we compare the performance of our metrics to that of the
code and commit history metrics shown by research to achieve the highest
performance to date. Finally, we analyze the prediction importance of each
metric. As a result of our analyses of twenty-one critical infrastructure
large-scale open-source software projects, we have presented: (1) a human
error-based framework with metrics useful for defect prediction at method
level; (2) models using our proposed metrics achieve better average prediction
performance than the state-of-the-art code metrics and history measures; (3)
the prediction importance of all metrics distributes differently with each of
the novel metrics having better average importance than code and history
metrics; (4) the novel metrics dramatically enhance the explainability,
practicality, and actionability of software defect prediction models,
significantly advancing the field. We present a systematic approach to
forecasting defect-prone software methods via a human error framework. This
work empowers practitioners to act on predictions, empirically demonstrating
how developer coding habits contribute to defects in software systems.

</details>


### [11] [Large Language Models Versus Static Code Analysis Tools: A Systematic Benchmark for Vulnerability Detection](https://arxiv.org/abs/2508.04448)
*Damian Gnieciak,Tomasz Szandala*

Main category: cs.SE

TL;DR: 该研究比较了六种自动化代码分析工具（三种静态分析工具和三种大语言模型）在检测漏洞方面的表现，发现语言模型在召回率上表现更优，但存在误报和定位不精确的问题，建议结合使用。


<details>
  <summary>Details</summary>
Motivation: 评估现代自动化测试工具在检测代码漏洞方面的效果，比较静态分析工具与大语言模型的优劣。

Method: 使用十个真实C#项目（含63个漏洞）测试六种工具，测量精度、召回率、F分数、延迟和开发者工作量。

Result: 语言模型的平均F-1分数（0.797、0.753、0.750）高于静态工具（0.260、0.386、0.546），但误报率高且定位不精确。

Conclusion: 建议结合语言模型的广泛检测和静态工具的高精度验证，并发布了开放基准测试工具。

Abstract: Modern software relies on a multitude of automated testing and quality
assurance tools to prevent errors, bugs and potential vulnerabilities. This
study sets out to provide a head-to-head, quantitative and qualitative
evaluation of six automated approaches: three industry-standard rule-based
static code-analysis tools (SonarQube, CodeQL and Snyk Code) and three
state-of-the-art large language models hosted on the GitHub Models platform
(GPT-4.1, Mistral Large and DeepSeek V3). Using a curated suite of ten
real-world C# projects that embed 63 vulnerabilities across common categories
such as SQL injection, hard-coded secrets and outdated dependencies, we measure
classical detection accuracy (precision, recall, F-score), analysis latency,
and the developer effort required to vet true positives. The language-based
scanners achieve higher mean F-1 scores,0.797, 0.753 and 0.750, than their
static counterparts, which score 0.260, 0.386 and 0.546, respectively. LLMs'
advantage originates from superior recall, confirming an ability to reason
across broader code contexts. However, this benefit comes with substantial
trade-offs: DeepSeek V3 exhibits the highest false-positive ratio, all language
models mislocate issues at line-or-column granularity due to tokenisation
artefacts. Overall, language models successfully rival traditional static
analysers in finding real vulnerabilities. Still, their noisier output and
imprecise localisation limit their standalone use in safety-critical audits. We
therefore recommend a hybrid pipeline: employ language models early in
development for broad, context-aware triage, while reserving deterministic
rule-based scanners for high-assurance verification. The open benchmark and
JSON-based result harness released with this paper lay a foundation for
reproducible, practitioner-centric research into next-generation automated code
security.

</details>


### [12] [Manifestations of Empathy in Software Engineering: How, Why, and When It Matters](https://arxiv.org/abs/2508.04479)
*Hashini Gunatilake,John Grundy,Rashina Hoda,Ingo Mueller*

Main category: cs.SE

TL;DR: 研究探讨了同理心在软件工程中的表现、动机及影响因素，通过访谈和调查揭示了其实际应用和驱动因素。


<details>
  <summary>Details</summary>
Motivation: 理解同理心在软件工程中的具体表现、动机及影响因素，填补现有研究的空白。

Method: 通过22次访谈和116名软件从业者的大规模调查进行研究。

Result: 揭示了同理心在软件工程中的表达方式、驱动因素、适用场景及其他影响因素。

Conclusion: 为软件工程实践和研究提供了如何有效整合同理心的实用建议。

Abstract: Empathy plays a crucial role in software engineering (SE), influencing
collaboration, communication, and decision-making. While prior research has
highlighted the importance of empathy in SE, there is limited understanding of
how empathy manifests in SE practice, what motivates SE practitioners to
demonstrate empathy, and the factors that influence empathy in SE work. Our
study explores these aspects through 22 interviews and a large scale survey
with 116 software practitioners. Our findings provide insights into the
expression of empathy in SE, the drivers behind empathetic practices, SE
activities where empathy is perceived as useful or not, and the other factors
that influence empathy. In addition, we offer practical implications for SE
practitioners and researchers, offering a deeper understanding of how to
effectively integrate empathy into SE processes.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [13] [Control Closure Certificates](https://arxiv.org/abs/2508.03947)
*Vishnu Murali,Mohammed Adib Oumer,Majid Zamani*

Main category: cs.LO

TL;DR: 论文提出控制闭包证书的概念，用于合成离散时间控制系统满足ω-正则规范的控制器。通过结合不变量和过渡不变量，提供自动化验证方法，并通过案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖归纳不变量和良基性证明，而过渡不变量提供了一种替代方案。本文旨在通过闭包证书自动验证和合成控制器，满足ω-正则规范。

Method: 提出控制闭包证书的概念，结合不变量和良基性论证，通过和-平方优化方法合成证书，并设计控制器。

Result: 成功合成满足ω-正则规范的控制器，并通过案例研究验证了方法的有效性。

Conclusion: 控制闭包证书为离散时间控制系统的ω-正则规范提供了一种有效的自动化验证和合成方法。

Abstract: This paper introduces the notion of control closure certificates to
synthesize controllers for discrete-time control systems against
$\omega$-regular specifications. Typical functional approaches to synthesize
controllers against $\omega$-regular specifications rely on combining inductive
invariants (for example, via barrier certificates) with proofs of
well-foundedness (for example, via ranking functions). Transition invariants,
provide an alternative where instead of standard well-foundedness arguments one
may instead search for disjunctive well-foundedness arguments that together
ensure a well-foundedness argument. Closure certificates, functional analogs of
transition invariants, provide an effective, automated approach to verify
discrete-time dynamical systems against linear temporal logic and
$\omega$-regular specifications. We build on this notion to synthesize
controllers to ensure the satisfaction of $\omega$-regular specifications. To
do so, we first illustrate how one may construct control closure certificates
to visit a region infinitely often (or only finitely often) via disjunctive
well-founded arguments. We then combine these arguments to provide an argument
for parity specifications. Thus, finding an appropriate control closure
certificate over the product of the system and a parity automaton specifying a
desired $\omega$-regular specification ensures that there exists a controller
$\kappa$ to enforce the $\omega$-regular specification. We propose a
sum-of-squares optimization approach to synthesize such certificates and
demonstrate their efficacy in designing controllers over some case studies.

</details>


### [14] [GradSTL: Comprehensive Signal Temporal Logic for Neurosymbolic Reasoning and Learning](https://arxiv.org/abs/2508.04438)
*Mark Chevallier,Filip Smola,Richard Schmoetten,Jacques D. Fleuriot*

Main category: cs.LO

TL;DR: GradSTL是首个全面支持信号时序逻辑（STL）的实现，适用于神经符号学习，能评估任意信号上的STL约束，并通过形式化验证确保正确性。


<details>
  <summary>Details</summary>
Motivation: 为神经符号学习提供一个严格且通用的STL实现，支持梯度下降学习。

Method: 通过形式化验证定义平滑的STL语义，自动生成实现代码，确保构造正确性。

Result: 案例研究表明，神经符号过程能通过学习满足预定义的STL约束。

Conclusion: GradSTL为信号时序逻辑与梯度下降学习的结合提供了严谨的基础。

Abstract: We present GradSTL, the first fully comprehensive implementation of signal
temporal logic (STL) suitable for integration with neurosymbolic learning. In
particular, GradSTL can successfully evaluate any STL constraint over any
signal, regardless of how it is sampled. Our formally verified approach
specifies smooth STL semantics over tensors, with formal proofs of soundness
and of correctness of its derivative function. Our implementation is generated
automatically from this formalisation, without manual coding, guaranteeing
correctness by construction. We show via a case study that using our
implementation, a neurosymbolic process learns to satisfy a pre-specified STL
constraint. Our approach offers a highly rigorous foundation for integrating
signal temporal logic and learning by gradient descent.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [15] [If-T: A Benchmark for Type Narrowing](https://arxiv.org/abs/2508.03830)
*Hanwen Guo,Ben Greenman*

Main category: cs.PL

TL;DR: 论文提出了If-T，一种语言无关的类型细化设计基准，用于评估类型细化系统的能力，通过简单程序展示其优缺点。


<details>
  <summary>Details</summary>
Motivation: 动态类型代码通常依赖运行时测试而非数据类型驱动设计，因此需要类型细化机制。现有系统缺乏统一标准，设计复杂且效果不明确。

Method: 基于文献、语言文档和类型检查器实验，If-T定义了核心技术维度，每个维度包含正反示例程序。

Result: If-T为五种类型检查器（如TypeScript、Flow等）提供了基准测试，揭示了它们在逻辑推理和用户定义谓词等方面的差异。

Conclusion: If-T为类型细化系统提供了评估标准，帮助研究者和设计者在精度、性能和复杂性之间找到平衡。

Abstract: **Context:** The design of static type systems that can validate
dynamically-typed programs (**gradually**) is an ongoing challenge. A key
difficulty is that dynamic code rarely follows datatype-driven design. Programs
instead use runtime tests to narrow down the proper usage of incoming data.
Type systems for dynamic languages thus need a **type narrowing** mechanism
that refines the type environment along individual control paths based on
dominating tests, a form of flow-sensitive typing. In order to express
refinements, the type system must have some notion of sets and subsets. Since
set-theoretic types are computationally and ergonomically complex, the need for
type narrowing raises design questions about how to balance precision and
performance. **Inquiry:** To date, the design of type narrowing systems has
been driven by intuition, past experience, and examples from users in various
language communities. There is no standard that captures desirable and
undesirable behaviors. Prior formalizations of narrowing are also significantly
more complex than a standard type system, and it is unclear how the extra
complexity pays off in terms of concrete examples. This paper addresses the
problems through If-T, a language-agnostic **design benchmark** for type
narrowing that characterizes the abilities of implementations using simple
programs that draw attention to fundamental questions. Unlike a traditional
performance-focused benchmark, If-T measures a narrowing system's ability to
validate correct code and reject incorrect code. Unlike a test suite, systems
are not required to fully conform to If-T. Deviations are acceptable provided
they are justified by well-reasoned design considerations, such as compile-time
performance. **Approach:** If-T is guided by the literature on type narrowing,
the documentation of gradual languages such as TypeScript, and experiments with
typechecker implementations. We have identified a set of core technical
dimensions for type narrowing. For each dimension, the benchmark contains a set
of topics and (at least) two characterizing programs per topic: one that should
typecheck and one that should not typecheck. **Knowledge:** If-T provides a
baseline to measure type narrowing systems. For researchers, it provides
criteria to categorize future designs via its collection of positive and
negative examples. For language designers, the benchmark demonstrates the
payoff of typechecker complexity in terms of concrete examples. Designers can
use the examples to decide whether supporting a particular example is
worthwhile. Both the benchmark and its implementations are freely available
online. **Grounding:** We have implemented the benchmark for five typecheckers:
TypeScript, Flow, Typed Racket, mypy, and Pyright. The results highlight
important differences, such as the ability to track logical implications among
program variables and typechecking for user-defined narrowing predicates.
**Importance:** Type narrowing is essential for gradual type systems, but the
tradeoffs between systems with different complexity have been unclear. If-T
clarifies these tradeoffs by illustrating the benefits and limitations of each
level of complexity. With If-T as a way to assess implementations in a fair,
cross-language manner, future type system designs can strive for a better
balance among precision, annotation burden, and performance.

</details>


### [16] [A Type System for Data Privacy Compliance in Active Object Languages](https://arxiv.org/abs/2508.03831)
*Chinmayi Prabhu Baramashetru,Paola Giannini,Silvia Lizeth Tapia Tarifa,Olaf Owe*

Main category: cs.PL

TL;DR: 该论文提出了一种基于语言的隐私集成方法，结合静态和运行时技术，通过类型检查和推断确保GDPR合规性。


<details>
  <summary>Details</summary>
Motivation: GDPR等数据保护法规要求系统在设计时嵌入隐私保护，但将抽象原则转化为具体方法仍具挑战性。

Method: 采用基于语言的框架，结合类型检查和运行时约束生成，跟踪授权数据流并验证用户同意。

Result: 通过类型系统实现合规性验证，并展示了方法的可行性，满足GDPR常见要求（如用户同意、目的限制）。

Conclusion: 该工作为隐私感知系统设计提供了自动化方法，适用于医疗、金融等关键领域。

Abstract: Data protection laws such as GDPR aim to give users unprecedented control
over their personal data. Compliance with these regulations requires
systematically considering information flow and interactions among entities
handling sensitive data. Privacy-by-design principles advocate embedding data
protection into system architectures as a default. However, translating these
abstract principles into concrete, explicit methods remains a significant
challenge. This paper addresses this gap by proposing a language-based approach
to privacy integration, combining static and runtime techniques. By employing
type checking and type inference in an active object language, the framework
enables the tracking of authorised data flows and the automatic generation of
constraints checked at runtime based on user consent. This ensures that
personal data is processed in compliance with GDPR constraints. The key
contribution of this work is a type system that gather the compliance checks
and the changes to users consent and integrates data privacy compliance
verification into system execution. The paper demonstrates the feasibility of
this approach through a soundness proof and several examples, illustrating how
the proposed language addresses common GDPR requirements, such as user consent,
purpose limitation, and data subject rights. This work advances the state of
the art in privacy-aware system design by offering a systematic and automated
method for integrating GDPR compliance into programming languages. This
capability has implications for building trustworthy systems in domains such as
healthcare or finance, where data privacy is crucial.

</details>


### [17] [Generating Inputs for Grammar Mining using Dynamic Symbolic Execution](https://arxiv.org/abs/2508.03832)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.PL

TL;DR: 论文提出了一种基于动态符号执行（DSE）的自动化输入生成方法，用于改进语法挖掘的完整性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有语法挖掘方法依赖输入数据的完整性，但实际运行中数据往往不完整，导致生成的语法遗漏边缘情况或旧功能。

Method: 结合DSE，采用迭代扩展输入和分三阶段生成输入的方法，克服DSE在结构化输入解析中的限制。

Result: 在11个基准应用中验证，该方法生成的语法接近现有最佳语法挖掘工具（如Mimid）的精度和召回率，并能发现更多边缘情况。

Conclusion: 该方法为软件工程提供了一种自动化、可扩展且精确的语法挖掘解决方案，显著减少了手动输入生成的工作量。

Abstract: A vast number of software systems include components that parse and process
structured input. In addition to programming languages, which are analyzed by
compilers or interpreters, there are numerous components that process
standardized or proprietary data formats of varying complexity. Even if such
components were initially developed and tested based on a specification, such
as a grammar, numerous modifications and adaptations over the course of
software evolution can make it impossible to precisely determine which inputs
they actually accept. In this situation, grammar mining can be used to
reconstruct the specification in the form of a grammar. Established approaches
already produce useful results, provided that sufficient input data is
available to fully cover the input language. However, achieving this
completeness is a major challenge. In practice, only input data recorded during
the operation of the software systems is available. If this data is used for
grammar mining, the resulting grammar reflects only the actual processed inputs
but not the complete grammar of the input language accepted by the software
component. As a result, edge cases or previously supported features that no
longer appear in the available input data are missing from the generated
grammar. This work addresses this challenge by introducing a novel approach for
the automatic generation of inputs for grammar mining. Although input
generators have already been used for fuzz testing, it remains unclear whether
they are also suitable for grammar miners. Building on the grammar miner Mimid,
this work presents a fully automated approach to input generation. The approach
leverages Dynamic Symbolic Execution (DSE) and extends it with two mechanisms
to overcome the limitations of DSE regarding structured input parsers. First,
the search for new inputs is guided by an iterative expansion that starts with
a single-character input and gradually extends it. Second, input generation is
structured into a novel three-phase approach, which separates the generation of
inputs for parser functions. The proposed method was evaluated against a
diverse set of eleven benchmark applications from the existing literature.
Results demonstrate that the approach achieves precision and recall for
extracted grammars close to those derived from state-of-the-art grammar miners
such as Mimid. Notably, it successfully uncovers subtle features and edge cases
in parsers that are typically missed by such grammar miners. The effectiveness
of the method is supported by empirical evidence, showing that it can achieve
high performance in various domains without requiring prior input samples. This
contribution is significant for researchers and practitioners in software
engineering, offering an automated, scalable, and precise solution for grammar
mining. By eliminating the need for manual input generation, the approach not
only reduces workload but also enhances the robustness and comprehensiveness of
the extracted grammars. Following this approach, software engineers can
reconstruct specification from existing (legacy) parsers.

</details>


### [18] [Weak Memory Model Formalisms: Introduction and Survey](https://arxiv.org/abs/2508.04115)
*Roger C. Su,Robert J. Colvin*

Main category: cs.PL

TL;DR: 本文综述了弱内存模型的正式化研究，包括其规范、执行影响及推理工具，并介绍了两种常见的表示方法。


<details>
  <summary>Details</summary>
Motivation: 由于并发编程中弱内存效应增加了开发难度，需对其模型进行严格规范以支持安全关键软件开发。

Method: 通过操作语义和公理语义两种形式化方法，结合简化版x86架构示例，分析弱内存模型的规范及其影响。

Result: 综述涵盖了硬件特性、历史发展、理论成果及未来方向，提供了全面的研究视角。

Conclusion: 弱内存模型的正式化研究对开发安全关键软件至关重要，未来需进一步探索其复杂性和应用。

Abstract: Memory consistency models define the order in which accesses to shared memory
in a concurrent system may be observed to occur. Such models are a necessity
since program order is not a reliable indicator of execution order, due to
microarchitectural features or compiler transformations. Concurrent
programming, already a challenging task, is thus made even harder when weak
memory effects must be addressed. A rigorous specification of weak memory
models is therefore essential to make this problem tractable for developers of
safety- and security-critical, low-level software.
  In this paper we survey the field of formalisations of weak memory models,
including their specification, their effects on execution, and tools and
inference systems for reasoning about code. To assist the discussion we also
provide an introduction to two styles of formal representation found commonly
in the literature (using a much simplified version of Intel's x86 as the
example): a step-by-step construction of traces of the system (operational
semantics); and with respect to relations between memory events (axiomatic
semantics). The survey covers some long-standing hardware features that lead to
observable weak behaviours, a description of historical developments in
practice and in theory, an overview of computability and complexity results,
and outlines current and future directions in the field.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [19] [Identity Testing for Stochastic Languages](https://arxiv.org/abs/2508.03826)
*Smayan Agarwal,Shobhit Singh,Aalok Thakkar*

Main category: cs.FL

TL;DR: 本文提出了一个多项式时间算法来验证有限状态机是否表示随机语言，并开发了一种基于截断的身份测试算法，用于区分已知和未知分布。


<details>
  <summary>Details</summary>
Motivation: 解决无限组合结构（特别是字符串）上的分布匹配问题，填补了形式语言理论与现代分布属性测试之间的空白。

Method: 提出多项式时间算法验证随机语言，证明有理随机语言可以近似任意概率分布，并开发基于截断的测试算法。

Result: 算法样本复杂度为$\widetilde{\Theta}\left( \frac{\sqrt{n}}{\varepsilon^2} + \frac{n}{\log n} \right)$，首次为无限离散分布建立了身份测试框架。

Conclusion: 该研究为概率形式方法和结构化数据的统计分析开辟了新方向。

Abstract: Determining whether an unknown distribution matches a known reference is a
cornerstone problem in distributional analysis. While classical results
establish a rigorous framework in the case of distributions over finite
domains, real-world applications in computational linguistics, bioinformatics,
and program analysis demand testing over infinite combinatorial structures,
particularly strings. In this paper, we initiate the theoretical study of
identity testing for stochastic languages, bridging formal language theory with
modern distribution property testing.
  We first propose a polynomial-time algorithm to verify if a finite state
machine represents a stochastic language, and then prove that rational
stochastic languages can approximate an arbitrary probability distribution.
Building on these representations, we develop a truncation-based identity
testing algorithm that distinguishes between a known and an unknown
distributions with sample complexity $\widetilde{\Theta}\left(
\frac{\sqrt{n}}{\varepsilon^2} + \frac{n}{\log n} \right)$ where $n$ is the
size of the truncated support. Our approach leverages the exponential decay
inherent in rational stochastic languages to bound truncation error, then
applies classical finite-domain testers to the restricted problem.
  This work establishes the first identity testing framework for infinite
discrete distributions, opening new directions in probabilistic formal methods
and statistical analysis of structured data.

</details>


### [20] [Componentwise Automata Learning for System Integration (Extended Version)](https://arxiv.org/abs/2508.04458)
*Hiroya Fujinami,Masaki Waga,Jie An,Kohei Suenaga,Nayuta Yanagisawa,Hiroki Iseri,Ichiro Hasuo*

Main category: cs.FL

TL;DR: 本文提出了一种新的组合自动机学习问题设置，称为组件化自动机学习，针对系统集成领域，通过直接访问黑盒组件减少冗余。


<details>
  <summary>Details</summary>
Motivation: 传统组合学习只能对整个系统进行查询，而本文旨在利用系统集成中直接访问组件的优势，解决组件冗余问题。

Method: 提出了一种上下文组件化学习算法，系统性去除组件冗余。

Result: 实验评估证明了该方法的实用性和有效性。

Conclusion: 组件化自动机学习为系统集成提供了新的分析工具，解决了传统方法中的冗余问题。

Abstract: Compositional automata learning is attracting attention as an analysis
technique for complex black-box systems. It exploits a target system's internal
compositional structure to reduce complexity. In this paper, we identify system
integration -- the process of building a new system as a composite of
potentially third-party and black-box components -- as a new application domain
of compositional automata learning. Accordingly, we propose a new problem
setting, where the learner has direct access to black-box components. This is
in contrast with the usual problem settings of compositional learning, where
the target is a legacy black-box system and queries can only be made to the
whole system (but not to components). We call our problem componentwise
automata learning for distinction. We identify a challenge there called
component redundancies: some parts of components may not contribute to
system-level behaviors, and learning them incurs unnecessary effort. We
introduce a contextual componentwise learning algorithm that systematically
removes such redundancies. We experimentally evaluate our proposal and show its
practical relevance.

</details>
