{"id": "2507.18792", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18792", "abs": "https://arxiv.org/abs/2507.18792", "authors": ["Zixu Zhou"], "title": "Decompiling Rust: An Empirical Study of Compiler Optimizations and Reverse Engineering Challenges", "comment": null, "summary": "Decompiling Rust binaries is challenging due to the language's rich type\nsystem, aggressive compiler optimizations, and widespread use of high-level\nabstractions. In this work, we conduct a benchmark-driven evaluation of\ndecompilation quality across core Rust features and compiler build modes. Our\nautomated scoring framework shows that generic types, trait methods, and error\nhandling constructs significantly reduce decompilation quality, especially in\nrelease builds. Through representative case studies, we analyze how specific\nlanguage constructs affect control flow, variable naming, and type information\nrecovery. Our findings provide actionable insights for tool developers and\nhighlight the need for Rust-aware decompilation strategies.", "AI": {"tldr": "\u8bc4\u4f30Rust\u4e8c\u8fdb\u5236\u6587\u4ef6\u53cd\u7f16\u8bd1\u8d28\u91cf\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6cdb\u578b\u3001\u7279\u8d28\u65b9\u6cd5\u548c\u9519\u8bef\u5904\u7406\u7ed3\u6784\u663e\u8457\u964d\u4f4e\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u53d1\u5e03\u6784\u5efa\u4e2d\u3002", "motivation": "\u7531\u4e8eRust\u7684\u4e30\u5bcc\u7c7b\u578b\u7cfb\u7edf\u3001\u7f16\u8bd1\u5668\u4f18\u5316\u548c\u9ad8\u5c42\u62bd\u8c61\uff0c\u53cd\u7f16\u8bd1\u5176\u4e8c\u8fdb\u5236\u6587\u4ef6\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u8bc4\u5206\u6846\u67b6\u548c\u5178\u578b\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u6838\u5fc3Rust\u529f\u80fd\u548c\u7f16\u8bd1\u5668\u6784\u5efa\u6a21\u5f0f\u5bf9\u53cd\u7f16\u8bd1\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u6cdb\u578b\u3001\u7279\u8d28\u65b9\u6cd5\u548c\u9519\u8bef\u5904\u7406\u7ed3\u6784\u663e\u8457\u964d\u4f4e\u53cd\u7f16\u8bd1\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u53d1\u5e03\u6784\u5efa\u4e2d\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\uff0c\u5e76\u5f3a\u8c03\u9700\u8981Rust\u611f\u77e5\u7684\u53cd\u7f16\u8bd1\u7b56\u7565\u3002"}}
{"id": "2507.18885", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.18885", "abs": "https://arxiv.org/abs/2507.18885", "authors": ["Qiyuan Xu", "Renxi Wang", "Haonan Li", "David Sanan", "Conrad Watt"], "title": "IsaMini: Redesigned Isabelle Proof Lanugage for Machine Learning", "comment": null, "summary": "Neural Theorem Proving (NTP) employs deep learning methods, particularly\nLarge Language Models (LLMs), to automate formal proofs in proof assistants.\nThis approach holds promise for reducing the dramatic labor costs or\ncomputation costs required in proof engineering, which is fundamental to formal\nverification and other software engineering methods. The paper explores the\npotential of improving NTP by redesigning the proof language, given that LLMs'\ncapabilities depend highly on representations. We introduce \\emph{MiniLang}, a\nredesigned proof language for Isabelle/HOL incorporating an improved version of\nSledgehammer. Experiments show MiniLang benefits two fine-tuned LLMs by\nimproving the success rate on the PISA benchmark by up to 29\\% in comparison to\ngeneration of Isar proof script. The success rate under one attempt (so-called\n\\emph{pass@1}) reaches 69.1\\%, exceeding the previous Baldur's pass@64\n(65.7\\%); The pass@8 reaches 79.2\\%, exceeding the state-of-the-art on PISA\n(71.0\\%) achieved by Magnushammer.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8bc1\u660e\u8bed\u8a00MiniLang\uff0c\u7528\u4e8e\u63d0\u5347\u795e\u7ecf\u5b9a\u7406\u8bc1\u660e\uff08NTP\uff09\u5728Isabelle/HOL\u4e2d\u7684\u8868\u73b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728PISA\u57fa\u51c6\u4e0a\u7684\u6210\u529f\u7387\u3002", "motivation": "\u901a\u8fc7\u4f18\u5316\u8bc1\u660e\u8bed\u8a00\u8bbe\u8ba1\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u51cf\u5c11\u8bc1\u660e\u5de5\u7a0b\u4e2d\u7684\u9ad8\u6210\u672c\u3002", "method": "\u5f15\u5165MiniLang\uff0c\u4e00\u79cd\u4e3aIsabelle/HOL\u8bbe\u8ba1\u7684\u6539\u8fdb\u8bc1\u660e\u8bed\u8a00\uff0c\u7ed3\u5408\u589e\u5f3a\u7248Sledgehammer\u5de5\u5177\uff0c\u5e76\u5728PISA\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u4e24\u79cd\u5fae\u8c03LLMs\u7684\u6027\u80fd\u3002", "result": "MiniLang\u4f7fLLMs\u5728PISA\u57fa\u51c6\u4e0a\u7684\u6210\u529f\u7387\u6700\u9ad8\u63d0\u534729%\uff0cpass@1\u8fbe\u523069.1%\uff0c\u8d85\u8d8a\u4e4b\u524dBaldur\u7684pass@64\uff0865.7%\uff09\uff1bpass@8\u8fbe\u523079.2%\uff0c\u8d85\u8d8a\u5f53\u524d\u6700\u4f73Magnushammer\uff0871.0%\uff09\u3002", "conclusion": "MiniLang\u663e\u8457\u63d0\u5347\u4e86NTP\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u4f18\u5316\u8bc1\u660e\u8bed\u8a00\u5bf9LLMs\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.19015", "categories": ["cs.PL", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19015", "abs": "https://arxiv.org/abs/2507.19015", "authors": ["Samuel Xifaras", "Panagiotis Manolios", "Andrew T. Walter", "William Robertson"], "title": "An Enumerative Embedding of the Python Type System in ACL2s", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Python is a high-level interpreted language that has become an industry\nstandard in a wide variety of applications. In this paper, we take a first step\ntowards using ACL2s to reason about Python code by developing an embedding of a\nsubset of the Python type system in ACL2s. The subset of Python types we\nsupport includes many of the most commonly used type annotations as well as\nuser-defined types comprised of supported types. We provide ACL2s definitions\nof these types, as well as defdata enumerators that are customized to provide\ncode coverage and identify errors in Python programs. Using the ACL2s\nembedding, we can generate instances of types that can then be used as inputs\nto fuzz Python programs, which allows us to identify bugs in Python code that\nare not detected by state-of-the-art Python type checkers. We evaluate our work\nagainst four open-source repositories, extracting their type information and\ngenerating inputs for fuzzing functions with type signatures that are in the\nsupported subset of Python types. Note that we only use the type signatures of\nfunctions to generate inputs and treat the bodies of functions as black boxes.\nWe measure code coverage, which ranges from about 68% to more than 80%, and\nidentify code patterns that hinder coverage such as complex branch conditions\nand external file system dependencies. We conclude with a discussion of the\nresults and recommendations for future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728ACL2s\u4e2d\u5d4c\u5165Python\u7c7b\u578b\u7cfb\u7edf\u5b50\u96c6\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8f93\u5165\u4ee5\u6a21\u7cca\u6d4b\u8bd5Python\u7a0b\u5e8f\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u6548\u679c\u3002", "motivation": "Python\u4f5c\u4e3a\u884c\u4e1a\u6807\u51c6\u8bed\u8a00\uff0c\u5176\u4ee3\u7801\u9a8c\u8bc1\u5de5\u5177\u4ecd\u6709\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u7c7b\u578b\u68c0\u67e5\u5668\u672a\u80fd\u68c0\u6d4b\u5230\u7684\u9519\u8bef\u3002", "method": "\u5728ACL2s\u4e2d\u5d4c\u5165Python\u7c7b\u578b\u7cfb\u7edf\u5b50\u96c6\uff0c\u751f\u6210\u7c7b\u578b\u5b9e\u4f8b\u4f5c\u4e3a\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\uff0c\u5e76\u8bc4\u4f30\u4ee3\u7801\u8986\u76d6\u7387\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u4ed3\u5e93\u4e2d\u6d4b\u8bd5\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u4e3a68%\u81f380%\uff0c\u5e76\u8bc6\u522b\u4e86\u5f71\u54cd\u8986\u76d6\u7387\u7684\u4ee3\u7801\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u672a\u6765\u5de5\u4f5c\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u8986\u76d6\u7387\u5e76\u6269\u5c55\u652f\u6301\u7684\u7c7b\u578b\u8303\u56f4\u3002"}}
{"id": "2507.19176", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.19176", "abs": "https://arxiv.org/abs/2507.19176", "authors": ["Weijun Chen", "Yuxi Fu", "Huan Long"], "title": "A Programming Language for Feasible Solutions", "comment": null, "summary": "Runtime efficiency and termination are crucial properties in the studies of\nprogram verification. Instead of dealing with these issues in an ad hoc manner,\nit would be useful to develop a robust framework in which such properties are\nguaranteed by design. This paper introduces a new imperative programming\nlanguage whose design is grounded in a static type system that ensures the\nfollowing equivalence property: All definable programs are guaranteed to run in\npolynomial time; Conversely, all problems solvable in polynomial time can be\nsolved by some programs of the language. The contribution of this work is\ntwofold. On the theoretical side, the foundational equivalence property is\nestablished, and the proof of the equivalence theorem is non-trivial. On the\npractical side, a programming approach is proposed that can streamline program\nanalysis and verification for feasible computations. An interpreter for the\nlanguage has been implemented, demonstrating the feasibility of the approach in\npractice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u547d\u4ee4\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff0c\u5176\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u786e\u4fdd\u6240\u6709\u53ef\u5b9a\u4e49\u7a0b\u5e8f\u5747\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8fd0\u884c\uff0c\u4e14\u6240\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u95ee\u9898\u5747\u53ef\u7531\u8be5\u8bed\u8a00\u5b9e\u73b0\u3002", "motivation": "\u4e3a\u89e3\u51b3\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u8fd0\u884c\u65f6\u6548\u7387\u548c\u7ec8\u6b62\u6027\u95ee\u9898\uff0c\u907f\u514d\u4e34\u65f6\u6027\u5904\u7406\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u4fdd\u8bc1\u8fd9\u4e9b\u6027\u8d28\u7684\u7a33\u5065\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u8bbe\u8ba1\u65b0\u8bed\u8a00\uff0c\u786e\u4fdd\u7a0b\u5e8f\u8fd0\u884c\u65f6\u95f4\u591a\u9879\u5f0f\u5316\uff0c\u5e76\u901a\u8fc7\u7b49\u4ef7\u6027\u5b9a\u7406\u8bc1\u660e\u5176\u5b8c\u5907\u6027\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u7b49\u4ef7\u6027\u5b9a\u7406\uff0c\u5b9e\u8df5\u4e0a\u5b9e\u73b0\u4e86\u8bed\u8a00\u89e3\u91ca\u5668\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u8bed\u8a00\u4e3a\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u9a8c\u8bc1\u548c\u7f16\u7a0b\u6846\u67b6\uff0c\u7406\u8bba\u548c\u5b9e\u8df5\u5747\u5177\u8d21\u732e\u3002"}}
{"id": "2507.18718", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2507.18718", "abs": "https://arxiv.org/abs/2507.18718", "authors": ["Ronald Fagin", "Neil Immerman", "Phokion Kolaitis", "Jonathan Lenchner", "Rik Sengupta"], "title": "Who Wins the Multi-Structural Game?", "comment": "27 pages, 7 figures", "summary": "Combinatorial games played between two players, called Spoiler and\nDuplicator, have often been used to capture syntactic properties of formal\nlogical languages. For instance, the widely used Ehrenfeucht-Fra\\\"iss\\'e (EF)\ngame captures the syntactic measure of quantifier rank of first-order formulas.\nFor every such game, there is an associated natural decision problem: \"given an\ninstance of the game, does Spoiler win the game on that instance?\" For EF\ngames, this problem was shown to be PSPACE-complete by Pezzoli in 1998. In this\npresent paper, we show that the same problem for the *multi-structural* (MS)\ngames of recent interest is PSPACE-hard, but contained in NEXPTIME. In the\nprocess, we also resolve an open problem posed by Pezzoli about the dependence\nof the hardness results for EF games on the arity of the schema under\nconsideration. Our techniques combine adaptations of Pezzoli's constructions\ntogether with insights from the theory of inapproximability of optimization\nproblems, as well as the recently developed technique of parallel play for MS\ngames.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u7ed3\u6784\uff08MS\uff09\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u4e3aPSPACE\u96be\u4f46\u5305\u542b\u4e8eNEXPTIME\u4e2d\uff0c\u5e76\u89e3\u51b3\u4e86Pezzoli\u63d0\u51fa\u7684\u5173\u4e8eEF\u6e38\u620f\u96be\u5ea6\u4e0e\u6a21\u5f0f\u57fa\u6570\u4f9d\u8d56\u7684\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u591a\u7ed3\u6784\uff08MS\uff09\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\u590d\u6742\u6027\uff0c\u4ee5\u6269\u5c55\u5bf9\u5f62\u5f0f\u903b\u8f91\u8bed\u8a00\u6e38\u620f\u7684\u7406\u89e3\uff0c\u5e76\u89e3\u51b3EF\u6e38\u620f\u7684\u76f8\u5173\u5f00\u653e\u95ee\u9898\u3002", "method": "\u7ed3\u5408Pezzoli\u7684\u6784\u9020\u65b9\u6cd5\u3001\u4f18\u5316\u95ee\u9898\u7684\u4e0d\u53ef\u8fd1\u4f3c\u6027\u7406\u8bba\u4ee5\u53caMS\u6e38\u620f\u7684\u5e76\u884c\u73a9\u6cd5\u6280\u672f\u3002", "result": "\u8bc1\u660eMS\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\u4e3aPSPACE\u96be\u4f46\u5305\u542b\u4e8eNEXPTIME\u4e2d\uff0c\u540c\u65f6\u89e3\u51b3\u4e86EF\u6e38\u620f\u6a21\u5f0f\u57fa\u6570\u4f9d\u8d56\u7684\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "MS\u6e38\u620f\u7684\u51b3\u7b56\u95ee\u9898\u590d\u6742\u6027\u4ecb\u4e8ePSPACE\u96be\u548cNEXPTIME\u4e4b\u95f4\uff0c\u4e3a\u5f62\u5f0f\u903b\u8f91\u8bed\u8a00\u6e38\u620f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.18726", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18726", "abs": "https://arxiv.org/abs/2507.18726", "authors": ["Sadia Afrin Mim"], "title": "Exploring the Landscape of Fairness Interventions in Software Engineering", "comment": null, "summary": "Current developments in AI made it broadly significant for reducing human\nlabor and expenses across several essential domains, including healthcare and\nfinance. However, the application of AI in the actual world poses multiple\nrisks and disadvantages due to potential risk factors in data (e.g., biased\ndataset). Practitioners developed a number of fairness interventions for\naddressing these kinds of problems. The paper acts as a survey, summarizing the\nvarious studies and approaches that have been developed to address fairness\nissues", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86AI\u516c\u5e73\u6027\u95ee\u9898\u53ca\u5176\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "AI\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u6570\u636e\u504f\u89c1\u7b49\u98ce\u9669\uff0c\u9700\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u603b\u7ed3\u4e86\u591a\u79cd\u516c\u5e73\u6027\u5e72\u9884\u63aa\u65bd\u7684\u7814\u7a76\u548c\u65b9\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u89e3\u51b3AI\u516c\u5e73\u6027\u95ee\u9898\u7684\u7efc\u5408\u89c6\u89d2\u3002", "conclusion": "\u516c\u5e73\u6027\u5e72\u9884\u662fAI\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.18755", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.18755", "abs": "https://arxiv.org/abs/2507.18755", "authors": ["Chandra Maddila", "Adam Tait", "Claire Chang", "Daniel Cheng", "Nauman Ahmad", "Vijayaraghavan Murali", "Marshall Roch", "Arnaud Avondet", "Aaron Meltzer", "Victor Montalvao", "Michael Hopko", "Chris Waterson", "Parth Thakkar", "Renuka Fernandez", "Kristian Kristensen", "Sivan Barzily", "Sherry Chen", "Rui Abreu", "Nachiappan Nagappan", "Payam Shodjai", "Killian Murphy", "James Everingham", "Aparna Ramani", "Peter C. Rigby"], "title": "Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback", "comment": null, "summary": "Aim: With the advent of LLMs, sophisticated agentic program repair has become\nviable at large organizations with large codebases. In this work, we develop an\nEngineering Agent that fixes the source code based on test failures at scale\nacross diverse software offerings internally.\n  Method: Using Llama as the base, we employ the ReAct harness to develop an\nagent. We start with a test failure that was triaged by a rule-based test\nfailure bot. We then set up an agentic harness and allow the agent to reason\nand run a set of 15 actions from reading a file to generating a patch. We\nprovide feedback to the agent through static analysis and test failures so it\ncan refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch\nconforms to the standards followed by a human review to land fixes.\n  Benchmark Findings: We curated offline benchmarks for our patch generator,\nthe Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we\nfound that a specialized 70B model is highly competitive with the much larger\nbut vanilla Llama-405B. In an ablation study, we found that the ReAct harness\n(neural model) benefited from the symbolic information from static analysis\ntools and test execution traces. A model that strikes a balance between the\nsolve rate and error rate vs the cost and latency has a benchmark solve rate of\n42.3% using an average 11.8 feedback iterations.\n  Production Findings: In a three month period, 80% of the generated fixes were\nreviewed, of which 31.5% were landed (25.5% of the total number of generated\nfixes).\n  Feedback from Engineers: We used open coding to extract qualitative themes\nfrom engineers' feedback. We saw positive feedback in the form of quick\napprovals, gratitude, and surprise. We also found mixed feedback when the\nEngineering Agent's solution was partially correct and it served as a good\nstarting point.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5de5\u7a0b\u4ee3\u7406\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4fee\u590d\u4ee3\u7801\u4e2d\u7684\u6d4b\u8bd5\u5931\u8d25\u95ee\u9898\uff0c\u7ed3\u5408ReAct\u6846\u67b6\u548cLLM-as-a-Judge\uff0c\u5728\u79bb\u7ebf\u8bc4\u4f30\u548c\u751f\u4ea7\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u968f\u7740LLM\u7684\u53d1\u5c55\uff0c\u5927\u578b\u7ec4\u7ec7\u53ef\u4ee5\u5229\u7528\u5176\u80fd\u529b\u8fdb\u884c\u5927\u89c4\u6a21\u7684\u4ee3\u7801\u4fee\u590d\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4ee5Llama\u4e3a\u57fa\u7840\uff0c\u4f7f\u7528ReAct\u6846\u67b6\u5f00\u53d1\u4ee3\u7406\uff0c\u901a\u8fc7\u9759\u6001\u5206\u6790\u548c\u6d4b\u8bd5\u53cd\u9988\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5229\u7528LLM-as-a-Judge\u786e\u4fdd\u4fee\u590d\u8d28\u91cf\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u4e2d\uff0c70B\u6a21\u578b\u8868\u73b0\u63a5\u8fd1405B\u6a21\u578b\uff0c\u751f\u4ea7\u73af\u5883\u4e2d31.5%\u7684\u4fee\u590d\u88ab\u91c7\u7eb3\u3002", "conclusion": "\u5de5\u7a0b\u4ee3\u7406\u5728\u4ee3\u7801\u4fee\u590d\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u90e8\u5206\u6b63\u786e\u89e3\u51b3\u65b9\u6848\u7684\u5904\u7406\u4e0a\u3002"}}
{"id": "2507.18798", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.18798", "abs": "https://arxiv.org/abs/2507.18798", "authors": ["Victor Barroso-Nascimento"], "title": "Higher-order Kripke models for intuitionistic and non-classical modal logics", "comment": null, "summary": "This paper introduces higher-order Kripke models, a generalization of\nstandard Kripke models that is remarkably close to Kripke's original idea -\nboth mathematically and conceptually. Standard Kripke models are now considered\n$0$-ary models, whereas an $n$-ary model for $n > 0$ is a model whose set of\nobjects (''possible worlds'') contains only $(n-1)$-ary Kripke models. Models\nwith infinitely many layers are also considered. This framework is obtained by\npromoting a radical change of perspective in how modal semantics for\nnon-classical logics are defined: just like classical modalities are obtained\nthrough use of an accessibility relation between classical propositional\nmodels, non-classical modalities are now obtained through use of an\naccessibility relation between non-classical propositional models (even when\nthey are Kripke models already). The paper introduces the new models after\ndealing specifically with the case of intuitionistic modal logic. It is shown\nthat, depending on which intuitionistic $0$-ary propositional models are\nallowed, we may obtain $1$-ary models equivalent to either birelational models\nfor $IK$ or for a new logic called $MK$. Those $1$-ary models have an intuitive\nreading that adds to the interpretation of intuitionistic models in terms of\n''timelines'' the concept of ''alternative timelines''. More generally, the\n$1$-ary models can be read as defining a concept of ''alternative'' for any\nsubstantive interpretation of the $0$-ary models. The semantic clauses for\nnecessity and possibility of $MK$ are also modular and can be used to obtain\nsimilar modal semantics for every non-classical logic, each of which can be\nprovided with a similar intuitive reading. After intuitionistic modal logic is\ndealt with, the general structure of High-order Kripke Models and some of its\nvariants are defined, and a series of conjectures about their properties are\nstated.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9ad8\u9636\u514b\u91cc\u666e\u514b\u6a21\u578b\uff0c\u63a8\u5e7f\u4e86\u6807\u51c6\u514b\u91cc\u666e\u514b\u6a21\u578b\uff0c\u901a\u8fc7\u5c42\u7ea7\u5316\u5b9a\u4e49\u6a21\u6001\u8bed\u4e49\uff0c\u9002\u7528\u4e8e\u975e\u7ecf\u5178\u903b\u8f91\u3002", "motivation": "\u901a\u8fc7\u5c42\u7ea7\u5316\u6a21\u578b\uff0c\u4e3a\u975e\u7ecf\u5178\u903b\u8f91\uff08\u5982\u76f4\u89c9\u4e3b\u4e49\u6a21\u6001\u903b\u8f91\uff09\u63d0\u4f9b\u66f4\u76f4\u89c2\u7684\u8bed\u4e49\u89e3\u91ca\u3002", "method": "\u5c06\u6807\u51c6\u514b\u91cc\u666e\u514b\u6a21\u578b\u89c6\u4e3a0\u9636\u6a21\u578b\uff0c\u9ad8\u9636\u6a21\u578b\u5219\u7531\u4f4e\u9636\u6a21\u578b\u6784\u6210\uff0c\u5e76\u5f15\u5165\u53ef\u8bbf\u95ee\u6027\u5173\u7cfb\u5b9a\u4e49\u6a21\u6001\u3002", "result": "\u5c55\u793a\u4e861\u9636\u6a21\u578b\u4e0e\u53cc\u5173\u7cfb\u6a21\u578b\uff08IK\uff09\u6216\u65b0\u903b\u8f91\uff08MK\uff09\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u65f6\u95f4\u7ebf\u548c\u66ff\u4ee3\u65f6\u95f4\u7ebf\u89e3\u91ca\u3002", "conclusion": "\u9ad8\u9636\u514b\u91cc\u666e\u514b\u6a21\u578b\u4e3a\u591a\u79cd\u975e\u7ecf\u5178\u903b\u8f91\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8bed\u4e49\u6846\u67b6\uff0c\u5e76\u5177\u6709\u76f4\u89c2\u7684\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.19012", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.19012", "abs": "https://arxiv.org/abs/2507.19012", "authors": ["Alessandro Coglio", "Eric McCarthy"], "title": "A Formalization of the Yul Language and Some Verified Yul Code Transformations", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Yul is an intermediate language used in the compilation of the Solidity\nprogramming language for Ethereum smart contracts. The compiler applies\ncustomizable sequences of transformations to Yul code. To help ensure the\ncorrectness of these transformations and their sequencing, we used the ACL2\ntheorem prover to develop a formalization of the syntax and semantics of Yul,\nproofs relating static and dynamic semantics, a formalization of some Yul code\ntransformations, and correctness proofs for these transformations.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Yul\u4f5c\u4e3aSolidity\u7f16\u8bd1\u4e2d\u95f4\u8bed\u8a00\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u4f7f\u7528ACL2\u5b9a\u7406\u8bc1\u660e\u5668\u786e\u4fdd\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u786e\u4fddYul\u4ee3\u7801\u8f6c\u6362\u53ca\u5176\u5e8f\u5217\u7684\u6b63\u786e\u6027\uff0c\u907f\u514d\u667a\u80fd\u5408\u7ea6\u4e2d\u7684\u6f5c\u5728\u9519\u8bef\u3002", "method": "\u4f7f\u7528ACL2\u5b9a\u7406\u8bc1\u660e\u5668\u5bf9Yul\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u5e76\u9a8c\u8bc1\u9759\u6001\u4e0e\u52a8\u6001\u8bed\u4e49\u7684\u5173\u7cfb\u53ca\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u3002", "result": "\u5f00\u53d1\u4e86Yul\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86Yul\u4ee3\u7801\u8f6c\u6362\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u667a\u80fd\u5408\u7ea6\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4fdd\u969c\u3002"}}
{"id": "2507.19008", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2507.19008", "abs": "https://arxiv.org/abs/2507.19008", "authors": ["Grant Jurgensen"], "title": "A Proof of the Schr\u00f6der-Bernstein Theorem in ACL2", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "The Schr\\\"oder-Bernstein theorem states that, for any two sets P and Q, if\nthere exists an injection from P to Q and an injection from Q to P, then there\nmust exist a bijection between the two sets. Classically, it follows that the\nordering of the cardinal numbers is antisymmetric. We describe a formulation\nand verification of the Schr\\\"oder-Bernstein theorem in ACL2 following a\nwell-known proof, introducing a theory of chains to define a non-computable\nwitness.", "AI": {"tldr": "\u5728ACL2\u4e2d\u9a8c\u8bc1Schr\u00f6der-Bernstein\u5b9a\u7406\uff0c\u901a\u8fc7\u94fe\u7406\u8bba\u5b9a\u4e49\u975e\u53ef\u8ba1\u7b97\u89c1\u8bc1\u3002", "motivation": "\u9a8c\u8bc1\u7ecf\u5178\u96c6\u5408\u8bba\u4e2d\u7684Schr\u00f6der-Bernstein\u5b9a\u7406\u5728\u5f62\u5f0f\u5316\u903b\u8f91\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u91c7\u7528\u94fe\u7406\u8bba\u5b9a\u4e49\u975e\u53ef\u8ba1\u7b97\u89c1\u8bc1\uff0c\u9075\u5faa\u5df2\u77e5\u8bc1\u660e\u8def\u5f84\u3002", "result": "\u6210\u529f\u5728ACL2\u4e2d\u9a8c\u8bc1\u4e86Schr\u00f6der-Bernstein\u5b9a\u7406\u3002", "conclusion": "\u8bc1\u660e\u4e86\u8be5\u5b9a\u7406\u5728\u5f62\u5f0f\u5316\u903b\u8f91\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u76f8\u5173\u7406\u8bba\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2507.18812", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.18812", "abs": "https://arxiv.org/abs/2507.18812", "authors": ["Yiping Jia", "Zhen Ming Jiang", "Shayan Noei", "Ying Zou"], "title": "MemoCoder: Automated Function Synthesis using LLM-Supported Agents", "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs) such as GitHub\nCopilot and ChatGPT, developers increasingly rely on AI-assisted tools to\nsupport code generation. While LLMs can generate syntactically correct\nsolutions for well-structured programming tasks, they often struggle with\nchallenges that require iterative debugging, error handling, or adaptation to\ndiverse problem structures. Existing approaches such as fine-tuning or\nself-repair strategies either require costly retraining or lack mechanisms to\naccumulate and reuse knowledge from previous attempts.\n  To address these limitations, we propose MemoCoder, a multi-agent framework\nthat enables collaborative problem solving and persistent learning from past\nfixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores\nsuccessful repairs and supports retrieval for future tasks. A central Mentor\nAgent supervises the repair process by identifying recurring error patterns and\nrefining high-level fixing strategies, providing a novel supervisory role that\nguides the self-repair loop. We evaluate MemoCoder across three public\nbenchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem\ncomplexities. Experimental results show that MemoCoder consistently outperforms\nboth zero-shot prompting and a Self-Repair strategy, with improvements ranging\nfrom 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating\nits effectiveness in iterative refinement and knowledge-guided code generation.", "AI": {"tldr": "MemoCoder\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u548c\u4ece\u8fc7\u53bb\u7684\u4fee\u590d\u4e2d\u5b66\u4e60\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u5fae\u8c03\u6216\u81ea\u6211\u4fee\u590d\u7b56\u7565\uff09\u6210\u672c\u9ad8\u6216\u7f3a\u4e4f\u77e5\u8bc6\u79ef\u7d2f\u673a\u5236\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fed\u4ee3\u8c03\u8bd5\u548c\u591a\u6837\u5316\u95ee\u9898\u7ed3\u6784\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faMemoCoder\u6846\u67b6\uff0c\u5305\u542b\u4fee\u590d\u77e5\u8bc6\u96c6\u548c\u5bfc\u5e08\u4ee3\u7406\uff0c\u652f\u6301\u534f\u4f5c\u4fee\u590d\u548c\u77e5\u8bc6\u590d\u7528\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemoCoder\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u548c\u81ea\u6211\u4fee\u590d\u7b56\u7565\uff0c\u63d0\u5347\u663e\u8457\u3002", "conclusion": "MemoCoder\u5728\u8fed\u4ee3\u4f18\u5316\u548c\u77e5\u8bc6\u5f15\u5bfc\u7684\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3aAI\u8f85\u52a9\u7f16\u7a0b\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2507.19271", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.19271", "abs": "https://arxiv.org/abs/2507.19271", "authors": ["Igli Begolli", "Meltem Aksoy", "Daniel Neider"], "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "comment": null, "summary": "Code review is essential for maintaining software quality but often\ntime-consuming and cognitively demanding, especially in industrial\nenvironments. Recent advancements in language models (LMs) have opened new\navenues for automating core review tasks. This study presents the empirical\nevaluation of monolingual fine-tuning on the performance of open-source LMs\nacross three key automated code review tasks: Code Change Quality Estimation,\nReview Comment Generation, and Code Refinement. We fine-tuned three distinct\nmodels, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific\ndataset combining public benchmarks with industrial repositories. Our study\ninvestigates how different configurations of programming languages and natural\nlanguages in the training data affect LM performance, particularly in comment\ngeneration. Additionally, we benchmark the fine-tuned models against an\nautomated software analysis tool (ASAT) and human reviewers to evaluate their\npractical utility in real-world settings. Our results show that monolingual\nfine-tuning improves model accuracy and relevance compared to multilingual\nbaselines. While LMs can effectively support code review workflows, especially\nfor routine or repetitive tasks, human reviewers remain superior in handling\nsemantically complex or context-sensitive changes. Our findings highlight the\nimportance of language alignment and task-specific adaptation in optimizing LMs\nfor automated code review.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5355\u8bed\u8a00\u5fae\u8c03\u5bf9\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u5ba1\u67e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u4f18\u4e8e\u591a\u8bed\u8a00\u57fa\u7ebf\uff0c\u4f46\u4eba\u7c7b\u5ba1\u67e5\u5458\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u4ecd\u66f4\u4f18\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8017\u65f6\u4e14\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u4e3a\u81ea\u52a8\u5316\u5ba1\u67e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "method": "\u5bf9CodeReviewer\u3001CodeLlama-7B\u548cDeepSeek-R1-Distill\u4e09\u79cd\u6a21\u578b\u5728C#\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5355\u8bed\u8a00\u5fae\u8c03\uff0c\u8bc4\u4f30\u5176\u5728\u4ee3\u7801\u53d8\u66f4\u8d28\u91cf\u4f30\u8ba1\u3001\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u548c\u4ee3\u7801\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5355\u8bed\u8a00\u5fae\u8c03\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\uff0c\u4f46\u4eba\u7c7b\u5ba1\u67e5\u5458\u5728\u8bed\u4e49\u590d\u6742\u6216\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u53d8\u66f4\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8bed\u8a00\u5bf9\u9f50\u548c\u4efb\u52a1\u7279\u5b9a\u9002\u914d\u5bf9\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u8868\u73b0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.19009", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.19009", "abs": "https://arxiv.org/abs/2507.19009", "authors": ["Carl Kwan"], "title": "RV32I in ACL2", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present a simple ACL2 simulator for the RISC-V 32-bit base instruction set\narchitecture, written in the operational semantics style. Like many other ISA\nmodels, our RISC-V state object is a single-threaded object and we prove\nread-over-write, write-over-write, writing-the-read, and state well-formedness\ntheorems. Unlike some other models, we separate the instruction decoding\nfunctions from their semantic counterparts. Accordingly, we verify encoding /\ndecoding functions for each RV32I instruction, the proofs for which are\nentirely automatic.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8eACL2\u7684RISC-V 32\u4f4d\u57fa\u7840\u6307\u4ee4\u96c6\u67b6\u6784\u6a21\u62df\u5668\uff0c\u91c7\u7528\u64cd\u4f5c\u8bed\u4e49\u98ce\u683c\u7f16\u5199\uff0c\u9a8c\u8bc1\u4e86\u72b6\u6001\u5bf9\u8c61\u7684\u591a\u9879\u5b9a\u7406\uff0c\u5e76\u5206\u79bb\u4e86\u89e3\u7801\u51fd\u6570\u4e0e\u8bed\u4e49\u51fd\u6570\u3002", "motivation": "\u4e3aRISC-V 32\u4f4d\u6307\u4ee4\u96c6\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u4e14\u53ef\u9a8c\u8bc1\u7684\u6a21\u62df\u5668\uff0c\u5f3a\u8c03\u89e3\u7801\u4e0e\u8bed\u4e49\u7684\u5206\u79bb\u4ee5\u5b9e\u73b0\u81ea\u52a8\u9a8c\u8bc1\u3002", "method": "\u4f7f\u7528ACL2\u7f16\u5199\u64cd\u4f5c\u8bed\u4e49\u98ce\u683c\u7684\u6a21\u62df\u5668\uff0c\u9a8c\u8bc1\u72b6\u6001\u5bf9\u8c61\u7684\u8bfb\u5199\u5b9a\u7406\uff0c\u5e76\u5206\u79bb\u6307\u4ee4\u89e3\u7801\u4e0e\u8bed\u4e49\u529f\u80fd\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86RV32I\u6307\u4ee4\u7684\u7f16\u7801/\u89e3\u7801\u51fd\u6570\uff0c\u6240\u6709\u8bc1\u660e\u5747\u4e3a\u81ea\u52a8\u5b8c\u6210\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u4e3aRISC-V\u6307\u4ee4\u96c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u4e14\u53ef\u9a8c\u8bc1\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u89e3\u7801\u4e0e\u8bed\u4e49\u7684\u5206\u79bb\u63d0\u9ad8\u4e86\u9a8c\u8bc1\u6548\u7387\u3002"}}
{"id": "2507.18833", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18833", "abs": "https://arxiv.org/abs/2507.18833", "authors": ["Wenyuan Jiang", "Diany Pressato", "Harsh Darji", "Thibaud Lutellier"], "title": "Exploring the Jupyter Ecosystem: An Empirical Study of Bugs and Vulnerabilities", "comment": null, "summary": "Background. Jupyter notebooks are one of the main tools used by data\nscientists. Notebooks include features (configuration scripts, markdown,\nimages, etc.) that make them challenging to analyze compared to traditional\nsoftware. As a result, existing software engineering models, tools, and studies\ndo not capture the uniqueness of Notebook's behavior. Aims. This paper aims to\nprovide a large-scale empirical study of bugs and vulnerabilities in the\nNotebook ecosystem. Method. We collected and analyzed a large dataset of\nNotebooks from two major platforms. Our methodology involved quantitative\nanalyses of notebook characteristics (such as complexity metrics, contributor\nactivity, and documentation) to identify factors correlated with bugs.\nAdditionally, we conducted a qualitative study using grounded theory to\ncategorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally,\nwe analyzed security-related commits and vulnerability reports to assess risks\nassociated with Notebook deployment frameworks. Results. Our findings highlight\nthat configuration issues are among the most common bugs in notebook documents,\nfollowed by incorrect API usage. Finally, we explore common vulnerabilities\nassociated with popular deployment frameworks to better understand risks\nassociated with Notebook development. Conclusions. This work highlights that\nnotebooks are less well-supported than traditional software, resulting in more\ncomplex code, misconfiguration, and poor maintenance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Jupyter Notebook\u4e2d\u7684\u9519\u8bef\u548c\u6f0f\u6d1e\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u9519\u8bef\u662f\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u4e86\u90e8\u7f72\u6846\u67b6\u7684\u98ce\u9669\u3002", "motivation": "\u7531\u4e8eJupyter Notebook\u7684\u72ec\u7279\u6027\uff0c\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u548c\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5206\u6790\u5176\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7814\u7a76\u5176\u9519\u8bef\u548c\u6f0f\u6d1e\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u548c\u5206\u6790\u4e24\u5927\u5e73\u53f0\u7684Notebook\u6570\u636e\uff0c\u7ed3\u5408\u5b9a\u91cf\u5206\u6790\u548c\u5b9a\u6027\u7814\u7a76\uff08\u624e\u6839\u7406\u8bba\uff09\uff0c\u5efa\u7acb\u4e86\u9519\u8bef\u5206\u7c7b\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u90e8\u7f72\u6846\u67b6\u7684\u5b89\u5168\u98ce\u9669\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u914d\u7f6e\u95ee\u9898\u548cAPI\u4f7f\u7528\u9519\u8bef\u662fNotebook\u4e2d\u6700\u5e38\u89c1\u7684\u9519\u8bef\uff0c\u540c\u65f6\u90e8\u7f72\u6846\u67b6\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "Notebook\u7684\u652f\u6301\u548c\u7ef4\u62a4\u4e0d\u5982\u4f20\u7edf\u8f6f\u4ef6\uff0c\u5bfc\u81f4\u4ee3\u7801\u590d\u6742\u3001\u914d\u7f6e\u9519\u8bef\u548c\u7ef4\u62a4\u4e0d\u5584\u3002"}}
{"id": "2507.19010", "categories": ["cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2507.19010", "abs": "https://arxiv.org/abs/2507.19010", "authors": ["Mayank Manjrekar"], "title": "On Automating Proofs of Multiplier Adder Trees using the RTL Books", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present an experimental, verified clause processor ctv-cp that fits into\nthe framework used at Arm for formal verification of arithmetic hardware\ndesigns. This largely automates the ACL2 proof development effort for integer\nmultiplier modules that exist in designs ranging from floating-point division\nto matrix multiplication.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u9a8c\u6027\u3001\u5df2\u9a8c\u8bc1\u7684\u6761\u6b3e\u5904\u7406\u5668ctv-cp\uff0c\u7528\u4e8eArm\u7684\u7b97\u672f\u786c\u4ef6\u8bbe\u8ba1\u5f62\u5f0f\u9a8c\u8bc1\u6846\u67b6\uff0c\u81ea\u52a8\u5316\u4e86\u6574\u6570\u4e58\u6cd5\u6a21\u5757\u7684ACL2\u8bc1\u660e\u5f00\u53d1\u3002", "motivation": "\u63d0\u9ad8\u6574\u6570\u4e58\u6cd5\u6a21\u5757\u5728\u786c\u4ef6\u8bbe\u8ba1\uff08\u5982\u6d6e\u70b9\u9664\u6cd5\u548c\u77e9\u9635\u4e58\u6cd5\uff09\u4e2d\u5f62\u5f0f\u9a8c\u8bc1\u7684\u6548\u7387\u3002", "method": "\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86ctv-cp\u6761\u6b3e\u5904\u7406\u5668\uff0c\u96c6\u6210\u5230Arm\u7684\u5f62\u5f0f\u9a8c\u8bc1\u6846\u67b6\u4e2d\u3002", "result": "ctv-cp\u663e\u8457\u81ea\u52a8\u5316\u4e86ACL2\u8bc1\u660e\u5f00\u53d1\u8fc7\u7a0b\u3002", "conclusion": "ctv-cp\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u7684\u5f62\u5f0f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.18957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18957", "abs": "https://arxiv.org/abs/2507.18957", "authors": ["Jianming Chang", "Jieke Shi", "Yunbo Lyu", "Xin Zhou", "Lulu Wang", "Zhou Yang", "Bixin Li", "David Lo"], "title": "SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents", "comment": null, "summary": "Static program slicing, which extracts the executable portions of a program\nthat affect the values at a specific location, supports many software analysis\ntasks such as debugging and security auditing. However, traditional slicing\ntools rely on computationally expensive reachability analysis over dependency\ngraphs, which struggle to scale to large programs and often fail to handle code\nwith incomplete syntax. Recently emerged learning-based methods, while more\nrobust to such cases, still fall short of achieving comparable performance to\ntraditional methods on well-formed code.\n  In this work, we propose SliceMate, a novel static program slicing solution\npowered by Large Language Model (LLM) agents. It bypasses the need for explicit\ndependency graph construction and achieving superior slicing accuracy.\nConcretely, SliceMate integrates three specialized agents: (1) a synthesis\nagent that produces candidate slices by incrementally expanding the scan scope\nacross functions and files guided by LLM-inferred dependencies; (2) a\nverification agent that performs conciseness and completeness checks of the\ncandidate slices, detecting missing or irrelevant statements; and (3) a\nrefinement agent that repairs the slices with minimal edits in accordance with\nthe verification results. These agents are orchestrated by a control module\nthat ensures timely convergence and outputs high-quality slices without manual\nintervention. For rigorous evaluation, we construct a new and high-quality\nbenchmark, SliceBench, comprising 2,200 manually annotated Java and Python\nprograms, with program lengths ranging from 5 to 8,577 lines, significantly\nlarger than those in existing slicing benchmarks. Experimental results show\nthat SliceMate greatly outperforms both traditional and learning-based slicing\ntools.", "AI": {"tldr": "SliceMate\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9759\u6001\u7a0b\u5e8f\u5207\u7247\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u4ee3\u7406\uff08\u5408\u6210\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\uff09\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5207\u7247\uff0c\u65e0\u9700\u663e\u5f0f\u4f9d\u8d56\u56fe\u6784\u5efa\u3002", "motivation": "\u4f20\u7edf\u5207\u7247\u5de5\u5177\u4f9d\u8d56\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u4f9d\u8d56\u56fe\u5206\u6790\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u578b\u7a0b\u5e8f\u6216\u5904\u7406\u8bed\u6cd5\u4e0d\u5b8c\u6574\u4ee3\u7801\uff1b\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4ecd\u4e0d\u53ca\u4f20\u7edf\u65b9\u6cd5\u3002", "method": "SliceMate\u96c6\u6210\u4e09\u4e2a\u4ee3\u7406\uff1a\u5408\u6210\u4ee3\u7406\u751f\u6210\u5019\u9009\u5207\u7247\uff0c\u9a8c\u8bc1\u4ee3\u7406\u68c0\u67e5\u5207\u7247\u8d28\u91cf\uff0c\u4f18\u5316\u4ee3\u7406\u4fee\u590d\u5207\u7247\u3002\u63a7\u5236\u6a21\u5757\u534f\u8c03\u4ee3\u7406\u5de5\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSliceMate\u57282,200\u4e2a\u624b\u52a8\u6807\u6ce8\u7684Java\u548cPython\u7a0b\u5e8f\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SliceMate\u901a\u8fc7LLM\u4ee3\u7406\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u9759\u6001\u7a0b\u5e8f\u5207\u7247\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002"}}
{"id": "2507.18982", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.18982", "abs": "https://arxiv.org/abs/2507.18982", "authors": ["Amir Hossain Raaj", "Fairuz Nawer Meem", "Sadia Afrin Mim"], "title": "Classifying Issues in Open-source GitHub Repositories", "comment": null, "summary": "GitHub is the most widely used platform for software maintenance in the\nopen-source community. Developers report issues on GitHub from time to time\nwhile facing difficulties. Having labels on those issues can help developers\neasily address those issues with prior knowledge of labels. However, most of\nthe GitHub repositories do not maintain regular labeling for the issues. The\ngoal of this work is to classify issues in the open-source community using ML\n\\& DNN models. There are thousands of open-source repositories on GitHub. Some\nof the repositories label their issues properly whereas some of them do not.\nWhen issues are pre-labeled, the problem-solving process and the immediate\nassignment of corresponding personnel are facilitated for the team, thereby\nexpediting the development process. In this work, we conducted an analysis of\nprominent GitHub open-source repositories. We classified the issues in some\ncommon labels which are: API, Documentation, Enhancement, Question, Easy,\nHelp-wanted, Dependency, CI, Waiting for OP's response, Test, Bug, etc. Our\nstudy shows that DNN models outperf", "AI": {"tldr": "\u8be5\u8bba\u6587\u65e8\u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5bf9GitHub\u5f00\u6e90\u793e\u533a\u4e2d\u7684\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u89e3\u51b3\u6807\u7b7e\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u4ece\u800c\u52a0\u5feb\u5f00\u53d1\u6d41\u7a0b\u3002", "motivation": "GitHub\u4e0a\u5927\u591a\u6570\u5f00\u6e90\u4ed3\u5e93\u672a\u5bf9\u95ee\u9898\u8fdb\u884c\u6807\u7b7e\u5316\uff0c\u5bfc\u81f4\u95ee\u9898\u89e3\u51b3\u6548\u7387\u4f4e\u4e0b\u3002\u901a\u8fc7\u81ea\u52a8\u5206\u7c7b\u95ee\u9898\uff0c\u53ef\u4ee5\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002", "method": "\u5206\u6790\u4e86GitHub\u4e0a\u7684\u5f00\u6e90\u4ed3\u5e93\uff0c\u4f7f\u7528ML\u548cDNN\u6a21\u578b\u5bf9\u95ee\u9898\u8fdb\u884c\u5e38\u89c1\u6807\u7b7e\u5206\u7c7b\uff08\u5982API\u3001\u6587\u6863\u3001Bug\u7b49\uff09\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cDNN\u6a21\u578b\u5728\u95ee\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u52a8\u5206\u7c7bGitHub\u95ee\u9898\u6807\u7b7e\u80fd\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0cDNN\u6a21\u578b\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.19013", "categories": ["cs.LO", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.19013", "abs": "https://arxiv.org/abs/2507.19013", "authors": ["Ankit Kumar", "Panagiotis Manolios"], "title": "A Formalization of the Correctness of the Floodsub Protocol", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "Floodsub is a simple, robust and popular peer-to-peer publish/subscribe\n(pubsub) protocol, where nodes can arbitrarily leave or join the network,\nsubscribe to or unsubscribe from topics and forward newly received messages to\nall of their neighbors, except the sender or the originating peer. To show the\ncorrectness of Floodsub, we propose its specification: Broadcastsub, in which\nimplementation details like network connections and neighbor subscriptions are\nelided. To show that Floodsub does really implement Broadcastsub, one would\nhave to show that the two systems have related infinite computations. We prove\nthis by reasoning locally about states and their successors using Well-Founded\nSimulation (WFS). In this paper, we focus on the mechanization of a proof which\nshows that Floodsub is a simulation refinement of Broadcastsub using WFS. To\nthe best of our knowledge, ours is the first mechanized refinement-based\nverification of a real world pubsub protocol.", "AI": {"tldr": "Floodsub\u662f\u4e00\u4e2a\u7b80\u5355\u3001\u5065\u58ee\u7684P2P\u53d1\u5e03/\u8ba2\u9605\u534f\u8bae\uff0c\u672c\u6587\u901a\u8fc7Well-Founded Simulation\u8bc1\u660e\u5176\u6b63\u786e\u6027\u3002", "motivation": "\u9a8c\u8bc1Floodsub\u534f\u8bae\u7684\u6b63\u786e\u6027\uff0c\u5c55\u793a\u5176\u4e0e\u62bd\u8c61\u89c4\u8303Broadcastsub\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u7528Well-Founded Simulation\uff08WFS\uff09\u8fdb\u884c\u5c40\u90e8\u72b6\u6001\u548c\u540e\u7eed\u72b6\u6001\u7684\u63a8\u7406\uff0c\u673a\u68b0\u5316\u8bc1\u660eFloodsub\u662fBroadcastsub\u7684\u6a21\u62df\u7ec6\u5316\u3002", "result": "\u6210\u529f\u673a\u68b0\u5316\u8bc1\u660e\u4e86Floodsub\u662fBroadcastsub\u7684\u6a21\u62df\u7ec6\u5316\uff0c\u9996\u6b21\u5b9e\u73b0\u771f\u5b9e\u4e16\u754c\u53d1\u5e03/\u8ba2\u9605\u534f\u8bae\u7684\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7WFS\u673a\u68b0\u5316\u9a8c\u8bc1\u4e86Floodsub\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u7c7b\u4f3c\u534f\u8bae\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2507.19027", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19027", "abs": "https://arxiv.org/abs/2507.19027", "authors": ["Aleksi Huotala", "Miikka Kuutila", "Mika M\u00e4ntyl\u00e4"], "title": "SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews", "comment": "12 pages (10 + 2 pages for references)", "summary": "Background: The use of large language models (LLMs) in the title-abstract\nscreening process of systematic reviews (SRs) has shown promising results, but\nsuffers from limited performance evaluation. Aims: Create a benchmark dataset\nto evaluate the performance of LLMs in the title-abstract screening process of\nSRs. Provide evidence whether using LLMs in title-abstract screening in\nsoftware engineering is advisable. Method: We start with 169 SR research\nartifacts and find 24 of those to be suitable for inclusion in the dataset.\nUsing the dataset we benchmark title-abstract screening using 9 LLMs. Results:\nWe present the SESR-Eval (Software Engineering Systematic Review Evaluation)\ndataset containing 34,528 labeled primary studies, sourced from 24 secondary\nstudies published in software engineering (SE) journals. Most LLMs performed\nsimilarly and the differences in screening accuracy between secondary studies\nare greater than differences between LLMs. The cost of using an LLM is\nrelatively low - less than $40 per secondary study even for the most expensive\nmodel. Conclusions: Our benchmark enables monitoring AI performance in the\nscreening task of SRs in software engineering. At present, LLMs are not yet\nrecommended for automating the title-abstract screening process, since accuracy\nvaries widely across secondary studies, and no LLM managed a high recall with\nreasonable precision. In future, we plan to investigate factors that influence\nLLM screening performance between studies.", "AI": {"tldr": "\u8bba\u6587\u521b\u5efa\u4e86\u4e00\u4e2a\u8bc4\u4f30LLMs\u5728\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u6027\u80fd\u7684\u6570\u636e\u96c6\uff0c\u53d1\u73b0LLMs\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u51c6\u786e\u6027\u5dee\u5f02\u8f83\u5927\uff0c\u76ee\u524d\u4e0d\u5efa\u8bae\u81ea\u52a8\u5316\u4f7f\u7528\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u7efc\u8ff0\u6807\u9898-\u6458\u8981\u7b5b\u9009\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u662f\u5426\u5efa\u8bae\u4f7f\u7528\u7684\u8bc1\u636e\u3002", "method": "\u4ece169\u4e2aSR\u7814\u7a76\u4e2d\u9009\u62e924\u4e2a\u6784\u5efa\u6570\u636e\u96c6\uff0c\u75289\u4e2aLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b34,528\u4e2a\u6807\u6ce8\u7814\u7a76\u7684SESR-Eval\u6570\u636e\u96c6\uff0cLLMs\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u51c6\u786e\u6027\u5dee\u5f02\u5927\uff0c\u6210\u672c\u8f83\u4f4e\u3002", "conclusion": "\u76ee\u524d\u4e0d\u5efa\u8bae\u81ea\u52a8\u5316\u4f7f\u7528LLMs\uff0c\u672a\u6765\u5c06\u7814\u7a76\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\u3002"}}
{"id": "2507.19014", "categories": ["cs.LO", "D.2.4"], "pdf": "https://arxiv.org/pdf/2507.19014", "abs": "https://arxiv.org/abs/2507.19014", "authors": ["Andrew T. Walter", "Panagiotis Manolios"], "title": "An ACL2s Interface to Z3", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "We present Lisp-Z3, an extension to the ACL2s systems programming framework\n(ASPF) that supports the use of the Z3 satisfiability modulo theories (SMT)\nsolver. Lisp-Z3 allows one to develop tools written using the full feature set\nof Common Lisp that can use both ACL2/s (either ACL2 or ACL2s) and Z3 as\nservices, combining the power of SMT and interactive theorem proving. Lisp-Z3\nis usable by anyone who would like to interact with Z3 from Common Lisp, as it\ndoes not depend on the availability of ACL2/s. We discuss the use of Lisp-Z3 in\nthree applications. The first is a Sudoku solver. The second is SeqSolve, a\nstring solver which solved a larger number of benchmark problems more quickly\nthan any other existing solver at the time of its publishing. Finally, Lisp-Z3\nwas also used in the context of hardware-in-the-loop fuzzing of wireless\nrouters, where low latency was an important goal. The latter two applications\nleveraged the ability of Lisp-Z3 to integrate Z3 with ACL2s code. We have\nfurther plans to use Lisp-Z3 inside of ACL2s to provide more powerful automated\nsupport for dependent types, and in particular more efficient generation of\ncounterexamples to properties involving dependent types. This paper describes\nthe usage and implementation of Lisp-Z3, as well as an evaluation of its use in\nthe aforementioned applications.", "AI": {"tldr": "Lisp-Z3\u662f\u4e00\u4e2a\u6269\u5c55ACL2s\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u652f\u6301\u4f7f\u7528Z3 SMT\u6c42\u89e3\u5668\uff0c\u7ed3\u5408Common Lisp\u3001ACL2/s\u548cZ3\u7684\u529f\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u7ed3\u5408SMT\u6c42\u89e3\u5668\u548c\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u7684\u4f18\u52bf\uff0c\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u5f00\u53d1\u80fd\u529b\u3002", "method": "\u901a\u8fc7Lisp-Z3\u6846\u67b6\uff0c\u5c06Z3\u4e0eACL2/s\u96c6\u6210\uff0c\u652f\u6301Common Lisp\u5f00\u53d1\u5de5\u5177\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u6570\u72ec\u6c42\u89e3\u5668\u3001\u5b57\u7b26\u4e32\u6c42\u89e3\u5668SeqSolve\u548c\u786c\u4ef6\u5728\u73af\u6a21\u7cca\u6d4b\u8bd5\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Lisp-Z3\u5c55\u793a\u4e86\u5728\u591a\u79cd\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\uff0c\u672a\u6765\u8ba1\u5212\u8fdb\u4e00\u6b65\u6269\u5c55\u5176\u5728\u4f9d\u8d56\u7c7b\u578b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.19113", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19113", "abs": "https://arxiv.org/abs/2507.19113", "authors": ["Liliana Pasquale", "Azzurra Ragone", "Emanuele Piemontese", "Armin Amiri Darban"], "title": "Exploring the Use of LLMs for Requirements Specification in an IT Consulting Company", "comment": "11 pages, 5 figures. Accepted for presentation at the Industrial\n  Innovation Track of the 33rd IEEE International Requirements Engineering\n  Conference (RE 2025), Valencia, Spain", "summary": "In practice, requirements specification remains a critical challenge. The\nknowledge necessary to generate a specification can often be fragmented across\ndiverse sources (e.g., meeting minutes, emails, and high-level product\ndescriptions), making the process cumbersome and time-consuming. In this paper,\nwe report our experience using large language models (LLMs) in an IT consulting\ncompany to automate the requirements specification process. In this company,\nrequirements are specified using a Functional Design Specification (FDS), a\ndocument that outlines the functional requirements and features of a system,\napplication, or process. We provide LLMs with a summary of the requirements\nelicitation documents and FDS templates, prompting them to generate Epic FDS\n(including high-level product descriptions) and user stories, which are\nsubsequently compiled into a complete FDS document. We compared the correctness\nand quality of the FDS generated by three state-of-the-art LLMs against those\nproduced by human analysts. Our results show that LLMs can help automate and\nstandardize the requirements specification, reducing time and human effort.\nHowever, the quality of LLM-generated FDS highly depends on inputs and often\nrequires human revision. Thus, we advocate for a synergistic approach in which\nan LLM serves as an effective drafting tool while human analysts provide the\ncritical contextual and technical oversight necessary for high-quality\nrequirements engineering (RE) documentation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u9700\u6c42\u89c4\u8303\u751f\u6210\u7684\u8fc7\u7a0b\uff0c\u7ed3\u679c\u663e\u793aLLM\u80fd\u51cf\u5c11\u65f6\u95f4\u548c\u4eba\u529b\uff0c\u4f46\u9700\u4eba\u5de5\u4fee\u8ba2\u3002", "motivation": "\u9700\u6c42\u89c4\u8303\u7684\u751f\u6210\u8fc7\u7a0b\u7e41\u7410\u4e14\u8017\u65f6\uff0c\u77e5\u8bc6\u5206\u6563\u4e8e\u591a\u79cd\u6765\u6e90\uff0c\u5e0c\u671b\u901a\u8fc7LLM\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528LLM\u57fa\u4e8e\u9700\u6c42\u6587\u6863\u548c\u6a21\u677f\u751f\u6210Epic FDS\u548c\u7528\u6237\u6545\u4e8b\uff0c\u5e76\u4e0e\u4eba\u5de5\u751f\u6210\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "LLM\u80fd\u81ea\u52a8\u5316\u5e76\u6807\u51c6\u5316\u9700\u6c42\u89c4\u8303\uff0c\u4f46\u8d28\u91cf\u4f9d\u8d56\u8f93\u5165\u4e14\u9700\u4eba\u5de5\u4fee\u8ba2\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528LLM\u4e0e\u4eba\u5de5\u534f\u540c\u7684\u65b9\u5f0f\uff0cLLM\u4f5c\u4e3a\u8d77\u8349\u5de5\u5177\uff0c\u4eba\u5de5\u63d0\u4f9b\u4e0a\u4e0b\u6587\u548c\u6280\u672f\u76d1\u7763\u3002"}}
{"id": "2507.19061", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.19061", "abs": "https://arxiv.org/abs/2507.19061", "authors": ["Alice Tarzariol", "Marco Maratea", "Mauro Vallati"], "title": "A CASP-based Solution for Traffic Signal Optimisation", "comment": "To appear in Theory and Practice of Logic Programming (TPLP),\n  Proceedings of ICLP 2025", "summary": "In the context of urban traffic control, traffic signal optimisation is the\nproblem of determining the optimal green length for each signal in a set of\ntraffic signals. The literature has effectively tackled such a problem, mostly\nwith automated planning techniques leveraging the PDDL+ language and solvers.\nHowever, such language has limitations when it comes to specifying optimisation\nstatements and computing optimal plans. In this paper, we provide an\nalternative solution to the traffic signal optimisation problem based on\nConstraint Answer Set Programming (CASP). We devise an encoding in a CASP\nlanguage, which is then solved by means of clingcon 3, a system extending the\nwell-known ASP solver clingo. We performed experiments on real historical data\nfrom the town of Huddersfield in the UK, comparing our approach to the PDDL+\nmodel that obtained the best results for the considered benchmark. The results\nshowed the potential of our approach for tackling the traffic signal\noptimisation problem and improving the solution quality of the PDDL+ plans.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7b54\u6848\u96c6\u7f16\u7a0b\uff08CASP\uff09\u7684\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u7684PDDL+\u8bed\u8a00\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u89e3\u51b3\u8d28\u91cf\u548c\u4f18\u5316\u80fd\u529b\u4e0a\u4f18\u4e8ePDDL+\u3002", "motivation": "\u4f20\u7edfPDDL+\u8bed\u8a00\u5728\u4f18\u5316\u4ea4\u901a\u4fe1\u53f7\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u6307\u5b9a\u4f18\u5316\u76ee\u6807\u548c\u8ba1\u7b97\u6700\u4f18\u65b9\u6848\u3002", "method": "\u4f7f\u7528CASP\u8bed\u8a00\u8fdb\u884c\u7f16\u7801\uff0c\u5e76\u901a\u8fc7clingcon 3\u7cfb\u7edf\u6c42\u89e3\uff0c\u5b9e\u9a8c\u57fa\u4e8e\u82f1\u56fd\u54c8\u5fb7\u65af\u83f2\u5c14\u5fb7\u9547\u7684\u5386\u53f2\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCASP\u65b9\u6cd5\u5728\u89e3\u51b3\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u95ee\u9898\u4e0a\u4f18\u4e8ePDDL+\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u3002", "conclusion": "CASP\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u514b\u670dPDDL+\u7684\u5c40\u9650\u6027\u5e76\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.19115", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19115", "abs": "https://arxiv.org/abs/2507.19115", "authors": ["Shweta Ramesh", "Joy Bose", "Hamender Singh", "A K Raghavan", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Nishrith Saini", "Ricardo Britto"], "title": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "comment": null, "summary": "Code review is one of the primary means of assuring the quality of released\nsoftware along with testing and static analysis. However, code review requires\nexperienced developers who may not always have the time to perform an in-depth\nreview of code. Thus, automating code review can help alleviate the cognitive\nburden on experienced software developers allowing them to focus on their\nprimary activities of writing code to add new features and fix bugs. In this\npaper, we describe our experience in using Large Language Models towards\nautomating the code review process in Ericsson. We describe the development of\na lightweight tool using LLMs and static program analysis. We then describe our\npreliminary experiments with experienced developers in evaluating our code\nreview tool and the encouraging results.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u7ecf\u9a8c\uff0c\u65e8\u5728\u51cf\u8f7b\u5f00\u53d1\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u662f\u4fdd\u8bc1\u8f6f\u4ef6\u8d28\u91cf\u7684\u91cd\u8981\u624b\u6bb5\uff0c\u4f46\u4f9d\u8d56\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u4e14\u8017\u65f6\u3002\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u53ef\u4ee5\u7f13\u89e3\u5f00\u53d1\u8005\u7684\u8d1f\u62c5\uff0c\u4f7f\u5176\u4e13\u6ce8\u4e8e\u7f16\u5199\u4ee3\u7801\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5de5\u5177\uff0c\u7ed3\u5408LLM\u548c\u9759\u6001\u7a0b\u5e8f\u5206\u6790\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u5de5\u5177\u5728\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u4e2d\u83b7\u5f97\u4e86\u79ef\u6781\u7684\u8bc4\u4ef7\u3002", "conclusion": "\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u3002"}}
{"id": "2507.19245", "categories": ["cs.LO", "cs.AI", "68T27, 03B70, 68Q55"], "pdf": "https://arxiv.org/pdf/2507.19245", "abs": "https://arxiv.org/abs/2507.19245", "authors": ["Faruk Alpay", "Bugra Kilictas", "Taylan Alpay"], "title": "Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory", "comment": "21 pages, 1 figure", "summary": "This paper contributes to the Alpay Algebra by demonstrating that the stable\noutcome of a self referential process, obtained by iterating a transformation\nthrough all ordinal stages, is identical to the unique equilibrium of an\nunbounded revision dialogue between a system and its environment. The analysis\ninitially elucidates how classical fixed point theorems guarantee such\nconvergence in finite settings and subsequently extends the argument to the\ntransfinite domain, relying upon well founded induction and principles of order\ntheoretic continuity.\n  Furthermore, the resulting transordinal fixed point operator is embedded into\ndependent type theory, a formalization which permits every step of the\ntransfinite iteration and its limit to be verified within a modern proof\nassistant. This procedure yields a machine checked proof that the iterative\ndialogue necessarily stabilizes and that its limit is unique. The result\nprovides a foundation for Alpay's philosophical claim of semantic convergence\nwithin the framework of constructive logic. By unifying concepts from fixed\npoint theory, game semantics, ordinal analysis, and type theory, this research\nestablishes a broadly accessible yet formally rigorous foundation for reasoning\nabout infinite self referential systems and offers practical tools for\ncertifying their convergence within computational environments.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u8fed\u4ee3\u53d8\u6362\u8bc1\u660e\u81ea\u5f15\u7528\u8fc7\u7a0b\u7684\u7a33\u5b9a\u7ed3\u679c\u4e0e\u65e0\u9650\u4fee\u8ba2\u5bf9\u8bdd\u7684\u552f\u4e00\u5747\u8861\u76f8\u540c\uff0c\u5e76\u5c06\u7ed3\u679c\u5d4c\u5165\u4f9d\u8d56\u7c7b\u578b\u7406\u8bba\uff0c\u63d0\u4f9b\u673a\u5668\u9a8c\u8bc1\u7684\u6536\u655b\u6027\u8bc1\u660e\u3002", "motivation": "\u4e3aAlpay\u4ee3\u6570\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff0c\u9a8c\u8bc1\u8bed\u4e49\u6536\u655b\u7684\u54f2\u5b66\u4e3b\u5f20\uff0c\u5e76\u4e3a\u65e0\u9650\u81ea\u5f15\u7528\u7cfb\u7edf\u7684\u63a8\u7406\u63d0\u4f9b\u5f62\u5f0f\u5316\u5de5\u5177\u3002", "method": "\u7ed3\u5408\u7ecf\u5178\u4e0d\u52a8\u70b9\u5b9a\u7406\u3001\u826f\u57fa\u5f52\u7eb3\u548c\u5e8f\u8bba\u8fde\u7eed\u6027\uff0c\u6269\u5c55\u5230\u8d85\u9650\u57df\uff0c\u5e76\u5d4c\u5165\u4f9d\u8d56\u7c7b\u578b\u7406\u8bba\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u8fed\u4ee3\u5bf9\u8bdd\u5fc5\u7136\u7a33\u5b9a\u4e14\u6781\u9650\u552f\u4e00\uff0c\u4e3a\u65e0\u9650\u81ea\u5f15\u7528\u7cfb\u7edf\u7684\u6536\u655b\u63d0\u4f9b\u4e86\u4e25\u683c\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u4e0d\u52a8\u70b9\u7406\u8bba\u3001\u6e38\u620f\u8bed\u4e49\u3001\u5e8f\u6570\u5206\u6790\u548c\u7c7b\u578b\u7406\u8bba\uff0c\u4e3a\u65e0\u9650\u81ea\u5f15\u7528\u7cfb\u7edf\u7684\u63a8\u7406\u548c\u8ba1\u7b97\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.19424", "categories": ["cs.LO", "18M05"], "pdf": "https://arxiv.org/pdf/2507.19424", "abs": "https://arxiv.org/abs/2507.19424", "authors": ["Elena Di Lavore", "Mario Rom\u00e1n", "Pawe\u0142 Soboci\u0144ski", "M\u00e1rk Sz\u00e9les"], "title": "Order in Partial Markov Categories", "comment": "20 pages, MFPS 2025", "summary": "Partial Markov categories are a recent framework for categorical probability\ntheory, providing an abstract account of partial probabilistic computation. In\nthis article, we discuss two order relations on the morphisms of a partial\nMarkov category. In particular, we prove that every partial Markov category is\ncanonically enriched over the category of preordered sets and monotone maps. We\nshow that our construction recovers several well-known order enrichments. We\nalso demonstrate that the existence of codiagonal maps (comparators) is closely\nrelated to order properties of partial Markov categories. We propose a\nsynthetic version of the Cauchy-Schwarz inequality to facilitate inequational\nreasoning in partial Markov categories. We apply this new axiom to prove that\nupdating a prior distribution with an evidence predicate increases the\nlikelihood of the evidence in the posterior.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u4e2d\u7684\u4e24\u79cd\u5e8f\u5173\u7cfb\uff0c\u8bc1\u660e\u4e86\u5176\u5177\u6709\u9884\u5e8f\u96c6\u548c\u5355\u8c03\u6620\u5c04\u7684\u8303\u7574\u5bcc\u96c6\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u67ef\u897f-\u65bd\u74e6\u8328\u4e0d\u7b49\u5f0f\u7684\u5408\u6210\u7248\u672c\u3002", "motivation": "\u7814\u7a76\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u4e2d\u7684\u5e8f\u5173\u7cfb\uff0c\u4ee5\u652f\u6301\u62bd\u8c61\u6982\u7387\u8ba1\u7b97\u7684\u4e0d\u7b49\u5f0f\u63a8\u7406\u3002", "method": "\u901a\u8fc7\u6784\u9020\u9884\u5e8f\u96c6\u548c\u5355\u8c03\u6620\u5c04\u7684\u8303\u7574\u5bcc\u96c6\u6027\uff0c\u5206\u6790\u6bd4\u8f83\u5668\uff08codiagonal maps\uff09\u4e0e\u5e8f\u6027\u8d28\u7684\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u7684\u5e8f\u5bcc\u96c6\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u67ef\u897f-\u65bd\u74e6\u8328\u4e0d\u7b49\u5f0f\u7684\u5408\u6210\u7248\u672c\u3002", "conclusion": "\u5e8f\u5bcc\u96c6\u6027\u548c\u67ef\u897f-\u65bd\u74e6\u8328\u4e0d\u7b49\u5f0f\u4e3a\u90e8\u5206\u9a6c\u5c14\u53ef\u592b\u8303\u7574\u4e2d\u7684\u4e0d\u7b49\u5f0f\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2507.19275", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19275", "abs": "https://arxiv.org/abs/2507.19275", "authors": ["Bo Wang", "Pengyang Wang", "Chong Chen", "Qi Sun", "Jieke Shi", "Chengran Yang", "Ming Deng", "Youfang Lin", "Zhou Yang", "David Lo"], "title": "Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports", "comment": null, "summary": "Mutation-based fuzzing is effective for uncovering compiler bugs, but\ndesigning high-quality mutators for modern languages with complex constructs\n(e.g., templates, macros) remains challenging. Existing methods rely heavily on\nmanual design or human-in-the-loop correction, limiting scalability and\ncross-language generalizability.\n  We present Mut4All, a fully automated, language-agnostic framework that\nsynthesizes mutators using Large Language Models (LLMs) and compiler-specific\nknowledge from bug reports. It consists of three agents: (1) a mutator\ninvention agent that identifies mutation targets and generates mutator metadata\nusing compiler-related insights; (2) a mutator implementation synthesis agent,\nfine-tuned to produce initial implementations; and (3) a mutator refinement\nagent that verifies and corrects the mutators via unit-test feedback.\n  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and\n403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these\nmutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++\ncompilers (16 new, 1 fixed). Mut4All outperforms existing methods in both\nunique crash detection and coverage, ranking first on Rust and second on C++.", "AI": {"tldr": "Mut4All\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u8bed\u8a00\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5229\u7528LLM\u548c\u7f16\u8bd1\u5668\u77e5\u8bc6\u751f\u6210\u9ad8\u8d28\u91cf\u53d8\u5f02\u5668\uff0c\u663e\u8457\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u7ed3\u6784\u590d\u6742\uff08\u5982\u6a21\u677f\u3001\u5b8f\uff09\uff0c\u73b0\u6709\u53d8\u5f02\u5668\u8bbe\u8ba1\u4f9d\u8d56\u4eba\u5de5\uff0c\u96be\u4ee5\u6269\u5c55\u548c\u8de8\u8bed\u8a00\u901a\u7528\u3002", "method": "Mut4All\u901a\u8fc7\u4e09\u4e2a\u4ee3\u7406\uff08\u53d1\u660e\u3001\u5b9e\u73b0\u5408\u6210\u3001\u4f18\u5316\uff09\u81ea\u52a8\u751f\u6210\u53d8\u5f02\u5668\uff0c\u7ed3\u5408LLM\u548c\u7f16\u8bd1\u5668\u77e5\u8bc6\u3002", "result": "\u5904\u74061000\u4e2a\u9519\u8bef\u62a5\u544a\uff0c\u751f\u6210722\u4e2a\u53d8\u5f02\u5668\uff0c\u6210\u672c\u4f4e\uff1b\u53d1\u73b062\u4e2aRust\u548c34\u4e2aC++\u7f16\u8bd1\u5668\u9519\u8bef\u3002", "conclusion": "Mut4All\u5728\u72ec\u7279\u5d29\u6e83\u68c0\u6d4b\u548c\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2507.19390", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.19390", "abs": "https://arxiv.org/abs/2507.19390", "authors": ["Altaf Allah Abbassi", "Leuson Da Silva", "Amin Nikanjam", "Foutse Khomh"], "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation", "comment": "24 pages, 3 Figures, 2 Tables", "summary": "Large Language Models (LLMs) for code generation evolve rapidly through\nfine-tuning, merging, or new model releases. However, such updates can\nintroduce regressions, not only in correctness but also in code quality and\nperformance. To address this, we present ReCatcher, a regression testing\nframework for Python code generation. ReCatcher systematically compares two\nLLMs, typically a current model and a candidate update, across three\ndimensions: logical correctness, static code quality, and execution\nperformance. We apply ReCatcher to assess regressions across three update\nscenarios, fine-tuning, merging, and model release, using CodeLlama,\nDeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with\ncross-language datasets increases syntax errors by up to 12%. Merging with\ngeneral-purpose models like Llama2 leads to regressions in correctness by up to\n18%. GPT-4o introduces regressions of up to 50% in handling missing imports\ncompared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance\ndegradation in execution time versus GPT-4o. Overall, logical correctness,\nperformance, and error handling (e.g., syntax errors and missing imports) are\nthe most regression-prone areas. Comparing ReCatcher with baseline solutions,\nit presents better and consistent accuracy across logical and performance\naspects. ReCatcher highlights the importance of systematic regression\nevaluation before adopting new models, while assisting researchers and\npractitioners in making more informed update decisions.", "AI": {"tldr": "ReCatcher\u662f\u4e00\u4e2a\u7528\u4e8ePython\u4ee3\u7801\u751f\u6210\u7684\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u903b\u8f91\u6b63\u786e\u6027\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\u6765\u8bc4\u4f30LLM\u66f4\u65b0\u4e2d\u7684\u56de\u5f52\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLM\u7684\u5feb\u901f\u66f4\u65b0\uff08\u5982\u5fae\u8c03\u3001\u5408\u5e76\u6216\u65b0\u6a21\u578b\u53d1\u5e03\uff09\uff0c\u53ef\u80fd\u5f15\u5165\u56de\u5f52\u95ee\u9898\uff0c\u5f71\u54cd\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3001\u8d28\u91cf\u548c\u6027\u80fd\u3002", "method": "ReCatcher\u7cfb\u7edf\u6bd4\u8f83\u4e24\u4e2aLLM\uff08\u5f53\u524d\u6a21\u578b\u548c\u5019\u9009\u66f4\u65b0\uff09\u5728\u903b\u8f91\u6b63\u786e\u6027\u3001\u9759\u6001\u4ee3\u7801\u8d28\u91cf\u548c\u6267\u884c\u6027\u80fd\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5fae\u8c03\u3001\u5408\u5e76\u548c\u65b0\u6a21\u578b\u53d1\u5e03\u5747\u53ef\u80fd\u5bfc\u81f4\u4e0d\u540c\u7a0b\u5ea6\u7684\u56de\u5f52\u95ee\u9898\uff0c\u5982\u8bed\u6cd5\u9519\u8bef\u589e\u52a0\u3001\u6b63\u786e\u6027\u4e0b\u964d\u6216\u6027\u80fd\u9000\u5316\u3002", "conclusion": "ReCatcher\u5728\u903b\u8f91\u548c\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u7cfb\u7edf\u56de\u5f52\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e2e\u52a9\u7528\u6237\u505a\u51fa\u66f4\u660e\u667a\u7684\u66f4\u65b0\u51b3\u7b56\u3002"}}
{"id": "2507.19403", "categories": ["cs.SE", "cs.AI", "cs.DC", "B.8.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2507.19403", "abs": "https://arxiv.org/abs/2507.19403", "authors": ["Matthias Wei\u00df", "Falk Dettinger", "Michael Weyrich"], "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions", "comment": "7 pages, 5 figures", "summary": "Connected and software-defined vehicles promise to offer a broad range of\nservices and advanced functions to customers, aiming to increase passenger\ncomfort and support autonomous driving capabilities. Due to the high\nreliability and availability requirements of connected vehicles, it is crucial\nto resolve any occurring failures quickly. To achieve this however, a complex\ncloud/edge architecture with a mesh of dependencies must be navigated to\ndiagnose the responsible root cause. As such, manual analyses become unfeasible\nsince they would significantly delay the troubleshooting.\n  To address this challenge, this paper presents SDVDiag, an extensible\nplatform for the automated diagnosis of connected vehicle functions. The\nplatform enables the creation of pipelines that cover all steps from initial\ndata collection to the tracing of potential root causes. In addition, SDVDiag\nsupports self-adaptive behavior by the ability to exchange modules at runtime.\nDependencies between functions are detected and continuously updated, resulting\nin a dynamic graph view of the system. In addition, vital system metrics are\nmonitored for anomalies. Whenever an incident is investigated, a snapshot of\nthe graph is taken and augmented by relevant anomalies. Finally, the analysis\nis performed by traversing the graph and creating a ranking of the most likely\ncauses.\n  To evaluate the platform, it is deployed inside an 5G test fleet environment\nfor connected vehicle functions. The results show that injected faults can be\ndetected reliably. As such, the platform offers the potential to gain new\ninsights and reduce downtime by identifying problems and their causes at an\nearly stage.", "AI": {"tldr": "SDVDiag\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u5e73\u53f0\uff0c\u7528\u4e8e\u81ea\u52a8\u8bca\u65ad\u8054\u7f51\u8f66\u8f86\u529f\u80fd\uff0c\u901a\u8fc7\u52a8\u6001\u4f9d\u8d56\u56fe\u548c\u5f02\u5e38\u76d1\u63a7\u5feb\u901f\u5b9a\u4f4d\u6545\u969c\u6839\u6e90\u3002", "motivation": "\u8054\u7f51\u8f66\u8f86\u7684\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u8981\u6c42\u9700\u8981\u5feb\u901f\u89e3\u51b3\u6545\u969c\uff0c\u4f46\u590d\u6742\u7684\u4e91/\u8fb9\u7f18\u67b6\u6784\u548c\u4f9d\u8d56\u5173\u7cfb\u4f7f\u624b\u52a8\u5206\u6790\u4e0d\u53ef\u884c\u3002", "method": "SDVDiag\u5e73\u53f0\u652f\u6301\u4ece\u6570\u636e\u6536\u96c6\u5230\u6839\u56e0\u8ffd\u8e2a\u7684\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u52a8\u6001\u66f4\u65b0\u4f9d\u8d56\u56fe\u5e76\u76d1\u63a7\u5f02\u5e38\uff0c\u901a\u8fc7\u56fe\u904d\u5386\u751f\u6210\u6700\u53ef\u80fd\u539f\u56e0\u7684\u6392\u540d\u3002", "result": "\u57285G\u6d4b\u8bd5\u8f66\u961f\u73af\u5883\u4e2d\uff0cSDVDiag\u53ef\u9760\u68c0\u6d4b\u6ce8\u5165\u7684\u6545\u969c\uff0c\u6709\u671b\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u5e76\u63d0\u524d\u53d1\u73b0\u95ee\u9898\u3002", "conclusion": "SDVDiag\u4e3a\u8054\u7f51\u8f66\u8f86\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u9ad8\u6548\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u7ef4\u62a4\u6548\u7387\u3002"}}
{"id": "2507.19432", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.19432", "abs": "https://arxiv.org/abs/2507.19432", "authors": ["Sheikh Shadab Towqir", "Fei He", "Todd Mytkowicz", "Na Meng"], "title": "Resolving Build Conflicts via Example-Based and Rule-Based Program Transformations", "comment": null, "summary": "Merge conflicts often arise when developers integrate changes from different\nsoftware branches. The conflicts can result from overlapping edits in programs\n(i.e., textual conflicts) or cause build and test errors (i.e., build and test\nconflicts). They degrade software quality and hinder programmer productivity.\nWhile several tools detect build conflicts, few offer meaningful support for\nresolving cases like those caused by method removal. To overcome limitations of\nexisting tools, we introduce BUCOR (Build Conflict Resolver), a new conflict\nresolver. BUCOR first detects conflicts by comparing three versions related to\na merging scenario: base b, left l, and right r. To resolve conflicts, it\nemploys two complementary strategies: example-based transformation (BUCOR-E)\nand rule-based transformation (BUCOR-R). BUCOR-R applies predefined rules to\nhandle common, well-understood conflicts. BUCOR-E mines branch versions (l and\nr) for exemplar edits applied to fix related build errors. From these examples,\nit infers and generalizes program transformation patterns to resolve more\ncomplex conflicts.\n  We evaluated BUCOR on 88 real-world build conflicts spanning 21 distinct\nconflict types. BUCOR generated at least one solution for 65 cases and\ncorrectly resolved 43 conflicts. We observed that this hybrid\napproach--combining context-aware, example-based learning with structured,\nrule-based resolution--can effectively help resolve conflicts. Our research\nsheds light on future directions for more intelligent and automated merge\ntools.", "AI": {"tldr": "BUCOR\u662f\u4e00\u79cd\u65b0\u7684\u6784\u5efa\u51b2\u7a81\u89e3\u51b3\u5de5\u5177\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u793a\u4f8b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5408\u5e76\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u5408\u5e76\u51b2\u7a81\uff08\u5305\u62ec\u6587\u672c\u51b2\u7a81\u548c\u6784\u5efa/\u6d4b\u8bd5\u51b2\u7a81\uff09\u4f1a\u964d\u4f4e\u8f6f\u4ef6\u8d28\u91cf\u548c\u5f00\u53d1\u6548\u7387\uff0c\u73b0\u6709\u5de5\u5177\u5bf9\u6b64\u652f\u6301\u4e0d\u8db3\u3002", "method": "BUCOR\u901a\u8fc7\u6bd4\u8f83\u57fa\u7840\u7248\u672c\u3001\u5de6\u5206\u652f\u548c\u53f3\u5206\u652f\u68c0\u6d4b\u51b2\u7a81\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u793a\u4f8b\uff08BUCOR-E\uff09\u548c\u57fa\u4e8e\u89c4\u5219\uff08BUCOR-R\uff09\u7684\u4e24\u79cd\u7b56\u7565\u89e3\u51b3\u51b2\u7a81\u3002", "result": "\u572888\u4e2a\u771f\u5b9e\u6784\u5efa\u51b2\u7a81\u4e2d\uff0cBUCOR\u4e3a65\u4e2a\u6848\u4f8b\u751f\u6210\u81f3\u5c11\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6b63\u786e\u89e3\u51b3\u4e8643\u4e2a\u51b2\u7a81\u3002", "conclusion": "\u6df7\u5408\u65b9\u6cd5\uff08\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u793a\u4f8b\u5b66\u4e60\u548c\u7ed3\u6784\u5316\u89c4\u5219\uff09\u80fd\u6709\u6548\u89e3\u51b3\u51b2\u7a81\uff0c\u4e3a\u672a\u6765\u66f4\u667a\u80fd\u7684\u5408\u5e76\u5de5\u5177\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.19446", "categories": ["cs.SE", "cs.DC", "B.8.2; C.2.4"], "pdf": "https://arxiv.org/pdf/2507.19446", "abs": "https://arxiv.org/abs/2507.19446", "authors": ["Matthias Wei\u00df", "Anish Navalgund", "Johannes St\u00fcmpfle", "Falk Dettinger", "Michael Weyrich"], "title": "An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles", "comment": "7 pages, 5 figures", "summary": "Software-defined vehicles (SDVs) offer a wide range of connected\nfunctionalities, including enhanced driving behavior and fleet management.\nThese features are continuously updated via over-the-air (OTA) mechanisms,\nresulting in a growing number of software versions and variants due to the\ndiversity of vehicles, cloud/edge environments, and stakeholders involved. The\nlack of a unified integration environment further complicates development, as\nconnected mobility solutions are often built in isolation. To ensure reliable\noperations across heterogeneous systems, a dynamic orchestration of functions\nthat considers hardware and software variability is essential. This paper\npresents an open-source CI/CD pipeline tailored for SDVs. It automates the\nbuild, test, and deployment phases using a combination of containerized\nopen-source tools, creating a standardized, portable, and scalable ecosystem\naccessible to all stakeholders. Additionally, a custom OTA middleware\ndistributes software updates and supports rollbacks across vehicles and backend\nservices. Update variants are derived based on deployment target dependencies\nand hardware configurations. The pipeline also supports continuous development\nand deployment of AI models for autonomous driving features. Its effectiveness\nis evaluated using an automated valet parking (AVP) scenario involving\nTurtleBots and a coordinating backend server. Two object detection variants are\ndeveloped and deployed to match hardware-specific requirements. Results\ndemonstrate seamless OTA updates, correct variant selection, and successful\norchestration across all targets. Overall, the proposed pipeline provides a\nscalable and efficient solution for managing software variants and OTA updates\nin SDVs, contributing to the advancement of future mobility technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\uff08SDV\uff09\u7684\u5f00\u6e90CI/CD\u6d41\u6c34\u7ebf\uff0c\u652f\u6301\u81ea\u52a8\u5316\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\uff0c\u5e76\u901a\u8fc7\u5b9a\u5236OTA\u4e2d\u95f4\u4ef6\u7ba1\u7406\u8f6f\u4ef6\u66f4\u65b0\u548c\u56de\u6eda\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "SDV\u7684\u8f6f\u4ef6\u7248\u672c\u548c\u53d8\u4f53\u56e0\u8f66\u8f86\u3001\u4e91/\u8fb9\u7f18\u73af\u5883\u548c\u5229\u76ca\u76f8\u5173\u8005\u7684\u591a\u6837\u6027\u800c\u4e0d\u65ad\u589e\u52a0\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u96c6\u6210\u73af\u5883\uff0c\u9700\u8981\u52a8\u6001\u7f16\u6392\u529f\u80fd\u4ee5\u786e\u4fdd\u5f02\u6784\u7cfb\u7edf\u7684\u53ef\u9760\u8fd0\u884c\u3002", "method": "\u91c7\u7528\u5bb9\u5668\u5316\u5f00\u6e90\u5de5\u5177\u6784\u5efa\u6807\u51c6\u5316\u3001\u53ef\u79fb\u690d\u548c\u53ef\u6269\u5c55\u7684CI/CD\u6d41\u6c34\u7ebf\uff0c\u652f\u6301AI\u6a21\u578b\u7684\u6301\u7eed\u5f00\u53d1\u548c\u90e8\u7f72\uff0c\u5e76\u901a\u8fc7\u5b9a\u5236OTA\u4e2d\u95f4\u4ef6\u5206\u53d1\u66f4\u65b0\u548c\u56de\u6eda\u3002", "result": "\u5728\u81ea\u52a8\u4ee3\u5ba2\u6cca\u8f66\uff08AVP\uff09\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6d41\u6c34\u7ebf\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u65e0\u7f1dOTA\u66f4\u65b0\u3001\u6b63\u786e\u7684\u53d8\u4f53\u9009\u62e9\u548c\u8de8\u76ee\u6807\u7f16\u6392\u3002", "conclusion": "\u8be5\u6d41\u6c34\u7ebf\u4e3aSDV\u7684\u8f6f\u4ef6\u53d8\u4f53\u548cOTA\u66f4\u65b0\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u672a\u6765\u79fb\u52a8\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
