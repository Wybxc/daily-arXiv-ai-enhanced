<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.SE](#cs.SE) [Total: 21]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [VerilogMonkey: Exploring Parallel Scaling for Automated Verilog Code Generation with LLMs](https://arxiv.org/abs/2509.16246)
*Juxin Niu,Yuxin Du,Dan Niu,Xi Wang,Zhe Jiang,Nan Guan*

Main category: cs.PL

TL;DR: VerilogMonkey是一个关于Verilog自动生成任务中并行扩展的实证研究，发现扩展到数百个样本在时间和成本上都是高效的，且无需额外增强方法就能超越先前基于LLM的Verilog生成结果。


<details>
  <summary>Details</summary>
Motivation: 研究并行扩展在自动化Verilog生成这一研究不足的任务中的效果，探索如何通过并行采样多个输出来提升LLM性能。

Method: 在多个基准测试和主流LLM上进行实验，通过并行采样数百个样本来评估并行扩展的效果，并分析LLM输出随机性对其有效性的影响。

Result: 研究发现扩展到数百个样本在时间和金钱上都是成本效益高的，即使没有任何额外的后训练或代理方法，也能超越先前基于LLM的Verilog生成结果。

Conclusion: 并行扩展是提升LLM在Verilog生成任务中性能的有效方法，LLM输出随机性对并行扩展效果有重要影响。

Abstract: We present VerilogMonkey, an empirical study of parallel scaling for the
under-explored task of automated Verilog generation. Parallel scaling improves
LLM performance by sampling many outputs in parallel. Across multiple
benchmarks and mainstream LLMs, we find that scaling to hundreds of samples is
cost-effective in both time and money and, even without any additional
enhancements such as post-training or agentic methods, surpasses prior results
on LLM-based Verilog generation. We further dissect why parallel scaling
delivers these gains and show how output randomness in LLMs affects its
effectiveness.

</details>


### [2] [GraphMend: Code Transformations for Fixing Graph Breaks in PyTorch 2](https://arxiv.org/abs/2509.16248)
*Savini Kashmira,Jayanaka Dantanarayana,Thamirawaran Sathiyalogeswaran,Yichao Yuan,Nishil Talati,Krisztian Flautner,Lingjia Tang,Jason Mars*

Main category: cs.PL

TL;DR: GraphMend是一个高级编译器，通过代码转换消除PyTorch 2程序中的FX图中断问题，提升编译优化效果和性能


<details>
  <summary>Details</summary>
Motivation: PyTorch 2的TorchDynamo和TorchInductor虽然支持即时图编译，但动态控制流和不支持的Python构造会导致模型被分割成多个FX图，造成频繁回退到eager模式、CPU-GPU同步开销和优化机会减少

Method: 基于Jac编译框架，GraphMend在代码执行前进行分析和转换，引入两种代码转换技术来消除动态控制流和Python I/O函数导致的图中断

Result: 在8个Hugging Face模型上评估，GraphMend消除了所有可修复的图中断，6个模型中断数降为0，另一个模型从5降至2。在RTX 3090和A40 GPU上实现最高75%延迟降低和8%端到端吞吐量提升

Conclusion: 高级代码转换是PyTorch动态JIT编译管道的有效补充，显著提升了可用性和性能

Abstract: This paper presents GraphMend, a high-level compiler that eliminates FX graph
breaks in PyTorch 2 programs. Although PyTorch 2 introduced TorchDynamo and
TorchInductor to enable just-in-time graph compilation, unresolved dynamic
control flow and unsupported Python constructs often fragment models into
multiple FX graphs. These fragments force frequent fallbacks to eager mode,
incur costly CPU-to-GPU synchronizations, and reduce optimization
opportunities. GraphMend addresses this limitation by analyzing and
transforming source code before execution. Built on the Jac compilation
framework, GraphMend introduces two code transformations that remove graph
breaks due to dynamic control flow and Python I/O functions. This design allows
PyTorch's compilation pipeline to capture larger, uninterrupted FX graphs
without requiring manual refactoring by developers. Evaluation across eight
Hugging Face models shows that GraphMend removes all fixable graph breaks due
to dynamic control flow and Python I/O functions, driving the break count to 0
in 6 models and reducing it from 5 to 2 in another model. On NVIDIA RTX 3090
and A40 GPUs, GraphMend achieves up to 75% latency reductions and up to 8%
higher end-to-end throughput. These results demonstrate that high-level code
transformation is an effective complement to PyTorch's dynamic JIT compilation
pipeline, substantially improving both usability and performance.

</details>


### [3] [Efficient Linearizability Monitoring](https://arxiv.org/abs/2509.17795)
*Parosh Aziz Abdulla,Samuel Grahn,Bengt Jonsson,Shankaranarayanan Krishna,Om Swostik Mishra*

Main category: cs.PL

TL;DR: 本文重新审视了监控并发栈、队列、集合和多集线性化性的基本问题，提出了更高效的监控算法，并发现了现有工具的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有监控线性化性的方法存在时间复杂度高（立方级）和正确性问题（缺乏证明、证明错误或算法错误），需要开发更高效且正确性可验证的算法。

Method: 针对栈、队列和（多）集合分别设计了时间复杂度为O(n²)、O(n log n)和O(n)的监控算法，其中n是操作数量。算法基于数据独立性假设，并提供了详细的正确性证明。

Result: 实现了栈和队列算法的工具LiMo，实验评估表明LiMo在效率和可扩展性上都优于现有工具Violin。

Conclusion: 本文提出的新算法在保证正确性的同时显著提高了监控效率，解决了现有方法存在的问题，为并发数据结构的线性化性验证提供了更可靠的解决方案。

Abstract: This paper revisits the fundamental problem of monitoring the linearizability
of concurrent stacks, queues, sets, and multisets. Given a history of a library
implementing one of these abstract data types, the monitoring problem is to
answer whether the given history is linearizable. For stacks, queues, and
(multi)sets, we present monitoring algorithms with complexities
$\mathcal{O}(n^2)$, $\mathcal{O}(n\; log\, n)$, and $\mathcal{O}{(n)}$,
respectively, where $n$ is the number of operations in the input history. For
stacks and queues, our results hold under the standard assumption of {\it
data-independence}, i.e., the behavior of the library is not sensitive to the
actual values stored in the data structure. Past works to solve the same
problems have cubic time complexity and (more seriously) have correctness
issues: they either (i) lack correctness proofs or (ii) the suggested
correctness proofs are erroneous (we present counter-examples), or (iii) have
incorrect algorithms. Our improved complexity results rely on substantially
different algorithms for which we provide detailed proofs of correctness. We
have implemented our stack and queue algorithms in LiMo (Linearizability
Monitor). We evaluate LiMo and compare it with the state-of-the-art tool Violin
-- whose correctness proofs we have found errors in -- which checks for
linearizability violations. Our experimental evaluation confirms that LiMo
outperforms Violin regarding both efficiency and scalability.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [4] [The hereditariness problem for the Černý conjecture](https://arxiv.org/abs/2509.17992)
*Emanuele Rodaro,Riccardo Venturi*

Main category: cs.FL

TL;DR: 本文研究了Černý猜想的提升问题，证明了只需验证三类特定重置自动机（根式、简单和拟简单）即可将猜想的有效性从商自动机转移到原自动机。


<details>
  <summary>Details</summary>
Motivation: 解决Černý猜想在自动机之间的提升问题，即验证商自动机满足猜想时原自动机是否也满足。

Method: 通过在转移幺半群的同余格和理想格之间建立Galois连接，计算根式理想并获得结构洞察。

Result: 证明了对于简单或拟简单自动机，转移幺半群具有覆盖常数映射最小理想的唯一理想；类似结果对根式自动机也成立。

Conclusion: 虽然完全解仍开放，但证明了只需验证三类特定自动机即可解决提升问题，为Černý猜想研究提供了新途径。

Abstract: This paper addresses the lifting problem for the \v{C}ern\'y conjecture:
namely, whether the validity of the conjecture for a quotient automaton can
always be transferred (or "lifted") to the original automaton. Although a
complete solution remains open, we show that it is sufficient to verify the
\v{C}ern\'y conjecture for three specific subclasses of reset automata:
radical, simple, and quasi-simple. Our approach relies on establishing a Galois
connection between the lattices of congruences and ideals of the transition
monoid. This connection not only serves as the main tool in our proofs but also
provides a systematic method for computing the radical ideal and for deriving
structural insights about these classes. In particular, we show that for every
simple or quasi-simple automaton $\mathcal{A}$, the transition monoid
$\text{M}(\mathcal{A})$ possesses a unique ideal covering the minimal ideal of
constant (reset) maps; a result of similar flavor holds for the class of
radical automata.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [5] [Compositional Interface Refinement Through Subtyping in Probabilistic Session Types](https://arxiv.org/abs/2509.16228)
*Paula Blechschmidt*

Main category: cs.LO

TL;DR: 本文提出了多概率混合选择多方会话类型（MCMP）的扩展框架，引入了一种新颖的灵活子类型系统，允许一个通道被多个通道替代，从而支持逐步细化和组合验证。


<details>
  <summary>Details</summary>
Motivation: 随着分布式协议复杂度的增加，需要组合建模来可扩展地验证其行为。经典MPST系统中的子类型本质上表示一种细化概念，本文旨在显著扩展这一概念，探索子类型关系的灵活性和表达能力。

Method: 提出了概率混合选择多方会话π演算的扩展，基于强大的MCMP变体构建系统，建立了概率混合选择多方会话系统的可靠性，证明了主题约简、无错误和无死锁等关键结果。

Result: 开发出的子类型系统具有显著表达能力，任何良好类型的通道选择作为细化都有对应的单通道类型接口。确保了良好类型进程的良好行为。

Conclusion: 这项工作展示了子类型在逐步细化和组合验证方面具有巨大潜力，提出的框架能够实现高度表达性、组合性和可验证的概率分布式通信建模。

Abstract: Multiparty session types (MPST) are a robust typing framework that ensures
safe and deadlock-free communication within distributed protocols. As these
protocols grow in complexity, compositional modelling becomes increasingly
important to scalably verify their behaviour. Therefore, we propose using a
refinement-based subtyping approach to facilitate the modularity needed for
compositional verification. Subtyping in classic MPST systems inherently
represents a notion of refinement: A larger type may be safely substituted by a
smaller, refined type. The aim of this thesis is to significantly extend this
concept and discover just how flexible and expressive subtyping relations can
be. We present a probabilistic extension for MPST, the probabilistic mixed
choice multiparty session pi-calculus, with a novel, flexible subtyping system
which allows one channel (the interface) to be substituted by several channels
(the refinement). Our subtyping is remarkably expressive; any selection of
well-typed channels as the refinement has a corresponding interface in a single
channel type. To facilitate this generality, we base our system on a powerful
variant of MPST, mixed choice multiparty session types (MCMP), which offers
greater flexibility in communication choices. We establish soundness of the
probabilistic mixed choice multiparty session system through several key
results. In particular, we prove subject reduction, error-freedom and
deadlock-freedom, ensuring that well-typed processes are well-behaved. This
work demonstrates subtyping to possess great previously untapped potential for
stepwise refinement and compositional verification. The presented framework
enables highly expressive, compositional, and verifiable modelling of
probabilistic distributed communication.

</details>


### [6] [parSAT: Parallel Solving of Floating-Point Satisfiability](https://arxiv.org/abs/2509.16237)
*Markus Krahl,Matthias Güdemann,Stefan Wallentowitz*

Main category: cs.LO

TL;DR: 本文提出了一种基于并行执行的浮点约束求解方法，通过结合全局优化和现代多核CPU的并行处理能力，构建了专门针对浮点算术的基于组合的半决策程序。


<details>
  <summary>Details</summary>
Motivation: 当前SMT求解器在处理非线性算术问题，特别是涉及浮点运算的问题时存在局限性，这对需要精确可靠浮点计算的安全关键应用构成了重大挑战。

Method: 采用浮点计算的替代满足性公式化方法，结合全局优化方法和现代多核CPU的并行执行，构建基于组合的半决策程序。

Result: 通过对各种基准测试的评估，证明了该方法在补充传统方法方面的潜力。

Conclusion: 提出的并行浮点约束求解方法能够有效解决传统SMT求解器在处理浮点算术时的局限性，为安全关键应用提供了更可靠的验证手段。

Abstract: Satisfiability-based verification techniques, leveraging modern Boolean
satisfiability (SAT) and Satisfiability Modulo Theories (SMT) solvers, have
demonstrated efficacy in addressing practical problem instances within program
analysis. However, current SMT solver implementations often encounter
limitations when addressing non-linear arithmetic problems, particularly those
involving floating point (FP) operations. This poses a significant challenge
for safety critical applications, where accurate and reliable calculations
based on FP numbers and elementary mathematical functions are essential.
  This paper shows how an alternative formulation of the satisfiability problem
for FP calculations allows for exploiting parallelism for FP constraint
solving. By combining global optimization approaches with parallel execution on
modern multi-core CPUs, we construct a portfolio-based semi-decision procedure
specifically tailored to handle FP arithmetic. We demonstrate the potential of
this approach to complement conventional methods through the evaluation of
various benchmarks.

</details>


### [7] [Gödel Mirror: A Formal System For Contradiction-Driven Recursion](https://arxiv.org/abs/2509.16239)
*Jhet Chan*

Main category: cs.LO

TL;DR: Gödel Mirror是一个在Lean 4中定义的形式系统，将矛盾作为递归结构演化的控制信号，利用自指悖论作为确定性转换，实现矛盾到结构的转化。


<details>
  <summary>Details</summary>
Motivation: 受哥德尔自指启发，旨在构建一个能够将矛盾代谢为结构的形式系统，为能够解决内部不一致性的智能体提供形式基础。

Method: 在Lean 4中实现的操作语义，将符号悖论编码为确定性转换，通过控制非终止循环作为生产性特征，实现悖论→封装→重入→节点的推理循环。

Result: Lean 4机械化证明自指悖论被确定性封装并解析为新结构，不会导致逻辑爆炸，形成准一致性推理循环。

Conclusion: 该演算开启了一类新的符号系统，其中矛盾被代谢为结构，为具有内部不一致性解决能力的智能体提供了形式基础。

Abstract: We introduce the G\"odel Mirror, a formal system defined in Lean 4 that
treats contradiction as a control signal for recursive structural evolution.
  Inspired by G\"odelian self-reference, our system's operational semantics
encode symbolic paradoxes as deterministic transitions. Unlike systems designed
to guarantee normalization, the G\"odel Mirror is a minimal and verifiable
architecture that leverages a controlled, non-terminating loop as a productive
feature.
  Our Lean 4 mechanization proves that self-referential paradoxes are
deterministically encapsulated and resolved into new structures without leading
to logical explosion, yielding a paraconsistent inference loop: Paradox ->
Encapsulate -> Reenter -> Node
  We argue that this calculus opens a new class of symbolic systems in which
contradiction is metabolized into structure, providing a formal basis for
agents capable of resolving internal inconsistencies.

</details>


### [8] [Equivalence of Halting Problem to Convergence of Power Series](https://arxiv.org/abs/2509.16270)
*Antonio Joaquim Fernandes*

Main category: cs.LO

TL;DR: 本文建立了可计算性理论中的停机问题与数学分析中幂级数收敛性的等价关系


<details>
  <summary>Details</summary>
Motivation: 探索计算理论与分析数学之间的深层联系，寻找不同数学分支之间的统一性

Method: 通过形式化证明建立停机问题与幂级数收敛性之间的等价关系

Result: 成功证明了这两个看似不相关的数学概念在本质上等价

Conclusion: 这一发现揭示了计算理论与分析数学之间的深刻联系，为跨学科研究提供了新的视角

Abstract: This paper establishes an equivalence between the halting problem in
computability theory and the convergence of power series in mathematical
analysis.

</details>


### [9] [Adhesive category theory for graph rewriting in Rocq](https://arxiv.org/abs/2509.17392)
*Samuel Arsac,Russ Harmer,Damien Pous*

Main category: cs.LO

TL;DR: 本文设计了一个关于粘合范畴的Rocq库，使用Hierarchy Builder构建了两个层次结构：范畴层次和态射层次，并实现了范畴图重写理论中的两个核心定理。


<details>
  <summary>Details</summary>
Motivation: 动机是构建一个形式化的粘合范畴库，为范畴图重写理论提供数学基础，并验证Hierarchy Builder在形式化数学中的实用性。

Method: 使用Hierarchy Builder构建两个层次结构：范畴层次（从普通范畴到粘合范畴）和态射层次（同构、单态射等），实现基本范畴概念和粘合范畴特定结果。

Result: 成功形式化了Church-Rosser定理和并发定理，提供了多个实例（类型范畴、有限类型范畴、简单图范畴等），并验证了HB在形式化工作中的有效性。

Conclusion: 该库为范畴图重写理论提供了坚实的形式化基础，证明了Hierarchy Builder在复杂数学结构形式化中的实用价值。

Abstract: We design a Rocq library about adhesive categories, using Hierarchy Builder
(HB). It is built around two hierarchies. The first is for categories, with
usual categories at the bottom and adhesive categories at the top, with weaker
variants of adhesive categories in between. The second is for morphisms
(notably isomorphisms, monomorphisms and regular monomorphisms). Each level of
these hierarchies is equipped with several interfaces to define instances. We
cover basic categorical concepts such as pullbacks and equalizers, as well as
results specific to adhesive categories. Using this library, we formalize two
central theorems of categorical graph rewriting theory: the Church-Rosser
theorem and the concurrency theorem. We provide several instances, including
the category of types, the category of finite types, the category of simple
graphs and categories of presheaves. We detail the implementation choices we
made and report on the usage of HB for this formalization work.

</details>


### [10] [The Proof-Theoretic Origin of Double Negation Introduction & Elimination](https://arxiv.org/abs/2509.17623)
*Khashayar Irani*

Main category: cs.LO

TL;DR: 本文探讨了经典逻辑中双重否定引入（DNI）和双重否定消除（DNE）的证明论基础，通过分析序列演算和自然演绎，表明这些规则源于归谬法（RAA），并证明它们具有和谐性和规范化特性。


<details>
  <summary>Details</summary>
Motivation: 研究双重否定规则在经典逻辑中的证明论基础，揭示它们如何确保归谬法在逻辑系统中的稳定整合，而非简单的冗余。

Method: 通过分析序列演算和自然演绎系统，考察双重否定引入和消除规则的起源及其与归谬法的关系。

Result: 证明双重否定规则具有和谐性（引入与消除之间的平衡）和规范化（推导可简化为规范形式），表明双重否定是保证证明论稳定性的机制。

Conclusion: 双重否定不是冗余，而是确保归谬法在经典逻辑中有纪律整合的证明论稳定性机制。

Abstract: This paper investigates the proof-theoretic foundations of double negation
introduction (DNI) and double negation elimination (DNE) in classical logic. By
examining both sequent calculus and natural deduction, it is shown that these
rules originate in reductio ad absurdum. The paper demonstrates that both rules
possess harmony, ensuring balance between introduction and elimination, and
normalisation, which guarantees that derivations reduce to canonical form
without detours. These features reveal double negation not as a redundancy, but
as a mechanism of proof-theoretic stability, securing the disciplined
integration of RAA into classical logic.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [11] [Digging Into the Internal: Causality-Based Analysis of LLM Function Calling](https://arxiv.org/abs/2509.16268)
*Zhenlan Ji,Daoyuan Wu,Wenxuan Wang,Pingchuan Ma,Shuai Wang,Lei Ma*

Main category: cs.SE

TL;DR: 本文通过因果分析方法研究函数调用（FC）在大型语言模型（LLMs）中的工作机制，发现FC不仅能促进模型与外部系统交互，还能显著增强模型对用户指令的遵从性。实验表明FC在恶意输入检测方面比传统提示方法平均提升135%的性能。


<details>
  <summary>Details</summary>
Motivation: 函数调用技术虽然已被广泛应用于LLMs与外部系统的交互，但其对模型行为的影响机制尚未得到充分研究。作者发现FC除了常规用途外，还能显著提高LLMs对用户指令的遵从性，这促使他们采用因果分析方法深入探究FC的工作机制。

Method: 采用层级别和令牌级别的因果干预方法，剖析FC在模型响应查询时的内部计算逻辑。通过大量实验比较基于FC的指令与传统提示方法的有效性，重点关注LLM安全鲁棒性这一关键应用场景。

Result: 因果分析确认了FC的显著影响，并揭示了其工作机制的多个深入见解。在四个主流LLMs和两个基准数据集上的实验显示，FC在检测恶意输入方面比传统提示方法平均性能提升约135%。

Conclusion: FC技术显示出增强LLMs在实际应用中可靠性和能力的巨大潜力，特别是在安全鲁棒性方面表现突出，为理解FC工作机制提供了新的分析视角。

Abstract: Function calling (FC) has emerged as a powerful technique for facilitating
large language models (LLMs) to interact with external systems and perform
structured tasks. However, the mechanisms through which it influences model
behavior remain largely under-explored. Besides, we discover that in addition
to the regular usage of FC, this technique can substantially enhance the
compliance of LLMs with user instructions. These observations motivate us to
leverage causality, a canonical analysis method, to investigate how FC works
within LLMs. In particular, we conduct layer-level and token-level causal
interventions to dissect FC's impact on the model's internal computational
logic when responding to user queries. Our analysis confirms the substantial
influence of FC and reveals several in-depth insights into its mechanisms. To
further validate our findings, we conduct extensive experiments comparing the
effectiveness of FC-based instructions against conventional prompting methods.
We focus on enhancing LLM safety robustness, a critical LLM application
scenario, and evaluate four mainstream LLMs across two benchmark datasets. The
results are striking: FC shows an average performance improvement of around
135% over conventional prompting methods in detecting malicious inputs,
demonstrating its promising potential to enhance LLM reliability and capability
in practical applications.

</details>


### [12] [Constrained Co-evolutionary Metamorphic Differential Testing for Autonomous Systems with an Interpretability Approach](https://arxiv.org/abs/2509.16478)
*Hossein Yousefizadeh,Shenghui Gu,Lionel C. Briand,Ali Nasr*

Main category: cs.SE

TL;DR: CoCoMagic是一种结合蜕变测试、差异测试和搜索技术的自动化测试用例生成方法，用于检测自动驾驶系统不同版本间的行为差异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统频繁更新可能导致意外行为退化，但系统级测试面临场景空间大、缺乏可靠测试预言等挑战。

Method: 将测试生成建模为约束协同协同进化搜索，同时进化源场景和蜕变扰动，最大化版本间蜕变关系违反差异。使用约束和种群初始化策略确保场景真实性和相关性。

Result: 在Carla模拟器中测试InterFuser系统，相比基线方法识别出287%更多的高严重性行为差异，同时保持场景真实性。

Conclusion: CoCoMagic为进化中的自主系统提供高效、有效且可解释的差异测试方法，支持针对性调试和安全评估。

Abstract: Autonomous systems, such as autonomous driving systems, evolve rapidly
through frequent updates, risking unintended behavioral degradations. Effective
system-level testing is challenging due to the vast scenario space, the absence
of reliable test oracles, and the need for practically applicable and
interpretable test cases. We present CoCoMagic, a novel automated test case
generation method that combines metamorphic testing, differential testing, and
advanced search-based techniques to identify behavioral divergences between
versions of autonomous systems. CoCoMagic formulates test generation as a
constrained cooperative co-evolutionary search, evolving both source scenarios
and metamorphic perturbations to maximize differences in violations of
predefined metamorphic relations across versions. Constraints and population
initialization strategies guide the search toward realistic, relevant
scenarios. An integrated interpretability approach aids in diagnosing the root
causes of divergences. We evaluate CoCoMagic on an end-to-end ADS, InterFuser,
within the Carla virtual simulator. Results show significant improvements over
baseline search methods, identifying up to 287\% more distinct high-severity
behavioral differences while maintaining scenario realism. The interpretability
approach provides actionable insights for developers, supporting targeted
debugging and safety assessment. CoCoMagic offers an efficient, effective, and
interpretable way for the differential testing of evolving autonomous systems
across versions.

</details>


### [13] [Causal Fuzzing for Verifying Machine Unlearning](https://arxiv.org/abs/2509.16525)
*Anna Mazhar,Sainyam Galhotra*

Main category: cs.SE

TL;DR: 提出了CAFÉ框架，基于因果关系的黑盒机器学习模型验证方法，用于数据点和特征级别的遗忘验证，能够检测基线方法遗漏的残余影响


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地嵌入决策系统，针对特定数据或特征的'遗忘'能力对于提高模型适应性、公平性和隐私保护至关重要，而现有验证方法在间接影响场景下效果有限

Method: CAFÉ框架通过因果依赖关系评估遗忘目标的直接和间接影响，为黑盒ML模型提供细粒度分析和可操作的见解

Result: 在五个数据集和三种模型架构上的评估表明，CAFÉ成功检测出基线方法遗漏的残余影响，同时保持计算效率

Conclusion: CAFÉ框架为机器遗忘验证提供了更全面的因果分析方法，能够有效识别直接和间接影响，具有实际应用价值

Abstract: As machine learning models become increasingly embedded in decision-making
systems, the ability to "unlearn" targeted data or features is crucial for
enhancing model adaptability, fairness, and privacy in models which involves
expensive training. To effectively guide machine unlearning, a thorough testing
is essential. Existing methods for verification of machine unlearning provide
limited insights, often failing in scenarios where the influence is indirect.
In this work, we propose CAF\'E, a new causality based framework that unifies
datapoint- and feature-level unlearning for verification of black-box ML
models. CAF\'E evaluates both direct and indirect effects of unlearning targets
through causal dependencies, providing actionable insights with fine-grained
analysis. Our evaluation across five datasets and three model architectures
demonstrates that CAF\'E successfully detects residual influence missed by
baselines while maintaining computational efficiency.

</details>


### [14] [Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing](https://arxiv.org/abs/2509.16595)
*Jiaming Ye,Xiongfei Wu,Shangzhou Xia,Fuyuan Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: 本文分析了量子程序测试中基于测量的验证方法的局限性，并将其与基于状态向量的验证方法进行比较，发现前者适用于简单验证，后者更适合复杂任务。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，确保量子程序质量变得至关重要。现有的大多数量子程序测试方法依赖基于测量的验证，但由于量子程序的概率特性，这些方法存在显著局限性。

Method: 通过对近期量子程序测试研究进行实证分析，将基于测量的验证方法分为分布级验证和输出值级验证两类，并与基于状态向量的验证方法进行比较。

Result: 研究发现基于测量的验证适用于简单评估（如验证特定输出值的存在），而基于状态向量的验证在评估复杂程序行为方面更有效。

Conclusion: 量子程序测试需要根据任务复杂度选择合适的验证方法，基于测量的验证适合简单任务，而基于状态向量的验证更适合复杂行为评估。

Abstract: As quantum computing continues to emerge, ensuring the quality of quantum
programs has become increasingly critical. Quantum program testing has emerged
as a prominent research area within the scope of quantum software engineering.
While numerous approaches have been proposed to address quantum program quality
assurance, our analysis reveals that most existing methods rely on
measurement-based validation in practice. However, due to the inherently
probabilistic nature of quantum programs, measurement-based validation methods
face significant limitations.
  To investigate these limitations, we conducted an empirical study of recent
research on quantum program testing, analyzing measurement-based validation
methods in the literature. Our analysis categorizes existing measurement-based
validation methods into two groups: distribution-level validation and
output-value-level validation. We then compare measurement-based validation
with statevector-based validation methods to evaluate their pros and cons. Our
findings demonstrate that measurement-based validation is suitable for
straightforward assessments, such as verifying the existence of specific output
values, while statevector-based validation proves more effective for
complicated tasks such as assessing the program behaviors.

</details>


### [15] [Incentives and Outcomes in Bug Bounties](https://arxiv.org/abs/2509.16655)
*Serena Wang,Martino Banchio,Krzysztof Kotowicz,Katrina Ligett,R. Preston McAfee,Eduardo' Vela'' Nava*

Main category: cs.SE

TL;DR: 该研究分析了谷歌漏洞奖励计划中奖励激励对漏洞报告质量和数量的影响，发现奖励金额增加200%后，高价值漏洞报告量显著增加，主要来自资深研究人员的关注转移和新研究人员的加入。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解奖励激励在漏洞奖励计划中的作用，特别是在谷歌VRP这样的大型项目中，奖励变化如何影响安全研究人员的行为和漏洞报告的质量与数量。

Method: 研究方法包括分析谷歌VRP在2024年7月奖励金额增加200%前后的数据，计算漏洞报告的弹性系数，并区分资深研究人员和新研究人员的影响。

Result: 实证结果显示，奖励增加后高价值漏洞报告量显著上升，弹性系数表明奖励对漏洞报告有积极影响，且这种增长既来自资深研究人员的关注转移，也来自新顶级安全研究人员的加入。

Conclusion: 结论是奖励激励在漏洞奖励计划中具有重要作用，提高奖励金额可以有效提升高价值漏洞的报告量，同时吸引更多优秀安全研究人员参与。

Abstract: Bug bounty programs have contributed significantly to security in technology
firms in the last decade, but little is known about the role of reward
incentives in producing useful outcomes. We analyze incentives and outcomes in
Google's Vulnerability Rewards Program (VRP), one of the world's largest bug
bounty programs. We analyze the responsiveness of the quality and quantity of
bugs received to changes in payments, focusing on a change in Google's reward
amounts posted in July, 2024, in which reward amounts increased by up to 200%
for the highest impact tier. Our empirical results show an increase in the
volume of high-value bugs received after the reward increase, for which we also
compute elasticities. We further break down the sources of this increase
between veteran researchers and new researchers, showing that the reward
increase both redirected the attention of veteran researchers and attracted new
top security researchers into the program.

</details>


### [16] [Verifying User Interfaces using SPARK Ada: A Case Study of the T34 Syringe Driver](https://arxiv.org/abs/2509.16681)
*Peterson Jean*

Main category: cs.SE

TL;DR: 本文探讨了在医疗设备开发中使用形式化验证方法（特别是SPARK Ada）来早期识别和减少人为因素风险的必要性，并以T34注射泵为例进行了案例研究。


<details>
  <summary>Details</summary>
Motivation: 医疗设备的安全性和合规性要求日益严格，但传统测试方法往往无法在开发早期发现所有人为因素风险，这可能导致在真实使用中出现灾难性后果。

Method: 研究使用SPARK Ada的形式化验证工具对T34注射泵的行为模型进行验证，探索并实现了通用输液泵模型的细化，评估了在SPARK中实现的最终原型的验证级别。

Result: 通过SPARK Ada的形式化验证，可以建立一个通用的安全集成框架，该框架可能通过数学证明来验证，从而在开发早期阶段识别和减少人为因素错误。

Conclusion: 形式化方法研究为医疗设备开发提供了新的解决方案，能够在开发早期阶段预测错误并减少其发生，但需要考虑抽象和用户界面设计组件在SPARK Ada中实现的潜在局限性。

Abstract: The increase in safety and critical systems improved Healthcare. Due to their
risk of harm, such systems are subject to stringent guidelines and compliances.
These safety measures ensure a seamless experience and mitigate the risk to
end-users. Institutions like the Food and Drug Administration and the NHS,
respectively, established international standards and competency frameworks to
ensure industry compliance with these safety concerns. Medical device
manufacturing is mainly concerned with standards. Consequently, these standards
now advocate for better human factors considered in user interaction for
medical devices. This forces manufacturers to rely on heavy testing and review
to cover many of these factors during development. Sadly, many human factor
risks will not be caught until proper testing in real life, which might be
catastrophic in the case of an ambulatory device like the T34 syringe pump.
Therefore, effort in formal methods research may propose new solutions in
anticipating these errors in the early stages of development or even reducing
their occurrence based on the use of standard generic model. These generically
developed models will provide a common framework for safety integration in
industry and may potentially be proven using formal verification mathematical
proofs. This research uses SPARK Ada's formal verification tool against a
behavioural model of the T34 syringe driver. A Generic Infusion Pump model
refinement is explored and implemented in SPARK Ada. As a subset of the Ada
language, the verification level of the end prototype is evaluated using SPARK.
Exploring potential limitations defines the proposed model's implementation
liability when considering abstraction and components of User Interface design
in SPARK Ada.

</details>


### [17] [RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code](https://arxiv.org/abs/2509.16701)
*Shunyu Liu,Guangdong Bai,Mark Utting,Guowei Yang*

Main category: cs.SE

TL;DR: RelRepair是一种通过检索项目特定代码来增强大型语言模型自动程序修复能力的新方法，在Defects4J和ManySStuBs4J数据集上显著提升了修复效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具有自动修复程序的潜力，但由于其通用预训练特性，缺乏对特定项目的理解能力，难以处理需要项目特定信息的修复任务。

Method: RelRepair首先通过分析函数名和代码注释识别相关函数签名，然后进行深度代码分析检索与修复上下文相关的代码片段，最后将这些相关信息整合到LLM的输入提示中。

Result: 在Defects4J V1.2上成功修复101个bug，在ManySStuBs4J数据集上实现了17.1%的性能提升，总体修复率达到48.3%。

Conclusion: 研究结果表明向LLM提供项目特定相关信息对于自动程序修复至关重要，为在APR任务中有效利用LLM提供了有效策略。

Abstract: Automated Program Repair (APR) has emerged as a promising paradigm for
reducing debugging time and improving the overall efficiency of software
development. Recent advances in Large Language Models (LLMs) have demonstrated
their potential for automated bug fixing and other software engineering tasks.
Nevertheless, the general-purpose nature of LLM pre-training means these models
often lack the capacity to perform project-specific repairs, which require
understanding of domain-specific identifiers, code structures, and contextual
relationships within a particular codebase. As a result, LLMs may struggle to
generate correct patches when the repair depends on project-specific
information.
  To address this limitation, we introduce RelRepair, a novel approach that
retrieves relevant project-specific code to enhance automated program repair.
RelRepair first identifies relevant function signatures by analyzing function
names and code comments within the project. It then conducts deeper code
analysis to retrieve code snippets relevant to the repair context. The
retrieved relevant information is then incorporated into the LLM's input
prompt, guiding the model to generate more accurate and informed patches. We
evaluate RelRepair on two widely studied datasets, Defects4J V1.2 and
ManySStuBs4J, and compare its performance against several state-of-the-art
LLM-based APR approaches. RelRepair successfully repairs 101 bugs in Defects4J
V1.2. Furthermore, RelRepair achieves a 17.1\% improvement in the ManySStuBs4J
dataset, increasing the overall fix rate to 48.3\%. These results highlight the
importance of providing relevant project-specific information to LLMs, shedding
light on effective strategies for leveraging LLMs in APR tasks.

</details>


### [18] [Can We Trust the AI Pair Programmer? Copilot for API Misuse Detection and Correction](https://arxiv.org/abs/2509.16795)
*Saikat Mondal,Chanchal K. Roy,Hong Wang,Juan Arguello,Samantha Mathan*

Main category: cs.SE

TL;DR: 该研究评估了GitHub Copilot在实时检测和修复API误用方面的有效性，使用MUBench基准测试，结果显示Copilot检测准确率达86.2%，成功修复超过95%的误用案例。


<details>
  <summary>Details</summary>
Motivation: API误用会导致安全漏洞、系统故障和维护成本增加，现有检测方法多为开发后检测，延迟了缺陷修复。AI代码助手如GitHub Copilot有望在开发环境中实现实时API误用检测。

Method: 使用MUBench基准构建740个误用案例和147个正确使用案例，通过Visual Studio Code中的Copilot进行分析，评估其检测准确率、精确度、召回率和修复能力。

Result: Copilot检测准确率86.2%，精确度91.2%，召回率92.4%，对常见误用类型表现良好，但对复杂或上下文相关案例有困难，成功修复超过95%的误用。

Conclusion: AI驱动的代码助手在实时检测和修复API误用方面具有潜力，Copilot可作为有前景的实时结对编程工具，但仍需改进对复杂案例的处理能力。

Abstract: API misuse introduces security vulnerabilities, system failures, and
increases maintenance costs, all of which remain critical challenges in
software development. Existing detection approaches rely on static analysis or
machine learning-based tools that operate post-development, which delays defect
resolution. Delayed defect resolution can significantly increase the cost and
complexity of maintenance and negatively impact software reliability and user
trust. AI-powered code assistants, such as GitHub Copilot, offer the potential
for real-time API misuse detection within development environments. This study
evaluates GitHub Copilot's effectiveness in identifying and correcting API
misuse using MUBench, which provides a curated benchmark of misuse cases. We
construct 740 misuse examples, manually and via AI-assisted variants, using
correct usage patterns and misuse specifications. These examples and 147
correct usage cases are analyzed using Copilot integrated in Visual Studio
Code. Copilot achieved a detection accuracy of 86.2%, precision of 91.2%, and
recall of 92.4%. It performed strongly on common misuse types (e.g.,
missing-call, null-check) but struggled with compound or context-sensitive
cases. Notably, Copilot successfully fixed over 95% of the misuses it
identified. These findings highlight both the strengths and limitations of
AI-driven coding assistants, positioning Copilot as a promising tool for
real-time pair programming and detecting and fixing API misuses during software
development.

</details>


### [19] [Implementation of the Collision Avoidance System for DO-178C Compliance](https://arxiv.org/abs/2509.16844)
*Rim Zrelli,Henrique Amaral Misson,Sorelle Kamkuimo,Maroua Ben Attia,Abdo Shabah,Felipe Gohring de Magalhaes,Gabriela Nicolescu*

Main category: cs.SE

TL;DR: 本文介绍了一个无人机防撞系统的详细实现，作为实现DO-178C合规性的案例研究，展示了在安全关键软件中应用形式化方法、模型驱动开发和自动化验证工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 为无人机安全集成到民用空域提供技术支撑，通过严格的软件开发方法实现DO-178C Design Assurance Level B的合规性要求。

Method: 结合形式化方法、模型驱动开发和自动化验证工具（Alloy、SPIN、Simulink Embedded Coder、LDRA工具套件），按照软件生命周期各阶段进行开发，重点关注需求规范验证、架构设计、编码和可追溯性。

Result: 形式化建模和自动化工具链能够早期发现和纠正规范缺陷，实现强大的可追溯性，静态和动态分析确认了代码质量和覆盖率，形式化验证方法为关键组件提供了数学正确性保证。

Conclusion: 该方法有效解决了无人机安全关键系统的认证挑战，虽然集成阶段未完全实现，但证明了其在实现DO-178C合规性方面的有效性。

Abstract: This technical report presents the detailed implementation of a Collision
Avoidance System (CAS) for Unmanned Aerial Vehicles (UAVs), developed as a case
study to demonstrate a rigorous methodology for achieving DO-178C compliance in
safety-critical software. The CAS is based on functional requirements inspired
by NASA's Access 5 project and is designed to autonomously detect, evaluate,
and avoid potential collision threats in real-time, supporting the safe
integration of UAVs into civil airspace.
  The implementation environment combines formal methods, model-based
development, and automated verification tools, including Alloy, SPIN, Simulink
Embedded Coder, and the LDRA tool suite. The report documents each phase of the
software lifecycle: requirements specification and validation, architectural
and detailed design, coding, verification, and traceability, with a strong
focus on compliance with DO-178C Design Assurance Level B objectives.
  Results demonstrate that formal modelling and automated toolchains enabled
early detection and correction of specification defects, robust traceability,
and strong evidence of verification and validation across all development
stages. Static and dynamic analyses confirmed code quality and coverage, while
formal verification methods provided mathematical assurance of correctness for
critical components. Although the integration phase was not fully implemented,
the approach proved effective in addressing certification challenges for UAV
safety-critical systems.
  \keywords Collision Avoidance System (CAS), Unmanned Aerial Vehicles (UAVs),
DO-178C compliance, Safety-critical software, Formal methods, Model-based
development, Alloy, SPIN model checker, Simulink Embedded Coder, LDRA tool
suite, Software verification and validation, Traceability, Certification.

</details>


### [20] [MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions](https://arxiv.org/abs/2509.16864)
*Wei Liu,Yi Wen Heng,Feng Lin,Tse-Hsun,Chen,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: MobileUPReg是一个黑盒框架，用于检测移动操作系统版本间的用户感知性能回归，通过比较用户可感知的性能指标（如响应时间、完成时间等）来识别真正影响用户体验的回归问题。


<details>
  <summary>Details</summary>
Motivation: 移动操作系统频繁更新可能引入性能回归，但现有检测技术依赖系统级指标或特定组件，可能错过用户实际感知的回归（如响应变慢或UI卡顿）。

Method: MobileUPReg在不同OS版本上运行相同应用，比较用户感知性能指标（响应时间、完成时间、启动时间、丢帧数）来识别回归。

Result: 在大规模研究中，MobileUPReg在提取用户感知指标方面达到高准确率，检测用户感知回归的精度为0.96，召回率为0.91，F1分数为0.93，显著优于使用Wilcoxon秩和检验和Cliff's Delta的统计基线。

Conclusion: MobileUPReg已在工业CI流水线中部署，每天分析数百个应用的数千个屏幕录像，发现了传统工具遗漏的回归，证明其能够实现准确、可扩展且与感知对齐的移动OS验证回归检测。

Abstract: Mobile operating systems (OS) are frequently updated, but such updates can
unintentionally degrade user experience by introducing performance regressions.
Existing detection techniques often rely on system-level metrics (e.g., CPU or
memory usage) or focus on specific OS components, which may miss regressions
actually perceived by users -- such as slower responses or UI stutters. To
address this gap, we present MobileUPReg, a black-box framework for detecting
user-perceived performance regressions across OS versions. MobileUPReg runs the
same apps under different OS versions and compares user-perceived performance
metrics -- response time, finish time, launch time, and dropped frames -- to
identify regressions that are truly perceptible to users. In a large-scale
study, MobileUPReg achieves high accuracy in extracting user-perceived metrics
and detects user-perceived regressions with 0.96 precision, 0.91 recall, and
0.93 F1-score -- significantly outperforming a statistical baseline using the
Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an
industrial CI pipeline, where it analyzes thousands of screencasts across
hundreds of apps daily and has uncovered regressions missed by traditional
tools. These results demonstrate that MobileUPReg enables accurate, scalable,
and perceptually aligned regression detection for mobile OS validation.

</details>


### [21] [DecipherGuard: Understanding and Deciphering Jailbreak Prompts for a Safer Deployment of Intelligent Software Systems](https://arxiv.org/abs/2509.16870)
*Rui Yang,Michael Fu,Chakkrit Tantithamthavorn,Chetan Arora,Gunel Gulmammadova,Joey Chua*

Main category: cs.SE

TL;DR: DecipherGuard是一个新型框架，通过在LlamaGuard基础上增加解密层和低秩适应机制，显著提高了LLM软件系统在运行时对抗混淆和模板化越狱攻击的防御能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的智能软件系统在关键领域部署，其运行时安全性成为重要挑战。研究发现现有最先进的LlamaGuard在混淆和模板化攻击下防御成功率下降24%，需要更有效的运行时保护机制。

Method: 提出DecipherGuard框架，集成解密层对抗混淆提示，采用低秩适应机制增强对模板化攻击的防护效果。

Result: 在22,000多个提示上的实证评估显示，相比LlamaGuard和其他两个运行时护栏，DecipherGuard将防御成功率提高36%-65%，整体护栏性能提升20%-50%。

Conclusion: DecipherGuard能有效防御LLM软件系统在运行时遭受的越狱攻击，显著提升部署安全性。

Abstract: Intelligent software systems powered by Large Language Models (LLMs) are
increasingly deployed in critical sectors, raising concerns about their safety
during runtime. Through an industry-academic collaboration when deploying an
LLM-powered virtual customer assistant, a critical software engineering
challenge emerged: how to enhance a safer deployment of LLM-powered software
systems at runtime? While LlamaGuard, the current state-of-the-art runtime
guardrail, offers protection against unsafe inputs, our study reveals a Defense
Success Rate (DSR) drop of 24% under obfuscation- and template-based jailbreak
attacks. In this paper, we propose DecipherGuard, a novel framework that
integrates a deciphering layer to counter obfuscation-based prompts and a
low-rank adaptation mechanism to enhance guardrail effectiveness against
template-based attacks. Empirical evaluation on over 22,000 prompts
demonstrates that DecipherGuard improves DSR by 36% to 65% and Overall
Guardrail Performance (OGP) by 20% to 50% compared to LlamaGuard and two other
runtime guardrails. These results highlight the effectiveness of DecipherGuard
in defending LLM-powered software systems against jailbreak attacks during
runtime.

</details>


### [22] [Deep Synthetic Cross-Project Approaches for Software Reliability Growth Modeling](https://arxiv.org/abs/2509.16939)
*Taehyoun Kim,Duksan Ryu,Jongmoon Baik*

Main category: cs.SE

TL;DR: 提出DSC-SRGM方法，通过合成数据生成和跨项目迁移学习解决数据稀缺环境下软件可靠性预测精度下降的问题


<details>
  <summary>Details</summary>
Motivation: 传统软件可靠性增长模型在数据稀缺环境（如早期测试阶段或安全关键系统）中预测精度下降，而跨项目迁移学习因真实数据集稀缺和保密性受限

Method: 使用传统SRGMs生成合成数据集保留缺陷发现趋势的统计特征，应用跨相关聚类方法识别与目标项目模式相似的合成数据集，然后用这些数据集训练深度学习模型进行可靠性预测

Result: 在60个真实数据集上评估，DSC-SRGM相比传统SRGMs预测精度提升23.3%，相比基于真实数据集的跨项目深度学习模型提升32.2%

Conclusion: DSC-SRGM是数据稀缺环境下软件可靠性预测的有前景方法，但需注意合成数据使用量和与真实数据的平衡，避免性能下降

Abstract: Software Reliability Growth Models (SRGMs) are widely used to predict
software reliability based on defect discovery data collected during testing or
operational phases. However, their predictive accuracy often degrades in
data-scarce environments, such as early-stage testing or safety-critical
systems. Although cross-project transfer learning has been explored to mitigate
this issue by leveraging data from past projects, its applicability remains
limited due to the scarcity and confidentiality of real-world datasets. To
overcome these limitations, we propose Deep Synthetic Cross-project SRGM
(DSC-SRGM), a novel approach that integrates synthetic data generation with
cross-project transfer learning. Synthetic datasets are generated using
traditional SRGMs to preserve the statistical characteristics of real-world
defect discovery trends. A cross-correlation-based clustering method is applied
to identify synthetic datasets with patterns similar to the target project.
These datasets are then used to train a deep learning model for reliability
prediction. The proposed method is evaluated on 60 real-world datasets, and its
performance is compared with both traditional SRGMs and cross-project deep
learning models trained on real-world datasets. DSC-SRGM achieves up to 23.3%
improvement in predictive accuracy over traditional SRGMs and 32.2% over
cross-project deep learning models trained on real-world datasets. However,
excessive use of synthetic data or a naive combination of synthetic and
real-world data may degrade prediction performance, highlighting the importance
of maintaining an appropriate data balance. These findings indicate that
DSC-SRGM is a promising approach for software reliability prediction in
data-scarce environments.

</details>


### [23] [SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941)
*Xiang Deng,Jeff Da,Edwin Pan,Yannis Yiming He,Charles Ide,Kanak Garg,Niklas Lauffer,Andrew Park,Nitin Pasari,Chetan Rane,Karmini Sampath,Maya Krishnan,Srivatsa Kundurthy,Sean Hendryx,Zifan Wang,Chen Bo Calvin Zhang,Noah Jacobson,Bing Liu,Brad Kenstler*

Main category: cs.SE

TL;DR: SWE-Bench Pro是一个比SWE-BENCH更具挑战性的基准测试，专门设计用于捕捉现实世界中复杂的企业级软件工程问题，包含1,865个来自41个活跃仓库的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的SWE-BENCH基准无法充分反映真实企业级软件开发的复杂性，需要创建更能代表专业软件工程挑战的测试平台。

Method: 从41个活跃仓库收集1,865个问题，分为公开集、保留集和商业集。所有任务都经过人工验证并包含足够上下文，确保可解决性。

Result: 在统一框架下评估广泛使用的编码模型，性能均低于25%（Pass@1），GPT-5达到最高分23.3%。通过聚类分析失败模式来理解模型局限性。

Conclusion: SWE-BENCH PRO提供了一个抗污染测试平台，更真实地反映了现实世界软件开发的复杂性，推动了真正自主软件工程代理的发展。

Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that
builds upon the best practices of SWE-BENCH [25], but is explicitly designed to
capture realistic, complex, enterprise-level problems beyond the scope of
SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of
41 actively maintained repositories spanning business applications, B2B
services, and developer tools. The benchmark is partitioned into a public set
with open access to problems sourced from 11 repositories, a held-out set of 12
repositories and a commercial set of 18 proprietary repositories where we have
formal partnership agreements with early-stage startups. Problems in the
held-out and the commercial set are not publicly accessible, but we release
results on the commercial set. Our benchmark features long-horizon tasks that
may require hours to days for a professional software engineer to complete,
often involving patches across multiple files and substantial code
modifications. All tasks are human-verified and augmented with sufficient
context to ensure resolvability. In our evaluation of widely used coding
models, under a unified scaffold, we observe that their performance on
SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest
score to date at 23.3%. To better understand these limitations, we cluster the
failure modes observed in the collected agent trajectories for a clearer
characterization of the error patterns exhibited by current models. Overall,
SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully
captures the complexity and diversity of real-world software development,
advancing the pursuit of truly autonomous software engineering agents at a
professional level.

</details>


### [24] [Static Security Vulnerability Scanning of Proprietary and Open-Source Software: An Adaptable Process with Variants and Results](https://arxiv.org/abs/2509.16985)
*James J. Cusick*

Main category: cs.SE

TL;DR: 本文提出了一个端到端的软件漏洞扫描和修复流程，包含支持方法和工具，用于在DevSecOps环境中系统化地检测和优先修复源代码漏洞。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞是软件开发组织实现安全目标的重要风险因素，特别是在包含专有或开源软件的技术环境中，需要建立系统化的漏洞管理流程。

Method: 提出了一个行业验证的通用流程，支持自定义实例化、配置和执行常规代码扫描，包括漏洞检测工具的选择和集成，形成迭代式DevSecOps流程。

Result: 提供了工业专有应用和开源应用的具体漏洞实例及其处理方法，展示了所选工具的优势，并介绍了替代工具选项。

Conclusion: 该方法可以最小化调整实现，灵活应用于SDLC模型，通过减少源代码漏洞、降低供应链风险和改善安全状况来提升软件安全性，未来可通过自动化和AI技术进一步增强。

Abstract: Software vulnerabilities remain a significant risk factor in achieving
security objectives within software development organizations. This is
especially true where either proprietary or open-source software (OSS) is
included in the technological environment. In this paper an end-to-end process
with supporting methods and tools is presented. This industry proven generic
process allows for the custom instantiation, configuration, and execution of
routinized code scanning for software vulnerabilities and their prioritized
remediation. A select set of tools are described for this key DevSecOps
function and placed into an iterative process. Examples of both industrial
proprietary applications and open-source applications are provided including
specific vulnerability instances and a discussion of their treatment. The
benefits of each selected tool are considered, and alternative tools are also
introduced. Application of this method in a comprehensive SDLC model is also
reviewed along with prospective enhancements from automation and the
application of advanced technologies including AI. Adoption of this method can
be achieved with minimal adjustments and with maximum flexibility for results
in reducing source code vulnerabilities, reducing supply chain risk, and
improving the security profile of new or legacy solutions.

</details>


### [25] [Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering](https://arxiv.org/abs/2509.17096)
*Ziyou Li,Agnia Sergeyuk,Maliheh Izadi*

Main category: cs.SE

TL;DR: Prompt-with-Me是一个嵌入开发环境的结构化提示管理系统，通过四维分类法自动分类提示，提供语言优化、敏感信息屏蔽和模板提取功能，提高提示的可靠性和重用性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在软件工程中的应用日益广泛，但提示管理仍处于临时状态，阻碍了可靠性、重用性和工业工作流的集成。

Method: 开发了Prompt-with-Me系统，使用四维分类法（意图、作者角色、软件开发生命周期阶段、提示类型）自动分类提示，并提供语言优化、敏感信息屏蔽和模板提取功能。通过1108个真实提示的分类研究和11名参与者的用户研究验证系统效果。

Result: 研究表明现代LLM能准确分类软件工程提示，用户研究显示高可用性（平均SUS=73）、低认知负荷（平均NASA-TLX=21），开发者报告提示质量和效率显著提升。

Conclusion: Prompt-with-Me为软件工程工作流中的提示管理和维护工具提供了可行的解决方案和建设性见解。

Abstract: Large Language Models are transforming software engineering, yet prompt
management in practice remains ad hoc, hindering reliability, reuse, and
integration into industrial workflows. We present Prompt-with-Me, a practical
solution for structured prompt management embedded directly in the development
environment. The system automatically classifies prompts using a
four-dimensional taxonomy encompassing intent, author role, software
development lifecycle stage, and prompt type. To enhance prompt reuse and
quality, Prompt-with-Me suggests language refinements, masks sensitive
information, and extracts reusable templates from a developer's prompt library.
Our taxonomy study of 1108 real-world prompts demonstrates that modern LLMs can
accurately classify software engineering prompts. Furthermore, our user study
with 11 participants shows strong developer acceptance, with high usability
(Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in
prompt quality and efficiency through reduced repetitive effort. Lastly, we
offer actionable insights for building the next generation of prompt management
and maintenance tools for software engineering workflows.

</details>


### [26] [Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs](https://arxiv.org/abs/2509.17314)
*Juyeon Yoon,Somin Kim,Robert Feldt,Shin Yoo*

Main category: cs.SE

TL;DR: CLOTHO是一种任务特定的预生成充分性度量方法，通过分析LLM隐藏状态来估计输入难度，无需生成输出即可预测模型失败概率，显著降低测试成本。


<details>
  <summary>Details</summary>
Motivation: 当前测试LLM在特定任务上的表现存在困难且成本高昂，许多提示缺乏真实标签，需要依赖人工判断，而现有不确定性度量通常需要完整推理过程。关键挑战是在生成输出前评估输入充分性。

Method: CLOTHO使用高斯混合模型(GMM)从大量未标记输入中自适应采样最具信息量的案例进行人工标注，然后基于参考集对未见输入按失败可能性进行排序。该方法直接分析LLM隐藏状态，无需生成任何输出。

Result: 在8个基准任务和3个开源LLM上的实证评估显示，CLOTHO能以0.716的ROC-AUC预测失败，参考集标注量平均仅为输入的5.4%。从开源LLM学习的充分性分数能有效迁移到专有模型，相比随机优先级排序，失败输入数量从18.7增加到42.5（每100个输入）。

Conclusion: CLOTHO提供了一种高效的预生成充分性度量方法，与后生成不确定性度量互补，显著降低了LLM测试成本，并展示了良好的模型间迁移能力。

Abstract: Software increasingly relies on the emergent capabilities of Large Language
Models (LLMs), from natural language understanding to program analysis and
generation. Yet testing them on specific tasks remains difficult and costly:
many prompts lack ground truth, forcing reliance on human judgment, while
existing uncertainty and adequacy measures typically require full inference. A
key challenge is to assess input adequacy in a way that reflects the demands of
the task, ideally before even generating any output. We introduce CLOTHO, a
task-specific, pre-generation adequacy measure that estimates input difficulty
directly from hidden LLM states. Given a large pool of unlabelled inputs for a
specific task, CLOTHO uses a Gaussian Mixture Model (GMM) to adaptively sample
the most informative cases for human labelling. Based on this reference set the
GMM can then rank unseen inputs by their likelihood of failure. In our
empirical evaluation across eight benchmark tasks and three open-weight LLMs,
CLOTHO can predict failures with a ROC-AUC of 0.716, after labelling reference
sets that are on average only 5.4% of inputs. It does so without generating any
outputs, thereby reducing costs compared to existing uncertainty measures.
Comparison of CLOTHO and post-generation uncertainty measures shows that the
two approaches complement each other. Crucially, we show that adequacy scores
learnt from open-weight LLMs transfer effectively to proprietary models,
extending the applicability of the approach. When prioritising test inputs for
proprietary models, CLOTHO increases the average number of failing inputs from
18.7 to 42.5 out of 100, compared to random prioritisation.

</details>


### [27] [BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing](https://arxiv.org/abs/2509.17335)
*Mingxuan Xiao,Yan Xiao,Shunhui Ji,Jiahe Tu,Pengcheng Zhang*

Main category: cs.SE

TL;DR: BASFuzz是一种针对基于LLM的NLP软件的模糊测试方法，通过文本一致性指标引导变异，结合束退火搜索算法，在NLG和NLU场景中显著提升测试效果并降低时间开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要挑战：1) 测试方法与基于LLM的NLP软件行为模式耦合不足；2) 在自然语言生成(NLG)测试场景中模糊测试能力普遍下降。

Method: BASFuzz针对包含提示和示例的完整测试输入，使用文本一致性指标指导模糊测试循环的变异，采用结合束搜索和模拟退火的束退火搜索算法，并引入基于信息熵的自适应调整和精英策略。

Result: 在六个NLG和自然语言理解(NLU)数据集上的实验结果表明，BASFuzz达到90.335%的测试效果，相比当前最佳基线平均减少2,163.852秒时间开销。

Conclusion: BASFuzz能够在软件部署前进行更有效的鲁棒性评估，为基于LLM的NLP软件提供高效的模糊测试解决方案。

Abstract: Fuzzing has shown great success in evaluating the robustness of intelligent
natural language processing (NLP) software. As large language model (LLM)-based
NLP software is widely deployed in critical industries, existing methods still
face two main challenges: 1 testing methods are insufficiently coupled with the
behavioral patterns of LLM-based NLP software; 2 fuzzing capability for the
testing scenario of natural language generation (NLG) generally degrades. To
address these issues, we propose BASFuzz, an efficient Fuzz testing method
tailored for LLM-based NLP software. BASFuzz targets complete test inputs
composed of prompts and examples, and uses a text consistency metric to guide
mutations of the fuzzing loop, aligning with the behavioral patterns of
LLM-based NLP software. A Beam-Annealing Search algorithm, which integrates
beam search and simulated annealing, is employed to design an efficient fuzzing
loop. In addition, information entropy-based adaptive adjustment and an elitism
strategy further enhance fuzzing capability. We evaluate BASFuzz on six
datasets in representative scenarios of NLG and natural language understanding
(NLU). Experimental results demonstrate that BASFuzz achieves a testing
effectiveness of 90.335% while reducing the average time overhead by 2,163.852
seconds compared to the current best baseline, enabling more effective
robustness evaluation prior to software deployment.

</details>


### [28] [SLICET5: Static Program Slicing using Language Models with Copy Mechanism and Constrained Decoding](https://arxiv.org/abs/2509.17338)
*Pengfei He,Shaowei Wang,Tse-Hsun Chen*

Main category: cs.SE

TL;DR: 本文提出了一种基于轻量级语言模型的静态程序切片框架，通过复制机制和约束解码解决传统方法和学习方法的依赖识别不准确和生成不受约束的问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态切片工具需要完整源代码，而学习方法存在依赖识别不准确和生成不受约束的问题，限制了在实际开发环境中的应用。

Method: 将静态程序切片重构为序列到序列任务，使用轻量级语言模型，结合复制机制和包含词汇约束与语法约束的约束解码过程。

Result: 在CodeNet和LeetCode数据集上评估，ExactMatch分数提升高达27%，在非完整代码上表现强劲。

Conclusion: 该方法在静态程序切片任务上优于现有技术，展示了在实际开发环境中的鲁棒性和实用性。

Abstract: Static program slicing is a fundamental technique in software engineering.
Traditional static slicing tools rely on parsing complete source code, which
limits their applicability to real-world scenarios where code snippets are
incomplete or unparsable. While recent research developed learning-based
approaches to predict slices, they face critical challenges: (1) Inaccurate
dependency identification, where models fail to precisely capture data and
control dependencies between code elements; and (2) Unconstrained generation,
where models produce slices with extraneous or hallucinated tokens not present
in the input, violating the structural integrity of slices. To address these
challenges, we propose \ourtool, a novel slicing framework that reformulates
static program slicing as a sequence-to-sequence task using lightweight
language models (e.g., CodeT5+). Our approach incorporates two key innovations.
First, we introduce a copy mechanism that enables the model to more accurately
capture inter-element dependencies and directly copy relevant tokens from the
input, improving both dependency reasoning and generation constraint. Second,
we design a constrained decoding process with (a) lexical constraint,
restricting outputs to input tokens only, and (b) syntactic constraint,
leveraging Tree Similarity of Edit Distance (TSED) monotonicity to detect
structurally invalid outputs and discard them. We evaluate \ourtool on CodeNet
and LeetCode datasets and show it consistently outperforms state-of-the-art
baselines, improving ExactMatch scores by up to 27\%. Furthermore, \ourtool
demonstrates strong performance on incomplete code, highlighting its robustness
and practical utility in real-world development environments.

</details>


### [29] [Prompts as Software Engineering Artifacts: A Research Agenda and Preliminary Findings](https://arxiv.org/abs/2509.17548)
*Hugo Villamizar,Jannik Fischbach,Alexander Korn,Andreas Vogelsang,Daniel Mendez*

Main category: cs.SE

TL;DR: 本文提出一个研究计划，旨在系统化地分析和管理软件工程中LLM提示的使用，包括当前实践、挑战以及提示作为软件工件的特性。


<details>
  <summary>Details</summary>
Motivation: 随着开发者越来越多地使用大型语言模型（LLM）支持软件工程任务，提示已成为重要的软件工程工件，但缺乏对其系统化开发、文档化和维护的研究。

Method: 采用探索性调查方法，对来自六个国家的74名软件专业人士进行调查，分析当前提示使用实践和挑战；并计划后续研究包括提示特性分析、演化追踪和实证评估指南。

Result: 调查发现提示在软件工程中的使用主要是临时性的：提示通常通过试错进行优化，很少被重用，更多依赖个人经验而非标准化实践。

Conclusion: 研究结果强调了需要更系统化的提示管理方法，并为后续研究阶段提供了实证基础。

Abstract: Developers now routinely interact with large language models (LLMs) to
support a range of software engineering (SE) tasks. This prominent role
positions prompts as potential SE artifacts that, like other artifacts, may
require systematic development, documentation, and maintenance. However, little
is known about how prompts are actually used and managed in LLM-integrated
workflows, what challenges practitioners face, and whether the benefits of
systematic prompt management outweigh the associated effort. To address this
gap, we propose a research programme that (a) characterizes current prompt
practices, challenges, and influencing factors in SE; (b) analyzes prompts as
software artifacts, examining their evolution, traceability, reuse, and the
trade-offs of systematic management; and (c) develops and empirically evaluates
evidence-based guidelines for managing prompts in LLM-integrated workflows. As
a first step, we conducted an exploratory survey with 74 software professionals
from six countries to investigate current prompt practices and challenges. The
findings reveal that prompt usage in SE is largely ad-hoc: prompts are often
refined through trial-and-error, rarely reused, and shaped more by individual
heuristics than standardized practices. These insights not only highlight the
need for more systematic approaches to prompt management but also provide the
empirical foundation for the subsequent stages of our research programme.

</details>


### [30] [From OCL to JSX: declarative constraint modeling in modern SaaS tools](https://arxiv.org/abs/2509.17629)
*Antonio Bucchiarone,Juri Di Rocco,Damiano Di Vincenzo,Alfonso Pierantonio*

Main category: cs.SE

TL;DR: 本文探讨了在SaaS建模环境中使用JSX作为约束表达式的替代方案，与OCL.js进行比较，发现JSX在表达能力和前端架构适配性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着Node.js和前端框架的发展，低代码开发平台兴起，但现有的OCL.js在标准覆盖、采用率和前端工具链集成方面存在不足，需要探索更适合现代建模工具的约束规范方法。

Method: 通过实证评估，在代表性建模场景中比较基于JSX的约束与OCL.js，分析JSX的声明式、功能性特性及其在React生态系统中的应用。

Result: JSX提供了更广泛的表达能力，并且更适合前端优先的架构，显示出在现代建模工具中约束规范的有前景的路径。

Conclusion: JSX作为约束表达式在SaaS建模环境中具有优势，特别是在表达能力和前端架构适配性方面，为现代建模工具提供了有希望的替代方案。

Abstract: The rise of Node.js in 2010, followed by frameworks like Angular, React, and
Vue.js, has accelerated the growth of low code development platforms. These
platforms harness modern UIX paradigms, component-based architectures, and the
SaaS model to enable non-experts to build software. The widespread adoption of
single-page applications (SPAs), driven by these frameworks, has shaped
low-code tools to deliver responsive, client side experiences. In parallel,
many modeling platforms have moved to the cloud, adopting either server-centric
architectures (e.g., GSLP) or client-side intelligence via SPA frameworks,
anchoring core components in JavaScript or TypeScript. Within this context,
OCL.js, a JavaScript-based implementation of the Object Constraint Language,
offers a web aligned approach to model validation, yet faces challenges such as
partial standard coverage, limited adoption, and weak integration with modern
front-end toolchains. In this paper, we explore JSX, a declarative, functional
subset of JavaScript/TypeScript used in the React ecosystem, as an alternative
to constraint expression in SaaS-based modeling environments. Its
component-oriented structure supports inductive definitions for syntax, code
generation, and querying. Through empirical evaluation, we compare JSX-based
constraints with OCL.js across representative modeling scenarios. Results show
JSX provides broader expressiveness and better fits front-end-first
architectures, indicating a promising path for constraint specification in
modern modeling tools.

</details>


### [31] [Diagnosing Violations of State-based Specifications in iCFTL](https://arxiv.org/abs/2509.17776)
*Cristina Stratan,Claudio Mandrioli,Domenico Bianculli*

Main category: cs.SE

TL;DR: 该论文提出了一种基于反向数据流分析的诊断方法，用于为违反iCFTL规范的软件系统生成信息丰富的诊断结果，通过程序插桩和运行时分析识别导致规范违规的相关语句。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性和动态性的增加，运行时验证技术变得至关重要。然而，当规范被违反时，传统的布尔或定量判决不足以理解违规原因，需要更信息化的诊断方法。

Method: 提出基于反向数据流分析的诊断方法，静态确定导致规范违规的相关语句，通过程序插桩生成增强的执行轨迹，在运行时分析中识别导致违规的具体语句。

Result: 原型工具iCFTL-Diagnostics在10个软件项目的112个规范上评估，90%的精确度识别相关语句，诊断违规需检查的代码行数减少至少90%，计算成本在7分钟内生成诊断，内存使用不超过25MB，插桩带来的执行时间开销低于30%，内存开销低于20%。

Conclusion: 该方法能有效生成信息丰富的诊断结果，显著减少诊断工作量，具有较低的计算开销，为复杂软件系统的运行时验证提供了实用的诊断解决方案。

Abstract: As modern software systems grow in complexity and operate in dynamic
environments, the need for runtime analysis techniques becomes a more critical
part of the verification and validation process. Runtime verification monitors
the runtime system behaviour by checking whether an execution trace - a
sequence of recorded events - satisfies a given specification, yielding a
Boolean or quantitative verdict. However, when a specification is violated,
such a verdict is often insufficient to understand why the violation happened.
To fill this gap, diagnostics approaches aim to produce more informative
verdicts. In this paper, we address the problem of generating informative
verdicts for violated Inter-procedural Control-Flow Temporal Logic (iCFTL)
specifications that express constraints over program variable values. We
propose a diagnostic approach based on backward data-flow analysis to
statically determine the relevant statements contributing to the specification
violation. Using this analysis, we instrument the program to produce enriched
execution traces. Using the enriched execution traces, we perform the runtime
analysis and identify the statements whose execution led to the specification
violation. We implemented our approach in a prototype tool, iCFTL-Diagnostics,
and evaluated it on 112 specifications across 10 software projects. Our tool
achieves 90% precision in identifying relevant statements for 100 of the 112
specifications. It reduces the number of lines that have to be inspected for
diagnosing a violation by at least 90%. In terms of computational cost,
iCFTL-Diagnostics generates a diagnosis within 7 min, and requires no more than
25 MB of memory. The instrumentation required to support diagnostics incurs an
execution time overhead of less than 30% and a memory overhead below 20%.

</details>
