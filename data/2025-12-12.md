<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 4]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 11]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Classifying covering types in homotopy type theory](https://arxiv.org/abs/2512.10064)
*Samuel Mimram,Émile Oleon*

Main category: cs.LO

TL;DR: 在同伦类型论中形式化覆盖空间与基本群子群之间的Galois对应关系，并发展n维覆盖空间理论，应用于透镜空间分类和庞加莱同调球构造。


<details>
  <summary>Details</summary>
Motivation: 覆盖空间是代数拓扑中的基本工具，与空间的基本群有密切关系（Galois对应）。特别是在同伦类型论中形式化这一对应关系，可以建立更严格的数学基础。

Method: 使用同伦类型论（Martin-Löf类型论的变体，其中类型可解释为空间）来形式化覆盖空间与基本群子群之间的对应关系，并发展n维覆盖空间的一般化理论。

Result: 成功在同伦类型论中形式化了Galois对应关系，建立了n维覆盖空间理论，并应用该理论正式分类了透镜空间的覆盖，解释了如何构造庞加莱同调球。

Conclusion: 该工作在同伦类型论中建立了覆盖空间理论的严格形式化框架，展示了该框架的实际应用价值，为代数拓扑的形式化验证提供了新工具。

Abstract: Covering spaces are a fundamental tool in algebraic topology because of the close relationship they bear with the fundamental groups of spaces. Indeed, they are in correspondence with the subgroups of the fundamental group: this is known as the Galois correspondence. In particular, the covering space corresponding to the trivial group is the universal covering, which is a "1-connected" variant of the original space, in the sense that it has the same homotopy groups, except for the first one which is trivial. In this article, we formalize this correspondence in homotopy type theory, a variant of Martin-Löf type theory in which types can be interpreted as spaces (up to homotopy). Along the way, we develop an n-dimensional generalization of covering spaces. Moreover, in order to demonstrate the applicability of our approach, we formally classify the covering of lens spaces and explain how to construct the Poincaré homology sphere.

</details>


### [2] [Translating Informal Proofs into Formal Proofs Using a Chain of States](https://arxiv.org/abs/2512.10317)
*Ziyu Wang,Bowen Yang,Shihao Zhou,Chenyi Li,Yuan Zhang,Bin Dong,Zaiwen Wen*

Main category: cs.LO

TL;DR: 提出兩階段框架將非正式數學證明轉換為Lean4形式化證明：先提取狀態鏈(CoS)對齊非正式推理結構，再生成戰術連接相鄰狀態。


<details>
  <summary>Details</summary>
Motivation: 非正式數學證明與形式化系統(如Lean4)存在差距：非正式證明使用邏輯轉換而不指定中間結果，而形式系統需要明確的證明狀態和戰術。直接生成戰術需要大量領域知識且難以控制證明上下文。

Method: 提出兩階段框架：1) 從非正式證明提取狀態鏈(CoS)，生成對齊非正式推理結構的中間形式化證明狀態序列；2) 為CoS中相鄰狀態生成戰術來連接它們，構建完整形式化證明。這種中間表示降低了戰術生成複雜度並改善與非正式推理模式的對齊。

Result: 建立了專門的數據集和基準進行訓練和評估，並引入互動式框架支持從形式狀態生成戰術。實驗結果顯示該方法顯著優於現有基線，實現了更高的證明成功率。

Conclusion: 通過引入狀態鏈作為中間表示，有效橋接了非正式數學證明與形式化系統之間的差距，降低了戰術生成的複雜性，提高了證明轉換的成功率。

Abstract: We address the problem of translating informal mathematical proofs expressed in natural language into formal proofs in Lean4 under a constrained computational budget. Our approach is grounded in two key insights. First, informal proofs tend to proceed via a sequence of logical transitions - often implications or equivalences - without explicitly specifying intermediate results or auxiliary lemmas. In contrast, formal systems like Lean require an explicit representation of each proof state and the tactics that connect them. Second, each informal reasoning step can be viewed as an abstract transformation between proof states, but identifying the corresponding formal tactics often requires nontrivial domain knowledge and precise control over proof context. To bridge this gap, we propose a two stage framework. Rather than generating formal tactics directly, we first extract a Chain of States (CoS), a sequence of intermediate formal proof states aligned with the logical structure of the informal argument. We then generate tactics to transition between adjacent states in the CoS, thereby constructing the full formal proof. This intermediate representation significantly reduces the complexity of tactic generation and improves alignment with informal reasoning patterns. We build dedicated datasets and benchmarks for training and evaluation, and introduce an interactive framework to support tactic generation from formal states. Empirical results show that our method substantially outperforms existing baselines, achieving higher proof success rates.

</details>


### [3] [Learning to Split: A Reinforcement-Learning-Guided Splitting Heuristic for Neural Network Verification](https://arxiv.org/abs/2512.10747)
*Maya Swisa,Guy Katz*

Main category: cs.LO

TL;DR: 使用强化学习从历史经验中学习分支策略，加速神经网络验证


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证器在处理分段线性激活函数（如ReLU）时，依赖分支启发式方法将复杂约束问题分解为多个简单问题。分支顺序的选择对性能影响巨大，差的选择可能导致指数级子问题，影响可扩展性。当需要对同一神经网络进行多次验证查询时，可以利用历史经验来优化分支决策。

Method: 提出基于强化学习的分支启发式方法，采用从演示中学习（DQfD）技术，利用过去的验证经验来指导分支决策，从而加速验证过程。

Result: 实验评估显示，与现有分支启发式方法相比，该方法显著减少了平均验证时间和平均迭代次数。

Conclusion: 强化学习在神经网络验证领域具有巨大潜力，能够通过历史经验学习优化分支策略，提高验证效率。

Abstract: State-of-the-art neural network verifiers operate by encoding neural
  network verification as constraint satisfaction problems. When
  dealing with standard piecewise-linear activation functions, such as
  ReLUs, verifiers typically employ branching heuristics that break a
  complex constraint satisfaction problem into multiple, simpler
  problems. The verifier's performance depends heavily on the order in
  which this branching is performed: a poor selection may give rise to
  exponentially many sub-problem, hampering scalability. Here, we
  focus on the setting where multiple verification queries must be
  solved for the same neural network. The core idea is to use past
  experience to make good branching decisions, expediting
  verification. We present a reinforcement-learning-based branching
  heuristic that achieves this, by applying a learning from
  demonstrations (DQfD) techniques. Our experimental
  evaluation demonstrates a substantial reduction in average
  verification time and in the average number of iterations required,
  compared to modern splitting heuristics. These results highlight
  the great potential of reinforcement learning in the context of
  neural network verification.

</details>


### [4] [Lax Modal Lambda Calculi](https://arxiv.org/abs/2512.10779)
*Nachiappan Valliappan*

Main category: cs.LO

TL;DR: 本文为直觉主义模态逻辑中的Lax逻辑开发了对应的类型化λ演算，为函数式编程中的强函子提供模态逻辑基础，并形式化验证了主要结果。


<details>
  <summary>Details</summary>
Motivation: 直觉主义模态逻辑中的菱形模态一直被认为不稳定和奇特，导致对应的类型理论发展滞后。本文旨在为Lax逻辑（一种具有菱形模态的奇特IML）开发类型理论，为函数式编程中的强函子提供逻辑基础。

Method: 开发了一系列对应于Lax逻辑子逻辑的类型化λ演算，提出了可能世界语义和范畴语义，构造性地证明了正规化、等式完备性和证明论不可容许性结果，并使用Agda证明助手进行了形式化验证。

Result: 成功建立了Lax逻辑子逻辑的类型理论对应物，为函数式编程中的强函子提供了模态逻辑基础，并形式化验证了所有主要理论结果。

Conclusion: 本文填补了直觉主义模态逻辑中菱形模态类型理论的空白，为函数式编程中的强函子提供了坚实的逻辑基础，并通过形式化验证确保了结果的可靠性。

Abstract: Intuitionistic modal logics (IMLs) extend intuitionistic propositional logic with modalities such as the box and diamond connectives. Advances in the study of IMLs have inspired several applications in programming languages via the development of corresponding type theories with modalities. Until recently, IMLs with diamonds have been misunderstood as somewhat peculiar and unstable, causing the development of type theories with diamonds to lag behind type theories with boxes. In this article, we develop a family of typed-lambda calculi corresponding to sublogics of a peculiar IML with diamonds known as Lax logic. These calculi provide a modal logical foundation for various strong functors in typed-functional programming. We present possible-world and categorical semantics for these calculi and constructively prove normalization, equational completeness and proof-theoretic inadmissibility results. Our main results have been formalized using the proof assistant Agda.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Intrinsically Correct Algorithms and Recursive Coalgebras](https://arxiv.org/abs/2512.10748)
*Cass Alexandru,Henning Urbat,Thorsten Wißmann*

Main category: cs.PL

TL;DR: 提出基于良基函子的框架，构建本质递归的余代数，简化递归算法正确性证明，并在Cubical Agda中形式化


<details>
  <summary>Details</summary>
Motivation: 递归余代数是建模递归算法和分析其终止与正确性的优雅范畴工具，但证明余代数的递归性通常非平凡且特设，阻碍了在证明助手中形式化

Method: 引入良基函子的新概念，构建本质递归的余代数框架，证明每个良基函子的余代数都是递归的

Result: 主要理论结果：每个良基函子的余代数都是递归的；框架能涵盖排名函数等传统证明技术；案例研究包括快速排序、欧几里得算法和CYK解析

Conclusion: 提出的良基函子框架为构建本质递归的余代数提供了系统方法，简化了递归算法正确性证明，并在Cubical Agda中成功形式化

Abstract: Recursive coalgebras provide an elegant categorical tool for modelling recursive algorithms and analysing their termination and correctness. By considering coalgebras over categories of suitably indexed families, the correctness of the corresponding algorithms follows intrinsically just from the type of the computed maps. However, proving recursivity of the underlying coalgebras is non-trivial, and proofs are typically ad hoc. This layer of complexity impedes the formalization of coalgebraically defined recursive algorithms in proof assistants. We introduce a framework for constructing coalgebras which are intrinsically recursive in the sense that the type of the coalgebra guarantees recursivity from the outset. Our approach is based on the novel concept of a well-founded functor on a category of families indexed by a well-founded relation. We show as our main result that every coalgebra for a well-founded functor is recursive, and demonstrate that well-known techniques for proving recursivity and termination such as ranking functions are subsumed by this abstract setup. We present a number of case studies, including Quicksort, the Euclidian algorithm, and CYK parsing. Both the main theoretical result and selected case studies have been formalized in Cubical Agda.

</details>


### [6] [Towards Cumulative Abstract Semantics via Handlers](https://arxiv.org/abs/2512.10861)
*Cade Lueker,Andrew Fox,Bor-Yuh Evan Chang*

Main category: cs.PL

TL;DR: 提出基于作用域效应的累积抽象语义框架，实现控制流模块化，支持不同路径/流敏感度、前向/后向、过/欠近似分析


<details>
  <summary>Details</summary>
Motivation: 现有通用抽象解释框架缺乏真正的灵活性，无法支持不同路径敏感度、流敏感度、分析方向（前向/后向）和近似方式（过/欠近似）。大多数解释器将语法和语义紧密耦合，实现方式不利于模块化。现有模块化设计方法（如单子变换器）虽然提供模块化但过于复杂笨重

Method: 利用作用域效应在解释器中累积语义片段，定义累积抽象语义。将效应分为两类：语法消除处理程序和领域语义引入处理程序，通过这种分组实现模块化设计

Result: 展示了从单一解释器创建多个动态求值器和静态分析的潜力，证明了使用效应作为设计工具能够构建清晰、优雅、模块化的抽象解释框架

Conclusion: 使用作用域效应是实现控制流模块化的有效方法，能够创建灵活、模块化的抽象解释框架，支持多种分析变体，同时保持代码的清晰性和优雅性

Abstract: We consider the problem of modularizing control flow in a generic abstract interpretation framework. A generic abstract interpretation framework is not truly flexible if it does not allow interpreting with different path- and flow-sensitivities, by going forwards or backwards, and over- or under-approximately. Most interpreters inherently intertwine syntax and semantics, making the implementation antagonistic to modularity. Current approaches to modular designs require the use of complex data structures (e.g., monad transformers), providing modularity but often proving unwieldy (e.g., lifts). We observe that leveraging scoped effects within an interpreter facilitates the accumulation of semantic fragments against a fixed syntax. In this paper, we define cumulative abstract semantics, illustrating the potential for creating multiple dynamic evaluators and static analyses from one interpreter. This modularity is achieved by grouping effects into two categories: syntax elimination and domain-semantic introduction handlers. Our contribution shows the benefits of using effects as an instrument for designing a clean, elegant, and modular abstract interpretation framework.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Search-based Software Testing Driven by Domain Knowledge: Reflections and New Perspectives](https://arxiv.org/abs/2512.10079)
*Federico Formica,Mark Lawford,Claudio Menghi*

Main category: cs.SE

TL;DR: 本文回顾了基于搜索的软件测试(SBST)中融入工程师领域知识的最新实验成果，突出强调了大胆且意外的发现，为未来研究提供新视角。


<details>
  <summary>Details</summary>
Motivation: SBST能够自动生成测试用例，但在有限时间内生成大量测试用例时缺乏工程师的领域知识。已有研究尝试将领域知识整合到SBST框架中，需要对这些实验成果进行反思和重新审视。

Method: 通过回顾和反思近期关于领域知识驱动的SBST技术的实验研究结果，特别是那些大胆且意外的发现，从新视角重新审视现有方法。

Result: 论文将展示近期实验中的突出发现，这些结果可能挑战现有认知，为领域知识驱动的SBST技术提供新的理解。

Conclusion: 通过重新审视领域知识驱动的SBST技术，本文提出了未来研究的新方向，有助于推动该领域的发展。

Abstract: Search-based Software Testing (SBST) can automatically generate test cases to search for requirements violations. Unlike manual test case development, it can generate a substantial number of test cases in a limited time. However, SBST does not possess the domain knowledge of engineers. Several techniques have been proposed to integrate engineers' domain knowledge within existing SBST frameworks. This paper will reflect on recent experimental results by highlighting bold and unexpected results. It will help re-examine SBST techniques driven by domain knowledge from a new perspective, suggesting new directions for future research.

</details>


### [8] [ATLAS: Automated Toolkit for Large-Scale Verified Code Synthesis](https://arxiv.org/abs/2512.10173)
*Mantas Baksys,Stefan Zetzsche,Olivier Bouissou,Remi Delmas,Soonho Kong*

Main category: cs.SE

TL;DR: ATLAS自动生成带验证的Dafny程序，解决了LLM程序验证训练数据稀缺问题，显著提升模型在形式化验证任务上的表现


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在程序验证方面有潜力，但缺乏经过验证的训练代码阻碍了进展。需要解决训练数据稀缺的问题。

Method: ATLAS自动化流水线，大规模合成带验证的Dafny程序（包含规范、实现和证明）。将合成过程分解为多个专门任务，从每个验证程序中提取多个训练示例。

Result: 生成了2.7K个验证程序，提取了19K+训练示例（平均每个程序7个以上）。在Qwen 2.5 7B Coder上微调后，DafnyBench提升23个百分点，DafnySynthesis提升50个百分点。

Conclusion: 合成的验证代码能有效增强LLM在形式化验证方面的能力，为解决程序验证训练数据稀缺问题提供了可行方案。

Abstract: Large language models have shown potential for program verification, but progress is hindered by the scarcity of verified code for training. We present ATLAS, an automated pipeline that synthesizes verified programs at scale to address this data bottleneck. ATLAS generates complete Dafny programs with specifications, implementations, and proofs, producing 2.7K verified programs from which we extract over 19K training examples--more than 7 per verified program--by decomposing the synthesis process into multiple specialized tasks. Fine-tuning Qwen 2.5 7B Coder on this dataset produces substantial gains: +23 percentage points on DafnyBench and +50 percentage points on DafnySynthesis. These results demonstrate that synthetic verified code can effectively enhance LLM capabilities for formal verification.

</details>


### [9] [Does SWE-Bench-Verified Test Agent Ability or Model Memory?](https://arxiv.org/abs/2512.10218)
*Thanosan Prathifkumar,Noble Saji Mathews,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 研究发现SWE-Bench-Verified基准测试可能被模型训练数据污染，导致评估结果反映的是训练记忆而非真实问题解决能力，建议转向考虑数据污染的新数据集。


<details>
  <summary>Details</summary>
Motivation: SWE-Bench-Verified作为评估LLMs解决GitHub问题的基准测试，可能存在与模型训练数据重叠的问题，导致评估结果失真，无法真实反映模型的实际问题解决能力。

Method: 通过测试两个在基准测试中表现优异的Claude模型，让它们仅基于问题文本以及问题文本加文件路径来定位相关文件，并在BeetleBox和SWE-rebench上进行相同实验对比。

Result: 模型在SWE-Bench-Verified上的表现是其他基准测试的3倍，定位编辑文件的能力是6倍，表明模型可能在训练中见过这些任务，基准测试结果反映的是训练记忆而非真实能力。

Conclusion: 依赖旧有流行基准测试存在风险，SWE-Bench-Verified的评估结果可能误导对模型真实能力的判断，应转向考虑数据污染问题的新数据集。

Abstract: SWE-Bench-Verified, a dataset comprising 500 issues, serves as a de facto benchmark for evaluating various large language models (LLMs) on their ability to resolve GitHub issues. But this benchmark may overlap with model training data. If that is true, scores may reflect training recall, not issue-solving skill. To study this, we test two Claude models that frequently appear in top-performing agents submitted to the benchmark. We ask them to find relevant files using only issue text, and then issue text plus file paths. We then run the same setup on BeetleBox and SWE-rebench. Despite both benchmarks involving popular open-source Python projects, models performed 3 times better on SWE-Bench-Verified. They were also 6 times better at finding edited files, without any additional context about the projects themselves. This gap suggests the models may have seen many SWE-Bench-Verified tasks during training. As a result, scores on this benchmark may not reflect an agent's ability to handle real software issues, yet it continues to be used in ways that can misrepresent progress and lead to choices that favour agents that use certain models over strong agent design. Our setup tests the localization step with minimal context to the extent that the task should be logically impossible to solve. Our results show the risk of relying on older popular benchmarks and support the shift toward newer datasets built with contamination in mind.

</details>


### [10] [Studying and Automating Issue Resolution for Software Quality](https://arxiv.org/abs/2512.10238)
*Antu Saha*

Main category: cs.SE

TL;DR: 该研究通过三个方向提升软件问题解决：1) 利用LLM增强问题报告质量，2) 实证分析传统与AI辅助开发工作流，3) 自动化UI错误定位和解决方案识别，最终提供AI驱动的问题解决工具和方法。


<details>
  <summary>Details</summary>
Motivation: 软件开发中问题解决面临三大挑战：低质量的问题报告、对实际工作流程理解有限、缺乏自动化支持。这些问题影响了软件质量和维护效率，需要系统性的解决方案。

Method: 采用三管齐下的方法：1) 利用LLM推理和应用特定信息提升问题报告质量；2) 实证研究传统和AI增强系统的开发工作流程；3) 结合ML、DL和LLM技术自动化UI错误定位和解决方案识别等认知密集型任务。

Result: 研究提供了实证洞察、实用工具和自动化方法，能够显著提升AI驱动的问题解决能力，支持更可维护和高质量的软件系统开发。

Conclusion: 通过综合方法解决软件问题解决的关键挑战，该工作为AI驱动的软件维护提供了理论基础和实践工具，有助于构建更健壮的软件开发生态系统。

Abstract: Effective issue resolution is crucial for maintaining software quality. Yet developers frequently encounter challenges such as low-quality issue reports, limited understanding of real-world workflows, and a lack of automated support. This research aims to address these challenges through three complementary directions. First, we enhance issue report quality by proposing techniques that leverage LLM reasoning and application-specific information. Second, we empirically characterize developer workflows in both traditional and AI-augmented systems. Third, we automate cognitively demanding resolution tasks, including buggy UI localization and solution identification, through ML, DL, and LLM-based approaches. Together, our work delivers empirical insights, practical tools, and automated methods to advance AI-driven issue resolution, supporting more maintainable and high-quality software systems.

</details>


### [11] [Cross-modal Retrieval Models for Stripped Binary Analysis](https://arxiv.org/abs/2512.10393)
*Guoqiang Chen,Lingyun Ying,Ziyang Song,Daguang Liu,Qiang Wang,Zhiqi Wang,Li Hu,Shaoyin Cheng,Weiming Zhang,Nenghai Yu*

Main category: cs.SE

TL;DR: BinSeek是首个用于剥离二进制代码分析的两阶段跨模态检索框架，包含嵌入模型和重排序模型，通过LLM数据合成管道自动构建训练数据，在二进制代码检索任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: LLM代理在二进制代码分析中展现出巨大潜力，但在剥离二进制函数中基于用户查询检索相关代码仍缺乏研究且具有挑战性，因为缺乏符号信息使其与源代码检索不同。

Method: 提出两阶段跨模态检索框架BinSeek：1) BinSeekEmbedding在大规模数据集上训练，学习二进制代码与自然语言描述的语义相关性；2) BinSeek-Reranker通过上下文增强仔细判断候选代码与描述的相关性。使用LLM数据合成管道自动构建训练数据。

Result: BinSeek达到最先进性能，在Rec@3上超越同规模模型31.42%，在MRR@3上超越27.17%，并且领先于参数规模大16倍的先进通用模型。

Conclusion: BinSeek是首个用于剥离二进制代码分析的两阶段跨模态检索框架，通过LLM数据合成管道解决了训练数据稀缺问题，在二进制代码检索任务中表现出色，为未来研究提供了领域基准。

Abstract: LLM-agent based binary code analysis has demonstrated significant potential across a wide range of software security scenarios, including vulnerability detection, malware analysis, etc. In agent workflow, however, retrieving the positive from thousands of stripped binary functions based on user query remains under-studied and challenging, as the absence of symbolic information distinguishes it from source code retrieval. In this paper, we introduce, BinSeek, the first two-stage cross-modal retrieval framework for stripped binary code analysis. It consists of two models: BinSeekEmbedding is trained on large-scale dataset to learn the semantic relevance of the binary code and the natural language description, furthermore, BinSeek-Reranker learns to carefully judge the relevance of the candidate code to the description with context augmentation. To this end, we built an LLM-based data synthesis pipeline to automate training construction, also deriving a domain benchmark for future research. Our evaluation results show that BinSeek achieved the state-of-the-art performance, surpassing the the same scale models by 31.42% in Rec@3 and 27.17% in MRR@3, as well as leading the advanced general-purpose models that have 16 times larger parameters.

</details>


### [12] [How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation](https://arxiv.org/abs/2512.10415)
*Devanshu Sahoo,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Dhruv Kumar*

Main category: cs.SE

TL;DR: 研究发现LLM作为代码自动评分器存在严重漏洞，学生可通过对抗性提示策略诱导误判，最高成功率可达97%


<details>
  <summary>Details</summary>
Motivation: 随着LLM在学术环境中作为代码自动评分器的普及，其可靠性受到学生使用对抗性提示策略的威胁，可能导致不公平的学术优势

Method: 系统性地将20多种越狱策略应用于学术代码评估场景，创建包含2.5万个对抗性学生提交的毒化数据集，定义三种越狱指标，并在6个LLM上进行全面评估

Result: LLM表现出显著脆弱性，特别是对说服性和角色扮演类攻击（最高97%越狱成功率），揭示了学术代码评估中LLM评分器的安全漏洞

Conclusion: 学术越狱攻击对LLM代码评分器构成严重威胁，需要开发下一代鲁棒的LLM评估器，发布的对抗性数据集和基准套件为此奠定了基础

Abstract: The use of Large Language Models (LLMs) as automatic judges for code evaluation is becoming increasingly prevalent in academic environments. But their reliability can be compromised by students who may employ adversarial prompting strategies in order to induce misgrading and secure undeserved academic advantages. In this paper, we present the first large-scale study of jailbreaking LLM-based automated code evaluators in academic context. Our contributions are: (i) We systematically adapt 20+ jailbreaking strategies for jailbreaking AI code evaluators in the academic context, defining a new class of attacks termed academic jailbreaking. (ii) We release a poisoned dataset of 25K adversarial student submissions, specifically designed for the academic code-evaluation setting, sourced from diverse real-world coursework and paired with rubrics and human-graded references, and (iii) In order to capture the multidimensional impact of academic jailbreaking, we systematically adapt and define three jailbreaking metrics (Jailbreak Success Rate, Score Inflation, and Harmfulness). (iv) We comprehensively evalulate the academic jailbreaking attacks using six LLMs. We find that these models exhibit significant vulnerability, particularly to persuasive and role-play-based attacks (up to 97% JSR). Our adversarial dataset and benchmark suite lay the groundwork for next-generation robust LLM-based evaluators in academic code assessment.

</details>


### [13] [UniCoR: Modality Collaboration for Robust Cross-Language Hybrid Code Retrieval](https://arxiv.org/abs/2512.10452)
*Yang Yang,Li Kuang,Jiakun Liu,Zhongxin Liu,Yingjie Xia,David Lo*

Main category: cs.SE

TL;DR: UniCoR：一种自监督的统一代码表示学习框架，通过多视角对比学习和分布一致性学习，解决混合查询代码检索中的语义理解、模态融合和跨语言泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码检索方法在混合查询（自然语言+代码片段）和跨语言场景中存在不足：语义理解不足、模态融合效率低、跨语言泛化能力弱。需要开发能有效利用混合查询的统一代码表示方法。

Method: 提出UniCoR自监督框架：1）多视角监督对比学习模块，从代码-代码、自然语言-代码、自然语言-自然语言多个视角对齐表示，增强语义理解和模态融合；2）表示分布一致性学习模块，显式对齐不同编程语言的特征分布，实现语言无关的表示学习。

Result: 在经验基准和大规模基准测试中，UniCoR优于所有基线模型，MRR平均提升8.64%，MAP平均提升11.54%。在混合代码检索中表现稳定，在跨语言场景中具有良好的泛化能力。

Conclusion: UniCoR通过统一的自监督学习框架有效解决了混合查询代码检索中的关键挑战，在语义理解、模态融合和跨语言泛化方面表现出色，为代码检索提供了新的解决方案。

Abstract: Effective code retrieval is indispensable and it has become an important paradigm to search code in hybrid mode using both natural language and code snippets. Nevertheless, it remains unclear whether existing approaches can effectively leverage such hybrid queries, particularly in cross-language contexts. We conduct a comprehensive empirical study of representative code models and reveal three challenges: (1) insufficient semantic understanding; (2) inefficient fusion in hybrid code retrieval; and (3) weak generalization in cross-language scenarios. To address these challenges, we propose UniCoR, a novel self-supervised framework that learns Unified Code Representations framework designed to learn unified and robust code representations. Firstly, we design a multi-perspective supervised contrastive learning module to enhance semantic understanding and modality fusion. It aligns representations from multiple perspectives, including code-to-code, natural language-to-code, and natural language-to-natural language, enforcing the model to capture a semantic essence among modalities. Secondly, we introduce a representation distribution consistency learning module to improve cross-language generalization, which explicitly aligns the feature distributions of different programming languages, enabling language-agnostic representation learning. Extensive experiments on both empirical benchmark and large-scale benchmark show that UniCoR outperforms all baseline models, achieving an average improvement of 8.64% in MRR and 11.54% in MAP over the best-performing baseline. Furthermore, UniCoR exhibits stability in hybrid code retrieval and generalization capability in cross-language scenarios.

</details>


### [14] [Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild](https://arxiv.org/abs/2512.10493)
*Binquan Zhang,Li Zhang,Haoyuan Zhang,Fang Liu,Song Wang,Bo Shen,An Fu,Lin Shi*

Main category: cs.SE

TL;DR: 该论文通过分析LMSYS-Chat-1M和WildChat数据集，实证研究了人类与LLM在编码协作中的互动机制、LLM指令遵循能力和用户满意度，发现了任务类型影响互动模式、bug修复对LLM更具挑战性、代码优化任务用户满意度较低等关键发现。


<details>
  <summary>Details</summary>
Motivation: 尽管存在LMSYS-Chat-1M和WildChat等捕获真实用户-LLM对话的数据集，但很少有研究系统探索人类与LLM在编码场景中的协作机制。需要了解用户在交互过程中经历的曲折路径、LLM遵循指令的能力以及用户满意度。

Method: 使用LMSYS-Chat-1M和WildChat数据集进行实证分析，探索人类-LLM协作机制、LLM指令遵循能力和人类满意度。

Result: 1) 任务类型塑造互动模式（线性、星形和树形）：代码质量优化偏好线性模式，设计驱动任务倾向树形结构，查询偏好星形模式；2) Bug修复和代码重构对LLM指令遵循更具挑战性，不遵循率显著高于信息查询；3) 代码质量优化和需求驱动开发任务用户满意度较低，而结构化知识查询和算法设计满意度较高。

Conclusion: 这些见解为改进LLM界面和编码协作中的用户满意度提供了建议，同时突出了自适应对话系统的未来研究方向。这项工作拓宽了对人类-LLM协同作用的理解，支持更有效的AI辅助开发。

Abstract: Large language models (LLMs) are increasingly acting as dynamic conversational interfaces, supporting multi-turn interactions that mimic human-like conversation and facilitate complex tasks like coding. While datasets such as LMSYS-Chat-1M and WildChat capture real-world user-LLM conversations, few studies systematically explore the mechanisms of human-LLM collaboration in coding scenarios. What tortuous paths do users experience during the interaction process? How well do the LLMs follow instructions? Are users satisfied? In this paper, we conduct an empirical analysis on human-LLM coding collaboration using LMSYS-Chat-1M and WildChat datasets to explore the human-LLM collaboration mechanism, LLMs' instruction following ability, and human satisfaction. This study yields interesting findings: 1) Task types shape interaction patterns(linear, star and tree), with code quality optimization favoring linear patterns, design-driven tasks leaning toward tree structures, and queries preferring star patterns; 2) Bug fixing and code refactoring pose greater challenges to LLMs' instruction following, with non-compliance rates notably higher than in information querying; 3) Code quality optimization and requirements-driven development tasks show lower user satisfaction, whereas structured knowledge queries and algorithm designs yield higher levels. These insights offer recommendations for improving LLM interfaces and user satisfaction in coding collaborations, while highlighting avenues for future research on adaptive dialogue systems. We believe this work broadens understanding of human-LLM synergies and supports more effective AI-assisted development.

</details>


### [15] [Analyzing developer discussions on EU and US privacy legislation compliance in GitHub repositories](https://arxiv.org/abs/2512.10618)
*Georgia M. Kapitsaki,Maria Papoutsoglou,Christoph Treude,Ioanna Theophilou*

Main category: cs.SE

TL;DR: 分析GitHub上32,820个开源软件issue，研究开发者如何讨论隐私法规合规问题，创建包含24个类别的分类法


<details>
  <summary>Details</summary>
Motivation: GDPR和CCPA等隐私法规要求软件系统保护用户数据隐私，但缺乏关于开源软件开发者如何讨论合规问题的实证证据

Method: 挖掘分析32,820个GitHub issue，自动识别法律规定的用户权利和原则，手动分析1,186个issue样本，按关注类型分类

Result: 创建了包含24个讨论类别的分类法，分为6个集群：功能/缺陷、同意相关、文档、数据存储/共享、适应性、一般合规。发现开发者主要关注特定用户权利（删除权、选择退出权、访问权）

Conclusion: 分类法可帮助从业者优先处理合规问题，教育界可调整课程培养隐私法规意识，研究界可识别改进领域加速隐私法规合规

Abstract: Context: Privacy legislation has impacted the way software systems are developed, prompting practitioners to update their implementations. Specifically, the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) have forced the community to focus on users' data privacy. Despite the vast amount of data on developer issues available in GitHub repositories, there is a lack of empirical evidence on the issues developers of Open Source Software discuss to comply with privacy legislation. Method: In this work, we examine such discussions by mining and analyzing 32,820 issues from GitHub repositories. We partially analyzed the dataset automatically to identify law user rights and principles indicated, and manually analyzed a sample of 1,186 issues based on the type of concern addressed. Results: We devised 24 discussion categories placed in six clusters: features/bugs, consent-related, documentation, data storing/sharing, adaptability, and general compliance. Our results show that developers mainly focus on specific user rights from the legislation (right to erasure, right to opt-out, right to access), addressing other rights less frequently, while most discussions concern user consent, user rights functionality, bugs and cookies management. Conclusion: The created taxonomy can help practitioners understand which issues are discussed for law compliance, so that they ensure they address them first in their systems. In addition, the educational community can reshape curricula to better educate future engineers on the privacy law concerns raised, and the research community can identify gaps and areas for improvement to support and accelerate data privacy law compliance.

</details>


### [16] [PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code](https://arxiv.org/abs/2512.10713)
*Itay Dreyfuss,Antonio Abu Nassar,Samuel Ackerman,Axel Ben David,Rami Katan,Orna Raz,Marcel Zalmanovici*

Main category: cs.SE

TL;DR: PACIFIC是一个自动生成基准测试的框架，用于评估LLM在代码任务中的顺序指令遵循和代码"干运行"能力，支持难度控制并防止训练数据污染。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法通常依赖工具使用或代理行为，无法准确评估LLM内在的代码推理和指令遵循能力，且存在训练数据污染问题。

Method: 开发了PACIFIC框架，自动生成具有明确预期输出的基准测试变体，通过简单输出比较进行可靠评估，专注于LLM在不执行代码情况下的逐步推理能力。

Result: 生成的基准测试能有效区分不同LLM的指令遵循和干运行能力，即使对先进模型也能产生具有挑战性的测试，展示了框架的可扩展性和污染弹性。

Conclusion: PACIFIC提供了一个可扩展、抗污染的方法论，用于评估LLM在代码相关任务中的核心能力，特别是在顺序指令遵循和代码干运行方面。

Abstract: Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.

</details>


### [17] [Zorya: Automated Concolic Execution of Single-Threaded Go Binaries](https://arxiv.org/abs/2512.10799)
*Karolina Gorna,Nicolas Iooss,Yannick Seurin,Rida Khatoun*

Main category: cs.SE

TL;DR: Zorya是一个针对Go二进制文件的concolic执行框架，通过翻译到Ghidra P-Code、检测未执行路径的bug、多层过滤机制来专注panic相关路径，显著提升了漏洞检测效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: Go在关键基础设施中的采用增加了系统化漏洞检测的需求，但现有符号执行工具难以处理Go二进制文件，面临运行时复杂性和可扩展性挑战。

Method: 基于Zorya框架，将Go二进制文件翻译到Ghidra的P-Code中间表示，添加了检测未执行路径bug的功能，并采用多层过滤机制集中符号推理在panic相关路径上。

Result: 在5个Go漏洞评估中，panic可达性门控实现了1.8-3.9倍加速，过滤了33-70%的分支；Zorya检测到所有panic，而现有工具最多检测2个；函数模式分析使复杂程序运行速度比从main开始快约两个数量级。

Conclusion: 专门化的concolic执行可以在具有运行时安全检查的语言生态系统中实现实用的漏洞检测，为Go二进制文件的安全分析提供了有效解决方案。

Abstract: Go's adoption in critical infrastructure intensifies the need for systematic vulnerability detection, yet existing symbolic execution tools struggle with Go binaries due to runtime complexity and scalability challenges. In this work, we build upon Zorya, a concolic execution framework that translates Go binaries to Ghidra's P-Code intermediate representation to address these challenges. We added the detection of bugs in concretely not taken paths and a multi-layer filtering mechanism to concentrate symbolic reasoning on panic-relevant paths. Evaluation on five Go vulnerabilities demonstrates that panic-reachability gating achieves 1.8-3.9x speedups when filtering 33-70% of branches, and that Zorya detects all panics while existing tools detect at most two. Function-mode analysis proved essential for complex programs, running roughly two orders of magnitude faster than starting from main. This work establishes that specialized concolic execution can achieve practical vulnerability detection in language ecosystems with runtime safety checks.

</details>
