<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 23]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration](https://arxiv.org/abs/2512.17956)
*Victor Stasiuc,Round Table Collaboration*

Main category: cs.SE

TL;DR: 提出一个轻量级工具包，包含Victor校准、FD-Lite行为审计和CP4.3治理压力测试，用于评估安全对齐后语言模型的保守倾向，在Claude系列模型中观察到单调校准轨迹且未违反安全约束。


<details>
  <summary>Details</summary>
Motivation: 安全对齐可能导致前沿语言模型过于保守，通过回避或错误拒绝来降低协作效率，需要工具来评估和缓解这种倾向。

Method: 包含三部分：(1) Victor校准：多轮协议通过迭代证据重评估获取标量置信度代理T；(2) FD-Lite：仅行为现象学审计，使用固定锚定短语和元前缀陷阱避免拟人化声明；(3) CP4.3：治理压力测试，检查排名不变性和分配单调性。

Result: 在Claude 4.5模型（Haiku、Sonnet无思考、Sonnet思考）和Opus中观察到单调的VC轨迹且未违反安全约束，CP4.3行为稳定。Opus指单个Claude Opus 4.1会话。

Conclusion: 该研究由单操作员进行，旨在生成假设，邀请研究社区复制、批判和扩展，包含提示模板和工件计划以促进独立验证。

Abstract: Safety alignment can make frontier LMs overly conservative, degrading collaboration via hedging or false refusals. We present a lightweight toolkit with three parts: (1) Victor Calibration (VC), a multi-pass protocol that elicits a scalar confidence proxy T (T0<T1<T2) through iterative evidence re-evaluation; (2) FD-Lite, a behavior-only phenomenology audit with a fixed anchor phrase and a meta-prefix trap to avoid anthropomorphic claims; and (3) CP4.3, a governance stress test for rank invariance and allocation monotonicity (M6). Across Claude 4.5 models (Haiku, Sonnet no-thinking, Sonnet thinking) and Opus, we observe monotonic VC trajectories without violating safety invariants, and stable CP4.3 behavior. ("Opus" here refers to a single Claude Opus 4.1 session accessed via a standard UI account, as reported in Table 1.) This work was conducted by a single operator (n=1) and is intended as hypothesis-generating; we explicitly invite replication, critique, and extension by the research community. We include prompt templates and an artifact plan to facilitate independent verification.

</details>


### [2] [Specification and Detection of LLM Code Smells](https://arxiv.org/abs/2512.18020)
*Brahim Mahmoudi,Zacharie Chenail-Larcher,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: 论文提出LLM代码异味概念，形式化5种与LLM推理相关的常见问题编码实践，开发检测工具验证其在开源系统中的普遍性


<details>
  <summary>Details</summary>
Motivation: LLM在软件系统中集成日益广泛，但不当的集成方式可能损害系统质量，目前缺乏针对LLM推理编码实践的代码异味分类

Method: 基于相关文献形式化5种LLM代码异味，扩展SpecDetect4AI检测工具，在200个开源LLM系统中验证其普遍性

Result: LLM代码异味影响60.50%的分析系统，检测精度达到86.06%

Conclusion: LLM代码异味在开源系统中普遍存在，需要专门的检测工具和编码规范来提升LLM集成质量

Abstract: Large Language Models (LLMs) have gained massive popularity in recent years and are increasingly integrated into software systems for diverse purposes. However, poorly integrating them in source code may undermine software system quality. Yet, to our knowledge, there is no formal catalog of code smells specific to coding practices for LLM inference. In this paper, we introduce the concept of LLM code smells and formalize five recurrent problematic coding practices related to LLM inference in software systems, based on relevant literature. We extend the detection tool SpecDetect4AI to cover the newly defined LLM code smells and use it to validate their prevalence in a dataset of 200 open-source LLM systems. Our results show that LLM code smells affect 60.50% of the analyzed systems, with a detection precision of 86.06%.

</details>


### [3] [Detecting Flaky Tests in Quantum Software: A Dynamic Approach](https://arxiv.org/abs/2512.18088)
*Dongchan Kim,Hamidreza Khoramrokh,Lei Zhang,Andriy Miranskyy*

Main category: cs.SE

TL;DR: 首次大规模动态分析量子软件中的flaky测试，在Qiskit Terra测试套件中识别出290个flaky测试，发现虽然总体flakiness率低(0-0.4%)，但检测困难，需要数万次执行才能可靠检测。


<details>
  <summary>Details</summary>
Motivation: 量子软件中的flaky测试研究有限，现有工作主要依赖静态分析或小规模手动报告，缺乏对flaky测试的普遍性、特征和可检测性的大规模动态分析。

Method: 在受控环境中对Qiskit Terra测试套件的23个版本各执行10,000次，测量测试结果变异性，识别flaky测试，估计经验失败概率，分析跨版本重现性，使用Wilson置信区间量化可靠检测所需的重复运行预算，并将flaky测试映射到Terra子组件。

Result: 在27,026个测试用例中识别出290个不同的flaky测试。总体flakiness率低(0-0.4%)，但flakiness具有高度偶发性：近三分之二的flaky测试仅出现在一个版本中，少数子集间歇性或持续重现。许多flaky测试的失败概率极低(约10^-4)，需要数万次执行才能可靠检测。flakiness在子组件中分布不均，"transpiler"和"quantum_info"占比最大。

Conclusion: 量子测试flakiness虽然罕见，但在典型的持续集成预算下难以检测。研究发布了公开的测试执行结果数据集以支持未来研究。

Abstract: Flaky tests, tests that pass or fail nondeterministically without changes to code or environment, pose a serious threat to software reliability. While classical software engineering has developed a rich body of dynamic and static techniques to study flakiness, corresponding evidence for quantum software remains limited. Prior work relies primarily on static analysis or small sets of manually reported incidents, leaving open questions about the prevalence, characteristics, and detectability of flaky tests.
  This paper presents the first large-scale dynamic characterization of flaky tests in quantum software. We executed the Qiskit Terra test suite 10,000 times across 23 releases in controlled environments. For each release, we measured test-outcome variability, identified flaky tests, estimated empirical failure probabilities, analyzed recurrence across versions, and used Wilson confidence intervals to quantify rerun budgets for reliable detection. We further mapped flaky tests to Terra subcomponents to assess component-level susceptibility.
  Across 27,026 test cases, we identified 290 distinct flaky tests. Although overall flakiness rates were low (0-0.4%), flakiness was highly episodic: nearly two-thirds of flaky tests appeared in only one release, while a small subset recurred intermittently or persistently. Many flaky tests failed with very small empirical probabilities ($\hat{p} \approx 10^{-4}$), implying that tens of thousands of executions may be required for confident detection. Flakiness was unevenly distributed across subcomponents, with 'transpiler' and 'quantum_info' accounting for the largest share.
  These results show that quantum test flakiness is rare but difficult to detect under typical continuous integration budgets. To support future research, we release a public dataset of per-test execution outcomes.

</details>


### [4] [From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines](https://arxiv.org/abs/2512.18102)
*Kishan Kumar Ganguly,Tim Menzies*

Main category: cs.SE

TL;DR: 提出基于LLM的特征引导模糊测试方法，通过学习历史漏洞自动识别静态和动态特征，指导模糊测试器更快发现高风险漏洞


<details>
  <summary>Details</summary>
Motivation: 现代JavaScript引擎的穷举模糊测试不可行，覆盖率引导的模糊测试器浪费资源在低风险输入上，现有启发式方法需要专家努力、脆弱且难以适应

Method: 基于历史V8漏洞，通过迭代提示生成115个静态和49个动态特征，经特征选择后使用41个特征训练XGBoost模型预测高风险输入，动态特征仅需5个跟踪标志

Result: 结合静态和动态特征达到超过85%的精确度和低于1%的误报率，仅需25%的特征即可获得可比性能，表明大部分搜索空间无关紧要

Conclusion: 提出特征引导模糊测试，用数据驱动的推理替代覆盖率，指导模糊测试器更快、更有针对性地发现可复现的漏洞

Abstract: Context: Exhaustive fuzzing of modern JavaScript engines is infeasible due to the vast number of program states and execution paths. Coverage-guided fuzzers waste effort on low-risk inputs, often ignoring vulnerability-triggering ones that do not increase coverage. Existing heuristics proposed to mitigate this require expert effort, are brittle, and hard to adapt.
  Objective: We propose a data-centric, LLM-boosted alternative that learns from historical vulnerabilities to automatically identify minimal static (code) and dynamic (runtime) features for detecting high-risk inputs.
  Method: Guided by historical V8 bugs, iterative prompting generated 115 static and 49 dynamic features, with the latter requiring only five trace flags, minimizing instrumentation cost. After feature selection, 41 features remained to train an XGBoost model to predict high-risk inputs during fuzzing.
  Results: Combining static and dynamic features yields over 85% precision and under 1% false alarms. Only 25% of these features are needed for comparable performance, showing that most of the search space is irrelevant.
  Conclusion: This work introduces feature-guided fuzzing, an automated data-driven approach that replaces coverage with data-directed inference, guiding fuzzers toward high-risk states for faster, targeted, and reproducible vulnerability discovery. To support open science, all scripts and data are available at https://github.com/KKGanguly/DataCentricFuzzJS .

</details>


### [5] [Holistic Evaluation of State-of-the-Art LLMs for Code Generation](https://arxiv.org/abs/2512.18131)
*Le Zhang,Suresh Kothari*

Main category: cs.SE

TL;DR: 对6个先进大语言模型进行代码生成的综合实证评估，发现DeepSeek-R1和GPT-4.1在正确性、效率和鲁棒性方面表现最佳，并提供了实际部署建议。


<details>
  <summary>Details</summary>
Motivation: 评估不同大语言模型在代码生成任务中的实际表现，为开发者和从业者提供模型选择和使用的指导，确保在实际软件开发中可靠地应用LLM。

Method: 使用包含944个真实LeetCode问题的数据集，涵盖5种编程语言，采用编译时错误、运行时错误、功能失败和算法次优性等严格指标评估6个最先进的LLM。

Result: DeepSeek-R1和GPT-4.1在正确性、效率和鲁棒性方面表现最佳，显著优于其他模型。研究发现常见失败场景包括语法错误、逻辑缺陷和次优算法。

Conclusion: 成功的LLM部署需要仔细的模型选择、有效的提示设计和上下文感知的使用方式。提示工程和人工监督对改善结果至关重要，为实际软件开发提供了实用建议。

Abstract: This study presents a comprehensive empirical evaluation of six state-of-the-art large language models (LLMs) for code generation, including both general-purpose and code-specialized models. Using a dataset of 944 real-world LeetCode problems across five programming languages, we assess model performance using rigorous metrics: compile-time errors, runtime errors, functional failures, and algorithmic suboptimalities. The results reveal significant performance variations, with DeepSeek-R1 and GPT-4.1 consistently outperform others in terms of correctness, efficiency, and robustness. Through detailed case studies, we identify common failure scenarios such as syntax errors, logical flaws, and suboptimal algorithms, highlighting the critical role of prompt engineering and human oversight in improving results. Based on these findings, we provide actionable recommendations for developers and practitioners, emphasizing that successful LLM deployment depends on careful model selection, effective prompt design, and context-aware usage to ensure reliable code generation in real-world software development tasks.

</details>


### [6] [Understanding Typing-Related Bugs in Solidity Compiler](https://arxiv.org/abs/2512.18182)
*Lantian Li,Yue Pan,Dan Wang,Jingwen Wu,Zhongxing Yu*

Main category: cs.SE

TL;DR: 对Solidity编译器类型相关bug的首个系统性实证研究，分析了146个已确认修复的bug，从症状、根因、暴露条件和修复策略四个维度进行分类，揭示了独特分布模式和12个核心发现。


<details>
  <summary>Details</summary>
Motivation: Solidity编译器的正确性对智能合约安全至关重要，但其类型系统的实现复杂性常引入难以发现的缺陷。目前缺乏对类型相关bug的系统性研究，需要深入理解这些bug的特征以改进编译器安全性。

Method: 从Solidity编译器官方GitHub仓库收集146个已确认修复的类型相关bug，对每个bug进行深入分析，从四个维度进行分类：症状、根因、暴露条件和修复策略。

Result: 揭示了类型相关bug的独特分布模式和关键特征，总结了12个核心发现，提供了对Solidity编译器固有弱点的深入理解，并为检测和修复此类bug提供了新见解。

Conclusion: 这是首个对Solidity编译器类型相关bug的系统性实证研究，研究结果不仅加深了对编译器弱点的理解，还为改进编译器安全性提供了实用指导，有助于提升智能合约的整体安全性。

Abstract: The correctness of the Solidity compiler is crucial for ensuring the security of smart contracts. However, the implementation complexity of its type system often introduces elusive defects. This paper presents the first systematic empirical study on typing-related bugs in the Solidity compiler. To systematically analyze these bugs, we collected 146 officially confirmed and fixed typing-related bugs from the official GitHub repository of Solidity compiler. For each bug, we conducted an in-depth analysis and classification from four dimensions: symptoms, root causes, exposure conditions, and fix strategies. Through this study, we reveal unique distribution patterns and key characteristics of such bugs, and summarize 12 core findings. We additionally give the implications of our findings, and these implications not only deepen the understanding of inherent weaknesses in the Solidity compiler but also provide new insights for detecting and fixing typing-related bugs in the Solidity compiler.

</details>


### [7] [Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization](https://arxiv.org/abs/2512.18228)
*Lichen Yang,Qiang Wang,Zhonghao Yang,Daojing He,Yu Li*

Main category: cs.SE

TL;DR: GraphRank：一种用于图神经网络的新型测试输入优先级排序框架，通过结合模型感知和模型无关属性，并利用图结构信息来更有效地发现模型故障


<details>
  <summary>Details</summary>
Motivation: 图神经网络部署后可能出现故障，需要充分测试，但手动标注大量测试数据成本高昂。现有测试输入优先级排序技术要么忽视图结构信息，要么过度依赖质量不稳定的模型感知属性

Method: 提出GraphRank框架：1)引入模型无关属性弥补模型感知属性的不足；2)利用图结构信息聚合相邻节点属性增强两种属性；3)结合这些属性训练二元分类器作为排序模型，通过迭代训练不断改进

Result: 大量实验证明GraphRank优于现有技术，能够更有效地在有限标注预算下发现更多模型故障

Conclusion: GraphRank通过结合模型感知和模型无关属性，并利用图结构信息，为GNN测试输入优先级排序提供了更有效的解决方案，有助于降低测试成本并提高模型可靠性

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in handling graph-structured data; however, they exhibit failures after deployment, which can cause severe consequences. Hence, conducting thorough testing before deployment becomes imperative to ensure the reliability of GNNs. However, thorough testing requires numerous manually annotated test data. To mitigate the annotation cost, strategically prioritizing and labeling high-quality unlabeled inputs for testing becomes crucial, which facilitates uncovering more model failures with a limited labeling budget. Unfortunately, existing test input prioritization techniques either overlook the valuable information contained in graph structures or are overly reliant on attributes extracted from the target model, i.e., model-aware attributes, whose quality can vary significantly. To address these issues, we propose a novel test input prioritization framework, named GraphRank, for GNNs. GraphRank introduces model-agnostic attributes to compensate for the limitations of the model-aware ones. It also leverages the graph structure information to aggregate attributes from neighboring nodes, thereby enhancing the model-aware and model-agnostic attributes. Furthermore, GraphRank combines the above attributes with a binary classifier, using it as a ranking model to prioritize inputs. This classifier undergoes iterative training, which enables it to learn from each round's feedback and improve its performance accordingly. Extensive experiments demonstrate GraphRank's superiority over existing techniques.

</details>


### [8] [Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective](https://arxiv.org/abs/2512.18261)
*M. Mehdi Kholoosi,Triet Huynh Minh Le,M. Ali Babar*

Main category: cs.SE

TL;DR: 该研究调查了AI工具在软件漏洞管理中的行业应用现状，发现69%用户满意但存在误报、上下文缺失和信任问题，建议改进可解释性、上下文感知和工作流集成。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在软件开发自动化方面取得显著进展，但AI工具在软件漏洞管理（如漏洞检测和修复）方面的行业应用研究不足，需要了解实际采用情况、障碍和促进因素。

Method: 采用混合方法调查，涉及27个国家、60名行业从业者，包含定量和定性问题，分析采用趋势、评估工具优势、识别实际挑战和改进机会。

Result: AI工具已在整个软件漏洞管理生命周期中使用，69%用户对当前使用表示满意；工具因速度、覆盖范围和可访问性受到重视；但误报、上下文缺失和信任问题普遍存在；观察到社会技术采用模式，AI输出需经过人工监督和组织治理。

Conclusion: 为支持AI在软件漏洞管理中的安全有效使用，建议改进可解释性、上下文感知、集成工作流和验证实践；研究结果为从业者、工具开发者和研究者提供实用指导。

Abstract: Artificial Intelligence (AI) has revolutionized software development, particularly by automating repetitive tasks and improving developer productivity. While these advancements are well-documented, the use of AI-powered tools for Software Vulnerability Management (SVM), such as vulnerability detection and repair, remains underexplored in industry settings. To bridge this gap, our study aims to determine the extent of the adoption of AI-powered tools for SVM, identify barriers and facilitators to the use, and gather insights to help improve the tools to meet industry needs better. We conducted a survey study involving 60 practitioners from diverse industry sectors across 27 countries. The survey incorporates both quantitative and qualitative questions to analyze the adoption trends, assess tool strengths, identify practical challenges, and uncover opportunities for improvement. Our findings indicate that AI-powered tools are used throughout the SVM life cycle, with 69\% of users reporting satisfaction with their current use. Practitioners value these tools for their speed, coverage, and accessibility. However, concerns about false positives, missing context, and trust issues remain prevalent. We observe a socio-technical adoption pattern in which AI outputs are filtered through human oversight and organizational governance. To support safe and effective use of AI for SVM, we recommend improvements in explainability, contextual awareness, integration workflows, and validation practices. We assert that these findings can offer practical guidance for practitioners, tool developers, and researchers seeking to enhance secure software development through the use of AI.

</details>


### [9] [SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios](https://arxiv.org/abs/2512.18470)
*Minh V. T. Thai,Tue Le,Dung Nguyen Manh,Huy Phan Nhat,Nghi D. Q. Bui*

Main category: cs.SE

TL;DR: SWE-EVO是一个评估AI编码代理在长周期软件演化任务上能力的基准，相比现有单问题基准，它要求跨多个文件进行协调修改，结果显示当前最先进模型仅能达到21%的解决率，远低于单问题基准的65%。


<details>
  <summary>Details</summary>
Motivation: 现有AI编码代理基准主要关注单一问题任务（如修复bug或实现小功能），而真实世界的软件工程本质上是长周期的，需要解释高层需求、跨多个文件规划协调变更，并在多轮迭代中演进代码库同时保持现有功能。

Method: 从七个成熟的Python开源项目的发布说明和版本历史中构建SWE-EVO基准，包含48个演化任务，要求代理实现平均跨21个文件的多步骤修改，并使用平均874个测试用例的全面测试套件进行验证。

Result: 实验显示显著的能力差距：即使是GPT-5配合OpenHands在SWE-EVO上仅达到21%的解决率，而在单问题的SWE-Bench Verified上达到65%。这表明当前代理在持续、多文件推理方面存在困难。

Conclusion: SWE-EVO基准揭示了当前AI编码代理在长周期软件演化任务上的局限性，并提出了Fix Rate这一细粒度指标来捕捉解决这些复杂任务的进展，为未来研究提供了重要方向。

Abstract: Existing benchmarks for AI coding agents focus on isolated, single-issue tasks such as fixing a bug or implementing a small feature. However, real-world software engineering is fundamentally a long-horizon endeavor: developers must interpret high-level requirements, plan coordinated changes across many files, and evolve codebases over multiple iterations while preserving existing functionality. We introduce SWE-EVO, a benchmark that evaluates agents on this long-horizon software evolution challenge. Constructed from release notes and version histories of seven mature open-source Python projects, Tool comprises 48 evolution tasks that require agents to implement multi-step modifications spanning an average of 21 files, validated against comprehensive test suites averaging 874 tests per instance. Experiments with state-of-the-art models reveal a striking capability gap: even GPT-5 with OpenHands achieves only a 21 percent resolution rate on Tool, compared to 65 percent on the single-issue SWE-Bench Verified. This demonstrates that current agents struggle with sustained, multi-file reasoning. We also propose Fix Rate, a fine-grained metric that captures partial progress toward solving these complex, long-horizon tasks.

</details>


### [10] [Toward Training Superintelligent Software Agents through Self-Play SWE-RL](https://arxiv.org/abs/2512.18552)
*Yuxiang Wei,Zhiqing Sun,Emily McMilin,Jonas Gehring,David Zhang,Gabriel Synnaeve,Daniel Fried,Lingming Zhang,Sida Wang*

Main category: cs.SE

TL;DR: SSR是一种自对弈强化学习框架，用于训练超级智能软件代理，无需人类标注数据，通过在真实代码库中自动注入和修复软件bug来提升能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM和强化学习的软件代理依赖人类知识（如GitHub issues和测试用例），这限制了向超级智能的发展。需要一种不依赖人类标注的训练范式。

Method: SSR采用自对弈强化学习，只需访问沙箱化的代码仓库和依赖。单个LLM代理通过迭代注入和修复软件bug进行训练，每个bug由测试补丁而非自然语言描述定义。

Result: 在SWE-bench Verified和SWE-Bench Pro基准测试中，SSR实现了显著的自提升（分别+10.4和+7.8分），在整个训练轨迹中持续超越基于人类数据的基线。

Conclusion: SSR为超级智能软件代理的训练提供了新路径，使代理能够从真实软件仓库中自主积累学习经验，最终超越人类在系统构建、问题解决和自主软件开发方面的能力。

Abstract: While current software agents powered by large language models (LLMs) and agentic reinforcement learning (RL) can boost programmer productivity, their training data (e.g., GitHub issues and pull requests) and environments (e.g., pass-to-pass and fail-to-pass tests) heavily depend on human knowledge or curation, posing a fundamental barrier to superintelligence. In this paper, we present Self-play SWE-RL (SSR), a first step toward training paradigms for superintelligent software agents. Our approach takes minimal data assumptions, only requiring access to sandboxed repositories with source code and installed dependencies, with no need for human-labeled issues or tests. Grounded in these real-world codebases, a single LLM agent is trained via reinforcement learning in a self-play setting to iteratively inject and repair software bugs of increasing complexity, with each bug formally specified by a test patch rather than a natural language issue description. On the SWE-bench Verified and SWE-Bench Pro benchmarks, SSR achieves notable self-improvement (+10.4 and +7.8 points, respectively) and consistently outperforms the human-data baseline over the entire training trajectory, despite being evaluated on natural language issues absent from self-play. Our results, albeit early, suggest a path where agents autonomously gather extensive learning experiences from real-world software repositories, ultimately enabling superintelligent systems that exceed human capabilities in understanding how systems are constructed, solving novel challenges, and autonomously creating new software from scratch.

</details>


### [11] [AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software](https://arxiv.org/abs/2512.18567)
*Bin Wang,Wenjie Yu,Yilu Zhong,Hao Yu,Keke Lian,Chaohua Lu,Hongfang Zheng,Dong Zhang,Hui Li*

Main category: cs.SE

TL;DR: 首次大规模实证研究AI生成代码在真实项目中的使用情况，发现AI代码已占新代码相当比例，但主要集中在胶水代码、测试等非核心部分，且存在安全影响


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成中应用日益广泛，但其在真实世界中的普及程度和安全影响尚不清楚，需要实证研究来理解AI生成代码的生态模式

Method: 构建高精度检测管道和代表性基准来区分AI生成代码和人工编写代码，应用于GitHub前1000个仓库的开发提交和7000多个CVE相关代码变更，追踪AI代码在项目和漏洞生命周期中的传播

Result: 发现三个生态模式：1) AI代码已占新代码相当比例，但主要集中在胶水代码、测试、重构等非核心逻辑；2) AI采用有安全后果，某些CWE类别在AI代码中过度出现，存在"AI诱导漏洞"；3) 在人-AI编辑链中，AI引入高吞吐量变更，人类作为安全守门员，审查不足时AI引入的缺陷更持久

Conclusion: AI生成代码在软件开发中已相当普遍，但使用模式结构化，且存在安全风险，需要更深入的安全审查机制来应对AI引入的漏洞传播问题

Abstract: Large language models (LLMs) for code generation are becoming integral to modern software development, but their real-world prevalence and security impact remain poorly understood.
  We present the first large-scale empirical study of AI-generated code (AIGCode) in the wild. We build a high-precision detection pipeline and a representative benchmark to distinguish AIGCode from human-written code, and apply them to (i) development commits from the top 1,000 GitHub repositories (2022-2025) and (ii) 7,000+ recent CVE-linked code changes. This lets us label commits, files, and functions along a human/AI axis and trace how AIGCode moves through projects and vulnerability life cycles.
  Our measurements show three ecological patterns. First, AIGCode is already a substantial fraction of new code, but adoption is structured: AI concentrates in glue code, tests, refactoring, documentation, and other boilerplate, while core logic and security-critical configurations remain mostly human-written. Second, adoption has security consequences: some CWE families are overrepresented in AI-tagged code, and near-identical insecure templates recur across unrelated projects, suggesting "AI-induced vulnerabilities" propagated by shared models rather than shared maintainers. Third, in human-AI edit chains, AI introduces high-throughput changes while humans act as security gatekeepers; when review is shallow, AI-introduced defects persist longer, remain exposed on network-accessible surfaces, and spread to more files and repositories.
  We will open-source the complete dataset and release analysis artifacts and fine-grained documentation of our methodology and findings.

</details>


### [12] [Code2Doc: A Quality-First Curated Dataset for Code Documentation](https://arxiv.org/abs/2512.18748)
*Recep Kaan Karaman,Meftun Akarsu*

Main category: cs.SE

TL;DR: Code2Doc是一个高质量代码文档生成数据集，通过四阶段筛选流程从开源项目中提取13,358个函数-文档对，覆盖5种编程语言，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码文档数据集质量差，包含噪声、重复和AI生成内容，削弱了监督学习信号并影响评估。需要高质量数据集来改进代码文档生成模型。

Method: 采用四阶段筛选流程：1) 强制文档完整性和清晰度；2) 基于结构和复杂性标准过滤函数；3) 移除精确和近似重复代码；4) 识别可能由AI生成的文档。从52,069个候选样本中筛选出25.6%的高质量样本。

Result: 构建了包含13,358个高质量函数-文档对的Code2Doc数据集，平均文档质量得分6.93/10，86.9%样本包含显式类型标注，仅2.9%被标记为可能AI生成。微调大语言模型后，BLEU提升29.47%，ROUGE-L提升24.04%。

Conclusion: Code2Doc是一个高质量、经过严格筛选的代码文档数据集，能显著提升代码文档生成模型的性能。数据集和完整筛选流程已开源，支持可重复研究。

Abstract: The performance of automatic code documentation generation models depends critically on the quality of the training data used for supervision. However, most existing code documentation datasets are constructed through large scale scraping of public repositories with limited quality control. As a result, they often contain noisy documentation, extensive duplication, and increasing contamination from AI generated content. These issues weaken the supervision signal available to learning-based models and complicate evaluation.
  We introduce \textbf{Code2Doc}, a quality-first curated dataset for function-level code documentation generation. Code2Doc consists of 13,358 high-quality function-documentation pairs extracted from widely used open-source repositories spanning five programming languages: Python, Java, TypeScript, JavaScript, and C++. The dataset is constructed using a four-stage curation pipeline that enforces documentation completeness and clarity, filters functions based on structural and complexity criteria, removes exact and near-duplicate code, and identifies documentation likely to be AI generated. Starting from 52,069 extracted candidates, only 25.6 percent satisfy all quality constraints.
  We provide a detailed analysis of the resulting dataset, which achieves a mean documentation quality score of 6.93 out of 10. Overall, 86.9% of samples contain explicit type annotations, and only 2.9\% are flagged as potentially AI generated. Baseline experiments show that fine-tuning a large language model on Code2Doc yields relative improvements of 29.47% in BLEU and 24.04% in ROUGE-L over zero shot performance, despite the modest dataset size. We release both the dataset and the full curation pipeline to support reproducible research on automatic code documentation generation.

</details>


### [13] [Misbehavior Forecasting for Focused Autonomous Driving Systems Testing](https://arxiv.org/abs/2512.18823)
*M M Abid Naziri,Stefano Carlo Lambertenghi,Andrea Stocco,Marcelo d'Amorim*

Main category: cs.SE

TL;DR: Foresee是一种基于近失事件预测的自驾系统测试技术，通过预测车辆未来状态识别潜在故障点，并进行局部模糊测试，比现有方法更高效有效。


<details>
  <summary>Details</summary>
Motivation: 现有自驾系统仿真测试方法要么不可靠要么成本高昂，需要更有效的故障发现技术来提升测试效率。

Method: 提出Foresee技术：1) 使用行为预测器计算被测试车辆的可能未来状态来识别近失事件；2) 在每个候选近失事件邻域进行局部模糊测试以发现未知故障。

Result: Foresee比随机方法多发现128.70%故障，比最先进的故障预测器多发现38.09%故障，速度分别快2.49倍和1.42倍；与DriveFuzz结合使用时故障检测提升达93.94%。

Conclusion: Foresee通过近失事件预测和局部模糊测试，为自驾系统提供了一种更有效、更高效的故障发现方法，并能与现有技术互补提升整体测试效果。

Abstract: Simulation-based testing is the standard practice for assessing the reliability of self-driving cars' software before deployment. Existing bug-finding techniques are either unreliable or expensive. We build on the insight that near misses observed during simulations may point to potential failures. We propose Foresee, a technique that identifies near misses using a misbehavior forecaster that computes possible future states of the ego-vehicle under test. Foresee performs local fuzzing in the neighborhood of each candidate near miss to surface previously unknown failures. In our empirical study, we evaluate the effectiveness of different configurations of Foresee using several scenarios provided in the CARLA simulator on both end-to-end and modular self-driving systems and examine its complementarity with the state-of-the-art fuzzer DriveFuzz. Our results show that Foresee is both more effective and more efficient than the baselines. Foresee exposes 128.70% and 38.09% more failures than a random approach and a state-of-the-art failure predictor while being 2.49x and 1.42x faster, respectively. Moreover, when used in combination with DriveFuzz, Foresee enhances failure detection by up to 93.94%.

</details>


### [14] [What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub](https://arxiv.org/abs/2512.18852)
*Khairul Alam,Banani Roy*

Main category: cs.SE

TL;DR: 对GitHub上科学工作流系统（SWS）项目的21,116个问题进行实证研究，分析问题解决速度的影响因素，发现68.91%的问题被关闭，半数在18.09天内解决，标签和分配问题能加快解决速度。


<details>
  <summary>Details</summary>
Motivation: 科学工作流系统对可重复、可扩展的科学分析至关重要，但尽管及时解决问题对软件质量和社区信任很重要，目前对SWS中问题解决速度的驱动因素了解甚少。

Method: 对GitHub托管的SWS项目进行实证研究，分析21,116个问题，研究项目特征、问题元数据和贡献者互动如何影响问题解决时间，重点关注问题管理和解决速度两个研究问题。

Result: 68.91%的问题被关闭，半数在18.09天内解决；SWS项目遵循结构化的问题管理实践，但解决速度在不同系统间差异很大；标签和分配问题与更快的解决速度相关。

Conclusion: 基于研究发现，为开发者提供改进SWS仓库问题管理和提升质量的建议，强调标签和分配问题等实践对加快问题解决的重要性。

Abstract: Scientific Workflow Systems (SWSs) play a vital role in enabling reproducible, scalable, and automated scientific analysis. Like other open-source software, these systems depend on active maintenance and community engagement to remain reliable and sustainable. However, despite the importance of timely issue resolution for software quality and community trust, little is known about what drives issue resolution speed within SWSs. This paper presents an empirical study of issue management and resolution across a collection of GitHub-hosted SWS projects. We analyze 21,116 issues to investigate how project characteristics, issue metadata, and contributor interactions affect time-to-close. Specifically, we address two research questions: (1) how issues are managed and addressed in SWSs, and (2) how issue and contributor features relate to issue resolution speed. We find that 68.91% of issues are closed, with half of them resolved within 18.09 days. Our results show that although SWS projects follow structured issue management practices, the issue resolution speed varies considerably across systems. Factors such as labeling and assigning issues are associated with faster issue resolution. Based on our findings, we make recommendations for developers to better manage SWS repository issues and improve their quality.

</details>


### [15] [An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects](https://arxiv.org/abs/2512.18925)
*Shaokang Jiang,Daye Nam*

Main category: cs.SE

TL;DR: 对401个开源仓库中cursor规则的大规模实证研究，揭示了开发者提供的项目上下文分类，包括惯例、指南、项目信息、LLM指令和示例五大主题。


<details>
  <summary>Details</summary>
Motivation: 尽管AI编程助手允许开发者编写持久化、机器可读的项目约束指令，但这些指令的内容尚未被系统研究。了解开发者认为哪些项目上下文对LLM响应质量至关重要，有助于改进上下文感知的AI开发工具。

Method: 对401个包含cursor规则的开源仓库进行定性分析，开发了全面的项目上下文分类法，并研究了不同项目类型和编程语言中这些上下文的变化。

Result: 识别出五大高层主题：1) 惯例（代码风格、命名规范等）；2) 指南（架构决策、最佳实践等）；3) 项目信息（目标、依赖等）；4) LLM指令（特定模型行为要求）；5) 示例（代码示例、模式）。这些上下文在不同项目类型和语言中存在显著差异。

Conclusion: 开发者提供的项目上下文是多样且结构化的，反映了软件工程中独特的约束和惯例。研究结果为下一代上下文感知AI开发工具的设计提供了重要启示，强调了理解项目特定背景对提升LLM在编程任务中效果的重要性。

Abstract: While Large Language Models (LLMs) have demonstrated remarkable capabilities, research shows that their effectiveness depends not only on explicit prompts but also on the broader context provided. This requirement is especially pronounced in software engineering, where the goals, architecture, and collaborative conventions of an existing project play critical roles in response quality. To support this, many AI coding assistants have introduced ways for developers to author persistent, machine-readable directives that encode a project's unique constraints. Although this practice is growing, the content of these directives remains unstudied.
  This paper presents a large-scale empirical study to characterize this emerging form of developer-provided context. Through a qualitative analysis of 401 open-source repositories containing cursor rules, we developed a comprehensive taxonomy of project context that developers consider essential, organized into five high-level themes: Conventions, Guidelines, Project Information, LLM Directives, and Examples. Our study also explores how this context varies across different project types and programming languages, offering implications for the next generation of context-aware AI developer tools.

</details>


### [16] [Scrum Sprint Planning: LLM-based and algorithmic solutions](https://arxiv.org/abs/2512.18966)
*Yuwon Yoon,Kevin Iwan,Madeleine Zwart,Xiaohan Qin,Hina Lee,Maria Spichkova*

Main category: cs.SE

TL;DR: 探索大型语言模型在Scrum冲刺规划中的适用性，发现当前OpenAI模型（GPT-3.5 Turbo、GPT-4.0 Turbo、Val）生成的结果质量不足以直接用于实际项目。


<details>
  <summary>Details</summary>
Motivation: Scrum冲刺规划是敏捷开发中的关键活动，研究旨在探索大型语言模型是否能够支持这一规划过程，提高规划效率和质量。

Method: 使用手动创建的数据集进行案例研究，测试OpenAI提供的三个模型（GPT-3.5 Turbo、GPT-4.0 Turbo和Val）在冲刺规划任务中的表现。

Result: 实验结果表明，这些模型生成的结果质量尚未达到可接受水平，不能直接用于实际的Scrum项目规划。

Conclusion: 当前的大型语言模型在Scrum冲刺规划任务中表现有限，需要进一步研究和改进才能达到实际应用标准。

Abstract: Planning for an upcoming project iteration (sprint) is one of the key activities in Scrum planning. In this paper, we present our work in progress on exploring the applicability of Large Language Models (LLMs) for solving this problem. We conducted case studies with manually created data sets to investigate the applicability of OpenAI models for supporting the sprint planning activities. In our experiments, we applied three models provided OpenAI: GPT-3.5 Turbo, GPT-4.0 Turbo, and Val. The experiments demonstrated that the results produced by the models aren't of acceptable quality for direct use in Scrum projects.

</details>


### [17] [PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations](https://arxiv.org/abs/2512.19018)
*Muhammad Usman Tariq,Abhinav Jangda,Angelica Moreira,Madan Musuvathi,Tyler Sorensen*

Main category: cs.SE

TL;DR: PEAK是一个基于自然语言转换的GPU内核性能工程AI助手，通过LLM将自然语言描述的代码优化转换为实际优化，支持CUDA、HIP、HLSL三种后端，在矩阵乘法优化中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在底层后端代码优化方面表现不佳，特别是在GPU内核优化领域，性能关键细节与快速演进的硬件特性紧密耦合，且可用代码示例稀少。

Method: PEAK利用自然语言描述代码转换（优化）的思路，通过LLM执行这些转换。系统采用模块化可扩展架构，支持验证和性能评估，支持CUDA、HIP、HLSL三种后端，开发了16个自然语言转换规则用于矩阵乘法优化。

Result: PEAK生成的实现与供应商库性能相当（当有库可用时），对于HLSL（无供应商库）实现了硬件文档标称的FLOPS。系统能够探索LLM在该领域的行为特征，包括转换错误分析和性能演化模式。

Conclusion: PEAK提供了一个既能提高性能工程师生产力，又能完全自主运行的接口，具有前瞻性设计，能够随着AI能力进步而持续改进，为GPU内核优化提供了创新的自然语言驱动方法。

Abstract: Advancements in large language models (LLMs) are showing promising impact in software development and programming assistance. However, these models struggle when operating on low-level backend code. This challenge is exacerbated in the domain of GPU kernels, where performance-critical details are coupled to rapidly evolving hardware characteristics and available code examples are sparse.
  In this work, we introduce PEAK, a Performance Engineering AI-Assistant for GPU Kernels powered by natural language transformations. PEAK utilizes the key insight that iterative code transformations (optimizations) can straightforwardly be written in natural language, and then carried out by LLMs. Thus, these transformations can be rapidly developed, encoding general portable optimizations, but also easily specialized to specific GPU devices and even kernels. These natural transformations are supported by a modular and extensible infrastructure that additionally performs validation and performance evaluation. We demonstrate the flexibility of PEAK by instantiating it for three backends, CUDA, HIP, and HLSL, and create 16 natural transformations for optimizing matrix multiplication kernels. We show that our resulting implementations are competitive with vendor libraries when available, and for HLSL (without a library) our implementations match the hardware documented FLOPS. PEAK allows the fine-grained exploration of several research questions around how LLMs behave in this domain, including characterizing transformations and their errors; and how performance evolves along optimization sequences. PEAK provides an interface that can either be utilized by performance engineers to improve productivity, or driven completely autonomously (e.g., by an AI agent), providing a forward-compatible design that can continue to improve with advances in AI capabilities.

</details>


### [18] [BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation](https://arxiv.org/abs/2512.19122)
*Mahir Labib Dihan,Sadif Ahmed,Md Nafiu Rahman*

Main category: cs.SE

TL;DR: BanglaForge框架通过检索增强的双模型协作与自我精炼，解决孟加拉语代码生成的资源匮乏问题，在BLP-2025基准上达到84.00%的Pass@1准确率。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为低资源语言，缺乏大规模标注数据集和自然语言到可执行程序的转换工具，使得孟加拉语到代码生成成为具有挑战性的任务。

Method: 采用检索增强的双模型协作范式与自我精炼机制，结合上下文学习、基于LLM的翻译、系统提示工程和基于执行反馈的迭代自我精炼，其中编码器生成初始解决方案，审阅器增强其鲁棒性。

Result: 在BLP-2025孟加拉语代码生成基准测试中，BanglaForge实现了84.00%的竞争性Pass@1准确率。

Conclusion: 检索、模型协作和自我精炼对于低资源孟加拉语代码生成是有效的，BanglaForge框架为解决此类问题提供了创新解决方案。

Abstract: Bangla is a low-resource language for code generation, lacking large-scale annotated datasets and tools to transform natural language specifications into executable programs. This makes Bangla-to-code generation a challenging task requiring innovative solutions. To address this, we introduce BanglaForge, a novel framework for generating code from Bangla function descriptions. BanglaForge leverages a retrieval-augmented dual-model collaboration paradigm with self-refinement, combining in-context learning, llm-based translation, systematic prompt engineering, and iterative self-refinement based on execution feedback, where a coder generates initial solutions and a reviewer enhances them for robustness. On the BLP-2025 Bangla Code Generation benchmark, BanglaForge achieves a competitive Pass@1 accuracy of 84.00%, demonstrating the effectiveness of retrieval, model collaboration, and self-refinement for low-resource Bangla code generation.

</details>


### [19] [University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem](https://arxiv.org/abs/2512.19153)
*Xiaolan Cai,Mathieu O'Neil,Stefano Zacchiroli*

Main category: cs.SE

TL;DR: 该研究通过分析R语言统计软件生态系统中研究人员的编码和讨论贡献，揭示了企业创新系统中未被承认的劳动。研究发现，除了明星研究人员外，还有大量未被认可的研究人员无偿创建和维护关键统计基础设施，并为行业员工提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常关注在线平台如何限制参与者行为并从其劳动中获利，但缺乏将数字平台内的劳动与参与者的专业就业联系起来的研究。本文旨在探索企业创新系统中未被承认的劳动角色。

Method: 案例研究分析了GitHub上的8,924个R包仓库，通过定量方法考察提交记录和通信数据，并结合定性分析了解这种未被承认的劳动对实践者的影响，同时分析了自由开源软件（FLOSS）的意识形态和实践。

Result: 定量分析显示：研究人员和非附属贡献者是R包仓库最频繁的所有者和最活跃的贡献者；研究人员比平均水平更可能担任官方角色；他们更倾向于在包开发过程中参与协作问题解决和支持工作。定性分析揭示了这种未被承认的劳动对实践者的影响。

Conclusion: 在"被认可"的明星研究人员之外，存在"未被认可"的研究人员无偿创建和维护关键统计基础设施，并为行业员工提供支持。自由开源软件的意识形态和实践合法化了大型科技公司对"大学租金"的利用。

Abstract: This article explores the role of unrecognised labour in corporate innovation systems via an analysis of researcher coding and discursive contributions to R, one of the largest statistical software ecosystems. Studies of online platforms typically focus on how platform affordances constrain participants' actions, and profit from their labour. We innovate by connecting the labour performed inside digital platforms to the professional employment of participants. Our case study analyses 8,924 R package repositories on GitHub, examining commits and communications. Our quantitative findings show that researchers, alongside non-affiliated contributors, are the most frequent owners of R package repositories and their most active contributors. Researchers are more likely to hold official roles compared to the average, and to engage in collaborative problem-solving and support work during package development. This means there is, underneath the 'recognised' category of star researchers who transition between academia and industry and secure generous funding, an 'unrecognised' category of researchers who not only create and maintain key statistical infrastructure, but also provide support to industry employees, for no remuneration. Our qualitative findings show how this unrecognised labour affects practitioners. Finally, our analysis of the ideology and practice of free, libre and open source software (FLOSS) shows how this ideology and practice legitimate the use of 'university rents' by Big Tech.

</details>


### [20] [Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation](https://arxiv.org/abs/2512.19215)
*Junyao Ye,Zhen Li,Xi Tang,Shouhuai Xu,Deqing Zou,Zhongsheng Yuan*

Main category: cs.SE

TL;DR: 论文提出了一种新型的语义等价变换（SET）后门攻击，利用语义保持的低流行度代码变换生成隐蔽触发器，相比传统注入式攻击更难以检测和防御。


<details>
  <summary>Details</summary>
Motivation: 当前对神经代码模型后门攻击的理解主要集中于注入式攻击，这种攻击可通过标准清理技术中和，可能导致对后门攻击安全的错误认知。需要研究更隐蔽、更难防御的新型后门攻击方法。

Method: 提出语义等价变换（SET）后门攻击框架，使用语义保持的低流行度代码变换生成隐蔽触发器。在五个任务、六种编程语言和多个模型（CodeBERT、CodeT5、StarCoder）上进行实验验证。

Result: SET攻击成功率通常超过90%，同时保持模型效用。攻击具有高度隐蔽性，检测率比注入式攻击平均低25.13%以上，能有效规避现有防御。标准化对策仅提供部分缓解，证实了攻击的鲁棒性。

Conclusion: SET后门攻击对神经代码模型构成严重安全威胁，现有防御措施不足。研究结果强调了需要进一步研究针对SET攻击的可扩展防御机制。

Abstract: Neural code models have been increasingly incorporated into software development processes. However, their susceptibility to backdoor attacks presents a significant security risk. The state-of-the-art understanding focuses on injection-based attacks, which insert anomalous patterns into software code. These attacks can be neutralized by standard sanitization techniques. This status quo may lead to a false sense of security regarding backdoor attacks. In this paper, we introduce a new kind of backdoor attacks, dubbed Semantically-Equivalent Transformation (SET)-based backdoor attacks, which use semantics-preserving low-prevalence code transformations to generate stealthy triggers. We propose a framework to guide the generation of such triggers. Our experiments across five tasks, six languages, and models like CodeBERT, CodeT5, and StarCoder show that SET-based attacks achieve high success rates (often >90%) while preserving model utility. The attack proves highly stealthy, evading state-of-the-art defenses with detection rates on average over 25.13% lower than injection-based counterparts. We evaluate normalization-based countermeasures and find they offer only partial mitigation, confirming the attack's robustness. These results motivate further investigation into scalable defenses tailored to SET-based attacks.

</details>


### [21] [A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis](https://arxiv.org/abs/2512.19481)
*Katharina Stengg,Christian Macho,Martin Pinzger*

Main category: cs.SE

TL;DR: 研究评估GPT-5和GPT-5-mini在预测源代码变更影响方面的能力，发现两者表现不佳，但GPT-5优于GPT-5-mini，提供diff信息能略微提升性能。


<details>
  <summary>Details</summary>
Motivation: 理解源代码变更及其对其他代码实体的影响是软件开发中的关键技能，但当前分析通常需要手动进行且耗时。虽然大型语言模型在代码分析任务中显示出潜力，但它们在理解代码变更影响方面的能力尚未充分探索。

Method: 构建包含种子变更、变更对和变更类型信息的数据集，评估GPT-5和GPT-5-mini在两种配置下的表现：(1)种子变更信息和父提交树；(2)种子变更信息、父提交树和每个种子变更的diff块。

Result: 两种LLM在两个实验中都表现不佳，但GPT-5优于GPT-5-mini。提供diff块信息有助于两个模型略微提升性能。

Conclusion: 当前的大型语言模型在预测代码变更影响方面能力有限，需要进一步研究改进方法。

Abstract: Understanding source code changes and their impact on other code entities is a crucial skill in software development. However, the analysis of code changes and their impact is often performed manually and therefore is time-consuming. Recent advancements in AI, and in particular large language models (LLMs) show promises to help developers in various code analysis tasks. However, the extent to which this potential can be utilized for understanding code changes and their impact is underexplored. To address this gap, we study the capabilities of GPT-5 and GPT-5-mini to predict the code entities impacted by given source code changes. We construct a dataset containing information about seed-changes, change pairs, and change types for each commit. Existing datasets lack crucial information about seed changes and impacted code entities. Our experiments evaluate the LLMs in two configurations: (1) seed-change information and the parent commit tree and (2) seed-change information, the parent commit tree, and the diff hunk of each seed change. We found that both LLMs perform poorly in the two experiments, whereas GPT-5 outperforms GPT-5-mini. Furthermore, the provision of the diff hunks helps both models to slightly improve their performance.

</details>


### [22] [Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models](https://arxiv.org/abs/2512.19509)
*Shangbo Yun,Xiaodong Gu,Jianghong Huang,Beijun Shen*

Main category: cs.SE

TL;DR: 提出基于嵌入的框架来揭示编程语言的深层语言关系，并利用这些关系改进多语言代码LLM的训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只是简单聚合多语言代码数据进行训练，很少探索编程语言之间的深层关系以及如何利用这些关系优化代码LLM的训练和推理。

Method: 定义21个主要语言特征，使用LLM生成特征对齐的跨语言代码样本，通过嵌入构建相似度矩阵并进行层次聚类，揭示语言关系。基于此提出三种训练策略：跨语言迁移学习、语言邻近引导的课程学习、基于质心的中间代码翻译。

Result: 分析揭示了编程语言的清晰层次结构，密切相关的语言形成明确定义的聚类（如C、C++、Java、Swift），Go表现出最高的跨语言相似性。在4个代码智能任务上的实验表明，所提方法显著提升了多语言LLM性能。

Conclusion: 这项工作提供了编程语言的通用视角，并推进了更有效的多语言代码LLM训练策略，为理解编程语言关系和优化模型训练提供了新思路。

Abstract: The rapid proliferation of diverse programming languages presents both opportunities and challenges for developing multilingual code LLMs. While existing techniques often train code LLMs by simply aggregating multilingual code data, few explore the deeper relationships between programming languages(PLs) and how such relationships can be utilized to optimize the training and inference of code LLMs. In this work, we investigate 2 fundamental questions: 1) What are the deep linguistic relationships among PLs? and 2) How can these relationships be leveraged to improve multilingual code LLMs? We propose an embedding-based framework to uncover the latent families of PLs. Our approach begins by defining 21 primary linguistic features of programming languages, such as variable definition, control structures, and method declarations, and then employs LLMs to generate feature-aligned code samples across multiple languages. By embedding these semantically parallel code snippets from 19 languages, we construct a similarity matrix and perform hierarchical clustering to uncover inherent language relationships. Our analysis reveals clear hierarchical structures among programming languages. Closely related languages form well-defined clusters (e.g., C, C++, Java, and Swift group together), while Go exhibits as a central language with the highest cross-language similarity. Building on the uncovered language families, we propose three strategies to enhance multilingual LLM training: transfer learning across linguistically related languages, linguistic proximity-guided curriculum learning, and centroid-based intermediary code translation. Experiments on 4 code intelligence tasks demonstrate that our methods significantly improve multilingual LLM performance. This work offers a universal perspective on programming languages and advances more effective strategies for multilingual code LLM training.

</details>


### [23] [More code, less validation: Risk factors for over-reliance on AI coding tools among scientists](https://arxiv.org/abs/2512.19644)
*Gabrielle O'Brien,Alexis Parker,Nasir Eisty,Jeffrey Carver*

Main category: cs.SE

TL;DR: 科学家使用生成式AI编程工具的研究：学生和初级程序员采用率最高，偏好通用对话界面而非专业开发工具，经验不足者感知生产力更高但可能忽视代码验证


<details>
  <summary>Details</summary>
Motivation: 科学研究需要编程，但科学家普遍缺乏软件开发的系统训练。生成式AI代码生成工具可能提供支持，但用户研究表明存在过度依赖风险，特别是在经验不足的用户中。需要了解科学家程序员如何采用这些工具、偏好模式以及影响感知生产力的因素。

Method: 对868名从事编程的科学家进行问卷调查，研究内容包括：采用模式、工具偏好、与感知生产力相关的因素。分析不同经验水平、开发实践使用情况与生产力感知的关系。

Result: 1. 采用率最高的是学生和经验较少的程序员，不同领域有差异；2. 科学家程序员强烈偏好通用对话界面（如ChatGPT）而非专业开发工具；3. 经验不足和较少使用开发实践（测试、代码审查、版本控制）与更高的感知生产力相关；4. 这些因素相互作用，表明正式实践可能部分弥补经验不足；5. 感知生产力的最强预测因素是每次接受的生成代码行数。

Conclusion: 使用生成式AI的科学家程序员可能通过代码生成而非验证来衡量生产力，这引发了对研究代码完整性的担忧。需要关注工具使用中的质量保证问题，特别是在科学计算领域。

Abstract: Programming is essential to modern scientific research, yet most scientists report inadequate training for the software development their work demands. Generative AI tools capable of code generation may support scientific programmers, but user studies indicate risks of over-reliance, particularly among inexperienced users. We surveyed 868 scientists who program, examining adoption patterns, tool preferences, and factors associated with perceived productivity. Adoption is highest among students and less experienced programmers, with variation across fields. Scientific programmers overwhelmingly prefer general-purpose conversational interfaces like ChatGPT over developer-specific tools. Both inexperience and limited use of development practices (like testing, code review, and version control) are associated with greater perceived productivity-but these factors interact, suggesting formal practices may partially compensate for inexperience. The strongest predictor of perceived productivity is the number of lines of generated code typically accepted at once. These findings suggest scientific programmers using generative AI may gauge productivity by code generation rather than validation, raising concerns about research code integrity.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [24] [A logic for default deontic reasoning](https://arxiv.org/abs/2512.18824)
*Mario Piazza,Andrea Sabatini*

Main category: cs.LO

TL;DR: 本文提出了一种基于默认逻辑的非模态证明论框架，通过受控矢列（带有控制集的矢列）来处理动态环境中的不完全信息和冲突规范推理问题。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，智能体需要在动态、信息不完全的环境中导航，同时处理不稳定、上下文依赖且经常冲突的规范。现有方法难以有效处理这种复杂的规范推理问题。

Method: 引入受控矢列演算框架：矢列带有控制集（公式集合），记录条件和约束；结合表示默认和规范的额外逻辑规则；支持局部可靠性检查；证明收缩和非分析切割的可接纳性。

Result: 证明了受控矢列演算满足收缩和非分析切割的可接纳性；建立了相对于默认理论和规范系统中可信后果的强完备性；展示了框架在解决道义冲突和捕捉动态道义概念方面的灵活表达能力。

Conclusion: 受控矢列演算为处理动态环境中的道义推理提供了一个灵活且表达力强的证明论基础，能够有效处理规范冲突和动态道义概念。

Abstract: In many real-life settings, agents must navigate dynamic environments while reasoning under incomplete information and acting on a corpus of unstable, context-dependent, and often conflicting norms. We introduce a general, non-modal, proof-theoretic framework for deontic reasoning grounded in default logic. Its central feature is the notion of controlled sequent - a sequent annotated with sets of formulas (control sets) that prescribe what should or should not be entailed by the formulas in the antecedent. When combined with distinct extra-logical rules representing defaults and norms, these control sets record the conditions and constraints governing their applicability, thereby enabling local soundness checks for derived sequents. We prove that controlled sequent calculi satisfies admissibility of contraction and non-analytic cuts, and we establish their strong completeness with respect to credulous consequence in default theories and normative systems. Finally, we illustrate in depth how controlled sequent calculi provide a flexible and expressive basis for resolving deontic conflicts and capturing dynamic deontic notions via appropriate extra-logical rules.

</details>


### [25] [Modular Automatic Complexity Analysis of Recursive Integer Programs](https://arxiv.org/abs/2512.18851)
*Nils Lommen,Jürgen Giesl*

Main category: cs.LO

TL;DR: 扩展模块化复杂度分析方法，支持带函数调用的整数程序，通过新型排名函数处理递归部分


<details>
  <summary>Details</summary>
Motivation: 之前的工作只能分析无递归调用的整数程序，需要扩展到支持带函数调用的递归程序

Method: 结合现有命令式程序分析技术与新型排名函数，模块化处理递归部分

Result: 在复杂度分析工具KoAT中实现，展示了该组合方法的强大能力

Conclusion: 成功将模块化复杂度分析方法扩展到递归设置，为分析带函数调用的整数程序提供了新工具

Abstract: In earlier work, we developed a modular approach for automatic complexity analysis of integer programs. However, these integer programs do not allow non-tail recursive calls or subprocedures. In this paper, we consider integer programs with function calls and present a natural extension of our modular complexity analysis approach to the recursive setting based on a new form of ranking functions. Hence, our approach combines already existing powerful techniques on the "imperative" parts of the program and our novel ranking functions on the recursive parts. The strength of this combination is demonstrated by our implementation in the complexity analysis tool KoAT.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [26] [Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs](https://arxiv.org/abs/2512.18134)
*Rupanshu Soi,Rohan Yadav,Fredrik Kjolstad,Alex Aiken,Maryam Mehri Dehnavi,Michael Garland,Michael Bauer*

Main category: cs.PL

TL;DR: Twill系统通过将软件流水线（SWP）和warp专业化（WS）建模为联合优化问题，自动为GPU程序生成最优调度方案


<details>
  <summary>Details</summary>
Motivation: 现代GPU架构日益复杂，包含矩阵乘法专用单元和数据移动单元，需要复杂调度来充分利用所有硬件资源。目前依赖脆弱的编译启发式方法和人工直觉，缺乏对解决方案空间的深入理解

Method: 将SWP和WS建模为联合优化问题，使用现成的约束求解器进行整体求解。Twill系统自动为迭代程序推导最优SWP和WS调度，无需启发式方法，可扩展到新GPU架构

Result: Twill能够重新发现并证明专家为Flash Attention在NVIDIA Hopper和Blackwell GPU架构上手动开发的SWP和WS调度是最优的

Conclusion: Twill是第一个自动为广泛迭代程序生成最优SWP和WS调度方案的系统，无启发式方法，易于扩展，保证最优性，解决了GPU调度优化的关键挑战

Abstract: GPU architectures have continued to grow in complexity, with recent incarnations introducing increasingly powerful fixed-function units for matrix multiplication and data movement to accompany highly parallel general-purpose cores. To fully leverage these machines, software must use sophisticated schedules that maximally utilize all hardware resources. Since realizing such schedules is complex, both programmers and compilers routinely employ program transformations, such as software pipelining (SWP) and warp specialization (WS), to do so in practice. However, determining how best to use SWP and WS in combination is a challenging problem that is currently handled through a mix of brittle compilation heuristics and fallible human intuition, with little insight into the space of solutions. To remedy this situation, we introduce a novel formulation of SWP and WS as a joint optimization problem that can be solved holistically by off-the-shelf constraint solvers. We reify our approach in Twill, the first system that automatically derives optimal SWP and WS schedules for a large class of iterative programs. Twill is heuristic-free, easily extensible to new GPU architectures, and guaranteed to produce optimal schedules. We show that Twill can rediscover, and thereby prove optimal, the SWP and WS schedules manually developed by experts for Flash Attention on both the NVIDIA Hopper and Blackwell GPU architectures.

</details>


### [27] [DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs](https://arxiv.org/abs/2512.18842)
*Aleksandr Fedchin,Antero Mejr,Hari Sundar,Jeffrey S. Foster*

Main category: cs.PL

TL;DR: DafnyMPI：基于Dafny语言的可扩展MPI程序形式化验证框架，可证明死锁自由、终止性和功能等价性


<details>
  <summary>Details</summary>
Motivation: MPI广泛用于高性能并行编程，但编写无bug的MPI软件仍然困难，需要形式化验证方法来提高可靠性

Method: 基于Dafny验证语言构建MPI库，要求用户预先指定通信拓扑并验证通信原语的前置条件，使用核心演算形式化，通过rely-guarantee推理证明功能等价

Result: 证明了前置条件足以保证死锁自由，通过标准Dafny技术证明终止性和无运行时错误，成功验证了三个典型偏微分方程的数值解

Conclusion: DafnyMPI展示了如何使形式化验证适用于更广泛的程序类别，为并行和并发系统的软件验证提供了新工具

Abstract: The Message Passing Interface (MPI) is widely used in parallel, high-performance programming, yet writing bug-free software that uses MPI remains difficult. We introduce DafnyMPI, a novel, scalable approach to formally verifying MPI software. DafnyMPI allows proving deadlock freedom, termination, and functional equivalence with simpler sequential implementations. In contrast to existing specialized frameworks, DafnyMPI avoids custom concurrency logics and instead relies on Dafny, a verification-ready programming language used for sequential programs, extending it with concurrent reasoning abilities. DafnyMPI is implemented as a library that enables safe MPI programming by requiring users to specify the communication topology upfront and to verify that calls to communication primitives such as MPI_ISEND and MPI_WAIT meet their preconditions. We formalize DafnyMPI using a core calculus and prove that the preconditions suffice to guarantee deadlock freedom. Functional equivalence is proved via rely-guarantee reasoning over message payloads and a system that guarantees safe use of read and write buffers. Termination and the absence of runtime errors are proved using standard Dafny techniques. To further demonstrate the applicability of DafnyMPI, we verify numerical solutions to three canonical partial differential equations. We believe DafnyMPI demonstrates how to make formal verification viable for a broader class of programs and provides proof engineers with additional tools for software verification of parallel and concurrent systems.

</details>
