<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Rewriting Systems on Arbitrary Monoids](https://arxiv.org/abs/2601.10564)
*Eduardo Magalhães*

Main category: cs.FL

TL;DR: 该论文引入幺半群重写系统（MRS），将字符串重写推广到任意幺半群环境，并建立了Noetherian Confluent MRS的2-范畴与幺半群范畴之间的双伴随关系，最后通过广义初等Tietze变换完全分类了给定幺半群的所有Noetherian Confluent MRS表示。


<details>
  <summary>Details</summary>
Motivation: 将字符串重写推广到任意幺半群环境，部分动机来自逻辑考虑：自由幺半群类不是一阶可公理化的，因此在应用一阶方法处理重写表示时，"在自由设置下工作"无法内部处理。

Method: 1. 引入幺半群重写系统（MRS），在任意环境幺半群而非自由幺半群上定义约简；2. 定义Noetherian Confluent MRS的2-范畴NCRS₂；3. 建立NCRS₂与幺半群范畴Mon之间的双伴随关系；4. 引入广义初等Tietze变换（GETTs）来分类给定幺半群的所有Noetherian Confluent MRS表示。

Result: 1. 证明了NCRS₂与Mon之间存在规范的双伴随关系；2. 证明了任意两个幺半群表示都可以通过（可能无限的）广义初等Tietze变换序列连接，从而完全分类了给定幺半群的所有Noetherian Confluent MRS表示。

Conclusion: 该研究将字符串重写推广到幺半群环境，建立了范畴理论框架，并通过广义初等Tietze变换完全分类了幺半群表示，为幺半群重写理论提供了系统的范畴化方法。

Abstract: In this paper, we introduce monoidal rewriting systems (MRS), an abstraction of string rewriting in which reductions are defined over an arbitrary ambient monoid rather than a free monoid of words. This shift is partly motivated by logic: the class of free monoids is not first-order axiomatizable, so "working in the free setting" cannot be treated internally when applying first-order methods to rewriting presentations.
  To analyze these systems categorically, we define $\mathbf{NCRS_2}$ as the 2-category of Noetherian Confluent MRS. We then prove the existence of a canonical biadjunction between $\mathbf{NCRS_2}$ and $\mathbf{Mon}$.
  Finally, we classify all Noetherian Confluent MRS that present a given fixed monoid. For this, we introduce Generalized Elementary Tietze Transformations (GETTs) and prove that any two presentations of a monoid are connected by a (possibly infinite) sequence of these transformations, yielding a complete characterization of generating systems up to GETT-equivalence.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Putting green software principles into practice](https://arxiv.org/abs/2601.09741)
*James Uther*

Main category: cs.SE

TL;DR: 论文探讨了在实际产品中实施绿色软件的实践方法，特别是利用无服务器系统的成本驱动效率提升


<details>
  <summary>Details</summary>
Motivation: 虽然测量和减少计算系统CO2排放的需求和理论方法已被理解，但实际应用案例仍然有限，需要探索在真实产品中实施绿色软件的具体实践

Method: 在公有云上运行的实际产品中实施绿色软件，特别利用无服务器系统的成本影响来驱动效率提升，通过实际解决方案的探索

Result: 提出了在该项目中有效的"绿色软件"原则，展示了如何在实际产品中成功实施绿色软件实践

Conclusion: 通过实际案例研究，证明了利用无服务器系统的成本驱动机制可以有效促进绿色软件实践，为其他项目提供了可借鉴的原则和方法

Abstract: The need and theoretical methods for measuring and reducing CO2 emitted by computing systems are well understood, but real-world examples are still limited. We describe a journey towards green software for a live product running on a public cloud. We discuss practical solutions found, in particular using the cost implications of serverless systems to drive efficiency. We end with some `green software' principles that worked well in this project.

</details>


### [3] [A Governance Model for IoT Data in Global Manufacturing](https://arxiv.org/abs/2601.09744)
*Vignesh Alagappan*

Main category: cs.SE

TL;DR: 提出一种面向全球制造环境中工业物联网平台的联邦治理模型，强调契约驱动的互操作性、策略即代码执行和资产中心责任制，解决分布式运营所有权下的治理挑战


<details>
  <summary>Details</summary>
Motivation: 全球制造环境中的工业物联网平台产生大量运营数据，虽然数据摄取和存储能力已成熟，但企业在规模化治理物联网数据方面仍面临系统性挑战。这些挑战并非源于工具限制，而是缺乏与分布式运营所有权、异构源系统和边缘持续变化现实相适应的治理模型

Method: 提出联邦治理模型，强调契约驱动的互操作性、策略即代码执行和资产中心责任制。该模型在架构边界实施治理，实现语义一致性、质量保证和法规遵从，无需集中控制运营技术系统。基于制造物联网需求和约束分析，贡献系统架构和设计框架

Result: 提出了一个完整的联邦治理模型，包括系统架构和设计框架，能够解决分布式运营环境中的物联网数据治理挑战。该模型支持语义一致性、质量保证和法规遵从，同时保持运营系统的分布式特性

Conclusion: 该联邦治理模型为全球制造组织提供了一种有效的物联网数据治理方法，通过契约驱动和策略即代码机制，在保持分布式运营所有权的同时实现治理目标。实证验证是未来的工作方向

Abstract: Industrial IoT platforms in global manufacturing environments generate continuous operational data across production assets, utilities, and connected products. While data ingestion and storage capabilities have matured significantly, enterprises continue to face systemic challenges in governing IoT data at scale. These challenges are not rooted in tooling limitations but in the absence of a governance model that aligns with the realities of distributed operational ownership, heterogeneous source systems, and continuous change at the edge. This paper presents a federated governance model that emphasizes contract-driven interoperability, policy-as-code enforcement, and asset-centric accountability across global manufacturing organizations. The model addresses governance enforcement at architectural boundaries, enabling semantic consistency, quality assurance, and regulatory compliance without requiring centralized control of operational technology systems. This work contributes a systems architecture and design framework grounded in analysis of manufacturing IoT requirements and constraints; empirical validation remains future work

</details>


### [4] [Enhancing Formal Software Specification with Artificial Intelligence](https://arxiv.org/abs/2601.09745)
*Antonio Abu Nassar,Eitan Farchi*

Main category: cs.SE

TL;DR: 使用自然语言增强轻量级数学符号作为中间规范语言，通过AI审查和精炼，显著降低形式化规范成本，实现早期验证和正确性设计


<details>
  <summary>Details</summary>
Motivation: 形式化软件规范虽然能实现早期错误检测和显式不变式，但由于符号开销大和传统形式化语言需要专业知识，工业应用有限。需要找到平衡形式化严谨性和实用性的方法。

Method: 使用自然语言增强轻量级数学符号（LaTeX格式）作为中间规范语言，通过AI进行审查和精炼，然后生成代码。应用于组织知识增长的非平凡模拟案例。

Result: 该方法实现了早期验证、显式不变式和设计正确性，显著减少开发工作量，并在首次尝试中产生正确实现。

Conclusion: AI的进步使得在显著降低成本的同时保留形式化规范的许多好处成为可能，需要明确区分哪些需要形式化控制的严谨性和哪些不需要。

Abstract: Formal software specification is known to enable early error detection and explicit invariants, yet it has seen limited industrial adoption due to its high notation overhead and the expertise required to use traditional formal languages. This paper presents a case study showing that recent advances in artificial intelligence make it possible to retain many of the benefits of formal specification while substantially reducing these costs. The necessity of a clear distinction between what is controlled by the system analyst and can highly benefits from the rigor of formal specification and what need not be controlled is demonstrated. We use natural language augmented with lightweight mathematical notation and written in \LaTeX\ as an intermediate specification language, which is reviewed and refined by AI prior to code generation. Applied to a nontrivial simulation of organizational knowledge growth, this approach enables early validation, explicit invariants, and correctness by design, while significantly reducing development effort and producing a correct implementation on the first attempt.

</details>


### [5] [R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation](https://arxiv.org/abs/2601.09749)
*Suriya Sureshkumar*

Main category: cs.SE

TL;DR: R-LAM是一个为科学工作流自动化设计的可重复性约束框架，通过结构化动作模式、确定性执行策略和显式溯源跟踪，解决大型动作模型在科学场景中的可重复性、可审计性和确定性执行问题。


<details>
  <summary>Details</summary>
Motivation: 大型动作模型在自动化科学工作流方面很有前景，但科学工作流对可重复性、可审计性和确定性执行有严格要求，而通用的基于LLM的智能体无法满足这些要求。不受约束的动作生成可能导致静默状态变化、非确定性执行和不可重复的实验结果。

Method: R-LAM引入了结构化动作模式、确定性执行策略和显式溯源跟踪，确保每个动作和中间产物都可审计和可重放。该框架支持故障感知执行循环和受控工作流分叉，允许迭代实验而不损害可重复性。

Result: R-LAM被实现为一个轻量级Python框架并作为开源PyPI包发布。在代表性科学工作流的实验评估中，R-LAM相比不受约束的基于LLM的智能体提高了可重复性成功率和执行可靠性，同时保持对工作流执行的自适应控制。

Conclusion: R-LAM为科学工作流自动化提供了一个可重复性约束框架，解决了大型动作模型在科学应用中的关键限制，通过结构化控制和溯源机制实现了可审计、可重放的科学实验自动化。

Abstract: Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings.
  In this paper, we propose R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility.
  We implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation of representative scientific workflows demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution.

</details>


### [6] [SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments](https://arxiv.org/abs/2601.09750)
*Robert K. Strehlow,Tobias Küster,Oskar F. Kupke,Brandon Llanque Kurps,Fikret Sivrikaya,Sahin Albayrak*

Main category: cs.SE

TL;DR: SAGE是一个基于OPACA框架的对话AI系统，专注于动态工具集成和零样本提示方法，通过模块化设计支持多种模型和策略切换。


<details>
  <summary>Details</summary>
Motivation: 现实应用中LLM需要访问实时工具，但现有工具集成方式固定且难以适应快速变化的软件环境，需要动态工具集成和可靠的零样本提示方法。

Method: 基于OPACA框架构建SAGE系统，支持动态工具发现和执行，采用模块化设计允许切换不同模型（GPT、LLAMA等），实现多种任务解决策略和提示方法。

Result: 在综合基准服务上评估了多种任务解决策略，结果显示出不同策略的明显优势和劣势，整体表现令人满意。

Conclusion: SAGE和OPACA框架提供了灵活的工具集成方案，支持动态工具添加和多种提示策略，开源实现为LLM工具集成研究提供了实用平台。

Abstract: Large language models (LLMs) have proven to work well in question-answering scenarios, but real-world applications often require access to tools for live information or actuation. For this, LLMs can be extended with tools, which are often defined in advance, also allowing for some fine-tuning for specific use cases. However, rapidly evolving software landscapes and individual services require the constant development and integration of new tools. Domain- or company-specific tools can greatly elevate the usefulness of an LLM, but such custom tools can be problematic to integrate, or the LLM may fail to reliably understand and use them. For this, we need strategies to define new tools and integrate them into the LLM dynamically, as well as robust and scalable zero-shot prompting methods that can make use of those tools in an efficient manner. In this paper, we present SAGE, a specialized conversational AI interface, based on the OPACA framework for tool discovery and execution. The integration with OPACA makes it easy to add new tools or services for the LLM to use, while SAGE itself presents rich extensibility and modularity. This not only provides the ability to seamlessly switch between different models (e.g. GPT, LLAMA), but also to add and select prompting methods, involving various setups of differently prompted agents for selecting and executing tools and evaluating the results. We implemented a number of task-solving strategies, making use of agentic concepts and prompting methods in various degrees of complexity, and evaluated those against a comprehensive set of benchmark services. The results are promising and highlight the distinct strengths and weaknesses of different task-solving strategies. Both SAGE and the OPACA framework, as well as the different benchmark services and results, are available as Open Source/Open Data on GitHub.

</details>


### [7] [Investigating Tool-Memory Conflicts in Tool-Augmented LLMs](https://arxiv.org/abs/2601.09760)
*Jiali Cheng,Rui Pan,Hadi Amiri*

Main category: cs.SE

TL;DR: 论文提出了一种新的知识冲突类型——工具-记忆冲突(TMC)，即工具增强型大语言模型内部参数知识与外部工具知识之间的矛盾，并发现现有方法无法有效解决此类冲突。


<details>
  <summary>Details</summary>
Motivation: 工具增强型大语言模型虽然应用广泛，但可能面临知识冲突问题。作者发现现有研究尚未充分探讨当模型内部参数知识与外部工具知识相矛盾时的冲突情况，特别是在STEM相关任务中这种冲突尤为明显。

Method: 作者首先定义了工具-记忆冲突(TMC)这一新概念，然后评估了现有LLM在此类冲突下的表现，分析了不同条件下工具知识和参数知识的优先级差异，最后测试了基于提示和检索增强生成(RAG)的现有冲突解决技术。

Result: 研究发现：1）现有LLM确实存在工具-记忆冲突问题，尤其在STEM任务中表现明显；2）不同条件下工具知识和参数知识会被不同优先级处理；3）现有的提示方法和RAG方法都无法有效解决工具-记忆冲突。

Conclusion: 工具-记忆冲突是工具增强型LLM面临的重要挑战，现有冲突解决技术对此无效，需要开发新的方法来处理这种特定类型的知识冲突，特别是在STEM领域。

Abstract: Tool-augmented large language models (LLMs) have powered many applications. However, they are likely to suffer from knowledge conflict. In this paper, we propose a new type of knowledge conflict -- Tool-Memory Conflict (TMC), where the internal parametric knowledge contradicts with the external tool knowledge for tool-augmented LLMs. We find that existing LLMs, though powerful, suffer from TMC, especially on STEM-related tasks. We also uncover that under different conditions, tool knowledge and parametric knowledge may be prioritized differently. We then evaluate existing conflict resolving techniques, including prompting-based and RAG-based methods. Results show that none of these approaches can effectively resolve tool-memory conflicts.

</details>


### [8] [Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation](https://arxiv.org/abs/2601.09762)
*Zhiyi Xue,Xiaohong Chen,Min Zhang*

Main category: cs.SE

TL;DR: RAFT框架通过多LLM自适应净化聚合策略，从复杂法规中自动形式化需求并生成合规测试，显著提升自动化水平并减少人工成本。


<details>
  <summary>Details</summary>
Motivation: 在高度监管领域，合规测试主要依赖人工将复杂法规转化为可执行测试用例，现有混合方法虽然使用形式化模型约束LLM，但仍需昂贵的人工建模成本。

Method: RAFT采用自适应净化-聚合策略，从多个LLM中提取隐性监管知识，整合为领域元模型、形式化需求表示和可测试性约束三个工件，动态注入提示中以指导高精度需求形式化和自动化测试生成。

Result: 在金融、汽车和电力领域的实验表明，RAFT达到专家级性能，显著优于现有最先进方法，同时减少了整体生成和审查时间。

Conclusion: RAFT通过自动形式化需求和生成合规测试，解决了监管领域自动化测试的挑战，减少了人工建模依赖，实现了可靠的高性能合规测试自动化。

Abstract: Compliance testing in highly regulated domains is crucial but largely manual, requiring domain experts to translate complex regulations into executable test cases. While large language models (LLMs) show promise for automation, their susceptibility to hallucinations limits reliable application. Existing hybrid approaches mitigate this issue by constraining LLMs with formal models, but still rely on costly manual modeling. To solve this problem, this paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation via explicating tacit regulatory knowledge from multiple LLMs. RAFT employs an Adaptive Purification-Aggregation strategy to explicate tacit regulatory knowledge from multiple LLMs and integrate it into three artifacts: a domain meta-model, a formal requirements representation, and testability constraints. These artifacts are then dynamically injected into prompts to guide high-precision requirement formalization and automated test generation. Experiments across financial, automotive, and power domains show that RAFT achieves expert-level performance, substantially outperforms state-of-the-art (SOTA) methods while reducing overall generation and review time.

</details>


### [9] [LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities](https://arxiv.org/abs/2601.09822)
*Yongjian Tang,Thomas Runkler*

Main category: cs.SE

TL;DR: 本文系统综述了基于大语言模型的多智能体系统在软件工程全生命周期中的应用，包括需求工程、代码生成、静态检查、测试和调试等环节，探讨了语言模型选择、评估基准、框架协议等关键技术，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型取得了显著进展，但复杂的软件工程任务需要更协作和专门化的方法。当前需要系统性地探索基于LLM的多智能体系统在软件工程领域的应用现状和未来发展方向。

Method: 采用概念论文的系统综述方法，全面考察LLM-based多智能体系统在软件开发生命周期（SDLC）各阶段的应用，包括需求工程、代码生成、静态代码检查、测试和调试等，并分析语言模型选择、评估基准、智能体框架和通信协议等关键技术。

Result: 系统梳理了LLM-based多智能体系统在软件工程领域的应用现状，识别了当前面临的关键挑战，包括多智能体编排、人机协调、计算成本优化和有效数据收集等问题。

Conclusion: 本文为研究者和从业者提供了软件工程领域智能体系统前沿景观的宝贵见解，并指出了未来研究方向，包括多智能体编排、人机协调、计算成本优化和有效数据收集等关键领域。

Abstract: Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. We delve into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. Furthermore, we identify key challenges and outline future research opportunities, with a focus on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain.

</details>


### [10] [Adoption and Evolution of Code Style and Best Programming Practices in Open-Source Projects](https://arxiv.org/abs/2601.09832)
*Alvari Kupari,Nasser Giacaman,Valerio Terragni*

Main category: cs.SE

TL;DR: 分析1036个热门Java开源项目，研究代码风格和编程实践的采用与演变，发现普遍存在违反情况，Javadoc和命名问题最常见，Google风格指南违规较多，声称遵循代码风格的项目合规性略高。


<details>
  <summary>Details</summary>
Motivation: 代码风格约定对软件质量至关重要，但实际采用情况缺乏大规模实证研究。需要了解开源Java项目中代码风格和编程实践的采用程度、演变趋势以及常见违规类型。

Method: 分析GitHub上1036个热门开源Java项目，研究代码风格和编程实践的采用与演变。对活跃仓库进行月度跟踪，监测编码标准遵循情况的变化。使用静态分析工具检测违规。

Result: 发现普遍存在代码风格违规，Javadoc和命名违规最常见。Google Java风格指南的许多违规被现代静态分析工具忽略。声称遵循代码风格的项目整体合规性略高。

Conclusion: 开源Java社区在代码风格采用方面存在改进空间，特别是Javadoc和命名规范。需要更好的工具支持来检测Google风格指南违规。研究为改进Java项目代码质量提供了重要见解。

Abstract: Following code style conventions in software projects is essential for maintaining overall code quality. Adhering to these conventions improves maintainability, understandability, and extensibility. Additionally, following best practices during software development enhances performance and reduces the likelihood of errors. This paper analyzes 1,036 popular open-source JAVA projects on GITHUB to study how code style and programming practices are adopted and evolve over time, examining their prevalence and the most common violations. Additionally, we study a subset of active repositories on a monthly basis to track changes in adherence to coding standards over time. We found widespread violations across repositories, with Javadoc and Naming violations being the most common. We also found a significant number of violations of the GOOGLE Java Style Guide in categories often missed by modern static analysis tools. Furthermore, repositories claiming to follow code-style practices exhibited slightly higher overall adherence to code-style and best-practices. The results provide valuable insights into the adoption of code style and programming practices, highlighting key areas for improvement in the open-source development community. Furthermore, the paper identifies important lessons learned and suggests future directions for improving code quality in JAVA projects.

</details>


### [11] [On Fun for Teaching Large Programming Courses](https://arxiv.org/abs/2601.09842)
*Walid Maalej*

Main category: cs.SE

TL;DR: 提出10种实体趣味活动，用于大型软件工程课程中提升学生参与度和概念理解，通过三年500+学生实践验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统大班授课模式成本效益高但学生容易分心、参与度低，教师互动机会有限，需要创新方法来激活学生并帮助理解抽象软件概念

Method: 开发了10种物理趣味活动目录，如LA-OLA算法模拟、纸飞机模拟对象消息和指针、教室遍历树或递归结构等；在500+学生课程中连续三年实践，并访谈15名前学生和14名全球教育专家

Result: 趣味活动能帮助学生保持专注、记忆关键概念并进行反思；但活动需要简洁且与教学内容明确关联才能确保接受度和有效性

Conclusion: 物理趣味活动是提升大型软件工程课程教学效果的有效方法，但设计时需要注重简洁性和概念关联性

Abstract: Teaching software development basics to hundreds of students in a frontal setting is cost-efficient and thus still common in universities. However, in a large lecture hall, students can easily get bored, distracted, and disengaged. The frontal setting can also frustrate lecturers since interaction opportunities are limited and hard to scale. Fun activities can activate students and, if well designed, can also help remember and reflect on abstract software development concepts. We present a novel catalogue of ten physical fun activities, developed over years to reflect on basic programming and software development concepts. The catalogue includes the execution of a LA-OLA algorithm as in stadiums, using paper planes to simulate object messages and pointers, and traversing a lecture hall as a tree or a recursive structure. We report our experience of using the activities in a large course with 500+ students three years in a row. We also conducted an interview study with 15 former students of the course and 14 experienced educators from around the globe. The results suggest that the fun activities can enable students to stay focused, remember key concepts, and reflect afterwards. However, keeping the activities concise and clearly linked to the concepts taught seems to be key to their acceptance and effectiveness.

</details>


### [12] [Beyond Strict Rules: Assessing the Effectiveness of Large Language Models for Code Smell Detection](https://arxiv.org/abs/2601.09873)
*Saymon Souza,Amanda Santana,Eduardo Figueiredo,Igor Muzetti,João Eduardo Montandon,Lionel Briand*

Main category: cs.SE

TL;DR: 评估四种大语言模型（DeepSeek-R1、GPT-5 mini、Llama-3.3、Qwen2.5-Code）在检测九种代码异味方面的效果，并提出结合LLM与静态分析工具的混合策略


<details>
  <summary>Details</summary>
Motivation: 代码异味会影响软件可维护性，增加开发成本并影响可靠性。虽然静态分析工具规则固定，但LLM能够提供灵活、可适应的检测策略，然而LLM在代码异味检测方面的应用尚未充分探索

Method: 1. 评估四种LLM在30个Java项目中检测九种代码异味的效果；2. 创建包含268个代码异味候选的基准数据集，由76名开发者人工检查；3. 提出并评估结合LLM与静态分析工具的混合检测策略

Result: 1. LLM在结构简单的异味（如Large Class、Long Method）上表现良好；2. 不同LLM和工具在不同代码异味上表现各异；3. 混合策略在九种异味中的五种上F1分数优于单独使用LLM或工具；4. 混合策略在复杂异味上会产生更多误报

Conclusion: 最优检测策略取决于代码异味检测的主要优先级是召回率还是精确率。LLM在结构简单异味上表现良好，而混合策略在某些情况下能提供更好的综合性能，但需权衡误报率

Abstract: Code smells are symptoms of potential code quality problems that may affect software maintainability, thus increasing development costs and impacting software reliability. Large language models (LLMs) have shown remarkable capabilities for supporting various software engineering activities, but their use for detecting code smells remains underexplored. However, unlike the rigid rules of static analysis tools, LLMs can support flexible and adaptable detection strategies tailored to the unique properties of code smells. This paper evaluates the effectiveness of four LLMs -- DeepSeek-R1, GPT-5 mini, Llama-3.3, and Qwen2.5-Code -- for detecting nine code smells across 30 Java projects. For the empirical evaluation, we created a ground-truth dataset by asking 76 developers to manually inspect 268 code-smell candidates. Our results indicate that LLMs perform strongly for structurally straightforward smells, such as Large Class and Long Method. However, we also observed that different LLMs and tools fare better for distinct code smells. We then propose and evaluate a detection strategy that combines LLMs and static analysis tools. The proposed strategy outperforms LLMs and tools in five out of nine code smells in terms of F1-Score. However, it also generates more false positives for complex smells. Therefore, we conclude that the optimal strategy depends on whether Recall or Precision is the main priority for code smell detection.

</details>


### [13] [Self-reflection in Automated Qualitative Coding: Improving Text Annotation through Secondary LLM Critique](https://arxiv.org/abs/2601.09905)
*Zackary Okun Dunivin,Mobina Noori,Seth Frey,Curtis Atkinson*

Main category: cs.SE

TL;DR: 提出兩階段LLM工作流程：第一階段LLM使用人工設計的編碼本進行標註，第二階段LLM通過自我反思重新評估正標籤，顯著降低錯誤率


<details>
  <summary>Details</summary>
Motivation: 傳統零樣本或少樣本LLM分類器在大型數據集上會產生不可接受的高錯誤率，即使使用精心設計的提示詞。需要一種更可靠的方法來提高LLM在質性編碼中的準確性。

Method: 兩階段工作流程：1) 第一線LLM使用人工設計、LLM適應的編碼本進行初步標註；2) 第二線LLM批評者通過重新閱讀源文本和第一階段模型的推理，對每個正標籤進行自我反思並做出最終決策。

Result: 在Apache軟件基金會項目評估討論的3,000封郵件上測試六個質性編碼。第一階段LLM的假陽性率達8%-54%，F1分數0.74-1.00。第二階段自我反思使F1提高0.04-0.25，兩個表現差的編碼從0.52/0.55提升到0.69/0.79。識別出兩類主要錯誤：誤解和元討論。

Conclusion: 第一階段LLM注重召回率，第二階段批評者注重精確度的兩階段工作流程，能以較低計算成本實現精確度優先的控制。結合人工指導和驗證，自我反思可整合到現有LLM輔助標註流程中，減少噪音並挽救原本不可用的分類器。

Abstract: Large language models (LLMs) allow for sophisticated qualitative coding of large datasets, but zero- and few-shot classifiers can produce an intolerable number of errors, even with careful, validated prompting. We present a simple, generalizable two-stage workflow: an LLM applies a human-designed, LLM-adapted codebook; a secondary LLM critic performs self-reflection on each positive label by re-reading the source text alongside the first model's rationale and issuing a final decision. We evaluate this approach on six qualitative codes over 3,000 high-content emails from Apache Software Foundation project evaluation discussions. Our human-derived audit of 360 positive annotations (60 passages by six codes) found that the first-line LLM had a false-positive rate of 8% to 54%, despite F1 scores of 0.74 and 1.00 in testing. Subsequent recoding of all stage-one annotations via a second self-reflection stage improved F1 by 0.04 to 0.25, bringing two especially poor performing codes up to 0.69 and 0.79 from 0.52 and 0.55 respectively. Our manual evaluation identified two recurrent error classes: misinterpretation (violations of code definitions) and meta-discussion (debate about a project evaluation criterion mistaken for its use as a decision justification). Code-specific critic clauses addressing observed failure modes were especially effective with testing and refinement, replicating the codebook-adaption process for LLM interpretation in stage-one. We explain how favoring recall in first-line LLM annotation combined with secondary critique delivers precision-first, compute-light control. With human guidance and validation, self-reflection slots into existing LLM-assisted annotation pipelines to reduce noise and potentially salvage unusable classifiers.

</details>


### [14] [S$^2$F: Principled Hybrid Testing With Fuzzing, Symbolic Execution, and Sampling](https://arxiv.org/abs/2601.10068)
*Lianjing Wang,Yufeng Zhang,Kenli Li,Zhenbang Chen,Xu Zhou,Pengfei Wang,Guangning Song,Ji Wang*

Main category: cs.SE

TL;DR: S²F提出了一种新的混合测试架构，结合传统符号执行的精确性和定制符号执行引擎的可扩展性，解决了现有混合测试工具在符号执行分支剪枝和采样分支选择方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的混合测试工具未能充分利用符号执行和采样的能力：1）定制符号执行引擎过度剪枝分支，导致浪费时间等待模糊测试种子并错过发现崩溃的机会；2）现有方法未将采样应用于适当的分支，无法充分利用采样的能力。

Method: 提出新颖的混合测试架构，结合传统符号执行的精确性和定制符号执行引擎的可扩展性。基于此架构，提出了结合模糊测试、符号执行和采样的若干原则，并实现为混合测试工具S²F。

Result: 在15个真实世界程序上的实验表明，S²F优于最先进工具，边缘覆盖率平均提升6.14%，发现的崩溃数量平均提升32.6%。特别地，该工具发现了真实世界程序中3个先前未知的崩溃。

Conclusion: S²F通过改进的混合测试架构有效解决了现有工具的局限性，显著提升了测试效率和崩溃发现能力，证明了结合精确符号执行和可扩展架构的优势。

Abstract: Hybrid testing that integrates fuzzing, symbolic execution, and sampling has demonstrated superior testing efficiency compared to individual techniques. However, the state-of-the-art (SOTA) hybrid testing tools do not fully exploit the capabilities of symbolic execution and sampling in two key aspects. First, the SOTA hybrid testing tools employ tailored symbolic execution engines that tend to over-prune branches, leading to considerable time wasted waiting for seeds from the fuzzer and missing opportunities to discover crashes. Second, existing methods do not apply sampling to the appropriate branches and therefore cannot utilize the full capability of sampling. To address these two limitations, we propose a novel hybrid testing architecture that combines the precision of conventional symbolic execution with the scalability of tailored symbolic execution engines. Based on this architecture, we propose several principles for combining fuzzing, symbolic execution, and sampling. We implement our method in a hybrid testing tool S$^2$F. To evaluate its effectiveness, we conduct extensive experiments on 15 real-world programs. Experimental results demonstrate that S$^2$F outperforms the SOTA tool, achieving an average improvement of 6.14% in edge coverage and 32.6% in discovered crashes. Notably, our tool uncovers three previously unknown crashes in real-world programs.

</details>


### [15] [Mark My Works Autograder for Programming Courses](https://arxiv.org/abs/2601.10093)
*Yiding Qiu,Seyed Mahdi Azimi,Artem Lensky*

Main category: cs.SE

TL;DR: 开发了Mark My Works本地自动评分系统，结合单元测试与LLM生成解释，为大型编程课程提供及时详细反馈


<details>
  <summary>Details</summary>
Motivation: 大型编程课程难以为学生代码提供及时、详细的反馈，需要自动化解决方案来辅助教学评估

Method: 使用基于角色的提示词分析提交代码，结合传统单元测试与LLM生成解释，评估代码质量并生成教学反馈，保持推理过程透明

Result: 在191名学生课程中测试，AI评分与人工评分无线性相关(r=-0.177)，但分布相似；AI评分更保守(平均59.95 vs 80.53)，但生成的技术反馈更详细

Conclusion: AI自动评分系统能识别与人工相似的代码质量层次，提供更详细的技术反馈，可作为编程课程的有价值辅助工具，尽管评分哲学不同

Abstract: Large programming courses struggle to provide timely, detailed feedback on student code. We developed Mark My Works, a local autograding system that combines traditional unit testing with LLM-generated explanations. The system uses role-based prompts to analyze submissions, critique code quality, and generate pedagogical feedback while maintaining transparency in its reasoning process.
  We piloted the system in a 191-student engineering course, comparing AI-generated assessments with human grading on 79 submissions. While AI scores showed no linear correlation with human scores (r = -0.177, p = 0.124), both systems exhibited similar left-skewed distributions, suggesting they recognize comparable quality hierarchies despite different scoring philosophies. The AI system demonstrated more conservative scoring (mean: 59.95 vs 80.53 human) but generated significantly more detailed technical feedback.

</details>


### [16] [Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants](https://arxiv.org/abs/2601.10112)
*Tsvi Cherny-Shahar,Amiram Yehudai*

Main category: cs.SE

TL;DR: 提出Repository Intelligence Graph (RIG)和SPADE提取器，为代码仓库提供确定性架构图，显著提升AI代码代理在构建和测试结构理解上的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有代码仓库感知的AI代理在多语言项目中难以恢复构建和测试结构，因为跨语言依赖分布在异构的构建系统和工具中，需要更好的结构表示方法。

Method: 1. 提出Repository Intelligence Graph (RIG)：确定性、基于证据的架构图，表示可构建组件、聚合器、运行器、测试、外部包和包管理器，通过明确的依赖和覆盖边连接。2. 开发SPADE提取器：从构建和测试工件中构造RIG，目前基于CMake File API和CTest元数据，将RIG暴露为LLM友好的JSON视图。

Result: 在8个仓库（包括MetaFFI项目）上评估3个商业代理（Claude Code, Cursor, Codex），提供RIG后：平均准确率提升12.2%，完成时间减少53.9%，每个正确答案所需时间减少57.8%。多语言仓库提升更大：准确率提升17.7%，效率提升69.5%（单语言仓库分别为6.6%和46.1%）。

Conclusion: RIG能显著改善AI代码代理对仓库结构的理解，将失败从结构误解转向基于正确结构的推理错误，但基于图的推理质量仍是关键因素。该方法特别适用于多语言项目的构建和测试结构恢复。

Abstract: Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. We also present SPADE, a deterministic extractor that constructs RIG from build and test artifacts (currently with an automatic CMake plugin based on the CMake File API and CTest metadata), and exposes RIG as an LLM friendly JSON view that agents can treat as the authoritative description of repository structure.
  We evaluate three commercial agents (Claude Code, Cursor, Codex) on eight repositories spanning low to high build oriented complexity, including the real world MetaFFI project. Each agent answers thirty structured questions per repository with and without RIG in context, and we measure accuracy, wall clock completion time, and efficiency (seconds per correct answer). Across repositories and agents, providing RIG improves mean accuracy by 12.2\% and reduces completion time by 53.9\%, yielding a mean 57.8\% reduction in seconds per correct answer. Gains are larger in multilingual repositories, which improve by 17.7\% in accuracy and 69.5\% in efficiency on average, compared to 6.6\% and 46.1\% in single language repositories. Qualitative analysis suggests that RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure, while rare regressions highlight that graph based reasoning quality remains a key factor.

</details>


### [17] [Towards Online Malware Detection using Process Resource Utilization Metrics](https://arxiv.org/abs/2601.10164)
*Themistoklis Diamantopoulos,Dimosthenis Natsos,Andreas L. Symeonidis*

Main category: cs.SE

TL;DR: 提出一种基于在线学习的动态恶意软件检测方法，利用进程资源利用指标作为行为特征，通过持续更新模型来适应不断演变的恶意软件威胁


<details>
  <summary>Details</summary>
Motivation: 云计算和物联网的快速发展增加了计算资源的互联性，使得恶意软件能够快速传播。现有机器学习方法依赖大型标注数据集、固定模型训练，且假设训练模型随时间保持有效，忽略了恶意软件不断演变的复杂性，因此难以检测随时间适应的恶意软件攻击

Method: 提出在线学习方法进行动态恶意软件检测，通过整合时间信息持续更新模型，使用行为特征（特别是进程资源利用指标），使模型能够增量适应新兴威胁

Result: 与传统批处理算法相比，该方法能有效检测零日恶意软件，并在数据可用性有限的情况下表现出色，而传统批处理方法在此类场景中往往表现不稳定

Conclusion: 在线学习方法通过持续更新模型并利用行为特征，能够有效应对不断演变的恶意软件威胁，特别是在检测零日恶意软件和数据有限场景下优于传统批处理方法

Abstract: The rapid growth of Cloud Computing and Internet of Things (IoT) has significantly increased the interconnection of computational resources, creating an environment where malicious software (malware) can spread rapidly. To address this challenge, researchers are increasingly utilizing Machine Learning approaches to identify malware through behavioral (i.e. dynamic) cues. However, current approaches are limited by their reliance on large labeled datasets, fixed model training, and the assumption that a trained model remains effective over time-disregarding the ever-evolving sophistication of malware. As a result, they often fail to detect evolving malware attacks that adapt over time. This paper proposes an online learning approach for dynamic malware detection, that overcomes these limitations by incorporating temporal information to continuously update its models using behavioral features, specifically process resource utilization metrics. By doing so, the proposed models can incrementally adapt to emerging threats and detect zero-day malware effectively. Upon evaluating our approach against traditional batch algorithms, we find it effective in detecting zero-day malware. Moreover, we demonstrate its efficacy in scenarios with limited data availability, where traditional batch-based approaches often struggle to perform reliably.

</details>


### [18] [Agentic Pipelines in Embedded Software Engineering: Emerging Practices and Challenges](https://arxiv.org/abs/2601.10220)
*Simin Sun,Miroslaw Staron*

Main category: cs.SE

TL;DR: 嵌入式软件工程团队正面临生成式AI集成挑战，研究通过专家访谈识别了11种新兴实践和14项挑战，涉及工作流重构、责任治理和可持续采用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在改变软件开发，但嵌入式软件工程组织首次在安全关键和资源受限环境中集成AI，对确定性、可靠性和可追溯性的严格要求带来了独特挑战。

Method: 对来自四家公司的十位资深专家进行定性研究，采用半结构化焦点小组访谈和结构化头脑风暴会议。

Result: 识别了11种新兴实践和14项挑战，涉及生成式AI工具的协调、责任治理和可持续采用。结果显示嵌入式软件工程团队正在重新思考工作流、角色和工具链。

Conclusion: 嵌入式软件工程团队正在重构工作流、角色和工具链，以实现向智能代理管道和生成式AI增强开发的可持续转型。

Abstract: A new transformation is underway in software engineering, driven by the rapid adoption of generative AI in development workflows. Similar to how version control systems once automated manual coordination, AI tools are now beginning to automate many aspects of programming. For embedded software engineering organizations, however, this marks their first experience integrating AI into safety-critical and resource-constrained environments. The strict demands for determinism, reliability, and traceability pose unique challenges for adopting generative technologies.
  In this paper, we present findings from a qualitative study with ten senior experts from four companies who are evaluating generative AI-augmented development for embedded software. Through semi-structured focus group interviews and structured brainstorming sessions, we identified eleven emerging practices and fourteen challenges related to the orchestration, responsible governance, and sustainable adoption of generative AI tools. Our results show how embedded software engineering teams are rethinking workflows, roles, and toolchains to enable a sustainable transition toward agentic pipelines and generative AI-augmented development.

</details>


### [19] [Evolving with AI: A Longitudinal Analysis of Developer Logs](https://arxiv.org/abs/2601.10258)
*Agnia Sergeyuk,Eric Huang,Dariia Karaeva,Anastasiia Serova,Yaroslav Golubev,Iftekhar Ahmed*

Main category: cs.SE

TL;DR: AI编程助手长期使用研究：通过两年纵向遥测数据和调查发现，AI用户产生更多代码但也删除更多，开发者报告生产力提升但其他维度变化感知有限


<details>
  <summary>Details</summary>
Motivation: AI编程助手已在专业IDE中广泛应用，但其对日常开发的长期影响尚不明确。先前研究多关注短期使用或自我报告，缺乏对AI持续使用如何重塑实际编码实践的实证理解。

Method: 采用混合方法研究：结合800名开发者两年的细粒度纵向遥测数据，以及62名专业开发者的调查问卷。从生产力、代码质量、代码编辑、代码重用和上下文切换五个维度分析工作流变化。

Result: 遥测数据显示AI用户产生显著更多代码但也删除更多；调查受访者报告生产力提升，但感知其他维度变化有限。揭示了AI对软件工作流的"静默重构"。

Conclusion: AI编程助手正在无声地重构软件开发工作流，产生更多代码的同时也导致更多删除。研究为设计未来AI增强工具提供了实证见解，强调需要关注AI对开发实践的长期结构性影响。

Abstract: AI-powered coding assistants are rapidly becoming fixtures in professional IDEs, yet their sustained influence on everyday development remains poorly understood. Prior research has focused on short-term use or self-reported perceptions, leaving open questions about how sustained AI use reshapes actual daily coding practices in the long term. We address this gap with a mixed-method study of AI adoption in IDEs, combining longitudinal two-year fine-grained telemetry from 800 developers with a survey of 62 professionals. We analyze five dimensions of workflow change: productivity, code quality, code editing, code reuse, and context switching. Telemetry reveals that AI users produce substantially more code but also delete significantly more. Meanwhile, survey respondents report productivity gains and perceive minimal changes in other dimensions. Our results offer empirical insights into the silent restructuring of software workflows and provide implications for designing future AI-augmented tooling.

</details>


### [20] [Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs](https://arxiv.org/abs/2601.10496)
*Ali Al-Kaswan,Claudio Spiess,Prem Devanbu,Arie van Deursen,Maliheh Izadi*

Main category: cs.SE

TL;DR: 论文提出了一个暴露感知评估框架，用于量化训练数据中buggy代码与fixed代码的暴露程度如何影响LLM的偏好，发现暴露会扭曲bug-fix评估，LLM可能传播记忆的错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于代码生成和调试，但其输出仍可能包含源自训练数据的bug。需要区分LLM是偏好正确代码还是熟悉的错误版本，这可能受到训练期间暴露内容的影响。

Method: 引入暴露感知评估框架，使用ManySStuBs4J基准，通过Data Portraits在Stack-V2语料库上进行成员测试，估计每个buggy和fixed变体在训练期间是否被看到。然后按暴露程度分层示例，使用代码补全和多种基于似然性的评分指标比较模型偏好。

Result: 大多数示例（67%）在训练数据中既没有buggy也没有fixed变体；当只有一个存在时，fixes比bugs更频繁出现。在模型生成中，模型复制buggy行的频率远高于fixes，bug暴露的示例会放大这种趋势，而fix暴露的示例仅显示边际改进。在似然性评分中，最小和最大token概率指标在所有条件下始终偏好fixed代码，表明对正确修复的稳定偏向。相比之下，像基尼系数这样的指标在只有buggy变体被看到时会反转偏好。

Conclusion: 暴露会扭曲bug-fix评估，并突显LLM在实践中可能传播记忆错误的风险。

Abstract: Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [21] [From Dynamic to Lexical: A Comparative Exploration of Scoping Rules in SAS and R](https://arxiv.org/abs/2601.09808)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 该论文对比了SAS的动态作用域和R的词法作用域机制，分析了两种语言在变量访问规则、解析方式上的差异，并提供了调试和优化变量的实用方法。


<details>
  <summary>Details</summary>
Motivation: 变量作用域对代码效率和结构至关重要，但SAS和R采用完全不同的作用域机制（动态vs词法），这导致代码行为差异显著。理解这些差异对于在两种语言中有效管理变量、调试代码和优化性能至关重要。

Method: 通过对比分析SAS的动态作用域（使用符号表，运行时在活动宏层中动态搜索变量）和R的词法作用域（使用环境，基于函数定义结构解析变量）。提供具体示例展示两种作用域策略的影响，并介绍检查SAS符号表和R环境的方法。

Result: 论文明确了两种作用域机制的核心差异：SAS在运行时动态解析变量，而R在定义时静态解析。提供了实用的变量检查技术（如查看符号表和环境），并讨论了控制变量作用域的策略，帮助提高代码精确性和可靠性。

Conclusion: 理解SAS和R的作用域差异对优化变量管理至关重要。掌握这些机制能帮助程序员更好地调试代码、控制变量可见性，从而提升在两种语言中的编程实践质量。

Abstract: Variable scoping dictates how and where variables are accessible within programming languages, playing a crucial role in code efficiency and organization. This paper examines the distinct scoping rules in SAS and R, focusing on SAS's dynamic scoping and R's lexical scoping. In SAS, dynamic scoping utilizes symbol tables, resolving variables at runtime by dynamically searching through active macro layers. R, in contrast, employs lexical scoping, using environments to resolve variables based on the structure in which functions are defined. Illustrative examples highlight the differences between these scoping strategies, showcasing their impact on code behavior. Additionally, the paper outlines methods for inspecting variables in SAS's symbol tables and R's environments, offering practical insights for debugging and optimization. Strategies for controlling variable scope in both languages are discussed, enhancing code precision and reliability. This exploration equips programmers with critical understanding to optimize variable management, improving their programming practices in SAS and R.

</details>


### [22] [Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT](https://arxiv.org/abs/2601.09986)
*Cheng Zhang,Qiancheng Fu,Hang Ji,Ines Santacruz Del Valle,Alexandra Silva,Marco Gaboardi*

Main category: cs.PL

TL;DR: 本文提出了几种高效的GKAT自动机迹等价决策过程，利用SAT求解器进行符号化处理，并在CF-GKAT系统中实现，相比现有方法获得数量级性能提升。


<details>
  <summary>Details</summary>
Motivation: GKAT自动机的迹等价验证在程序分析和控制流验证中很重要，但现有方法效率有限，需要更高效的决策过程来支持实际应用。

Method: 开发了基于SAT求解器的符号化决策过程，设计了CF-GKAT的符号导数，并在Rust中实现算法，使用随机生成基准和真实控制流变换进行评估。

Result: 相比现有的KAT和CF-GKAT实现，获得了数量级的性能提升，并在实验中发现了行业标准反编译器Ghidra的一个bug。

Conclusion: 提出的符号化决策过程显著提高了GKAT迹等价验证的效率，证明了在实际控制流验证中的可行性，并发现了真实工具中的缺陷。

Abstract: This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems.

</details>


### [23] [Lazy Evaluation: A Comparative Analysis of SAS MACROs and R Functions](https://arxiv.org/abs/2601.09839)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 本文比较了SAS MACRO和R函数中的惰性求值机制，分析了两者在实现原理、内存管理和调用策略上的差异，为医药行业从SAS转向R的程序员提供优化代码的指导。


<details>
  <summary>Details</summary>
Motivation: 随着医药行业从SAS向R的转型日益普遍，理解两种语言中惰性求值机制的差异对于程序员优化代码效率至关重要。目前对SAS中惰性求值的研究相对不足，而R的惰性求值机制已较为成熟。

Method: 通过比较分析SAS MACRO和R函数的惰性求值实现机制：R使用Promise数据结构实现按需调用策略，SAS通过符号表实现按名调用策略。论文通过实例说明这些差异如何影响编程结果。

Result: 研究发现R的惰性求值使用Promise数据结构延迟求值，直到需要时才占用内存；而SAS通过符号表存储参数，采用不同的内存管理方式。这些策略差异显著影响R函数和SAS MACRO的执行结果和效率。

Conclusion: 理解SAS和R中惰性求值机制的差异有助于程序员在两种语言间迁移时优化代码性能。论文为医药行业程序员提供了实用的编程指导，帮助他们充分利用两种语言的特性提升编程效率和代码性能。

Abstract: Lazy evaluation is a powerful technique that can optimize code execution by deferring evaluations until their results are required, thus enhancing efficiency. In most modern programming languages, like R, lazy evaluation is commonly applied to function arguments. However, the application of lazy evaluation in SAS has not been extensively explored. This paper focuses on the mechanisms of lazy evaluation in SAS MACROs and R functions, offering a comparative analysis of the underlying principles that drive these processes.
  R's lazy evaluation is driven by a data structure called Promise, which postpones evaluation and does not occupy memory until the value is needed, utilizing a call-by-need strategy. SAS, on the other hand, achieves lazy evaluation through its symbol tables, employing memory to store parameters, and operates on a call-by-name basis. These discrepancies in lazy evaluation strategies can notably impact the results of R functions and SAS MACROs. By examining these distinct approaches, the paper illuminates the impact of lazy evaluation on programming efficiency, supported by illustrative examples. As the shift from SAS to R becomes increasingly prevalent in the pharmaceutical industry, understanding these techniques enables programmers to optimize their code for greater efficacy. This exploration serves as a guide to enhance programming capabilities and performance in both languages.

</details>
