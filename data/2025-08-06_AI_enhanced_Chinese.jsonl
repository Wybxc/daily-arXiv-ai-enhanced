{"id": "2508.02857", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.02857", "abs": "https://arxiv.org/abs/2508.02857", "authors": ["Mikhail Mints", "Finn Voichick", "Leonidas Lampropoulos", "Robert Rand"], "title": "Compositional Quantum Control Flow with Efficient Compilation in Qunity", "comment": "88 pages, 30 figures", "summary": "Most existing quantum programming languages are based on the quantum circuit\nmodel of computation, as higher-level abstractions are particularly challenging\nto implement - especially ones relating to quantum control flow. The Qunity\nlanguage, proposed by Voichick et al., offered such an abstraction in the form\nof a quantum control construct, with great care taken to ensure that the\nresulting language is still realizable. However, Qunity lacked a working\nimplementation, and the originally proposed compilation procedure was very\ninefficient, with even simple quantum algorithms compiling to unreasonably\nlarge circuits.\n  In this work, we focus on the efficient compilation of high-level quantum\ncontrol flow constructs, using Qunity as our starting point. We introduce a\nwider range of abstractions on top of Qunity's core language that offer\ncompelling trade-offs compared to its existing control construct. We create a\ncomplete implementation of a Qunity compiler, which converts high-level Qunity\ncode into the quantum assembly language OpenQASM 3. We develop optimization\ntechniques for multiple stages of the Qunity compilation procedure, including\nboth low-level circuit optimizations as well as methods that consider the\nhigh-level structure of a Qunity program, greatly reducing the number of qubits\nand gates used by the compiler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u91cf\u5b50\u63a7\u5236\u6d41\u6784\u9020\u7f16\u8bd1\u65b9\u6cd5\uff0c\u57fa\u4e8eQunity\u8bed\u8a00\uff0c\u4f18\u5316\u4e86\u7f16\u8bd1\u8fc7\u7a0b\u5e76\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u548c\u95e8\u7684\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u5728\u5b9e\u73b0\u9ad8\u7ea7\u62bd\u8c61\uff08\u5c24\u5176\u662f\u91cf\u5b50\u63a7\u5236\u6d41\uff09\u65f6\u6548\u7387\u4f4e\u4e0b\uff0cQunity\u8bed\u8a00\u867d\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u4f46\u7f3a\u4e4f\u5b9e\u73b0\u4e14\u7f16\u8bd1\u6548\u7387\u4f4e\u3002", "method": "\u5728Qunity\u57fa\u7840\u4e0a\u5f15\u5165\u66f4\u5e7f\u6cdb\u7684\u62bd\u8c61\uff0c\u5f00\u53d1\u5b8c\u6574\u7684Qunity\u7f16\u8bd1\u5668\uff0c\u4f18\u5316\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u5305\u62ec\u4f4e\u5c42\u7535\u8def\u4f18\u5316\u548c\u9ad8\u5c42\u7a0b\u5e8f\u7ed3\u6784\u4f18\u5316\u3002", "result": "\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7f16\u8bd1\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u548c\u95e8\u7684\u6570\u91cf\uff0c\u751f\u6210OpenQASM 3\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u7f16\u8bd1\u8fc7\u7a0b\uff0cQunity\u8bed\u8a00\u7684\u9ad8\u6548\u5b9e\u73b0\u6210\u4e3a\u53ef\u80fd\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2508.03558", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03558", "abs": "https://arxiv.org/abs/2508.03558", "authors": ["M Zafir Sadik Khan", "Nowfel Mashnoor", "Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation", "comment": "Accepted to the IEEE International Conference on Computer Design\n  (ICCD 2025)", "summary": "In today's rapidly evolving field of electronic design automation (EDA), the\ncomplexity of hardware designs is increasing, necessitating more sophisticated\nautomation solutions. High-level synthesis (HLS), as a pivotal solution,\nautomates hardware designs from high-level abstractions (e.g., C/C++). However,\nit faces significant challenges, particularly in design space exploration and\noptimization. While large language models (LLMs) have shown notable\ncapabilities in code generation, their application to HLS has been limited due\nto the scarcity of (publicly) available HLS code datasets. Hence, research in\nthis domain has primarily focused on techniques such as prompt engineering and\nretrieval-augmented generation (RAG). To overcome this limitation, this paper\nintroduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS\ncode generation. Our method includes three key advancements: (i) We implement\nVerilog-to-C/C++ porting, converting verified and synthesizable Verilog codes\ninto corresponding C, creating a dataset of 16.7K HLS codes; (ii) We implement\na fine-tuning strategy, which is based on instruction prompting to code\ngeneration guided by abstract syntax tree (AST); (iii) We develop a\nsemi-automated evaluation framework using VerilogEval to assess the\nfunctionality of the generated HLS code. Our experiments show that SAGE-HLS,\nfined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100% success rate\nin code synthesizability and a 75% success rate in functional correctness.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SAGE-HLS\uff0c\u4e00\u79cd\u4e13\u4e3aHLS\u4ee3\u7801\u751f\u6210\u8bbe\u8ba1\u7684\u5fae\u8c03LLM\uff0c\u901a\u8fc7Verilog-to-C/C++\u8f6c\u6362\u521b\u5efa\u6570\u636e\u96c6\uff0c\u5e76\u7ed3\u5408AST\u6307\u5bfc\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86HLS\u4ee3\u7801\u7684\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u7531\u4e8e\u516c\u5f00\u53ef\u7528\u7684HLS\u4ee3\u7801\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u73b0\u6709LLM\u5728HLS\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e94\u7528\u53d7\u9650\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7Verilog-to-C/C++\u8f6c\u6362\u521b\u5efa16.7K HLS\u4ee3\u7801\u6570\u636e\u96c6\uff0c\u91c7\u7528\u57fa\u4e8eAST\u7684\u6307\u4ee4\u63d0\u793a\u5fae\u8c03\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u534a\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6VerilogEval\u3002", "result": "SAGE-HLS\u5728QwenCoder 7B\u6a21\u578b\u4e0a\u5fae\u8c03\u540e\uff0c\u4ee3\u7801\u53ef\u5408\u6210\u7387\u63a5\u8fd1100%\uff0c\u529f\u80fd\u6b63\u786e\u7387\u8fbe75%\u3002", "conclusion": "SAGE-HLS\u4e3aHLS\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86LLM\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u7a7a\u767d\u3002"}}
{"id": "2508.03640", "categories": ["cs.PL", "D.3.2;D.3.4;K.3.1"], "pdf": "https://arxiv.org/pdf/2508.03640", "abs": "https://arxiv.org/abs/2508.03640", "authors": ["Pedro Vasconcelos"], "title": "Teaching Introductory Functional Programming Using Haskelite", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "Learning functional programming requires learning a substitution-based\ncomputational model. While substitution should be a familiar concept from\nhigh-school algebra, students often have difficulty applying it to new\nsettings, such as recursive definitions, algebraic data types and higher-order\nfunctions. Step-by-step interpreters have been shown to help beginners by\nclarifying misconceptions and improving understanding.\n  This paper reports on the experience of using a step-by-step tracing\ninterpreter for a subset of Haskell while teaching an introductory functional\nprogramming course at the University of Porto. We describe the use of the\ninterpreter, present some feedback obtained from students, reflect on the\nlessons learned and point directions for further work.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6559\u6388\u51fd\u6570\u5f0f\u7f16\u7a0b\u65f6\u4f7f\u7528\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u7684\u7ecf\u9a8c\uff0c\u5c55\u793a\u4e86\u5176\u5bf9\u5b66\u751f\u7406\u89e3\u9012\u5f52\u5b9a\u4e49\u3001\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u548c\u9ad8\u9636\u51fd\u6570\u7b49\u6982\u5ff5\u7684\u5e2e\u52a9\u3002", "motivation": "\u5b66\u751f\u5728\u5b66\u4e60\u51fd\u6570\u5f0f\u7f16\u7a0b\u65f6\uff0c\u5bf9\u57fa\u4e8e\u66ff\u6362\u7684\u8ba1\u7b97\u6a21\u578b\uff08\u5982\u9012\u5f52\u5b9a\u4e49\u3001\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u548c\u9ad8\u9636\u51fd\u6570\uff09\u5b58\u5728\u7406\u89e3\u56f0\u96be\uff0c\u9010\u6b65\u89e3\u91ca\u5668\u88ab\u8bc1\u660e\u80fd\u6709\u6548\u6f84\u6e05\u8bef\u89e3\u5e76\u63d0\u5347\u7406\u89e3\u3002", "method": "\u5728\u6ce2\u5c14\u56fe\u5927\u5b66\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\u5165\u95e8\u8bfe\u7a0b\u4e2d\uff0c\u4f7f\u7528\u4e86\u4e00\u4e2a\u9488\u5bf9Haskell\u5b50\u96c6\u7684\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\uff0c\u5e76\u6536\u96c6\u4e86\u5b66\u751f\u7684\u53cd\u9988\u3002", "result": "\u5b66\u751f\u53cd\u9988\u8868\u660e\u9010\u6b65\u89e3\u91ca\u5668\u6709\u52a9\u4e8e\u7406\u89e3\u590d\u6742\u6982\u5ff5\uff0c\u8bfe\u7a0b\u7ecf\u9a8c\u4e5f\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u662f\u6559\u6388\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u6709\u6548\u5de5\u5177\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u6269\u5c55\u5176\u5e94\u7528\u3002"}}
{"id": "2508.02721", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.02721", "abs": "https://arxiv.org/abs/2508.02721", "authors": ["Libin Qiu", "Yuhang Ye", "Zhirong Gao", "Xide Zou", "Junfu Chen", "Ziming Gui", "Weizhi Huang", "Xiaobo Xue", "Wenkai Qiu", "Kun Zhao"], "title": "Blueprint First, Model Second: A Framework for Deterministic LLM Workflow", "comment": "8 pages, 6 figures, 3 tables", "summary": "While powerful, the inherent non-determinism of large language model (LLM)\nagents limits their application in structured operational environments where\nprocedural fidelity and predictable execution are strict requirements. This\nlimitation stems from current architectures that conflate probabilistic,\nhigh-level planning with low-level action execution within a single generative\nprocess. To address this, we introduce the Source Code Agent framework, a new\nparadigm built on the \"Blueprint First, Model Second\" philosophy. Our framework\ndecouples the workflow logic from the generative model. An expert-defined\noperational procedure is first codified into a source code-based Execution\nBlueprint, which is then executed by a deterministic engine. The LLM is\nstrategically invoked as a specialized tool to handle bounded, complex\nsub-tasks within the workflow, but never to decide the workflow's path. We\nconduct a comprehensive evaluation on the challenging tau-bench benchmark,\ndesigned for complex user-tool-rule scenarios. Our results demonstrate that the\nSource Code Agent establishes a new state-of-the-art, outperforming the\nstrongest baseline by 10.1 percentage points on the average Pass^1 score while\ndramatically improving execution efficiency. Our work enables the verifiable\nand reliable deployment of autonomous agents in applications governed by strict\nprocedural logic.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSource Code Agent\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5de5\u4f5c\u6d41\u903b\u8f91\u4e0e\u751f\u6210\u6a21\u578b\u89e3\u8026\uff0c\u89e3\u51b3\u4e86LLM\u4ee3\u7406\u5728\u7ed3\u6784\u5316\u64cd\u4f5c\u73af\u5883\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u975e\u786e\u5b9a\u6027\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u4e25\u683c\u7a0b\u5e8f\u4fdd\u771f\u5ea6\u548c\u53ef\u9884\u6d4b\u6267\u884c\u7684\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u2018Blueprint First, Model Second\u2019\u54f2\u5b66\uff0c\u5c06\u4e13\u5bb6\u5b9a\u4e49\u7684\u64cd\u4f5c\u7a0b\u5e8f\u7f16\u7801\u4e3a\u57fa\u4e8e\u6e90\u4ee3\u7801\u7684\u6267\u884c\u84dd\u56fe\uff0c\u5e76\u7531\u786e\u5b9a\u6027\u5f15\u64ce\u6267\u884c\uff0cLLM\u4ec5\u7528\u4e8e\u5904\u7406\u6709\u9650\u590d\u6742\u5b50\u4efb\u52a1\u3002", "result": "\u5728tau-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSource Code Agent\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747Pass^1\u5f97\u5206\u6bd4\u6700\u5f3a\u57fa\u7ebf\u9ad8\u51fa10.1\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6267\u884c\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u5728\u4e25\u683c\u7a0b\u5e8f\u903b\u8f91\u5e94\u7528\u4e2d\u7684\u53ef\u9a8c\u8bc1\u548c\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2508.03627", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2508.03627", "abs": "https://arxiv.org/abs/2508.03627", "authors": ["Anirban Majumdar", "Sayan Mukherjee", "Jean-Fran\u00e7ois Raskin"], "title": "Learning Event-recording Automata Passively", "comment": "Shorter version of this article has been accepted at ATVA 2025", "summary": "This paper presents a state-merging algorithm for learning timed languages\ndefinable by Event-Recording Automata (ERA) using positive and negative samples\nin the form of symbolic timed words. Our algorithm, LEAP (Learning\nEvent-recording Automata Passively), constructs a possibly nondeterministic ERA\nfrom such samples based on merging techniques. We prove that determining\nwhether two ERA states can be merged while preserving sample consistency is an\nNP-complete problem, and address this with a practical SMT-based solution. Our\nimplementation demonstrates the algorithm's effectiveness through examples. We\nalso show that every ERA-definable language can be inferred using our algorithm\nwith a suitable sample.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u72b6\u6001\u5408\u5e76\u7b97\u6cd5LEAP\uff0c\u7528\u4e8e\u4ece\u7b26\u53f7\u5316\u65f6\u95f4\u8bcd\u7684\u6837\u672c\u4e2d\u5b66\u4e60\u4e8b\u4ef6\u8bb0\u5f55\u81ea\u52a8\u673a\uff08ERA\uff09\u5b9a\u4e49\u7684\u65f6\u95f4\u8bed\u8a00\uff0c\u5e76\u8bc1\u660e\u4e86\u72b6\u6001\u5408\u5e76\u7684NP\u5b8c\u5168\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4ece\u6b63\u8d1f\u6837\u672c\u4e2d\u5b66\u4e60\u65f6\u95f4\u8bed\u8a00\uff0c\u4ee5\u89e3\u51b3\u4e8b\u4ef6\u8bb0\u5f55\u81ea\u52a8\u673a\u7684\u72b6\u6001\u5408\u5e76\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86LEAP\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5408\u5e76\u6280\u672f\u4ece\u6837\u672c\u4e2d\u6784\u5efa\u53ef\u80fd\u975e\u786e\u5b9a\u6027\u7684\u4e8b\u4ef6\u8bb0\u5f55\u81ea\u52a8\u673a\uff0c\u5e76\u4f7f\u7528SMT\u6c42\u89e3\u5668\u89e3\u51b3NP\u5b8c\u5168\u6027\u95ee\u9898\u3002", "result": "\u7b97\u6cd5\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u6240\u6709ERA\u53ef\u5b9a\u4e49\u7684\u8bed\u8a00\u5747\u53ef\u901a\u8fc7\u5408\u9002\u6837\u672c\u63a8\u65ad\u3002", "conclusion": "LEAP\u7b97\u6cd5\u80fd\u6709\u6548\u5b66\u4e60ERA\u5b9a\u4e49\u7684\u65f6\u95f4\u8bed\u8a00\uff0c\u89e3\u51b3\u4e86\u72b6\u6001\u5408\u5e76\u7684\u590d\u6742\u6027\u95ee\u9898\u3002"}}
{"id": "2508.02764", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.02764", "abs": "https://arxiv.org/abs/2508.02764", "authors": ["Konstantin Doubrovinski"], "title": "When are two algorithms the same? Towards addressing Hilbert's 24th problem", "comment": null, "summary": "The informal question of when two theorem proofs are \"essentially the same\"\ngoes back to David Hilbert, who considered adding it (or something largely\nequivalent) to his famous list of open problems, but eventually decided to\nleave it out. Given that the notion of a formal proof is closely related to\nthat of a (computer) program, i.e. a recursive function, it may be useful to\nask the same question with regard to programs instead. Here we propose a\nminimalistic approach to this question within Recursion Theory, building\nheavily on the use of Kolmogorov Complexity.", "AI": {"tldr": "\u63a2\u8ba8\u4e24\u4e2a\u5b9a\u7406\u8bc1\u660e\u6216\u7a0b\u5e8f\u662f\u5426\u201c\u672c\u8d28\u4e0a\u76f8\u540c\u201d\u7684\u95ee\u9898\uff0c\u57fa\u4e8e\u9012\u5f52\u7406\u8bba\u548c\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u6027\u63d0\u51fa\u4e86\u4e00\u79cd\u6781\u7b80\u65b9\u6cd5\u3002", "motivation": "\u53d7\u5e0c\u5c14\u4f2f\u7279\u672a\u5217\u5165\u5176\u8457\u540d\u95ee\u9898\u5217\u8868\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8bc1\u660e\u6216\u7a0b\u5e8f\u7684\u672c\u8d28\u76f8\u4f3c\u6027\u3002", "method": "\u5229\u7528\u9012\u5f52\u7406\u8bba\u548c\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u6027\u6784\u5efa\u6781\u7b80\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5224\u65ad\u8bc1\u660e\u6216\u7a0b\u5e8f\u672c\u8d28\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7814\u7a76\u8bc1\u660e\u548c\u7a0b\u5e8f\u7684\u76f8\u4f3c\u6027\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.02820", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.02820", "abs": "https://arxiv.org/abs/2508.02820", "authors": ["David Svoboda", "Lori Flynn", "William Klieber", "Michael Duggan", "Nicholas Reimer", "Joseph Sible"], "title": "Automated Code Repair for C/C++ Static Analysis Alerts", "comment": null, "summary": "(Note: This work is a preprint.) Static analysis (SA) tools produce many\ndiagnostic alerts indicating that source code in C or C++ may be defective and\npotentially vulnerable to security exploits. Many of these alerts are false\npositives. Identifying the true-positive alerts and repairing the defects in\nthe associated code are huge efforts that automated program repair (APR) tools\ncan help with. Our experience showed us that APR can reduce the number of SA\nalerts significantly and reduce the manual effort of analysts to review code.\nThis engineering experience paper details the application of design,\ndevelopment, and performance testing to an APR tool we built that repairs C/C++\ncode associated with 3 categories of alerts produced by multiple SA tools. Its\nrepairs are simple and local. Furthermore, our findings convinced the\nmaintainers of the CERT Coding Standards to re-assess and update the metrics\nused to assess when violations of guidelines are detectable or repairable. We\ndiscuss engineering design choices made to support goals of trustworthiness and\nacceptability to developers. Our APR tool repaired 8718 out of 9234 alerts\nproduced by one SA tool on one codebase. It can repair 3 flaw categories. For 2\nflaw categories, 2 SA tools, and 2 codebases, our tool repaired or dismissed as\nfalse positives over 80% of alerts, on average. Tests showed repairs did not\nappreciably degrade the performance of the code or cause new alerts to appear\n(with the possible exception of sqlite3.c). This paper describes unique\ncontributions that include a new empirical analysis of SA data, our selection\nmethod for flaw categories to repair, publication of our APR tool, and a\ndataset of SA alerts from open-source SA tools run on open-source codebases. It\ndiscusses positive and negative results and lessons learned.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9759\u6001\u5206\u6790\uff08SA\uff09\u5de5\u5177\u5728C/C++\u4ee3\u7801\u4e2d\u4ea7\u751f\u7684\u8bca\u65ad\u8b66\u62a5\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u5de5\u5177\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8b66\u62a5\u6570\u91cf\u548c\u5206\u6790\u5e08\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\u3002", "motivation": "\u9759\u6001\u5206\u6790\u5de5\u5177\u4ea7\u751f\u5927\u91cf\u8bca\u65ad\u8b66\u62a5\uff0c\u5176\u4e2d\u8bb8\u591a\u662f\u8bef\u62a5\uff0c\u624b\u52a8\u4fee\u590d\u7f3a\u9677\u8017\u65f6\u8017\u529b\u3002APR\u5de5\u5177\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u8b66\u62a5\u6570\u91cf\u5e76\u964d\u4f4e\u4eba\u5de5\u5ba1\u67e5\u6210\u672c\u3002", "method": "\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u6027\u80fd\u6d4b\u8bd5\u4e86\u4e00\u79cdAPR\u5de5\u5177\uff0c\u7528\u4e8e\u4fee\u590d\u7531\u591a\u4e2aSA\u5de5\u5177\u4ea7\u751f\u76843\u7c7b\u8b66\u62a5\u3002\u4fee\u590d\u65b9\u6cd5\u7b80\u5355\u4e14\u5c40\u90e8\u5316\u3002", "result": "APR\u5de5\u5177\u6210\u529f\u4fee\u590d\u4e868718/9234\u4e2a\u8b66\u62a5\uff0c\u5bf92\u7c7b\u7f3a\u9677\u30012\u4e2aSA\u5de5\u5177\u548c2\u4e2a\u4ee3\u7801\u5e93\uff0c\u5e73\u5747\u4fee\u590d\u6216\u6392\u9664\u4e8680%\u4ee5\u4e0a\u7684\u8b66\u62a5\u3002\u4fee\u590d\u672a\u663e\u8457\u5f71\u54cd\u4ee3\u7801\u6027\u80fd\u6216\u5f15\u53d1\u65b0\u8b66\u62a5\u3002", "conclusion": "APR\u5de5\u5177\u5728\u51cf\u5c11SA\u8b66\u62a5\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u540c\u65f6\u63a8\u52a8\u4e86CERT\u7f16\u7801\u6807\u51c6\u7684\u66f4\u65b0\u3002\u8bba\u6587\u8fd8\u516c\u5f00\u4e86APR\u5de5\u5177\u548c\u6570\u636e\u96c6\uff0c\u603b\u7ed3\u4e86\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2508.03638", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03638", "abs": "https://arxiv.org/abs/2508.03638", "authors": ["Marco T. Moraz\u00e1n", "Oliwia Kempinski", "Andr\u00e9s M. Garced"], "title": "Design Support for Multitape Turing Machines", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "Many Formal Languages and Automata Theory courses introduce students to\nTuring machine extensions. One of the most widely-used extensions endows Turing\nmachines with multiple tapes. Although multitape Turing machines are an\nabstraction to simplify Turing machine design, students find them no less\nchallenging. To aid students in understanding these machines, the FSM\nprogramming language provides support for their definition and execution. This,\nhowever, has proven insufficient for many students to understand the\noperational semantics of such machines and to understand why such machines\naccept or reject a word. To address this problem, three visualization tools\nhave been developed. The first is a dynamic visualization tool that simulates\nmachine execution. The second is a static visualization tool that automatically\nrenders a graphic for a multitape Turing machine's transition diagram. The\nthird is a static visualization tool that automatically renders computation\ngraphs for multitape Turing machines. This article presents these tools and\nillustrates how they are used to help students design and implement multitape\nTuring machines. In addition, empirical data is presented that suggests these\ntools are well-received and found useful by students.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e09\u79cd\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u548c\u8bbe\u8ba1\u591a\u5e26\u56fe\u7075\u673a\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6570\u636e\u652f\u6301\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5b66\u751f\u5728\u5b66\u4e60\u591a\u5e26\u56fe\u7075\u673a\u65f6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u7684FSM\u7f16\u7a0b\u8bed\u8a00\u652f\u6301\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u76f4\u89c2\u7684\u5de5\u5177\u8f85\u52a9\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u4e86\u4e09\u79cd\u53ef\u89c6\u5316\u5de5\u5177\uff1a\u52a8\u6001\u6a21\u62df\u6267\u884c\u5de5\u5177\u3001\u9759\u6001\u8fc7\u6e21\u56fe\u6e32\u67d3\u5de5\u5177\u548c\u9759\u6001\u8ba1\u7b97\u56fe\u6e32\u67d3\u5de5\u5177\u3002", "result": "\u5de5\u5177\u53d7\u5230\u5b66\u751f\u6b22\u8fce\uff0c\u5e76\u88ab\u8bc1\u660e\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u8bbe\u8ba1\u591a\u5e26\u56fe\u7075\u673a\u3002", "conclusion": "\u53ef\u89c6\u5316\u5de5\u5177\u80fd\u6709\u6548\u63d0\u5347\u5b66\u751f\u5bf9\u591a\u5e26\u56fe\u7075\u673a\u7684\u7406\u89e3\u548c\u8bbe\u8ba1\u80fd\u529b\u3002"}}
{"id": "2508.02774", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.02774", "abs": "https://arxiv.org/abs/2508.02774", "authors": ["Zoran Majkic"], "title": "Intensional FOL over Belnap's Billatice for Strong-AI Robotics", "comment": "28 pages", "summary": "AGI (Strong AI) aims to create intelligent robots that are quasi\nindistinguishable from the human mind. Like a child, the AGI robot would have\nto learn through input and experiences, constantly progressing and advancing\nits abilities over time. The AGI robot would require an intelligence more close\nto human's intelligence: it would have a self-aware consciousness that has the\nability to solve problems, learn, and plan. Based on this approach an\nIntensional many-sorted First-order Logic (IFOL), as an extension of a standard\nFOL with Tarskian's semantics, is proposed in order to avoid the problems of\nstandard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity\nfor robots to work with incomplete (unknown) knowledge as well. This is a more\nsophisticated version of IFOL with the same syntax but different semantics,\nable to deal with truth-ordering and knowledge-ordering as well, based on the\nwell known Belnap's billatice with four truth-values that extend the set of\nclassical two truth-values.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u5c55\u7684IFOL\u903b\u8f91\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3AGI\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u7684\u6096\u8bba\u548c\u4e0d\u5b8c\u6574\u77e5\u8bc6\u95ee\u9898\u3002", "motivation": "AGI\u673a\u5668\u4eba\u9700\u8981\u63a5\u8fd1\u4eba\u7c7b\u667a\u80fd\u7684\u5b66\u4e60\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u6807\u51c6FOL\u5b58\u5728\u6096\u8bba\u548c\u4e0d\u5b8c\u6574\u77e5\u8bc6\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684IFOL\u903b\u8f91\u7cfb\u7edf\uff0c\u57fa\u4e8eBelnap\u7684\u56db\u79cd\u771f\u503c\uff0c\u652f\u6301\u771f\u503c\u6392\u5e8f\u548c\u77e5\u8bc6\u6392\u5e8f\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u4e0d\u4e00\u81f4\u516c\u5f0f\u548c\u4e0d\u5b8c\u6574\u77e5\u8bc6\uff0c\u9002\u7528\u4e8eAGI\u673a\u5668\u4eba\u7684\u667a\u80fd\u53d1\u5c55\u3002", "conclusion": "\u6269\u5c55\u7684IFOL\u4e3aAGI\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u63a5\u8fd1\u4eba\u7c7b\u667a\u80fd\u7684\u903b\u8f91\u6846\u67b6\u3002"}}
{"id": "2508.02729", "categories": ["cs.SE", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.02729", "abs": "https://arxiv.org/abs/2508.02729", "authors": ["Zhuoran Liu"], "title": "Interpreting Performance Profiles with Deep Learning", "comment": "Master of Science in Computer Science thesis, North Carolina State\n  University, 2022. Advisor: Dr. Xu Liu", "summary": "Profiling tools (also known as profilers) play an important role in\nunderstanding program performance at runtime, such as hotspots, bottlenecks,\nand inefficiencies. While profilers have been proven to be useful, they give\nextra burden to software engineers. Software engineers, as the users, are\nresponsible to interpret the complex performance data and identify actionable\noptimization in program source code. However, it can be challenging for users\nto associate inefficiencies with the program semantics, especially if the users\nare not the authors of the code, which limits the applicability of profilers.\n  In this thesis, we explore a new direction to combine performance profiles\nand program semantics with a deep learning approach. The key idea is to glean\ncode summary for semantic information (at a certain level) and integrate it\ninto a profiler, which can better understand program inefficiencies for\nactionable optimization. To be concrete, we combine profiles generated by Async\nProfiler (the state-of-the-art Java profiler) with code summarization from a\nfine-tuned CodeBERT-based model. We demonstrate the code summaries of any\nselected call path in a graphic user interface. Our system can effectively\nassist analysis on many Java benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u7ed3\u5408\u6027\u80fd\u5206\u6790\u548c\u7a0b\u5e8f\u8bed\u4e49\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6539\u8fdb\u6027\u80fd\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u76f4\u89c2\u5730\u7406\u89e3\u7a0b\u5e8f\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u6027\u80fd\u5206\u6790\u5de5\u5177\u867d\u7136\u6709\u7528\uff0c\u4f46\u7528\u6237\uff08\u5c24\u5176\u662f\u975e\u4ee3\u7801\u4f5c\u8005\uff09\u96be\u4ee5\u5c06\u6027\u80fd\u6570\u636e\u4e0e\u7a0b\u5e8f\u8bed\u4e49\u5173\u8054\uff0c\u9650\u5236\u4e86\u5de5\u5177\u7684\u5b9e\u7528\u6027\u3002", "method": "\u7ed3\u5408Async Profiler\u751f\u6210\u7684\u6027\u80fd\u6570\u636e\u548c\u57fa\u4e8eCodeBERT\u7684\u4ee3\u7801\u6458\u8981\u6a21\u578b\uff0c\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u5c55\u793a\u8c03\u7528\u8def\u5f84\u7684\u4ee3\u7801\u6458\u8981\u3002", "result": "\u7cfb\u7edf\u5728\u591a\u4e2aJava\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u8f85\u52a9\u4e86\u6027\u80fd\u5206\u6790\u3002", "conclusion": "\u7ed3\u5408\u6027\u80fd\u5206\u6790\u548c\u7a0b\u5e8f\u8bed\u4e49\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u5347\u6027\u80fd\u5206\u6790\u5de5\u5177\u7684\u5b9e\u7528\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u3002"}}
{"id": "2508.03435", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03435", "abs": "https://arxiv.org/abs/2508.03435", "authors": ["Thomas S. Heinze", "Andr\u00e9 Sch\u00e4fer", "Wolfram Amme"], "title": "StoneDetector: Conventional and versatile code clone detection for Java", "comment": "supplementary information available at\n  https://stonedetector.fmi.uni-jena.de/", "summary": "Copy & paste is a widespread practice when developing software and, thus,\nduplicated and subsequently modified code occurs frequently in software\nprojects. Since such code clones, i.e., identical or similar fragments of code,\ncan bloat software projects and cause issues like bug or vulnerability\npropagation, their identification is of importance. In this paper, we present\nthe StoneDetector platform and its underlying method for finding code clones in\nJava source and Bytecode. StoneDetector implements a conventional clone\ndetection approach based upon the textual comparison of paths derived from the\ncode's representation by dominator trees. In this way, the tool does not only\nfind exact and syntactically similar near-miss code clones, but also code\nclones that are harder to detect due to their larger variety in the syntax. We\ndemonstrate StoneDetector's versatility as a conventional clone detection\nplatform and analyze its various available configuration parameters, including\nthe usage of different string metrics, hashing algorithms, etc. In our\nexhaustive evaluation with other conventional clone detectors on several\nstate-of-the-art benchmarks, we can show StoneDetector's performance and\nscalability in finding code clones in both, Java source and Bytecode.", "AI": {"tldr": "StoneDetector\u5e73\u53f0\u7528\u4e8e\u68c0\u6d4bJava\u6e90\u4ee3\u7801\u548c\u5b57\u8282\u7801\u4e2d\u7684\u4ee3\u7801\u514b\u9686\uff0c\u57fa\u4e8e\u652f\u914d\u6811\u8def\u5f84\u7684\u6587\u672c\u6bd4\u8f83\uff0c\u652f\u6301\u591a\u79cd\u914d\u7f6e\u53c2\u6570\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u4ee3\u7801\u514b\u9686\u53ef\u80fd\u5bfc\u81f4\u8f6f\u4ef6\u81a8\u80c0\u548c\u6f0f\u6d1e\u4f20\u64ad\uff0c\u56e0\u6b64\u8bc6\u522b\u514b\u9686\u4ee3\u7801\u5bf9\u8f6f\u4ef6\u9879\u76ee\u81f3\u5173\u91cd\u8981\u3002", "method": "StoneDetector\u91c7\u7528\u57fa\u4e8e\u652f\u914d\u6811\u8def\u5f84\u6587\u672c\u6bd4\u8f83\u7684\u4f20\u7edf\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u79cd\u5b57\u7b26\u4e32\u5ea6\u91cf\u548c\u54c8\u5e0c\u7b97\u6cd5\u914d\u7f6e\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cStoneDetector\u5728\u68c0\u6d4bJava\u6e90\u4ee3\u7801\u548c\u5b57\u8282\u7801\u4e2d\u7684\u4ee3\u7801\u514b\u9686\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "StoneDetector\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u914d\u7f6e\u7684\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u514b\u9686\u7c7b\u578b\u548c\u573a\u666f\u3002"}}
{"id": "2508.03639", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03639", "abs": "https://arxiv.org/abs/2508.03639", "authors": ["Marco T. Moraz\u00e1n", "Shamil Dzhatdoyev", "Josephine Des Rosiers", "Tijana Mini\u0107", "Andr\u00e9s M. Garced", "David Anthony K. Fields"], "title": "A Design Recipe and Recipe-Based Errors for Regular Expressions", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "This article presents a novel framework to provide Formal Languages and\nAutomata Theory students design support for the development of regular\nexpressions. This framework includes a design recipe for regular expressions\nand a customized error messaging system. The error messaging system produces\nrecipe-based errors that include the step of the design recipe not successfully\ncompleted. Furthermore, the error messages follow the established practices of\nbeing concise, succinct, jargon-free, and nonprescriptive. In addition, a\nshorthand syntax developed for writing unit tests is described. The in-class\nuse of the design recipe is illustrated, two debugging sessions using the\ndescribed system are discussed, and the implementation of the error messaging\nsystem is briefly sketched.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u6b63\u5219\u8868\u8fbe\u5f0f\u8bbe\u8ba1\u7684\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u8bbe\u8ba1\u65b9\u6cd5\u548c\u9519\u8bef\u63d0\u793a\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u5f62\u5f0f\u8bed\u8a00\u4e0e\u81ea\u52a8\u673a\u7406\u8bba\u5b66\u751f\u63d0\u4f9b\u6b63\u5219\u8868\u8fbe\u5f0f\u8bbe\u8ba1\u7684\u652f\u6301\u3002", "method": "\u6846\u67b6\u5305\u542b\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u8bbe\u8ba1\u65b9\u6cd5\u548c\u5b9a\u5236\u5316\u7684\u9519\u8bef\u63d0\u793a\u7cfb\u7edf\uff0c\u9519\u8bef\u4fe1\u606f\u57fa\u4e8e\u8bbe\u8ba1\u6b65\u9aa4\u3002", "result": "\u9519\u8bef\u4fe1\u606f\u7b80\u6d01\u3001\u65e0\u672f\u8bed\u4e14\u975e\u6307\u4ee4\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u7b80\u5199\u8bed\u6cd5\u7528\u4e8e\u5355\u5143\u6d4b\u8bd5\u3002", "conclusion": "\u6846\u67b6\u5728\u8bfe\u5802\u4e2d\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u8c03\u8bd5\u8fc7\u7a0b\u548c\u9519\u8bef\u63d0\u793a\u7cfb\u7edf\u7684\u5b9e\u73b0\u3002"}}
{"id": "2508.03574", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.03574", "abs": "https://arxiv.org/abs/2508.03574", "authors": ["Michael Benedikt", "Chia-Hsuan Lu", "Tony Tan"], "title": "Analysis of logics with arithmetic", "comment": null, "summary": "We present new results on finite satisfiability of logics with counting and\narithmetic. This includes tight bounds on the complexity for two-variable logic\nwith counting and cardinality comparisons between unary formulas, and also on\nlogics with so-called local Presburger quantifiers. In the process, we provide\nsimpler proofs of some key prior results on finite satisfiability and\nsemi-linearity of the spectrum for these logics.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e26\u8ba1\u6570\u548c\u7b97\u672f\u7684\u903b\u8f91\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\uff0c\u7ed9\u51fa\u4e86\u4e8c\u53d8\u91cf\u903b\u8f91\u7684\u7d27\u590d\u6742\u5ea6\u754c\u9650\uff0c\u5e76\u7b80\u5316\u4e86\u5148\u524d\u5173\u952e\u7ed3\u679c\u7684\u8bc1\u660e\u3002", "motivation": "\u63a2\u7d22\u5e26\u8ba1\u6570\u548c\u7b97\u672f\u7684\u903b\u8f91\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\uff0c\u586b\u8865\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e8c\u53d8\u91cf\u903b\u8f91\u4e0e\u4e00\u5143\u516c\u5f0f\u7684\u57fa\u6570\u6bd4\u8f83\uff0c\u4ee5\u53ca\u5c40\u90e8Presburger\u91cf\u8bcd\u7684\u903b\u8f91\u3002", "result": "\u83b7\u5f97\u4e86\u7d27\u590d\u6742\u5ea6\u754c\u9650\uff0c\u5e76\u7b80\u5316\u4e86\u5148\u524d\u7ed3\u679c\u7684\u8bc1\u660e\u3002", "conclusion": "\u8bba\u6587\u4e3a\u76f8\u5173\u903b\u8f91\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\u548c\u65b9\u6cd5\u7b80\u5316\u3002"}}
{"id": "2508.02732", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02732", "abs": "https://arxiv.org/abs/2508.02732", "authors": ["Sherman Wong", "Jalaj Bhandari", "Leo Zhou Fan Yang", "Xylan Xu", "Yi Zhuang", "Cem Cayiroglu", "Payal Bhuptani", "Sheela Yadawad", "Hung Duong"], "title": "A Note on Code Quality Score: LLMs for Maintainable Large Codebases", "comment": "24 pages, ICLR format", "summary": "Maintaining code quality in large-scale software systems presents significant\nchallenges, particularly in settings where a large numbers of engineers work\nconcurrently on a codebase. This paper introduces Code Quality Score (CQS)\nsystem to automatically detect issues with a set of code changes and provide\nactionable insights. At its core, the CQS system is powered by two Llama3\nmodels, fine-tuned (with SFT and offline RL approaches), to a) detect common\ncode quality issues related to coding best practices and b) to provide good\n``critiques'' for LLM-generated code review respectively. To maintain good user\nexperience, we layer the system with hand-crafted rules to filter out incorrect\nresponses/hallucinations. Offline evaluations show that our CQS system is able\nto achieve an impressive precision rate for identifying valid issues. This\nsystem has already been rolled out to developers in an industrial scale setting\nand has consistently achieved 60\\% week over week user helpfulness rate,\ndemonstrating its effectiveness in a real-world environment. In this paper, we\npresent details of the CQS system along with some learnings on curating\ndeveloper feedback to create training data for LLM fine-tuning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLlama3\u6a21\u578b\u7684\u4ee3\u7801\u8d28\u91cf\u8bc4\u5206\u7cfb\u7edf\uff08CQS\uff09\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4b\u4ee3\u7801\u95ee\u9898\u5e76\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\uff0c\u5df2\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u591a\u5de5\u7a0b\u5e08\u5e76\u884c\u5f00\u53d1\u5bfc\u81f4\u4ee3\u7801\u8d28\u91cf\u7ef4\u62a4\u56f0\u96be\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u4f9b\u5b9e\u65f6\u53cd\u9988\u3002", "method": "CQS\u7cfb\u7edf\u7ed3\u5408\u4e24\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684Llama3\u6a21\u578b\uff08SFT\u548c\u79bb\u7ebfRL\u65b9\u6cd5\uff09\u68c0\u6d4b\u4ee3\u7801\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u89c4\u5219\u8fc7\u6ee4\u9519\u8bef\u54cd\u5e94\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u663e\u793aCQS\u7cfb\u7edf\u5728\u8bc6\u522b\u6709\u6548\u95ee\u9898\u65b9\u9762\u5177\u6709\u9ad8\u7cbe\u5ea6\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u7528\u6237\u6ee1\u610f\u5ea6\u8fbe60%\u3002", "conclusion": "CQS\u7cfb\u7edf\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4e3aLLM\u5fae\u8c03\u63d0\u4f9b\u4e86\u5f00\u53d1\u8005\u53cd\u9988\u6570\u636e\u7684\u5b9e\u8df5\u7ecf\u9a8c\u3002"}}
{"id": "2508.03603", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03603", "abs": "https://arxiv.org/abs/2508.03603", "authors": ["Iti Shree", "Karine Even-Mendoz", "Tomasz Radzik"], "title": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs", "comment": null, "summary": "Existing LLM-based compiler fuzzers often produce syntactically or\nsemantically invalid test programs, limiting their effectiveness in exercising\ncompiler optimizations and backend components. We introduce ReFuzzer, a\nframework for refining LLM-generated test programs by systematically detecting\nand correcting compilation and runtime violations (e.g. division by zero or\narray out-of-bounds accesses). ReFuzzer employs a feedback loop with a local\nLLM to validate and filter erroneous programs before execution, improving\nfuzzing effectiveness beyond crash detection and enabling the generation of\ndiverse yet valid test programs.\n  We evaluated ReFuzzer's effectiveness across black-, grey- and white-box\nfuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs'\nvalidity from 47.0-49.4% to 96.6-97.3%, with an average processing time of\n2.9-3.5 s per test program on a dual-GPU machine. Further, refuzzing\nsignificantly increased code coverage in critical optimization and IR\ngeneration components. For example, vectorization coverage had an absolute\nimprovement of 9.2%, 2.3%, and 7.1% in black-, grey-, and white-box fuzzing,\nenhancing testing effectiveness.", "AI": {"tldr": "ReFuzzer\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u6d4b\u548c\u4fee\u6b63LLM\u751f\u6210\u7684\u6d4b\u8bd5\u7a0b\u5e8f\u4e2d\u7684\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u548c\u4ee3\u7801\u8986\u76d6\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u751f\u6210\u7684\u6d4b\u8bd5\u7a0b\u5e8f\u5e38\u5b58\u5728\u8bed\u6cd5\u6216\u8bed\u4e49\u9519\u8bef\uff0c\u9650\u5236\u4e86\u5176\u5728\u6d4b\u8bd5\u7f16\u8bd1\u5668\u4f18\u5316\u548c\u540e\u7aef\u7ec4\u4ef6\u4e2d\u7684\u6548\u679c\u3002", "method": "ReFuzzer\u91c7\u7528\u53cd\u9988\u5faa\u73af\u673a\u5236\uff0c\u5229\u7528\u672c\u5730LLM\u9a8c\u8bc1\u548c\u8fc7\u6ee4\u9519\u8bef\u7a0b\u5e8f\uff0c\u786e\u4fdd\u7a0b\u5e8f\u5728\u8fd0\u884c\u524d\u6709\u6548\u3002", "result": "ReFuzzer\u5c06\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u4ece47.0-49.4%\u63d0\u5347\u81f396.6-97.3%\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u5173\u952e\u4f18\u5316\u548cIR\u751f\u6210\u7ec4\u4ef6\u7684\u4ee3\u7801\u8986\u76d6\u7387\u3002", "conclusion": "ReFuzzer\u901a\u8fc7\u7cfb\u7edf\u6027\u4fee\u6b63\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6d4b\u8bd5\u573a\u666f\u3002"}}
{"id": "2508.03641", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03641", "abs": "https://arxiv.org/abs/2508.03641", "authors": ["Marco T. Moraz\u00e1n", "David Anthony K. Fields", "Andr\u00e9s M. Garced", "Tijana Mini\u0107"], "title": "Visual Execution and Validation of Finite-State Machines and Pushdown Automata", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "In Formal Languages and Automata Theory courses, students find understanding\nnondeterministic finite-state and pushdown automata difficult. In many cases,\nthis means that it is challenging for them to comprehend the operational\nsemantics of such machines and, as a consequence, determine why a word is\naccepted or rejected. This is not entirely surprising, because students are\nmostly trained to design and implement deterministic programs. Comprehension of\npushdown automata is further complicated, because reasoning about the stack is\nnecessary. A common difficulty students face, for example, is understanding\nthat two different computations on the same word may reach the same state with\ndifferent stack values. To aid student understanding, we present two novel\ndynamic visualization tools for FSM -- a domain-specific programming language\nfor the Automata Theory classroom -- to support the design of such machines.\nThese tools visualize all computations that may be performed, respectively, by\na nondeterministic finite-state machine or by a pushdown automata in a stepwise\nmanner. In addition, these tools aid the machine verification process by\nallowing users to visually validate whether the properties a state represents\nhold when a machine transitions into it.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u975e\u786e\u5b9a\u6027\u6709\u9650\u72b6\u6001\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u64cd\u4f5c\u8bed\u4e49\u3002", "motivation": "\u5b66\u751f\u5728\u5f62\u5f0f\u8bed\u8a00\u4e0e\u81ea\u52a8\u673a\u7406\u8bba\u8bfe\u7a0b\u4e2d\u96be\u4ee5\u7406\u89e3\u975e\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u64cd\u4f5c\u8bed\u4e49\uff0c\u5c24\u5176\u662f\u5806\u6808\u76f8\u5173\u7684\u63a8\u7406\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u9010\u6b65\u5c55\u793a\u975e\u786e\u5b9a\u6027\u6709\u9650\u72b6\u6001\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u6240\u6709\u53ef\u80fd\u8ba1\u7b97\uff0c\u5e76\u652f\u6301\u673a\u5668\u9a8c\u8bc1\u3002", "result": "\u5de5\u5177\u80fd\u591f\u5e2e\u52a9\u5b66\u751f\u76f4\u89c2\u5730\u7406\u89e3\u81ea\u52a8\u673a\u7684\u884c\u4e3a\uff0c\u9a8c\u8bc1\u72b6\u6001\u8f6c\u6362\u65f6\u7684\u5c5e\u6027\u3002", "conclusion": "\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u5bf9\u975e\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2508.02733", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.02733", "abs": "https://arxiv.org/abs/2508.02733", "authors": ["Rijul Jain", "Shraddha Barke", "Gabriel Ebner", "Md Rakib Hossain Misu", "Shan Lu", "Sarah Fakhoury"], "title": "What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus", "comment": null, "summary": "Proof-oriented programming languages (POPLs) empower developers to write code\nalongside formal correctness proofs, providing formal guarantees that the code\nadheres to specified requirements. Despite their powerful capabilities, POPLs\npresent a steep learning curve and have not yet been adopted by the broader\nsoftware community. The lack of understanding about the proof-development\nprocess and how expert proof developers interact with POPLs has hindered the\nadvancement of effective proof engineering and the development of\nproof-synthesis models/tools.\n  In this work, we conduct a user study, involving the collection and analysis\nof fine-grained source code telemetry from eight experts working with two\nlanguages, F* and Verus. Results reveal interesting trends and patterns about\nhow experts reason about proofs and key challenges encountered during the proof\ndevelopment process. We identify three distinct strategies and multiple\ninformal practices that are not captured final code snapshots, yet are\npredictive of task outcomes. We translate these findings into concrete design\nguidance for AI proof assistants: bias toward early specification drafting,\nexplicit sub-goal decomposition, bounded active errors, and disciplined\nverifier interaction. We also present a case study of an F* proof agent\ngrounded in these recommendations, and demonstrate improved performance over\nbaseline LLMs", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u5206\u6790\u4e13\u5bb6\u5728F*\u548cVerus\u8bed\u8a00\u4e2d\u7684\u8bc1\u660e\u5f00\u53d1\u884c\u4e3a\uff0c\u603b\u7ed3\u51fa\u4e09\u79cd\u7b56\u7565\u548c\u975e\u6b63\u5f0f\u5b9e\u8df5\uff0c\u5e76\u63d0\u51fa\u4e86AI\u8bc1\u660e\u52a9\u624b\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1\u8bc1\u660e\u5bfc\u5411\u7f16\u7a0b\u8bed\u8a00\uff08POPLs\uff09\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u4f46\u5176\u9ad8\u5b66\u4e60\u95e8\u69db\u548c\u7f3a\u4e4f\u5bf9\u8bc1\u660e\u5f00\u53d1\u8fc7\u7a0b\u7684\u7406\u89e3\u963b\u788d\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u516b\u4f4d\u4e13\u5bb6\u5728F*\u548cVerus\u4e2d\u7684\u6e90\u4ee3\u7801\u9065\u6d4b\u6570\u636e\uff0c\u8bc6\u522b\u8bc1\u660e\u5f00\u53d1\u4e2d\u7684\u7b56\u7565\u548c\u6311\u6218\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u7b56\u7565\u548c\u975e\u6b63\u5f0f\u5b9e\u8df5\uff0c\u63d0\u51faAI\u8bc1\u660e\u52a9\u624b\u7684\u8bbe\u8ba1\u5efa\u8bae\uff08\u5982\u65e9\u671f\u89c4\u8303\u8d77\u8349\u3001\u663e\u5f0f\u5b50\u76ee\u6807\u5206\u89e3\u7b49\uff09\uff0c\u5e76\u901a\u8fc7F*\u8bc1\u660e\u4ee3\u7406\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6539\u8fdbAI\u8bc1\u660e\u52a9\u624b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8e\u5efa\u8bae\u7684F*\u4ee3\u7406\u4f18\u4e8e\u57fa\u7ebfLLMs\u3002"}}
{"id": "2508.02827", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02827", "abs": "https://arxiv.org/abs/2508.02827", "authors": ["Ora Nova Fandina", "Eitan Farchi", "Shmulik Froimovich", "Rami Katan", "Alice Podolsky", "Orna Raz", "Avi Ziv"], "title": "Automated Validation of LLM-based Evaluators for Software Engineering Artifacts", "comment": null, "summary": "Automation in software engineering increasingly relies on large language\nmodels (LLMs) to generate, review, and assess code artifacts. However,\nestablishing LLMs as reliable evaluators remains an open challenge: human\nevaluations are costly, subjective and non scalable, while existing automated\nmethods fail to discern fine grained variations in artifact quality.\n  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation),\nan automated framework for benchmarking LLM based evaluators across software\nengineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder\napplies novel generation techniques to automatically synthesize artifacts with\nprogressively reduced quality, and Evaluator Tester quantifies each candidate\nevaluator configuration by measuring how closely its rankings align with\nexpected ordering.\n  A key feature of REFINE is controllability: users can tune the granularity of\ndegradation to progressively refine evaluator configurations, from coarse\nfiltering to stress testing on subtle quality gaps.\n  While the methodology is general, we focus on coding tasks reflecting the\npractical demands in our production setting. REFINE was integrated into IBM's\ninternal development workflows and applied to code generation, translation, and\nsummarization for COBOL, an enterprise critical programming language, using\nindustrial data. It was used to identify LLM as a Judge configurations that\nlifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks.\nThese nuance sensitive evaluators are now actively used by model training teams\nto support model release decisions.", "AI": {"tldr": "REFINE\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u751f\u6210\u6e10\u8fdb\u8d28\u91cf\u4e0b\u964d\u7684\u6570\u636e\u96c6\u548c\u91cf\u5316\u8bc4\u4f30\u5668\u914d\u7f6e\u7684\u6392\u540d\u51c6\u786e\u6027\uff0c\u63d0\u5347\u8bc4\u4f30\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u8bc4\u4f30\u6210\u672c\u9ad8\u4e14\u4e0d\u5177\u6269\u5c55\u6027\uff0c\u800c\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u4ee3\u7801\u8d28\u91cf\u7684\u7ec6\u5fae\u5dee\u5f02\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "REFINE\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1aHierarchy Dataset Builder\u751f\u6210\u6e10\u8fdb\u8d28\u91cf\u4e0b\u964d\u7684\u4ee3\u7801\u6570\u636e\u96c6\uff0cEvaluator Tester\u901a\u8fc7\u6392\u540d\u5bf9\u9f50\u91cf\u5316\u8bc4\u4f30\u5668\u914d\u7f6e\u7684\u51c6\u786e\u6027\u3002", "result": "REFINE\u5728IBM\u5185\u90e8\u5de5\u4f5c\u6d41\u4e2d\u5e94\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u4f30\u5668\u914d\u7f6e\u7684\u51c6\u786e\u6027\uff0c\u5c06\u67d0\u4e9b\u4efb\u52a1\u7684\u8bc4\u5206\u4ece0.7\u63d0\u5347\u81f30.9\u4ee5\u4e0a\u3002", "conclusion": "REFINE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u63a7\u4e14\u9ad8\u6548\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u652f\u6301\u6a21\u578b\u8bad\u7ec3\u56e2\u961f\u505a\u51fa\u66f4\u7cbe\u51c6\u7684\u53d1\u5e03\u51b3\u7b56\u3002"}}
{"id": "2508.02968", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02968", "abs": "https://arxiv.org/abs/2508.02968", "authors": ["Shavindra Wickramathilaka", "John Grundy", "Kashumi Madampe", "Omar Haggag"], "title": "Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors", "comment": "This paper has been submitted to ACM Transactions on Software\n  Engineering and Methodology (TOSEM)", "summary": "The global ageing population presents a growing societal challenge, creating\nan urgent need for inclusive technologies that promote autonomy among older\nadults. Software practitioners can address this by delivering digital services\nthat enhance seniors' independence and reduce reliance on routine support from\nfamily members and healthcare infrastructure. However, traditional development\npractices, constrained by time and resources, often result in applications with\nmajor accessibility and personalisation barriers. Increasing pressure from\nregulatory requirements, such as the European Accessibility Act (EAA), and the\npersonal empathy many developers feel toward supporting their older loved ones\nand their own future selves have created a demand for tools that support the\ndevelopment of accessible and adaptive software. To address this demand, this\npaper presents an interview-based empirical study with 18 software\npractitioners, evaluating AdaptForge: a low-code model-driven engineering (MDE)\ntool that enables the efficient creation of accessible and adaptive\napplications for senior users by mitigating development constraints through\nautomated code generation. Based on these insights, we identify developer\nexpectations for adopting such tools as industry-standard solutions and provide\nempirically grounded recommendations for designing low-code tools that support\naccessible and adaptive software development.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f4e\u4ee3\u7801\u5de5\u5177AdaptForge\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u5e2e\u52a9\u5f00\u53d1\u8005\u9ad8\u6548\u521b\u5efa\u9002\u5e94\u8001\u5e74\u7528\u6237\u9700\u6c42\u7684\u53ef\u8bbf\u95ee\u548c\u81ea\u9002\u5e94\u5e94\u7528\u3002", "motivation": "\u5168\u7403\u8001\u9f84\u5316\u95ee\u9898\u52a0\u5267\uff0c\u4e9f\u9700\u652f\u6301\u8001\u5e74\u4eba\u81ea\u4e3b\u6027\u7684\u6280\u672f\u3002\u4f20\u7edf\u5f00\u53d1\u65b9\u5f0f\u5b58\u5728\u53ef\u8bbf\u95ee\u6027\u548c\u4e2a\u6027\u5316\u969c\u788d\uff0c\u5f00\u53d1\u8005\u9700\u5de5\u5177\u4ee5\u6ee1\u8db3\u6cd5\u89c4\u8981\u6c42\u548c\u540c\u7406\u5fc3\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8bbf\u8c0818\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\uff0c\u8bc4\u4f30\u4f4e\u4ee3\u7801\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u5de5\u5177AdaptForge\u3002", "result": "\u7814\u7a76\u660e\u786e\u4e86\u5f00\u53d1\u8005\u5bf9\u7c7b\u4f3c\u5de5\u5177\u7684\u671f\u671b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u4f4e\u4ee3\u7801\u5de5\u5177\u7684\u5efa\u8bae\u3002", "conclusion": "AdaptForge\u80fd\u6709\u6548\u89e3\u51b3\u5f00\u53d1\u7ea6\u675f\uff0c\u652f\u6301\u53ef\u8bbf\u95ee\u548c\u81ea\u9002\u5e94\u8f6f\u4ef6\u5f00\u53d1\uff0c\u672a\u6765\u53ef\u6210\u4e3a\u884c\u4e1a\u6807\u51c6\u3002"}}
{"id": "2508.02998", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02998", "abs": "https://arxiv.org/abs/2508.02998", "authors": ["Haiyang Li"], "title": "MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode generation. However, current evaluation datasets suffer from issues such\nas the lack of runnable test cases, deviation from the distribution of\nreal-world code, and the ability to evaluate only the Python language. These\nlimitations undermine the credibility of the evaluation results.\n  To address these limitations, we introduce \\textbf{MRG-Bench} (Multi-language\nRepository-level Code Generation Benchmark), a novel dataset that provides a\nmore accurate evaluation of LLMs in practical repository-level code generation\ntasks. MRG-Bench has three main features: (1) practical data sourced from\nreal-world code repositories that align to the practical distribution, (2)\nmultiple programming languages support, including Python, Java, and Go, and (3)\nproject-level runnable test cases to assess the quality of the generated code.\n  Based on MRG-Bench, we conducted extensive experiments including large\nlanguage models, long-context models, and RAG-related methods. These evaluation\nresults demonstrate that \\textbf{current repository-level code generation\ntechniques suffer from significant performance deficiencies}. To further\ninvestigate why models fail, we designed novel experiments to annotate the\nunderlying causes of generation errors. The results explicitly show that the\nmajority of methods suffer from \"\\textbf{difficulty in understanding user\nrequirements},\" failing to comprehend their assigned tasks accurately.\nMoreover, the impact of different repository-level contexts on this issue\nexhibits significant disparities across different programming languages,\nsuggesting that, in practice, specialized contextual information needs to be\ndesigned for different languages.", "AI": {"tldr": "MRG-Bench\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u53ef\u8fd0\u884c\u6d4b\u8bd5\u7528\u4f8b\u3001\u504f\u79bb\u771f\u5b9e\u4ee3\u7801\u5206\u5e03\u548c\u4ec5\u652f\u6301Python\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6280\u672f\u5728\u7406\u89e3\u7528\u6237\u9700\u6c42\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6570\u636e\u96c6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u7f3a\u4e4f\u53ef\u8fd0\u884c\u6d4b\u8bd5\u7528\u4f8b\u3001\u504f\u79bb\u771f\u5b9e\u4ee3\u7801\u5206\u5e03\u548c\u4ec5\u652f\u6301Python\uff0c\u5f71\u54cd\u4e86\u8bc4\u4f30\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f15\u5165MRG-Bench\u6570\u636e\u96c6\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff08Python\u3001Java\u3001Go\uff09\uff0c\u63d0\u4f9b\u771f\u5b9e\u4ee3\u7801\u5e93\u6570\u636e\u548c\u9879\u76ee\u7ea7\u53ef\u8fd0\u884c\u6d4b\u8bd5\u7528\u4f8b\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30LLMs\u3001\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u548cRAG\u65b9\u6cd5\u3002", "result": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6280\u672f\u5728\u7406\u89e3\u7528\u6237\u9700\u6c42\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5bf9\u4e0a\u4e0b\u6587\u7684\u9700\u6c42\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "MRG-Bench\u4e3a\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u7684\u4e0d\u8db3\uff0c\u5e76\u5f3a\u8c03\u9700\u9488\u5bf9\u4e0d\u540c\u8bed\u8a00\u8bbe\u8ba1\u4e13\u7528\u4e0a\u4e0b\u6587\u3002"}}
{"id": "2508.03012", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03012", "abs": "https://arxiv.org/abs/2508.03012", "authors": ["Zexiong Ma", "Chao Peng", "Qunhong Zeng", "Pengfei Gao", "Yanzhen Zou", "Bing Xie"], "title": "Tool-integrated Reinforcement Learning for Repo Deep Search", "comment": null, "summary": "Issue localization, the process of identifying code locations that need\nmodification to resolve software issues, is a critical yet challenging task in\nsoftware development. The semantic gap between natural language issue\ndescriptions and faulty code requires complex multi-hop reasoning through code\ndependencies. Existing LLM-based agents attempt to address this by integrating\nrepository retrieval tools. However, this transforms issue localization into a\ndemanding task we call Repo Deep Search, which requires the LLM to effectively\nutilize various repository retrieval tools throughout a multi-step reasoning\nand navigation process. To tackle this challenge, we present ToolTrain, a\ntwo-stage tool-integrated training framework combining rejection-sampled\nsupervised fine-tuning and tool-integrated reinforcement learning to enhance\nLLMs' ability to use retrieval tools for issue localization. Experimental\nresults show that ToolTrain-trained models achieve state-of-the-art\nperformance, with our 32B model even surpassing Claude-3.7 on function-level\nlocalization. The results also show that improved localization performance\ntranslates to better end-to-end issue resolution performance. This further\ndemonstrates that training for issue localization is a viable and effective\nstrategy for improving automated software development.", "AI": {"tldr": "ToolTrain\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5de5\u5177\u96c6\u6210\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u7684\u76d1\u7763\u5fae\u8c03\u548c\u5de5\u5177\u96c6\u6210\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347LLM\u5728\u95ee\u9898\u5b9a\u4f4d\u4e2d\u4f7f\u7528\u68c0\u7d22\u5de5\u5177\u7684\u80fd\u529b\uff0c\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u4e0e\u9519\u8bef\u4ee3\u7801\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4ee5\u53ca\u73b0\u6709LLM\u4ee3\u7406\u5728\u591a\u6b65\u63a8\u7406\u548c\u5bfc\u822a\u8fc7\u7a0b\u4e2d\u6709\u6548\u5229\u7528\u68c0\u7d22\u5de5\u5177\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faToolTrain\u6846\u67b6\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u7684\u76d1\u7763\u5fae\u8c03\u548c\u5de5\u5177\u96c6\u6210\u5f3a\u5316\u5b66\u4e60\uff0c\u8bad\u7ec3LLM\u4ee5\u66f4\u597d\u5730\u4f7f\u7528\u68c0\u7d22\u5de5\u5177\u8fdb\u884c\u95ee\u9898\u5b9a\u4f4d\u3002", "result": "ToolTrain\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u95ee\u9898\u5b9a\u4f4d\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c32B\u6a21\u578b\u751a\u81f3\u8d85\u8d8aClaude-3.7\uff0c\u4e14\u5b9a\u4f4d\u6027\u80fd\u63d0\u5347\u5e26\u6765\u66f4\u597d\u7684\u7aef\u5230\u7aef\u95ee\u9898\u89e3\u51b3\u6027\u80fd\u3002", "conclusion": "ToolTrain\u8bc1\u660e\u4e86\u901a\u8fc7\u95ee\u9898\u5b9a\u4f4d\u8bad\u7ec3\u63d0\u5347\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.03215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03215", "abs": "https://arxiv.org/abs/2508.03215", "authors": ["Dongming Jin", "Zhi Jin", "Linyu Li", "Zheng Fang", "Jia Li", "Xiaohong Chen"], "title": "A System Model Generation Benchmark from Natural Language Requirements", "comment": "16 pages, 14 figures", "summary": "System models, a critical artifact in software development, provide a formal\nabstraction of both the structural and behavioral aspects of software systems,\nwhich can facilitate the early requirements analysis and architecture design.\nHowever, developing system models remains challenging due to the specific\nsyntax of model description languages and the relative scarcity of public model\nexamples. While large language models (LLMs) have shown promise in generating\ncode with programming languages and could potentially aid in system model\ndevelopment, no benchmarks currently exist for evaluating their ability to\ngenerate system models with specific description languages. We present\nSysMBench, which comprises 151 human-curated scenarios spanning a wide range of\npopular domains and varying difficulty levels. Each scenario mainly comprises a\nnatural language requirements description, a system model expressed in a\nspecific model description language, and a visualized system model diagram. The\nrequirements description is fed as user input to the LLM, the system model with\ndescription language is used to verify if the generated system model conforms\nto the requirements, and the visualized diagram serves to support manual\nvalidation. We introduce SysMEval, a semantic-aware evaluation metric to\nevaluate the quality of generated system models. We evaluate 17 popular LLMs on\nthis task with three traditional metrics and SysMEval, from directly prompting\nto three commonly used enhancement strategies. Our in-depth evaluation shows\nthat LLMs perform poorly on SysMBench, with the highest BLEU of 4% and\nSysMEval-F1 of 62%. We release the SysMBench and its evaluation framework to\nenable future research on LLM-based system model generation.", "AI": {"tldr": "SysMBench\u662f\u4e00\u4e2a\u5305\u542b151\u4e2a\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7cfb\u7edf\u6a21\u578b\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793aLLM\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7cfb\u7edf\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f00\u53d1\u56f0\u96be\u4e14\u7f3a\u4e4f\u516c\u5f00\u793a\u4f8b\u3002LLM\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u8bc4\u4f30\u5176\u751f\u6210\u7cfb\u7edf\u6a21\u578b\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51faSysMBench\u57fa\u51c6\uff0c\u5305\u542b\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u63cf\u8ff0\u3001\u7cfb\u7edf\u6a21\u578b\u548c\u53ef\u89c6\u5316\u56fe\u8868\uff0c\u5e76\u5f15\u5165SysMEval\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u8bc4\u4f3017\u79cdLLM\uff0c\u6700\u9ad8BLEU\u4e3a4%\uff0cSysMEval-F1\u4e3a62%\uff0c\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "LLM\u5728\u7cfb\u7edf\u6a21\u578b\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u9650\uff0cSysMBench\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u6846\u67b6\u3002"}}
{"id": "2508.03258", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03258", "abs": "https://arxiv.org/abs/2508.03258", "authors": ["Yueyue Liu", "Hongyu Zhang", "Yuantian Miao"], "title": "SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization", "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4 and Llama have shown remarkable\ncapabilities in a variety of software engineering tasks. Despite the\nadvancements, their practical deployment faces challenges, including high\nfinancial costs, long response time, and varying performance, especially when\nhandling a large number of queries (jobs). Existing optimization strategies for\ndeploying LLMs for diverse tasks focus on static scheduling, which requires\nextensive training data for performance prediction, increasing the\ncomputational costs and limiting the applicability and flexibility. In this\npaper, we propose the SmartLLMs Scheduler (SLS), a dynamic and cost-effective\nscheduling solution. The key idea is to learn LLMs' performance on diverse\ntasks and incorporate their real-time feedback to update strategies\nperiodically. Specifically, SLS incorporates three key components, including an\nAdaptive Cache Manager, a Performance-Cost Optimized Scheduler, and a Dynamic\nUpdate Manager. The Cache Manager stores the outputs of previously processed\nqueries and employs an adaptive strategy to reduce redundant computations and\nminimize response times. For queries not found in the cache, the Scheduler\ndynamically allocates them to the most suitable LLM based on the predicted\nperformance and cost from models that take both query-specific and LLM-specific\nfeatures as input. The Update Manager continuously refines the cache and\nscheduling strategies based on real-time feedback from the assigned queries to\nenhance decision-making and adapt to evolving task characteristics. To evaluate\nthe effectiveness of SLS, we conduct extensive experiments on two LLM-based\nsoftware engineering tasks, including log parsing and code generation. The\nresults show that SLS significantly outperforms the baseline methods, achieving\nan average performance improvement of 198.82% and an average processing time\nreduction of 63.28%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSmartLLMs Scheduler (SLS)\uff0c\u4e00\u79cd\u52a8\u6001\u8c03\u5ea6\u65b9\u6848\uff0c\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u4f18\u5316LLM\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u9ad8\u6210\u672c\u3001\u957f\u54cd\u5e94\u65f6\u95f4\u548c\u6027\u80fd\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u9759\u6001\u8c03\u5ea6\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u9002\u7528\u6027\u3002", "method": "SLS\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u81ea\u9002\u5e94\u7f13\u5b58\u7ba1\u7406\u5668\u3001\u6027\u80fd-\u6210\u672c\u4f18\u5316\u8c03\u5ea6\u5668\u548c\u52a8\u6001\u66f4\u65b0\u7ba1\u7406\u5668\uff0c\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u52a8\u6001\u8c03\u6574\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSLS\u5728\u6027\u80fd\u4e0a\u5e73\u5747\u63d0\u5347198.82%\uff0c\u5904\u7406\u65f6\u95f4\u51cf\u5c1163.28%\u3002", "conclusion": "SLS\u4e3aLLM\u7684\u52a8\u6001\u8c03\u5ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.03298", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03298", "abs": "https://arxiv.org/abs/2508.03298", "authors": ["Kristian Kolthoff", "Felix Kretzer", "Christian Bartelt", "Alexander Maedche", "Simone Paolo Ponzetto"], "title": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking", "comment": null, "summary": "GUI prototyping is a fundamental component in the development of modern\ninteractive systems, which are now ubiquitous across diverse application\ndomains. GUI prototypes play a critical role in requirements elicitation by\nenabling stakeholders to visualize, assess, and refine system concepts\ncollaboratively. Moreover, prototypes serve as effective tools for early\ntesting, iterative evaluation, and validation of design ideas with both end\nusers and development teams. Despite these advantages, the process of\nconstructing GUI prototypes remains resource-intensive and time-consuming,\nfrequently demanding substantial effort and expertise. Recent research has\nsought to alleviate this burden through NL-based GUI retrieval approaches,\nwhich typically rely on embedding-based retrieval or tailored ranking models\nfor specific GUI repositories. However, these methods often suffer from limited\nretrieval performance and struggle to generalize across arbitrary GUI datasets.\nIn this work, we present GUI-ReRank, a novel framework that integrates rapid\nembedding-based constrained retrieval models with highly effective MLLM-based\nreranking techniques. GUI-ReRank further introduces a fully customizable GUI\nrepository annotation and embedding pipeline, enabling users to effortlessly\nmake their own GUI repositories searchable, which allows for rapid discovery of\nrelevant GUIs for inspiration or seamless integration into customized LLM-based\nRAG workflows. We evaluated our approach on an established NL-based GUI\nretrieval benchmark, demonstrating that GUI-ReRank significantly outperforms\nSOTA tailored LTR models in both retrieval accuracy and generalizability.\nAdditionally, we conducted a comprehensive cost and efficiency analysis of\nemploying MLLMs for reranking, providing valuable insights regarding the\ntrade-offs between retrieval effectiveness and computational resources. Video:\nhttps://youtu.be/_7x9UCh82ug", "AI": {"tldr": "GUI-ReRank\u662f\u4e00\u4e2a\u7ed3\u5408\u5d4c\u5165\u68c0\u7d22\u548cMLLM\u91cd\u6392\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86GUI\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "GUI\u539f\u578b\u8bbe\u8ba1\u8d44\u6e90\u5bc6\u96c6\u4e14\u8017\u65f6\uff0c\u73b0\u6709NL\u68c0\u7d22\u65b9\u6cd5\u6027\u80fd\u6709\u9650\u4e14\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u96c6\u6210\u5feb\u901f\u5d4c\u5165\u68c0\u7d22\u4e0eMLLM\u91cd\u6392\u6280\u672f\uff0c\u5e76\u63d0\u4f9b\u53ef\u5b9a\u5236\u7684GUI\u5e93\u6807\u6ce8\u548c\u5d4c\u5165\u6d41\u7a0b\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709LTR\u6a21\u578b\uff0c\u5e76\u5728\u68c0\u7d22\u6548\u679c\u4e0e\u8ba1\u7b97\u8d44\u6e90\u95f4\u63d0\u4f9b\u6743\u8861\u5206\u6790\u3002", "conclusion": "GUI-ReRank\u4e3aGUI\u68c0\u7d22\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.03329", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03329", "abs": "https://arxiv.org/abs/2508.03329", "authors": ["Mari Ashiga", "Vardan Voskanyan", "Fateme Dinmohammadi", "Jingzhi Gong", "Paul Brookes", "Matthew Truscott", "Rafail Giavrimis", "Mike Basios", "Leslie Kanthan", "Wei Jie"], "title": "Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach", "comment": "Submitted to ASE'25 Industry Showcase", "summary": "Recent advancements in Large Language Models (LLMs) for code optimization\nhave enabled industrial platforms to automate software performance engineering\nat unprecedented scale and speed. Yet, organizations in regulated industries\nface strict constraints on which LLMs they can use - many cannot utilize\ncommercial models due to data privacy regulations and compliance requirements,\ncreating a significant challenge for achieving high-quality code optimization\nwhile maintaining cost-effectiveness. We address this by implementing a\nMixture-of-Agents (MoA) approach that directly synthesizes code from multiple\nspecialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm\n(GA)-based ensemble system and individual LLM optimizers using real-world\nindustrial codebases. Our key contributions include: (1) First MoA application\nto industrial code optimization using real-world codebases; (2) Empirical\nevidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost\nsavings and 28.6% to 32.2% faster optimization times for regulated\nenvironments; (3) Deployment guidelines demonstrating GA's advantage with\ncommercial models while both ensembles outperform individual LLMs; and (4)\nReal-world validation across 50 code snippets and seven LLM combinations,\ngenerating over 8,700 variants, addresses gaps in industrial LLM ensemble\nevaluation. This provides actionable guidance for organizations balancing\nregulatory compliance with optimization performance in production environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdMixture-of-Agents\uff08MoA\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u53d7\u76d1\u7ba1\u884c\u4e1a\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4ee3\u7801\u4f18\u5316\uff0c\u7ed3\u5408\u5f00\u6e90\u6a21\u578b\u8282\u7701\u6210\u672c\u5e76\u63d0\u5347\u901f\u5ea6\u3002", "motivation": "\u53d7\u76d1\u7ba1\u884c\u4e1a\u56e0\u9690\u79c1\u548c\u5408\u89c4\u8981\u6c42\u65e0\u6cd5\u4f7f\u7528\u5546\u4e1aLLM\uff0c\u9700\u627e\u5230\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u8d28\u91cf\u4ee3\u7801\u4f18\u5316\u53c8\u7ecf\u6d4e\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528MoA\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u4e2a\u4e13\u7528LLM\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u4e0e\u9057\u4f20\u7b97\u6cd5\uff08GA\uff09\u548c\u5355\u4e2aLLM\u4f18\u5316\u5668\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "MoA\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8282\u770114.3%\u81f322.2%\u6210\u672c\uff0c\u4f18\u5316\u65f6\u95f4\u7f29\u77ed28.6%\u81f332.2%\u3002GA\u5728\u5546\u4e1a\u6a21\u578b\u4e2d\u66f4\u4f18\uff0c\u4f46\u4e24\u79cd\u96c6\u6210\u65b9\u6cd5\u5747\u4f18\u4e8e\u5355\u4e2aLLM\u3002", "conclusion": "MoA\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u63d0\u4f9b\u4e86\u517c\u987e\u5408\u89c4\u6027\u548c\u4f18\u5316\u6027\u80fd\u7684\u53ef\u884c\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u9a8c\u8bc1\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.03340", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03340", "abs": "https://arxiv.org/abs/2508.03340", "authors": ["Alex Wolf", "Marco Edoardo Palma", "Pooja Rani", "Harald C. Gall"], "title": "Key-Augmented Neural Triggers for Knowledge Sharing", "comment": null, "summary": "Repository-level code comprehension and knowledge sharing remain core\nchallenges in software engineering. Large language models (LLMs) have shown\npromise by generating explanations of program structure and logic. However,\nthese approaches still face limitations: First, relevant knowledge is\ndistributed across multiple files within a repository, aka semantic\nfragmentation. Second, retrieval inefficiency and attention saturation degrade\nperformance in RAG pipelines, where long, unaligned contexts overwhelm\nattention. Third, repository specific training data is scarce and often\noutdated. Finally, proprietary LLMs hinder industrial adoption due to privacy\nand deployment constraints. To address these issues, we propose Key-Augmented\nNeural Triggers (KANT), a novel approach that embeds knowledge anchors into\nboth training and inference. Unlike prior methods, KANT enables internal access\nto repository specific knowledge, reducing fragmentation and grounding\ninference in localized context. Moreover, we synthesize specialized data\ndirectly from code. At inference, knowledge anchors replace verbose context,\nreducing token overhead and latency while supporting efficient, on premise\ndeployment. We evaluate KANT via: a qualitative human evaluation of the\nsynthesized dataset's intent coverage and quality across five dimensions;\ncompare against SOTA baselines across five qualitative dimensions and inference\nspeed; and replication across different LLMs to assess generalizability.\nResults show that the synthetic training data aligned with information-seeking\nneeds. KANT achieved over 60% preference from human annotators and a LocalStack\nexpert (preferring 79% of cases). Also, KANT reduced inference latency by up to\n85% across all models. Overall, it is well-suited for scalable, low-latency,\non-premise deployments, providing a strong foundation for code comprehension.", "AI": {"tldr": "KANT\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5d4c\u5165\u77e5\u8bc6\u951a\u70b9\u89e3\u51b3\u4ee3\u7801\u5e93\u7406\u89e3\u4e2d\u7684\u8bed\u4e49\u788e\u7247\u5316\u548c\u68c0\u7d22\u6548\u7387\u95ee\u9898\uff0c\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u5e76\u652f\u6301\u672c\u5730\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7801\u5e93\u7406\u89e3\u4e2d\u7684\u8bed\u4e49\u788e\u7247\u5316\u3001\u68c0\u7d22\u6548\u7387\u4f4e\u3001\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u4ee5\u53ca\u4e13\u6709LLM\u7684\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51faKey-Augmented Neural Triggers (KANT)\uff0c\u5d4c\u5165\u77e5\u8bc6\u951a\u70b9\uff0c\u5408\u6210\u4e13\u7528\u6570\u636e\uff0c\u51cf\u5c11\u63a8\u7406\u65f6\u7684\u4e0a\u4e0b\u6587\u8d1f\u62c5\u3002", "result": "\u5408\u6210\u6570\u636e\u4e0e\u9700\u6c42\u5bf9\u9f50\uff0cKANT\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u83b760%\u504f\u597d\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e85%\u3002", "conclusion": "KANT\u9002\u5408\u4f4e\u5ef6\u8fdf\u3001\u672c\u5730\u90e8\u7f72\u7684\u4ee3\u7801\u7406\u89e3\uff0c\u4e3a\u884c\u4e1a\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.03369", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03369", "abs": "https://arxiv.org/abs/2508.03369", "authors": ["Beatriz Santana", "Lidiv\u00e2nio Monte", "Bianca Santana de Ara\u00fajo Silva", "Glauco Carneiro", "S\u00e1vio Freire", "Jos\u00e9 Amancio Macedo Santos", "Manoel Mendon\u00e7a"], "title": "Psychological safety in software workplaces: A systematic literature review", "comment": null, "summary": "Context: Psychological safety (PS) is an important factor influencing team\nwell-being and performance, particularly in collaborative and dynamic domains\nsuch as software development. Despite its acknowledged significance, research\non PS within the field of software engineering remains limited. The\nsocio-technical complexities and fast-paced nature of software development\npresent challenges to cultivating PS. To the best of our knowledge, no\nsystematic secondary study has synthesized existing knowledge on PS in the\ncontext of software engineering.\n  Objective: This study aims to systematically review and synthesize the\nexisting body of knowledge on PS in software engineering. Specifically, it\nseeks to identify the potential antecedents and consequences associated with\nthe presence or absence of PS among individuals involved in the software\ndevelopment process.\n  Methods: A systematic literature review was conducted, encompassing studies\nretrieved from four digital libraries. The extracted data were subjected to\nboth quantitative and qualitative analyses.\n  Results: The findings indicate a growing academic interest in PS within\nsoftware engineering, with the majority of studies grounded in Edmondson's\nframework. Factors antecedents of PS were identified at the individual, team,\nand organizational levels, including team autonomy, agile methodologies, and\nleadership behaviors.\n  Conclusion: PS fosters innovation, learning, and team performance within\nsoftware development. However, significant gaps persist in understanding the\ncontextual factors influencing PS, its underlying mechanisms, and effective\nstrategies for its enhancement. Future research should address these gaps by\ninvestigating the practical applications of PS within diverse organizational\nsettings in the software engineering domain.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5fc3\u7406\u5b89\u5168\uff08PS\uff09\u7684\u73b0\u6709\u77e5\u8bc6\uff0c\u8bc6\u522b\u4e86\u5176\u524d\u56e0\u540e\u679c\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5fc3\u7406\u5b89\u5168\u5bf9\u56e2\u961f\u798f\u7949\u548c\u7ee9\u6548\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u76f8\u5173\u7814\u7a76\u6709\u9650\uff0c\u4e9f\u9700\u7cfb\u7edf\u7efc\u8ff0\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u56db\u4e2a\u6570\u5b57\u56fe\u4e66\u9986\u68c0\u7d22\u7814\u7a76\uff0c\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0PS\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u65e5\u76ca\u53d7\u5173\u6ce8\uff0c\u524d\u56e0\u5305\u62ec\u56e2\u961f\u81ea\u4e3b\u6743\u3001\u654f\u6377\u65b9\u6cd5\u548c\u9886\u5bfc\u884c\u4e3a\u3002", "conclusion": "PS\u4fc3\u8fdb\u521b\u65b0\u548c\u5b66\u4e60\uff0c\u4f46\u5bf9\u5176\u5f71\u54cd\u56e0\u7d20\u548c\u63d0\u5347\u7b56\u7565\u7684\u7406\u89e3\u4ecd\u6709\u4e0d\u8db3\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.03393", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03393", "abs": "https://arxiv.org/abs/2508.03393", "authors": ["Muhammad Zohaib", "Muhammad Azeem Akbar", "Sami Hyrynsalmi", "Arif Ali Khan"], "title": "Agentic AI in 6G Software Businesses: A Layered Maturity Model", "comment": "6 pages, 3 figures and FIT'25 Conference", "summary": "The emergence of agentic AI systems in 6G software businesses presents both\nstrategic opportunities and significant challenges. While such systems promise\nincreased autonomy, scalability, and intelligent decision-making across\ndistributed environments, their adoption raises concerns regarding technical\nimmaturity, integration complexity, organizational readiness, and\nperformance-cost trade-offs. In this study, we conducted a preliminary thematic\nmapping to identify factors influencing the adoption of agentic software within\nthe context of 6G. Drawing on a multivocal literature review and targeted\nscanning, we identified 29 motivators and 27 demotivators, which were further\ncategorized into five high-level themes in each group. This thematic mapping\noffers a structured overview of the enabling and inhibiting forces shaping\norganizational readiness for agentic transformation. Positioned as a\nfeasibility assessment, the study represents an early phase of a broader\nresearch initiative aimed at developing and validating a layered maturity model\ngrounded in CMMI model with the software architectural three dimensions\npossibly Data, Business Logic, and Presentation. Ultimately, this work seeks to\nprovide a practical framework to help software-driven organizations assess,\nstructure, and advance their agent-first capabilities in alignment with the\ndemands of 6G.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e866G\u8f6f\u4ef6\u4e1a\u52a1\u4e2d\u4ee3\u7406\u578bAI\u7cfb\u7edf\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u901a\u8fc7\u4e3b\u9898\u6620\u5c04\u8bc6\u522b\u4e86\u5f71\u54cd\u91c7\u7528\u7684\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u884c\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u63a2\u8ba8\u4ee3\u7406\u578bAI\u7cfb\u7edf\u57286G\u73af\u5883\u4e2d\u7684\u6218\u7565\u673a\u9047\u4e0e\u6311\u6218\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u91c7\u7528\u51b3\u7b56\u7684\u4f9d\u636e\u3002", "method": "\u91c7\u7528\u591a\u6e90\u6587\u732e\u7efc\u8ff0\u548c\u9488\u5bf9\u6027\u626b\u63cf\uff0c\u8bc6\u522b\u5e76\u5206\u7c7b\u4e8629\u4e2a\u6fc0\u52b1\u56e0\u7d20\u548c27\u4e2a\u6291\u5236\u56e0\u7d20\u3002", "result": "\u63d0\u51fa\u4e86\u4e94\u7c7b\u9ad8\u5c42\u4e3b\u9898\uff0c\u4e3a\u4ee3\u7406\u578b\u8f6c\u578b\u7684\u7ec4\u7ec7\u51c6\u5907\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u89c6\u89d2\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8f6f\u4ef6\u9a71\u52a8\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u548c\u63d0\u5347\u4ee3\u7406\u4f18\u5148\u80fd\u529b\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2508.03470", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03470", "abs": "https://arxiv.org/abs/2508.03470", "authors": ["Dong wang", "Junji Yu", "Honglin Shu", "Michael Fu", "Chakkrit Tantithamthavorn", "Yasutaka Kamei", "Junjie Chen"], "title": "On the Evaluation of Large Language Models in Multilingual Vulnerability Repair", "comment": null, "summary": "Various Deep Learning-based approaches with pre-trained language models have\nbeen proposed for automatically repairing software vulnerabilities. However,\nthese approaches are limited to a specific programming language (C/C++). Recent\nadvances in large language models (LLMs) offer language-agnostic capabilities\nand strong semantic understanding, exhibiting potential to overcome\nmultilingual vulnerability limitations. Although some work has begun to explore\nLLMs' repair performance, their effectiveness is unsatisfactory. To address\nthese limitations, we conducted a large-scale empirical study to investigate\nthe performance of automated vulnerability repair approaches and\nstate-of-the-art LLMs across seven programming languages. Results show GPT-4o,\ninstruction-tuned with few-shot prompting, performs competitively against the\nleading approach, VulMaster. Additionally, the LLM-based approach shows\nsuperior performance in repairing unique vulnerabilities and is more likely to\nrepair the most dangerous vulnerabilities. Instruction-tuned GPT-4o\ndemonstrates strong generalization on vulnerabilities in previously unseen\nlanguage, outperforming existing approaches. Analysis shows Go consistently\nachieves the highest effectiveness across all model types, while C/C++ performs\nthe worst. Based on findings, we discuss the promise of LLM on multilingual\nvulnerability repair and the reasons behind LLM's failed cases. This work takes\nthe first look at repair approaches and LLMs across multiple languages,\nhighlighting the promising future of adopting LLMs for multilingual\nvulnerability repair.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u591a\u8bed\u8a00\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\uff0c\u53d1\u73b0\u6307\u4ee4\u8c03\u4f18\u7684GPT-4o\u5728\u6027\u80fd\u4e0a\u63a5\u8fd1\u9886\u5148\u65b9\u6cd5VulMaster\uff0c\u5e76\u5728\u67d0\u4e9b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u5c40\u9650\u4e8e\u7279\u5b9a\u8bed\u8a00\uff08\u5982C/C++\uff09\uff0c\u800cLLMs\u5177\u5907\u8bed\u8a00\u65e0\u5173\u6027\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u53ef\u80fd\u7a81\u7834\u591a\u8bed\u8a00\u6f0f\u6d1e\u4fee\u590d\u7684\u9650\u5236\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u548c\u6700\u65b0LLMs\u5728\u4e03\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u6307\u4ee4\u8c03\u4f18\u7684GPT-4o\u3002", "result": "GPT-4o\u5728\u4fee\u590d\u72ec\u7279\u6f0f\u6d1e\u548c\u6700\u5371\u9669\u6f0f\u6d1e\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5728\u672a\u89c1\u8fc7\u7684\u8bed\u8a00\u4e2d\u6cdb\u5316\u80fd\u529b\u5f3a\u3002Go\u8bed\u8a00\u4fee\u590d\u6548\u679c\u6700\u4f73\uff0cC/C++\u6700\u5dee\u3002", "conclusion": "LLMs\u5728\u591a\u8bed\u8a00\u6f0f\u6d1e\u4fee\u590d\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5931\u8d25\u6848\u4f8b\u7684\u539f\u56e0\u3002"}}
{"id": "2508.03487", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.03487", "abs": "https://arxiv.org/abs/2508.03487", "authors": ["Yuanpeng Li", "Qi Long", "Zhiyuan Yao", "Jian Xu", "Lintao Xie", "Xu He", "Lu Geng", "Xin Han", "Yueyan Chen", "Wenbo Duan"], "title": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice", "comment": null, "summary": "As enterprise codebases continue to grow in scale and complexity, the volume\nof lint errors far exceeds engineers' manual remediation capacity, leading to\ncontinuous accumulation of technical debt and hindered development efficiency.\nThis paper presents BitsAI-Fix, an automated lint error remediation workflow\nbased on Large Language Models (LLMs), designed to address this critical\nchallenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for\ncontext expansion and generates search-and-replace format patches through\nspecially trained LLMs, followed by lint scan re-verification to output final\nremediation results. Additionally, our approach introduces an innovative\nprogressive reinforcement learning (RL) training strategy that can\nautomatically acquire verifiable training data during the project cold-start\nphase and continuously iterate the model by collecting online samples through\nfeedback after system deployment. Furthermore, we designed a targeted\nrule-based reward mechanism that combines format rewards and correctness\nrewards while penalizing redundant modifications. We also propose a \"code diff\nmatching\" methodology to continuously track online effectiveness. In production\ndeployment at ByteDance, our solution has supported over 5,000 engineers,\nresolved more than 12,000 static analysis issues, achieved approximately 85%\nremediation accuracy, with around 1,000 weekly active adopters. This work\ndemonstrates the practical feasibility of LLM-based code remediation solutions\nin enterprise environments and serves as a reference for automated code fix in\nlarge-scale industrial scenarios.", "AI": {"tldr": "BitsAI-Fix\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u5316lint\u9519\u8bef\u4fee\u590d\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u6811\u89e3\u6790\u5668\u6269\u5c55\u4e0a\u4e0b\u6587\u5e76\u751f\u6210\u8865\u4e01\uff0c\u7ed3\u5408\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u548c\u89c4\u5219\u5956\u52b1\u673a\u5236\uff0c\u5728\u5b57\u8282\u8df3\u52a8\u751f\u4ea7\u4e2d\u53d6\u5f97\u663e\u8457\u6548\u679c\u3002", "motivation": "\u4f01\u4e1a\u4ee3\u7801\u5e93\u89c4\u6a21\u6269\u5927\u5bfc\u81f4lint\u9519\u8bef\u8fdc\u8d85\u5de5\u7a0b\u5e08\u624b\u52a8\u4fee\u590d\u80fd\u529b\uff0c\u6280\u672f\u503a\u52a1\u79ef\u7d2f\u548c\u5f00\u53d1\u6548\u7387\u53d7\u963b\u3002", "method": "\u4f7f\u7528\u6811\u89e3\u6790\u5668\u6269\u5c55\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7LLM\u751f\u6210\u8865\u4e01\uff0c\u7ed3\u5408\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u548c\u89c4\u5219\u5956\u52b1\u673a\u5236\uff0c\u6301\u7eed\u8ddf\u8e2a\u5728\u7ebf\u6548\u679c\u3002", "result": "\u5728\u5b57\u8282\u8df3\u52a8\u652f\u63015000+\u5de5\u7a0b\u5e08\uff0c\u89e3\u51b312000+\u9759\u6001\u5206\u6790\u95ee\u9898\uff0c\u4fee\u590d\u51c6\u786e\u7387\u7ea685%\uff0c\u6bcf\u5468\u6d3b\u8dc3\u7528\u6237\u7ea61000\u3002", "conclusion": "\u8bc1\u660e\u4e86LLM\u5728\u4ee3\u7801\u4fee\u590d\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u5de5\u4e1a\u573a\u666f\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.03560", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03560", "abs": "https://arxiv.org/abs/2508.03560", "authors": ["Yi Gui", "Zhen Li", "Zhongyi Zhang", "Guohao Wang", "Tianpeng Lv", "Gaoyang Jiang", "Yi Liu", "Dongping Chen", "Yao Wan", "Hongyu Zhang", "Wenbin Jiang", "Xuanhua Shi", "Hai Jin"], "title": "LaTCoder: Converting Webpage Design to Code with Layout-as-Thought", "comment": "KDD 2025 v2", "summary": "Converting webpage designs into code (design-to-code) plays a vital role in\nUser Interface (UI) development for front-end developers, bridging the gap\nbetween visual design and functional implementation. While recent Multimodal\nLarge Language Models (MLLMs) have shown significant potential in\ndesign-to-code tasks, they often fail to accurately preserve the layout during\ncode generation. To this end, we draw inspiration from the Chain-of-Thought\n(CoT) reasoning in human cognition and propose LaTCoder, a novel approach that\nenhances layout preservation in webpage design during code generation with\nLayout-as-Thought (LaT). Specifically, we first introduce a simple yet\nefficient algorithm to divide the webpage design into image blocks. Next, we\nprompt MLLMs using a CoTbased approach to generate code for each block.\nFinally, we apply two assembly strategies-absolute positioning and an\nMLLM-based method-followed by dynamic selection to determine the optimal\noutput. We evaluate the effectiveness of LaTCoder using multiple backbone MLLMs\n(i.e., DeepSeek-VL2, Gemini, and GPT-4o) on both a public benchmark and a newly\nintroduced, more challenging benchmark (CC-HARD) that features complex layouts.\nThe experimental results on automatic metrics demonstrate significant\nimprovements. Specifically, TreeBLEU scores increased by 66.67% and MAE\ndecreased by 38% when using DeepSeek-VL2, compared to direct prompting.\nMoreover, the human preference evaluation results indicate that annotators\nfavor the webpages generated by LaTCoder in over 60% of cases, providing strong\nevidence of the effectiveness of our method.", "AI": {"tldr": "LaTCoder\u901a\u8fc7Layout-as-Thought\u65b9\u6cd5\u63d0\u5347\u7f51\u9875\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u4e2d\u7684\u5e03\u5c40\u4fdd\u7559\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f51\u9875\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u4e2d\u5e03\u5c40\u4fdd\u7559\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002", "method": "\u5c06\u7f51\u9875\u8bbe\u8ba1\u5212\u5206\u4e3a\u56fe\u50cf\u5757\uff0c\u91c7\u7528Chain-of-Thought\u65b9\u6cd5\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u7edd\u5bf9\u5b9a\u4f4d\u548cMLLM\u7ec4\u88c5\u7b56\u7565\u52a8\u6001\u9009\u62e9\u6700\u4f18\u8f93\u51fa\u3002", "result": "\u5728DeepSeek-VL2\u4e0a\uff0cTreeBLEU\u63d0\u534766.67%\uff0cMAE\u964d\u4f4e38%\uff0c60%\u4ee5\u4e0a\u4eba\u5de5\u8bc4\u4f30\u504f\u597dLaTCoder\u751f\u6210\u7ed3\u679c\u3002", "conclusion": "LaTCoder\u6709\u6548\u63d0\u5347\u5e03\u5c40\u4fdd\u7559\u80fd\u529b\uff0c\u4e3a\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u4efb\u52a1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2508.03642", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03642", "abs": "https://arxiv.org/abs/2508.03642", "authors": ["Oliver Westphal"], "title": "Intent Preserving Generation of Diverse and Idiomatic (Code-)Artifacts", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "When automatically generating programming exercise tasks one often also needs\nto automatically generate programs. At the very least when providing sample\nsolutions is part of automated feedback. But programs can also be used as part\nof the exercise task description to communicate a task's requirements.\n  Writing good program generators that produce varied yet idiomatic code while\nbeing easily adaptable for new tasks is challenging. The challenges are\nintensified if task generation requires additional artifacts, like a more\ngeneral behavior specification for testing or additional textual descriptions.\nManually writing generators for multiple different but strongly related\nartifacts gets complicated quickly.\n  We present an approach where instead of writing monolithic generators for\nmultiple connected artifacts one specifies a small set of abstract building\nblocks and for each such building block defines sets of concrete realizations\nfor various kinds of artifacts. Then the intended structure of the resulting\nartifacts is specified as a composition of the small abstract building blocks.\nThis abstract description then serves as the common source from which related\nartifacts can be derived automatically. The approach is generic in the kind of\nartifacts it can produce and is therefore adaptable to a wide range of\ncontexts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u6784\u5efa\u5757\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u7f16\u7a0b\u7ec3\u4e60\u4efb\u52a1\u548c\u76f8\u5173\u5de5\u4ef6\uff0c\u907f\u514d\u7f16\u5199\u590d\u6742\u7684\u5355\u4f53\u751f\u6210\u5668\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u751f\u6210\u7f16\u7a0b\u4efb\u52a1\u65f6\uff0c\u7f16\u5199\u591a\u6837\u4e14\u7b26\u5408\u4e60\u60ef\u7684\u4ee3\u7801\u751f\u6210\u5668\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u9700\u8981\u751f\u6210\u591a\u4e2a\u76f8\u5173\u5de5\u4ef6\u65f6\u7684\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u5c0f\u578b\u62bd\u8c61\u6784\u5efa\u5757\u5b9a\u4e49\u5177\u4f53\u5b9e\u73b0\uff0c\u901a\u8fc7\u7ec4\u5408\u8fd9\u4e9b\u6784\u5efa\u5757\u751f\u6210\u76f8\u5173\u5de5\u4ef6\uff0c\u907f\u514d\u76f4\u63a5\u7f16\u5199\u590d\u6742\u7684\u5355\u4f53\u751f\u6210\u5668\u3002", "result": "\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4e0a\u4e0b\u6587\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u7684\u7f16\u7a0b\u4efb\u52a1\u548c\u76f8\u5173\u5de5\u4ef6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u7f16\u7a0b\u4efb\u52a1\u751f\u6210\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u3002"}}
