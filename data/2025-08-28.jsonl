{"id": "2508.19558", "categories": ["cs.SE", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.19558", "abs": "https://arxiv.org/abs/2508.19558", "authors": ["Zhuohao Li", "Wenqing Chen", "Jianxing Yu", "Zhichao Lu"], "title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "comment": null, "summary": "Embedding models have demonstrated strong performance in tasks like\nclustering, retrieval, and feature extraction while offering computational\nadvantages over generative models and cross-encoders. Benchmarks such as MTEB\nhave shown that text embeddings from large language models (LLMs) capture rich\nsemantic information, but their ability to reflect code-level functional\nsemantics remains unclear. Existing studies largely focus on code clone\ndetection, which emphasizes syntactic similarity and overlooks functional\nunderstanding. In this paper, we focus on the functional consistency of LLM\ncode embeddings, which determines if two code snippets perform the same\nfunction regardless of syntactic differences. We propose a novel data synthesis\nframework called Functionality-Oriented Code Self-Evolution to construct\ndiverse and challenging benchmarks. Specifically, we define code examples\nacross four semantic and syntactic categories and find that existing datasets\npredominantly capture syntactic properties. Our framework generates four unique\nvariations from a single code instance, providing a broader spectrum of code\nexamples that better reflect functional differences. Extensive experiments on\nthree downstream tasks-code clone detection, code functional consistency\nidentification, and code retrieval-demonstrate that embedding models\nsignificantly improve their performance when trained on our evolved datasets.\nThese results highlight the effectiveness and generalization of our data\nsynthesis framework, advancing the functional understanding of code."}
{"id": "2508.19449", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.19449", "abs": "https://arxiv.org/abs/2508.19449", "authors": ["Md Afif Al Mamun", "Gias Uddin", "Lan Xia", "Longyu Zhang"], "title": "Stack Trace-Based Crash Deduplication with Transformer Adaptation", "comment": "This work is currently under review at IEEE Transactions on Software\n  Engineering. The replication package will be made publicly available upon\n  acceptance", "summary": "Automated crash reporting systems generate large volumes of duplicate\nreports, overwhelming issue-tracking systems and increasing developer workload.\nTraditional stack trace-based deduplication methods, relying on string\nsimilarity, rule-based heuristics, or deep learning (DL) models, often fail to\ncapture the contextual and structural relationships within stack traces. We\npropose dedupT, a transformer-based approach that models stack traces\nholistically rather than as isolated frames. dedupT first adapts a pretrained\nlanguage model (PLM) to stack traces, then uses its embeddings to train a\nfully-connected network (FCN) to rank duplicate crashes effectively. Extensive\nexperiments on real-world datasets show that dedupT outperforms existing DL and\ntraditional methods (e.g., sequence alignment and information retrieval\ntechniques) in both duplicate ranking and unique crash detection, significantly\nreducing manual triage effort. On four public datasets, dedupT improves Mean\nReciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up\nto 9% over traditional methods while achieving higher Receiver Operating\nCharacteristic Area Under the Curve (ROC-AUC) in detecting unique crash\nreports. Our work advances the integration of modern natural language\nprocessing (NLP) techniques into software engineering, providing an effective\nsolution for stack trace-based crash deduplication."}
{"id": "2508.19888", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.19888", "abs": "https://arxiv.org/abs/2508.19888", "authors": ["Matthew Hague", "Artur Jeż", "Anthony W. Lin", "Oliver Markgraf", "Philipp Rümmer"], "title": "The Power of Regular Constraint Propagation (Technical Report)", "comment": null, "summary": "The past decade has witnessed substantial developments in string solving.\nMotivated by the complexity of string solving strategies adopted in existing\nstring solvers, we investigate a simple and generic method for solving string\nconstraints: regular constraint propagation. The method repeatedly computes\npre- or post-images of regular languages under the string functions present in\na string formula, inferring more and more knowledge about the possible values\nof string variables, until either a conflict is found or satisfiability of the\nstring formula can be concluded. Such a propagation strategy is applicable to\nstring constraints with multiple operations like concatenation, replace, and\nalmost all flavors of string transductions. We demonstrate the generality and\neffectiveness of this method theoretically and experimentally. On the\ntheoretical side, we show that RCP is sound and complete for a large fragment\nof string constraints, subsuming both straight-line and chain-free constraints,\ntwo of the most expressive decidable fragments for which some modern string\nsolvers provide formal completeness guarantees. On the practical side, we\nimplement regular constraint propagation within the open-source string solver\nOSTRICH.\n  Our experimental evaluation shows that this addition significantly improves\nOSTRICH's performance and makes it competitive with existing solvers. In fact,\nit substantially outperforms other solvers on random PCP and bioinformatics\nbenchmarks. The results also suggest that incorporating regular constraint\npropagation alongside other techniques could lead to substantial performance\ngains for existing solvers."}
{"id": "2508.19558", "categories": ["cs.SE", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.19558", "abs": "https://arxiv.org/abs/2508.19558", "authors": ["Zhuohao Li", "Wenqing Chen", "Jianxing Yu", "Zhichao Lu"], "title": "Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking", "comment": null, "summary": "Embedding models have demonstrated strong performance in tasks like\nclustering, retrieval, and feature extraction while offering computational\nadvantages over generative models and cross-encoders. Benchmarks such as MTEB\nhave shown that text embeddings from large language models (LLMs) capture rich\nsemantic information, but their ability to reflect code-level functional\nsemantics remains unclear. Existing studies largely focus on code clone\ndetection, which emphasizes syntactic similarity and overlooks functional\nunderstanding. In this paper, we focus on the functional consistency of LLM\ncode embeddings, which determines if two code snippets perform the same\nfunction regardless of syntactic differences. We propose a novel data synthesis\nframework called Functionality-Oriented Code Self-Evolution to construct\ndiverse and challenging benchmarks. Specifically, we define code examples\nacross four semantic and syntactic categories and find that existing datasets\npredominantly capture syntactic properties. Our framework generates four unique\nvariations from a single code instance, providing a broader spectrum of code\nexamples that better reflect functional differences. Extensive experiments on\nthree downstream tasks-code clone detection, code functional consistency\nidentification, and code retrieval-demonstrate that embedding models\nsignificantly improve their performance when trained on our evolved datasets.\nThese results highlight the effectiveness and generalization of our data\nsynthesis framework, advancing the functional understanding of code."}
{"id": "2508.20054", "categories": ["cs.LO", "math.CT"], "pdf": "https://arxiv.org/pdf/2508.20054", "abs": "https://arxiv.org/abs/2508.20054", "authors": ["Cipriano Junior Cioffo", "Fabio Gadducci", "Davide Trotta"], "title": "Between Markov and restriction: Two more monads on categories for relations", "comment": null, "summary": "The study of categories abstracting the structural properties of relations\nhas been extensively developed over the years, resulting in a rich and diverse\nbody of work. A previous paper offered a survey providing a modern and\ncomprehensive presentation of these ``categories for relations'' as instances\nof gs-monoidal categories, showing how they arise as Kleisli categories of\nsuitable symmetric monoidal monads. The end result was a taxonomy that\norganised numerous related concepts in the literature, including in particular\nMarkov and restriction categories. This paper further enriches the taxonomy: it\nproposes two categories that are once more instances of gs-monoidal categories,\nyet more abstract than Markov and restriction categories. They are\ncharacterised by an axiomatic notion of mass and domain of an arrow, the latter\none of the key ingredient of restriction categories, which generalises the\ndomain of partial functions. The paper then introduces mass and domain\npreserving monads, proving that the associated Kleisli categories in fact\npreserve the corresponding equations and that these monads arise naturally for\nthe categories of semiring-weighted relations."}
{"id": "2508.19610", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19610", "abs": "https://arxiv.org/abs/2508.19610", "authors": ["Kathrin Figl", "Maria Kirchner", "Sebastian Baltes", "Michael Felderer"], "title": "The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts", "comment": "31 pages, 7 figures, 2 tables, to appear in the Empirical Software\n  Engineering journal", "summary": "Question-and-answer platforms such as Stack Overflow have become an important\nway for software developers to share and retrieve knowledge. However, reusing\npoorly understood code can lead to serious problems, such as bugs or security\nvulnerabilities. To better understand how code comments affect the perceived\nhelpfulness of Stack Overflow answers, we conducted an online experiment\nsimulating a Stack Overflow environment (n=91). The results indicate that both\nblock and inline comments are perceived as significantly more helpful than\nuncommented source code. Moreover, novices rated code snippets with block\ncomments as more helpful than those with inline comments. Interestingly, other\nsurface features, such as the position of an answer and its answer score, were\nconsidered less important. The content of Stack Overflow has been a major\nsource for training large language models. AI-based coding assistants such as\nGitHub Copilot, which are based on these models, might change the way Stack\nOverflow is used. However, our findings have implications beyond this specific\nplatform. First, they may help to improve the relevance of community-driven\nplatforms such as Stack Overflow, which provide human advice and explanations\nof code solutions, complementing AI-based support for software developers.\nSecond, since chat-based AI tools can be prompted to generate code in different\nways, knowing which properties influence perceived helpfulness might lead to\ntargeted prompting strategies to generate more readable code snippets."}
{"id": "2508.19663", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19663", "abs": "https://arxiv.org/abs/2508.19663", "authors": ["Lola Solovyeva", "Eduardo Carneiro Oliveira", "Shiyu Fan", "Alper Tuncay", "Shamil Gareev", "Andrea Capiluppi"], "title": "Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation", "comment": null, "summary": "The VT legacy system, comprising approximately 2.5 million lines of PL/SQL\ncode, lacks consistent documentation and automated tests, posing significant\nchallenges for refactoring and modernisation. This study investigates the\nfeasibility of leveraging large language models (LLMs) to assist in translating\nPL/SQL code into Java for the modernised \"VTF3\" system. By leveraging a dataset\ncomprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively\nestablished a domain model for the translated files, multiple LLMs were\nevaluated. Furthermore, we propose a customized prompting strategy that\nintegrates chain-of-guidance reasoning with $n$-shot prompting. Our findings\nindicate that this methodology effectively guides LLMs in generating\nsyntactically accurate translations while also achieving functional\ncorrectness. However, the findings are limited by the small sample size of\navailable code files and the restricted access to test cases used for\nvalidating the correctness of the generated code. Nevertheless, these findings\nlay the groundwork for scalable, automated solutions in modernising large\nlegacy systems."}
{"id": "2508.19797", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19797", "abs": "https://arxiv.org/abs/2508.19797", "authors": ["Joan Giner-Miguelez", "Abel Gómez", "Jordi Cabot"], "title": "Enabling Content Management Systems as an Information Source in Model-driven Projects", "comment": null, "summary": "Content Management Systems (CMSs) are the most popular tool when it comes to\ncreate and publish content across the web. Recently, CMSs have evolved,\nbecoming \\emph{headless}. Content served by a \\emph{headless CMS} aims to be\nconsumed by other applications and services through REST APIs rather than by\nhuman users through a web browser. This evolution has enabled CMSs to become a\nnotorious source of content to be used in a variety of contexts beyond pure web\nnavigation. As such, CMS have become an important component of many information\nsystems. Unfortunately, we still lack the tools to properly discover and manage\nthe information stored in a CMS, often highly customized to the needs of a\nspecific domain. Currently, this is mostly a time-consuming and error-prone\nmanual process.\n  In this paper, we propose a model-based framework to facilitate the\nintegration of headless CMSs in software development processes. Our framework\nis able to discover and explicitly represent the information schema behind the\nCMS. This facilitates designing the interaction between the CMS model and other\ncomponents consuming that information. These interactions are then generated as\npart of a middleware library that offers platform-agnostic access to the CMS to\nall the client applications. The complete framework is open-source and\navailable online."}
{"id": "2508.19803", "categories": ["cs.SE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.19803", "abs": "https://arxiv.org/abs/2508.19803", "authors": ["Peter Fettke", "Wolfgang Reisig"], "title": "Towards a fundamental theory of modeling discrete systems", "comment": "6 pages, 2 figures, author prepared version of final manuscript\n  accepted at the 44th International Conference on Conceptual Modeling, 20-23\n  October 2025, Poitiers / Futuroscope, France, Workshop on Fundamentals of\n  Conceptual Modeling (FCM)", "summary": "Modeling is a central concern in both science and engineering. However, we\nneed a new fundamental theory to address the challenges of the digital age. In\nthis paper, we first explain why modeling is fundamental and which challenges\nmust be addressed in the digital world. As a main contribution, we introduce\nthe Heraklit modeling framework as a new approach to modeling. We conclude with\nsome general remarks. Future work will involve the correctness of modeling, the\nnotion of information, and the description of invariance in modeling."}
{"id": "2508.19834", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.19834", "abs": "https://arxiv.org/abs/2508.19834", "authors": ["Antero Taivalsaari", "Tommi Mikkonen", "Cesare Pautasso"], "title": "On the Future of Software Reuse in the Era of AI Native Software Engineering", "comment": "21 pages", "summary": "Software development is currently under a paradigm shift in which artificial\nintelligence and generative software reuse are taking the center stage in\nsoftware creation. Earlier opportunistic software reuse practices and organic\nsoftware development methods are rapidly being replaced by \"AI Native\"\napproaches in which developers place their trust on code that has been\ngenerated by artificial intelligence. This is leading to a new form of software\nreuse that is conceptually not all that different from cargo cult development.\nIn this paper we discuss the implications of AI-assisted generative software\nreuse, bring forth relevant questions, and define a research agenda for\ntackling the central issues associated with this emerging approach."}
{"id": "2508.19882", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.19882", "abs": "https://arxiv.org/abs/2508.19882", "authors": ["Qunying Song", "He Ye", "Mark Harman", "Federica Sarro"], "title": "Generative AI for Testing of Autonomous Driving Systems: A Survey", "comment": "67 pages, 6 figures, 29 tables", "summary": "Autonomous driving systems (ADS) have been an active area of research, with\nthe potential to deliver significant benefits to society. However, before\nlarge-scale deployment on public roads, extensive testing is necessary to\nvalidate their functionality and safety under diverse driving conditions.\nTherefore, different testing approaches are required, and achieving effective\nand efficient testing of ADS remains an open challenge. Recently, generative AI\nhas emerged as a powerful tool across many domains, and it is increasingly\nbeing applied to ADS testing due to its ability to interpret context, reason\nabout complex tasks, and generate diverse outputs. To gain a deeper\nunderstanding of its role in ADS testing, we systematically analyzed 91\nrelevant studies and synthesized their findings into six major application\ncategories, primarily centered on scenario-based testing of ADS. We also\nreviewed their effectiveness and compiled a wide range of datasets, simulators,\nADS, metrics, and benchmarks used for evaluation, while identifying 27\nlimitations. This survey provides an overview and practical insights into the\nuse of generative AI for testing ADS, highlights existing challenges, and\noutlines directions for future research in this rapidly evolving field."}
{"id": "2508.20086", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.20086", "abs": "https://arxiv.org/abs/2508.20086", "authors": ["Youwei Huang", "Jianwen Li", "Sen Fang", "Yao Li", "Peng Yang", "Bin Hu", "Tao Zhang"], "title": "Smart Contract Intent Detection with Pre-trained Programming Language Model", "comment": "10 pages, 5 figures, conference", "summary": "Malicious intent in smart contract development can lead to substantial\neconomic losses. SmartIntentNN is a deep learning model specifically designed\nto identify unsafe intents in smart contracts. This model integrates the\nUniversal Sentence Encoder, a K-means clustering-based intent highlighting\nmechanism, and a Bidirectional Long Short-Term Memory network for multi-label\nclassification, achieving an F1 of 0.8633 in distinguishing ten different\nintent categories. In this study, we present an upgraded version of this model,\nSmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant\nenhancement in V2 is the incorporation of a BERT-based pre-trained language\nmodel, which has been trained on a dataset of 16,000 real smart contracts using\na Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based\nmulti-label classification network. With an improved F1 of 0.927, V2\ndemonstrates enhanced performance compared to its predecessor, establishing\nitself as the state-of-the-art model for smart contract intent detection."}
