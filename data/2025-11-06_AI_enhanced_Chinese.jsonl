{"id": "2511.02869", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.02869", "abs": "https://arxiv.org/abs/2511.02869", "authors": ["Amirreza Esmaeili", "Fahd Seddik", "Yongyi Ji", "Fatemeh Fard", "Fuxiang Chen"], "title": "Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models", "comment": null, "summary": "Programming languages can benefit from one another by utilizing a language\nmodel for software engineering tasks. Full fine-tuning and Parameter Efficient\nFine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for\nmultilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims\nto enhance task performance by leveraging information from multiple programming\nlanguages, but primarily focuses on the target programming language.\n  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that\neffectively learns from other programming languages before adapting to the\ntarget task. Though previous experiments showed that AdvFusion outperformed\nAdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited\nto only two tasks, code summarization and method name prediction. In this\nstudy, we expanded our work and investigated AdvFusion on Code Large Language\nModels (Code-LLMs), considering three new tasks: code generation, code\ntranslation, and commit message generation. We observed that different\nCode-LLMs/tasks exhibit different characteristics. In code generation,\nAdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,\nCompacter, and TaskAdapter). In commit message generation, AdapterFusion\nperformed better than AdvFusion, and contrary to code generation, we found that\nthe other PEFT methods do not have better performance. In code translation,\nAdvFusion performed worse than AdapterFusion overall, with the performance gap\nmarginally widening as the model size increases. However, consistent with code\ngeneration, other PEFT methods showed better performance.", "AI": {"tldr": "AdvFusion\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u591a\u8bed\u8a00\u4ee3\u7801\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e86\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u7ffb\u8bd1\u548c\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u4e09\u4e2a\u65b0\u4efb\u52a1\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b/\u4efb\u52a1\u8868\u73b0\u51fa\u4e0d\u540c\u7279\u6027\u3002", "motivation": "\u63a2\u7d22AdvFusion\u65b9\u6cd5\u5728\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6269\u5c55\u5e94\u7528\uff0c\u9a8c\u8bc1\u5176\u5728\u66f4\u591a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528AdvFusion\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u67b6\u6784\uff0c\u5728\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u591a\u4efb\u52a1\u8bc4\u4f30\uff0c\u5305\u62ec\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u7ffb\u8bd1\u548c\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u3002", "result": "\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u5404\u5f02\uff1a\u4ee3\u7801\u751f\u6210\u4e2dAdvFusion\u4f18\u4e8eAdapterFusion\u4f46\u4e0d\u5982\u5176\u4ed6PEFT\u65b9\u6cd5\uff1b\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u4e2dAdapterFusion\u66f4\u597d\uff1b\u4ee3\u7801\u7ffb\u8bd1\u4e2dAdvFusion\u6574\u4f53\u8868\u73b0\u8f83\u5dee\uff0c\u4e14\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u5dee\u8ddd\u6269\u5927\u3002", "conclusion": "AdvFusion\u5728\u4e0d\u540c\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2511.02854", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02854", "abs": "https://arxiv.org/abs/2511.02854", "authors": ["Yixiang Chen", "Tianshi Zheng", "Shijue Huang", "Zhitao He", "Yi R. Fung"], "title": "SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation", "comment": "15 pages, 8 figures,2 tables", "summary": "Test-time scaling without interpreter feedback is essential for real-world\ncode generation scenarios where test cases are not readily available. While\nexisting paradigms often rely on either greedy exploitation (i.e., iterative\nrefinement) or stochastic exploration (i.e., relying on sample-based voting or\nreranking mechanisms), the balance between these two dimensions remains\nunderexplored. To investigate the LLM's intrinsic ability to balance\nexploitation and exploration, we introduce SELF-REDRAFT, a framework built upon\nSelf-Refine that encourages the model to propose new drafts for solutions that\nare fundamentally flawed. Our results show that SELF-REDRAFT consistently\nachieves better performance than Self-Refine when converged under the same\nmaximum number of iterations. Still, we observe that significant room for\nimprovement remains, largely due to two core aspects of current self-redraft\ncapabilities: constrained capacity for generating instructive feedback and\nfragile discriminative judgment. We also find that balancing strategies vary\nnotably across different LLMs, reflecting distinct, model-specific behaviors.\nOverall, our study establishes a baseline for intrinsic\nexploration-exploitation balancing in test-time scaling and identifies feedback\nand discrimination as key areas with potential for future advances.", "AI": {"tldr": "\u63d0\u51fa\u4e86SELF-REDRAFT\u6846\u67b6\uff0c\u57fa\u4e8eSelf-Refine\u6784\u5efa\uff0c\u901a\u8fc7\u9f13\u52b1\u6a21\u578b\u4e3a\u5b58\u5728\u6839\u672c\u7f3a\u9677\u7684\u89e3\u51b3\u65b9\u6848\u63d0\u51fa\u65b0\u8349\u7a3f\uff0c\u6765\u63a2\u7d22LLM\u5728\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e2d\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22\u7684\u5185\u5728\u80fd\u529b\u3002", "motivation": "\u5728\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u53ef\u7528\u7684\u771f\u5b9e\u4ee3\u7801\u751f\u6210\u573a\u666f\u4e2d\uff0c\u6d4b\u8bd5\u65f6\u6269\u5c55\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8d2a\u5a6a\u5229\u7528\uff08\u8fed\u4ee3\u4f18\u5316\uff09\uff0c\u8981\u4e48\u4f9d\u8d56\u968f\u673a\u63a2\u7d22\uff08\u57fa\u4e8e\u91c7\u6837\u7684\u6295\u7968\u6216\u91cd\u6392\uff09\uff0c\u4f46\u8fd9\u4e24\u8005\u4e4b\u95f4\u7684\u5e73\u8861\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165SELF-REDRAFT\u6846\u67b6\uff0c\u5efa\u7acb\u5728Self-Refine\u57fa\u7840\u4e0a\uff0c\u9f13\u52b1\u6a21\u578b\u4e3a\u6839\u672c\u6709\u7f3a\u9677\u7684\u89e3\u51b3\u65b9\u6848\u63d0\u51fa\u65b0\u8349\u7a3f\uff0c\u4ee5\u5e73\u8861\u5229\u7528\u548c\u63a2\u7d22\u3002", "result": "SELF-REDRAFT\u5728\u76f8\u540c\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u4e0b\u6536\u655b\u65f6\uff0c\u59cb\u7ec8\u6bd4Self-Refine\u8868\u73b0\u66f4\u597d\u3002\u4f46\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u751f\u6210\u6307\u5bfc\u6027\u53cd\u9988\u7684\u80fd\u529b\u6709\u9650\u548c\u5224\u522b\u5224\u65ad\u8106\u5f31\u3002\u4e0d\u540cLLM\u7684\u5e73\u8861\u7b56\u7565\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e2d\u7684\u5185\u5728\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u5efa\u7acb\u4e86\u57fa\u7ebf\uff0c\u5e76\u786e\u5b9a\u53cd\u9988\u548c\u5224\u522b\u80fd\u529b\u662f\u672a\u6765\u8fdb\u6b65\u7684\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2511.02859", "categories": ["cs.SE", "D.2.9"], "pdf": "https://arxiv.org/pdf/2511.02859", "abs": "https://arxiv.org/abs/2511.02859", "authors": ["Bianca Leech", "Ridewaan Hanslo"], "title": "The Evolution of Agile and Hybrid Project Management Methodologies: A Systematic Literature Review", "comment": "10 pages, 5 images, 1 table, 7th World Symposium on Software\n  Engineering (WSSE 2025)", "summary": "The rapid evolution of IT projects has driven the transformation of project\nmanagement methodologies, from traditional waterfall approaches to agile\nframeworks and, more recently, hybrid models. This systematic literature review\ninvestigates the evolution of agile methodologies into hybrid frameworks,\nanalysing their implementation challenges and success factors. We identify key\ntrends through PRISMA-guided analysis of peer-reviewed studies from the last 8\nyears. Hybrid methodologies emerge from agile limitations in large-scale and\nregulated environments, combining iterative flexibility with structured\ngovernance. Agile has several implementation challenges, leading to hybrid\nmethods, and the success hinges on leadership support, tailored process\nintegration, and continuous improvement mechanisms. The study explores the need\nfor contextual adaptation over rigid frameworks, offering practical insights\nfor organisations navigating hybrid transitions.", "AI": {"tldr": "\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u6790\u654f\u6377\u65b9\u6cd5\u8bba\u5411\u6df7\u5408\u6846\u67b6\u7684\u6f14\u53d8\uff0c\u8bc6\u522b\u5b9e\u65bd\u6311\u6218\u548c\u6210\u529f\u56e0\u7d20\uff0c\u5f3a\u8c03\u60c5\u5883\u9002\u5e94\u7684\u91cd\u8981\u6027\u3002", "motivation": "IT\u9879\u76ee\u7684\u5feb\u901f\u53d1\u5c55\u63a8\u52a8\u4e86\u9879\u76ee\u7ba1\u7406\u65b9\u6cd5\u8bba\u7684\u8f6c\u53d8\uff0c\u4ece\u4f20\u7edf\u7011\u5e03\u5f0f\u5230\u654f\u6377\u6846\u67b6\uff0c\u518d\u5230\u6df7\u5408\u6a21\u578b\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u654f\u6377\u65b9\u6cd5\u8bba\u5982\u4f55\u6f14\u53d8\u4e3a\u6df7\u5408\u6846\u67b6\uff0c\u5206\u6790\u5176\u6311\u6218\u548c\u6210\u529f\u56e0\u7d20\u3002", "method": "\u91c7\u7528PRISMA\u6307\u5357\u5bf9\u8fc7\u53bb8\u5e74\u7684\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u5206\u6790\uff0c\u8bc6\u522b\u5173\u952e\u8d8b\u52bf\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u8bba\u6e90\u4e8e\u654f\u6377\u5728\u5927\u89c4\u6a21\u548c\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u7ed3\u5408\u4e86\u8fed\u4ee3\u7075\u6d3b\u6027\u548c\u7ed3\u6784\u5316\u6cbb\u7406\u3002\u6210\u529f\u56e0\u7d20\u5305\u62ec\u9886\u5bfc\u652f\u6301\u3001\u5b9a\u5236\u5316\u6d41\u7a0b\u6574\u5408\u548c\u6301\u7eed\u6539\u8fdb\u673a\u5236\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u60c5\u5883\u9002\u5e94\u6bd4\u50f5\u5316\u6846\u67b6\u66f4\u91cd\u8981\uff0c\u4e3a\u7ec4\u7ec7\u5728\u6df7\u5408\u8f6c\u578b\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u5b9e\u8df5\u89c1\u89e3\u3002"}}
{"id": "2511.02866", "categories": ["cs.SE", "cs.AI", "cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.02866", "abs": "https://arxiv.org/abs/2511.02866", "authors": ["Ahmad Tahmasivand", "Noureldin Zahran", "Saba Al-Sayouri", "Mohammed Fouda", "Khaled N. Khasawneh"], "title": "LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models", "comment": "Accepted at IEEE ICCD 2025. Code: https://github.com/ata990/lm-fix.\n  Detects over 94 percent single-bit flips (near 100 percent multi-bit) with\n  about 1 to 7.7 percent overhead; recovery is over 100x faster than a full\n  reload. Keywords: LLMs, bit-flip, fault injection, reliability, security,\n  Rowhammer, SDC, Jailbreaking, Attack, Defense, GPU DRAM faults", "summary": "This paper presents LM-Fix, a lightweight detection and rapid recovery\nframework for faults in large language models (LLMs). Existing integrity\napproaches are often heavy or slow for modern LLMs. LM-Fix runs a short\ntest-vector pass and uses hash-guided checks to detect bit-flip faults, then\nrepairs them locally without a full reload. Across multiple models, it detects\nover 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with\napproximately 1% to 7.7% runtime overhead; recovery is more than 100x faster\nthan reloading. These results show a practical, low-overhead solution to keep\nLLMs reliable in production", "AI": {"tldr": "LM-Fix\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u548c\u5feb\u901f\u6062\u590d\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6545\u969c\u3002\u5b83\u901a\u8fc7\u77ed\u6d4b\u8bd5\u5411\u91cf\u548c\u54c8\u5e0c\u5f15\u5bfc\u68c0\u67e5\u68c0\u6d4b\u4f4d\u7ffb\u8f6c\u6545\u969c\uff0c\u5e76\u8fdb\u884c\u5c40\u90e8\u4fee\u590d\uff0c\u65e0\u9700\u5b8c\u5168\u91cd\u65b0\u52a0\u8f7d\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b8c\u6574\u6027\u65b9\u6cd5\u901a\u5e38\u8fc7\u4e8e\u7b28\u91cd\u6216\u7f13\u6162\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3LLM\u7684\u9700\u6c42\u3002\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u5feb\u901f\u7684\u6545\u969c\u68c0\u6d4b\u548c\u6062\u590d\u65b9\u6848\u6765\u786e\u4fddLLM\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "LM-Fix\u8fd0\u884c\u77ed\u6d4b\u8bd5\u5411\u91cf\u5e76\u901a\u8fc7\u54c8\u5e0c\u5f15\u5bfc\u68c0\u67e5\u6765\u68c0\u6d4b\u4f4d\u7ffb\u8f6c\u6545\u969c\uff0c\u7136\u540e\u8fdb\u884c\u5c40\u90e8\u4fee\u590d\u800c\u4e0d\u9700\u8981\u5b8c\u5168\u91cd\u65b0\u52a0\u8f7d\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\uff0cLM-Fix\u5728TVL=200\u65f6\u68c0\u6d4b\u5230\u8d85\u8fc794%\u7684\u5355\u6bd4\u7279\u7ffb\u8f6c\u548c\u63a5\u8fd1100%\u7684\u591a\u6bd4\u7279\u7ffb\u8f6c\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u7ea6\u4e3a1%\u52307.7%\uff1b\u6062\u590d\u901f\u5ea6\u6bd4\u91cd\u65b0\u52a0\u8f7d\u5feb100\u500d\u4ee5\u4e0a\u3002", "conclusion": "LM-Fix\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u3001\u4f4e\u5f00\u9500\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4fdd\u6301\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.02874", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02874", "abs": "https://arxiv.org/abs/2511.02874", "authors": ["Jannatul Shefa", "Taylan G. Topcu"], "title": "An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering", "comment": null, "summary": "As systems become increasingly complex, conducting effective safety analysis\nin the earlier phases of a system's lifecycle is essential to identify and\nmitigate risks before they escalate. To that end, this paper investigates the\ncapabilities of key safety analysis techniques, namely: Failure Mode and\nEffects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional\nFailure Identification and Propagation (FFIP), along with the current state of\nthe literature in terms of their integration into Model-Based Systems\nEngineering (MBSE). A two-phase approach is adopted. The first phase is focused\non contrasting FMEA, FHA, and FFIP techniques, examining their procedures,\nalong with a documentation of their relative strengths and limitations. Our\nanalysis highlights FFIP's capability in identifying emergent system behaviors,\nsecond-order effects, and fault propagation; thus, suggesting it is better\nsuited for the safety needs of modern interconnected systems. Second, we review\nthe existing research on the efforts to integrate each of these methods into\nMBSE. We find that MBSE integration efforts primarily focus on FMEA, and\nintegration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration\nefforts could be organized into four categories: model-to-model transformation,\nuse of external customized algorithms, built-in MBSE packages, and manual use\nof standard MBSE diagrams. While our findings indicate a variety of MBSE\nintegration approaches, there is no universally established framework or\nstandard. This leaves room for an integration approach that could support the\nongoing Digital Engineering transformation efforts by enabling a more\nsynergistic lifecycle safety management methods and tools.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86FMEA\u3001FHA\u548cFFIP\u4e09\u79cd\u5b89\u5168\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u7814\u7a76\u4e86\u5b83\u4eec\u5728MBSE\u4e2d\u7684\u96c6\u6210\u73b0\u72b6\u3002\u7814\u7a76\u53d1\u73b0FFIP\u66f4\u9002\u5408\u73b0\u4ee3\u4e92\u8054\u7cfb\u7edf\u7684\u5b89\u5168\u9700\u6c42\uff0c\u800cMBSE\u96c6\u6210\u4e3b\u8981\u96c6\u4e2d\u5728FMEA\u4e0a\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u5728\u7cfb\u7edf\u751f\u547d\u5468\u671f\u65e9\u671f\u8fdb\u884c\u6709\u6548\u7684\u5b89\u5168\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5173\u952e\u5b89\u5168\u5206\u6790\u65b9\u6cd5\u7684\u80fd\u529b\u53ca\u5176\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u96c6\u6210\u73b0\u72b6\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5bf9\u6bd4FMEA\u3001FHA\u548cFFIP\u6280\u672f\u7684\u7a0b\u5e8f\u3001\u4f18\u7f3a\u70b9\uff1b\u7b2c\u4e8c\u9636\u6bb5\u56de\u987e\u8fd9\u4e9b\u65b9\u6cd5\u5728MBSE\u4e2d\u7684\u96c6\u6210\u7814\u7a76\u3002", "result": "\u5206\u6790\u663e\u793aFFIP\u5728\u8bc6\u522b\u7cfb\u7edf\u6d8c\u73b0\u884c\u4e3a\u3001\u4e8c\u9636\u6548\u5e94\u548c\u6545\u969c\u4f20\u64ad\u65b9\u9762\u80fd\u529b\u66f4\u5f3a\uff1bMBSE\u96c6\u6210\u4e3b\u8981\u96c6\u4e2d\u5728FMEA\uff0c\u53ef\u5206\u4e3a\u56db\u7c7b\u96c6\u6210\u65b9\u6cd5\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "\u9700\u8981\u4e00\u79cd\u96c6\u6210\u65b9\u6cd5\u652f\u6301\u6570\u5b57\u5de5\u7a0b\u8f6c\u578b\uff0c\u5b9e\u73b0\u66f4\u534f\u540c\u7684\u751f\u547d\u5468\u671f\u5b89\u5168\u7ba1\u7406\u65b9\u6cd5\u548c\u5de5\u5177\u3002"}}
{"id": "2511.02876", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02876", "abs": "https://arxiv.org/abs/2511.02876", "authors": ["Anjali Chouhan", "Sruti Srinivasa Ragavan", "Amey Karkare"], "title": "CS Educator challenges and their solutions : A systematic mapping study", "comment": null, "summary": "Computer Science (CS) education is expanding rapidly, but educators continue\nto face persistent challenges in teaching and learning environments.Despite\ngrowing interest, limited systematic work exists to categorize and synthesize\nthe specific challenges faced by CS educators and the remedies adopted in\nresponse.This is problematic because it remains unclear which areas have been\nthoroughly addressed and which still lack sufficient scholarly attention. In\nthis study, we conducted a structured literature review of peer-reviewed\nresearch papers published over the last five years, focusing on challenges and\nremedies across ten categorized themes, including pedagogical, emotional,\ntechnological, and institutional dimensions.Our analysis revealed recurring\nissues in areas such as assessment practices, teacher training, classroom\nmanagement, and emotional well-being, along with various strategies such as\nprofessional development programs and policy interventions adopted to mitigate\nthem while also revealing several areas that have received insufficient\nattention.This review offers a consolidated understanding of the CS education\nlandscape, providing valuable insights for researchers, curriculum designers,\nand policymakers aiming to improve teaching effectiveness and educator support.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u6559\u5e08\u9762\u4e34\u7684\u6311\u6218\u53ca\u5e94\u5bf9\u63aa\u65bd\uff0c\u8bc6\u522b\u4e86\u5341\u5927\u4e3b\u9898\u9886\u57df\u4e2d\u7684\u91cd\u590d\u6027\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u4e86\u7814\u7a76\u4e0d\u8db3\u7684\u9886\u57df\u3002", "motivation": "\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u6559\u5e08\u5728\u6559\u5b66\u73af\u5883\u4e2d\u9762\u4e34\u6301\u7eed\u6311\u6218\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6311\u6218\u5206\u7c7b\u548c\u5e94\u5bf9\u63aa\u65bd\u7efc\u5408\u7814\u7a76\uff0c\u4e0d\u6e05\u695a\u54ea\u4e9b\u9886\u57df\u5df2\u5145\u5206\u89e3\u51b3\uff0c\u54ea\u4e9b\u4ecd\u9700\u5173\u6ce8\u3002", "method": "\u5bf9\u8fc7\u53bb\u4e94\u5e74\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u8bba\u6587\u8fdb\u884c\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\uff0c\u91cd\u70b9\u5173\u6ce8\u5341\u5927\u5206\u7c7b\u4e3b\u9898\u4e2d\u7684\u6311\u6218\u548c\u5e94\u5bf9\u63aa\u65bd\uff0c\u5305\u62ec\u6559\u5b66\u6cd5\u3001\u60c5\u611f\u3001\u6280\u672f\u548c\u5236\u5ea6\u7b49\u7ef4\u5ea6\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u5728\u8bc4\u4f30\u5b9e\u8df5\u3001\u6559\u5e08\u57f9\u8bad\u3001\u8bfe\u5802\u7ba1\u7406\u548c\u60c5\u611f\u5065\u5eb7\u7b49\u9886\u57df\u7684\u91cd\u590d\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u4e3a\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u91c7\u53d6\u7684\u5404\u79cd\u7b56\u7565\uff0c\u540c\u65f6\u53d1\u73b0\u82e5\u5e72\u7814\u7a76\u4e0d\u8db3\u7684\u9886\u57df\u3002", "conclusion": "\u672c\u7efc\u8ff0\u63d0\u4f9b\u4e86\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u73b0\u72b6\u7684\u6574\u5408\u7406\u89e3\uff0c\u4e3a\u7814\u7a76\u8005\u3001\u8bfe\u7a0b\u8bbe\u8ba1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u6539\u5584\u6559\u5b66\u6548\u679c\u548c\u6559\u5e08\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.02885", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02885", "abs": "https://arxiv.org/abs/2511.02885", "authors": ["Gwendal Jouneaux", "Jordi Cabot"], "title": "AgentSLA : Towards a Service Level Agreement for AI Agents", "comment": null, "summary": "AI components are increasingly becoming a key element of all types of\nsoftware systems to enhance their functionality. These AI components are often\nimplemented as AI Agents, offering more autonomy than a plain integration of\nLarge Language Models (LLMs), moving from a Model-as-a-Service paradigm to an\nAgent-as-a-Service one, bringing new challenges to the development of smart\nsoftware systems. Indeed, while support for the design, implementation, and\ndeployment of those agents exist, the specification of Quality of Service (QoS)\nand definition of Service Level Agreements (SLAs) aspects for those agents,\nimportant to ensure the quality of the resulting systems, remains an open\nchallenge. Part of this is due to the difficulty to clearly define quality in\nthe context of AI components, resulting in a lack of consensus on how to best\napproach Quality Assurance (QA) for these types of systems. To address this\nchallenge, this paper proposes both a quality model for AI agents based on the\nISO/IEC 25010 standard, and a domain specific language to support the\ndefinition of SLAs for the services provided by these AI agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u7684AI\u667a\u80fd\u4f53\u8d28\u91cf\u6a21\u578b\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u7528\u4e8e\u652f\u6301AI\u667a\u80fd\u4f53\u670d\u52a1\u7684SLA\u5b9a\u4e49\u3002", "motivation": "AI\u667a\u80fd\u4f53\u6b63\u6210\u4e3a\u5404\u7c7b\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u4ece\u6a21\u578b\u5373\u670d\u52a1\u8f6c\u5411\u667a\u80fd\u4f53\u5373\u670d\u52a1\u8303\u5f0f\uff0c\u4f46AI\u7ec4\u4ef6\u7684\u8d28\u91cf\u5b9a\u4e49\u548cSLA\u89c4\u8303\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u7f3a\u4e4f\u8d28\u91cf\u4fdd\u8bc1\u7684\u5171\u8bc6\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u7684AI\u667a\u80fd\u4f53\u8d28\u91cf\u6a21\u578b\uff0c\u5e76\u521b\u5efa\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6765\u652f\u6301AI\u667a\u80fd\u4f53\u670d\u52a1\u7684SLA\u5b9a\u4e49\u3002", "result": "\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u8d28\u91cf\u6a21\u578b\u548cSLA\u5b9a\u4e49\u5de5\u5177\uff0c\u4e3a\u89e3\u51b3AI\u667a\u80fd\u4f53\u8d28\u91cf\u4fdd\u8bc1\u95ee\u9898\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u667a\u80fd\u4f53\u7684\u8d28\u91cf\u4fdd\u8bc1\u548cSLA\u89c4\u8303\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u667a\u80fd\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5f00\u53d1\u8d28\u91cf\u3002"}}
{"id": "2511.02922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02922", "abs": "https://arxiv.org/abs/2511.02922", "authors": ["Yunhan Qiao", "Christopher Hundhausen", "Summit Haque", "Md Istiak Hossain Shihab"], "title": "Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension", "comment": "12 pages", "summary": "Code comprehension is essential for brownfield programming tasks, in which\ndevelopers maintain and enhance legacy code bases. Generative AI (GenAI) coding\nassistants such as GitHub Copilot have been shown to improve developer\nproductivity, but their impact on code understanding is less clear. We\nreplicate and extend a previous study by exploring both performance and\ncomprehension in GenAI-assisted brownfield programming tasks. In a\nwithin-subjects experimental study, 18 computer science graduate students\ncompleted feature implementation tasks with and without Copilot. Results show\nthat Copilot significantly reduced task time and increased the number of test\ncases passed. However, comprehension scores did not differ across conditions,\nrevealing a comprehension-performance gap: participants passed more test cases\nwith Copilot, but did not demonstrate greater understanding of the legacy\ncodebase. Moreover, we failed to find a correlation between comprehension and\ntask performance. These findings suggest that while GenAI tools can accelerate\nprogramming progress in a legacy codebase, such progress may come without an\nimproved understanding of that codebase. We consider the implications of these\nfindings for programming education and GenAI tool design.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7f16\u7801\u52a9\u624b\u5728\u9057\u7559\u4ee3\u7801\u7ef4\u62a4\u4efb\u52a1\u4e2d\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u4e0d\u4f1a\u6539\u5584\u4ee3\u7801\u7406\u89e3\u80fd\u529b\uff0c\u5b58\u5728\u7406\u89e3\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0fAI\u7f16\u7801\u52a9\u624b\u5728\u9057\u7559\u4ee3\u7801\u7ef4\u62a4\u4efb\u52a1\u4e2d\u5bf9\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u9a8c\u8bc1\u662f\u5426\u5b58\u5728\u7406\u89e3-\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u7ec4\u5185\u5b9e\u9a8c\u8bbe\u8ba1\uff0c18\u540d\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\u751f\u5728\u6709\u65e0Copilot\u8f85\u52a9\u4e0b\u5b8c\u6210\u529f\u80fd\u5b9e\u73b0\u4efb\u52a1\uff0c\u6bd4\u8f83\u4efb\u52a1\u65f6\u95f4\u3001\u6d4b\u8bd5\u7528\u4f8b\u901a\u8fc7\u7387\u548c\u7406\u89e3\u5f97\u5206\u3002", "result": "Copilot\u663e\u8457\u51cf\u5c11\u4efb\u52a1\u65f6\u95f4\u5e76\u63d0\u9ad8\u6d4b\u8bd5\u7528\u4f8b\u901a\u8fc7\u7387\uff0c\u4f46\u7406\u89e3\u5f97\u5206\u6ca1\u6709\u5dee\u5f02\uff0c\u4e14\u7406\u89e3\u4e0e\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u65e0\u76f8\u5173\u6027\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u5177\u80fd\u52a0\u901f\u9057\u7559\u4ee3\u7801\u5e93\u7684\u7f16\u7a0b\u8fdb\u5ea6\uff0c\u4f46\u8fd9\u79cd\u8fdb\u6b65\u53ef\u80fd\u4e0d\u4f1a\u5e26\u6765\u5bf9\u4ee3\u7801\u5e93\u7684\u66f4\u597d\u7406\u89e3\uff0c\u8fd9\u5bf9\u7f16\u7a0b\u6559\u80b2\u548cAI\u5de5\u5177\u8bbe\u8ba1\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2511.02927", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02927", "abs": "https://arxiv.org/abs/2511.02927", "authors": ["Rafael Baez", "Alejandro Olivas", "Nathan K. Diamond", "Marcelo Frias", "Yannic Noller", "Saeid Tizpaz-Niari"], "title": "Risk Estimation in Differential Fuzzing via Extreme Value Theory", "comment": "In Proceedings of the 40th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE 25), 13 Pages, 4 Figures, 5 Tables", "summary": "Differential testing is a highly effective technique for automatically\ndetecting software bugs and vulnerabilities when the specifications involve an\nanalysis over multiple executions simultaneously. Differential fuzzing, in\nparticular, operates as a guided randomized search, aiming to find (similar)\ninputs that lead to a maximum difference in software outputs or their\nbehaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the\nabsence of bugs: from a differential fuzzing campaign that has observed no bugs\n(or a minimal difference), what is the risk of observing a bug (or a larger\ndifference) if we run the fuzzer for one or more steps?\n  This paper investigates the application of Extreme Value Theory (EVT) to\naddress the risk of missing or underestimating bugs in differential fuzzing.\nThe key observation is that differential fuzzing as a random process resembles\nthe maximum distribution of observed differences. Hence, EVT, a branch of\nstatistics dealing with extreme values, is an ideal framework to analyze the\ntail of the differential fuzzing campaign to contain the risk. We perform\nexperiments on a set of real-world Java libraries and use differential fuzzing\nto find information leaks via side channels in these libraries. We first\nexplore the feasibility of EVT for this task and the optimal hyperparameters\nfor EVT distributions. We then compare EVT-based extrapolation against baseline\nstatistical methods like Markov's as well as Chebyshev's inequalities, and the\nBayes factor. EVT-based extrapolations outperform the baseline techniques in\n14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we\nevaluate the accuracy and performance gains of EVT-enabled differential fuzzing\nin real-world Java libraries, where we reported an average saving of tens of\nmillions of bytecode executions by an early stop.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5e94\u7528\u6781\u503c\u7406\u8bba\u6765\u8bc4\u4f30\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u9057\u6f0f\u6216\u4f4e\u4f30bug\u7684\u98ce\u9669\uff0c\u901a\u8fc7\u5728\u771f\u5b9eJava\u5e93\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660eEVT\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u98ce\u9669\u5e76\u8282\u7701\u6d4b\u8bd5\u8d44\u6e90\u3002", "motivation": "\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u4f5c\u4e3a\u52a8\u6001\u5206\u6790\u65e0\u6cd5\u4fdd\u8bc1bug\u7684\u5b8c\u5168\u68c0\u6d4b\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc4\u4f30\u5728\u672a\u53d1\u73b0bug\u6216\u5dee\u5f02\u8f83\u5c0f\u65f6\u7ee7\u7eed\u6d4b\u8bd5\u7684\u98ce\u9669\u3002", "method": "\u5e94\u7528\u6781\u503c\u7406\u8bba\u5206\u6790\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u89c2\u5bdf\u5230\u7684\u6700\u5927\u5dee\u5f02\u5206\u5e03\uff0c\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u9884\u6d4b\u9057\u6f0fbug\u7684\u98ce\u9669\u3002", "result": "EVT\u65b9\u6cd5\u572814.3%\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u7edf\u8ba1\u65b9\u6cd5\uff0c\u572864.2%\u7684\u60c5\u51b5\u4e0b\u4e0e\u57fa\u7ebf\u6301\u5e73\uff0c\u5728\u771f\u5b9eJava\u5e93\u6d4b\u8bd5\u4e2d\u5e73\u5747\u8282\u7701\u4e86\u6570\u5343\u4e07\u5b57\u8282\u7801\u6267\u884c\u3002", "conclusion": "\u6781\u503c\u7406\u8bba\u4e3a\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2511.03026", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03026", "abs": "https://arxiv.org/abs/2511.03026", "authors": ["Logan Murphy", "Torin Viger", "Alessio Di Sandro", "Aren A. Babikian", "Marsha Chechik"], "title": "Assurance Case Development for Evolving Software Product Lines: A Formal Approach", "comment": null, "summary": "In critical software engineering, structured assurance cases (ACs) are used\nto demonstrate how key system properties are supported by evidence (e.g., test\nresults, proofs). Creating rigorous ACs is particularly challenging in the\ncontext of software product lines (SPLs), i.e, sets of software products with\noverlapping but distinct features and behaviours. Since SPLs can encompass very\nlarge numbers of products, developing a rigorous AC for each product\nindividually is infeasible. Moreover, if the SPL evolves, e.g., by the\nmodification or introduction of features, it can be infeasible to assess the\nimpact of this change. Instead, the development and maintenance of ACs ought to\nbe lifted such that a single AC can be developed for the entire SPL\nsimultaneously, and be analyzed for regression in a variability-aware fashion.\nIn this article, we describe a formal approach to lifted AC development and\nregression analysis. We formalize a language of variability-aware ACs for SPLs\nand study the lifting of template-based AC development. We also define a\nregression analysis to determine the effects of SPL evolutions on\nvariability-aware ACs. We describe a model-based assurance management tool\nwhich implements these techniques, and illustrate our contributions by\ndeveloping an AC for a product line of medical devices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8f6f\u4ef6\u4ea7\u54c1\u7ebf(SPL)\u7684\u5f62\u5f0f\u5316\u63d0\u5347\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u65b9\u6cd5\uff0c\u652f\u6301\u53d8\u4f53\u611f\u77e5\u7684\u56de\u5f52\u5206\u6790\uff0c\u4ee5\u89e3\u51b3SPL\u4e2d\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u4e2d\uff0c\u4e3a\u6bcf\u4e2a\u4ea7\u54c1\u5355\u72ec\u5f00\u53d1\u4e25\u683c\u7684\u4fdd\u8bc1\u6848\u4f8b\u4e0d\u53ef\u884c\uff0c\u4e14\u5f53\u4ea7\u54c1\u7ebf\u6f14\u8fdb\u65f6\u96be\u4ee5\u8bc4\u4f30\u53d8\u66f4\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4e3a\u6574\u4e2a\u4ea7\u54c1\u7ebf\u5f00\u53d1\u4fdd\u8bc1\u6848\u4f8b\u7684\u65b9\u6cd5\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u7528\u4e8eSPL\u7684\u53d8\u4f53\u611f\u77e5\u4fdd\u8bc1\u6848\u4f8b\u8bed\u8a00\uff0c\u7814\u7a76\u4e86\u57fa\u4e8e\u6a21\u677f\u7684\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u63d0\u5347\u65b9\u6cd5\uff0c\u5b9a\u4e49\u4e86SPL\u6f14\u8fdb\u5bf9\u53d8\u4f53\u611f\u77e5\u4fdd\u8bc1\u6848\u4f8b\u5f71\u54cd\u7684\u56de\u5f52\u5206\u6790\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u4fdd\u8bc1\u7ba1\u7406\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u533b\u7597\u8bbe\u5907\u4ea7\u54c1\u7ebf\u7684\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u7684\u63d0\u5347\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u548c\u53d8\u4f53\u611f\u77e5\u56de\u5f52\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u4ea7\u54c1\u7ebf\u4e2d\u4fdd\u8bc1\u6848\u4f8b\u5f00\u53d1\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002"}}
{"id": "2511.03103", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03103", "abs": "https://arxiv.org/abs/2511.03103", "authors": ["Rafael Jos\u00e9 Moura", "Maria Gizele Nascimento", "Fumio Machida", "Ermeson Andrade"], "title": "Adaptive Detection of Software Aging under Workload Shift", "comment": "SIMP\\'OSIO EM SISTEMAS COMPUTACIONAIS DE ALTO DESEMPENHO (SSCAD)", "summary": "Software aging is a phenomenon that affects long-running systems, leading to\nprogressive performance degradation and increasing the risk of failures. To\nmitigate this problem, this work proposes an adaptive approach based on machine\nlearning for software aging detection in environments subject to dynamic\nworkload conditions. We evaluate and compare a static model with adaptive\nmodels that incorporate adaptive detectors, specifically the Drift Detection\nMethod (DDM) and Adaptive Windowing (ADWIN), originally developed for concept\ndrift scenarios and applied in this work to handle workload shifts. Experiments\nwith simulated sudden, gradual, and recurring workload transitions show that\nstatic models suffer a notable performance drop when applied to unseen workload\nprofiles, whereas the adaptive model with ADWIN maintains high accuracy,\nachieving an F1-Score above 0.93 in all analyzed scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u8f6f\u4ef6\u8001\u5316\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u4f7f\u7528ADWIN\u81ea\u9002\u5e94\u7a97\u53e3\u6280\u672f\uff0c\u76f8\u6bd4\u9759\u6001\u6a21\u578b\u80fd\u4fdd\u6301\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u8f6f\u4ef6\u8001\u5316\u73b0\u8c61\u5f71\u54cd\u957f\u671f\u8fd0\u884c\u7cfb\u7edf\uff0c\u5bfc\u81f4\u6027\u80fd\u9010\u6e10\u4e0b\u964d\u548c\u6545\u969c\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u89e3\u51b3\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u7684\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u6bd4\u8f83\u9759\u6001\u6a21\u578b\u4e0e\u5305\u542bDDM\u548cADWIN\u81ea\u9002\u5e94\u68c0\u6d4b\u5668\u7684\u81ea\u9002\u5e94\u6a21\u578b\uff0c\u5c06\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u5e94\u7528\u4e8e\u5904\u7406\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u3002", "result": "\u81ea\u9002\u5e94\u6a21\u578b\u5728\u7a81\u53d1\u3001\u6e10\u8fdb\u548c\u91cd\u590d\u5de5\u4f5c\u8d1f\u8f7d\u8f6c\u6362\u573a\u666f\u4e2d\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0cF1\u5206\u6570\u5747\u8d85\u8fc70.93\uff0c\u800c\u9759\u6001\u6a21\u578b\u5728\u672a\u89c1\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u57fa\u4e8eADWIN\u7684\u81ea\u9002\u5e94\u6a21\u578b\u80fd\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\uff0c\u5728\u8f6f\u4ef6\u8001\u5316\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.03136", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03136", "abs": "https://arxiv.org/abs/2511.03136", "authors": ["Kexing Ji", "Shiyun Fu", "Cuiyun Gao", "Yujia Chen", "Zezhou Yang", "Chaozheng Wang", "Yuetang Deng"], "title": "Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat", "comment": "Accepted by ASE 2025 Industry Track", "summary": "Large Code Models (LCMs) show potential in code intelligence, but their\neffectiveness is greatly influenced by prompt quality. Current prompt design is\nmostly manual, which is time-consuming and highly dependent on specific LCMs\nand tasks. While automated prompt generation (APG) exists in NLP, it is\nunderexplored for code intelligence. This creates a gap, as automating the\nprompt process is essential for developers facing diverse tasks and black-box\nLCMs.\n  To mitigate this, we empirically investigate two important parts of APG:\nInstruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a\ntask-related description to instruct LCMs, while MSR guides them to produce\nlogical steps before the final answer. We evaluate widely-used APG methods for\neach part on four open-source LCMs and three code intelligence tasks: code\ntranslation (PL-PL), code summarization (PL-NL), and API recommendation\n(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance\nperformance compared to basic prompts. Based on these results, we propose a\nnovel APG approach combining the best methods of the two parts. Experiments\nshow our approach achieves average improvements of 28.38% in CodeBLEU (code\ntranslation), 58.11% in ROUGE-L (code summarization), and 84.53% in\nSuccessRate@1 (API recommendation) over basic prompts. To validate its\neffectiveness in an industrial scenario, we evaluate our approach on\nWeChat-Bench, a proprietary dataset, achieving an average MRR improvement of\n148.89% for API recommendation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u4ee3\u7801\u6a21\u578b\u4e2d\u81ea\u52a8\u63d0\u793a\u751f\u6210\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6307\u4ee4\u751f\u6210\u548c\u591a\u6b65\u63a8\u7406\u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u4ee3\u7801\u6a21\u578b\u7684\u63d0\u793a\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\uff0c\u8017\u65f6\u4e14\u4f9d\u8d56\u7279\u5b9a\u6a21\u578b\u548c\u4efb\u52a1\u3002\u867d\u7136NLP\u9886\u57df\u5df2\u6709\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\uff0c\u4f46\u5728\u4ee3\u7801\u667a\u80fd\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u8fd9\u7ed9\u9762\u5bf9\u591a\u6837\u5316\u4efb\u52a1\u548c\u9ed1\u76d2\u6a21\u578b\u7684\u5f00\u53d1\u8005\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u5b9e\u8bc1\u7814\u7a76\u6307\u4ee4\u751f\u6210\u548c\u591a\u6b65\u63a8\u7406\u4e24\u79cd\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u5728\u56db\u79cd\u5f00\u6e90\u5927\u578b\u4ee3\u7801\u6a21\u578b\u548c\u4e09\u4e2a\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u57fa\u4e8e\u8bc4\u4f30\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u6700\u4f73\u5b9e\u8df5\u7684\u65b0\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u534728.38%\u7684CodeBLEU\u5206\u6570\uff0c\u5728\u4ee3\u7801\u6458\u8981\u4efb\u52a1\u4e0a\u63d0\u534758.11%\u7684ROUGE-L\u5206\u6570\uff0c\u5728API\u63a8\u8350\u4efb\u52a1\u4e0a\u63d0\u534784.53%\u7684SuccessRate@1\u3002\u5728\u5de5\u4e1a\u573a\u666f\u7684WeChat-Bench\u6570\u636e\u96c6\u4e0a\uff0cAPI\u63a8\u8350\u7684MRR\u5e73\u5747\u63d0\u5347148.89%\u3002", "conclusion": "\u81ea\u52a8\u63d0\u793a\u751f\u6210\u80fd\u663e\u8457\u63d0\u5347\u5927\u578b\u4ee3\u7801\u6a21\u578b\u7684\u6027\u80fd\uff0c\u6307\u4ee4\u751f\u6210\u548c\u591a\u6b65\u63a8\u7406\u662f\u6709\u6548\u7684\u81ea\u52a8\u63d0\u793a\u751f\u6210\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03153", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03153", "abs": "https://arxiv.org/abs/2511.03153", "authors": ["Khouloud Oueslati", "Maxime Lamothe", "Foutse Khomh"], "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "comment": null, "summary": "Large Language Models (LLMs) have substantially influenced various software\nengineering tasks. Indeed, in the case of software refactoring, traditional\nLLMs have shown the ability to reduce development time and enhance code\nquality. However, these LLMs often rely on static, detailed instructions for\nspecific tasks. In contrast, LLM-based agents can dynamically adapt to evolving\ncontexts and autonomously make decisions by interacting with software tools and\nexecuting workflows. In this paper, we explore the potential of LLM-based\nagents in supporting refactoring activities. Specifically, we introduce\nRefAgent, a multi-agent LLM-based framework for end-to-end software\nrefactoring. RefAgent consists of specialized agents responsible for planning,\nexecuting, testing, and iteratively refining refactorings using self-reflection\nand tool-calling capabilities. We evaluate RefAgent on eight open-source Java\nprojects, comparing its effectiveness against a single-agent approach, a\nsearch-based refactoring tool, and historical developer refactorings. Our\nassessment focuses on: (1) the impact of generated refactorings on software\nquality, (2) the ability to identify refactoring opportunities, and (3) the\ncontribution of each LLM agent through an ablation study. Our results show that\nRefAgent achieves a median unit test pass rate of 90%, reduces code smells by a\nmedian of 52.5%, and improves key quality attributes (e.g., reusability) by a\nmedian of 8.6%. Additionally, it closely aligns with developer refactorings and\nthe search-based tool in identifying refactoring opportunities, attaining a\nmedian F1-score of 79.15% and 72.7%, respectively. Compared to single-agent\napproaches, RefAgent improves the median unit test pass rate by 64.7% and the\nmedian compilation success rate by 40.1%. These findings highlight the promise\nof multi-agent architectures in advancing automated software refactoring.", "AI": {"tldr": "RefAgent\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u7aef\u5230\u7aef\u7684\u8f6f\u4ef6\u91cd\u6784\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u89c4\u5212\u3001\u6267\u884c\u3001\u6d4b\u8bd5\u548c\u8fed\u4ee3\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8d28\u91cf\u548c\u91cd\u6784\u6548\u679c\u3002", "motivation": "\u4f20\u7edfLLM\u5728\u8f6f\u4ef6\u91cd\u6784\u4e2d\u4f9d\u8d56\u9759\u6001\u6307\u4ee4\uff0c\u800cLLM\u667a\u80fd\u4f53\u80fd\u591f\u52a8\u6001\u9002\u5e94\u4e0a\u4e0b\u6587\u5e76\u81ea\u4e3b\u51b3\u7b56\uff0c\u63a2\u7d22\u5176\u5728\u91cd\u6784\u6d3b\u52a8\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u5f15\u5165RefAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u8d1f\u8d23\u89c4\u5212\u3001\u6267\u884c\u3001\u6d4b\u8bd5\u548c\u8fed\u4ee3\u4f18\u5316\u7684\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u5229\u7528\u81ea\u53cd\u601d\u548c\u5de5\u5177\u8c03\u7528\u80fd\u529b\u8fdb\u884c\u91cd\u6784\u3002", "result": "\u57288\u4e2a\u5f00\u6e90Java\u9879\u76ee\u4e0a\u8bc4\u4f30\uff0cRefAgent\u8fbe\u523090%\u7684\u5355\u5143\u6d4b\u8bd5\u901a\u8fc7\u7387\uff0c\u51cf\u5c1152.5%\u7684\u4ee3\u7801\u574f\u5473\uff0c\u63d0\u53478.6%\u7684\u5173\u952e\u8d28\u91cf\u5c5e\u6027\uff0c\u4e0e\u5f00\u53d1\u8005\u91cd\u6784\u548c\u641c\u7d22\u5de5\u5177\u76f8\u6bd4\u5206\u522b\u83b7\u5f9779.15%\u548c72.7%\u7684F1\u5206\u6570\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5728\u63a8\u8fdb\u81ea\u52a8\u5316\u8f6f\u4ef6\u91cd\u6784\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u901a\u8fc7\u7387\u548c\u7f16\u8bd1\u6210\u529f\u7387\u3002"}}
{"id": "2511.03182", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03182", "abs": "https://arxiv.org/abs/2511.03182", "authors": ["Vinaik Chhetri", "A. B Siddique", "Umar Farooq"], "title": "Understanding Robustness of Model Editing in Code LLMs: An Empirical Study", "comment": "26 pages, 2 figures, 15 tables", "summary": "Large language models (LLMs) are increasingly used in software development.\nHowever, while LLMs remain static after pretraining, programming languages and\nAPIs continue to evolve, leading to the generation of deprecated or\nincompatible code that undermines reliability. Retraining LLMs from scratch to\nreflect such changes is computationally expensive, making model editing a\npromising lightweight alternative that updates only a small subset of\nparameters. Despite its potential, it remains unclear whether model editing\nyields genuine syntactic and semantic adaptations or merely superficial fixes.\nIn this work, we present a systematic study of five state-of-the-art model\nediting methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We\napply these methods to three leading open-source code LLMs, CodeLlama,\nCodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.\nOur evaluation covers both instant and sequential editing settings, using three\ndisjoint evaluation sets designed to assess reliability, generalization, and\nspecificity. We measure model correctness at three levels: successful\ncompilation, partial test case pass, and full test pass. Our findings show that\ninstant edits consistently degrade model performance, with syntactic validity\ndropping by up to 86 percentage points and functional correctness declining by\n45 points even in the best-performing setting. Sequential edits further amplify\nthis degradation, and in some cases, model performance collapses entirely.\nAcross all models, most passing generations relied on workarounds rather than\ncorrectly adopting the intended changes, while faulty adoptions that result in\ntest failures or compilation errors were significantly more frequent. Correct\nadoptions, where the model correctly integrates the intended change, occurred\nin only about 6% of cases.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e865\u79cd\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u4ee3\u7801LLMs\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5728API\u5f03\u7528\u573a\u666f\u4e0b\uff0c\u5373\u65f6\u7f16\u8f91\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u6700\u591a\u4e0b\u964d86\u4e2a\u767e\u5206\u70b9\uff0c\u529f\u80fd\u6b63\u786e\u6027\u4e0b\u964d45\u70b9\u3002\u987a\u5e8f\u7f16\u8f91\u8fdb\u4e00\u6b65\u52a0\u5267\u6027\u80fd\u9000\u5316\uff0c\u6b63\u786e\u91c7\u7528\u7f16\u8f91\u7684\u60c5\u51b5\u4ec5\u5360\u7ea66%\u3002", "motivation": "LLMs\u5728\u8bad\u7ec3\u540e\u4fdd\u6301\u9759\u6001\uff0c\u800c\u7f16\u7a0b\u8bed\u8a00\u548cAPI\u6301\u7eed\u6f14\u8fdb\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u53ef\u80fd\u5df2\u8fc7\u65f6\u6216\u4e0d\u517c\u5bb9\u3002\u91cd\u65b0\u8bad\u7ec3LLMs\u6210\u672c\u9ad8\u6602\uff0c\u6a21\u578b\u7f16\u8f91\u4f5c\u4e3a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5176\u662f\u5426\u80fd\u5b9e\u73b0\u771f\u6b63\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u9002\u5e94\u3002", "method": "\u5bf95\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\uff08Constrained FT\u3001GRACE\u3001MEMIT\u3001PMET\u3001ROME\uff09\u57283\u4e2a\u5f00\u6e90\u4ee3\u7801LLMs\uff08CodeLlama\u3001CodeQwen1.5\u3001DeepSeek-Coder\uff09\u4e0a\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5728\u53d7\u63a7API\u5f03\u7528\u573a\u666f\u4e0b\u8bc4\u4f30\u5373\u65f6\u548c\u987a\u5e8f\u7f16\u8f91\u8bbe\u7f6e\u3002", "result": "\u5373\u65f6\u7f16\u8f91\u6301\u7eed\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u6700\u591a\u4e0b\u964d86\u4e2a\u767e\u5206\u70b9\uff0c\u529f\u80fd\u6b63\u786e\u6027\u4e0b\u964d45\u70b9\u3002\u987a\u5e8f\u7f16\u8f91\u8fdb\u4e00\u6b65\u653e\u5927\u8fd9\u79cd\u9000\u5316\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6a21\u578b\u6027\u80fd\u5b8c\u5168\u5d29\u6e83\u3002\u6b63\u786e\u91c7\u7528\u7f16\u8f91\u7684\u60c5\u51b5\u4ec5\u5360\u7ea66%\uff0c\u5927\u591a\u6570\u901a\u8fc7\u751f\u6210\u4f9d\u8d56\u53d8\u901a\u65b9\u6848\u800c\u975e\u6b63\u786e\u91c7\u7eb3\u9884\u671f\u66f4\u6539\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u4ee3\u7801LLMs\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u4ea7\u751f\u8868\u9762\u4fee\u590d\u800c\u975e\u771f\u6b63\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u9002\u5e94\uff0c\u6b63\u786e\u91c7\u7528\u7387\u6781\u4f4e\uff0c\u8868\u660e\u9700\u8981\u66f4\u6709\u6548\u7684\u6a21\u578b\u66f4\u65b0\u7b56\u7565\u6765\u5e94\u5bf9\u7f16\u7a0b\u73af\u5883\u7684\u6301\u7eed\u6f14\u8fdb\u3002"}}
{"id": "2511.03404", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03404", "abs": "https://arxiv.org/abs/2511.03404", "authors": ["Qianhui Zhao", "Li Zhang", "Fang Liu", "Junhang Cheng", "Chengru Wu", "Junchen Ai", "Qiaoyuanhe Meng", "Lichen Zhang", "Xiaoli Lian", "Shubin Song", "Yuanping Guo"], "title": "Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling", "comment": null, "summary": "In recent years, Large Language Models (LLMs) have achieved remarkable\nprogress in automated code generation. In real-world software engineering, the\ngrowing demand for rapid iteration and continuous delivery underscores the\nimportance of project-level code generation, where LLMs are expected to\ngenerate complete software projects directly from complex user requirements.\nAlthough existing studies have made initial explorations, they still face key\nlimitations, including unrealistic datasets and unreliable evaluation metrics\nthat fail to reflect real-world complexity, the semantic gap between\nhuman-written requirements and machine-interpretable structures, and\ndifficulties in managing hierarchical dependencies and maintaining quality\nthroughout the generation process. To address these limitations, we first\nintroduce CodeProjectEval, a project-level code generation dataset built from\n18 real-world repositories with 12.7 files and 2,388.6 lines of code per task\non average, supplemented with documentation and executable test cases for\nautomatic evaluation. We further propose ProjectGen, a multi-agent framework\nthat decomposes projects into architecture design, skeleton generation, and\ncode filling stages with iterative refinement and memory-based context\nmanagement. Within this framework, we introduce the Semantic Software\nArchitecture Tree (SSAT), a structured and semantically rich representation\nthat effectively bridges user requirements and source code implementation.\nExperiments show that ProjectGen achieves state-of-the-art performance, passing\n52/124 test cases on the small-scale project-level code generation dataset\nDevBench, a 57% improvement over the baseline approaches, and 310 test cases on\nCodeProjectEval, representing an improvement of roughly tenfold compared to the\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86ProjectGen\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548cCodeProjectEval\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8bed\u4e49\u9e3f\u6c9f\u3001\u5c42\u6b21\u4f9d\u8d56\u7ba1\u7406\u548c\u8d28\u91cf\u7ef4\u62a4\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u9879\u76ee\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u7814\u7a76\u5b58\u5728\u6570\u636e\u96c6\u4e0d\u771f\u5b9e\u3001\u8bc4\u4f30\u6307\u6807\u4e0d\u53ef\u9760\u3001\u7528\u6237\u9700\u6c42\u4e0e\u673a\u5668\u53ef\u89e3\u91ca\u7ed3\u6784\u4e4b\u95f4\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u3001\u96be\u4ee5\u7ba1\u7406\u5c42\u6b21\u4f9d\u8d56\u548c\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faProjectGen\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u9879\u76ee\u5206\u89e3\u4e3a\u67b6\u6784\u8bbe\u8ba1\u3001\u9aa8\u67b6\u751f\u6210\u548c\u4ee3\u7801\u586b\u5145\u4e09\u4e2a\u9636\u6bb5\uff0c\u91c7\u7528\u8fed\u4ee3\u4f18\u5316\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0c\u5f15\u5165\u8bed\u4e49\u8f6f\u4ef6\u67b6\u6784\u6811(SSAT)\u6765\u6865\u63a5\u7528\u6237\u9700\u6c42\u548c\u6e90\u4ee3\u7801\u5b9e\u73b0\u3002", "result": "\u5728DevBench\u5c0f\u89c4\u6a21\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6\u4e0a\u901a\u8fc752/124\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534757%\uff1b\u5728CodeProjectEval\u6570\u636e\u96c6\u4e0a\u901a\u8fc7310\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u7ea610\u500d\u3002", "conclusion": "ProjectGen\u6846\u67b6\u548cCodeProjectEval\u6570\u636e\u96c6\u6709\u6548\u89e3\u51b3\u4e86\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u81ea\u52a8\u5316\u9879\u76ee\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.03421", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03421", "abs": "https://arxiv.org/abs/2511.03421", "authors": ["Shihai Wang", "Tao Chen"], "title": "Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement", "comment": "accepted by ICSE 2026", "summary": "Elicited performance requirements need to be quantified for compliance in\ndifferent engineering tasks, e.g., configuration tuning and performance\ntesting. Much existing work has relied on manual quantification, which is\nexpensive and error-prone due to the imprecision. In this paper, we present\nLQPR, a highly efficient automatic approach for performance requirements\nquantification.LQPR relies on a new theoretical framework that converts\nquantification as a classification problem. Despite the prevalent applications\nof Large Language Models (LLMs) for requirement analytics, LQPR takes a\ndifferent perspective to address the classification: we observed that\nperformance requirements can exhibit strong patterns and are often\nshort/concise, therefore we design a lightweight linguistically induced\nmatching mechanism. We compare LQPR against nine state-of-the-art\nlearning-based approaches over diverse datasets, demonstrating that it is\nranked as the sole best for 75% or more cases with two orders less cost. Our\nwork proves that, at least for performance requirement quantification,\nspecialized methods can be more suitable than the general LLM-driven\napproaches.", "AI": {"tldr": "LQPR\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u6027\u80fd\u9700\u6c42\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u91cf\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8bed\u8a00\u8bf1\u5bfc\u5339\u914d\u673a\u5236\uff0c\u5728\u6027\u80fd\u548c\u6210\u672c\u4e0a\u90fd\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6027\u80fd\u9700\u6c42\u91cf\u5316\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u65b9\u6cd5\uff0c\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u9700\u8981\u5f00\u53d1\u81ea\u52a8\u5316\u7684\u91cf\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "LQPR\u5c06\u6027\u80fd\u9700\u6c42\u91cf\u5316\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u5229\u7528\u6027\u80fd\u9700\u6c42\u5177\u6709\u5f3a\u6a21\u5f0f\u548c\u7b80\u6d01\u6027\u7684\u7279\u70b9\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u8bed\u8a00\u8bf1\u5bfc\u5339\u914d\u673a\u5236\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u4e0e9\u79cd\u6700\u5148\u8fdb\u7684\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8f83\uff0cLQPR\u572875%\u4ee5\u4e0a\u7684\u60c5\u51b5\u4e0b\u6392\u540d\u7b2c\u4e00\uff0c\u4e14\u6210\u672c\u964d\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u5bf9\u4e8e\u6027\u80fd\u9700\u6c42\u91cf\u5316\u4efb\u52a1\uff0c\u4e13\u95e8\u5316\u7684\u65b9\u6cd5\u6bd4\u901a\u7528\u7684LLM\u9a71\u52a8\u65b9\u6cd5\u66f4\u5408\u9002\uff0cLQPR\u8bc1\u660e\u4e86\u8fd9\u4e00\u70b9\u3002"}}
{"id": "2511.03517", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03517", "abs": "https://arxiv.org/abs/2511.03517", "authors": ["Wencheng Ye", "Yan Liu"], "title": "U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility", "comment": null, "summary": "Large language models (LLMs) have shown strong capabilities in software\nengineering tasks, yet most existing LLM-based SWE-Agents mainly tackle\nwell-defined problems using conventional methods, often overlooking alternative\nor innovative solutions beyond their predefined frameworks. This limitation is\nevident in open-world software environments, where emerging challenges\ntranscend established paradigms.\n  We propose U2F (Unknown Unknowns to Functional solutions), a\ncognitive-inspired, uncertainty-embracing multi-agent framework that\nsystematically surfaces \"Unknown Unknowns\" - novel solution pathways absent\nfrom initial formulations but holding innovative potential. U2F consists of two\nkey components: (1) a Discovery-Exploration-Integration agent system for\nuncovering and synthesizing potential solutions, and (2) cognitive enhancement\nmechanisms across three dimensions: cross-domain analogical reasoning, reverse\nthinking, and external validation, which strategically reframe and extend\nconventional solution boundaries.\n  Applied to 218 real-world software enabler stories curated from authentic\nengineering tasks, U2F achieved notable improvements: human experts reported a\n14 percent increase in overall novelty, 51 percent improvement in semantic\nnovelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based\nevaluator. These results highlight the potential of embracing uncertainty as a\ncatalyst for innovation in software engineering.", "AI": {"tldr": "U2F\u662f\u4e00\u4e2a\u8ba4\u77e5\u542f\u53d1\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u62e5\u62b1\u4e0d\u786e\u5b9a\u6027\u6765\u53d1\u73b0\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u65b0\u9896\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u4e3b\u8981\u89e3\u51b3\u5b9a\u4e49\u660e\u786e\u7684\u95ee\u9898\uff0c\u4f46\u5728\u5f00\u653e\u4e16\u754c\u8f6f\u4ef6\u73af\u5883\u4e2d\u96be\u4ee5\u53d1\u73b0\u8d85\u8d8a\u9884\u5b9a\u4e49\u6846\u67b6\u7684\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "U2F\u5305\u542b\u53d1\u73b0-\u63a2\u7d22-\u96c6\u6210\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4ee5\u53ca\u8de8\u9886\u57df\u7c7b\u6bd4\u63a8\u7406\u3001\u9006\u5411\u601d\u7ef4\u548c\u5916\u90e8\u9a8c\u8bc1\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8ba4\u77e5\u589e\u5f3a\u673a\u5236\u3002", "result": "\u5728218\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\uff0cU2F\u4f7f\u6574\u4f53\u65b0\u9896\u6027\u63d0\u534714%\uff0c\u8bed\u4e49\u65b0\u9896\u6027\u63d0\u534751%\uff0c\u53ef\u884c\u6027\u7a33\u5b9a\u57284.02/5.0\u3002", "conclusion": "\u62e5\u62b1\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u521b\u65b0\u7684\u50ac\u5316\u5242\uff0cU2F\u6846\u67b6\u5c55\u793a\u4e86\u901a\u8fc7\u7cfb\u7edf\u6027\u53d1\u73b0\u672a\u77e5\u672a\u77e5\u6765\u63a8\u52a8\u521b\u65b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.03549", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03549", "abs": "https://arxiv.org/abs/2511.03549", "authors": ["Ziv Nevo", "Orna Raz", "Karen Yorav"], "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding", "comment": "7 pages, 6 figures, to be published in AISM 2025, see\n  https://aism25.github.io/aism25/", "summary": "Understanding the purpose of source code is a critical task in software\nmaintenance, onboarding, and modernization. While large language models (LLMs)\nhave shown promise in generating code explanations, they often lack grounding\nin the broader software engineering context. We propose a novel approach that\nleverages natural language artifacts from GitHub -- such as pull request\ndescriptions, issue descriptions and discussions, and commit messages -- to\nenhance LLM-based code understanding. Our system consists of three components:\none that extracts and structures relevant GitHub context, another that uses\nthis context to generate high-level explanations of the code's purpose, and a\nthird that validates the explanation. We implemented this as a standalone tool,\nas well as a server within the Model Context Protocol (MCP), enabling\nintegration with other AI-assisted development tools. Our main use case is that\nof enhancing a standard LLM-based code explanation with code insights that our\nsystem generates. To evaluate explanations' quality, we conducted a small scale\nuser study, with developers of several open projects, as well as developers of\nproprietary projects. Our user study indicates that when insights are generated\nthey often are helpful and non trivial, and are free from hallucinations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528GitHub\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\uff08\u5982PR\u63cf\u8ff0\u3001issue\u8ba8\u8bba\u7b49\uff09\u6765\u589e\u5f3aLLM\u4ee3\u7801\u7406\u89e3\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6GitHub\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4ee3\u7801\u76ee\u7684\u89e3\u91ca\u548c\u9a8c\u8bc1\u89e3\u91ca\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u63d0\u5347\u4ee3\u7801\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524dLLM\u5728\u751f\u6210\u4ee3\u7801\u89e3\u91ca\u65f6\u7f3a\u4e4f\u8f6f\u4ef6\u5de5\u7a0b\u4e0a\u4e0b\u6587\u57fa\u7840\uff0c\u9700\u8981\u5229\u7528GitHub\u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\u6765\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u80cc\u666f\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u4ee3\u7801\u7406\u89e3\u7684\u8d28\u91cf\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u63d0\u53d6\u548c\u7ed3\u6784\u5316GitHub\u4e0a\u4e0b\u6587\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u751f\u6210\u4ee3\u7801\u76ee\u7684\u7684\u9ad8\u5c42\u89e3\u91ca\u3001\u9a8c\u8bc1\u89e3\u91ca\u7684\u6709\u6548\u6027\u3002\u5b9e\u73b0\u4e86\u72ec\u7acb\u5de5\u5177\u548cMCP\u670d\u52a1\u5668\u4e24\u79cd\u5f62\u5f0f\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u5f53\u7cfb\u7edf\u751f\u6210\u89c1\u89e3\u65f6\uff0c\u8fd9\u4e9b\u89c1\u89e3\u901a\u5e38\u662f\u6709\u5e2e\u52a9\u4e14\u975e\u5e73\u51e1\u7684\uff0c\u5e76\u4e14\u6ca1\u6709\u51fa\u73b0\u5e7b\u89c9\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528GitHub\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\u589e\u5f3aLLM\u7684\u4ee3\u7801\u7406\u89e3\u80fd\u529b\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u4ee3\u7801\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u8f6f\u4ef6\u7ef4\u62a4\u548c\u73b0\u4ee3\u5316\u63d0\u4f9b\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2511.03690", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03690", "abs": "https://arxiv.org/abs/2511.03690", "authors": ["Xingyao Wang", "Simon Rosenberg", "Juan Michelini", "Calvin Smith", "Hoang Tran", "Engel Nyst", "Rohit Malhotra", "Xuhui Zhou", "Valerie Chen", "Robert Brennan", "Graham Neubig"], "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents", "comment": null, "summary": "Agents are now used widely in the process of software development, but\nbuilding production-ready software engineering agents is a complex task.\nDeploying software agents effectively requires flexibility in implementation\nand experimentation, reliable and secure execution, and interfaces for users to\ninteract with agents. In this paper, we present the OpenHands Software Agent\nSDK, a toolkit for implementing software development agents that satisfy these\ndesiderata. This toolkit is a complete architectural redesign of the agent\ncomponents of the popular OpenHands framework for software development agents,\nwhich has 64k+ GitHub stars. To achieve flexibility, we design a simple\ninterface for implementing agents that requires only a few lines of code in the\ndefault case, but is easily extensible to more complex, full-featured agents\nwith features such as custom tools, memory management, and more. For security\nand reliability, it delivers seamless local-to-remote execution portability,\nintegrated REST/WebSocket services. For interaction with human users, it can\nconnect directly to a variety of interfaces, such as visual workspaces (VS\nCode, VNC, browser), command-line interfaces, and APIs. Compared with existing\nSDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native\nsandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and\nbuilt-in security analysis. Empirical results on SWE-Bench Verified and GAIA\nbenchmarks demonstrate strong performance. Put together, these elements allow\nthe OpenHands Software Agent SDK to provide a practical foundation for\nprototyping, unlocking new classes of custom applications, and reliably\ndeploying agents at scale.", "AI": {"tldr": "OpenHands Software Agent SDK\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u5de5\u5177\u5305\uff0c\u63d0\u4f9b\u7075\u6d3b\u6027\u3001\u5b89\u5168\u6027\u548c\u7528\u6237\u4ea4\u4e92\u529f\u80fd\uff0c\u652f\u6301\u4ece\u7b80\u5355\u5230\u590d\u6742\u7684\u4ee3\u7406\u5b9e\u73b0\u3002", "motivation": "\u6784\u5efa\u751f\u4ea7\u5c31\u7eea\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u662f\u4e00\u4e2a\u590d\u6742\u4efb\u52a1\uff0c\u9700\u8981\u7075\u6d3b\u7684\u5b9e\u73b0\u5728\u7ebf\u3001\u53ef\u9760\u5b89\u5168\u7684\u6267\u884c\u73af\u5883\u4ee5\u53ca\u7528\u6237\u4ea4\u4e92\u63a5\u53e3\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u4e86OpenHands\u6846\u67b6\u7684\u4ee3\u7406\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u7b80\u5355\u63a5\u53e3\u5b9e\u73b0\u57fa\u672c\u4ee3\u7406\uff0c\u53ef\u6269\u5c55\u652f\u6301\u81ea\u5b9a\u4e49\u5de5\u5177\u3001\u5185\u5b58\u7ba1\u7406\u7b49\u590d\u6742\u529f\u80fd\uff0c\u5177\u5907\u672c\u5730\u5230\u8fdc\u7a0b\u6267\u884c\u7684\u53ef\u79fb\u690d\u6027\u3001\u96c6\u6210REST/WebSocket\u670d\u52a1\u3002", "result": "\u5728SWE-Bench Verified\u548cGAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u53ef\u9760\u5730\u5927\u89c4\u6a21\u90e8\u7f72\u4ee3\u7406\u3002", "conclusion": "OpenHands Software Agent SDK\u4e3a\u539f\u578b\u8bbe\u8ba1\u3001\u89e3\u9501\u65b0\u578b\u81ea\u5b9a\u4e49\u5e94\u7528\u548c\u5927\u89c4\u6a21\u53ef\u9760\u90e8\u7f72\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
