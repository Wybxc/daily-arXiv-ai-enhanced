{"id": "2601.03249", "categories": ["cs.LO", "cs.FL", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03249", "abs": "https://arxiv.org/abs/2601.03249", "authors": ["Leen Lambers", "Oszk\u00e1r Semer\u00e1th"], "title": "Proceedings 16th International Workshop on Graph Computation Models", "comment": null, "summary": "This volume contains the post-proceedings of the Sixteenth International Workshop on Graph Computation Models (GCM 2025). The workshops took place in Koblenz, Germany on June 10 as part of STAF (Software Technologies: Applications and Foundations).  \n  Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modeling in science, engineering, and beyond, including computer science, biology, and business process modeling. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.", "AI": {"tldr": "GCM 2025\u662f\u7b2c\u5341\u516d\u5c4a\u56fd\u9645\u56fe\u8ba1\u7b97\u6a21\u578b\u7814\u8ba8\u4f1a\u7684\u540e\u8bba\u6587\u96c6\uff0c\u805a\u7126\u4e8e\u56fe\u4f5c\u4e3a\u8ba1\u7b97\u6a21\u578b\u6838\u5fc3\u7684\u7814\u7a76\u4e0e\u5e94\u7528", "motivation": "\u56fe\u4f5c\u4e3a\u76f4\u89c2\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u5728\u79d1\u5b66\u3001\u5de5\u7a0b\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u751f\u7269\u5b66\u548c\u4e1a\u52a1\u6d41\u7a0b\u5efa\u6a21\u7b49\u9886\u57df\u5177\u6709\u5929\u7136\u7684\u7cfb\u7edf\u5efa\u6a21\u4f18\u52bf\u3002\u56fe\u8ba1\u7b97\u6a21\u578b\u4f5c\u4e3a\u9ad8\u7ea7\u6a21\u578b\uff0c\u5c06\u56fe\u4f5c\u4e3a\u4e00\u7b49\u516c\u6c11\uff0c\u9700\u8981\u4fc3\u8fdb\u4e0d\u540c\u7814\u7a76\u793e\u533a\u4e4b\u95f4\u7684\u4ea4\u6d41\u4e0e\u5408\u4f5c\u3002", "method": "\u901a\u8fc7\u56fd\u9645\u7814\u8ba8\u4f1a\u5f62\u5f0f\uff0c\u6c47\u96c6\u5bf9\u57fa\u4e8e\u56fe\u548c\u56fe\u53d8\u6362\u7684\u8ba1\u7b97\u6a21\u578b\u5404\u65b9\u9762\u611f\u5174\u8da3\u7684\u7814\u7a76\u4eba\u5458\uff0c\u4fc3\u8fdb\u8d44\u6df1\u548c\u5e74\u8f7b\u7814\u7a76\u8005\u4e4b\u95f4\u7684\u601d\u60f3\u4ea4\u6d41\u4e0e\u7ecf\u9a8c\u5206\u4eab\u3002", "result": "\u6210\u529f\u4e3e\u529e\u4e86\u7b2c\u5341\u516d\u5c4aGCM\u7814\u8ba8\u4f1a\uff0c\u4f5c\u4e3aSTAF\uff08\u8f6f\u4ef6\u6280\u672f\uff1a\u5e94\u7528\u4e0e\u57fa\u7840\uff09\u7684\u4e00\u90e8\u5206\uff0c\u5e76\u51fa\u7248\u4e86\u540e\u8bba\u6587\u96c6\u3002", "conclusion": "GCM\u7814\u8ba8\u4f1a\u7cfb\u5217\u6301\u7eed\u63a8\u52a8\u56fe\u8ba1\u7b97\u6a21\u578b\u5728\u7406\u8bba\u57fa\u7840\u3001\u5e94\u7528\u5b9e\u73b0\u548c\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\uff0c\u4fc3\u8fdb\u4e86\u8de8\u793e\u533a\u7684\u77e5\u8bc6\u4ea4\u6d41\u4e0e\u521b\u65b0\u3002"}}
{"id": "2601.02653", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.02653", "abs": "https://arxiv.org/abs/2601.02653", "authors": ["Ajay Brahmakshatriya", "Saman Amarasinghe", "Martin Rinard"], "title": "Backwards Data-Flow Analysis using Prophecy Variable in the BuildIt System", "comment": null, "summary": "Many program transformations and optimizations require information about the future behavior of the program. A standard way to obtain this information is to build an intermediate program representation, then use a backwards program analysis to propagate relevant information against the flow of control back to the transformation/optimization site. We instead propose to use prophecy variables, which predict information about the future execution of the program, to enable such transformations and optimizations. We implement prophecy variables in BuildIt, a lightweight domain specific language implementation system. BuildIt uses staged compilation to implement high performance domain specific languages embedded within a standard general purpose programming language (C++). The BuildIt first phase uses standard C++ program execution to generate optimized C, C++, and CUDA second phase code. This approach enables BuildIt to eliminate programming language implementation components such as parsers and intermediate representations, delivering a dramatic decrease in the engineering effort required to implement domain specific languages. The combination of prophecy variables and repeated forward program execution enables BuildIt to extend this approach to include transformations and optimizations that require information about the future execution of the program without backwards analyses and without the engineering overhead associated with implementing these analyses. We formalize the use of prophecy variables for this purpose, discuss the implementation of prophecy variables and repeated execution in BuildIt, and present experimental results for BuildIt computations that benefit from optimizations enabled by the information that prophecy variables provide.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u9884\u8a00\u53d8\u91cf\uff08prophecy variables\uff09\u6765\u9884\u6d4b\u7a0b\u5e8f\u672a\u6765\u6267\u884c\u4fe1\u606f\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u53cd\u5411\u7a0b\u5e8f\u5206\u6790\uff0c\u4ece\u800c\u7b80\u5316\u9700\u8981\u672a\u6765\u884c\u4e3a\u4fe1\u606f\u7684\u7a0b\u5e8f\u8f6c\u6362\u548c\u4f18\u5316\u3002", "motivation": "\u8bb8\u591a\u7a0b\u5e8f\u8f6c\u6362\u548c\u4f18\u5316\u9700\u8981\u7a0b\u5e8f\u672a\u6765\u884c\u4e3a\u7684\u4fe1\u606f\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u6784\u5efa\u4e2d\u95f4\u7a0b\u5e8f\u8868\u793a\u5e76\u4f7f\u7528\u53cd\u5411\u7a0b\u5e8f\u5206\u6790\u6765\u4f20\u64ad\u76f8\u5173\u4fe1\u606f\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5b9e\u73b0\u590d\u6742\u4e14\u5de5\u7a0b\u5f00\u9500\u5927\u3002", "method": "\u5728BuildIt\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9884\u8a00\u53d8\u91cf\uff0c\u8fd9\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9e\u73b0\u7cfb\u7edf\u3002BuildIt\u91c7\u7528\u5206\u9636\u6bb5\u7f16\u8bd1\uff0c\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u6807\u51c6C++\u7a0b\u5e8f\u6267\u884c\u751f\u6210\u4f18\u5316\u7684C\u3001C++\u548cCUDA\u7b2c\u4e8c\u9636\u6bb5\u4ee3\u7801\u3002\u7ed3\u5408\u9884\u8a00\u53d8\u91cf\u548c\u91cd\u590d\u6b63\u5411\u7a0b\u5e8f\u6267\u884c\uff0c\u65e0\u9700\u53cd\u5411\u5206\u6790\u5373\u53ef\u83b7\u53d6\u672a\u6765\u6267\u884c\u4fe1\u606f\u3002", "result": "BuildIt\u6210\u529f\u5b9e\u73b0\u4e86\u9884\u8a00\u53d8\u91cf\uff0c\u6d88\u9664\u4e86\u4f20\u7edf\u8bed\u8a00\u5b9e\u73b0\u7ec4\u4ef6\uff08\u5982\u89e3\u6790\u5668\u548c\u4e2d\u95f4\u8868\u793a\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9e\u73b0\u7684\u5de5\u7a0b\u5de5\u4f5c\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aBuildIt\u8ba1\u7b97\u80fd\u591f\u4ece\u9884\u8a00\u53d8\u91cf\u63d0\u4f9b\u7684\u4fe1\u606f\u4e2d\u53d7\u76ca\u3002", "conclusion": "\u9884\u8a00\u53d8\u91cf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u83b7\u53d6\u7a0b\u5e8f\u672a\u6765\u6267\u884c\u4fe1\u606f\uff0c\u65e0\u9700\u590d\u6742\u7684\u53cd\u5411\u7a0b\u5e8f\u5206\u6790\uff0c\u7b80\u5316\u4e86\u9700\u8981\u672a\u6765\u884c\u4e3a\u4fe1\u606f\u7684\u7a0b\u5e8f\u8f6c\u6362\u548c\u4f18\u5316\u5b9e\u73b0\u3002"}}
{"id": "2601.02803", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2601.02803", "abs": "https://arxiv.org/abs/2601.02803", "authors": ["Kasper Hagens", "Cynthia Kop"], "title": "Bounded Rewriting Induction for LCSTRSs", "comment": "50 pages, 3 figures, to be submitted to LMCS", "summary": "Rewriting Induction (RI) is a method to prove inductive theorems, originating from equational reasoning. By using Logically Constrained Simply-typed Term Rewriting Systems (LCSTRSs) as an intermediate language, rewriting induction becomes a tool for program verification, with inductive theorems taking the role of equivalence predicates. Soundness of RI depends on well-founded induction, and one of the core obstacles for obtaining a practically useful proof system is to find suitable well-founded orderings automatically. Using naive approaches, all induction hypotheses must be oriented within the well-founded ordering, which leads to very strong termination requirements. This, in turn, severely limits the proof capacity of RI. Here, we introduce Bounded RI: an adaption of RI for LCSTRSs where such termination requirements are minimized.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBounded RI\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7ec8\u6b62\u8981\u6c42\u6765\u6539\u8fdb\u57fa\u4e8eLCSTRS\u7684\u6539\u5199\u5f52\u7eb3\u6cd5\uff0c\u589e\u5f3a\u7a0b\u5e8f\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u6539\u5199\u5f52\u7eb3\u6cd5(RI)\u5728\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u9762\u4e34\u4e25\u683c\u7684\u7ec8\u6b62\u8981\u6c42\u9650\u5236\uff0c\u6240\u6709\u5f52\u7eb3\u5047\u8bbe\u5fc5\u987b\u5728\u826f\u57fa\u5e8f\u4e2d\u53ef\u5b9a\u5411\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86RI\u7684\u8bc1\u660e\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6700\u5c0f\u5316\u8fd9\u4e9b\u7ec8\u6b62\u8981\u6c42\u3002", "method": "\u63d0\u51faBounded RI\u65b9\u6cd5\uff0c\u8fd9\u662f\u9488\u5bf9\u903b\u8f91\u7ea6\u675f\u7b80\u5355\u7c7b\u578b\u9879\u91cd\u5199\u7cfb\u7edf(LCSTRSs)\u7684RI\u6539\u8fdb\u7248\u672c\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7ec8\u6b62\u8981\u6c42\u6765\u589e\u5f3a\u8bc1\u660e\u80fd\u529b\u3002", "result": "Bounded RI\u51cf\u5c11\u4e86\u4f20\u7edfRI\u4e2d\u7684\u4e25\u683c\u7ec8\u6b62\u8981\u6c42\uff0c\u4ece\u800c\u6269\u5c55\u4e86\u7a0b\u5e8f\u9a8c\u8bc1\u7684\u8bc1\u660e\u80fd\u529b\uff0c\u4f7f\u6539\u5199\u5f52\u7eb3\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u5b9e\u7528\u3002", "conclusion": "Bounded RI\u901a\u8fc7\u6700\u5c0f\u5316\u7ec8\u6b62\u8981\u6c42\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLCSTRS\u7684\u6539\u5199\u5f52\u7eb3\u6cd5\u5728\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u8bc1\u660e\u80fd\u529b\u3002"}}
{"id": "2601.02399", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02399", "abs": "https://arxiv.org/abs/2601.02399", "authors": ["Jiaxin Ai", "Yukang Feng", "Fanrui Zhang", "Jianwen Sun", "Zizhen Li", "Chuanhao Li", "Yifan Chang", "Wenxiao Wu", "Ruoxi Wang", "Mingliang Zhai", "Kaipeng Zhang"], "title": "ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments", "comment": null, "summary": "Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.", "AI": {"tldr": "ProSoftArena\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b436\u4e2a\u8de86\u4e2a\u5b66\u79d1\u300113\u4e2a\u4e13\u4e1a\u5e94\u7528\u7684\u771f\u5b9e\u4efb\u52a1\uff0c\u91c7\u7528\u6267\u884c\u8bc4\u4f30\u548c\u4eba\u5de5\u53c2\u4e0e\u8303\u5f0f\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5c40\u9650\u4e8e\u6d4f\u89c8\u5668\u548c\u57fa\u7840\u684c\u9762\u5e94\u7528\uff0c\u65e0\u6cd5\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u79d1\u5b66\u548c\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u4f7f\u7528\u7684\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86\u9488\u5bf9\u4e13\u4e1a\u8f6f\u4ef6\u4f7f\u7528\u7684\u9996\u4e2a\u80fd\u529b\u5c42\u6b21\u7ed3\u6784\uff0c\u521b\u5efa\u4e86\u5305\u542b436\u4e2a\u771f\u5b9e\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5efa\u7acb\u4e86\u53ef\u6267\u884c\u7684\u771f\u5b9e\u8ba1\u7b97\u673a\u73af\u5883\uff0c\u91c7\u7528\u57fa\u4e8e\u6267\u884c\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u72ec\u7279\u5730\u878d\u5165\u4e86\u4eba\u5de5\u53c2\u4e0e\u8bc4\u4f30\u8303\u5f0f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u4f73\u7684\u667a\u80fd\u4f53\u5728L2\u4efb\u52a1\u4e0a\u4e5f\u53ea\u670924.4%\u7684\u6210\u529f\u7387\uff0c\u5728L3\u591a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4e0a\u5b8c\u5168\u5931\u8d25\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u4e25\u91cd\u5c40\u9650\u6027\u3002", "conclusion": "ProSoftArena\u4e3a\u8bc4\u4f30\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u591a\u6a21\u6001\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u6df1\u5165\u5206\u6790\u4e3a\u514b\u670d\u5f53\u524d\u667a\u80fd\u4f53\u5c40\u9650\u6027\u548c\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u63a8\u52a8\u4e86\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u66f4\u5f3a\u5927\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.02563", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.02563", "abs": "https://arxiv.org/abs/2601.02563", "authors": ["Viacheslav Siniaev", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "Compressed code: the hidden effects of quantization and distillation on programming tokens", "comment": "18 pages, 1 figure and 6 tables", "summary": "Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684token\u7ea7\u673a\u5236\uff0c\u7279\u522b\u662f\u538b\u7f29\u6a21\u578b\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5bf9token\u8868\u793a\u548c\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176token\u7ea7\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u538b\u7f29\u6a21\u578b\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u7406\u89e3\u7f16\u7a0b\u8bed\u8a00\u5728LLM tokenizer\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f\uff0c\u4ee5\u53ca\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5982\u4f55\u5f71\u54cdtoken\u7ea7\u8868\u793a\u548c\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "method": "1. \u7cfb\u7edf\u5206\u6790\u7f16\u7a0b\u8bed\u8a00token\u8868\u793a\uff0c\u5305\u62ec\u8bcd\u6c47\u5206\u5e03\u548c\u5173\u952e\u8bcd\u8986\u76d6\u6a21\u5f0f\u5206\u6790\uff1b2. \u5f15\u5165\u65b0\u9896\u7684\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u65b9\u6cd5\uff0c\u65e0\u9700\u663e\u5f0f\u63d0\u793a\u5373\u53ef\u6d1e\u5bdf\u6a21\u578b\u884c\u4e3a\uff1b3. \u5168\u9762\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u4f18\u5316\u6280\u672f\uff08\u91cf\u5316\u3001\u84b8\u998f\u3001\u6a21\u578b\u7f29\u653e\u3001\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff09\u5bf9token\u7ea7\u8868\u793a\u548c\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff1b4. \u4f7f\u7528\u6982\u7387\u5206\u5e03\u5206\u6790\u548c\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86token\u7ea7\u884c\u4e3a\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u63d0\u4f9b\u4e86\u7ecf\u5b9e\u8bc1\u9a8c\u8bc1\u7684\u6307\u5bfc\u539f\u5219\uff0c\u5e2e\u52a9\u5728\u5404\u79cd\u4f18\u5316\u7ea6\u675f\u4e0b\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002\u7814\u7a76\u7ed3\u679c\u589e\u8fdb\u4e86\u5bf9LLM\u4ee3\u7801\u751f\u6210\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u4f18\u5316\u6a21\u578b\u7684\u5b9e\u8df5\u5b9e\u65bd\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u5206\u6790LLM\u4ee3\u7801\u751f\u6210\u7684token\u7ea7\u673a\u5236\uff0c\u7279\u522b\u662f\u538b\u7f29\u6a21\u578b\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u521b\u65b0\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u4e3a\u4e0d\u540c\u4f18\u5316\u6280\u672f\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7ef4\u62a4\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\uff0c\u63a8\u52a8\u4e86LLM\u4ee3\u7801\u751f\u6210\u7684\u7406\u8bba\u7406\u89e3\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.03201", "categories": ["cs.LO", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.03201", "abs": "https://arxiv.org/abs/2601.03201", "authors": ["Martin Grohe", "Christoph Standke", "Juno Steegmans", "Jan Van den Bussche"], "title": "Recursive querying of neural networks via weighted structures", "comment": null, "summary": "Expressive querying of machine learning models - viewed as a form of intentional data - enables their verification and interpretation using declarative languages, thereby making learned representations of data more accessible. Motivated by the querying of feedforward neural networks, we investigate logics for weighted structures. In the absence of a bound on neural network depth, such logics must incorporate recursion; thereto we revisit the functional fixpoint mechanism proposed by Gr\u00e4del and Gurevich. We adopt it in a Datalog-like syntax; we extend normal forms for fixpoint logics to weighted structures; and show an equivalent \"loose\" fixpoint mechanism that allows values of inductively defined weight functions to be overwritten. We propose a \"scalar\" restriction of functional fixpoint logic, of polynomial-time data complexity, and show it can express all PTIME model-agnostic queries over reduced networks with polynomially bounded weights. In contrast, we show that very simple model-agnostic queries are already NP-complete. Finally, we consider transformations of weighted structures by iterated transductions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7528\u4e8e\u52a0\u6743\u7ed3\u6784\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u7684\u903b\u8f91\u67e5\u8be2\u8bed\u8a00\uff0c\u63d0\u51fa\u57fa\u4e8e\u51fd\u6570\u4e0d\u52a8\u70b9\u7684\u903b\u8f91\u673a\u5236\uff0c\u5206\u6790\u5176\u8ba1\u7b97\u590d\u6742\u6027\u548c\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u4e3a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662f\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff09\u63d0\u4f9b\u8868\u8fbe\u6027\u67e5\u8be2\u8bed\u8a00\uff0c\u5c06\u6a21\u578b\u89c6\u4e3a\u6709\u610f\u56fe\u7684\u6570\u636e\uff0c\u901a\u8fc7\u58f0\u660e\u5f0f\u8bed\u8a00\u5b9e\u73b0\u6a21\u578b\u7684\u9a8c\u8bc1\u548c\u89e3\u91ca\uff0c\u4f7f\u5b66\u4e60\u5230\u7684\u6570\u636e\u8868\u793a\u66f4\u6613\u4e8e\u8bbf\u95ee\u3002", "method": "\u91c7\u7528Gr\u00e4del\u548cGurevich\u63d0\u51fa\u7684\u51fd\u6570\u4e0d\u52a8\u70b9\u673a\u5236\uff0c\u4f7f\u7528\u7c7b\u4f3cDatalog\u7684\u8bed\u6cd5\uff0c\u6269\u5c55\u52a0\u6743\u7ed3\u6784\u7684\u4e0d\u52a8\u70b9\u903b\u8f91\u8303\u5f0f\uff0c\u63d0\u51fa\"\u677e\u6563\"\u4e0d\u52a8\u70b9\u673a\u5236\u5141\u8bb8\u8986\u76d6\u5f52\u7eb3\u5b9a\u4e49\u7684\u6743\u91cd\u51fd\u6570\u503c\uff0c\u5e76\u5f15\u5165\"\u6807\u91cf\"\u9650\u5236\u7684\u529f\u80fd\u4e0d\u52a8\u70b9\u903b\u8f91\u3002", "result": "\u8bc1\u660e\u4e86\u6807\u91cf\u9650\u5236\u7684\u529f\u80fd\u4e0d\u52a8\u70b9\u903b\u8f91\u5177\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u6570\u636e\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u8868\u8fbe\u6240\u6709PTIME\u6a21\u578b\u65e0\u5173\u67e5\u8be2\uff08\u5728\u6743\u91cd\u591a\u9879\u5f0f\u6709\u754c\u7684\u7b80\u5316\u7f51\u7edc\u4e0a\uff09\u3002\u540c\u65f6\u53d1\u73b0\u975e\u5e38\u7b80\u5355\u7684\u6a21\u578b\u65e0\u5173\u67e5\u8be2\u5df2\u7ecf\u662fNP\u5b8c\u5168\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u52a0\u6743\u7ed3\u6784\u7684\u8fed\u4ee3\u8f6c\u6362\u8003\u8651\u7ed3\u6784\u53d8\u6362\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u903b\u8f91\u67e5\u8be2\u6846\u67b6\uff0c\u5e73\u8861\u4e86\u8868\u8fbe\u80fd\u529b\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2601.02410", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.02410", "abs": "https://arxiv.org/abs/2601.02410", "authors": ["Aizierjiang Aiersilan"], "title": "The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming", "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \\textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \\textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \\textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \\textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \\textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVibe-Check Protocol (VCP)\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u91cf\u5316\u6307\u6807\u8bc4\u4f30Vibe Coding\uff08AI\u8f85\u52a9\u7f16\u7a0b\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u6548\u679c\uff0c\u65e8\u5728\u786e\u5b9a\u5176\u6700\u4f73\u6559\u5b66\u8fb9\u754c\u3002", "motivation": "\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u6574\u5408\uff0c\u51fa\u73b0\u4e86\"Vibe Coding\"\u8303\u5f0f\uff0c\u5373\u5f00\u53d1\u8005\u7528\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u9ad8\u5c42\u610f\u56fe\uff0c\u7531AI\u4ee3\u7406\u5b9e\u73b0\u4ee3\u7801\u3002\u867d\u7136\u652f\u6301\u8005\u8ba4\u4e3a\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u5f3a\u8c03\u6982\u5ff5\u8bbe\u8ba1\u800c\u975e\u8bed\u6cd5\u8bb0\u5fc6\u6765\u73b0\u4ee3\u5316\u6559\u5b66\uff0c\u4f46\u79ef\u7d2f\u7684\u5b9e\u8bc1\u8bc1\u636e\u5f15\u53d1\u4e86\u5bf9\u6280\u80fd\u4fdd\u6301\u548c\u6df1\u5ea6\u6982\u5ff5\u7406\u89e3\u7684\u62c5\u5fe7\u3002", "method": "\u63d0\u51faVibe-Check Protocol (VCP)\u7cfb\u7edf\u5316\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u91cf\u5316\u6307\u6807\uff1a1) Cold Start Refactor (M_CSR)\u7528\u4e8e\u5efa\u6a21\u6280\u80fd\u8870\u51cf\uff1b2) Hallucination Trap Detection (M_HT)\u57fa\u4e8e\u4fe1\u53f7\u68c0\u6d4b\u7406\u8bba\u8bc4\u4f30\u9519\u8bef\u8bc6\u522b\u80fd\u529b\uff1b3) Explainability Gap (E_gap)\u7528\u4e8e\u91cf\u5316\u4ee3\u7801\u590d\u6742\u6027\u4e0e\u6982\u5ff5\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u901a\u8fc7\u53d7\u63a7\u6bd4\u8f83\uff0cVCP\u65e8\u5728\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u91cf\u5316\u57fa\u7840\uff0c\u4ee5\u786e\u5b9a\u6700\u4f73\u6559\u5b66\u8fb9\u754c\uff1a\u8bc6\u522bVibe Coding\u4fc3\u8fdb\u771f\u6b63\u638c\u63e1\u7684\u4e0a\u4e0b\u6587\uff0c\u4ee5\u53ca\u5f15\u5165\u9690\u85cf\u6280\u672f\u503a\u52a1\u548c\u8868\u9762\u80fd\u529b\u7684\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u6765\u7814\u7a76Vibe Coding\u662f\u5426\u662f\u5b66\u4e60\u8f6f\u4ef6\u5de5\u7a0b\u7684\u66f4\u597d\u65b9\u5f0f\uff0c\u533a\u5206\u5b66\u751f\u5229\u7528AI\u8fdb\u884c\u52a0\u901f\u4e0e\u8ba4\u77e5\u5378\u8f7d\u7684\u4e0d\u540c\u7ed3\u679c\uff0c\u901a\u8fc7VCP\u8bc4\u4f30\u8fd9\u4e9b\u6559\u80b2\u6743\u8861\u3002"}}
{"id": "2601.02421", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02421", "abs": "https://arxiv.org/abs/2601.02421", "authors": ["Nyan Lin Zaw"], "title": "Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams", "comment": "26 pages, 0 figure. Mixed-methods study examining factors contributing to successful product design teams with emerging professionals. Submitted to Southern States Communication Association", "summary": "This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.", "AI": {"tldr": "\u7814\u7a76\u5e74\u8f7b\u4e13\u4e1a\u4eba\u58eb\uff0818-27\u5c81\uff09\u4ea7\u54c1\u56e2\u961f\u7684\u6210\u529f\u56e0\u7d20\uff0c\u53d1\u73b0\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u63a5\u8fd1\u3001\u6587\u6863\u8bb0\u5f55\u548c\u8d44\u6e90\u83b7\u53d6\u7b49\u65b0\u56e0\u7d20\u5bf9\u56e2\u961f\u751f\u4ea7\u529b\u6709\u91cd\u8981\u5f71\u54cd", "motivation": "\u73b0\u6709\u7ec4\u7ec7\u6c9f\u901a\u7814\u7a76\u4e3b\u8981\u5173\u6ce827\u5c81\u4ee5\u4e0a\u3001\u67095\u5e74\u4ee5\u4e0a\u7ecf\u9a8c\u7684\u6210\u719f\u4e13\u4e1a\u4eba\u58eb\uff0c\u7f3a\u4e4f\u5bf9\u5e74\u8f7b\u65b0\u5174\u4e13\u4e1a\u4eba\u58eb\uff0818-27\u5c81\uff09\u4ea7\u54c1\u56e2\u961f\u7684\u7814\u7a76\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u6587\u732e\u7a7a\u767d", "method": "\u7814\u7a76\u5e74\u8f7b\u4ea7\u54c1\u56e2\u961f\uff08\u6210\u5458\u5e74\u9f8418-27\u5c81\uff09\uff0c\u63a2\u7d22\u5f71\u54cd\u5176\u6210\u529f\u7684\u56e0\u7d20\uff0c\u57fa\u4e8e\u56e2\u961f\u5f00\u53d1\u4ea7\u54c1\u7684\u6210\u529f\u7387\u6765\u8bc4\u4f30\u56e2\u961f\u751f\u4ea7\u529b", "result": "\u53d1\u73b0\u4e00\u4e9b\u4f20\u7edf\u56e0\u7d20\u4ecd\u7136\u9002\u7528\uff0c\u4f46\u6709\u4e9b\u53d8\u5f97\u4e0d\u90a3\u4e48\u76f8\u5173\uff0c\u540c\u65f6\u8bc6\u522b\u51fa\u65b0\u7684\u5173\u952e\u56e0\u7d20\uff1a\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u63a5\u8fd1\u3001\u6587\u6863\u8bb0\u5f55\u548c\u8d44\u6e90\u83b7\u53d6", "conclusion": "\u8fd9\u9879\u7814\u7a76\u586b\u8865\u4e86\u5173\u4e8e\u5e74\u8f7b\u4e13\u4e1a\u4eba\u58eb\u56e2\u961f\u5982\u4f55\u88ab\u65b0\u56e0\u7d20\u5851\u9020\u7684\u6587\u732e\u7a7a\u767d\uff0c\u4e3a\u7406\u89e3\u65b0\u5174\u4e13\u4e1a\u4eba\u58eb\u56e2\u961f\u7684\u6210\u529f\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2601.02430", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02430", "abs": "https://arxiv.org/abs/2601.02430", "authors": ["Chenxu Liu", "Yingjie Fu", "Wei Yang", "Ying Zhang", "Tao Xie"], "title": "WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics", "comment": null, "summary": "Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.", "AI": {"tldr": "WebCoderBench\uff1a\u9996\u4e2a\u771f\u5b9e\u7528\u6237\u9700\u6c42\u6536\u96c6\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u7f51\u9875\u5e94\u7528\u751f\u6210\u57fa\u51c6\uff0c\u5305\u542b1572\u4e2a\u771f\u5b9e\u7528\u6237\u9700\u6c42\uff0c24\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\uff0c\u8986\u76d69\u4e2a\u7ef4\u5ea6\uff0c\u652f\u6301\u5168\u81ea\u52a8\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524dLLM\u5728\u7f51\u9875\u5e94\u7528\u4ee3\u7801\u751f\u6210\u9886\u57df\u7f3a\u4e4f\u6709\u6548\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u9700\u8981\u771f\u5b9e\u7528\u6237\u9700\u6c42\u3001\u4e0d\u4f9d\u8d56\u53c2\u8003\u5b9e\u73b0\u6216\u6d4b\u8bd5\u7528\u4f8b\u7684\u53ef\u6cdb\u5316\u8bc4\u4f30\u6307\u6807\u3001\u4ee5\u53ca\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u7ed3\u679c\u3002", "method": "\u6536\u96c61572\u4e2a\u771f\u5b9e\u7528\u6237\u9700\u6c42\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u6001\u548c\u8868\u8fbe\u98ce\u683c\uff1b\u8bbe\u8ba124\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\u8986\u76d69\u4e2a\u7ef4\u5ea6\uff1b\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bc4\u4f30\u8303\u5f0f\uff1b\u91c7\u7528\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6307\u6807\u6743\u91cd\u6765\u83b7\u5f97\u53ef\u89e3\u91ca\u7684\u7efc\u5408\u8bc4\u5206\u3002", "result": "\u572812\u4e2a\u4ee3\u8868\u6027LLM\u548c2\u4e2aLLM\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6ca1\u6709\u6a21\u578b\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u8fd9\u4e3aLLM\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u9488\u5bf9\u6027\u4f18\u5316\u7684\u673a\u4f1a\u3002", "conclusion": "WebCoderBench\u586b\u8865\u4e86\u7f51\u9875\u5e94\u7528\u751f\u6210\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u771f\u5b9e\u3001\u53ef\u6cdb\u5316\u3001\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8LLM\u5728\u7f51\u9875\u5e94\u7528\u5f00\u53d1\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2601.02438", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02438", "abs": "https://arxiv.org/abs/2601.02438", "authors": ["Yun Bian", "Yi Chen", "HaiQuan Wang", "ShiHao Li", "Zhe Cui"], "title": "Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection", "comment": null, "summary": "Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.", "AI": {"tldr": "\u63d0\u51faTaCCS-DFA\u6846\u67b6\uff0c\u901a\u8fc7Fisher\u4fe1\u606f\u5ea6\u91cf\u7279\u5f81\u65b9\u5411\u5bf9\u5206\u7c7b\u51b3\u7b56\u7684\u654f\u611f\u6027\uff0c\u5b9e\u73b0\u4efb\u52a1\u5bfc\u5411\u7684\u4e92\u8865\u878d\u5408\uff0c\u63d0\u5347\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u901a\u5e38\u878d\u5408\u81ea\u7136\u4ee3\u7801\u5e8f\u5217\u548c\u4ee3\u7801\u5c5e\u6027\u56fe\u8868\u793a\uff0c\u4f46\u9690\u542b\u5047\u8bbe\u6dfb\u52a0\u6a21\u6001\u5fc5\u7136\u5e26\u6765\u989d\u5916\u4fe1\u606f\u3002\u5b9e\u9645\u4e0a\u5e8f\u5217\u548c\u56fe\u8868\u793a\u53ef\u80fd\u5b58\u5728\u5197\u4f59\uff0c\u4e14\u56fe\u6a21\u6001\u8d28\u91cf\u6ce2\u52a8\u53ef\u80fd\u7a00\u91ca\u4e3b\u5bfc\u6a21\u6001\u7684\u5224\u522b\u4fe1\u53f7\u3002", "method": "\u63d0\u51faTaCCS-DFA\u6846\u67b6\uff1a1) \u5f15\u5165Fisher\u4fe1\u606f\u4f5c\u4e3a\u51e0\u4f55\u5ea6\u91cf\uff0c\u8bc4\u4f30\u7279\u5f81\u65b9\u5411\u5bf9\u5206\u7c7b\u51b3\u7b56\u7684\u654f\u611f\u6027\uff1b2) \u5728\u7ebf\u4f30\u8ba1\u4f4e\u79e9\u4e3bFisher\u5b50\u7a7a\u95f4\uff0c\u5c06\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u9650\u5236\u5728\u4efb\u52a1\u654f\u611f\u65b9\u5411\uff1b3) \u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u52a8\u6001\u8c03\u6574\u6bcf\u4e2a\u6837\u672c\u7684\u56fe\u6a21\u6001\u8d21\u732e\u4ee5\u6291\u5236\u566a\u58f0\u4f20\u64ad\u3002", "result": "\u5728BigVul\u3001Devign\u548cReVeal\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u4f7f\u7528CodeT5\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\u65f6\uff0c\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684BigVul\u6570\u636e\u96c6\u4e0a\u8fbe\u523087.80%\u7684F1\u5206\u6570\uff0c\u6bd4\u5f3a\u57fa\u7ebfVul-LMGNNs\u63d0\u53476.3\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u6821\u51c6\u8bef\u5dee\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "TaCCS-DFA\u901a\u8fc7\u4efb\u52a1\u5bfc\u5411\u7684\u4e92\u8865\u878d\u5408\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u8868\u793a\u4e2d\u7684\u5197\u4f59\u548c\u566a\u58f0\u95ee\u9898\uff0c\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u5176\u98ce\u9669\u754c\u9650\u4f18\u4e8e\u4f20\u7edf\u5168\u8c31\u6ce8\u610f\u529b\u65b9\u6cd5\u3002"}}
{"id": "2601.02454", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02454", "abs": "https://arxiv.org/abs/2601.02454", "authors": ["Saba Naqvi", "Mohammad Baqar", "Nawaz Ali Mohammad"], "title": "The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance", "comment": "11 Pages", "summary": "Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u95ed\u73af\u81ea\u6821\u6b63\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u751f\u6210\u3001\u6267\u884c\u5206\u6790\u548c\u4f18\u5316\u8bc4\u5ba1\u4e09\u4e2a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u5229\u7528\u6c99\u7bb1\u6267\u884c\u548c\u8fed\u4ee3\u4fee\u590d\uff0c\u663e\u8457\u51cf\u5c11\u65e0\u6548\u6d4b\u8bd5\u5e76\u63d0\u5347\u8986\u76d6\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eAI\u7684\u6d4b\u8bd5\u751f\u6210\u5668\u5b58\u5728\u9759\u6001\u3001\u5355\u6b21\u8f93\u51fa\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u6267\u884c\u611f\u77e5\u53cd\u9988\uff0c\u5bfc\u81f4\u4ea7\u751f\u5927\u91cf\u65e0\u6548\u3001\u5197\u4f59\u6216\u4e0d\u53ef\u6267\u884c\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u6d4b\u8bd5\u751f\u6210\u667a\u80fd\u4f53\u3001\u6267\u884c\u5206\u6790\u667a\u80fd\u4f53\u548c\u8bc4\u5ba1\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6c99\u7bb1\u6267\u884c\u3001\u8be6\u7ec6\u5931\u8d25\u62a5\u544a\u548c\u8fed\u4ee3\u4fee\u590d\u673a\u5236\uff0c\u5f62\u6210\u95ed\u73af\u81ea\u6821\u6b63\u7cfb\u7edf\uff0c\u5e76\u4e0eCI/CD\u7ba1\u9053\u96c6\u6210\u3002", "result": "\u5728\u5fae\u670d\u52a1\u5e94\u7528\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff1a\u65e0\u6548\u6d4b\u8bd5\u51cf\u5c1160%\uff0c\u8986\u76d6\u7387\u63d0\u534730%\uff0c\u4eba\u5de5\u5de5\u4f5c\u91cf\u663e\u8457\u964d\u4f4e\uff0c\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u3001\u53cd\u9988\u9a71\u52a8\u7684\u95ed\u73af\u7cfb\u7edf\u53ef\u4ee5\u5c06\u8f6f\u4ef6\u6d4b\u8bd5\u6f14\u53d8\u4e3a\u81ea\u4e3b\u3001\u6301\u7eed\u5b66\u4e60\u7684\u8d28\u91cf\u4fdd\u8bc1\u751f\u6001\u7cfb\u7edf\uff0c\u5b9e\u73b0\u81ea\u4fee\u590d\u3001\u9ad8\u53ef\u9760\u6027\u7684\u4ee3\u7801\u5e93\u3002"}}
{"id": "2601.02504", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.02504", "abs": "https://arxiv.org/abs/2601.02504", "authors": ["Elizaveta Artser", "Daniil Karol", "Anna Potriasaeva", "Aleksei Rostovskii", "Katsiaryna Dzialets", "Ekaterina Koshchenko", "Xiaotian Su", "April Yi Wang", "Anastasiia Birillo"], "title": "Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support", "comment": "Accepted at ICSE SEET 2026, 6 pages, 2 figures", "summary": "Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.", "AI": {"tldr": "AI\u9a71\u52a8\u7684IDE\u8c03\u8bd5\u52a9\u624b\uff0c\u901a\u8fc7RAG\u3001\u7a0b\u5e8f\u5207\u7247\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u5b9e\u65f6\u8c03\u8bd5\u652f\u6301\uff0c\u51cf\u5c11LLM\u8c03\u7528\u5e76\u63d0\u9ad8\u51c6\u786e\u6027", "motivation": "\u8c03\u8bd5\u662f\u7f16\u7a0b\u6559\u80b2\u548c\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u6280\u80fd\uff0c\u4f46\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u7ecf\u5e38\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u5de5\u5177\u6765\u652f\u6301\u8c03\u8bd5\u6559\u5b66\u548c\u5b9e\u8df5", "method": "\u96c6\u6210\u5230IDE\u4e2d\u7684AI\u8c03\u8bd5\u52a9\u624b\uff0c\u4f7f\u7528RAG\u4e0eLLMs\u3001\u7a0b\u5e8f\u5207\u7247\u548c\u81ea\u5b9a\u4e49\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5206\u6790\u4ee3\u7801\u3001\u5efa\u8bae\u65ad\u70b9\u5e76\u63d0\u4f9b\u4e0a\u4e0b\u6587\u63d0\u793a", "result": "\u901a\u8fc7\u4e09\u7ea7\u8bc4\u4f30\uff08\u6280\u672f\u5206\u6790\u3001\u7528\u6237\u4f53\u9a8c\u7814\u7a76\u548c\u8bfe\u5802\u6d4b\u8bd5\uff09\u663e\u793a\u5176\u5728\u6559\u5b66\u8c03\u8bd5\u65b9\u9762\u7684\u6f5c\u529b", "conclusion": "AI\u9a71\u52a8\u7684\u8c03\u8bd5\u52a9\u624b\u6709\u6f5c\u529b\u6539\u5584\u8c03\u8bd5\u6559\u5b66\uff0c\u901a\u8fc7\u51cf\u5c11LLM\u8c03\u7528\u63d0\u9ad8\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u591a\u7ea7\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027"}}
{"id": "2601.02512", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02512", "abs": "https://arxiv.org/abs/2601.02512", "authors": ["Pelin Rabia Kuran", "Rumbidzai Chitakunye", "Vincenzo Stoico", "Ilja Heitlager", "Justus Bogner"], "title": "Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP'26)", "summary": "The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.\n  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u56db\u79cd\u4f18\u5316\u6280\u672f\u5728\u5de5\u4e1aLLM\u5e94\u7528\u4e2d\u7684\u80fd\u8017\u6548\u679c\uff0c\u53d1\u73b0Prompt\u4f18\u5316\u548c2-bit\u91cf\u5316\u53ef\u663e\u8457\u964d\u4f4e\u80fd\u8017\u4f46\u635f\u5bb3\u51c6\u786e\u6027\uff0c\u800c\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u662f\u552f\u4e00\u80fd\u663e\u8457\u8282\u80fd\u4e14\u4e0d\u4e25\u91cd\u635f\u5bb3\u5176\u4ed6\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72\u65f6\u80fd\u8017\u5de8\u5927\uff0c\u4f46\u73b0\u6709\u4f18\u5316\u6280\u672f\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5206\u6790\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5bf9\u5de5\u4e1aLLM\u5e94\u7528\u7684\u80fd\u8017\u3001\u51c6\u786e\u6027\u548c\u54cd\u5e94\u65f6\u95f4\u7684\u5f71\u54cd\u3002", "method": "\u9009\u53d6\u8377\u5170IT\u670d\u52a1\u516c\u53f8Schuberg Philis\u7684\u804a\u5929\u673a\u5668\u4eba\u5e94\u7528\u4f5c\u4e3a\u6848\u4f8b\uff0c\u5e94\u7528\u56db\u79cd\u4f18\u5316\u6280\u672f\uff08\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u3001\u63d0\u793a\u4f18\u5316\u3001\u91cf\u5316\u3001\u6279\u5904\u7406\uff09\u7684\u516b\u79cd\u53d8\u4f53\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u5b83\u4eec\u4e0e\u672a\u4f18\u5316\u57fa\u7ebf\u7684\u80fd\u8017\u3001\u51c6\u786e\u6027\u548c\u54cd\u5e94\u65f6\u95f4\u8868\u73b0\u3002", "result": "\u63d0\u793a\u4f18\u5316\u548c2-bit\u91cf\u5316\u7b49\u6280\u672f\u53ef\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff08\u6700\u9ad8\u8fbe90%\uff09\uff0c\u4f46\u4e25\u91cd\u635f\u5bb3\u51c6\u786e\u6027\u5230\u4e0d\u53ef\u63a5\u53d7\u7684\u7a0b\u5ea6\u3002\u53ea\u6709\u4f7f\u7528Nvidia Prompt Task and Complexity Classifier\uff08NPCC\uff09\u7684\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u6280\u672f\u80fd\u5728\u663e\u8457\u964d\u4f4e\u80fd\u8017\u7684\u540c\u65f6\uff0c\u4e0d\u4e25\u91cd\u635f\u5bb3\u5176\u4ed6\u8d28\u91cf\u6307\u6807\u3002", "conclusion": "\u964d\u4f4eLLM\u5e94\u7528\u7684\u80fd\u8017\u5728\u5b9e\u8df5\u4e2d\u5e76\u4e0d\u56f0\u96be\uff0c\u4f46\u5b9e\u73b0\u80fd\u6548\u63d0\u5347\uff08\u5373\u5728\u4e0d\u635f\u5bb3\u5176\u4ed6\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u80fd\u8017\uff09\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u5927\u5c0f\u6a21\u578b\u534f\u4f5c\u662f\u5f53\u524d\u6700\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u672c\u7814\u7a76\u4e3a\u5de5\u4e1a\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2601.02522", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02522", "abs": "https://arxiv.org/abs/2601.02522", "authors": ["Zhinuan", "Guo", "Chushu Gao", "Justus Bogner"], "title": "On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS'26)", "summary": "The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.\n  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e94\u79cd\u964d\u4f4eRAG\u7cfb\u7edf\u80fd\u8017\u7684\u6280\u672f\uff0c\u53d1\u73b0\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u68c0\u7d22\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u80fd\u5728\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\uff0c\u800c\u5176\u4ed6\u6280\u672f\u5219\u53ef\u80fd\u5bfc\u81f4\u51c6\u786e\u6027\u5927\u5e45\u4e0b\u964d\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\uff08\u7279\u522b\u662fRAG\u7cfb\u7edf\uff09\u7684\u80fd\u6e90\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u5f15\u53d1\u4e86\u5bf9\u5176\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u62c5\u5fe7\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63d0\u51fa\u4e86\u7eff\u8272ML\u6280\u672f\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u5b9e\u8bc1\u8bc4\u4f30\u4ecd\u5f88\u7f3a\u4e4f\u3002", "method": "\u5728\u5408\u4f5c\u65b9Software Improvement Group\u5f00\u53d1\u7684\u751f\u4ea7\u7ea7RAG\u7cfb\u7edf\u4e0a\u8fdb\u884c\u63a7\u5236\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u8282\u80fd\u6280\u672f\u5bf9\u80fd\u8017\u3001\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002\u4f7f\u7528CRAG\u6570\u636e\u96c6\u8fdb\u884c\u4e869\u79cd\u914d\u7f6e\u3001\u8d85\u8fc7200\u5c0f\u65f6\u7684\u8bd5\u9a8c\u3002", "result": "\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u68c0\u7d22\u9608\u503c\u3001\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u3001\u5e94\u7528\u5411\u91cf\u7d22\u5f15\u548c\u4f7f\u7528BM25S\u91cd\u6392\u5e8f\u7b49\u6280\u672f\u53ef\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff08\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8fbe60%\uff09\u3002\u4f46\u7d22\u5f15\u7b56\u7565\u7b49\u6280\u672f\u53ef\u80fd\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u8fbe30%\u3002\u6700\u4f18\u68c0\u7d22\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u80fd\u5728\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5173\u4e8eRAG\u7cfb\u7edf\u8282\u80fd\u8bbe\u8ba1\u6280\u672f\u7684\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u53ef\u6301\u7eedRAG\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u67d0\u4e9b\u6280\u672f\u80fd\u5b9e\u73b0\u771f\u6b63\u7684\u80fd\u6e90\u6548\u7387\uff0c\u800c\u5176\u4ed6\u6280\u672f\u5219\u9700\u8981\u6743\u8861\u51c6\u786e\u6027\u3002"}}
{"id": "2601.02559", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.02559", "abs": "https://arxiv.org/abs/2601.02559", "authors": ["Lauren Olson", "Emitz\u00e1 Guzm\u00e1n", "Florian Kunneman"], "title": "PerspectiveCoach: Exploring LLMs for Developer Reflection", "comment": "48th International Conference of Software Engineering", "summary": "Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.", "AI": {"tldr": "PerspectiveCoach\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c6\u89d2\u8bad\u7ec3\u5e2e\u52a9\u5f00\u53d1\u8005\u53cd\u601d\u8f6f\u4ef6\u8bbe\u8ba1\u5bf9\u8fb9\u7f18\u5316\u793e\u533a\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u8868\u660e\u8be5\u5de5\u5177\u80fd\u63d0\u5347\u81ea\u6211\u610f\u8bc6\u3001\u62d3\u5bbd\u89c6\u89d2\u5e76\u6539\u5584\u4f26\u7406\u63a8\u7406\u3002", "motivation": "\u5c3d\u7ba1\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f26\u7406\u6311\u6218\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u4ece\u4e1a\u8005\u4ecd\u7f3a\u4e4f\u7ed3\u6784\u5316\u5de5\u5177\u6765\u6279\u5224\u6027\u5730\u53c2\u4e0e\u8fb9\u7f18\u5316\u7528\u6237\u7684\u771f\u5b9e\u4f53\u9a8c\u3002\u9700\u8981\u4e00\u79cd\u5de5\u5177\u6765\u5e2e\u52a9\u5f00\u53d1\u8005\u6df1\u5165\u53cd\u601d\u8f6f\u4ef6\u8bbe\u8ba1\u51b3\u7b56\u5982\u4f55\u5f71\u54cd\u8fb9\u7f18\u5316\u793e\u533a\u3002", "method": "\u5f00\u53d1\u4e86PerspectiveCoach\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89c6\u89d2\u8bad\u7ec3\u5f15\u5bfc\u5f00\u53d1\u8005\u3002\u5bf918\u540d\u524d\u7aef\u5f00\u53d1\u8005\uff08\u6027\u522b\u5e73\u8861\uff09\u8fdb\u884c\u4e86\u5bf9\u7167\u7814\u7a76\uff0c\u4f7f\u7528\u5728\u7ebf\u6027\u522b\u9a9a\u6270\u7684\u771f\u5b9e\u6848\u4f8b\u3002\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u3001\u6587\u672c\u76f8\u4f3c\u6027\u5206\u6790\u548c\u8865\u5145\u7684\u4eba\u4e0e\u4eba\u7814\u7a76\u6765\u8bc4\u4f30\u5de5\u5177\u6548\u679c\u3002", "result": "\u5b9a\u6027\u5206\u6790\u663e\u793a\uff1a\u81ea\u6211\u610f\u8bc6\u589e\u5f3a\u3001\u89c6\u89d2\u62d3\u5bbd\u3001\u4f26\u7406\u8868\u8fbe\u66f4\u7ec6\u81f4\u3002\u6587\u672c\u76f8\u4f3c\u6027\u5206\u6790\u8868\u660e\uff0c\u53c2\u4e0e\u8005\u901a\u8fc7\u591a\u6b21\u5c1d\u8bd5\u63d0\u9ad8\u4e86\u91cd\u8ff0\u7684\u51c6\u786e\u6027\uff0c\u80fd\u6355\u6349\u7528\u6237\u5173\u6ce8\u70b9\u7684\u8868\u9762\u548c\u8bed\u4e49\u5c42\u9762\u3002\u4f46\u4eba-\u5de5\u5177\u5bf9\u8bdd\u7684\u91cd\u8ff0\u57fa\u7ebf\u4f4e\u4e8e\u4eba\u4e0e\u4eba\u5bf9\u8bdd\u3002\u53c2\u4e0e\u8005\u5bf9\u5de5\u5177\u7684\u53ef\u7528\u6027\u548c\u76f8\u5173\u6027\u8bc4\u4ef7\u5f88\u9ad8\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec8\u7aef\u7528\u6237\u89c6\u89d2\u8bad\u7ec3\u63d0\u4f9b\u4e86\u63a2\u7d22\u6027\u8bbe\u8ba1\uff0c\u652f\u6301\u6279\u5224\u6027\u4f26\u7406\u81ea\u6211\u53cd\u601d\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u89c1\u89e3\uff08\u5982\u589e\u5f3a\u9002\u5e94\u6027\u3001\u5173\u6ce8\u591a\u5143\u6027\uff09\uff0c\u8868\u660e\u6b64\u7c7b\u5de5\u5177\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u6784\u5efa\u66f4\u5177\u5305\u5bb9\u6027\u548c\u793e\u4f1a\u54cd\u5e94\u6027\u7684\u6280\u672f\u3002"}}
{"id": "2601.02601", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02601", "abs": "https://arxiv.org/abs/2601.02601", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "State of the Quantum Software Engineering Ecosystem", "comment": null, "summary": "We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.", "AI": {"tldr": "\u4f7f\u7528GPT-5\u5206\u6790\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u751f\u6001\u7cfb\u7edf\u73b0\u72b6\uff0c\u8bc6\u522b\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u4e2d\u6d3b\u8dc3\u4e14\u6709\u6210\u5c31\u7684\u673a\u6784\u4e0e\u516c\u53f8", "motivation": "\u7814\u7a76\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u751f\u6001\u7cfb\u7edf\u7684\u5f53\u524d\u72b6\u6001\uff0c\u7279\u522b\u5173\u6ce8\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u6210\u5c31\u3001\u6d3b\u52a8\u4e0e\u53c2\u4e0e\uff0c\u91cd\u70b9\u5173\u6ce8\u8be5\u9886\u57df\u6210\u529f\u7684\u521b\u4e1a\u4f01\u4e1a", "method": "\u91c7\u7528\u65b0\u9896\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u5229\u7528\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u667a\u80fd\u6280\u672f\u2014\u2014\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u7279\u522b\u662fGPT-5\uff09\uff0c\u901a\u8fc7ChatGPT\u5de5\u5177\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u5728QSE\u9886\u57df\u6d3b\u8dc3\u4e14\u6709\u663e\u8457\u6210\u679c\u7684\u673a\u6784\u548c\u516c\u53f8", "result": "\u8bc6\u522b\u51fa\u5728\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u9ad8\u5ea6\u6d3b\u8dc3\u4e14\u53d6\u5f97\u6770\u51fa\u6210\u679c\u7684\u673a\u6784\u548c\u516c\u53f8\uff0c\u8fd9\u4e9b\u6210\u679c\u901a\u8fc7\u540c\u884c\u8bc4\u5ba1\u51fa\u7248\u7269\u6216\u5728\u98ce\u9669\u8d44\u672c\u5e02\u573a\u7b79\u96c6\u8d44\u91d1\u5f97\u5230\u8bc1\u660e", "conclusion": "\u5c55\u793a\u4e86\u5229\u7528\u5148\u8fdbAI\u6280\u672f\u5206\u6790\u65b0\u5174\u6280\u672f\u751f\u6001\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u7814\u7a76\u548c\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003"}}
{"id": "2601.02632", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02632", "abs": "https://arxiv.org/abs/2601.02632", "authors": ["Alireza Ezaz", "Ghazal Khodabandeh", "Majid Babaei", "Naser Ezzati-Jivan"], "title": "TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs", "comment": "Accepted to ICSE 2026. DOI 10.1145/3744916.3787832", "summary": "Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.", "AI": {"tldr": "TAAF\u6846\u67b6\u7ed3\u5408\u65f6\u95f4\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\u548cLLM\uff0c\u5c06\u539f\u59cb\u6267\u884c\u8f68\u8ff9\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5206\u6790\u590d\u6742\u7cfb\u7edf\u8f68\u8ff9\uff0c\u5728TraceQA-100\u57fa\u51c6\u4e0a\u63d0\u5347\u51c6\u786e\u738731.2%", "motivation": "\u64cd\u4f5c\u7cfb\u7edf\u5185\u6838\u6216\u5927\u578b\u5e94\u7528\uff08\u5982Chrome\u3001MySQL\uff09\u7684\u6267\u884c\u8f68\u8ff9\u6570\u636e\u91cf\u5de8\u5927\u4e14\u96be\u4ee5\u5206\u6790\u3002\u73b0\u6709\u5de5\u5177\u4f9d\u8d56\u9884\u5b9a\u4e49\u5206\u6790\uff0c\u5b9a\u5236\u5316\u6d1e\u5bdf\u9700\u8981\u7f16\u5199\u6613\u9519\u8017\u65f6\u7684\u9886\u57df\u7279\u5b9a\u811a\u672c\uff0c\u7f3a\u4e4f\u7075\u6d3b\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u80fd\u529b\u3002", "method": "\u63d0\u51faTAAF\u6846\u67b6\uff1a1\uff09\u4ece\u8f68\u8ff9\u4e8b\u4ef6\u6784\u5efa\u65f6\u95f4\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\uff0c\u6355\u6349\u7ebf\u7a0b\u3001CPU\u3001\u7cfb\u7edf\u8d44\u6e90\u7b49\u5b9e\u4f53\u5173\u7cfb\uff1b2\uff09\u4f7f\u7528LLM\u89e3\u91ca\u67e5\u8be2\u7279\u5b9a\u5b50\u56fe\uff0c\u56de\u7b54\u81ea\u7136\u8bed\u8a00\u95ee\u9898\uff0c\u51cf\u5c11\u4eba\u5de5\u68c0\u67e5\u548c\u6df1\u5ea6\u7cfb\u7edf\u4e13\u4e1a\u77e5\u8bc6\u9700\u6c42\u3002", "result": "\u5728TraceQA-100\u57fa\u51c6\uff08\u57fa\u4e8e\u771f\u5b9e\u5185\u6838\u8f68\u8ff9\u7684100\u4e2a\u95ee\u9898\uff09\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u6db5\u76d63\u4e2aLLM\u548c\u591a\u79cd\u65f6\u95f4\u8bbe\u7f6e\uff0cTAAF\u5c06\u7b54\u6848\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe31.2%\uff0c\u5728\u591a\u8df3\u548c\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "TAAF\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u548cLLM\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8f68\u8ff9\u5206\u6790\u5de5\u5177\u5960\u5b9a\u57fa\u7840\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u7cfb\u7edf\u8f68\u8ff9\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6613\u7528\u6027\uff0c\u540c\u65f6\u5206\u6790\u4e86\u56fe\u8c31\u57fa\u7840\u63a8\u7406\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2601.02698", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02698", "abs": "https://arxiv.org/abs/2601.02698", "authors": ["Manideep Reddy Chinthareddy"], "title": "Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study", "comment": "11 pages, 3 Figures", "summary": "AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06OAuth 2.0\u548cOpenID Connect\u96c6\u6210\u5230MCP\u5f00\u53d1\u8005\u73af\u5883\u4e2d\u7684\u4f01\u4e1a\u7ea7\u8eab\u4efd\u9a8c\u8bc1\u67b6\u6784\uff0c\u89e3\u51b3\u4e86AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u8eab\u4efd\u7ba1\u7406\u548c\u8bbf\u95ee\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u4f01\u4e1a\u9700\u8981\u5728AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u4e2d\u786e\u4fdd\u8eab\u4efd\u9a8c\u8bc1\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u6cbb\u7406\u8981\u6c42\uff0c\u4f46\u73b0\u6709\u7684Model Context Protocol (MCP)\u89c4\u8303\u4ec5\u63d0\u4f9b\u6700\u5c0f\u6388\u6743\u6a21\u578b\uff0c\u7f3a\u4e4f\u4f01\u4e1a\u5355\u70b9\u767b\u5f55(SSO)\u96c6\u6210\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u67b6\u6784\uff0c\u5c06OAuth 2.0\u548cOpenID Connect\u96c6\u6210\u5230MCP\u73af\u5883\u4e2d\uff0c\u5305\u62ec\uff1aIDE\u6269\u5c55\u83b7\u53d6\u548c\u5448\u73b0\u4ee4\u724c\u3001MCP\u670d\u52a1\u5668\u901a\u8fc7\u8eab\u4efd\u63d0\u4f9b\u5546\u9a8c\u8bc1\u4ee4\u724c\u3001\u4f7f\u7528\u8303\u56f4\u548c\u58f0\u660e\u5b9e\u65bd\u6700\u5c0f\u6743\u9650\u8bbf\u95ee\u3002", "result": "\u4f7f\u7528Visual Studio Code\u3001Python MCP\u670d\u52a1\u5668\u548cOIDC\u517c\u5bb9\u8eab\u4efd\u63d0\u4f9b\u5546\u7684\u539f\u578b\u5b9e\u73b0\u8bc1\u660e\u4e86\u53ef\u884c\u6027\u3002\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u8eab\u4efd\u9a8c\u8bc1\u5ef6\u8fdf\u3001\u4ee4\u724c\u9a8c\u8bc1\u5f00\u9500\u3001\u64cd\u4f5c\u8003\u8651\u56e0\u7d20\u548cAI\u7279\u5b9a\u98ce\u9669\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ec4\u7ec7\u91c7\u7528AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u90e8\u7f72\u7684\u6a21\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8eab\u4efd\u4fdd\u8bc1\u548c\u53ef\u5ba1\u8ba1\u6027\uff0c\u89e3\u51b3\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6cbb\u7406\u9700\u6c42\u3002"}}
{"id": "2601.02732", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02732", "abs": "https://arxiv.org/abs/2601.02732", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Mengxi Jia", "Ying Li"], "title": "Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices", "comment": "accepted by ICSE-SEIP'26", "summary": "As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.", "AI": {"tldr": "AMER-RCL\u662f\u4e00\u4e2a\u7528\u4e8e\u5fae\u670d\u52a1\u6839\u56e0\u5b9a\u4f4d\u7684\u667a\u80fd\u4f53\u8bb0\u5fc6\u589e\u5f3a\u9012\u5f52\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9012\u5f52\u63a8\u7406\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u7ed3\u5408\u8de8\u8b66\u62a5\u77e5\u8bc6\u590d\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u6d45\u5c42\u3001\u75c7\u72b6\u4e2d\u5fc3\u7684\u63a8\u7406\u5bfc\u81f4\u51c6\u786e\u6027\u4e0d\u8db3\uff1b2\uff09\u7f3a\u4e4f\u8de8\u8b66\u62a5\u590d\u7528\u5bfc\u81f4\u5197\u4f59\u63a8\u7406\u548c\u9ad8\u5ef6\u8fdf\u3002\u901a\u8fc7\u7814\u7a76SRE\u4e13\u5bb6\u7684\u6839\u56e0\u5206\u6790\u8fc7\u7a0b\uff0c\u53d1\u73b0\u5176\u5177\u6709\u9012\u5f52\u6027\u3001\u591a\u7ef4\u6269\u5c55\u548c\u8de8\u6a21\u6001\u63a8\u7406\u4e09\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u8fd9\u542f\u53d1\u4e86\u65b0\u6846\u67b6\u7684\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faAMER-RCL\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u9012\u5f52\u63a8\u7406RCL\u5f15\u64ce\uff1a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5bf9\u6bcf\u4e2a\u8b66\u62a5\u6267\u884c\u9012\u5f52\u63a8\u7406\uff0c\u9010\u6b65\u7ec6\u5316\u5019\u9009\u539f\u56e0\uff1b2\uff09\u667a\u80fd\u4f53\u8bb0\u5fc6\uff1a\u5728\u65f6\u95f4\u7a97\u53e3\u5185\u589e\u91cf\u79ef\u7d2f\u548c\u590d\u7528\u5148\u524d\u8b66\u62a5\u7684\u63a8\u7406\u7ed3\u679c\uff0c\u51cf\u5c11\u5197\u4f59\u63a2\u7d22\u5e76\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAMER-RCL\u5728\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u7406\u590d\u6742\u7684\u5fae\u670d\u52a1\u7cfb\u7edf\u6545\u969c\u3002", "conclusion": "AMER-RCL\u901a\u8fc7\u6a21\u62df\u4e13\u5bb6\u7ea7\u9012\u5f52\u63a8\u7406\u548c\u8de8\u8b66\u62a5\u77e5\u8bc6\u590d\u7528\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u5728\u5fae\u670d\u52a1\u6839\u56e0\u5b9a\u4f4d\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4fdd\u969c\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02736", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02736", "abs": "https://arxiv.org/abs/2601.02736", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Pei Xiao", "Ying Li"], "title": "Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism", "comment": "accepted by ICSE-NIER'26", "summary": "Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \\textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.", "AI": {"tldr": "SpecRCA\uff1a\u57fa\u4e8e\u63a8\u6d4b\u63a8\u7406\u7684\u5fae\u670d\u52a1\u6839\u56e0\u5206\u6790\u6846\u67b6\uff0c\u91c7\u7528\"\u5047\u8bbe-\u9a8c\u8bc1\"\u8303\u5f0f\uff0c\u901a\u8fc7\u5047\u8bbe\u8349\u7a3f\u6a21\u5757\u5feb\u901f\u751f\u6210\u5019\u9009\u6839\u56e0\uff0c\u5e76\u884c\u9a8c\u8bc1\u5668\u9ad8\u6548\u9a8c\u8bc1\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5fae\u670d\u52a1\u7cfb\u7edf\u5df2\u6210\u4e3a\u4e91\u539f\u751f\u4f01\u4e1a\u5e94\u7528\u7684\u652f\u67f1\uff0c\u4f46\u5176\u5185\u5728\u590d\u6742\u6027\u548c\u52a8\u6001\u8fd0\u884c\u65f6\u4ea4\u4e92\u4e0d\u53ef\u907f\u514d\u5730\u5bfc\u81f4\u5f02\u5e38\u3002\u786e\u4fdd\u7cfb\u7edf\u53ef\u9760\u6027\u4f9d\u8d56\u4e8e\u6709\u6548\u7684\u6839\u56e0\u5206\u6790\uff0c\u9700\u8981\u53ca\u65f6\u3001\u53ef\u89e3\u91ca\u5730\u5b9a\u4f4d\u5f02\u5e38\u6e90\u5e76\u63cf\u8ff0\u5e95\u5c42\u6545\u969c\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a(a) \u63a2\u7d22\u591a\u6837\u6027\u6709\u9650\uff0c\u5f71\u54cd\u51c6\u786e\u6027\uff1b(b) \u4e25\u91cd\u4f9d\u8d56\u5927\u89c4\u6a21LLM\uff0c\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u6162\u3002", "method": "\u63d0\u51faSpecRCA\u6846\u67b6\uff0c\u91c7\u7528\"\u5047\u8bbe-\u9a8c\u8bc1\"\u8303\u5f0f\uff1a1) \u5047\u8bbe\u8349\u7a3f\u6a21\u5757\u5feb\u901f\u751f\u6210\u5019\u9009\u6839\u56e0\uff1b2) \u5e76\u884c\u6839\u56e0\u9a8c\u8bc1\u5668\u9ad8\u6548\u9a8c\u8bc1\u5019\u9009\u6839\u56e0\u3002", "result": "\u5728AIOps 2022\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0cSpecRCA\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SpecRCA\u5c55\u793a\u4e86\u4f5c\u4e3a\u590d\u6742\u5fae\u670d\u52a1\u73af\u5883\u4e2d\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u6839\u56e0\u5206\u6790\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709LLM-based\u65b9\u6cd5\u7684\u63a2\u7d22\u591a\u6837\u6027\u6709\u9650\u548c\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002"}}
{"id": "2601.02868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02868", "abs": "https://arxiv.org/abs/2601.02868", "authors": ["Peiding Wang", "Li Zhang", "Fang Liu", "Chongyang Tao", "Yinghao Zhu"], "title": "CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation", "comment": "preprint", "summary": "Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.", "AI": {"tldr": "CodeMEM\uff1a\u57fa\u4e8eAST\u7684\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ed3\u5e93\u7ea7\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\uff0c\u901a\u8fc7AST\u5f15\u5bfc\u7684LLM\u64cd\u4f5c\u7ef4\u62a4\u4ed3\u5e93\u4e0a\u4e0b\u6587\uff0c\u51cf\u5c11\u9057\u5fd8\u5e76\u63d0\u5347\u6307\u4ee4\u9075\u5faa\u80fd\u529b", "motivation": "\u73b0\u6709LLM\u5728\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u968f\u7740\u4ea4\u4e92\u8fdb\u884c\uff0c\u4ed3\u5e93\u4e0a\u4e0b\u6587\u9700\u8981\u6301\u7eed\u4fdd\u5b58\u548c\u66f4\u65b0\uff1b2\uff09\u6269\u5927\u7684\u4f1a\u8bdd\u5386\u53f2\u589e\u52a0\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5bfc\u81f4\u9057\u5fd8\u548c\u5df2\u89e3\u51b3\u9519\u8bef\u7684\u91cd\u65b0\u5f15\u5165\u3002\u73b0\u6709\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faCodeMEM\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09Code Context Memory\uff1a\u901a\u8fc7AST\u5f15\u5bfc\u7684LLM\u64cd\u4f5c\u52a8\u6001\u7ef4\u62a4\u548c\u66f4\u65b0\u4ed3\u5e93\u4e0a\u4e0b\u6587\uff1b2\uff09Code Session Memory\uff1a\u6784\u5efa\u4ee5\u4ee3\u7801\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u5386\u53f2\u8868\u793a\uff0c\u901a\u8fc7AST\u5206\u6790\u663e\u5f0f\u68c0\u6d4b\u548c\u7f13\u89e3\u9057\u5fd8\u95ee\u9898\u3002", "result": "\u5728CodeIF-Bench\u548cCoderEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u63d0\u534712.2%\uff08\u5f53\u524d\u8f6e\u6b21\uff09\u548c11.5%\uff08\u4f1a\u8bdd\u7ea7\uff09\uff0c\u4ea4\u4e92\u8f6e\u6b21\u51cf\u5c112-3\u8f6e\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u5ef6\u8fdf\u548ctoken\u6548\u7387\u3002", "conclusion": "CodeMEM\u901a\u8fc7AST\u5f15\u5bfc\u7684\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u6709\u6548\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ef4\u62a4\u548c\u9057\u5fd8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.02971", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02971", "abs": "https://arxiv.org/abs/2601.02971", "authors": ["Muhammad Laiq"], "title": "Few-shot learning for security bug report identification", "comment": null, "summary": "Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSetFit\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\uff0c\u76f8\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u9700\u8981\u53ca\u65f6\u8bc6\u522b\u4ee5\u964d\u4f4e\u8f6f\u4ef6\u7cfb\u7edf\u98ce\u9669\uff0c\u4f46\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800c\u5b9e\u9645\u4e2d\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u6570\u636e\u96c6\u901a\u5e38\u7a00\u7f3a\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u4e14\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u3002", "method": "\u91c7\u7528SetFit\u8fd9\u4e00\u5148\u8fdb\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u53e5\u5b50\u8f6c\u6362\u5668\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u5c11\u91cf\u6807\u6ce8\u7684\u6f0f\u6d1e\u62a5\u544a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8bc4\u4f30\u7684\u6240\u6709\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6700\u4f73AUC\u8fbe\u52300.865\uff0c\u663e\u793a\u51fa\u6709\u6548\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8eSetFit\u7684\u5c0f\u6837\u672c\u5b66\u4e60\u4e3a\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5f00\u53d1\u6a21\u578b\uff0c\u6700\u5c0f\u5316\u6807\u6ce8\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2601.03009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03009", "abs": "https://arxiv.org/abs/2601.03009", "authors": ["Nek Dil Khan", "Javed Ali Khan", "Darvesh Khan", "Jianqiang Li", "Mumrez Khan", "Shah Fahad Khan"], "title": "A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis", "comment": null, "summary": "In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u6765\u81ea\u4e9a\u9a6c\u900a\u8f6f\u4ef6\u5546\u5e9764\u4e2a\u4f4e\u8bc4\u5206\u5e94\u7528\u768479,821\u6761\u7528\u6237\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u5176\u4e2d6,000\u6761\u88ab\u624b\u52a8\u6807\u6ce8\u4e3a\u516d\u5927\u95ee\u9898\u7c7b\u522b\uff0c\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7528\u6237\u53cd\u9988\u81ea\u52a8\u5206\u7c7b\u63d0\u4f9b\u8d44\u6e90\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u5173\u6ce8\u9ad8\u8bc4\u5206\u5e94\u7528\uff0c\u800c\u4f4e\u8bc4\u5206\u5e94\u7528\u867d\u7136\u80fd\u63ed\u793a\u6709\u4ef7\u503c\u7684\u6539\u8fdb\u89c1\u89e3\uff0c\u5374\u5e38\u88ab\u5ffd\u89c6\u3002\u7528\u6237\u53cd\u9988\u5bf9\u8f6f\u4ef6\u6f14\u8fdb\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u8bc6\u522b\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u7684\u95ee\u9898\u3002", "method": "\u4ece\u4e9a\u9a6c\u900a\u8f6f\u4ef6\u5546\u5e97\u6536\u96c664\u4e2a\u4f4e\u8bc4\u5206\u5e94\u7528\u768479,821\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u5e76\u624b\u52a8\u6807\u6ce8\u5176\u4e2d6,000\u6761\u8bc4\u8bba\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u516d\u5927\u95ee\u9898\u7c7b\u522b\uff1aUI/UX\u3001\u529f\u80fd\u7279\u6027\u3001\u517c\u5bb9\u6027\u3001\u6027\u80fd\u7a33\u5b9a\u6027\u3001\u5ba2\u6237\u652f\u6301\u3001\u5b89\u5168\u9690\u79c1\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b\u539f\u59cb\u6570\u636e\u548c\u6807\u6ce8\u6570\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5206\u6790\u4f4e\u8bc4\u5206\u5e94\u7528\u5e38\u89c1\u95ee\u9898\u7684\u5de5\u5177\uff0c\u652f\u6301\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u81ea\u52a8\u5206\u7c7b\u7528\u6237\u53cd\u9988\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u57fa\u4e8e\u7528\u6237\u53cd\u9988\u6539\u8fdb\u8f6f\u4ef6\u8d28\u91cf\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e2e\u52a9\u7406\u89e3\u4f4e\u8bc4\u5206\u539f\u56e0\uff0c\u5e76\u4e3a\u8f6f\u4ef6\u6f14\u8fdb\u76f8\u5173\u7814\u7a76\uff08\u5982\u7f3a\u5931\u529f\u80fd\u3001\u8bbd\u523a\u3001\u60c5\u611f\u5206\u6790\uff09\u63d0\u4f9b\u673a\u4f1a\u3002"}}
{"id": "2601.03251", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03251", "abs": "https://arxiv.org/abs/2601.03251", "authors": ["Xue Qin", "Matthew DiGiovanni"], "title": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments", "comment": null, "summary": "Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.", "AI": {"tldr": "NavAI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528VR\u5bfc\u822a\u6846\u67b6\uff0c\u652f\u6301\u8de8\u4e0d\u540cVR\u5e94\u7528\u7684\u57fa\u672c\u52a8\u4f5c\u548c\u590d\u6742\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\uff0c\u5728\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4e2d\u8fbe\u523089%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u6280\u672f\u4e3b\u8981\u9488\u5bf9360\u5ea6\u56fe\u50cf\u6570\u636e\u96c6\u548c3D\u6a21\u62df\u5668\u8fdb\u884c\u8def\u5f84\u4f18\u5316\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u6c89\u6d78\u5f0fVR\u73af\u5883\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8eVR\u7684\u901a\u7528\u5bfc\u822a\u6846\u67b6\u3002", "method": "\u63d0\u51faNavAI\u6846\u67b6\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6784\u5efa\uff0c\u652f\u6301\u8de8\u4e0d\u540cVR\u5e94\u7528\u7684\u57fa\u672c\u52a8\u4f5c\u548c\u590d\u6742\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u7684VR\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "NavAI\u5728\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4e2d\u8fbe\u523089%\u7684\u6210\u529f\u7387\uff0c\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002\u5206\u6790\u63ed\u793a\u4e86\u5b8c\u5168\u4f9d\u8d56LLM\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u52a8\u6001\u76ee\u6807\u8bc4\u4f30\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "NavAI\u5c55\u793a\u4e86LLM\u5728VR\u5bfc\u822a\u4e2d\u7684\u6f5c\u529b\uff0c\u4f46\u5b8c\u5168\u4f9d\u8d56LLM\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u76ee\u6807\u8bc4\u4f30\u65b9\u9762\u3002\u8bba\u6587\u8ba8\u8bba\u4e86\u5b9e\u9a8c\u4e2d\u7684\u9650\u5236\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
