<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 13]
- [cs.LO](#cs.LO) [Total: 7]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale](https://arxiv.org/abs/2511.14002)
*Chengpeng Li,Farnaz Behrang,August Shi,Peng Liu*

Main category: cs.SE

TL;DR: FlakyGuard通过将代码视为图结构并使用选择性图探索来找到最相关的上下文，解决了现有方法在工业环境中修复不稳定测试时的上下文问题，显著提高了修复成功率。


<details>
  <summary>Details</summary>
Motivation: 不稳定的测试会浪费开发者时间并减缓发布周期。现有方法如FlakyDoctor在工业环境中因上下文问题（提供太少或太多上下文）而失败。

Method: 将代码视为图结构，使用选择性图探索来找到最相关的上下文，避免提供过多或过少的信息。

Result: 在真实工业仓库的不稳定测试中，FlakyGuard修复了47.6%的可重现不稳定测试，其中51.8%的修复被开发者接受，比最先进方法至少高出22%的修复成功率。

Conclusion: FlakyGuard通过选择性图探索有效解决了不稳定测试修复中的上下文问题，开发者调查显示100%认为其根本原因解释有用。

Abstract: Flaky tests that non-deterministically pass or fail waste developer time and slow release cycles. While large language models (LLMs) show promise for automatically repairing flaky tests, existing approaches like FlakyDoctor fail in industrial settings due to the context problem: providing either too little context (missing critical production code) or too much context (overwhelming the LLM with irrelevant information). We present FlakyGuard, which addresses this problem by treating code as a graph structure and using selective graph exploration to find only the most relevant context. Evaluation on real-world flaky tests from industrial repositories shows that FlakyGuard repairs 47.6 % of reproducible flaky tests with 51.8 % of the fixes accepted by developers. Besides it outperforms state-of-the-art approaches by at least 22 % in repair success rate. Developer surveys confirm that 100 % find FlakyGuard's root cause explanations useful.

</details>


### [2] [Show and Tell: Prompt Strategies for Style Control in Multi-Turn LLM Code Generation](https://arxiv.org/abs/2511.13972)
*Jeremiah Bohr*

Main category: cs.SE

TL;DR: 该研究比较了基于指令、基于示例和组合提示在代码生成中的风格控制效果，发现在两轮协议中组合提示能提供最稳定的风格控制，具有最强的初始压缩效果和最大的扩展纪律性。


<details>
  <summary>Details</summary>
Motivation: 语言模型生成的代码往往过于冗长，包含复杂的文档和防御性模式，与人类基准存在差异。需要研究不同提示机制在保持功能准确性的同时，如何维持风格约束。

Method: 采用配对两轮协议，在四种提示条件下让模型首先生成Python任务解决方案，然后在通用改进指令下修订代码，保持用户任务固定（N=160对程序）。

Result: 组合提示产生最强的初始压缩和最大的扩展纪律性；指令提示显示较大的初始效果和中等扩展纪律性；示例提示显示适度的初始效果但没有扩展纪律性。

Conclusion: 初始提示有效性和扩展纪律性是提示设计的两个独立方面，组合方法在两轮工作流程中提供最稳定的风格控制。

Abstract: Language models generate functionally correct code that tends toward excessive verbosity, with elaborate documentation and defensive patterns that diverge from human baselines. Two prompting mechanisms have emerged for stylistic control: instruction based prompts that articulate abstract directives, and example based prompts that provide concrete code demonstrations. The core problem is whether stylistic constraints persist when models enhance initial implementations with additional features while maintaining high functional accuracy. Here we show that instruction-based, example-based, and combined prompts produce distinct patterns of initial control and expansion discipline over one enhancement turn. We manipulated system prompts across four conditions in a paired two-turn protocol where models first generated solutions to an intermediate Python task, then revised their code under general improvement directives, holding the user task fixed (N = 160 paired programs). Combined prompts produced the strongest initial compression and greatest expansion discipline. Instructions showed large initial effects and moderate expansion discipline. Examples showed modest initial effects with no expansion discipline. These results show that initial prompt effectiveness and expansion discipline are separate aspects of prompt design, and that combined approaches provide the most stable stylistic control in this two-turn workflow.

</details>


### [3] [Exploring the Use of ChatGPT by Computer Science Students in Software Development: Applications, Ethical Considerations, and Insights for Engineering Education](https://arxiv.org/abs/2511.13996)
*Daihan Xu,Diana Martin*

Main category: cs.SE

TL;DR: 本研究通过定性访谈探讨计算机科学学生如何在软件开发项目中战略性和道德地使用ChatGPT，发现学生采用新的学习模式，限制AI贡献约30%，但缺乏对生成代码的深入分析，需要明确的指导方针。


<details>
  <summary>Details</summary>
Motivation: ChatGPT在计算机科学教育中日益普及，但现有研究主要依赖调查问卷，缺乏对学生使用策略和道德意识的深入分析。本研究旨在填补这一空白。

Method: 采用半结构化访谈的定性研究方法，调查英国一所高校计算机科学学生在软件开发项目中使用ChatGPT的战略和道德考量。

Result: 学生学习模式从传统模式转向"AI辅助构思-交互编程-协作优化"；多数学生限制ChatGPT贡献约30%，通过对话加深理解；但只有少数深入分析AI生成代码；学生拒绝未经授权使用，关注隐私泄露和技能退化风险。

Conclusion: 研究揭示了学习者与AI动态关系的变化，强调需要明确的指导方针来支持负责任和教学合理的使用方式。

Abstract: ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in software development projects. Drawing on semi-structured interviews, it explores two key questions: How do computer science students ethically and strategically report using ChatGPT in software development projects? How do students understand and perceive the ethical issues associated with using ChatGPT in academic and professional contexts? Findings reveal a shift in students' learning models, moving from traditional "independent thinking-manual coding-iterative debugging" to "AI-assisted ideation-interactive programming-collaborative optimization." Importantly, many use ChatGPT conversationally to deepen understanding, while consciously reserving creative and high-level decision-making tasks for themselves. Students tend to cap ChatGPT's contribution to roughly 30%, and evaluate its output to mitigate overreliance. However, only a minority thoroughly analyze AI-generated code, raising concerns about reduced critical engagement. Meanwhile, students reject uncredited use, highlight risks such as privacy breaches and skill degradation, and call for clear usage guidelines set by their teachers. This research offers novel insights into the evolving learner-AI dynamic and highlights the need for explicit guidance to support responsible and pedagogically sound use of such tools.

</details>


### [4] [LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering](https://arxiv.org/abs/2511.13998)
*Jielin Qiu,Zuxin Liu,Zhiwei Liu,Rithesh Murthy,Jianguo Zhang,Haolin Chen,Shiyu Wang,Ming Zhu,Liangwei Yang,Juntao Tan,Roshan Ram,Akshara Prabhakar,Tulika Awalgaonkar,Zixiang Chen,Zhepeng Cen,Cheng Qian,Shelby Heinecke,Weiran Yao,Silvio Savarese,Caiming Xiong,Huan Wang*

Main category: cs.SE

TL;DR: LoCoBench-Agent是一个专为评估LLM智能体在真实长上下文软件工程工作流中表现的综合评估框架，扩展了LoCoBench的8000个场景为交互式环境，系统评估多轮对话、工具使用效率、错误恢复和架构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基准如LoCoBench主要评估单轮代码理解，无法捕捉真实世界编码智能体所需的多轮交互、工具使用模式和自适应推理能力。

Method: 将LoCoBench的8000个场景扩展为交互式智能体环境，提供8种专用工具（文件操作、搜索、代码分析），在10K到1M令牌的上下文长度范围内评估，采用包含9个指标的评价方法学。

Result: 系统评估揭示了关键发现：智能体表现出显著的长上下文鲁棒性；理解与效率存在负相关的权衡；对话效率在不同模型间差异显著，策略性工具使用模式区分高性能智能体。

Conclusion: 作为首个面向软件工程的长上下文LLM智能体基准，LoCoBench-Agent为衡量智能体能力、识别性能差距和推进大规模自主软件开发建立了严谨基础。

Abstract: As large language models (LLMs) evolve into sophisticated autonomous agents capable of complex software development tasks, evaluating their real-world capabilities becomes critical. While existing benchmarks like LoCoBench~\cite{qiu2025locobench} assess long-context code understanding, they focus on single-turn evaluation and cannot capture the multi-turn interactive nature, tool usage patterns, and adaptive reasoning required by real-world coding agents. We introduce \textbf{LoCoBench-Agent}, a comprehensive evaluation framework specifically designed to assess LLM agents in realistic, long-context software engineering workflows. Our framework extends LoCoBench's 8,000 scenarios into interactive agent environments, enabling systematic evaluation of multi-turn conversations, tool usage efficiency, error recovery, and architectural consistency across extended development sessions. We also introduce an evaluation methodology with 9 metrics across comprehension and efficiency dimensions. Our framework provides agents with 8 specialized tools (file operations, search, code analysis) and evaluates them across context lengths ranging from 10K to 1M tokens, enabling precise assessment of long-context performance. Through systematic evaluation of state-of-the-art models, we reveal several key findings: (1) agents exhibit remarkable long-context robustness; (2) comprehension-efficiency trade-off exists with negative correlation, where thorough exploration increases comprehension but reduces efficiency; and (3) conversation efficiency varies dramatically across models, with strategic tool usage patterns differentiating high-performing agents. As the first long-context LLM agent benchmark for software engineering, LoCoBench-Agent establishes a rigorous foundation for measuring agent capabilities, identifying performance gaps, and advancing autonomous software development at scale.

</details>


### [5] [Keeping Code-Aware LLMs Fresh: Full Refresh, In-Context Deltas, and Incremental Fine-Tuning](https://arxiv.org/abs/2511.14022)
*Pradeep Kumar Sharma,Ishaan Puri,Mantinder Jit Singh,Swapnil Shivaprasad,Hritvik Shrivastava*

Main category: cs.SE

TL;DR: 研究如何在代码库持续演化的背景下保持代码搜索模型的新鲜度，通过比较三种更新策略：完全刷新、上下文学习和增量微调，发现增量微调结合新旧数据混合的方法在整体平衡性上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现代代码库不断演化，导致训练好的代码搜索模型会快速过时。需要研究如何在不丢失对旧代码记忆的情况下保持模型的新鲜度。

Method: 将代码新鲜度视为领域漂移问题，比较三种更新策略：(A)完全刷新重新训练；(B)上下文学习注入最近的代码变更；(C)增量微调结合新旧数据混合以防止灾难性遗忘。

Result: 在Flask、SQLAlchemy、Pandas和Poetry等项目中，增量微调结合新旧数据混合在混合数据集上表现最佳，上下文学习在无法训练时提供最快的新代码提升，完全刷新在追求最大新代码准确率时仍是上限。

Conclusion: 增量微调是保持代码搜索模型新鲜度的最佳平衡方案，而不同更新策略在不同场景下各有优势，需要根据具体需求选择。

Abstract: Modern codebases evolve continuously: files are renamed or deleted; public APIs drift; behavior shifts within otherwise familiar modules. A model trained yesterday to map a developer's natural-language question to the exact set of repository file paths that matter will degrade tomorrow, even if the questions themselves look unchanged. In this paper we study, at system scale and across several widely used repositories, how to keep such a model fresh without surrendering retention on earlier code. We frame freshness as a form of domain drift between a base snapshot and the current HEAD, and we compare three families of update strategies: (A) Full Refresh, retraining the entire model at the new snapshot; (B) In-Context Learning (ICL) that injects recent deltas (raw git diffs or concise English summaries) at inference; and (C) Incremental Fine-Tuning (Inc-FT) on delta-derived training sets, with carefully controlled NEW:OLD mixing to mitigate catastrophic forgetting. We contribute an alias-aware evaluation protocol that credits rename while never rewarding deleted paths, and a practical Forgetting Probe that quantifies residual emissions of obsolete paths. Across Flask, SQLAlchemy, Pandas, and Poetry, Inc-FT with old-aware mixes delivers the best overall balance on mixed sets, ICL with English delta summaries delivers the fastest new-code lift when training is not feasible, and Full Refresh remains the ceiling when maximum NEW accuracy matters. We also compare Git-diff Inc-FT to full-file Inc-FT, showing that diffs excel in rename/delete-heavy windows while full-file context wins in behavior-change-heavy windows.

</details>


### [6] [LogPurge: Log Data Purification for Anomaly Detection via Rule-Enhanced Filtering](https://arxiv.org/abs/2511.14062)
*Shenglin Zhang,Ziang Chen,Zijing Que,Yilun Liu,Yongqian Sun,Sicheng Wei,Dan Pei,Hailin Li*

Main category: cs.SE

TL;DR: 提出了LogPurge框架，通过两阶段过滤算法自动从受污染的日志序列中选择足够多的正常样本来训练异常检测模型，显著提高了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的日志异常检测方法需要干净的异常免费日志数据进行训练，但获取这样的数据需要昂贵的人工标注，现有的自动清理方法未能充分整合日志的特定特征和实际语义。

Method: 采用两阶段过滤算法：第一阶段使用大语言模型移除聚集的异常模式并增强系统规则；第二阶段使用分治策略将剩余污染区域分解为更小的子问题，通过第一阶段程序有效净化。

Result: 在两个公共数据集和一个工业数据集上的实验显示，该方法平均移除了98.74%的异常，同时保留了82.39%的正常样本。与最新的无监督日志样本选择算法相比，在公共数据集上F-1分数分别提高了35.7%和84.11%，在私有数据集上提高了149.72%。

Conclusion: LogPurge框架在自动净化受污染日志数据方面表现出色，显著提升了日志异常检测模型的训练效果。

Abstract: Log anomaly detection, which is critical for identifying system failures and preempting security breaches, detects irregular patterns within large volumes of log data, and impacts domains such as service reliability, performance optimization, and database log analysis. Modern log anomaly detection methods rely on training deep learning models on clean, anomaly-free log sequences. However, obtaining such clean log data requires costly and tedious human labeling, and existing automatic cleaning methods fail to fully integrate the specific characteristics and actual semantics of logs in their purification process. In this paper, we propose a cost-aware, rule-enhanced purification framework, LogPurge, that automatically selects a sufficient subset of normal log sequences from contamination log sequences to train a anomaly detection model. Our approach involves a two-stage filtering algorithm: In the first stage, we use a large language model (LLM) to remove clustered anomalous patterns and enhance system rules to improve LLM's understanding of system logs; in the second stage, we utilize a divide-and-conquer strategy that decomposes the remaining contaminated regions into smaller subproblems, allowing each to be effectively purified through the first stage procedure. Our experiments, conducted on two public datasets and one industrial dataset, show that our method significantly removes an average of 98.74% of anomalies while retaining 82.39% of normal samples. Compared to the latest unsupervised log sample selection algorithms, our method achieves F-1 score improvements of 35.7% and 84.11% on the public datasets, and an impressive 149.72% F-1 improvement on the private dataset, demonstrating the effectiveness of our approach.

</details>


### [7] [A Practical Implementation of Customized Scrum-Based Agile Framework in Aerospace Software Development Under DO-178C Constraints](https://arxiv.org/abs/2511.14215)
*Malik Muhammad Umer*

Main category: cs.SE

TL;DR: 提出一个经过实证验证的基于Scrum的敏捷框架，专门用于符合DO-178C标准的安全关键航空航天软件，在保持完全合规的同时显著提升了开发效率和质量。


<details>
  <summary>Details</summary>
Motivation: 航空航天系统日益复杂，需要在敏捷性和严格的安全认证要求之间取得平衡，传统开发方法难以同时满足这两方面需求。

Method: 定制化的Scrum敏捷框架，包括多学科产品所有权模型、双重验收标准、独立测试和文档团队、认证联络员等关键增强功能，并通过两个可比项目进行实证评估。

Result: 相比传统瀑布模型，总需求工作量减少76%，缺陷检测速度提升75%，缺陷解决速度提升78%，缺陷密度降低50%以上，同时保持DO-178C设计保证等级A的完全合规。

Conclusion: 敏捷实践与监管合规可以共存，但需要严格的定制化和与认证机构的主动合作，未来可通过自动化、CI/CD等进一步提升效益。

Abstract: The increasing complexity of aerospace systems requires development processes that balance agility with stringent safety and certification demands. This study presents an empirically validated Scrum-based Agile framework tailored for DO-178C compliant, safety-critical aerospace software. The framework adapts core Scrum roles, artifacts, and events to meet certification, verification, and independence objectives. Key enhancements include a multi-disciplinary product ownership model, dual compliance-and-functionality acceptance criteria, independent testing and documentation teams, and dedicated certification liaisons. The approach was evaluated through two comparable aerospace projects-one using the customized Agile process and the other a traditional Waterfall model. Results showed significant improvements: a 76% reduction in Total Effort per Requirement, 75% faster Defect Detection, 78% faster Defect Resolution, and over 50% lower Defect Density, while maintaining full compliance with DO-178C Design Assurance Level A. These findings demonstrate that Agile practices and regulatory compliance can coexist effectively when supported by disciplined tailoring and proactive engagement with certification authorities. The study also notes challenges, including increased V&V effort due to recurring Sprint activities and refactoring inherent to iterative development. Nonetheless, it identifies substantial opportunities for further gains through workflow automation, CI/CD practices, and automated documentation, verification, and configuration management. Future research should expand validation of this framework across the aerospace domain and other safety-critical industries with similar certification requirements.

</details>


### [8] [KTester: Leveraging Domain and Testing Knowledge for More Effective LLM-based Test Generation](https://arxiv.org/abs/2511.14224)
*Anji Li,Mingwei Liu,Zhenxi Chen,Zheng Pei,Zike Li,Dekun Dai,Yanlin Wang,Zibin Zheng*

Main category: cs.SE

TL;DR: KTester是一个集成项目特定知识和测试领域知识的LLM测试生成框架，通过静态分析提取项目结构知识，采用测试领域知识指导的测试用例设计与测试方法生成分离策略，结合多视角提示技术，显著提升测试生成的质量和可维护性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的自动化单元测试生成方法在真实项目中往往难以生成既正确又可维护的测试用例，需要更好的知识集成和指导策略。

Method: 1) 通过静态分析提取项目结构和用法知识；2) 采用测试领域知识指导的测试用例设计与测试方法生成分离；3) 多视角提示策略引导LLM考虑多样化的测试启发式方法；4) 使用结构化模板生成测试用例。

Result: 在多个开源项目上的评估显示，KTester在六个关键指标上显著优于现有方法：执行通过率提高5.69%，行覆盖率提高8.83%，同时需要更少时间并生成更少的测试用例。人工评估也确认KTester生成的测试在正确性、可读性和可维护性方面评分更高。

Conclusion: KTester证明了知识驱动框架在提升LLM测试生成质量方面的有效性，通过集成项目特定知识和测试领域知识，能够生成更正确、可读和可维护的测试用例。

Abstract: Automated unit test generation using large language models (LLMs) holds great promise but often struggles with generating tests that are both correct and maintainable in real-world projects. This paper presents KTester, a novel framework that integrates project-specific knowledge and testing domain knowledge to enhance LLM-based test generation. Our approach first extracts project structure and usage knowledge through static analysis, which provides rich context for the model. It then employs a testing-domain-knowledge-guided separation of test case design and test method generation, combined with a multi-perspective prompting strategy that guides the LLM to consider diverse testing heuristics. The generated tests follow structured templates, improving clarity and maintainability. We evaluate KTester on multiple open-source projects, comparing it against state-of-the-art LLM-based baselines using automatic correctness and coverage metrics, as well as a human study assessing readability and maintainability. Results demonstrate that KTester significantly outperforms existing methods across six key metrics, improving execution pass rate by 5.69% and line coverage by 8.83% over the strongest baseline, while requiring less time and generating fewer test cases. Human evaluators also rate the tests produced by KTester significantly higher in terms of correctness, readability, and maintainability, confirming the practical advantages of our knowledge-driven framework.

</details>


### [9] [Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems](https://arxiv.org/abs/2511.14435)
*Angelo Ferrando*

Main category: cs.SE

TL;DR: 本文提出将运行时验证（RV）与大语言模型（LLMs）进行共生集成，RV可作为LLM驱动自主系统的安全护栏，而LLMs可扩展RV在规范捕获、预测推理和处理不确定性方面的能力。


<details>
  <summary>Details</summary>
Motivation: 在涉及学习组件和开放环境的自主系统中，确保安全性和可信性具有挑战性。形式化方法提供强保证但依赖完整模型和静态假设，而LLMs擅长模式识别但缺乏形式化保证且易出错。

Method: 通过RV和LLMs的共生集成：RV作为LLM驱动自主系统的安全护栏，LLMs辅助RV进行规范捕获、支持预测推理和处理不确定性。

Result: 这种相互强化方法不同于现有的调查和路线图，为构建可信自主系统提供了新的研究方向。

Conclusion: RV和LLMs的共生集成能够实现更可靠的自主性，但仍需解决挑战和认证影响，未来研究应朝着可信自主系统的方向发展。

Abstract: Assuring the safety and trustworthiness of autonomous systems is particularly difficult when learning-enabled components and open environments are involved. Formal methods provide strong guarantees but depend on complete models and static assumptions. Runtime verification (RV) complements them by monitoring executions at run time and, in its predictive variants, by anticipating potential violations. Large language models (LLMs), meanwhile, excel at translating natural language into formal artefacts and recognising patterns in data, yet they remain error-prone and lack formal guarantees. This vision paper argues for a symbiotic integration of RV and LLMs. RV can serve as a guardrail for LLM-driven autonomy, while LLMs can extend RV by assisting specification capture, supporting anticipatory reasoning, and helping to handle uncertainty. We outline how this mutual reinforcement differs from existing surveys and roadmaps, discuss challenges and certification implications, and identify future research directions towards dependable autonomy.

</details>


### [10] [How Does Cognitive Capability and Personality Influence Problem-Solving in Coding Interview Puzzles?](https://arxiv.org/abs/2511.14367)
*Dulaji Hidellaarachchi,Sebastian Baltes,John Grundy*

Main category: cs.SE

TL;DR: 本研究探讨认知能力和人格特质如何共同影响软件问题解决，发现认知能力与问题解决表现正相关，尽责性和开放性人格特质对软件问题解决有积极影响，而神经质则有负面作用。


<details>
  <summary>Details</summary>
Motivation: 软件工程是深度认知活动，受个体差异影响。研究旨在了解认知能力和人格特质如何共同影响软件问题解决表现。

Method: 对80名参与者（40名软件从业者，40名软件工程学生）进行认知能力测试（Baddeley语法推理测试）、人格测试（IPIP NEO 50）和9个问题解决任务（6个编码相关，3个逻辑推理）。

Result: 从业者表现略优于学生；认知能力与问题解决表现正相关；尽责性人格与问题解决和推理准确性最相关；开放性人格与两者正相关；神经质与准确性和表现呈负相关。

Conclusion: 尽责性和开放性人格特质与认知能力共同支持软件问题解决，而负面情绪可能阻碍时间压力下的精确性。研究对教育和行业实践有重要启示。

Abstract: Software engineering is a deeply cognitive activity shaped by individual differences that extend beyond technical skill. This study investigates how cognitive capability and personality traits jointly relate to software problem solving among 80 participants (40 software practitioners, 40 software engineering students). Cognitive capability was measured using Baddeleys three minute grammatical reasoning test, while personality was assessed using the IPIP NEO 50 test. Participants further completed nine interview style problem solving questions. Six questions were related to coding and three were related to logical reasoning. Descriptive and correlational analyses show that practitioners achieved slightly higher grammatical reasoning accuracy and overall task performance than students. Grammatical-reasoning accuracy correlated positively with problem solving performance, indicating that stronger cognitive capability is associated with better performance in coding and logical tasks. Personality performance links were systematic. We identified that the conscientiousness trait correlated most strongly with problem solving and with reasoning accuracy, while the openness to experience trait was positively related to both outcomes. Neuroticism showed small, negative associations with accuracy and performance. Taken together, our results suggest that conscientiousness and openness to experience characteristics complement reasoning accuracy to support software problem solving, whereas elevated negative affect may hinder precision under time pressure. Our findings suggest practical implications for education and industry such as integrating structured reasoning tasks in curricula, and considering personality cognition in recruitment and role allocation. We highlight directions for future research such as longitudinal and task diverse replications with larger samples.

</details>


### [11] [LLM-Assisted Thematic Analysis: Opportunities, Limitations, and Recommendations](https://arxiv.org/abs/2511.14528)
*Tatiane Ornelas,Allysson Allex Araújo,Júlia Araújo,Marina Araújo,Bianca Trinkenreich,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本研究探讨了在软件工程定性研究中集成大语言模型进行主题分析的方法论影响，发现LLMs能提高效率但存在偏见、上下文丢失等风险，需要人类持续监督。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件工程定性研究中的应用日益增多，但其在解释性过程（如主题分析）中的方法论影响尚未充分探索，涉及严谨性、透明度和研究者能动性等基本问题。

Method: 与25名ISERN研究人员进行反思性研讨会，通过结构化讨论LLM辅助的开放编码、主题生成和主题评审，使用彩色编码画布记录感知的机会、局限性和建议。

Result: 参与者认识到潜在的效率和可扩展性收益，但强调了与偏见、上下文丢失、可重复性以及LLMs快速演变相关的风险，同时强调需要提示素养和持续的人类监督。

Conclusion: 研究结果表明LLMs可以作为支持工具但不能替代解释性分析，为社区关于如何负责任地使用LLMs增强软件工程定性研究提供了反思。

Abstract: [Context] Large Language Models (LLMs) are increasingly used to assist qualitative research in Software Engineering (SE), yet the methodological implications of this usage remain underexplored. Their integration into interpretive processes such as thematic analysis raises fundamental questions about rigor, transparency, and researcher agency. [Objective] This study investigates how experienced SE researchers conceptualize the opportunities, risks, and methodological implications of integrating LLMs into thematic analysis. [Method] A reflective workshop with 25 ISERN researchers guided participants through structured discussions of LLM-assisted open coding, theme generation, and theme reviewing, using color-coded canvases to document perceived opportunities, limitations, and recommendations. [Results] Participants recognized potential efficiency and scalability gains, but highlighted risks related to bias, contextual loss, reproducibility, and the rapid evolution of LLMs. They also emphasized the need for prompting literacy and continuous human oversight. [Conclusion] Findings portray LLMs as tools that can support, but not substitute, interpretive analysis. The study contributes to ongoing community reflections on how LLMs can responsibly enhance qualitative research in SE.

</details>


### [12] [FHIRconnect: Towards a seamless integration of openEHR and FHIR](https://arxiv.org/abs/2511.14618)
*Severin Kohler,Jordi Piera Jiménez,Michael Anywar,Lars Fuhrmann,Heather Leslie,Maximilian Meixner,Julian Saß,Florian Kärcher,Diego Boscá,Birger Haarbrandt,Michael Marschollek,Roland Eils*

Main category: cs.SE

TL;DR: FHIRconnect是一个用于openEHR和HL7 FHIR之间双向数据转换的领域特定语言和开源转换引擎，通过三层架构实现65%的映射复用，成功映射了24个国际原型到15个FHIR配置文件。


<details>
  <summary>Details</summary>
Motivation: 解决openEHR和HL7 FHIR之间由于数据建模方法根本差异和缺乏标准化转换机制而导致的医疗互操作性挑战。

Method: 开发了FHIRconnect领域特定语言和开源转换引擎，采用三层架构，利用国际原型基础支持本地定制化，实现标准化双向数据交换。

Result: 成功映射24个国际原型到15个FHIR配置文件，覆盖7个临床领域，建立了社区驱动的映射标准化技术基础。

Conclusion: FHIRconnect组件为基于开放标准的医疗IT系统建立了技术基础，减少了对自定义ETL解决方案的依赖，推进了语法和语义互操作性。

Abstract: Healthcare interoperability between openEHR and HL7 FHIR remains challenging due to fundamental differences in their data modeling approaches and the absence of standardized transformation mechanisms. This paper presents FHIRconnect, a novel domain-specific language and open-source transformation engine that enables standardized, bidirectional data exchange between openEHR and FHIR. Our approach addresses critical interoperability gaps through a triple-layered architecture that achieves 65% mapping reuse across projects by leveraging international archetype-based foundations while supporting local customizations. Using this framework, FHIRconnect successfully mapped 24 international archetypes to 15 FHIR profiles across seven clinical domains. Key contributions include the first comprehensive DSL for openEHR-FHIR transformation with a formal specification, an open-source execution engine (openFHIR), and an accessible mapping library covering high-impact clinical archetypes. Together, these components establish the technical basis for community-driven mapping standardization, reducing reliance on custom ETL solutions and advancing syntactic and semantic interoperability in healthcare IT systems built on open standards.

</details>


### [13] [Why Do We Code? A Theory on Motivations and Challenges in Software Engineering from Education to Practice](https://arxiv.org/abs/2511.14711)
*Aaliyah Chang,Mariam Guizani,Brittany Johnson*

Main category: cs.SE

TL;DR: 该研究通过访谈构建了动机与挑战的分类法，提出了暴露-追求-评估(EPE)过程模型，揭示了早期接触体验如何影响内在动机形成，以及不同挑战如何制约动机满足。


<details>
  <summary>Details</summary>
Motivation: 探索软件工程从业者在从教育到职业实践过渡过程中，动机与挑战如何共同塑造其进入、坚持和职业发展的过程，这一互动关系目前研究不足。

Method: 采用15个半结构化访谈，运用来自组织行为学的Gioia方法论（一种改编的扎根理论方法），归纳性地推导动机和挑战的分类法，并构建暴露-追求-评估(EPE)过程模型。

Result: 研究发现：有影响力的早期接触会触发内在动机，而无影响力的接触需要外在推动；识别出好奇心和避免替代选择作为独特的教育驱动力；归属感障碍是唯一贯穿教育和职业生涯的挑战；职业发展挑战制约外在满足，而技术培训挑战、归属感障碍和动机威胁制约内在满足。

Conclusion: 未满足的动机和反复出现的挑战会影响坚持、职业转变或离开该领域。该理论为设计干预措施提供了基础模型，以增强软件工程教育和实践中的内在满足感并减少系统性障碍。

Abstract: Motivations and challenges jointly shape how individuals enter, persist, and evolve within software engineering (SE), yet their interplay remains underexplored across the transition from education to professional practice. We conducted 15 semi-structured interviews and employed the Gioia Methodology, an adapted grounded theory methodology from organizational behavior, to inductively derive taxonomies of motivations and challenges, and build the Exposure-Pursuit-Evaluation (EPE) Process Model. Our findings reveal that impactful early exposure triggers intrinsic motivations, while non-impactful exposure requires an extrinsic push (e.g., career/ personal goals, external validation). We identify curiosity and avoiding alternatives as a distinct educational drivers, and barriers to belonging as the only challenge persisting across education and career. Our findings show that career progression challenges (e.g., navigating the corporate world) constrain extrinsic fulfillment while technical training challenges, barriers to belonging and threats to motivation constrain intrinsic fulfillment. The theory shows how unmet motivations and recurring challenges influence persistence, career shifts, or departure from the field. Our results provide a grounded model for designing interventions that strengthen intrinsic fulfillment and reduce systemic barriers in SE education and practice.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [14] [Towards A Catalogue of Requirement Patterns for Space Robotic Missions](https://arxiv.org/abs/2511.14438)
*Mahdi Etumi,Hazel M. Taylor,Marie Farrell*

Main category: cs.LO

TL;DR: 本文探讨了现有机器人规范模式在太空任务中的适用性，通过文献回顾将太空任务需求形式化，贡献了5个新需求规范模式，并进行了专家评估。


<details>
  <summary>Details</summary>
Motivation: 在安全关键系统和任务关键系统的开发中，需求通常用自然语言表达，存在歧义且难以进行形式化验证。规范模式提供了可重用的逻辑模板，但现有的机器人规范模式是领域无关的，需要探索其在太空任务中的适用性。

Method: 通过文献回顾分析现有太空任务，使用NASA的FRET工具形式化需求，构建太空任务需求语料库，并用现有规范模式分类这些需求。对于无法对应现有模式的需求，开发了新的规范模式。

Result: 研究表明现有规范模式在太空任务中具有适用性，但仍有部分需求无法对应现有模式，因此贡献了5个新需求规范模式及其变体。专家评估验证了新模式的益处和局限性。

Conclusion: 规范模式在太空任务需求形式化中具有重要价值，新贡献的模式填补了现有模式的空白，为太空任务的形式化验证提供了更好的支持。

Abstract: In the development of safety and mission-critical systems, including autonomous space robotic missions, complex behaviour is captured during the requirements elicitation phase. Requirements are typically expressed using natural language which is ambiguous and not amenable to formal verification methods that can provide robust guarantees of system behaviour. To support the definition of formal requirements, specification patterns provide reusable, logic-based templates. A suite of robotic specification patterns, along with their formalisation in NASA's Formal Requirements Elicitation Tool (FRET) already exists. These pre-existing requirement patterns are domain agnostic and, in this paper we explore their applicability for space missions. To achieve this we carried out a literature review of existing space missions and formalised their requirements using FRET, contributing a corpus of space mission requirements. We categorised these requirements using pre-existing specification patterns which demonstrated their applicability in space missions. However, not all of the requirements that we formalised corresponded to an existing pattern so we have contributed 5 new requirement specification patterns as well as several variants of the existing and new patterns. We also conducted an expert evaluation of the new patterns, highlighting their benefits and limitations.

</details>


### [15] [Probabilistic Verification for Modular Network-on-Chip Systems (extended version)](https://arxiv.org/abs/2511.13890)
*Nick Waddoups,Jonah Boe,Arnd Hartmanns,Prabal Basu,Sanghamitra Roy,Koushik Chakraborty,Zhen Zhang*

Main category: cs.LO

TL;DR: 本文提出了一种基于Modest语言的系统化、模块化NoC建模方法，用于早期验证电源噪声对网络可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 现代NoC设计中网络流量的波动导致电源传输变化，引起不可靠性和数据传输错误。NoC设计在规模、用途和实现上差异很大，需要早期理解并缓解电源噪声问题。

Method: 使用Modest语言构建反映数字系统标准分层设计的模块化NoC模型，通过Modest工具集验证功能正确性，使用统计模型检查验证电源噪声相关属性。

Result: 验证了通用路由器、路由器间通信和整个NoC的功能正确性，并对8x8规模的NoC进行了电源噪声相关属性的统计模型检查验证。

Conclusion: 该建模方法能够系统化地验证NoC设计的功能和定量正确性，为早期识别和缓解电源噪声问题提供了有效手段。

Abstract: Quantitative verification can provide deep insights into reliable Network-On-Chip (NoC) designs. It is critical to understanding and mitigating operational issues caused by power supply noise (PSN) early in the design process: fluctuations in network traffic in modern NoC designs cause dramatic variations in power delivery across the network, leading to unreliability and errors in data transfers. Further complicating these challenges, NoC designs vary widely in size, usage, and implementation. This case study paper presents a principled, systematic, and modular NoC modeling approach using the Modest language that closely reflects the standard hierarchical design approach in digital systems. Using the Modest Toolset, functional and quantitative correctness was established for several NoC models, all of which were instantiated from a generic modular router model. Specifically, this work verifies the functional correctness of a generic router, inter-router communication, and the entire NoC. Statistical model checking was used to verify PSN-related properties for NoCs of size up to 8x8.

</details>


### [16] [Context-aware, Ante-hoc Explanations of Driving Behaviour](https://arxiv.org/abs/2511.14428)
*Dominik Grundt,Ishan Saxena,Malte Petersen,Bernd Westphal,Eike Möhlmann*

Main category: cs.LO

TL;DR: 提出了一种基于交通序列图的形式化方法，用于在自动驾驶车辆运行时提供上下文感知的预期/非预期驾驶操作的先验解释，通过运行时监控实现上下文识别和解释展示。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要既安全又可信才能获得社会认可，但AI驾驶功能的决策过程往往不透明，需要通过解释系统行为来提高安全性和信任度。

Method: 使用交通序列图形式化描述解释上下文和相应的(非)预期驾驶操作，通过专门的运行时监控实现上下文识别和运行时先验解释展示。

Result: 在模拟超车场景中演示了该方法，能够支持正确且良好的解释的桥接。

Conclusion: 该方法有助于提高自动驾驶系统的透明度和可信度，通过形式化的上下文建模和运行时监控实现有效的解释生成。

Abstract: Autonomous vehicles (AVs) must be both safe and trustworthy to gain social acceptance and become a viable option for everyday public transportation. Explanations about the system behaviour can increase safety and trust in AVs. Unfortunately, explaining the system behaviour of AI-based driving functions is particularly challenging, as decision-making processes are often opaque. The field of Explainability Engineering tackles this challenge by developing explanation models at design time. These models are designed from system design artefacts and stakeholder needs to develop correct and good explanations. To support this field, we propose an approach that enables context-aware, ante-hoc explanations of (un)expectable driving manoeuvres at runtime. The visual yet formal language Traffic Sequence Charts is used to formalise explanation contexts, as well as corresponding (un)expectable driving manoeuvres. A dedicated runtime monitoring enables context-recognition and ante-hoc presentation of explanations at runtime. In combination, we aim to support the bridging of correct and good explanations. Our method is demonstrated in a simulated overtaking.

</details>


### [17] [Abstract Scene Graphs: Formalizing and Monitoring Spatial Properties of Automated Driving Functions](https://arxiv.org/abs/2511.14430)
*Ishan Saxena,Bernd Westphal,Martin Fränzle*

Main category: cs.LO

TL;DR: 提出Abstract Scene Graph（ASG）形式化方法来形式化自动驾驶功能的空间属性，并开发了一个基于ASG的运行时监控框架。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶功能需要遵守复杂多样的空间属性，这些安全关键场景需要持续监控以确保合规性，因此需要形式化方法来支持自动化检查。

Method: 基于场景图（SG）构建Abstract Scene Graph（ASG）形式化方法，将空间属性形式化为ASG，并开发运行时监控框架来检查ADF系统行为是否满足ASG定义的空间属性。

Result: 展示了如何使用ASG形式化真实世界中的空间属性，并算法化地证明了ADF系统行为如何满足ASG定义的空间属性。

Conclusion: ASG为自动驾驶功能的空间属性提供了一种有效的形式化方法，支持运行时监控以确保安全合规性。

Abstract: Automated Driving Functions (ADFs) need to comply with spatial properties of varied complexity while driving on public roads. Since such situations are safety-critical in nature, it is necessary to continuously check ADFs for compliance with their spatial properties. Due to their complexity, such spatial properties need to be formalized to enable their automated checking. Scene Graphs (SGs) allow for an explicit structured representation of objects present in a traffic scene and their spatial relationships to each other. In this paper, we build upon the SG construct and propose the Abstract Scene Graph (ASG) formalism to formalize spatial properties of ADFs. We show using real-world examples how spatial properties can be formalized using ASGs. Finally, we present a framework that uses ASGs to perform Runtime Monitoring of ADFs. To this end, we also show algorithmically how a spatial property formalized as an ASG can be satisfied by ADF system behaviour.

</details>


### [18] [Safe-ROS: An Architecture for Autonomous Robots in Safety-Critical Domains](https://arxiv.org/abs/2511.14433)
*Diana C. Benjumea,Marie Farrell,Louise A. Dennis*

Main category: cs.LO

TL;DR: 提出了Safe-ROS架构，用于在安全关键领域开发可靠且可验证的自主机器人，包含智能控制系统和基于形式化验证的安全系统。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域部署自主机器人需要确保操作有效性和安全合规性的架构，特别是在核工业等严格监管环境中。

Method: 采用双子系统架构：智能控制系统负责常规操作，安全系统包含可形式化验证的安全仪表功能(SIFs)。通过认知代理实现SIF，当检测到机器人距离障碍物过近时停止机器人。

Result: 在AgileX Scout Mini机器人上成功演示了自主核环境巡检，实现了安全要求的验证、集成和部署验证。

Conclusion: Safe-ROS架构能够在安全关键领域为自主机器人提供可验证的安全监督，提供了一个可扩展到其他要求和应用的稳健框架。

Abstract: Deploying autonomous robots in safety-critical domains requires architectures that ensure operational effectiveness and safety compliance. In this paper, we contribute the Safe-ROS architecture for developing reliable and verifiable autonomous robots in such domains. It features two distinct subsystems: (1) an intelligent control system that is responsible for normal/routine operations, and (2) a Safety System consisting of Safety Instrumented Functions (SIFs) that provide formally verifiable independent oversight. We demonstrate Safe-ROS on an AgileX Scout Mini robot performing autonomous inspection in a nuclear environment. One safety requirement is selected and instantiated as a SIF. To support verification, we implement the SIF as a cognitive agent, programmed to stop the robot whenever it detects that it is too close to an obstacle. We verify that the agent meets the safety requirement and integrate it into the autonomous inspection. This integration is also verified, and the full deployment is validated in a Gazebo simulation, and lab testing. We evaluate this architecture in the context of the UK nuclear sector, where safety and regulation are crucial aspects of deployment. Success criteria include the development of a formal property from the safety requirement, implementation, and verification of the SIF, and the integration of the SIF into the operational robotic autonomous system. Our results demonstrate that the  Safe-ROS architecture can provide safety verifiable oversight while deploying autonomous robots in safety-critical domains, offering a robust framework that can be extended to additional requirements and various applications.

</details>


### [19] [Analyzing Many Simulations of Hybrid Programs in Lince](https://arxiv.org/abs/2511.14436)
*Reydel Arrieta,José Proença,Patrick Meumeu Yomsi*

Main category: cs.LO

TL;DR: 扩展Lince工具以支持多仿真变体和直方图生成，用于量化属性频率


<details>
  <summary>Details</summary>
Motivation: 混合系统在关键应用中日益重要，需要更好的仿真分析工具来验证系统属性

Method: 在Lince工具中增加多仿真变体执行机制和直方图生成功能，使用类C语言和微分方程进行系统建模

Result: 通过自适应巡航控制系统的变体案例展示了扩展Lince的功能

Conclusion: 扩展后的Lince能够有效分析混合系统属性在不同仿真变体中的频率分布

Abstract: Hybrid systems are increasingly used in critical applications such as medical devices, infrastructure systems, and autonomous vehicles. Lince is an academic tool for specifying and simulating such systems using a C-like language with differential equations. This paper presents recent experiments that enhance Lince with mechanisms for executing multiple simulation variants and generating histograms that quantify the frequency with which a given property holds. We illustrate our extended Lince using variations of an adaptive cruise control system.

</details>


### [20] [Redundancy rules for MaxSAT](https://arxiv.org/abs/2511.14657)
*Ilario Bonacina,Maria Luisa Bonet,Sam Buss,Massimo Lauria*

Main category: cs.LO

TL;DR: 本文定义了MaxSAT的结构化冗余证明系统层次结构，研究了其证明复杂性，提出了比现有方法更简单、更弱但多项式可检查的规则，并展示了与MaxSAT分辨率证明系统的集成。


<details>
  <summary>Details</summary>
Motivation: SAT中的冗余概念已证明能增强证明搜索能力，但在MaxSAT中的研究相对较少。本文旨在将SAT中的冗余证明系统（如SPR、PR、SR等）扩展到MaxSAT，建立相应的证明系统层次结构并研究其证明复杂性。

Method: 定义了MaxSAT的冗余证明系统层次结构，提出了仅使用硬子句和阻塞变量的系统，所有规则都是多项式可检查的。与现有方法相比，这些规则更简单、更弱，但可能更适合获得下界。

Result: 展示了引入系统的强度，揭示了其局限性，并给出了弱鸽巢原理$PHP^{m}_{n}$的简短cost-SR证明，证明任何赋值都会违反至少$m-n$个子句。

Conclusion: 提出的MaxSAT冗余证明系统比现有方法更易集成到当前求解器和证明检查器中，并讨论了与MaxSAT分辨率证明系统的集成可能性。

Abstract: The concept of redundancy in SAT leads to more expressive and powerful proof search techniques, e.g., able to express various inprocessing techniques, and originates interesting hierarchies of proof systems [Heule et$.$al'20, Buss-Thapen'19]. Redundancy has also been integrated in MaxSAT [Ihalainen et$.$al'22, Berg et$.$al'23, Bonacina et$.$al'24].
  In this paper, we define a structured hierarchy of redundancy proof systems for MaxSAT, with the goal of studying its proof complexity. We obtain MaxSAT variants of proof systems such as SPR, PR, SR, and others, previously defined for SAT.
  All our rules are polynomially checkable, unlike [Ihalainen et$.$al'22]. Moreover, they are simpler and weaker than [Berg et$.$al'23], and possibly amenable to lower bounds.
  This work also complements the approach of [Bonacina et$.$al'24]. Their proof systems use different rule sets for soft and hard clauses, while here we propose a system using only hard clauses and blocking variables. This is easier to integrate with current solvers and proof checkers.
  We discuss the strength of the systems introduced, we show some limitations of them, and we give a short cost-SR proof that any assignment for the weak pigeonhole principle $PHP^{m}_{n}$ falsifies at least $m-n$ clauses.
  We conclude by discussing the integration of our rules with the MaxSAT resolution proof system, which is a commonly studied proof system for MaxSAT.

</details>
