<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 27]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [High-Performance Generation of Constrained Input](https://arxiv.org/abs/2511.05987)
*Addison Crump,Alexi Turcotte,José Antonio Zamudio Amaya,Andreas Zeller*

Main category: cs.SE

TL;DR: 本文提出了一种新的进化语言测试方法FANDANGO-RS，通过将语法定义转换为Rust类型和使用改进的进化算法，将性能提升了3-4个数量级，能够快速生成复杂的测试输入。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语言的测试方法在处理复杂约束时性能不佳，SMT求解器速度慢，进化算法难以处理编译器测试等领域的复杂约束。

Method: 1) 将语法定义转换为Rust类型和trait实现，让编译器最大化优化语法操作；2) 使用改进的进化算法来更好地解决复杂约束系统。

Result: FANDANGO-RS原型系统性能比现有技术提升了3-4个数量级，生成时间从小时级减少到秒级，能够每分钟生成401个多样化、复杂且有效的C编译器测试输入。

Conclusion: 该方法在性能和算法上的改进使得FANDANGO-RS能够处理先前策略无法解决的约束，为编译器测试等复杂领域提供了高效的测试输入生成方案。

Abstract: Language-based testing combines context-free grammar definitions with semantic constraints over grammar elements to generate test inputs. By pairing context-free grammars with constraints, users have the expressiveness of unrestricted grammars while retaining simple structure. However, producing inputs in the presence of such constraints can be challenging. In past approaches, SMT solvers have been found to be very slow at finding string solutions; evolutionary algorithms are faster and more general, but current implementations still struggle with complex constraints that would be required for domains such as compiler testing. In this paper, we present a novel approach for evolutionary language-based testing that improves performance by 3-4 orders of magnitude over the current state of the art, reducing hours of generation and constraint solving time to seconds. We accomplish this by (1) carefully transforming grammar definitions into Rust types and trait implementations, ensuring that the compiler may near-maximally optimize arbitrary operations on arbitrary grammars; and (2) using better evolutionary algorithms that improve the ability of language-based testing to solve complex constraint systems. These performance and algorithmic improvements allow our prototype, FANDANGO-RS, to solve constraints that previous strategies simply cannot handle. We demonstrate this by a case study for a C subset, in which FANDANGO-RS is able to generate 401 diverse, complex, and valid test inputs for a C compiler per minute.

</details>


### [2] [LLMs as Packagers of HPC Software](https://arxiv.org/abs/2511.05626)
*Caetano Melone,Daniel Nichols,Konstantinos Parasyris,Todd Gamblin,Harshitha Menon*

Main category: cs.SE

TL;DR: SpackIt框架通过结合仓库分析、相关示例检索和基于诊断反馈的迭代优化，将HPC软件包安装成功率从20%提升到80%以上，解决了手动维护Spack构建配方的挑战。


<details>
  <summary>Details</summary>
Motivation: HPC软件生态系统日益复杂，包含数百个依赖包，每个都有不同的构建系统和依赖约束。虽然Spack等工具可以自动化依赖解析和环境管理，但依赖手动编写的构建配方，维护成本高昂。

Method: 开发了SpackIt端到端框架，结合仓库分析、相关示例检索和基于诊断反馈的迭代优化方法，对308个开源HPC软件包进行系统评估。

Result: 在最佳配置下，SpackIt将安装成功率从零样本设置的20%提高到80%以上，证明了检索和结构化反馈在可靠包合成中的价值。

Conclusion: SpackIt框架通过上下文增强和迭代优化，显著提高了LLM生成Spack配方的准确性和可靠性，为自动化HPC软件包管理提供了有效解决方案。

Abstract: High performance computing (HPC) software ecosystems are inherently heterogeneous, comprising scientific applications that depend on hundreds of external packages, each with distinct build systems, options, and dependency constraints. Tools such as Spack automate dependency resolution and environment management, but their effectiveness relies on manually written build recipes. As these ecosystems grow, maintaining existing specifications and creating new ones becomes increasingly labor-intensive. While large language models (LLMs) have shown promise in code generation, automatically producing correct and maintainable Spack recipes remains a significant challenge. We present a systematic analysis of how LLMs and context-augmentation methods can assist in the generation of Spack recipes. To this end, we introduce SpackIt, an end-to-end framework that combines repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback. We apply SpackIt to a representative subset of 308 open-source HPC packages to assess its effectiveness and limitations. Our results show that SpackIt increases installation success from 20% in a zero-shot setting to over 80% in its best configuration, demonstrating the value of retrieval and structured feedback for reliable package synthesis.

</details>


### [3] [Accelerating Control Systems with GitOps: A Path to Automation and Reliability](https://arxiv.org/abs/2511.05663)
*M. Gonzalez,M. Acosta*

Main category: cs.SE

TL;DR: GitOps作为现代化基础设施的基础方法，通过将Git作为声明性配置的单一事实来源，实现完全自动化、可审计和版本控制的基础设施管理。


<details>
  <summary>Details</summary>
Motivation: 云原生和容器化环境正在改变生态系统，不仅影响IT行业，也影响计算科学领域。ACORN项目旨在现代化费米实验室的控制系统基础设施和软件。

Method: 实施经过验证的最佳实践和尖端技术标准，包括GitOps、容器化、基础设施即代码和现代化数据管道，用于控制系统数据采集和AI/ML集成。

Result: GitOps能够转变传统控制系统基础设施、服务和应用程序，实现完全自动化、可审计和版本控制的基础设施管理。

Conclusion: GitOps是现代化基础设施管理的关键方法，特别适用于加速器/科学设施的控制系统现代化。

Abstract: GitOps is a foundational approach for modernizing infrastructure by leveraging Git as the single source of truth for declarative configurations. The poster explores how GitOps transforms traditional control system infrastructure, services and applications by enabling fully automated, auditable, and version-controlled infrastructure management. Cloud-native and containerized environments are shifting the ecosystem not only in the IT industry but also within the computational science field, as is the case of CERN [1] and Diamond Light Source [2] among other Accelerator/Science facilities which are slowly shifting towards modern software and infrastructure paradigms. The ACORN project, which aims to modernize Fermilab's control system infrastructure and software is implementing proven best-practices and cutting-edge technology standards including GitOps, containerization, infrastructure as code and modern data pipelines for control system data acquisition and the inclusion of AI/ML in our accelerator complex.

</details>


### [4] [An Empirical Study of Java Code Improvements Based on Stack Overflow Answer Edits](https://arxiv.org/abs/2511.05813)
*In-on Wiratsin,Chaiyong Ragkhitwetsagul,Matheus Paixao,Denis De Sousa,Pongpop Lapvikai,Peter Haddawy*

Main category: cs.SE

TL;DR: 对Stack Overflow Java答案编辑进行实证研究，分析代码改进在开源项目中的应用效果。研究发现49.24%的代码片段可应用于开源项目，11个基于编辑的bug修复建议被项目维护者接受。


<details>
  <summary>Details</summary>
Motivation: 软件开发中普遍存在次优代码，导致高昂维护成本和技术债务。开发者常参考Stack Overflow等知识库，但其内容不断演进，需要研究如何利用这些编辑改进实际项目代码。

Method: 使用改进的代码克隆搜索工具分析SO Java答案版本历史，应用于10,668个GitHub Java项目。手动分类SO答案编辑，向开源项目创建包含代码改进建议的pull request。

Result: 6.91%的SO Java接受答案有多个修订版本（平均2.82个）。49.24%的代码片段可应用于开源项目，36个基于编辑的bug修复建议中有11个被项目维护者接受。

Conclusion: SO答案编辑是宝贵的代码改进资源，可有效识别和修复开源项目中的过时或未优化代码，显著提升代码质量。

Abstract: Suboptimal code is prevalent in software systems. Developers often write low-quality code due to factors like technical knowledge gaps, insufficient experience, time pressure, management decisions, or personal factors. Once integrated, the accumulation of this suboptimal code leads to significant maintenance costs and technical debt.
  Developers frequently consult external knowledge bases, such as API documentation and Q&A websites like Stack Overflow (SO), to aid their programming tasks. SO's crowdsourced, collaborative nature has created a vast repository of programming knowledge. Its community-curated content is constantly evolving, with new answers posted or existing ones edited.
  In this paper, we present an empirical study of SO Java answer edits and their application to improving code in open-source projects. We use a modified code clone search tool to analyze SO code snippets with version history and apply it to open-source Java projects. This identifies outdated or unoptimized code and suggests improved alternatives. Analyzing 140,840 Java accepted answers from SOTorrent and 10,668 GitHub Java projects, we manually categorized SO answer edits and created pull requests to open-source projects with the suggested code improvements. Our results show that 6.91% of SO Java accepted answers have more than one revision (average of 2.82). Moreover, 49.24% of the code snippets in the answer edits are applicable to open-source projects, and 11 out of 36 proposed bug fixes based on these edits were accepted by the GitHub project maintainers.

</details>


### [5] [WAR-Re: Web API Recommendation with Semantic Reasoning](https://arxiv.org/abs/2511.05820)
*Zishuo Xu,Dezhong Yao,Yao Wan*

Main category: cs.SE

TL;DR: WAR-Re是一个基于LLM的Web API推荐模型，通过语义推理提供推荐理由，解决了传统方法无法适应不同mashup的API数量需求且缺乏解释性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Web API推荐方法存在两个关键挑战：1)固定的top-N推荐无法适应不同mashup的API数量需求；2)方法只输出排名列表而不提供推荐理由，用户无法理解推荐依据。

Method: 使用特殊开始和停止标记处理第一个挑战，采用两阶段训练：监督微调和通过GRPO的强化学习，增强模型在推荐和推理两个任务上的能力。

Result: 在ProgrammableWeb数据集上的实验表明，WAR-Re在推荐准确率上比最先进的基线模型提升高达21.59%，同时能持续产生高质量的语义推荐理由。

Conclusion: WAR-Re有效解决了Web API推荐中的灵活性和可解释性问题，在推荐准确性和语义推理质量方面都表现出色。

Abstract: With the development of cloud computing, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Despite the demonstrated success of previous Web API recommendation solutions, two critical challenges persist: 1) a fixed top-N recommendation that cannot accommodate the varying API cardinality requirements of different mashups, and 2) these methods output only ranked API lists without accompanying reasons, depriving users of understanding the recommendation. To address these challenges, we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification. WAR-Re leverages special start and stop tokens to handle the first challenge and uses two-stage training: supervised fine-tuning and reinforcement learning via Group Relative Policy Optimization (GRPO) to enhance the model's ability in both tasks. Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59\% over the state-of-the-art baseline model in recommendation accuracy, while consistently producing high-quality semantic reasons for recommendations.

</details>


### [6] [ZeroLog: Zero-Label Generalizable Cross-System Log-based Anomaly Detection](https://arxiv.org/abs/2511.05862)
*Xinlong Zhao,Tong Jia,Minghua He,Ying Li,Gang Huang*

Main category: cs.SE

TL;DR: ZeroLog是一种零标签跨系统日志异常检测方法，通过元学习和无监督域适应实现无需目标系统标签的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有跨系统日志异常检测方法仍需要目标系统的部分标签数据，但在实际场景中获取目标系统标签数据困难，因此研究零标签条件下的跨系统检测具有重要意义。

Method: 采用无监督域适应进行源域和目标域之间的对抗训练，学习系统无关的通用特征表示；通过元学习进一步泛化到目标系统，无需任何目标标签。

Result: 在三个公共日志数据集上的实验表明，ZeroLog在无标签情况下达到80%以上的F1分数，与使用标签的最先进跨系统方法相当，且在零标签条件下优于现有方法。

Conclusion: ZeroLog证明了在零标签条件下实现有效跨系统日志异常检测的可行性，为实际部署提供了实用解决方案。

Abstract: Log-based anomaly detection is an important task in ensuring the stability and reliability of software systems. One of the key problems in this task is the lack of labeled logs. Existing works usually leverage large-scale labeled logs from mature systems to train an anomaly detection model of a target system based on the idea of transfer learning. However, these works still require a certain number of labeled logs from the target system. In this paper, we take a step forward and study a valuable yet underexplored setting: zero-label cross-system log-based anomaly detection, that is, no labeled logs are available in the target system. Specifically, we propose ZeroLog, a system-agnostic representation meta-learning method that enables cross-system log-based anomaly detection under zero-label conditions. To achieve this, we leverage unsupervised domain adaptation to perform adversarial training between the source and target domains, aiming to learn system-agnostic general feature representations. By employing meta-learning, the learned representations are further generalized to the target system without any target labels. Experimental results on three public log datasets from different systems show that ZeroLog reaches over 80% F1-score without labels, comparable to state-of-the-art cross-system methods trained with labeled logs, and outperforms existing methods under zero-label conditions.

</details>


### [7] [Generality Is Not Enough: Zero-Label Cross-System Log-Based Anomaly Detection via Knowledge-Level Collaboration](https://arxiv.org/abs/2511.05882)
*Xinlong Zhao,Tong Jia,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: GeneralLog是一种新颖的LLM-小模型协作方法，用于零标签跨系统日志异常检测，通过动态路由未标记日志，让LLM处理专有日志，小模型处理通用日志，在完全零标签设置下实现超过90%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决跨系统日志异常检测中标签稀缺的问题，现有方法在零标签设置下存在局限性：小模型方法忽略目标系统专有知识，LLM方法依赖少量正例且推理成本高。

Method: 提出GeneralLog方法，动态路由未标记日志，LLM处理专有日志，小模型处理通用日志，实现无需目标系统标签的跨系统泛化。

Result: 在三个公共日志数据集上的实验表明，GeneralLog在完全零标签设置下达到超过90%的F1分数，显著优于现有方法。

Conclusion: GeneralLog通过LLM与小模型的智能协作，有效解决了零标签跨系统日志异常检测问题，具有优异的性能和实用性。

Abstract: Log-based anomaly detection is crucial for ensuring software system stability. However, the scarcity of labeled logs limits rapid deployment to new systems. Cross-system transfer has become an important research direction. State-of-the-art approaches perform well with a few labeled target logs, but limitations remain: small-model methods transfer general knowledge but overlook mismatches with the target system's proprietary knowledge; LLM-based methods can capture proprietary patterns but rely on a few positive examples and incur high inference cost. Existing LLM-small model collaborations route 'simple logs' to the small model and 'complex logs' to the LLM based on output uncertainty. In zero-label cross-system settings, supervised sample complexity is unavailable, and such routing does not consider knowledge separation. To address this, we propose GeneralLog, a novel LLM-small model collaborative method for zero-label cross-system log anomaly detection. GeneralLog dynamically routes unlabeled logs, letting the LLM handle 'proprietary logs' and the small model 'general logs,' enabling cross-system generalization without labeled target logs. Experiments on three public log datasets show that GeneralLog achieves over 90% F1-score under a fully zero-label setting, significantly outperforming existing methods.

</details>


### [8] [SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?](https://arxiv.org/abs/2511.06090)
*Jeffrey Jian Ma,Milad Hashemi,Amir Yazdanbakhsh,Kevin Swersky,Ofir Press,Enhui Li,Vijay Janapa Reddi,Parthasarathy Ranganathan*

Main category: cs.SE

TL;DR: SWE-fficiency是一个评估仓库级性能优化的基准测试，包含498个真实数据科学、机器学习和HPC仓库的性能优化任务，要求智能体分析代码语义、定位瓶颈并生成能匹配专家加速效果的正确补丁。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试大多关注修复什么代码，而非如何修复代码，缺乏对性能优化过程的评估。需要专门评估智能体在真实仓库中进行性能优化的能力。

Method: 通过自动化流水线从GitHub拉取请求中收集性能改进编辑，结合关键词过滤、静态分析、覆盖率工具和执行验证来确认专家加速基准和识别相关单元测试。

Result: 对最先进智能体的实证评估显示显著性能不足，平均仅达到专家加速效果的0.15倍，智能体在定位优化机会、跨函数执行推理和保持编辑正确性方面存在困难。

Conclusion: SWE-fficiency基准测试和配套数据流水线将促进自动化性能工程和长周期软件推理的研究，揭示了当前智能体在性能优化任务上的局限性。

Abstract: Optimizing the performance of large-scale software repositories demands expertise in code reasoning and software engineering (SWE) to reduce runtime while preserving program correctness. However, most benchmarks emphasize what to fix rather than how to fix code. We introduce \textsc{SWE-fficiency}, a benchmark for evaluating repository-level performance optimization on real workloads. Our suite contains 498 tasks across nine widely used data-science, machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a complete codebase and a slow workload, an agent must investigate code semantics, localize bottlenecks and relevant tests, and produce a patch that matches or exceeds expert speedup while passing the same unit tests. To enable this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests for performance-improving edits, combining keyword filtering, static analysis, coverage tooling, and execution validation to both confirm expert speedup baselines and identify relevant repository unit tests. Empirical evaluation of state-of-the-art agents reveals significant underperformance. On average, agents achieve less than 0.15x the expert speedup: agents struggle in localizing optimization opportunities, reasoning about execution across functions, and maintaining correctness in proposed edits. We release the benchmark and accompanying data pipeline to facilitate research on automated performance engineering and long-horizon software reasoning.

</details>


### [9] [Quality in model-driven engineering: a tertiary study](https://arxiv.org/abs/2511.06103)
*Miguel Goulão,Vasco Amaral,Marjan Mernik*

Main category: cs.SE

TL;DR: 该论文通过三级研究综述了模型驱动工程(MDE)对软件质量的影响，发现可维护性是MDE最常研究的质量属性，但现有研究多为映射型而非实证比较，且对使用质量的关注较少。


<details>
  <summary>Details</summary>
Motivation: MDE对软件质量的影响证据分散在不同文献中，研究人员和从业者难以获取整合信息。本文旨在汇总MDE质量相关的研究发现，帮助了解现有研究覆盖范围和主要发现，并识别需要进一步关注的研究空白。

Method: 对MDE质量进行三级研究，识别了22篇系统文献综述和映射研究，分析这些研究中涉及的主要质量属性。

Result: 可维护性是MDE最常研究和报告的质量属性。83个研究问题中有80个是映射现有研究的结构，而非比较具体MDE方法对特定质量属性的影响。研究覆盖了软件产品质量的广泛方面，但普遍指出需要更多实证研究验证现有主张。

Conclusion: MDE对软件质量的影响研究主要集中在可维护性上，现有研究多为映射型而非实证比较，且对MDE开发产品的使用质量关注相对较少，需要更多实证研究来验证现有主张。

Abstract: Model-driven engineering (MDE) is believed to have a significant impact in software quality. However, researchers and practitioners may have a hard time locating consolidated evidence on this impact, as the available information is scattered in several different publications. Our goal is to aggregate consolidated findings on quality in MDE, facilitating the work of researchers and practitioners in learning about the coverage and main findings of existing work as well as identifying relatively unexplored niches of research that need further attention. We performed a tertiary study on quality in MDE, in order to gain a better understanding of its most prominent findings and existing challenges, as reported in the literature. We identified 22 systematic literature reviews and mapping studies and the most relevant quality attributes addressed by each of those studies, in the context of MDE. Maintainability is clearly the most often studied and reported quality attribute impacted by MDE. Eighty out of 83 research questions in the selected secondary studies have a structure that is more often associated with mapping existing research than with answering more concrete research questions (e.g., comparing two alternative MDE approaches with respect to their impact on a specific quality attribute). We briefly outline the main contributions of each of the selected literature reviews. In the collected studies, we observed a broad coverage of software product quality, although frequently accompanied by notes on how much more empirical research is needed to further validate existing claims. Relatively, little attention seems to be devoted to the impact of MDE on the quality in use of products developed using MDE.

</details>


### [10] [On the impact of semantic transparency on understanding and reviewing social goal models](https://arxiv.org/abs/2511.06110)
*Mafalda Santos,Catarina Gralha,Miguel Goulão,João Araújo,Ana Moreira*

Main category: cs.SE

TL;DR: 评估语义透明度对i*模型理解和评审的影响，发现替代语法虽未提高准确性和速度，但显著降低了视觉努力


<details>
  <summary>Details</summary>
Motivation: i*语言在需求工程研究中影响重大，但由于复杂性和工业采用率低，成为改进其具体语法和利益相关者理解能力的研究对象

Method: 通过准实验比较标准i*语法与语义透明度更高的替代语法，57名新手参与者执行理解和评审任务，使用眼动追踪和参与者反馈测量准确性、速度和易用性

Result: 未发现替代语法提高准确性或速度的证据，参与者感知易用性相似，但使用替代语法时对模型和语言键的视觉努力显著降低

Conclusion: 模型和语言键提供的上下文可能缓解了先前研究中报告的i*符号识别缺陷，但替代语法显著降低了视觉努力

Abstract: Context: i* is one of the most influential languages in the Requirements Engineering research community. Perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models.
  Objectives: We evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. Methods: We performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. We asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback.
  Results: We found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. Although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax.
  Conclusions: The context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. However, the alternative concrete syntax required a significantly lower visual effort.

</details>


### [11] [The Lifecycle Workbench - A Configurable Framework for Digitized Product Maintenance Services](https://arxiv.org/abs/2511.06149)
*Dominique Briechle,Mohammed Fahad Ali,Marit Briechle-Mathiszig,Tobias Geger,Robert Werner,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文提出了生命周期工作台（LCW）生态系统，通过数字表示来提高循环经济中服务定价的可靠性和产品状态评估，解决当前服务执行中的弱点。


<details>
  <summary>Details</summary>
Motivation: 全球电子产品生产达到历史新高，导致负面环境和健康影响以及自然资源持续枯竭。循环经济系统提供了重新分配全球资源和产品使用的选择，但用户因成本不确定性而回避使用可持续服务，服务提供商也因无法预先检测产品状态而面临经济风险。

Method: 作者提出了生命周期工作台（LCW）生态系统，该生态系统采用数字表示来增强服务定价的可靠性，并改进循环经济领域中物品、组件和部件的状态评估。

Result: LCW生态系统能够解决当前服务执行中的关键弱点，包括服务定价的不确定性和产品状态评估的困难，从而提高循环经济服务的可靠性和可行性。

Conclusion: 通过实施LCW生态系统，可以显著提高循环经济服务的可靠性，降低用户和服务提供商的风险，从而促进更可持续的产品生命周期管理实践。

Abstract: The global production of electric goods is at an all-time high, causing negative environmental and health impacts as well as a continuing depletion of natural resources. Considering the worsening global climate change, a transition of current industrial processes is necessary to tackle the above-mentioned factors. To address this urgent issue, socio-economic systems like the Circular Economy (CE) provide options to reallocate the use of resources and products on a global scale. Especially in terms of product lifecycle-prolonging, this system provides suitable approaches to alter the current modes of product handling by society and industry alike, based on the condition of the products. Although the importance and benefits of sustainable services enabling these options are widely known, users tend to shy away from using them. One of the reasons is the missing reliability in terms of the knowledge of the costs associated with a particular service. This uncertainty in expected pricing can, therefore, lower the willingness of potential clients. However, not only clients struggle with the boundary conditions of such services. On the part of the potential providers of services, the monetary risk is often caused by the incapability to detect the condition of a product in advance. This can result on the provider side in a severe economic loss if this possibility is not covered by the service price or through the mass of items, which could allow equalization of serval service operations. To address these weak points in current service execution, the authors propose the \textit{Lifecycle Workbench (LCW)}-ecosystem, which features digital representations to enhance the reliability of service pricing as well as the assessment of the condition of items, assemblies, and parts in the Circular Economy domain.

</details>


### [12] [Diagnosing and Resolving Android Applications Building Issues: An Empirical Study](https://arxiv.org/abs/2511.06186)
*Lakshmi Priya Bodepudi,Yutong Zhao,Ming Quan Fu,Yuanyuan Wu,Sen He,Yu Zhao*

Main category: cs.SE

TL;DR: 对200个开源Android项目进行实证分析，识别并修复构建失败问题，使用五阶段流程诊断和解决构建错误，显著降低故障排除工作量。


<details>
  <summary>Details</summary>
Motivation: Android应用构建面临复杂依赖、多样化配置和快速演进的生态系统挑战，需要系统化的构建失败诊断和修复方法。

Method: 采用五阶段流程：数据收集、构建执行、失败分类、修复策略设计和LLM辅助评估，分析Java和Kotlin项目中的构建错误。

Result: 在135个初始构建失败的项目中，成功修复102个（75.56%）；LLM辅助诊断达到53.3%的成功率；项目语言、年龄和大小影响构建成功率。

Conclusion: 研究为改进Android构建可靠性提供了实用见解，并推进了AI辅助软件维护的发展。

Abstract: Building Android applications reliably remains a persistent challenge due to complex dependencies, diverse configurations, and the rapid evolution of the Android ecosystem. This study conducts an empirical analysis of 200 open-source Android projects written in Java and Kotlin to diagnose and resolve build failures. Through a five-phase process encompassing data collection, build execution, failure classification, repair strategy design, and LLM-assisted evaluation, we identified four primary types of build errors: environment issues, dependency and Gradle task errors, configuration problems, and syntax/API incompatibilities. Among the 135 projects that initially failed to build, our diagnostic and repair strategy enabled developers to resolve 102 cases (75.56%), significantly reducing troubleshooting effort. We further examined the potential of Large Language Models, such as GPT-5, to assist in error diagnosis, achieving a 53.3% success rate in suggesting viable fixes. An analysis of project attributes revealed that build success is influenced by programming language, project age, and app size. These findings provide practical insights into improving Android build reliability and advancing AI-assisted software maintenance.

</details>


### [13] [Assertion-Aware Test Code Summarization with Large Language Models](https://arxiv.org/abs/2511.06227)
*Anamul Haque Mollah,Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文研究了如何通过LLM生成单元测试摘要，发现使用断言语义作为提示比完整方法上下文效果更好，且所需输入token更少。Codex和Qwen-Coder表现最佳。


<details>
  <summary>Details</summary>
Motivation: 单元测试通常缺乏简洁的摘要来说明测试意图，特别是在自动生成或文档不完善的代码库中。LLM提供了有前景的解决方案，但其效果高度依赖于提示方式。

Method: 创建包含91个真实Java测试用例的基准数据集，进行受控消融研究，评估四种代码LLM在七种提示配置下的表现，使用n-gram指标、语义相似度和LLM评估。

Result: 使用断言语义作为提示比完整方法上下文平均提高摘要质量0.10分（2.3%），同时需要更少的输入token。Codex和Qwen-Coder与人工编写摘要的匹配度最高。

Conclusion: 断言语义是生成高质量测试摘要的有效提示策略，在减少输入需求的同时提高质量。Codex和Qwen-Coder在测试代码摘要任务中表现优异。

Abstract: Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than im- plementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with as- sertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550

</details>


### [14] [WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation](https://arxiv.org/abs/2511.06251)
*Mingde Xu,Zhen Yang,Wenyi Hong,Lihang Pan,Xinyue Fan,Yan Wang,Xiaotao Gu,Bin Xu,Jie Tang*

Main category: cs.SE

TL;DR: WebVIA是一个首个用于交互式UI到代码生成的代理框架，包含探索代理、UI2Code模型和验证模块，能够生成可执行的交互式代码并验证其交互性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型只能生成静态的HTML/CSS/JavaScript布局，缺乏交互性，而UI开发需要将设计稿转换为功能代码，这个过程仍然重复且劳动密集。

Method: 提出WebVIA框架，包含三个组件：1)探索代理捕获多状态UI截图；2)UI2Code模型生成可执行的交互式代码；3)验证模块验证交互性。

Result: WebVIA-Agent比通用代理（如Gemini-2.5-Pro）实现更稳定准确的UI探索，微调的WebVIA-UI2Code模型在生成可执行交互式代码方面显著优于基础模型。

Conclusion: WebVIA框架成功解决了交互式UI到代码生成的挑战，在交互性和静态UI2Code基准测试中都表现出色。

Abstract: User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\texttt{https://webvia.github.io}}.

</details>


### [15] [State of the Art on Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06352)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 介绍博士研究基础概念和相关研究


<details>
  <summary>Details</summary>
Motivation: 为不确定性及风险感知适应的博士研究奠定基础

Method: 引入基本概念并讨论相关研究

Result: 建立了研究基础框架

Conclusion: 为后续不确定性及风险感知适应研究提供了理论支撑

Abstract: In this essay, we introduce the basic concepts necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation, and discuss relevant related research.

</details>


### [16] [Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges](https://arxiv.org/abs/2511.06362)
*Anastasiia Birillo,Aleksei Rostovskii,Yaroslav Golubev,Hieke Keuning*

Main category: cs.SE

TL;DR: 本研究分析了学生在IDE学习环境中与AI驱动的下一步提示系统的交互行为，通过过程挖掘识别了16种常见交互场景，并揭示了学生处理无用提示的策略。


<details>
  <summary>Details</summary>
Motivation: 自动反馈生成在计算机科学教育中对于提升个性化学习体验至关重要，其中下一步提示反馈尤为重要，因为它能为学生提供解决编程任务的可操作步骤。

Method: 收集了34名学生解决Kotlin任务的详细提示交互日志数据集，应用过程挖掘技术识别交互模式，并对6名学生进行半结构化访谈。

Result: 识别出16种常见交互场景，访谈揭示了学生处理无用提示的策略，如调整部分提示或修改代码以生成相同提示的变体。

Conclusion: 这些发现结合公开数据集为未来研究提供了宝贵机会，并为改进提示设计以增强学习支持提供了关键见解。

Abstract: Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.

</details>


### [17] [Methodological Considerations for Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06367)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 该论文概述了为博士研究奠定方法论基础的必要考虑因素


<details>
  <summary>Details</summary>
Motivation: 为关于不确定性和风险感知适应的博士研究建立方法论基础

Method: 概述方法论考虑因素，为研究奠定基础

Result: 提供了方法论框架，但尚未展示具体研究结果

Conclusion: 为后续的博士研究建立了方法论基础

Abstract: In this essay, we provide an overview of methodological considerations necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation.

</details>


### [18] [Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective](https://arxiv.org/abs/2511.06428)
*Samuel Ferino,Rashina Hoda,John Grundy,Christoph Treude*

Main category: cs.SE

TL;DR: 该研究通过22次访谈分析了LLMs对软件开发的影响，识别了在个体、团队、组织和社会层面的利弊，并提出了采用LLMs的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究开始调查LLMs对软件开发的感知影响，但需要实证研究来理解如何平衡使用LLMs的前向和后向效应。

Method: 在2024年10月至2025年9月期间进行了3轮数据收集和分析，采用社会技术扎根理论(STGT)对22名软件从业者的访谈数据进行分析。

Result: 识别了使用LLMs的益处（如维护开发流程、改善开发者心智模型、促进创业）和劣势（如对开发者个性的负面影响、损害开发者声誉），以及在个体、团队、组织和社会层面的影响。

Conclusion: 提出了软件从业者、团队和组织在使用LLMs时面临的权衡，研究结果对软件团队领导和IT经理评估LLMs在其特定环境中的可行性特别有用。

Abstract: Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.

</details>


### [19] [Automatically Identifying Solution-Related Content in Issue Report Discussions with Language Models](https://arxiv.org/abs/2511.06501)
*Antu Saha,Mehedi Sun,Oscar Chaparro*

Main category: cs.SE

TL;DR: 该论文提出使用语言模型自动识别问题报告中的解决方案相关内容，通过比较嵌入、提示和微调三种方法在传统机器学习模型、预训练语言模型和大语言模型上的表现，发现微调的大语言模型效果最佳。


<details>
  <summary>Details</summary>
Motivation: 在问题解决过程中，开发者需要从冗长的问题讨论中手动识别解决方案相关内容，这个过程既困难又耗时，因此需要自动化方法来提高效率。

Method: 使用356个Mozilla Firefox问题创建数据集，训练和评估六种传统机器学习模型、四种预训练语言模型和两种大语言模型，共68种配置，比较嵌入、提示和微调三种应用方法。

Result: 结果显示：使用LLM嵌入的传统机器学习模型优于TF-IDF特征，提示方法表现不佳，微调的LLM达到最高性能（LLAMAft F1分数0.716），最佳模型集成后进一步提升至0.737 F1分数。

Conclusion: 微调的大语言模型在解决方案识别任务中表现最佳，模型在不同项目间具有可迁移性，少量项目特定数据可进一步提升性能，该工作有助于软件维护、问题理解和解决方案重用。

Abstract: During issue resolution, software developers rely on issue reports to discuss solutions for defects, feature requests, and other changes. These discussions contain proposed solutions-from design changes to code implementations-as well as their evaluations. Locating solution-related content is essential for investigating reopened issues, addressing regressions, reusing solutions, and understanding code change rationale. Manually understanding long discussions to identify such content can be difficult and time-consuming.
  This paper automates solution identification using language models as supervised classifiers. We investigate three applications-embeddings, prompting, and fine-tuning-across three classifier types: traditional ML models (MLMs), pre-trained language models (PLMs), and large language models (LLMs). Using 356 Mozilla Firefox issues, we created a dataset to train and evaluate six MLMs, four PLMs, and two LLMs across 68 configurations.
  Results show that MLMs with LLM embeddings outperform TF-IDF features, prompting underperforms, and fine-tuned LLMs achieve the highest performance, with LLAMAft reaching 0.716 F1 score. Ensembles of the best models further improve results (0.737 F1). Misclassifications often arise from misleading clues or missing context, highlighting the need for context-aware classifiers. Models trained on Mozilla transfer to other projects, with a small amount of project-specific data, further enhancing results. This work supports software maintenance, issue understanding, and solution reuse.

</details>


### [20] [LLM For Loop Invariant Generation and Fixing: How Far Are We?](https://arxiv.org/abs/2511.06552)
*Mostafijur Rahman Akhond,Saikat Chakraborty,Gias Uddin*

Main category: cs.SE

TL;DR: LLMs在推断循环不变式方面有一定能力，但需要辅助信息（如领域知识和示例）来显著提升性能，生成成功率最高78%，修复成功率仅16%。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在推断循环不变式方面的能力，这是自动化程序安全评估的关键步骤，但目前缺乏相关研究。

Method: 对开源和闭源的不同规模LLMs进行实证研究，评估它们在推断归纳循环不变式和修复不正确不变式方面的表现。

Result: LLMs在推断循环不变式方面表现出一定效用，但在补充领域知识和示例等辅助信息后性能显著提升；生成成功率最高78%，修复成功率仅16%。

Conclusion: LLMs在循环不变式推断和修复方面具有潜力，但需要额外的辅助信息支持才能发挥更好的性能。

Abstract: A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\% in generating, but are limited to 16\% in repairing the invariant.

</details>


### [21] [PhaseSeed: Precise Call Graph Construction for Split-Phase Applications using Dynamic Seeding](https://arxiv.org/abs/2511.06661)
*Tapti Palit,Seyedhamed Ghavamnia,Michalis Polychronakis*

Main category: cs.SE

TL;DR: PhaseSeed是一种提高分阶段应用程序指针分析精度的新技术，通过动态分析初始化阶段收集运行时指向关系，然后将其作为静态分析的种子信息，显著提升了多种安全机制的精度。


<details>
  <summary>Details</summary>
Motivation: 传统静态指针分析技术在构建应用程序调用图时存在精度不足的问题，这些技术对应用程序架构不敏感，设计用于广泛适用性。

Method: PhaseSeed动态分析应用程序的初始化阶段，收集运行时建立的指向关系，在初始化阶段结束后将这些信息作为种子提供给静态分析阶段，对处理阶段保持作用域的代码进行指针分析。

Result: PhaseSeed相比静态调用图构建技术，为控制流完整性提供了高达92.6%的精度提升，在生成Seccomp配置文件时过滤了9个额外的安全关键系统调用。

Conclusion: PhaseSeed通过结合动态和静态分析，显著提高了分阶段应用程序指针分析的精度，为多种安全机制提供了更准确的基础。

Abstract: Precise and sound call graph construction is crucial for many software security mechanisms. Unfortunately, traditional static pointer analysis techniques used to generate application call graphs suffer from imprecision. These techniques are agnostic to the application's architecture and are designed for broad applicability. To mitigate this precision problem, we propose PhaseSeed, a novel technique that improves the accuracy of pointer analysis for split-phase applications, which have distinct initialization and processing phases. PhaseSeed analyzes the initialization phase dynamically, collecting the points-to relationships established at runtime. At the end of the initialization phase, it then seeds this information to a static analysis stage that performs pointer analysis for all code that stays in scope during the processing phase, improving precision. Our observations show that, given the same runtime configuration options, the points-to relationships established during the initialization phase remain constant across multiple runs. Therefore, PhaseSeed is sound with respect to a given initial configuration. We apply PhaseSeed to three security mechanisms: control flow integrity (CFI), software debloating, and system call filtering. PhaseSeed provides up to 92.6% precision improvement for CFI compared to static call graph construction techniques, and filters nine additional security-critical system calls when used to generate Seccomp profiles.

</details>


### [22] [Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture](https://arxiv.org/abs/2511.06701)
*Karen Sargsyan*

Main category: cs.SE

TL;DR: 提出了一种用于自动化研究系统的函数式架构，通过Research单子强制实施顺序统计协议，防止LLM驱动的AI科学家产生虚假发现。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的自动化研究系统在动态假设检验中可能产生虚假发现，需要强制性的统计严谨性保障。

Method: 使用Haskell eDSL创建Research单子，通过单子变换器栈强制执行顺序统计协议（如在线FDR控制），并采用声明式脚手架生成刚性约束框架。

Result: 通过大规模模拟（N=2000个假设）和端到端案例研究验证了该方法，证明其能够有效保护自动化科学的完整性。

Conclusion: 该方法为自动化科学研究提供了深度防御机制，能够结构性地防止方法学错误如数据泄露。

Abstract: Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.

</details>


### [23] [Minimizing Breaking Changes and Redundancy in Mitigating Technical Lag for Java Projects](https://arxiv.org/abs/2511.06762)
*Rui Lu,Lyuye Zhang,Kaixuan Li,Min Zhang,Yixiang Chen*

Main category: cs.SE

TL;DR: DepUpdater是一个自动化依赖升级工具，旨在最小化技术滞后，同时避免兼容性问题和冗余依赖。


<details>
  <summary>Details</summary>
Motivation: 开源软件重用虽然能避免重复造轮子，但过时的依赖会带来技术滞后、安全漏洞和功能缺失问题。手动升级面临兼容性风险和冗余依赖挑战，需要自动化解决方案。

Method: 提出DepUpdater工具，通过平衡版本升级、减少技术滞后、确保兼容性和避免冗余依赖来实现自动化依赖管理。

Result: 与现有依赖管理工具相比，DepUpdater能更有效地减少技术滞后，同时确保兼容性和修剪冗余依赖。消融研究显示考虑修剪需求有助于缓解兼容性问题。

Conclusion: DepUpdater为自动化依赖升级提供了有效解决方案，并揭示了传递依赖升级对客户端兼容性的影响，为未来研究提供了见解。

Abstract: Re-using open-source software (OSS) can avoid reinventing the wheel, but failing to keep it up-to-date can lead to missing new features and persistent bugs or vulnerabilities that have already been resolved. The use of outdated OSS libraries introduces technical lag, necessitating timely upgrades. However, maintaining up-to-date libraries is challenging, as it may introduce incompatibility issues that break the project or redundant dependencies that unnecessarily increase the size of the project. These issues discourage developers from upgrading libraries, highlighting the need for a fully automated solution that balances version upgrades, reduces technical lag, ensures compatibility, and avoids redundant dependencies.
  To this end, we propose DepUpdater, which ensures that upgrades minimize technical lag as much as possible while avoiding incompatibility issues and redundant dependencies. The comparison with existing dependency management tools demonstrates that DepUpdater more effectively reduces technical lag while ensuring compatibility and pruning redundant dependencies. Additionally, an ablation study highlights the potential benefits of considering pruning requirements during upgrades to mitigate incompatibility issues. Finally, leveraging DepUpdater, we investigate the impact of transitive dependency upgrades on client compatibility, providing insights for future research.

</details>


### [24] [MetricSynth: Framework for Aggregating DORA and KPI Metrics Across Multi-Platform Engineering](https://arxiv.org/abs/2511.06864)
*Pallav Jain,Yuvraj Agrawal,Ashutosh Nigam,Pushpak Patil*

Main category: cs.SE

TL;DR: 提出了一个集中式框架，用于聚合来自各种内部工具的数据，计算和可视化开发者体验和KPI指标，显著减少了手动报告工作。


<details>
  <summary>Details</summary>
Motivation: 在现代大规模软件开发中，工程领导者面临获取团队性能和系统健康整体数据驱动视图的挑战。数据通常分散在多个不同的工具中，手动报告生成耗时且容易不一致。

Method: 采用基于cron的数据摄取层、双模式数据存储方法、指标预计算处理引擎、主动警报系统，并使用开源BI工具Metabase进行可视化，所有功能都通过基于角色的访问控制进行保护。

Result: 实施后显著减少了手动报告工作，每周节省约20人时，并实现了更快的数据驱动瓶颈识别。

Conclusion: 该系统具有良好的可扩展性，是工程智能平台的有价值贡献。

Abstract: In modern, large-scale software development, engineering leaders face the significant challenge of gaining a holistic and data-driven view of team performance and system health. Data is often siloed across numerous disparate tools, making manual report generation time-consuming and prone to inconsistencies. This paper presents the architecture and implementation of a centralized framework designed to provide near-real-time visibility into developer experience (DevEx) and Key Performance Indicator (KPI) metrics for a software ecosystem. By aggregating data from various internal tools and platforms, the system computes and visualizes metrics across key areas such as Developer Productivity, Quality, and Operational Efficiency. The architecture features a cron-based data ingestion layer, a dual-schema data storage approach, a processing engine for metric pre-computation, a proactive alerting system, and utilizes the open-source BI tool Metabase for visualization, all secured with role-based access control (RBAC). The implementation resulted in a significant reduction in manual reporting efforts, saving an estimated 20 person-hours per week, and enabled faster, data-driven bottleneck identification. Finally, we evaluate the system's scalability and discuss its trade-offs, positioning it as a valuable contribution to engineering intelligence platforms.

</details>


### [25] [A Collaborative Model for Improving Information Sharing among Cancer Care Groups using Software Engineering Principles](https://arxiv.org/abs/2511.06885)
*Davis Byamugisha,Francis Kamuganga,Adones Rukundo,John Businge*

Main category: cs.SE

TL;DR: 该论文提出了一种基于软件工程原则的癌症护理信息共享模型，借鉴GitHub版本控制系统中的bug修复原理来协调癌症病例管理中各护理团队之间的协作。


<details>
  <summary>Details</summary>
Motivation: 现有癌症诊断和治疗过程中存在信息共享不畅、利益相关者参与不足导致的延误和沟通问题，需要一种更有效的协调机制来改善早期诊断和治疗效果。

Method: 分析癌症治疗与软件工程信息管理的相似性，基于GitHub版本控制系统的bug修复原则设计信息共享模型，使用Any-Logic仿真软件验证模型有效性。

Result: 结果显示，软件工程中的bug解决原则和GitHub版本控制系统可以成功应用于协调癌症病例管理环境中各护理团队之间的协作和信息共享。

Conclusion: 通过采用软件工程原则，可以改善癌症护理团队间的协调和信息共享，从而提高治疗效果、确保早期诊断并增加患者生存机会。

Abstract: Effective treatment of cancer requires early diagnosis which involves the patient's awareness of the early signs and symptoms, leading to a consultation with a health provider, who would then promptly refer the patient for confirmation of the diagnosis and thereafter treatment. However, this is not always the case because of delays arising from limited skilled manpower and health information management systems that are neither integrated nor organized in their design hence leading to information gap among care groups. Existing methods focus on using accumulated data to support decision making, enhancing the sharing of secondary data while others exclude some critical stakeholders like patient caretakers and administrators thus, leaving an information gap that creates delays and miscommunication during case management. We however notice some similarities between cancer treatment and software engineering information management especially when progress history needs to be maintained (versioning).
  We analyze the similarities and propose a model for information sharing among cancer care groups using the software engineering principles approach. We model for reducing delays and improving coordination among care groups in cancer case management. Model design was guided by software engineering principles adopted in GitHub version control system for bug fixing in open-source code projects. Any-Logic simulation software was used to mimic the model realism in a virtual environment. Results show that bug resolution principles from software engineering and GitHub version control system can be adopted to coordinate collaboration and information sharing among care groups in a cancer case management environment while involving all stakeholders to improve care treatment outcomes, ensure early diagnosis and increase patient's survival chances.

</details>


### [26] [Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in Practice](https://arxiv.org/abs/2511.07017)
*Ruida Hu,Xinchen Wang,Xin-Cheng Wen,Zhao Zhang,Bo Jiang,Pengfei Gao,Chao Peng,Cuiyun Gao*

Main category: cs.SE

TL;DR: ContextCRBench是一个高质量、上下文丰富的代码审查基准测试，解决了现有基准测试的三个主要限制：缺乏语义上下文、数据质量问题、粗粒度评估。该基准测试支持三种评估场景，并在工业部署中显著提升了代码审查系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代码审查基准测试存在三个主要问题：(1)缺乏语义上下文，只提供代码差异而没有问题描述等文本信息；(2)数据质量问题，包含过时或无关代码的噪声样本；(3)粗粒度评估，忽略了细粒度的行级推理。这些限制影响了评估的可靠性。

Method: 构建流程包括：(1)原始数据爬取，从顶级仓库收集15.37万个问题和拉取请求；(2)全面上下文提取，链接问题-PR对获取文本上下文，提取完整函数或类获取代码上下文；(3)多阶段数据过滤，结合基于规则和基于LLM的验证，移除过时、格式错误或低价值样本，最终得到67,910个上下文丰富的条目。

Result: 评估八个领先LLM（四个闭源和四个开源）显示：文本上下文比单独代码上下文带来更大的性能提升，但当前LLM仍远未达到人类审查能力。在字节跳动部署后，ContextCRBench驱动自演进代码审查系统，性能提升61.98%，证明了其稳健性和工业实用性。

Conclusion: ContextCRBench为LLM代码审查提供了高质量的评估基准，强调了上下文信息的重要性，并展示了在工业环境中的实际应用价值。当前LLM在代码审查方面仍有很大提升空间。

Abstract: Code review is a cornerstone of software quality assurance, and recent advances in Large Language Models (LLMs) have shown promise in automating this process. However, existing benchmarks for LLM-based code review face three major limitations. (1) Lack of semantic context: most benchmarks provide only code diffs without textual information such as issue descriptions, which are crucial for understanding developer intent. (2) Data quality issues: without rigorous validation, many samples are noisy-e.g., reviews on outdated or irrelevant code-reducing evaluation reliability. (3) Coarse granularity: most benchmarks operate at the file or commit level, overlooking the fine-grained, line-level reasoning essential for precise review.
  We introduce ContextCRBench, a high-quality, context-rich benchmark for fine-grained LLM evaluation in code review. Our construction pipeline comprises: (1) Raw Data Crawling, collecting 153.7K issues and pull requests from top-tier repositories; (2) Comprehensive Context Extraction, linking issue-PR pairs for textual context and extracting the full surrounding function or class for code context; and (3) Multi-stage Data Filtering, combining rule-based and LLM-based validation to remove outdated, malformed, or low-value samples, resulting in 67,910 context-enriched entries.
  ContextCRBench supports three evaluation scenarios aligned with the review workflow: (1) hunk-level quality assessment, (2) line-level defect localization, and (3) line-level comment generation. Evaluating eight leading LLMs (four closed-source and four open-source) reveals that textual context yields greater performance gains than code context alone, while current LLMs remain far from human-level review ability. Deployed at ByteDance, ContextCRBench drives a self-evolving code review system, improving performance by 61.98% and demonstrating its robustness and industrial utility.

</details>


### [27] [Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation](https://arxiv.org/abs/2511.07257)
*Hanya Elhashemy,Youssef Lotfy,Yongjian Tang*

Main category: cs.SE

TL;DR: Codelevate是一个多智能体系统，能够自动将Jupyter笔记本转换为结构良好的Python代码仓库，解决原型到生产环境的转换问题。


<details>
  <summary>Details</summary>
Motivation: Jupyter笔记本在数据科学和机器学习工作流中广泛使用，但缺乏软件工程原则，难以直接部署到生产环境，存在原型到生产的转换鸿沟。

Method: 采用三个专门化智能体（架构师、开发者、结构师）通过共享依赖树协同工作，确保架构一致性和代码质量。

Result: 实验验证了Codelevate能够通过自主代码转换弥合原型到生产差距，在保持计算语义的同时显著提升代码质量指标。

Conclusion: Codelevate系统成功解决了Jupyter笔记本向生产环境转换的挑战，为数据科学工作流提供了有效的工程化解决方案。

Abstract: The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents - Architect, Developer, and Structure - working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [28] [Generalized Security-Preserving Refinement for Concurrent Systems](https://arxiv.org/abs/2511.06862)
*Huan Sun,David Sanán,Jingyi Wang,Yongwang Zhao,Jun Sun,Wenhai Wang*

Main category: cs.LO

TL;DR: 提出了一种针对并发系统的广义安全保持精化技术，用于验证信息流安全(IFS)属性，特别适用于多核操作系统等复杂并发系统。


<details>
  <summary>Details</summary>
Motivation: 现有的精化验证技术仅限于顺序系统或缺乏表达复杂安全策略的能力，难以验证并发系统的信息流安全。

Method: 形式化并发系统的IFS属性，提出基于精化的组合方法，建立实现与抽象之间的步骤映射关系，确保每对步骤都符合安全策略。

Result: 在Isabelle/HOL中完全机械化验证了两个非平凡案例研究，发现ARINC 653多核标准中存在两个隐蔽通道，并证明了修正机制的正确性。

Conclusion: 该方法能有效验证并发系统的复杂安全策略，展示了在验证多核系统信息流安全方面的实用性。

Abstract: Ensuring compliance with Information Flow Security (IFS) is known to be challenging, especially for concurrent systems with large codebases such as multicore operating system (OS) kernels. Refinement, which verifies that an implementation preserves certain properties of a more abstract specification, is promising for tackling such challenges. However, in terms of refinement-based verification of security properties, existing techniques are still restricted to sequential systems or lack the expressiveness needed to capture complex security policies for concurrent systems.
  In this work, we present a generalized security-preserving refinement technique, particularly for verifying the IFS of concurrent systems governed by potentially complex security policies. We formalize the IFS properties for concurrent systems and present a refinement-based compositional approach to prove that the generalized security properties (e.g., intransitive noninterference) are preserved between implementation and abstraction. The key intuition enabling such reasoning, compared to previous refinement work, is to establish a step-mapping relation between the implementation and the abstraction, which is sufficient to ensure that every paired step (in the abstraction and the implementation, respectively) is either permitted or prohibited by the security policy. We apply our approach to verify two non-trivial case studies against a collection of security policies. Our proofs are fully mechanized in Isabelle/HOL, during which we identified that two covert channels previously reported in the ARINC 653 single-core standard also exist in the ARINC 653 multicore standard. We subsequently proved the correctness of the revised mechanism, showcasing the effectiveness of our approach.

</details>


### [29] [Verifying rich robustness properties for neural networks](https://arxiv.org/abs/2511.07293)
*Mohammad Afzal,S. Akshay,Ashutosh Gupta*

Main category: cs.LO

TL;DR: 提出一个统一的神经网络鲁棒性验证框架，通过简单语法规范定义多种鲁棒性变体，并开发了通过添加额外层来统一验证这些变体的方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络鲁棒性验证方法需要专门编码且忽略模型输出置信度，需要更通用、考虑置信度的鲁棒性验证框架。

Method: 使用简单语法规范框架定义鲁棒性变体，通过向神经网络添加额外层实现统一验证，可与现有验证工具兼容。

Result: 在8870个基准测试（最大网络1.38亿参数）上验证，能捕获多种鲁棒性变体并显著优于直接编码方法。

Conclusion: 该框架能灵活定义和高效验证考虑置信度的鲁棒性变体，为神经网络安全验证提供统一解决方案。

Abstract: Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [30] [A Data-driven Analysis of Code Optimizations](https://arxiv.org/abs/2511.06117)
*Yacine Hakimi,Riyadh Baghdadi*

Main category: cs.PL

TL;DR: 本文研究自动代码优化中的变换顺序问题，探讨固定变换顺序是否能加速搜索而不严重损害优化潜力，通过数据驱动方法分析随机程序的优化序列性能。


<details>
  <summary>Details</summary>
Motivation: 随着计算需求增长，自动代码优化技术变得至关重要。编译器开发者面临设计选择：允许任意变换顺序还是固定序列。前者可能获得最佳性能但搜索空间巨大，需要研究固定顺序是否能平衡搜索效率与优化效果。

Method: 采用数据驱动方法，生成大量随机程序，应用随机优化序列并记录执行时间，通过统计分析为自动代码优化算法开发提供指导。

Result: 通过统计分析揭示了变换顺序对优化效果的影响，为设计更高效的自动代码优化算法提供了数据支持。

Conclusion: 固定变换顺序可以在不严重损害优化潜力的前提下加速搜索过程，为自动代码优化算法的设计提供了重要指导。

Abstract: As the demand for computational power grows, optimizing code through compilers becomes increasingly crucial. In this context, we focus on fully automatic code optimization techniques that automate the process of selecting and applying code transformations for better performance without manual intervention. Understanding how these transformations behave and interact is key to designing more effective optimization strategies. Compiler developers must make numerous design choices when constructing these heuristics. For instance, they may decide whether to allow transformations to be explored in any arbitrary order or to enforce a fixed sequence. While the former may theoretically offer the best performance gains, it significantly increases the search space. This raises an important question: Can a predefined, fixed order of applying transformations speed up the search without severely compromising optimization potential? In this paper, we address this and other related questions that arise in the design of automatic code optimization algorithms. Using a data-driven approach, we generate a large dataset of random programs, apply random optimization sequences, and record their execution times. Through statistical analysis, we provide insights that guide the development of more efficient automatic code optimization algorithms.

</details>
