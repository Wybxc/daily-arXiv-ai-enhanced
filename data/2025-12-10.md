<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [On semantics of first-order justification logic with binding modalities](https://arxiv.org/abs/2512.07994)
*Tatiana Yavorskaya,Elena Popova*

Main category: cs.LO

TL;DR: 该论文提出了结合证明项和绑定模态词的一阶证明逻辑FOLP□，建立了其Kripke风格语义，通过个体变量赋值而非引入常量的方式定义模型，并证明了该逻辑相对于所描述语义的可靠性和完备性。


<details>
  <summary>Details</summary>
Motivation: 动机是为一阶证明逻辑FOLP□建立合适的Kripke风格语义模型。传统方法需要向语言中引入常量，而本文采用个体变量赋值的新方法，这需要重新定义证据函数格式，从而能够为包含自由变量的公式赋予语义意义。

Method: 方法包括：1) 引入结合证明项和绑定模态词的一阶证明逻辑FOLP□；2) 采用基于个体变量赋值的Kripke语义模型，而非传统的引入常量方法；3) 设计新的证据函数格式以适应变量赋值；4) 为包含自由变量的公式提供语义解释。

Result: 主要结果是证明了FOLP□相对于所描述的Kripke语义的可靠性和完备性定理。通过新的变量赋值方法和证据函数格式，成功地为包含自由变量的公式建立了语义模型。

Conclusion: 结论是成功构建了FOLP□的Kripke语义模型，通过个体变量赋值的新方法避免了引入常量，建立了新的证据函数格式，并证明了该逻辑的可靠性和完备性，为包含自由变量的公式提供了语义基础。

Abstract: We introduce the first order logic of proofs $FOLP^\Box$ in the joint language combining justification terms and binding modalities. The main issue is Kripke--style semantics for this logic. We describe models for $FOLP^\Box$ in terms of valuations of individual variables instead of introducing constants to the language. This approach requires a new format of the evidence function. This allows us to assign semantic meaning to formulas that contain free variables. The main results are soundness and completeness of $FOLP^\Box$ with respect to the described semantics.

</details>


### [2] [Applications of Interval-based Temporal Separation: the Reactivity Normal Form, Inverse $Π$, Craig Interpolation and Beth Definability](https://arxiv.org/abs/2512.08640)
*Dimitar P. Guelev*

Main category: cs.LO

TL;DR: 本文展示了如何利用ITL-NL（带邻域模态的离散时间区间时态逻辑）中的区间时态分离技术，简洁地证明了反应性范式、时间投影算子的逆、命题量词消除等结果，进而得到ITL-NL的一致Craig插值和Beth可定义性。


<details>
  <summary>Details</summary>
Motivation: 研究ITL-NL（带邻域模态的区间时态逻辑）的元逻辑性质，特别是如何利用区间时态分离技术来简化复杂定理的证明，并建立该逻辑的重要元逻辑特性。

Method: 使用ITL-NL中的区间时态分离技术，基于Guelev和Moszkowski（2022）中的关键引理，构建简洁的证明方法，应用于反应性范式、时间投影算子逆、命题量词消除等问题。

Result: 成功获得了ITL-NL中区间形式的反应性范式、时间投影算子的逆、命题量词消除，并由此推导出ITL-NL的一致Craig插值和Beth可定义性。

Conclusion: 区间时态分离技术是证明ITL-NL中重要元逻辑性质的有效工具，能够简化复杂定理的证明过程，并为该逻辑建立了完整的元逻辑基础。

Abstract: We show how interval-based temporal separation on the extension of Moszkowski's discrete time interval temporal logic (Moszkowski, 1986) by the neighbourhood modalities (ITL-NL) and a lemma which is key in establishing this form of separation in (Guelev and Moszkowski, 2022) can be used to obtain concise proofs of an interval-based form of the reactivity normal form as known from (Manna and Pnueli, 1990), the inverse of the temporal projection operator from (Halpern, Manna and Moszkowski, 1983), the elimination of propositional quantification in ITL-NL and, consequently, uniform Craig interpolation and Beth definability for ITL-NL.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [CFD-copilot: leveraging domain-adapted large language model and model context protocol to enhance simulation automation](https://arxiv.org/abs/2512.07917)
*Zhehao Dong,Shanghai Du,Zhen Lu,Yue Yang*

Main category: cs.SE

TL;DR: CFD-copilot是一个基于大语言模型的领域专用框架，能够通过自然语言驱动完整的CFD仿真工作流，从设置到后处理，降低了非专家用户的使用门槛。


<details>
  <summary>Details</summary>
Motivation: CFD仿真配置需要深厚的物理建模和数值方法专业知识，这对非专家用户构成了障碍。虽然大语言模型在科学任务自动化方面受到关注，但由于CFD工作流严格的领域特定要求，实现端到端的自动化仍然具有挑战性。

Method: 采用微调的大语言模型直接将用户描述翻译为可执行的CFD设置；多智能体系统集成LLM与仿真执行、自动错误修正和结果分析；后处理使用模型上下文协议（MCP）解耦LLM推理与外部工具执行，通过统一接口访问多种专用后处理功能。

Result: 在NACA~0012翼型和30P-30N三元素翼型等基准测试中，领域特定适应和MCP的结合共同提高了LLM驱动工程工作流的可靠性和效率。

Conclusion: CFD-copilot框架通过领域专用的大语言模型和模块化设计，成功实现了自然语言驱动的端到端CFD仿真自动化，为工程工作流提供了更可靠和高效的解决方案。

Abstract: Configuring computational fluid dynamics (CFD) simulations requires significant expertise in physics modeling and numerical methods, posing a barrier to non-specialists. Although automating scientific tasks with large language models (LLMs) has attracted attention, applying them to the complete, end-to-end CFD workflow remains a challenge due to its stringent domain-specific requirements. We introduce CFD-copilot, a domain-specialized LLM framework designed to facilitate natural language-driven CFD simulation from setup to post-processing. The framework employs a fine-tuned LLM to directly translate user descriptions into executable CFD setups. A multi-agent system integrates the LLM with simulation execution, automatic error correction, and result analysis. For post-processing, the framework utilizes the model context protocol (MCP), an open standard that decouples LLM reasoning from external tool execution. This modular design allows the LLM to interact with numerous specialized post-processing functions through a unified and scalable interface, improving the automation of data extraction and analysis. The framework was evaluated on benchmarks including the NACA~0012 airfoil and the three-element 30P-30N airfoil. The results indicate that domain-specific adaptation and the incorporation of the MCP jointly enhance the reliability and efficiency of LLM-driven engineering workflows.

</details>


### [4] [DeepCode: Open Agentic Coding](https://arxiv.org/abs/2512.07921)
*Zongwei Li,Zhonghang Li,Zirui Guo,Xubin Ren,Chao Huang*

Main category: cs.SE

TL;DR: DeepCode是一个完全自主的框架，通过信息流管理解决文档到代码库合成中的信息过载与上下文瓶颈冲突，在PaperBench基准测试中超越商业代理和人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实现高保真文档到代码库合成（如科学论文到代码）时面临重大挑战，主要是信息过载与LLMs上下文瓶颈之间的根本冲突。

Method: 将仓库合成视为信道优化问题，通过四个信息操作最大化任务相关信号：蓝图蒸馏进行源压缩、状态化代码内存的结构化索引、检索增强生成的条件知识注入、闭环错误纠正。

Result: 在PaperBench基准测试中达到最先进性能，显著优于Cursor和Claude Code等商业代理，并在关键复制指标上超越顶尖机构的博士级人类专家。

Conclusion: 通过系统地将论文规范转化为生产级实现，为自主科学复制建立新基础，加速研究评估和发现。

Abstract: Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity document-to-codebase synthesis--such as scientific papers to code--primarily due to a fundamental conflict between information overload and the context bottlenecks of LLMs. In this work, we introduce DeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as a channel optimization problem, DeepCode seamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression via blueprint distillation, structured indexing using stateful code memory, conditional knowledge injection via retrieval-augmented generation, and closed-loop error correction. Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics. By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations for autonomous scientific reproduction that can accelerate research evaluation and discovery.

</details>


### [5] [An Empirical Framework for Evaluating Semantic Preservation Using Hugging Face](https://arxiv.org/abs/2512.07983)
*Nan Jia,Anita Raja,Raffi Khatchadourian*

Main category: cs.SE

TL;DR: 该论文提出了一个评估学习型软件系统语义保持性的经验框架，通过挖掘HuggingFace上的模型演化数据来检测语义漂移。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习成为高自治系统的核心组成部分，确保学习型软件系统的可信性变得至关重要。然而，ML的非确定性和运行时定义语义使得传统软件重构变得复杂，需要定义和评估语义保持性。

Method: 1. 从HuggingFace挖掘模型演化数据，包括提交历史、模型卡片和性能指标；2. 建立可重复的数据收集管道，处理170万个HuggingFace条目；3. 对536个模型和4000多个指标进行语义保持性评估；4. 通过提交消息分析识别常见重构模式；5. 在三个领域进行案例研究，追踪版本间的性能变化。

Result: 1. 创建了大规模ML模型演化数据集；2. 开发了实用的语义保持性评估管道；3. 通过案例研究展示了语义漂移的实际检测；4. 证明了可以通过评估指标跨提交检测语义漂移；5. 揭示了基于提交消息分析的常见重构模式。

Conclusion: 该研究为定义社区接受的语义保持性边界奠定了基础，推动了更可维护和可信的ML系统的发展。虽然API限制影响了全规模阈值的估计，但提出的框架和管道为评估ML系统语义保持性提供了重要工具。

Abstract: As machine learning (ML) becomes an integral part of high-autonomy systems, it is critical to ensure the trustworthiness of learning-enabled software systems (LESS). Yet, the nondeterministic and run-time-defined semantics of ML complicate traditional software refactoring. We define semantic preservation in LESS as the property that optimizations of intelligent components do not alter the system's overall functional behavior. This paper introduces an empirical framework to evaluate semantic preservation in LESS by mining model evolution data from HuggingFace. We extract commit histories, $\textit{Model Cards}$, and performance metrics from a large number of models. To establish baselines, we conducted case studies in three domains, tracing performance changes across versions. Our analysis demonstrates how $\textit{semantic drift}$ can be detected via evaluation metrics across commits and reveals common refactoring patterns based on commit message analysis. Although API constraints limited the possibility of estimating a full-scale threshold, our pipeline offers a foundation for defining community-accepted boundaries for semantic preservation. Our contributions include: (1) a large-scale dataset of ML model evolution, curated from 1.7 million Hugging Face entries via a reproducible pipeline using the native HF hub API, (2) a practical pipeline for the evaluation of semantic preservation for a subset of 536 models and 4000+ metrics and (3) empirical case studies illustrating semantic drift in practice. Together, these contributions advance the foundations for more maintainable and trustworthy ML systems.

</details>


### [6] [A Gray Literature Study on Fairness Requirements in AI-enabled Software Engineering](https://arxiv.org/abs/2512.07990)
*Thanh Nguyen,Chaima Boufaied,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 该论文通过灰色文献综述，系统分析了AI系统中公平性需求的定义、SDLC管理实践、违反原因及后果，强调需要建立一致性框架将公平性与有效性同等重视。


<details>
  <summary>Details</summary>
Motivation: 当前AI/ML应用过度关注模型有效性（如F1分数），而公平性关注不足。需要系统理解AI系统中公平性需求的定义、管理实践、违反原因及后果，以促进公平性在AI软件开发中的整合。

Method: 采用灰色文献综述方法，分析现有文献中AI系统公平性需求的定义、在软件开发生命周期（SDLC）中的管理方式、违反原因及相应后果。

Result: 研究发现：1）公平性需求定义多样，但普遍强调非歧视和跨人口/社会属性的平等对待；2）SDLC管理实践在模型训练与偏见缓解、公平性监控评估、数据处理等方面存在差异；3）违反原因主要与数据表示偏见、算法模型设计偏见、人类判断、评估透明度差距相关；4）后果包括广义伤害、刻板印象强化、数据隐私风险、AI决策信任与合法性丧失。

Conclusion: 需要建立一致性框架和实践，将公平性整合到AI软件中，给予公平性与有效性同等重视，以应对AI系统可能带来的各种负面影响。

Abstract: Today, with the growing obsession with applying Artificial Intelligence (AI), particularly Machine Learning (ML), to software across various contexts, much of the focus has been on the effectiveness of AI models, often measured through common metrics such as F1- score, while fairness receives relatively little attention. This paper presents a review of existing gray literature, examining fairness requirements in AI context, with a focus on how they are defined across various application domains, managed throughout the Software Development Life Cycle (SDLC), and the causes, as well as the corresponding consequences of their violation by AI models. Our gray literature investigation shows various definitions of fairness requirements in AI systems, commonly emphasizing non-discrimination and equal treatment across different demographic and social attributes. Fairness requirement management practices vary across the SDLC, particularly in model training and bias mitigation, fairness monitoring and evaluation, and data handling practices. Fairness requirement violations are frequently linked, but not limited, to data representation bias, algorithmic and model design bias, human judgment, and evaluation and transparency gaps. The corresponding consequences include harm in a broad sense, encompassing specific professional and societal impacts as key examples, stereotype reinforcement, data and privacy risks, and loss of trust and legitimacy in AI-supported decisions. These findings emphasize the need for consistent frameworks and practices to integrate fairness into AI software, paying as much attention to fairness as to effectiveness.

</details>


### [7] [What Pulls the Strings? Understanding the Characteristics and Role of Argumentation in Open-Source Software Usability Discussions](https://arxiv.org/abs/2512.08032)
*Arghavan Sanei,Chaima Amiri,Atefeh Shokrizadeh,Jinghui Cheng*

Main category: cs.SE

TL;DR: 开源软件可用性讨论中论证话语与质量分析，发现讨论以论证驱动但质量参差不齐，评论质量低于问题帖，论证质量影响参与者后续行为


<details>
  <summary>Details</summary>
Motivation: 开源软件（OSS）的可用性很重要，但常被技术和功能复杂性所掩盖。论证可作为不同利益相关者在OSS可用性讨论中表达意见和说服他人的关键工具，但目前对这些讨论中论证话语的特征了解不足，导致难以为参与者提供有效支持。

Method: 通过对五个开源项目的论证话语和质量进行全面分析，研究可用性讨论中的论证特征。

Result: 研究发现：1）可用性讨论主要是论证驱动的，但质量参差不齐；2）问题评论中的论证质量低于问题帖子，表明OSS社区在可用性方面缺乏集体智慧；3）论证话语和质量对参与者的后续行为有不同影响。

Conclusion: 这项研究为OSS利益相关者构建更有效的论证并最终改善OSS可用性提供了见解，这些见解也可为其他分布式协作社区的研究提供参考。

Abstract: The usability of open-source software (OSS) is important but frequently overlooked in favor of technical and functional complexity. Argumentation can be a pivotal device for diverse stakeholders in OSS usability discussions to express opinions and persuade others. However, the characteristics of argument discourse in those discussions remain unknown, resulting in difficulties in providing effective support for discussion participants. We address this through a comprehensive analysis of argument discourse and quality in five OSS projects. Our results indicated that usability discussions are predominantly argument-driven, although their qualities vary. Issue comments exhibit lower-quality arguments than the issue posts, suggesting a shortage of collective intelligence about usability in OSS communities. Moreover, argument discourse and quality have various impacts on the subsequent behavior of participants. Overall, this research offers insights to help OSS stakeholders build more effective arguments and eventually improve OSS usability. These insights can also inform studies about other distributed collaborative communities.

</details>


### [8] [Secure or Suspect? Investigating Package Hallucinations of Shell Command in Original and Quantized LLMs](https://arxiv.org/abs/2512.08213)
*Md Nazmul Haque,Elizabeth Lin,Lawrence Arkoh,Biruk Tadesse,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术显著增加LLM生成Go包时的幻觉率和安全漏洞风险，4-bit量化模型表现最差


<details>
  <summary>Details</summary>
Motivation: 量化技术虽能降低LLM推理成本，但其对代码生成正确性和安全性的影响尚不明确，特别是在生成软件依赖包时可能增加幻觉和漏洞风险

Method: 系统评估五种Qwen模型在不同精度（全精度、8-bit、4-bit）下在三个数据集（SO、MBPP、paraphrase）上的表现，分析包幻觉率和漏洞存在率

Result: 量化显著增加包幻觉率，4-bit模型退化最严重；正确生成的包中漏洞存在率随精度降低而上升；幻觉包大多呈现类似真实URL的Go模块路径模式

Conclusion: 量化部署LLM用于代码生成和依赖推荐时需谨慎，需考虑其可靠性和安全性影响，特别是低精度模型会显著增加幻觉和漏洞风险

Abstract: Large Language Models for code (LLMs4Code) are increasingly used to generate software artifacts, including library and package recommendations in languages such as Go. However, recent evidence shows that LLMs frequently hallucinate package names or generate dependencies containing known security vulnerabilities, posing significant risks to developers and downstream software supply chains. At the same time, quantization has become a widely adopted technique to reduce inference cost and enable deployment of LLMs on resource-constrained environments. Despite its popularity, little is known about how quantization affects the correctness and security of LLM-generated software dependencies while generating shell commands for package installation.
  In this work, we conduct the first systematic empirical study of the impact of quantization on package hallucination and vulnerability risks in LLM-generated Go packages. We evaluate five Qwen model sizes under full-precision, 8-bit, and 4-bit quantization across three datasets (SO, MBPP, and paraphrase). Our results show that quantization substantially increases the package hallucination rate (PHR), with 4-bit models exhibiting the most severe degradation. We further find that even among the correctly generated packages, the vulnerability presence rate (VPR) rises as precision decreases, indicating elevated security risk in lower-precision models. Finally, our analysis of hallucinated outputs reveals that most fabricated packages resemble realistic URL-based Go module paths, such as most commonly malformed or non-existent GitHub and golang.org repositories, highlighting a systematic pattern in how LLMs hallucinate dependencies. Overall, our findings provide actionable insights into the reliability and security implications of deploying quantized LLMs for code generation and dependency recommendation.

</details>


### [9] [Migrating QAOA from Qiskit 1.x to 2.x: An experience report](https://arxiv.org/abs/2512.08245)
*Julien Cardinal,Imen Benzarti,Ghizlane El boussaidi,Christophe Pere*

Main category: cs.SE

TL;DR: 量子算法在不同框架间迁移时，由于隐藏参数（如采样预算）的差异，会导致结果显著不同，影响准确性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 量子算法框架的演进（如从Qiskit 1.x到2.x）引入了隐藏的行为变化，这些变化会影响算法的准确性和可复现性，需要系统性地识别和解决这些问题。

Method: 将量子近似优化算法（QAOA）从Qiskit 1.x（v1原语）迁移到使用Qiskit 2.x（v2原语）的自定义实现，通过系统分析识别导致结果差异的根本原因。

Result: 尽管电路、优化器和哈密顿量完全相同，新版本产生了截然不同的结果。根本原因是采样预算（每次迭代的电路执行次数）：v1隐式使用无限次采样产生密集概率分布，而v2默认10,000次采样仅捕获23%的状态空间。将采样次数增加到250,000次后恢复了库级精度。

Conclusion: 量子-经典交互层面的隐藏参数会主导混合算法的性能。研究为开发者和框架设计者提供了可操作的建议，以确保量子软件迁移中的可复现结果。

Abstract: Migrating quantum algorithms across evolving frameworks introduces subtle behavioral changes that affect accuracy and reproducibility. This paper reports our experience converting the Quantum Approximate Optimization Algorithm (QAOA) from Qiskit Algorithms with Qiskit 1.x (v1 primitives) to a custom implementation using Qiskit 2.x (v2 primitives). Despite identical circuits, optimizers, and Hamiltonians, the new version produced drastically different results. A systematic analysis revealed the root cause: the sampling budget -- the number of circuit executions (shots) per iteration. The library's implicit use of unlimited shots yielded dense probability distributions, whereas the v2 default of 10 000 shots captured only 23% of the state space. Increasing shots to 250 000 restored library-level accuracy. This study highlights how hidden parameters at the quantum-classical interaction level can dominate hybrid algorithm performance and provides actionable recommendations for developers and framework designers to ensure reproducible results in quantum software migration.

</details>


### [10] [Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand](https://arxiv.org/abs/2512.08266)
*Zhensu Sun,Chengran Yang,Xiaoning Du,Zhou Yang,Li Li,David Lo*

Main category: cs.SE

TL;DR: Token Sugar：通过将高频、冗长的代码模式替换为可逆的、token高效的简写形式，在保持代码功能的同时显著减少LLM代码生成和理解中的token数量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码任务中表现出色，但编程语言的固有冗长性（如不必要的格式元素和冗长的样板代码）导致token数量膨胀，增加了推理成本并减慢了生成速度。现有方法局限于语法层面的转换，未能充分利用语义层面的token减少机会。

Method: 提出Token Sugar概念，设计系统化解决方案：1）从代码语料库中挖掘高频、token密集的代码模式；2）为每个模式映射唯一的简写形式；3）通过代码转换将简写集成到LLM预训练中。最终获得799个（代码模式，简写）对。

Result: Token Sugar可在源代码中减少高达15.1%的token数量，与现有语法聚焦方法互补。在三个广泛使用的LLM上进行训练后，实验结果显示在生成过程中实现了显著的token节省（高达11.2%的减少），同时与未经处理代码训练的基线相比，Pass@1分数保持几乎相同。

Conclusion: Token Sugar通过语义层面的代码模式简写，有效减少了LLM代码生成和理解中的token使用，在保持性能的同时显著降低了计算成本，为高效代码处理提供了新途径。

Abstract: Large language models (LLMs) have shown exceptional performance in code generation and understanding tasks, yet their high computational costs hinder broader adoption. One important factor is the inherent verbosity of programming languages, such as unnecessary formatting elements and lengthy boilerplate code. This leads to inflated token counts in both input and generated outputs, which increases inference costs and slows down the generation process. Prior work improves this through simplifying programming language grammar, reducing token usage across both code understanding and generation tasks. However, it is confined to syntactic transformations, leaving significant opportunities for token reduction unrealized at the semantic level.
  In this work, we propose Token Sugar, a concept that replaces frequent and verbose code patterns with reversible, token-efficient shorthand in the source code. To realize this concept in practice, we designed a systematic solution that mines high-frequency, token-heavy patterns from a code corpus, maps each to a unique shorthand, and integrates them into LLM pretraining via code transformation. With this solution, we obtain 799 (code pattern, shorthand) pairs, which can reduce up to 15.1% token count in the source code and is complementary to existing syntax-focused methods. We further trained three widely used LLMs on Token Sugar-augmented data. Experimental results show that these models not only achieve significant token savings (up to 11.2% reduction) during generation but also maintain near-identical Pass@1 scores compared to baselines trained on unprocessed code.

</details>


### [11] [FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection](https://arxiv.org/abs/2512.08277)
*Yihan Liao,Jacky Keung,Zhenyu Mao,Jingyu Zhang,Jialong Li*

Main category: cs.SE

TL;DR: FedLAD是一个用于联邦学习环境下日志异常检测的统一平台，支持多种模型、数据集和聚合策略，提供可复现的实验环境。


<details>
  <summary>Details</summary>
Motivation: 现有的日志异常检测方法大多假设集中式训练，但在实际分布式系统中由于隐私约束和日志分散性难以实现。联邦学习提供了替代方案，但缺乏专门针对日志异常检测的测试平台。

Method: 开发FedLAD平台，支持即插即用集成多种日志异常检测模型、基准数据集和聚合策略，提供运行时验证日志记录、参数调优和自适应策略控制功能。

Result: FedLAD平台已开发完成并开源，填补了联邦学习框架与日志异常检测需求之间的空白，为未来研究提供了坚实基础。

Conclusion: FedLAD通过提供可复现和可扩展的实验平台，解决了联邦学习环境下日志异常检测缺乏专用测试环境的问题，促进了该领域的研究发展。

Abstract: Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.

</details>


### [12] [Empowering smart app development with SolidGPT: an edge-cloud hybrid AI agent framework](https://arxiv.org/abs/2512.08286)
*Liao Hu,Qiteng Wu,Ruoyu Qi*

Main category: cs.SE

TL;DR: SolidGPT是一个开源的边缘-云混合开发者助手，通过语义代码搜索、项目工作流自动化和隐私优先设计，解决LLM在开发工作流中语义理解、生产力与数据隐私的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决将大型语言模型集成到移动和软件开发工作流中的三个核心矛盾：语义理解、开发者生产力和数据隐私。传统的云工具虽然推理能力强但存在数据暴露和延迟风险，而本地解决方案缺乏对代码库和开发工具的全上下文理解。

Method: 构建基于GitHub的开源边缘-云混合开发者助手SolidGPT，支持：1）与代码库对话的交互式查询；2）自动化软件项目工作流（生成PRD、任务分解、看板等）；3）配置私有可扩展代理（支持约500个私有代码文件、连接Notion、定制AI代理角色）；4）通过Docker、CLI或VSCode扩展部署。

Result: SolidGPT通过语义丰富的代码导航、集成的文档和任务管理、隐私优先设计，提升了开发者生产力。开发者无需手动搜索文件，可以无缝同步生成的内容到工作流，同时在本地运行保持对代码和数据的完全控制。

Conclusion: SolidGPT通过结合交互式代码查询、自动化项目脚手架和人机协作，提供了一个实用且尊重隐私的边缘助手，加速了现实世界的开发工作流，特别适合智能移动和软件工程场景。

Abstract: The integration of Large Language Models (LLMs) into mobile and software development workflows faces a persistent tension among three demands: semantic awareness, developer productivity, and data privacy. Traditional cloud-based tools offer strong reasoning but risk data exposure and latency, while on-device solutions lack full-context understanding across codebase and developer tooling. We introduce SolidGPT, an open-source, edge-cloud hybrid developer assistant built on GitHub, designed to enhance code and workspace semantic search. SolidGPT enables developers to: talk to your codebase: interactively query code and project structure, discovering the right methods and modules without manual searching. Automate software project workflows: generate PRDs, task breakdowns, Kanban boards, and even scaffold web app beginnings, with deep integration via VSCode and Notion. Configure private, extensible agents: onboard private code folders (up to approximately 500 files), connect Notion, customize AI agent personas via embedding and in-context training, and deploy via Docker, CLI, or VSCode extension. In practice, SolidGPT empowers developer productivity through: Semantic-rich code navigation: no more hunting through files or wondering where a feature lives. Integrated documentation and task management: seamlessly sync generated PRD content and task boards into developer workflows. Privacy-first design: running locally via Docker or VSCode, with full control over code and data, while optionally reaching out to LLM APIs as needed. By combining interactive code querying, automated project scaffolding, and human-AI collaboration, SolidGPT provides a practical, privacy-respecting edge assistant that accelerates real-world development workflows, ideal for intelligent mobile and software engineering contexts.

</details>


### [13] [Measuring Agile Agreement: Development and Validation of the Manifesto and Principle Scales](https://arxiv.org/abs/2512.08461)
*Nicolas Matton,Anthony Simonofski,Marie-Ange Remiche,Benoît Vanderose*

Main category: cs.SE

TL;DR: 本文开发并验证了两个测量敏捷协议的工具：MAS测量对敏捷宣言高层价值观的认同，PAS测量对12条具体原则的认同，两者相关但不互换，为更精细测量敏捷协议提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能区分对敏捷宣言抽象高层价值观的认同与对12条具体原则日常实践的认同，导致个体"敏捷协议"测量不明确且具有挑战性。本文旨在填补这一方法学空白。

Method: 设计了两个独立工具：新颖的宣言协议量表（MAS）和原则协议量表（PAS，对现有工具的改编和精炼）。采用系统化的项目创建与选择、调查设计和验证流程，包括收敛与发散分析、比例优势逻辑回归、Bland-Altman图和组内相关系数（ICC）。

Result: 两个量表均具有良好的内部一致性和构念效度。分析显示两个量表中度相关但不可互换，捕捉了敏捷协议的不同维度。研究提供了在比利时IT专业人员群体中验证的公开可用工具。

Conclusion: 本文贡献了一对公开可用的验证工具，代表了向更精细测量敏捷协议迈出的关键第一步，能够区分不同感知层次的敏捷协议，有助于更精确解释人与敏捷的匹配度。

Abstract: While the importance of human factors in agile software development is widely acknowledged, the measurement of an individual's "agile agreement" remains an ill-defined and challenging area. A key limitation in existing research is the failure to distinguish between agreement with the abstract, high-level values of the Agile Manifesto and agreement with the concrete, day-to-day practices derived from the 12 Principles. This paper addresses this methodological gap by presenting the design and validation of two distinct instruments: the novel Manifesto Agreement Scale (MAS), and the Principle Agreement Scale (PAS), which is a systematic adaptation and refinement of a prior instrument.
  We detail the systematic process of item creation and selection, survey design, and validation. The results demonstrate that both scales possess important internal consistency and construct validity. A convergence and divergence analysis, including Proportional Odds Logistic Regression, a Bland-Altman plot, and an Intraclass Correlation Coefficient (ICC), reveals that while the two scales are moderately correlated, they are not interchangeable and capture distinct dimensions of agile agreement. The primary contribution of this work is a pair of publicly available instruments, validated within a specific demographic of Belgian IT professionals. These scales represent a critical initial step toward facilitating a more nuanced measurement of agile agreement, distinguishing agile agreement across various levels of perception and aiding in a more refined interpretation of person-agile fit.

</details>


### [14] [Measuring Computer Science Enthusiasm: A Questionnaire-Based Analysis of Age and Gender Effects on Students' Interest](https://arxiv.org/abs/2512.08472)
*Kai Marquardt,Robert Hanak,Anne Koziolek,Lucia Happe*

Main category: cs.SE

TL;DR: 研究发现年龄比性别对计算机科学兴趣发展影响更大，早期青春期兴趣明显下降，精心设计的短期活动即使对年龄较大的学生也能有效重新激发兴趣。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为早期接触是维持计算机科学兴趣的主要途径，但缺乏对年龄和性别影响的细致分析。本研究旨在通过兴趣理论框架，探究不同年龄和性别学生在计算机科学教育中的兴趣动态变化。

Method: 基于兴趣对象理论(POI)开发了理论基础的问卷，用于评估计算机科学干预活动的热情潜力。收集了400多名参与在线计算机科学课程学生的前后测数据，分析年龄和性别相关的热情模式。

Result: 发现早期青春期热情明显下降，尤其是女生；年龄比性别对兴趣发展影响更大；识别出关键的发展转折点；尽管年龄较大的学生基线态度较低，但在干预后表现出最大的积极变化。

Conclusion: 研究挑战了早期接触是维持计算机科学兴趣主要途径的传统观念，强调需要建立动态的、对年龄敏感的计算机科学教育框架，使教学策略与个体发展轨迹相匹配。

Abstract: This study offers new insights into students' interest in computer science (CS) education by disentangling the distinct effects of age and gender across a diverse adolescent sample. Grounded in the person-object theory of interest (POI), we conceptualize enthusiasm as a short-term, activating expression of interest that combines positive affect, perceived relevance, and intention to re-engage. Experiencing such enthusiasm can temporarily shift CS attitudes and strengthen future engagement intentions, making it a valuable lens for evaluating brief outreach activities. To capture these dynamics, we developed a theoretically grounded questionnaire for pre-post assessment of the enthusiasm potential of CS interventions. Using data from more than 400 students participating in online CS courses, we examined age- and gender-related patterns in enthusiasm. The findings challenge the prevailing belief that early exposure is the primary pathway to sustained interest in CS. Instead, we identify a marked decline in enthusiasm during early adolescence, particularly among girls, alongside substantial variability in interest trajectories across age groups. Crucially, our analyses reveal that age is a more decisive factor than gender in shaping interest development and uncover key developmental breakpoints. Despite starting with lower baseline attitudes, older students showed the largest positive changes following the intervention, suggesting that well-designed short activities can effectively re-activate interest even at later ages. Overall, the study highlights the need for a dynamic, age-sensitive framework for CS education in which instructional strategies are aligned with developmental trajectories.

</details>


### [15] [Gamification with Purpose: What Learners Prefer to Motivate Their Learning](https://arxiv.org/abs/2512.08551)
*Kai Marquardt,Mona Schulz,Anne Koziolek,Lucia Happe*

Main category: cs.SE

TL;DR: 学习者偏好直接支持学习过程的游戏化设计元素，如进度条、概念图、即时反馈和成就，而非单纯的外在激励。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解学习者在教育情境中对游戏化设计元素的偏好，以开发目标驱动的游戏化策略，同时避免内在动机被侵蚀的风险。

Method: 通过系统文献综述确定10个常用游戏化设计元素，开发视觉原型，采用最佳-最差量表调查125名参与者进行偏好排序，并收集定性反馈分析动机驱动因素。

Result: 学习者一致偏好直接支持学习过程的元素（进度条、概念图、即时反馈、成就）。定性分析发现六个重复出现的动机主题：可见进展、内容相关性、建设性反馈等。

Conclusion: 学习者重视与教育内容有意义的整合并能支持内在动机的游戏化元素。目标对齐的游戏化应优先考虑可视化学习进展和提供可操作反馈的工具，而非仅依赖外在激励。

Abstract: This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative feedback was also collected to uncover motivational drivers. Learners consistently preferred GDEs that support learning processes directly-most notably progress bars, concept maps, immediate feedback, and achievements. Qualitative analysis revealed six recurring motivational themes, including visible progress, content relevance, and constructive feedback. The findings suggest that learners value gamification elements that are meaningfully integrated with educational content and support intrinsic motivation. Purpose-aligned gamification should prioritize tools that visualize learning progress and provide actionable feedback, rather than relying solely on extrinsic incentives.

</details>


### [16] [Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain](https://arxiv.org/abs/2512.08657)
*Renato Cordeiro Ferreira,Aditya Dhinavahi,Rowanne Trapmann,Willem-Jan van den Heuvel*

Main category: cs.SE

TL;DR: 该论文介绍了在海洋卫士（Ocean Guard）ML系统中应用六边形架构（Hexagonal Architecture）和端口适配器模式（Ports and Adapters pattern）的经验，展示了如何从单一代码库构建多个微服务，提高ML系统架构的可重用性。


<details>
  <summary>Details</summary>
Motivation: ML系统（MLES）通常很复杂，需要多个组件协同工作。作者希望通过分享在海洋卫士（一个海事领域异常检测系统）中应用架构模式的经验，展示如何提高ML系统的可重用性和可维护性。

Method: 应用六边形架构（Hexagonal Architecture）和端口适配器模式（Ports and Adapters pattern），从单一代码库构建多个微服务。通过这种架构设计，实现了组件解耦和代码重用。

Result: 成功构建了Ocean Guard系统，展示了端口适配器模式在ML系统中的有效应用。获得了关于架构重用、微服务构建和ML系统开发的重要经验教训。

Conclusion: 六边形架构模式适用于构建ML系统，能够提高代码重用性和系统可维护性。该经验报告旨在启发软件工程师、机器学习工程师和数据科学家在他们的ML系统中应用类似的架构模式。

Abstract: ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.

</details>


### [17] [RESTifAI: LLM-Based Workflow for Reusable REST API Testing](https://arxiv.org/abs/2512.08706)
*Leon Kogler,Maximilian Ehrhart,Benedikt Dornauer,Eduard Paul Enoiu*

Main category: cs.SE

TL;DR: RESTifAI是一个基于LLM的工具，用于生成可重用、CI/CD就绪的REST API测试，专注于构建有效测试场景（happy path）和衍生负面测试用例。


<details>
  <summary>Details</summary>
Motivation: 现有工具主要关注内部服务器错误，缺乏系统化的有效测试场景生成方法，且存在可重用性、测试预言复杂性和集成方面的限制。

Method: 采用LLM驱动的方法，系统化构建有效测试场景（happy path），并从中衍生负面测试用例，验证2xx响应和4xx错误处理。

Result: RESTifAI性能与最新的LLM工具（AutoRestTest和LogiAgent）相当，同时解决了可重用性、测试预言复杂性和集成问题，并在工业服务中展示了适用性。

Conclusion: RESTifAI提供了一个有效的LLM驱动方法，用于生成可重用、CI/CD就绪的REST API测试，填补了现有工具在系统化测试生成方面的空白。

Abstract: With this paper, we introduce RESTifAI, an LLM-driven approach for generating reusable, CI/CD ready REST API tests, following the happy-path approach. Unlike existing tools that often focus primarily on internal server errors, RESTifAI systematically constructs valid test scenarios (happy paths) and derives negative cases to verify both intended functionality (2xx responses) and robustness against invalid inputs or business-rule violations (4xx responses). The results indicate that RESTifAI performs on par with the latest LLM tools, i.e., AutoRestTest and LogiAgent, while addressing limitations related to reusability, oracle complexity, and integration. To support this, we provide common comparative results and demonstrate the tool's applicability in industrial services. For tool demonstration, please refer to https://www.youtube.com/watch?v=2vtQo0T0Lo4. RESTifAI is publicly available at https://github.com/casablancahotelsoftware/RESTifAI.

</details>


### [18] [Multicalibration for LLM-based Code Generation](https://arxiv.org/abs/2512.08810)
*Viola Campos,Robin Kuschnereit,Adrian Ulges*

Main category: cs.SE

TL;DR: 研究代码LLM的多重校准方法，通过考虑代码复杂度、长度、编程语言等因素，显著提升校准效果


<details>
  <summary>Details</summary>
Motivation: 随着AI代码生成普及，需要确保代码LLM的置信度分数能真实反映代码正确性的概率，现有校准方法可能未充分利用编码问题的额外因素

Method: 在三个函数合成基准测试上研究四种多重校准方法，使用最新代码LLM（Qwen3 Coder、GPT-OSS、DeepSeek-R1-Distill），考虑代码复杂度、长度、编程语言等因素

Result: 多重校准相比未校准的token似然度提升1.03技能分数，相比基线校准提升0.37技能分数，消融实验验证了各因素的影响

Conclusion: 多重校准能显著提升代码LLM的校准效果，公开数据集促进未来研究

Abstract: As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.

</details>


### [19] [SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA](https://arxiv.org/abs/2512.08867)
*Jing Zhang,Lianghong Guo,Yanlin Wang,Mingwei Liu,Jiachi Chen,Yuchi Ma,Ensheng Shi,Terry Yue Zhuo,Hongyu Zhang,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文分析了软件开发中的知识问答任务，发现现有基准存在局限性，提出了从真实对话构建的SimpleDevQA基准，并验证了代码LLM在开发知识问答上的优势。


<details>
  <summary>Details</summary>
Motivation: 研究发现开发知识问答在真实用户-LLM对话中占比最高（39.6%），但现有基准主要关注代码理解，忽略了更广泛的开发知识需求，且缺乏基于真实用户查询的评估。

Method: 设计了三阶段流水线将真实对话转化为简单的开发知识问答对，构建了多语言基准SimpleDevQA（包含2,740个问答对），并进行了实验评估。

Result: 代码LLM普遍优于同规模通用LLM；RAG策略平均提升准确率11.3%；LLM在开发知识问答中存在系统性过度自信；代码生成能力与开发知识问答性能正相关。

Conclusion: 开发知识问答是软件开发中的重要需求，现有评估基准不足，SimpleDevQA基准填补了这一空白，为评估LLM的开发知识问答能力提供了更全面、真实的测试平台。

Abstract: The Development Knowledge Question Answering (Dev Knowledge QA) task aims to provide natural language answers to knowledge-seeking questions during software development. To investigate its importance and to what extent it has been explored, we analyze real user-LLM dialogues from WildChat and find that: (1) The Dev Knowledge QA task accounts for 39.6% of interactions(highest among all tasks), revealing broad knowledge needs beyond code generation (32.3%). (2) Only 27.5% of real Dev Knowledge QA dialogues focus on code understanding, leaving out development knowledge-seeking. (3) Only 17.1% of real-world Dev Knowledge QA dialogues can be used for constructing a benchmark. Existing benchmarks have two primary limitations for evaluating the Dev Knowledge QA capability of LLMs. First, existing benchmarks offer a limited development knowledge scope, mainly focusing on code understanding and neglecting broader knowledge during development. Second, some benchmarks are not built from real user queries. To bridge this gap, we design a three-phase pipeline that transforms real-world dialogue into simple development knowledge-seeking QA pairs. Through this pipeline, we introduce SimpleDevQA, a multilingual benchmark derived from real user dialogues. It contains 2,740 QA pairs in three languages (English, Chinese, and Russian), and focuses on questions with unique, short, and verifiable answers for accurate and simple evaluation. Experiments show that: Code LLMs generally outperform general LLMs of similar scale; Knowledge injection with the Retrieval-Augmented Generation (RAG) strategy can boost LLM accuracy by 11.3% on average; LLMs show systematic overconfidence in Dev Knowledge QA, and the answering accuracy of LLMs shows a positive correlation with their stated confidence; Generally, LLMs with stronger code generation performance also exhibit stronger performance in Dev Knowledge QA.

</details>


### [20] [Exploring the Garden of Forking Paths in Empirical Software Engineering Research: A Multiverse Analysis](https://arxiv.org/abs/2512.08910)
*Nathan Cassee,Robert Feldt*

Main category: cs.SE

TL;DR: 对软件工程实证研究中"分岔路径花园"问题的多宇宙分析，发现分析方法选择对结果影响巨大，仅有不到0.2%的分析路径能复现原论文结果。


<details>
  <summary>Details</summary>
Motivation: 软件工程实证研究中，研究人员在数据处理、操作化定义和统计模型选择方面有较大自由度（"分岔路径花园"问题），这种自由度虽然提供了灵活性，但也威胁到研究的稳健性和可复现性。

Method: 采用多宇宙分析方法，选取一篇已发表的软件仓库挖掘研究论文，识别出9个关键分析决策点（每个都有至少一个同等合理的替代方案），系统性地在原始数据集上运行所有3,072种分析路径组合。

Result: 仅有6个分析宇宙（<0.2%）能够复现已发表的结果；绝大多数分析路径产生了质量上不同的发现，有时甚至得出相反的结论。

Conclusion: 分析方法选择对结果的影响比通常认知的更为深远。建议软件工程研究者补充稳健性检查，明确论证每个分析决策的合理性，并提出结构化分类模型来改进方法选择的论证。多宇宙分析是提高研究可靠性和可复现性的实用工具。

Abstract: In empirical software engineering (SE) research, researchers have considerable freedom to decide how to process data, what operationalizations to use, and which statistical model to fit. Gelman and Loken refer to this freedom as leading to a "garden of forking paths". Although this freedom is often seen as an advantage, it also poses a threat to robustness and replicability: variations in analytical decisions, even when justifiable, can lead to divergent conclusions.
  To better understand this risk, we conducted a so-called multiverse analysis on a published empirical SE paper. The paper we picked is a Mining Software Repositories study, as MSR studies commonly use non-trivial statistical models to analyze post-hoc, observational data. In the study, we identified nine pivotal analytical decisions-each with at least one equally defensible alternative and systematically reran all the 3,072 resulting analysis pipelines on the original dataset. Interestingly, only 6 of these universes (<0.2%) reproduced the published results; the overwhelming majority produced qualitatively different, and sometimes even opposite, findings.
  This case study of a data analytical method commonly applied to empirical software engineering data reveals how methodological choices can exert a more profound influence on outcomes than is often acknowledged. We therefore advocate that SE researchers complement standard reporting with robustness checks across plausible analysis variants or, at least, explicitly justify each analytical decision. We propose a structured classification model to help classify and improve justification for methodological choices. Secondly, we show how the multiverse analysis is a practical tool in the methodological arsenal of SE researchers, one that can help produce more reliable, reproducible science.

</details>
