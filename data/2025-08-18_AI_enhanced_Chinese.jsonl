{"id": "2508.11019", "categories": ["cs.LO", "cs.FL", "F.1.3; F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2508.11019", "abs": "https://arxiv.org/abs/2508.11019", "authors": ["Anuj Dawar", "Aidan T. Evans"], "title": "Characterizing NC1 with Typed Monoids", "comment": "22 pages", "summary": "Krebs et al. (2007) gave a characterization of the complexity class TC0 as\nthe class of languages recognized by a certain class of typed monoids. The\nnotion of typed monoid was introduced to extend methods of algebraic automata\ntheory to infinite monoids and hence characterize classes beyond the regular\nlanguages. We advance this line of work beyond TC0 by giving a characterization\nof NC1. This is obtained by first showing that NC1 can be defined as the\nlanguages expressible in an extension of first-order logic using only unary\nquantifiers over regular languages. The expressibility result is a consequence\nof a general result showing that finite monoid multiplication quantifiers of\nhigher dimension can be replaced with unary quantifiers in the context of\ninterpretations over strings, which also answers a question of Lautemann et al.\n(2001). We establish this collapse result for a much more general class of\ninterpretations using results on interpretations due to Boja\\'nczyk et al.\n(2019), which may be of independent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86Krebs\u7b49\u4eba\uff082007\uff09\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u903b\u8f91\u6269\u5c55\u548c\u91cf\u5316\u65b9\u6cd5\uff0c\u5c06NC1\u590d\u6742\u6027\u7c7b\u8868\u5f81\u4e3a\u4e00\u7c7b\u7279\u5b9a\u903b\u8f91\u8868\u8fbe\u7684\u8bed\u8a00\u3002", "motivation": "\u6269\u5c55\u4ee3\u6570\u81ea\u52a8\u673a\u7406\u8bba\u65b9\u6cd5\uff0c\u4ee5\u8868\u5f81\u8d85\u8d8aTC0\u7684\u590d\u6742\u6027\u7c7bNC1\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u4e00\u9636\u903b\u8f91\u5e76\u4ec5\u4f7f\u7528\u4e00\u5143\u91cf\u8bcd\uff0c\u7ed3\u5408\u6709\u9650\u5e7a\u534a\u7fa4\u4e58\u6cd5\u91cf\u8bcd\u7684\u66ff\u6362\uff0c\u5b9e\u73b0NC1\u7684\u8868\u5f81\u3002", "result": "\u8bc1\u660e\u4e86NC1\u53ef\u4ee5\u901a\u8fc7\u7279\u5b9a\u903b\u8f91\u8868\u8fbe\uff0c\u5e76\u89e3\u51b3\u4e86Lautemann\u7b49\u4eba\uff082001\uff09\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u8868\u5f81\u4e86NC1\uff0c\u8fd8\u6269\u5c55\u4e86Boja\u0144czyk\u7b49\u4eba\uff082019\uff09\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u5177\u6709\u72ec\u7acb\u610f\u4e49\u3002"}}
{"id": "2508.11034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11034", "abs": "https://arxiv.org/abs/2508.11034", "authors": ["Antonio Collante", "Samuel Abedu", "SayedHassan Khatoonabadi", "Ahmad Abdellatif", "Ebube Alor", "Emad Shihab"], "title": "The Impact of Large Language Models (LLMs) on Code Review Process", "comment": null, "summary": "Large language models (LLMs) have recently gained prominence in the field of\nsoftware development, significantly boosting productivity and simplifying\nteamwork. Although prior studies have examined task-specific applications, the\nphase-specific effects of LLM assistance on the efficiency of code review\nprocesses remain underexplored. This research investigates the effect of GPT on\nGitHub pull request (PR) workflows, with a focus on reducing resolution time,\noptimizing phase-specific performance, and assisting developers. We curated a\ndataset of 25,473 PRs from 9,254 GitHub projects and identified GPT-assisted\nPRs using a semi-automated heuristic approach that combines keyword-based\ndetection, regular expression filtering, and manual verification until\nachieving 95% labeling accuracy. We then applied statistical modeling,\nincluding multiple linear regression and Mann-Whitney U test, to evaluate\ndifferences between GPT-assisted and non-assisted PRs, both at the overall\nresolution level and across distinct review phases. Our research has revealed\nthat early adoption of GPT can substantially boost the effectiveness of the PR\nprocess, leading to considerable time savings at various stages. Our findings\nsuggest that GPT-assisted PRs reduced median resolution time by more than 60%\n(9 hours compared to 23 hours for non-assisted PRs). We discovered that\nutilizing GPT can reduce the review time by 33% and the waiting time before\nacceptance by 87%. Analyzing a sample dataset of 300 GPT-assisted PRs, we\ndiscovered that developers predominantly use GPT for code optimization (60%),\nbug fixing (26%), and documentation updates (12%). This research sheds light on\nthe impact of the GPT model on the code review process, offering actionable\ninsights for software teams seeking to enhance workflows and promote seamless\ncollaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86GPT\u5728GitHub\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u51cf\u5c11\u89e3\u51b3\u65f6\u95f4\uff0c\u4f18\u5316\u5404\u9636\u6bb5\u6027\u80fd\uff0c\u5e76\u5e2e\u52a9\u5f00\u53d1\u8005\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u4ee3\u7801\u5ba1\u67e5\u5404\u9636\u6bb5\u7684\u5177\u4f53\u6548\u679c\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\u7b5b\u9009GPT\u8f85\u52a9\u7684PR\uff0c\u5e76\u8fd0\u7528\u7edf\u8ba1\u6a21\u578b\uff08\u5982\u591a\u5143\u7ebf\u6027\u56de\u5f52\u548cMann-Whitney U\u68c0\u9a8c\uff09\u8fdb\u884c\u5206\u6790\u3002", "result": "GPT\u8f85\u52a9\u7684PR\u4e2d\u4f4d\u89e3\u51b3\u65f6\u95f4\u51cf\u5c1160%\uff0c\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1133%\uff0c\u7b49\u5f85\u65f6\u95f4\u51cf\u5c1187%\u3002", "conclusion": "GPT\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\uff0c\u4e3a\u56e2\u961f\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2508.11110", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11110", "abs": "https://arxiv.org/abs/2508.11110", "authors": ["Mukul Singh", "Gust Verbruggen", "Vu Le", "Sumit Gulwani"], "title": "Diffusion is a code repair operator and generator", "comment": "12 pages", "summary": "Code diffusion models generate code by iteratively removing noise from the\nlatent representation of a code snippet. During later steps of the diffusion\nprocess, when the code snippet has almost converged, differences between\ndiscrete representations of these snippets look like last-mile repairs applied\nto broken or incomplete code. We evaluate the extent to which this resemblance\ncan be exploited to leverage pre-trained code diffusion models for the problem\nof last-mile repair by considering two applications with significant potential.\nFirst, we can leverage the diffusion model for last-mile repair by adding noise\nto a broken code snippet and resuming the diffusion process. Second, we can\nleverage the diffusion model to generate arbitrary amount of training data for\nlast-mile repair tasks (that are computationally more efficient) by sampling an\nintermediate program (input) and the final program (output) from the diffusion\nprocess. We perform experiments on 3 domains (Python, Excel and PowerShell) to\nevaluate applications, as well as analyze properties.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528\u9884\u8bad\u7ec3\u7684\u4ee3\u7801\u6269\u6563\u6a21\u578b\u8fdb\u884c\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\uff0c\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u6216\u751f\u6210\u8bad\u7ec3\u6570\u636e\u6765\u4f18\u5316\u4ee3\u7801\u7247\u6bb5\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5229\u7528\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u540e\u671f\u9636\u6bb5\u7684\u7279\u6027\uff0c\u89e3\u51b3\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u5e76\u6062\u590d\u6269\u6563\u8fc7\u7a0b\uff0c\u6216\u4ece\u6269\u6563\u8fc7\u7a0b\u4e2d\u91c7\u6837\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u8bc4\u4f30\u5176\u5728Python\u3001Excel\u548cPowerShell\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6269\u6563\u6a21\u578b\u5728\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5728\u4e0d\u540c\u9886\u57df\u7684\u6027\u80fd\u3002", "conclusion": "\u4ee3\u7801\u6269\u6563\u6a21\u578b\u5728\u6700\u540e\u4e00\u82f1\u91cc\u4fee\u590d\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u751f\u6210\u9ad8\u6548\u8bad\u7ec3\u6570\u636e\u5e76\u4f18\u5316\u4ee3\u7801\u4fee\u590d\u8fc7\u7a0b\u3002"}}
{"id": "2508.11297", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.11297", "abs": "https://arxiv.org/abs/2508.11297", "authors": ["Casper Bach"], "title": "Generic Reduction-Based Interpreters (Extended Version)", "comment": null, "summary": "Reduction-based interpreters are traditionally defined in terms of a one-step\nreduction function which systematically decomposes a term into a potential\nredex and context, contracts the redex, and recomposes it to construct the new\nterm to be further reduced. While implementing such interpreters follows a\nsystematic recipe, they often require interpreter engineers to write a\nsubstantial amount of code -- much of it boilerplate. In this paper, we apply\nwell-known techniques from generic programming to reduce boilerplate code in\nreduction-based interpreters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\u51cf\u5c11\u57fa\u4e8e\u89c4\u7ea6\u7684\u89e3\u91ca\u5668\u4e2d\u7684\u6837\u677f\u4ee3\u7801\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u7ea6\u7684\u89e3\u91ca\u5668\u9700\u8981\u5927\u91cf\u6837\u677f\u4ee3\u7801\uff0c\u589e\u52a0\u4e86\u5b9e\u73b0\u590d\u6742\u5ea6\u3002", "method": "\u5e94\u7528\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\u4f18\u5316\u4ee3\u7801\u7ed3\u6784\u3002", "result": "\u51cf\u5c11\u4e86\u6837\u677f\u4ee3\u7801\uff0c\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "\u6cdb\u578b\u7f16\u7a0b\u80fd\u6709\u6548\u7b80\u5316\u57fa\u4e8e\u89c4\u7ea6\u7684\u89e3\u91ca\u5668\u5b9e\u73b0\u3002"}}
{"id": "2508.11126", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11126", "abs": "https://arxiv.org/abs/2508.11126", "authors": ["Huanting Wang", "Jingzhi Gong", "Huawei Zhang", "Zheng Wang"], "title": "AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities", "comment": null, "summary": "AI agentic programming is an emerging paradigm in which large language models\n(LLMs) autonomously plan, execute, and interact with external tools like\ncompilers, debuggers, and version control systems to iteratively perform\ncomplex software development tasks. Unlike conventional code generation tools,\nagentic systems are capable of decomposing high-level goals, coordinating\nmulti-step processes, and adapting their behavior based on intermediate\nfeedback. These capabilities are transforming the software development\npractice. As this emerging field evolves rapidly, there is a need to define its\nscope, consolidate its technical foundations, and identify open research\nchallenges. This survey provides a comprehensive and timely review of AI\nagentic programming. We introduce a taxonomy of agent behaviors and system\narchitectures, and examine core techniques including planning, memory and\ncontext management, tool integration, and execution monitoring. We also analyze\nexisting benchmarks and evaluation methodologies used to assess coding agent\nperformance. Our study identifies several key challenges, including limitations\nin handling long context, a lack of persistent memory across tasks, and\nconcerns around safety, alignment with user intent, and collaboration with\nhuman developers. We discuss emerging opportunities to improve the reliability,\nadaptability, and transparency of agentic systems. By synthesizing recent\nadvances and outlining future directions, this survey aims to provide a\nfoundation for research and development in building the next generation of\nintelligent and trustworthy AI coding agents.", "AI": {"tldr": "AI\u4ee3\u7406\u7f16\u7a0b\u662f\u4e00\u79cd\u65b0\u5174\u8303\u5f0f\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4e3b\u89c4\u5212\u3001\u6267\u884c\u5e76\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\uff0c\u5b8c\u6210\u590d\u6742\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u3002\u672c\u6587\u7efc\u8ff0\u4e86\u5176\u8303\u56f4\u3001\u6280\u672f\u57fa\u7840\u53ca\u7814\u7a76\u6311\u6218\u3002", "motivation": "\u5b9a\u4e49AI\u4ee3\u7406\u7f16\u7a0b\u7684\u8303\u7574\uff0c\u5de9\u56fa\u5176\u6280\u672f\u57fa\u7840\uff0c\u5e76\u8bc6\u522b\u5f00\u653e\u7814\u7a76\u6311\u6218\uff0c\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4ee3\u7406\u884c\u4e3a\u548c\u7cfb\u7edf\u67b6\u6784\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u6838\u5fc3\u6280\u672f\uff08\u5982\u89c4\u5212\u3001\u8bb0\u5fc6\u7ba1\u7406\u3001\u5de5\u5177\u96c6\u6210\u7b49\uff09\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u57fa\u51c6\u548c\u65b9\u6cd5\u3002", "result": "\u603b\u7ed3\u4e86AI\u4ee3\u7406\u7f16\u7a0b\u7684\u5173\u952e\u6311\u6218\uff08\u5982\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u3001\u6301\u4e45\u8bb0\u5fc6\u7f3a\u5931\u3001\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u95ee\u9898\uff09\u53ca\u6539\u8fdb\u673a\u4f1a\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u53ef\u4fe1AI\u7f16\u7801\u4ee3\u7406\u7684\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2508.11443", "categories": ["cs.PL", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.11443", "abs": "https://arxiv.org/abs/2508.11443", "authors": ["William Henrich Due", "Martin Elsman", "Troels Henriksen"], "title": "Towards Efficient Hash Maps in Functional Array Languages", "comment": null, "summary": "We present a systematic derivation of a data-parallel implementation of\ntwo-level, static and collision-free hash maps, by giving a functional\nformulation of the Fredman et al. construction, and then flattening it. We\ndiscuss the challenges of providing a flexible, polymorphic, and abstract\ninterface to hash maps in a functional array language, with particular\nattention paid to the problem of dynamically sized keys, which we address by\nassociating each hash map with an arbitrary context. The algorithm is\nimplemented in Futhark, and the achieved GPU execution performance is compared\non simple benchmark problems. We find that our hash maps outperform\nconventional tree/search-based approaches. Furthermore, our implementation is\ncompared against the state-of-the-art cuCollections library, which is\nsignificantly faster for hash map construction, and to a lesser degree for\nlookups. We explain to which extent the performance difference is due to\nlow-level code generation limitation in the Futhark compiler, and to which\nextent it can be attributed to the data-parallel programming vocabulary not\nproviding the constructs necessary to express the equivalent of the algorithms\nused by cuCollections. We end by reflecting to which extent the functional\narray language programming model could, or should, be extended to address these\nweaknesses.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u5e76\u884c\u7684\u4e24\u7ea7\u9759\u6001\u65e0\u51b2\u7a81\u54c8\u5e0c\u6620\u5c04\u5b9e\u73b0\u65b9\u6cd5\uff0c\u57fa\u4e8eFredman\u7b49\u4eba\u7684\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u529f\u80fd\u5316\u548c\u5e73\u5766\u5316\u5b9e\u73b0\u3002\u8ba8\u8bba\u4e86\u5728\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u4e2d\u63d0\u4f9b\u7075\u6d3b\u3001\u591a\u6001\u548c\u62bd\u8c61\u63a5\u53e3\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u52a8\u6001\u5927\u5c0f\u952e\u7684\u95ee\u9898\u3002\u7b97\u6cd5\u5728Futhark\u4e2d\u5b9e\u73b0\uff0cGPU\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u6811/\u641c\u7d22\u65b9\u6cd5\uff0c\u4f46\u6bd4cuCollections\u5e93\u6162\u3002\u5206\u6790\u4e86\u6027\u80fd\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u5e76\u63a2\u8ba8\u4e86\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\u53ef\u80fd\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u4e2d\u54c8\u5e0c\u6620\u5c04\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\u95ee\u9898\uff0c\u7279\u522b\u662f\u52a8\u6001\u5927\u5c0f\u952e\u7684\u5904\u7406\uff0c\u540c\u65f6\u63a2\u7d22\u6570\u636e\u5e76\u884c\u5b9e\u73b0\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u529f\u80fd\u5316Fredman\u7b49\u4eba\u7684\u6784\u5efa\u65b9\u6cd5\u5e76\u5e73\u5766\u5316\uff0c\u5b9e\u73b0\u4e24\u7ea7\u9759\u6001\u65e0\u51b2\u7a81\u54c8\u5e0c\u6620\u5c04\u3002\u5728Futhark\u4e2d\u5b9e\u73b0\uff0c\u5e76\u5bf9\u6bd4GPU\u6027\u80fd\u3002", "result": "\u5b9e\u73b0\u7684\u54c8\u5e0c\u6620\u5c04\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u6bd4cuCollections\u5e93\u6162\u3002\u6027\u80fd\u5dee\u5f02\u90e8\u5206\u6e90\u4e8eFuthark\u7f16\u8bd1\u5668\u7684\u9650\u5236\uff0c\u90e8\u5206\u6e90\u4e8e\u6570\u636e\u5e76\u884c\u7f16\u7a0b\u6a21\u578b\u7684\u8868\u8fbe\u4e0d\u8db3\u3002", "conclusion": "\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u9700\u8981\u6269\u5c55\u4ee5\u89e3\u51b3\u6027\u80fd\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u62bd\u8c61\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.11136", "categories": ["cs.LO", "D.2.4; F.3.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.11136", "abs": "https://arxiv.org/abs/2508.11136", "authors": ["Richard Waldinger"], "title": "Automating the Derivation of Unification Algorithms: A Case Study in Deductive Program Synthesis", "comment": "92 pages", "summary": "The unification algorithm has long been a target for program synthesis\nresearch, but a fully automatic derivation remains a research goal. In\ndeductive program synthesis, computer programming is phrased as a task in\ntheorem proving; a declarative specification is expressed in logical form and\npresented to an automatic theorem prover, and a program meeting the\nspecification is extracted from the proof. The correctness of the program is\nsupported by the proof, which also provides an explanation of how the program\nworks. The proof is conducted in an appropriate axiomatic subject-domain\ntheory, which defines the concepts in the specification and the constructs in\nthe target programming language and provides the background knowledge necessary\nto connect them.\n  For the unification proof, we generalize and automate the manual proof\npresented in Manna and Waldinger [1981]. The new program unifies two given\nsymbolic expressions (s-expressions) relative to a given \"environment\"\nsubstitution. The proof establishes the existence of an output substitution\nthat is a most-general idempotent unifier of the given expressions and is an\n\"extension\" of the environment substitution. If no such substitution exists and\nthe expressions are not unifiable, the program is to produce a failure\nindicator.\n  Initially the environment substitution is the empty substitution, which makes\nno replacements at all; during execution of recursive calls, the environment\nsubstitution records the replacements that have been found so far. Our own\nunification algorithm employs an environment, and such algorithms appear in the\nliterature [e.g., Luger and Stubblefield, 1997]. We suspect, in addition to\nbeing more efficient, the three-argument algorithm with an environment is\neasier to synthesize automatically than the two-argument version from the\nManna-Waldinger paper.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u52a8\u63a8\u5bfc\u7edf\u4e00\u7b97\u6cd5\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u7406\u8bc1\u660e\u751f\u6210\u6ee1\u8db3\u89c4\u683c\u7684\u7a0b\u5e8f\uff0c\u5e76\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002", "motivation": "\u7edf\u4e00\u7b97\u6cd5\u662f\u7a0b\u5e8f\u5408\u6210\u7814\u7a76\u7684\u91cd\u8981\u76ee\u6807\uff0c\u4f46\u5b8c\u5168\u81ea\u52a8\u63a8\u5bfc\u4ecd\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5b9a\u7406\u8bc1\u660e\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u5408\u6210\u3002", "method": "\u91c7\u7528\u6f14\u7ece\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\uff0c\u5c06\u7f16\u7a0b\u4efb\u52a1\u8f6c\u5316\u4e3a\u5b9a\u7406\u8bc1\u660e\u95ee\u9898\uff0c\u5e76\u5728\u9002\u5f53\u7684\u516c\u7406\u9886\u57df\u7406\u8bba\u4e2d\u8fdb\u884c\u8bc1\u660e\u3002", "result": "\u6210\u529f\u751f\u6210\u4e86\u4e00\u4e2a\u4e09\u53c2\u6570\u7edf\u4e00\u7b97\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u73af\u5883\u66ff\u6362\u5e76\u8f93\u51fa\u6700\u4e00\u822c\u5e42\u7b49\u7edf\u4e00\u5668\u3002", "conclusion": "\u5e26\u73af\u5883\u7684\u4e09\u53c2\u6570\u7b97\u6cd5\u6bd4\u4f20\u7edf\u4e24\u53c2\u6570\u7248\u672c\u66f4\u9ad8\u6548\u4e14\u6613\u4e8e\u81ea\u52a8\u5408\u6210\u3002"}}
{"id": "2508.11147", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2508.11147", "abs": "https://arxiv.org/abs/2508.11147", "authors": ["Zhengquan Li", "Zhenhao Li", "Zishuo Ding"], "title": "From Feedback to Failure: Automated Android Performance Issue Reproduction", "comment": "10page, 8 figures", "summary": "Mobile application performance is a vital factor for user experience. Yet,\nperformance issues are notoriously difficult to detect within development\nenvironments, where their manifestations are often less conspicuous and\ndiagnosis proves more challenging. To address this limitation, we propose\nRevPerf, an advanced performance issue reproduction tool that leverages app\nreviews from Google Play to acquire pertinent information. RevPerf employs\nrelevant reviews and prompt engineering to enrich the original review with\nperformance issue details. An execution agent is then employed to generate and\nexecute commands to reproduce the issue. After executing all necessary steps,\nthe system incorporates multifaceted detection methods to identify performance\nissues by monitoring Android logs, GUI changes, and system resource utilization\nduring the reproduction process. Experimental results demonstrate that our\nproposed framework achieves a 70\\% success rate in reproducing performance\nissues on the dataset we constructed and manually validated.", "AI": {"tldr": "RevPerf\u662f\u4e00\u4e2a\u5229\u7528Google Play\u5e94\u7528\u8bc4\u8bba\u68c0\u6d4b\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u4e30\u5bcc\u8bc4\u8bba\u5185\u5bb9\u5e76\u6267\u884c\u547d\u4ee4\u590d\u73b0\u95ee\u9898\uff0c\u6210\u529f\u7387\u8fbe70%\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u5728\u5f00\u53d1\u73af\u5883\u4e2d\u96be\u4ee5\u68c0\u6d4b\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u590d\u73b0\u548c\u8bca\u65ad\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "RevPerf\u5229\u7528Google Play\u8bc4\u8bba\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u4e30\u5bcc\u8bc4\u8bba\u5185\u5bb9\uff0c\u751f\u6210\u5e76\u6267\u884c\u547d\u4ee4\u590d\u73b0\u95ee\u9898\uff0c\u540c\u65f6\u76d1\u6d4bAndroid\u65e5\u5fd7\u3001GUI\u53d8\u5316\u548c\u7cfb\u7edf\u8d44\u6e90\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cRevPerf\u5728\u6784\u5efa\u7684\u6570\u636e\u96c6\u4e0a\u590d\u73b0\u6027\u80fd\u95ee\u9898\u7684\u6210\u529f\u7387\u4e3a70%\u3002", "conclusion": "RevPerf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u590d\u73b0\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u5728\u65e9\u671f\u53d1\u73b0\u548c\u89e3\u51b3\u95ee\u9898\u3002"}}
{"id": "2508.11447", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.11447", "abs": "https://arxiv.org/abs/2508.11447", "authors": ["Maximiliano Cristi\u00e1", "Gianfranco Rossi"], "title": "Encoding and Reasoning About Arrays in Set Theory", "comment": "Under consideration at ACM Transactions on Computational Logic", "summary": "We encode arrays as functions which, in turn, are encoded as sets of ordered\npairs. The set cardinality of each of these functions coincides with the length\nof the array it is representing. Then we define a fragment of set theory that\nis used to give the specifications of a non-trivial class of programs with\narrays. In this way, array reasoning becomes set reasoning. Furthermore, a\ndecision procedure for this fragment is also provided and implemented as part\nof the {log} (read 'setlog') tool. {log} is a constraint logic programming\nlanguage and satisfiability solver where sets and binary relations are\nfirst-class citizens. The tool already implements a few decision procedures for\ndifferent fragments of set theory. In this way, arrays are seamlessly\nintegrated into {log} thus allowing users to reason about sets, functions and\narrays all in the same language and with the same solver. The decision\nprocedure presented in this paper is an extension of decision procedures\ndefined in earlier works not supporting arrays.", "AI": {"tldr": "\u5c06\u6570\u7ec4\u7f16\u7801\u4e3a\u51fd\u6570\uff0c\u518d\u8fdb\u4e00\u6b65\u7f16\u7801\u4e3a\u6709\u5e8f\u5bf9\u96c6\u5408\uff0c\u901a\u8fc7\u96c6\u5408\u8bba\u7247\u6bb5\u5b9e\u73b0\u6570\u7ec4\u7a0b\u5e8f\u89c4\u8303\uff0c\u5e76\u6269\u5c55\u4e86{log}\u5de5\u5177\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "motivation": "\u5c06\u6570\u7ec4\u63a8\u7406\u8f6c\u5316\u4e3a\u96c6\u5408\u63a8\u7406\uff0c\u7edf\u4e00\u8bed\u8a00\u548c\u6c42\u89e3\u5668\u5904\u7406\u96c6\u5408\u3001\u51fd\u6570\u548c\u6570\u7ec4\u3002", "method": "\u5b9a\u4e49\u96c6\u5408\u8bba\u7247\u6bb5\uff0c\u7f16\u7801\u6570\u7ec4\u4e3a\u51fd\u6570\u548c\u6709\u5e8f\u5bf9\u96c6\u5408\uff0c\u6269\u5c55{log}\u5de5\u5177\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5b9e\u73b0\u4e86\u6570\u7ec4\u4e0e{log}\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u652f\u6301\u96c6\u5408\u3001\u51fd\u6570\u548c\u6570\u7ec4\u7684\u7edf\u4e00\u63a8\u7406\u3002", "conclusion": "\u901a\u8fc7\u96c6\u5408\u8bba\u65b9\u6cd5\u6210\u529f\u6269\u5c55\u4e86{log}\u5de5\u5177\uff0c\u4f7f\u5176\u652f\u6301\u6570\u7ec4\u63a8\u7406\u3002"}}
{"id": "2508.11179", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11179", "abs": "https://arxiv.org/abs/2508.11179", "authors": ["Pei Liu", "Terry Zhuo", "Jiawei Deng", "Zhenchang Xing", "Qinghua Lu", "Xiaoning Du", "Hongyu Zhan"], "title": "PTMPicker: Facilitating Efficient Pretrained Model Selection for Application Developers", "comment": null, "summary": "The rapid emergence of pretrained models (PTMs) has attracted significant\nattention from both Deep Learning (DL) researchers and downstream application\ndevelopers. However, selecting appropriate PTMs remains challenging because\nexisting methods typically rely on keyword-based searches in which the keywords\nare often derived directly from function descriptions. This often fails to\nfully capture user intent and makes it difficult to identify suitable models\nwhen developers also consider factors such as bias mitigation, hardware\nrequirements, or license compliance. To address the limitations of\nkeyword-based model search, we propose PTMPicker to accurately identify\nsuitable PTMs. We first define a structured template composed of common and\nessential attributes for PTMs and then PTMPicker represents both candidate\nmodels and user-intended features (i.e., model search requests) in this unified\nformat. To determine whether candidate models satisfy user requirements, it\ncomputes embedding similarities for function-related attributes and uses\nwell-crafted prompts to evaluate special constraints such as license compliance\nand hardware requirements. We scraped a total of 543,949 pretrained models from\nHugging Face to prepare valid candidates for selection. PTMPicker then\nrepresented them in the predefined structured format by extracting their\nassociated descriptions. Guided by the extracted metadata, we synthesized a\ntotal of 15,207 model search requests with carefully designed prompts, as no\nsuch search requests are readily available. Experiments on the curated PTM\ndataset and the synthesized model search requests show that PTMPicker can help\nusers effectively identify models,with 85% of the sampled requests successfully\nlocating appropriate PTMs within the top-10 ranked candidates.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPTMPicker\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u677f\u548c\u5d4c\u5165\u76f8\u4f3c\u6027\u8ba1\u7b97\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u51c6\u786e\u5730\u9009\u62e9\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u6a21\u578b\u641c\u7d22\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u6355\u6349\u7528\u6237\u610f\u56fe\uff0c\u5c24\u5176\u662f\u5728\u8003\u8651\u504f\u5dee\u7f13\u89e3\u3001\u786c\u4ef6\u8981\u6c42\u6216\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u7b49\u56e0\u7d20\u65f6\u3002", "method": "\u5b9a\u4e49\u7ed3\u6784\u5316\u6a21\u677f\u8868\u793a\u6a21\u578b\u548c\u7528\u6237\u9700\u6c42\uff0c\u8ba1\u7b97\u5d4c\u5165\u76f8\u4f3c\u6027\u8bc4\u4f30\u529f\u80fd\u5c5e\u6027\uff0c\u4f7f\u7528\u63d0\u793a\u8bc4\u4f30\u7279\u6b8a\u7ea6\u675f\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cPTMPicker\u6210\u529f\u4e3a85%\u7684\u8bf7\u6c42\u5728\u524d10\u5019\u9009\u4e2d\u627e\u5230\u5408\u9002\u6a21\u578b\u3002", "conclusion": "PTMPicker\u6709\u6548\u89e3\u51b3\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u641c\u7d22\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2508.11449", "categories": ["cs.LO", "03B05 (Primary)"], "pdf": "https://arxiv.org/pdf/2508.11449", "abs": "https://arxiv.org/abs/2508.11449", "authors": ["Patrick Koopmann", "Christoph Wernhard", "Frank Wolter"], "title": "Interpolation in Classical Propositional Logic", "comment": "The article will appear in Balder ten Cate, Jean Christoph Jung,\n  Patrick Koopmann, Christoph Wernhard and Frank Wolter, editors. Theory and\n  Applications of Craig Interpolation. Ubiquity Press, 2026", "summary": "We introduce Craig interpolation and related notions such as uniform\ninterpolation, Beth definability, and theory decomposition in classical\npropositional logic. We present four approaches to computing interpolants: via\nquantifier elimination, from formulas in disjunctive normal form, and by\nextraction from resolution or tableau refutations. We close with a discussion\nof the size of interpolants and links to circuit complexity.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u7ecf\u5178\u547d\u9898\u903b\u8f91\u4e2d\u7684Craig\u63d2\u503c\u53ca\u76f8\u5173\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\u56db\u79cd\u8ba1\u7b97\u63d2\u503c\u7684\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u63d2\u503c\u5927\u5c0f\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u7684\u8054\u7cfb\u3002", "motivation": "\u7814\u7a76\u7ecf\u5178\u547d\u9898\u903b\u8f91\u4e2d\u7684\u63d2\u503c\u95ee\u9898\uff0c\u63a2\u7d22\u4e0d\u540c\u65b9\u6cd5\u8ba1\u7b97\u63d2\u503c\u5e76\u5206\u6790\u5176\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u91cf\u8bcd\u6d88\u53bb\u3001\u6790\u53d6\u8303\u5f0f\u516c\u5f0f\u3001\u4ece\u5f52\u7ed3\u6216\u8868\u63a8\u6f14\u4e2d\u63d0\u53d6\u56db\u79cd\u65b9\u6cd5\u8ba1\u7b97\u63d2\u503c\u3002", "result": "\u63d0\u51fa\u4e86\u56db\u79cd\u6709\u6548\u7684\u63d2\u503c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u63d2\u503c\u5927\u5c0f\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u7684\u5173\u7cfb\u3002", "conclusion": "\u8bba\u6587\u4e3a\u7ecf\u5178\u547d\u9898\u903b\u8f91\u4e2d\u7684\u63d2\u503c\u95ee\u9898\u63d0\u4f9b\u4e86\u591a\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u7684\u8054\u7cfb\u3002"}}
{"id": "2508.11222", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.11222", "abs": "https://arxiv.org/abs/2508.11222", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Jiashui Wang", "Xinlei Ying", "Long Liu", "Wenhai Wang"], "title": "ORFuzz: Fuzzing the \"Other Side\" of LLM Safety -- Testing Over-Refusal", "comment": null, "summary": "Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously\nrejecting benign queries due to overly conservative safety measures - a\ncritical functional flaw that undermines their reliability and usability.\nCurrent methods for testing this behavior are demonstrably inadequate,\nsuffering from flawed benchmarks and limited test generation capabilities, as\nhighlighted by our empirical user study. To the best of our knowledge, this\npaper introduces the first evolutionary testing framework, ORFuzz, for the\nsystematic detection and analysis of LLM over-refusals. ORFuzz uniquely\nintegrates three core components: (1) safety category-aware seed selection for\ncomprehensive test coverage, (2) adaptive mutator optimization using reasoning\nLLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge\nmodel validated to accurately reflect user perception of toxicity and refusal.\nOur extensive evaluations demonstrate that ORFuzz generates diverse, validated\nover-refusal instances at a rate (6.98% average) more than double that of\nleading baselines, effectively uncovering vulnerabilities. Furthermore,\nORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly\ntransferable test cases that achieves a superior 63.56% average over-refusal\nrate across 10 diverse LLMs, significantly outperforming existing datasets.\nORFuzz and ORFuzzSet provide a robust automated testing framework and a\nvaluable community resource, paving the way for developing more reliable and\ntrustworthy LLM-based software systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ORFuzz\uff0c\u9996\u4e2a\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\u7684\u8fdb\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5LLM\u8fc7\u5ea6\u62d2\u7edd\u884c\u4e3a\u7684\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u5982\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u5b8c\u5584\u548c\u6d4b\u8bd5\u751f\u6210\u80fd\u529b\u6709\u9650\uff0c\u5f71\u54cd\u4e86LLM\u7684\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "ORFuzz\u6574\u5408\u4e86\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u5b89\u5168\u7c7b\u522b\u611f\u77e5\u7684\u79cd\u5b50\u9009\u62e9\u3001\u57fa\u4e8e\u63a8\u7406LLM\u7684\u81ea\u9002\u5e94\u53d8\u5f02\u4f18\u5316\uff0c\u4ee5\u53ca\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bc4\u5224\u6a21\u578bOR-Judge\u3002", "result": "ORFuzz\u751f\u6210\u7684\u8fc7\u5ea6\u62d2\u7edd\u5b9e\u4f8b\u7387\uff086.98%\uff09\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u4e24\u500d\u4ee5\u4e0a\uff0c\u5e76\u521b\u5efa\u4e86ORFuzzSet\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u8986\u76d610\u79cdLLM\uff0c\u5e73\u5747\u62d2\u7edd\u7387\u8fbe63.56%\u3002", "conclusion": "ORFuzz\u548cORFuzzSet\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u548c\u793e\u533a\u8d44\u6e90\u3002"}}
{"id": "2508.11515", "categories": ["cs.LO", "cs.AI", "03C13, 68T27", "F.4.0"], "pdf": "https://arxiv.org/pdf/2508.11515", "abs": "https://arxiv.org/abs/2508.11515", "authors": ["Qipeng Kuang", "V\u00e1clav K\u016fla", "Ond\u0159ej Ku\u017eelka", "Yuanhong Wang", "Yuyi Wang"], "title": "Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations", "comment": "24 pages, 5 figures", "summary": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the\nweighted sum of models of a given first-order logic sentence over a given\ndomain. The boundary between fragments for which WFOMC can be computed in\npolynomial time relative to the domain size lies between the two-variable\nfragment ($\\text{FO}^2$) and the three-variable fragment ($\\text{FO}^3$). It is\nknown that WFOMC for \\FOthree{} is $\\mathsf{\\#P_1}$-hard while polynomial-time\nalgorithms exist for computing WFOMC for $\\text{FO}^2$ and $\\text{C}^2$,\npossibly extended by certain axioms such as the linear order axiom, the\nacyclicity axiom, and the connectedness axiom. All existing research has\nconcentrated on extending the fragment with axioms on a single distinguished\nrelation, leaving a gap in understanding the complexity boundary of axioms on\nmultiple relations. In this study, we explore the extension of the two-variable\nfragment by axioms on two relations, presenting both negative and positive\nresults. We show that WFOMC for $\\text{FO}^2$ with two linear order relations\nand $\\text{FO}^2$ with two acyclic relations are $\\mathsf{\\#P_1}$-hard.\nConversely, we provide an algorithm in time polynomial in the domain size for\nWFOMC of $\\text{C}^2$ with a linear order relation, its successor relation and\nanother successor relation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u52a0\u6743\u4e00\u9636\u6a21\u578b\u8ba1\u6570\u95ee\u9898\uff08WFOMC\uff09\u5728\u4e8c\u53d8\u91cf\u7247\u6bb5\uff08FO\u00b2\uff09\u4e2d\u6269\u5c55\u4e24\u4e2a\u5173\u7cfb\u7684\u590d\u6742\u6027\uff0c\u53d1\u73b0\u67d0\u4e9b\u6269\u5c55\u4f1a\u5bfc\u81f4\u95ee\u9898\u53d8\u4e3a#P\u2081-\u96be\uff0c\u800c\u5176\u4ed6\u6269\u5c55\u4ecd\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6c42\u89e3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u5355\u5173\u7cfb\u4e0a\u7684\u516c\u7406\u6269\u5c55\uff0c\u7f3a\u4e4f\u5bf9\u591a\u5173\u7cfb\u516c\u7406\u6269\u5c55\u590d\u6742\u6027\u7684\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63a2\u7d22\u4e86FO\u00b2\u548cC\u00b2\u7247\u6bb5\u5728\u4e24\u79cd\u5173\u7cfb\u516c\u7406\u6269\u5c55\u4e0b\u7684\u590d\u6742\u6027\uff0c\u5305\u62ec\u8d1f\u7ed3\u679c\uff08#P\u2081-\u96be\uff09\u548c\u6b63\u7ed3\u679c\uff08\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff09\u3002", "result": "\u53d1\u73b0FO\u00b2\u6269\u5c55\u4e24\u4e2a\u7ebf\u6027\u5e8f\u5173\u7cfb\u6216\u4e24\u4e2a\u65e0\u73af\u5173\u7cfb\u65f6\u4e3a#P\u2081-\u96be\uff0c\u800cC\u00b2\u6269\u5c55\u7ebf\u6027\u5e8f\u5173\u7cfb\u53ca\u5176\u4e24\u4e2a\u540e\u7ee7\u5173\u7cfb\u65f6\u4ecd\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u6c42\u89e3\u3002", "conclusion": "\u591a\u5173\u7cfb\u516c\u7406\u6269\u5c55\u7684\u590d\u6742\u6027\u8fb9\u754c\u4e0d\u540c\u4e8e\u5355\u5173\u7cfb\u6269\u5c55\uff0c\u4e3aWFOMC\u95ee\u9898\u7684\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.11257", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11257", "abs": "https://arxiv.org/abs/2508.11257", "authors": ["Marc Pavel", "Nenad Petrovic", "Lukasz Mazur", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "Hallucination in LLM-Based Code Generation: An Automotive Case Study", "comment": null, "summary": "Large Language Models (LLMs) have shown significant potential in automating\ncode generation tasks offering new opportunities across software engineering\ndomains. However, their practical application remains limited due to\nhallucinations - outputs that appear plausible but are factually incorrect,\nunverifiable or nonsensical. This paper investigates hallucination phenomena in\nthe context of code generation with a specific focus on the automotive domain.\nA case study is presented that evaluates multiple code LLMs for three different\nprompting complexities ranging from a minimal one-liner prompt to a prompt with\nCovesa Vehicle Signal Specifications (VSS) as additional context and finally to\na prompt with an additional code skeleton. The evaluation reveals a high\nfrequency of syntax violations, invalid reference errors and API knowledge\nconflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the\nevaluated models, only GPT-4.1 and GPT-4o were able to produce a correct\nsolution when given the most context-rich prompt. Simpler prompting strategies\nfailed to yield a working result, even after multiple refinement iterations.\nThese findings highlight the need for effective mitigation techniques to ensure\nthe safe and reliable use of LLM generated code, especially in safety-critical\ndomains such as automotive software systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6c7d\u8f66\u9886\u57df\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u63d0\u793a\u590d\u6742\u5ea6\u4e0b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u9ad8\u9891\u7387\u7684\u9519\u8bef\uff0c\u4ec5\u5c11\u6570\u6a21\u578b\u5728\u4e30\u5bcc\u4e0a\u4e0b\u6587\u7684\u63d0\u793a\u4e0b\u80fd\u751f\u6210\u6b63\u786e\u4ee3\u7801\u3002", "motivation": "LLMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5e7b\u89c9\u95ee\u9898\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u7684\u6c7d\u8f66\u9886\u57df\u3002", "method": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86GPT-4.1\u3001Codex\u548cGPT-4o\u7b49\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u590d\u6742\u5ea6\u4e0b\u7684\u8868\u73b0\uff0c\u5305\u62ec\u7b80\u5355\u63d0\u793a\u3001\u5e26VSS\u4e0a\u4e0b\u6587\u7684\u63d0\u793a\u548c\u5e26\u4ee3\u7801\u9aa8\u67b6\u7684\u63d0\u793a\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u7b80\u5355\u63d0\u793a\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u4ec5GPT-4.1\u548cGPT-4o\u5728\u4e30\u5bcc\u4e0a\u4e0b\u6587\u7684\u63d0\u793a\u4e0b\u80fd\u751f\u6210\u6b63\u786e\u4ee3\u7801\u3002", "conclusion": "\u9700\u5f00\u53d1\u6709\u6548\u7684\u7f13\u89e3\u6280\u672f\uff0c\u4ee5\u786e\u4fddLLM\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2508.11623", "categories": ["cs.LO", "06B35, 06F07", "F.3.2"], "pdf": "https://arxiv.org/pdf/2508.11623", "abs": "https://arxiv.org/abs/2508.11623", "authors": ["Francesco Dagnino", "Amin Farjudian Eugenio Moggi"], "title": "Robust Topology and the Hausdorff-Smyth Monad on Metric Spaces over Continuous Quantales", "comment": "28 pages, 6 figures", "summary": "We define a (preorder-enriched) category $\\mathsf{Met}$ of quantale-valued\nmetric spaces and uniformly continuous maps, with the essential requirement\nthat the quantales are continuous. For each object $(X,d,Q)$ in this category,\nwhere $X$ is the carrier set, $Q$ is a continuous quantale, and $d: X \\times X\n\\to Q$ is the metric, we consider a topology $\\tau_d$ on $X$, which generalizes\nthe open ball topology, and a topology $\\tau_{d,R}$ on the powerset\n$\\mathsf{P}(X)$, called the robust topology, which captures robustness with\nrespect to small perturbations of parameters. We define a (preorder-enriched)\nmonad $\\mathsf{P}_S$ on $\\mathsf{Met}$, called the Hausdorff-Smyth monad, which\ncaptures the robust topology, in the sense that the open ball topology of the\nobject $\\mathsf{P}_S(X,d,Q)$ coincides with the robust topology $\\tau_{d,R}$\nfor the object $(X,d,Q)$. We prove that every topology arises from a\nquantale-valued metric. As such, our framework provides a foundation for\nquantitative reasoning about imprecision and robustness in a wide range of\ncomputational and physical systems.", "AI": {"tldr": "\u8bba\u6587\u5b9a\u4e49\u4e86\u57fa\u4e8e\u8fde\u7eed\u91cf\u5b50\u7684\u5ea6\u91cf\u7a7a\u95f4\u7c7b\u522b\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49\u5f00\u7403\u62d3\u6251\u548c\u9c81\u68d2\u62d3\u6251\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u6709\u62d3\u6251\u5747\u53ef\u7531\u91cf\u5b50\u503c\u5ea6\u91cf\u751f\u6210\uff0c\u4e3a\u5b9a\u91cf\u5206\u6790\u4e0d\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u4e3a\u8ba1\u7b97\u548c\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e0d\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u5b9a\u91cf\u5206\u6790\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8fde\u7eed\u91cf\u5b50\u7684\u5ea6\u91cf\u7a7a\u95f4\u7c7b\u522b\uff0c\u5f15\u5165\u5e7f\u4e49\u5f00\u7403\u62d3\u6251\u548c\u9c81\u68d2\u62d3\u6251\uff0c\u5e76\u6784\u5efa\u4e86Hausdorff-Smyth\u5355\u5b50\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u6709\u62d3\u6251\u5747\u53ef\u7531\u91cf\u5b50\u503c\u5ea6\u91cf\u751f\u6210\uff0c\u4e14\u9c81\u68d2\u62d3\u6251\u4e0eHausdorff-Smyth\u5355\u5b50\u7684\u5f00\u7403\u62d3\u6251\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5e7f\u6cdb\u7684\u8ba1\u7b97\u548c\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u5b9a\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.11305", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11305", "abs": "https://arxiv.org/abs/2508.11305", "authors": ["Xin Wang", "Zhenhao Li", "Zishuo Ding"], "title": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning", "comment": null, "summary": "Logging code is written by developers to capture system runtime behavior and\nplays a vital role in debugging, performance analysis, and system monitoring.\nHowever, defects in logging code can undermine the usefulness of logs and lead\nto misinterpretations. Although prior work has identified several logging\ndefect patterns and provided valuable insights into logging practices, these\nstudies often focus on a narrow range of defect patterns derived from limited\nsources (e.g., commit histories) and lack a systematic and comprehensive\nanalysis. Moreover, large language models (LLMs) have demonstrated promising\ngeneralization and reasoning capabilities across a variety of code-related\ntasks, yet their potential for detecting logging code defects remains largely\nunexplored.\n  In this paper, we derive a comprehensive taxonomy of logging code defects,\nwhich encompasses seven logging code defect patterns with 14 detailed\nscenarios. We further construct a benchmark dataset, \\dataset, consisting of\n164 developer-verified real-world logging defects. Then we propose an automated\nframework that leverages various prompting strategies and contextual\ninformation to evaluate LLMs' capability in detecting and reasoning logging\ncode defects. Experimental results reveal that LLMs generally struggle to\naccurately detect and reason logging code defects based on the source code\nonly. However, incorporating proper knowledge (e.g., detailed scenarios of\ndefect patterns) can lead to 10.9\\% improvement in detection accuracy. Overall,\nour findings provide actionable guidance for practitioners to avoid common\ndefect patterns and establish a foundation for improving LLM-based reasoning in\nlogging code defect detection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u9762\u7684\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u4e86\u771f\u5b9e\u7f3a\u9677\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u65e5\u5fd7\u7f3a\u9677\u4e2d\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLLMs\u5728\u4ec5\u57fa\u4e8e\u6e90\u4ee3\u7801\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u52a0\u5165\u9002\u5f53\u77e5\u8bc6\u540e\u53ef\u63d0\u534710.9%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u65e5\u5fd7\u8bef\u8bfb\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u4e14LLMs\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e03\u79cd\u65e5\u5fd7\u7f3a\u9677\u6a21\u5f0f\u7684\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u5305\u542b164\u4e2a\u771f\u5b9e\u7f3a\u9677\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u81ea\u52a8\u5316\u6846\u67b6\u8bc4\u4f30LLMs\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "result": "LLMs\u4ec5\u57fa\u4e8e\u6e90\u4ee3\u7801\u68c0\u6d4b\u7f3a\u9677\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u52a0\u5165\u7f3a\u9677\u6a21\u5f0f\u8be6\u7ec6\u573a\u666f\u540e\u51c6\u786e\u7387\u63d0\u534710.9%\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u907f\u514d\u5e38\u89c1\u7f3a\u9677\u7684\u6307\u5bfc\uff0c\u5e76\u4e3a\u6539\u8fdbLLMs\u5728\u65e5\u5fd7\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.11468", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11468", "abs": "https://arxiv.org/abs/2508.11468", "authors": ["Zhihao Gong", "Zeyu Sun", "Dong Huang", "Qingyuan Liang", "Jie M. Zhang", "Dan Hao"], "title": "TRACY: Benchmarking Execution Efficiency of LLM-Based Code Translation", "comment": null, "summary": "Automatic code translation is a fundamental task in modern software\ndevelopment. While the advent of Large Language Models (LLMs) has significantly\nimproved the correctness of code translation, the critical dimension of\nexecution efficiency remains overlooked. To address this gap, we introduce\nTRACY, the first comprehensive benchmark designed to evaluate the execution\nefficiency of LLM-translated code. TRACY is constructed through an LLM-driven\ntwo-stage pipeline: an initial stage generates a suite of stress tests to\namplify performance differences, followed by an efficiency-oriented task\npruning stage that isolates the efficiency-distinguishing tasks. The resulting\nbenchmark comprises 1,011 code translation tasks across C++, Java, and Python,\neach accompanied by an average of 22.1 verified reference translations and 10\ncomputationally demanding tests. Our extensive evaluation of 26 representative\nLLMs reveals that even top-tier LLMs struggle to consistently produce efficient\ncode translations. For instance, Claude-4-think, the leading model for\ncorrectness, ranks eighth overall when time efficiency is taken into account,\nsurpassed by several smaller open-source models. We further pinpoint that\nalgorithmic flaws and improper resource handling are the most detrimental,\ncausing a median time slowdown of 5.6$\\times$ and memory increase of\n12.0$\\times$, respectively. Our work underscores the necessity of jointly\noptimizing for correctness and efficiency in future LLM-based code translation.", "AI": {"tldr": "TRACY\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u7ffb\u8bd1\u4ee3\u7801\u6267\u884c\u6548\u7387\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\uff0c\u53d1\u73b0\u9876\u7ea7LLM\u5728\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u540c\u65f6\u4f18\u5316\u6b63\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u5ffd\u89c6\u4e86\u6267\u884c\u6548\u7387\uff0cTRACY\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528LLM\u9a71\u52a8\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a\u751f\u6210\u538b\u529b\u6d4b\u8bd5\u548c\u6548\u7387\u5bfc\u5411\u4efb\u52a1\u7b5b\u9009\uff0c\u6784\u5efa\u5305\u542b1,011\u4efb\u52a1\u7684\u57fa\u51c6\u3002", "result": "26\u4e2aLLM\u8bc4\u4f30\u663e\u793a\uff0c\u9876\u7ea7\u6a21\u578b\u5728\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u7b97\u6cd5\u7f3a\u9677\u548c\u8d44\u6e90\u5904\u7406\u4e0d\u5f53\u662f\u4e3b\u8981\u539f\u56e0\u3002", "conclusion": "\u672a\u6765\u4ee3\u7801\u7ffb\u8bd1\u9700\u540c\u65f6\u4f18\u5316\u6b63\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.11571", "categories": ["cs.SE", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.11571", "abs": "https://arxiv.org/abs/2508.11571", "authors": ["Alexander Bakhtin"], "title": "Temporal Network Analysis of Microservice Architectural Degradation", "comment": null, "summary": "Microservice architecture can be modeled as a network of microservices making\ncalls to each other, commonly known as the service dependency graph. Network\nScience can provide methods to study such networks. In particular, temporal\nnetwork analysis is a branch of Network Science that analyzes networks evolving\nwith time. In microservice systems, temporal networks can arise if we examine\nthe architecture of the system across releases or monitor a deployed system\nusing tracing.\n  In this research summary paper, I discuss the challenges in obtaining\ntemporal networks from microservice systems and analyzing them with the\ntemporal network methods. In particular, the most complete temporal network\nthat we could obtain contains 7 time instances and 42 microservices, which\nlimits the potential analysis that could be applied.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4ece\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u83b7\u53d6\u65f6\u95f4\u7f51\u7edc\u5e76\u8fdb\u884c\u5206\u6790\u7684\u6311\u6218\uff0c\u6307\u51fa\u76ee\u524d\u83b7\u53d6\u7684\u6570\u636e\u89c4\u6a21\u6709\u9650\uff087\u4e2a\u65f6\u95f4\u5b9e\u4f8b\u548c42\u4e2a\u5fae\u670d\u52a1\uff09\uff0c\u9650\u5236\u4e86\u5206\u6790\u65b9\u6cd5\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u5fae\u670d\u52a1\u67b6\u6784\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u7f51\u7edc\uff0c\u5229\u7528\u7f51\u7edc\u79d1\u5b66\u65b9\u6cd5\u5206\u6790\u5176\u52a8\u6001\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u8ffd\u8e2a\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u67b6\u6784\u53d8\u5316\u6216\u90e8\u7f72\u76d1\u63a7\uff0c\u6784\u5efa\u65f6\u95f4\u7f51\u7edc\u3002", "result": "\u76ee\u524d\u83b7\u53d6\u7684\u6700\u5b8c\u6574\u65f6\u95f4\u7f51\u7edc\u4ec5\u5305\u542b7\u4e2a\u65f6\u95f4\u5b9e\u4f8b\u548c42\u4e2a\u5fae\u670d\u52a1\uff0c\u6570\u636e\u89c4\u6a21\u9650\u5236\u4e86\u5206\u6790\u6df1\u5ea6\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u4ee5\u652f\u6301\u66f4\u5168\u9762\u7684\u65f6\u95f4\u7f51\u7edc\u5206\u6790\u3002"}}
