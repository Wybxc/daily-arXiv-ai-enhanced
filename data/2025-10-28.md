<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 26]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Software Engineering Agents for Embodied Controller Generation : A Study in Minigrid Environments](https://arxiv.org/abs/2510.21902)
*Timothé Boulet,Xavier Hinaut,Clément Moulin-Frier*

Main category: cs.SE

TL;DR: 首次系统评估软件工程智能体在具身任务控制器生成中的表现，通过Mini-SWE-Agent在Minigrid环境中解决20个任务，分析不同信息访问条件对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索SWE-Agents在需要良好信息发现的具身任务中的表现，现有研究主要关注传统软件工程任务，对具身任务控制器生成的性能尚未充分研究。

Method: 将Mini-SWE-Agent适配到Minigrid环境，在20个多样化具身任务上进行实验，比较有/无环境源代码访问以及不同交互探索能力条件下的性能表现。

Result: 量化了不同信息访问级别对SWE-Agent在具身任务中性能的影响，分析了静态代码分析与动态探索在任务解决中的相对重要性。

Conclusion: 确立了具身任务控制器生成作为SWE-Agents关键评估领域，为未来高效推理系统研究提供了基准结果。

Abstract: Software Engineering Agents (SWE-Agents) have proven effective for
traditional software engineering tasks with accessible codebases, but their
performance for embodied tasks requiring well-designed information discovery
remains unexplored. We present the first extended evaluation of SWE-Agents on
controller generation for embodied tasks, adapting Mini-SWE-Agent (MSWEA) to
solve 20 diverse embodied tasks from the Minigrid environment. Our experiments
compare agent performance across different information access conditions: with
and without environment source code access, and with varying capabilities for
interactive exploration. We quantify how different information access levels
affect SWE-Agent performance for embodied tasks and analyze the relative
importance of static code analysis versus dynamic exploration for task solving.
This work establishes controller generation for embodied tasks as a crucial
evaluation domain for SWE-Agents and provides baseline results for future
research in efficient reasoning systems.

</details>


### [2] [TOM-SWE: User Mental Modeling For Software Engineering Agents](https://arxiv.org/abs/2510.21903)
*Xuhui Zhou,Valerie Chen,Zora Zhiruo Wang,Graham Neubig,Maarten Sap,Xingyao Wang*

Main category: cs.SE

TL;DR: ToM-SWE是一个双代理架构，将主要软件工程代理与轻量级心理理论代理配对，通过建模用户心理状态来提升编码任务的成功率和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 当前编码代理在推断和跟踪用户意图方面存在困难，特别是在指令不明确或依赖上下文的情况下。

Method: 采用双代理架构：一个主要软件工程代理负责编码任务，一个轻量级心理理论代理专门建模用户心理状态，包括推断用户目标、约束和偏好，并维护用户的持久记忆。

Result: 在两个软件工程基准测试中，ToM-SWE显著提高了任务成功率和用户满意度。在状态化SWE基准测试中，任务成功率从18.1%提升到59.7%。在三周的专业开发者研究中，86%的参与者认为它有用。

Conclusion: 状态化用户建模对实用编码代理具有重要价值，双代理架构能有效提升编码代理理解用户意图的能力。

Abstract: Recent advances in coding agents have made them capable of planning, editing,
running, and testing complex code bases. Despite their growing ability in
coding tasks, these systems still struggle to infer and track user intent,
especially when instructions are underspecified or context-dependent. To bridge
this gap, we introduce ToM-SWE, a dual-agent architecture that pairs a primary
software-engineering (SWE) agent with a lightweight theory-of-mind (ToM)
partner agent dedicated to modeling the user's mental state. The ToM agent
infers user goals, constraints, and preferences from instructions and
interaction history, maintains a \textbf{persistent memory} of the user, and
provides user-related suggestions to the SWE agent. In two software engineering
benchmarks (ambiguous SWE-bench and stateful SWE-bench), ToM-SWE improves task
success rates and user satisfaction. Notably, on the stateful SWE benchmark, a
newly introduced evaluation that provides agents with a user simulator along
with previous interaction histories, ToM-SWE achieves a substantially higher
task success rate of 59.7\% compared to 18.1\% for OpenHands, a
state-of-the-art SWE agent. Furthermore, in a three-week study with
professional developers using ToM-SWE in their daily work, participants found
it useful 86\% of the time, underscoring the value of stateful user modeling
for practical coding agents.

</details>


### [3] [A Comparison of Conversational Models and Humans in Answering Technical Questions: the Firefox Case](https://arxiv.org/abs/2510.21933)
*Joao Correia,Daniel Coutinho,Marco Castelluccio,Caio Barbosa,Rafael de Mello,Anita Sarma,Alessandro Garcia,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: 评估RAG在Mozilla Firefox项目中协助开发者的效果，发现RAG增强的GPT模型比人类开发者提供更全面的回答，帮助性接近人类，但回答不够简洁。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中的使用增加，需要评估RAG技术在真实开源项目环境中协助开发者的有效性，以减轻核心维护者的负担。

Method: 与Mozilla基金会合作，对来自Firefox开发者聊天室的真实查询进行实证分析，比较人类开发者、标准GPT模型和RAG增强GPT模型的回答质量。

Result: RAG辅助回答比人类开发者更全面（62.50% vs 54.17%），帮助性接近人类（75.00% vs 79.17%），但不够简洁且冗长。

Conclusion: RAG工具有潜力应用于开源软件，在不损失回答质量的前提下减轻核心维护者负担，未来需要优化检索机制和缩短回答长度。

Abstract: The use of Large Language Models (LLMs) to support tasks in software
development has steadily increased over recent years. From assisting developers
in coding activities to providing conversational agents that answer newcomers'
questions. In collaboration with the Mozilla Foundation, this study evaluates
the effectiveness of Retrieval-Augmented Generation (RAG) in assisting
developers within the Mozilla Firefox project. We conducted an empirical
analysis comparing responses from human developers, a standard GPT model, and a
GPT model enhanced with RAG, using real queries from Mozilla's developer chat
rooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses
based on helpfulness, comprehensiveness, and conciseness. The results show that
RAG-assisted responses were more comprehensive than human developers (62.50% to
54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to
enhance developer assistance. However, the RAG responses were not as concise
and often verbose. The results show the potential to apply RAG-based tools to
Open Source Software (OSS) to minimize the load to core maintainers without
losing answer quality. Toning down retrieval mechanisms and making responses
even shorter in the future would enhance developer assistance in massive
projects like Mozilla Firefox.

</details>


### [4] [ArchISMiner: A Framework for Automatic Mining of Architectural Issue-Solution Pairs from Online Developer Communities](https://arxiv.org/abs/2510.21966)
*Musengamana Jean de Dieu,Ruiyin Li,Peng Liang,Mojtaba Shahin,Muhammad Waseem,Arif Ali Khan,Bangchao Wang,Mst Shamima Aktar*

Main category: cs.SE

TL;DR: ArchISMiner框架用于从Stack Overflow等开发者社区挖掘架构知识，包含ArchPI组件识别架构相关帖子，ArchISPE组件提取架构问题-解决方案对，显著提高了架构知识挖掘的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow等论坛包含丰富的软件开发知识，但架构知识因内容量大且分散而难以定位，开发者需要手动筛选帖子，过程耗时且容易出错。

Method: ArchISMiner框架包含两个组件：ArchPI使用ML/DL模型、预训练语言模型和LLM识别架构相关帖子；ArchISPE采用间接监督方法，结合BERT嵌入和TextCNN特征提取架构问题-解决方案对。

Result: ArchPI在架构相关帖子检测中F1-score达到0.960，ArchISPE在架构问题和解决方案提取中F1-score分别达到0.883和0.894，优于SE和NLP领域的基线方法。用户研究验证了提取内容的质量。

Conclusion: ArchISMiner能帮助架构师和开发者更准确高效地从开发者社区识别架构相关帖子和提取相关有用的架构知识，并已在三个额外论坛上应用，发布了包含18K+架构问题-解决方案对的数据集。

Abstract: Stack Overflow (SO), a leading online community forum, is a rich source of
software development knowledge. However, locating architectural knowledge, such
as architectural solutions remains challenging due to the overwhelming volume
of unstructured content and fragmented discussions. Developers must manually
sift through posts to find relevant architectural insights, which is
time-consuming and error-prone. This study introduces ArchISMiner, a framework
for mining architectural knowledge from SO. The framework comprises two
complementary components: ArchPI and ArchISPE. ArchPI trains and evaluates
multiple models, including conventional ML/DL models, Pre-trained Language
Models (PLMs), and Large Language Models (LLMs), and selects the
best-performing model to automatically identify Architecture-Related Posts
(ARPs) among programming-related discussions. ArchISPE employs an indirect
supervised approach that leverages diverse features, including BERT embeddings
and local TextCNN features, to extract architectural issue-solution pairs. Our
evaluation shows that the best model in ArchPI achieves an F1-score of 0.960 in
ARP detection, and ArchISPE outperforms baselines in both SE and NLP fields,
achieving F1-scores of 0.883 for architectural issues and 0.894 for solutions.
A user study further validated the quality (e.g., relevance and usefulness) of
the identified ARPs and the extracted issue-solution pairs. Moreover, we
applied ArchISMiner to three additional forums, releasing a dataset of over 18K
architectural issue-solution pairs. Overall, ArchISMiner can help architects
and developers identify ARPs and extract succinct, relevant, and useful
architectural knowledge from developer communities more accurately and
efficiently. The replication package of this study has been provided at
https://github.com/JeanMusenga/ArchISPE

</details>


### [5] [FeaGPT: an End-to-End agentic-AI for Finite Element Analysis](https://arxiv.org/abs/2510.21993)
*Yupeng Qi,Ran Xu,Xu Chu*

Main category: cs.SE

TL;DR: FeaGPT是首个通过对话界面实现完整几何-网格-仿真工作流程的框架，能够将工程规范转化为验证的计算结果而无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有工具仅自动化单个FEA组件，需要实现完全集成的GMSA（几何-网格-仿真-分析）流程，通过自然语言接口使高级计算工程工具民主化。

Method: 系统解释工程意图，自动生成物理感知的自适应网格，配置完整的FEA仿真并进行边界条件推断，通过闭环迭代执行多目标分析。

Result: 实验验证显示具备完整的端到端自动化能力，工业涡轮增压器案例成功将自然语言规范转化为验证的CalculiX仿真，432个NACA翼型配置验证了参数化设计探索的可扩展性。

Conclusion: 自然语言接口能够有效民主化高级计算工程工具的访问，同时保持分析严谨性。

Abstract: Large language models (LLMs) are establishing new paradigms for engineering
applications by enabling natural language control of complex computational
workflows. This paper introduces FeaGPT, the first framework to achieve
complete geometry-mesh-simulation workflows through conversational interfaces.
Unlike existing tools that automate individual FEA components, FeaGPT
implements a fully integrated Geometry-Mesh-Simulation-Analysis (GMSA) pipeline
that transforms engineering specifications into validated computational results
without manual intervention. The system interprets engineering intent,
automatically generates physics-aware adaptive meshes, configures complete FEA
simulations with proper boundary condition inference, and performs
multi-objective analysis through closed-loop iteration.
  Experimental validation confirms complete end-to-end automation capability.
Industrial turbocharger cases (7-blade compressor and 12-blade turbine at
\SI{110000}{rpm}) demonstrate the system successfully transforms natural
language specifications into validated CalculiX simulations, producing
physically realistic results for rotating machinery analysis. Additional
validation through 432 NACA airfoil configurations confirms scalability for
parametric design exploration. These results demonstrate that natural language
interfaces can effectively democratize access to advanced computational
engineering tools while preserving analytical rigor.

</details>


### [6] [Taming Silent Failures: A Framework for Verifiable AI Reliability](https://arxiv.org/abs/2510.22224)
*Guan-Yan Yang,Farn Wang*

Main category: cs.SE

TL;DR: FAME框架结合离线形式化合成和在线运行时监控，为安全关键系统中的AI组件提供可验证的安全保障，在自动驾驶感知系统中成功检测到93.5%的关键安全违规。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键系统中存在静默故障风险，即AI产生自信但错误的输出，这可能带来危险。需要一种方法来确保AI系统的可靠性和安全性。

Method: FAME框架将离线形式化合成的数学严谨性与在线运行时监控的警惕性相结合，为不透明的AI组件创建可验证的安全网。

Result: 在自动驾驶感知系统中的应用显示，FAME成功检测到93.5%的关键安全违规，这些违规原本是静默的。

Conclusion: FAME代表了从接受概率性能到强制执行可证明安全的关键转变，为部署可信AI提供了实用且可认证的途径，符合ISO 26262和ISO/PAS 8800标准。

Abstract: The integration of Artificial Intelligence (AI) into safety-critical systems
introduces a new reliability paradigm: silent failures, where AI produces
confident but incorrect outputs that can be dangerous. This paper introduces
the Formal Assurance and Monitoring Environment (FAME), a novel framework that
confronts this challenge. FAME synergizes the mathematical rigor of offline
formal synthesis with the vigilance of online runtime monitoring to create a
verifiable safety net around opaque AI components. We demonstrate its efficacy
in an autonomous vehicle perception system, where FAME successfully detected
93.5% of critical safety violations that were otherwise silent. By
contextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,
we provide reliability engineers with a practical, certifiable pathway for
deploying trustworthy AI. FAME represents a crucial shift from accepting
probabilistic performance to enforcing provable safety in next-generation
systems.

</details>


### [7] [Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review](https://arxiv.org/abs/2510.22003)
*Stefan Julian Kooy,Jean Paul Sebastian Piest,Rob Henk Bemthuis*

Main category: cs.SE

TL;DR: 本文通过系统文献综述分析了生成式AI在敏捷软件组织企业架构工作中的影响，识别了主要应用场景、风险、技能需求和治理要求。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑企业架构工作，但相关证据分散，需要系统梳理其影响、风险和机遇。

Method: 采用Kitchenham和PRISMA协议进行系统文献综述，分析了1,697条记录中的33项研究。

Result: 发现GenAI主要支持设计构思、工件创建和决策支持，同时存在透明度、偏见、隐私等风险，需要新的技能和组织能力。

Conclusion: 研究为负责任地采用GenAI提供了指导，既能加速数字化转型，又能保障架构完整性。

Abstract: Generative AI (GenAI) is reshaping enterprise architecture work in agile
software organizations, yet evidence on its effects remains scattered. We
report a systematic literature review (SLR), following established SLR
protocols of Kitchenham and PRISMA, of 1,697 records, yielding 33 studies
across enterprise, solution, domain, business, and IT architect roles. GenAI
most consistently supports (i) design ideation and trade-off exploration; (ii)
rapid creation and refinement of artifacts (e.g., code, models, documentation);
and (iii) architectural decision support and knowledge retrieval. Reported
risks include opacity and bias, contextually incorrect outputs leading to
rework, privacy and compliance concerns, and social loafing. We also identify
emerging skills and competencies, including prompt engineering, model
evaluation, and professional oversight, and organizational enablers around
readiness and adaptive governance. The review contributes with (1) a mapping of
GenAI use cases and risks in agile architecting, (2) implications for
capability building and governance, and (3) an initial research agenda on
human-AI collaboration in architecture. Overall, the findings inform
responsible adoption of GenAI that accelerates digital transformation while
safeguarding architectural integrity.

</details>


### [8] [LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test Generation](https://arxiv.org/abs/2510.22210)
*Gwihwan Go,Quan Zhang,Chijin Zhou,Zhao Wei,Yu Jiang*

Main category: cs.SE

TL;DR: LSPRAG是一个利用语言服务器协议(LSP)为LLM提供精确符号定义和引用的框架，用于实时、语言无关的单元测试生成，显著提高了测试覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的单元测试生成方法难以跨多种编程语言泛化，且在实时开发环境中表现不佳。虽然LLM有潜力，但生成高覆盖率测试代码需要精确的上下文信息。

Method: LSPRAG框架利用现成的LSP后端，为LLM实时提供精确的符号定义和引用，实现语言感知的上下文检索，无需为每种语言构建昂贵的静态分析流水线。

Result: 在Java、Go和Python的开源项目评估中，LSPRAG相比基线最佳性能，将行覆盖率提高了：Go达174.55%，Java达213.31%，Python达31.57%。

Conclusion: LSPRAG通过重用成熟的LSP服务器，为LLM提供语言感知的上下文检索，显著提升了跨语言单元测试生成的覆盖率和效率，同时最小化了每种语言的工程投入。

Abstract: Automated unit test generation is essential for robust software development,
yet existing approaches struggle to generalize across multiple programming
languages and operate within real-time development. While Large Language Models
(LLMs) offer a promising solution, their ability to generate high coverage test
code depends on prompting a concise context of the focal method. Current
solutions, such as Retrieval-Augmented Generation, either rely on imprecise
similarity-based searches or demand the creation of costly, language-specific
static analysis pipelines. To address this gap, we present LSPRAG, a framework
for concise-context retrieval tailored for real-time, language-agnostic unit
test generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP)
back-ends to supply LLMs with precise symbol definitions and references in real
time. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware
context retrieval, requiring minimal per-language engineering effort. We
evaluated LSPRAG on open-source projects spanning Java, Go, and Python.
Compared to the best performance of baselines, LSPRAG increased line coverage
by up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python.

</details>


### [9] [Understanding Self-Admitted Technical Debt in Test Code: An Empirical Study](https://arxiv.org/abs/2510.22249)
*Ibuki Nakamura,Yutaro Kashiwa,Bin Lin,Hajimu Iida*

Main category: cs.SE

TL;DR: 本研究分析了测试代码中的自承认技术债务(SATD)，发现测试代码中的SATD与生产代码中的特征不同，且与测试异味无直接关联。研究提出了测试代码SATD的分类体系，并开发了基于CodeBERT的自动分类模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注生产代码中的技术债务，而忽视了测试代码中的SATD。测试代码中存在大量不符合生产代码分类的SATD实例，需要专门研究其特性和影响。

Method: 对50个代码库中的17,766个SATD注释(14,987个来自生产代码，2,779个来自测试代码)进行实证研究，分析SATD在测试代码中的分布、类型及其与测试质量的关系，并开发机器学习模型进行自动分类。

Result: 测试代码中广泛存在SATD，但与测试异味无直接关联。基于CodeBERT的模型在召回率和F1分数上表现最佳，但在不同类型的SATD上性能存在差异。

Conclusion: 测试代码中的SATD具有独特特征，需要专门的分类和管理方法。基于CodeBERT的自动分类模型可以有效识别测试代码中的SATD类型，为技术债务管理提供支持。

Abstract: Developers often opt for easier but non-optimal implementation to meet
deadlines or create rapid prototypes, leading to additional effort known as
technical debt to improve the code later. Oftentimes, developers explicitly
document the technical debt in code comments, referred to as Self-Admitted
Technical Debt (SATD). Numerous researchers have investigated the impact of
SATD on different aspects of software quality and development processes.
However, most of these studies focus on SATD in production code, often
overlooking SATD in the test code or assuming that it shares similar
characteristics with SATD in production code. In fact, a significant amount of
SATD is also present in the test code, with many instances not fitting into
existing categories for the production code. This study aims to fill this gap
and disclose the nature of SATD in the test code by examining its distribution
and types. Moreover, the relation between its presence and test quality is also
analyzed. Our empirical study, involving 17,766 SATD comments (14,987 from
production code, 2,779 from test code) collected from 50 repositories,
demonstrates that while SATD widely exists in test code, it is not directly
associated with test smells. Our study also presents comprehensive categories
of SATD types in the test code, and machine learning models are developed to
automatically classify SATD comments based on their types for easier
management. Our results show that the CodeBERT-based model outperforms other
machine learning models in terms of recall and F1-score. However, the
performance varies on different types of SATD.

</details>


### [10] [Ten Simple Rules for AI-Assisted Coding in Science](https://arxiv.org/abs/2510.22254)
*Eric W. Bridgeford,Iain Campbell,Zijao Chen,Zhicheng Lin,Harrison Ritz,Joachim Vandekerckhove,Russell A. Poldrack*

Main category: cs.SE

TL;DR: 本文提出了10条AI辅助编码的实用规则，旨在平衡AI能力利用与科学方法严谨性，确保科学计算代码的可靠性和有效性。


<details>
  <summary>Details</summary>
Motivation: AI编码工具在加速软件开发方面展现出潜力，但在科学计算中引发了关于代码质量和科学有效性的关键问题，需要建立指导原则来确保研究完整性。

Method: 围绕四个关键主题制定实用规则：问题准备与理解、上下文管理与交互、测试与验证、代码质量保证与迭代改进，强调保持人类在编码决策中的主导权。

Result: 建立了一套系统的AI辅助编码指导原则，帮助研究人员在利用AI加速软件开发的同时，确保代码满足可靠性、可重复性和科学有效性的标准。

Conclusion: 这些规则旨在帮助研究人员充分利用AI的变革潜力，同时确保其代码符合研究完整性所需的可靠性、可重复性和科学有效性标准。

Abstract: While AI coding tools have demonstrated potential to accelerate software
development, their use in scientific computing raises critical questions about
code quality and scientific validity. In this paper, we provide ten practical
rules for AI-assisted coding that balance leveraging capabilities of AI with
maintaining scientific and methodological rigor. We address how AI can be
leveraged strategically throughout the development cycle with four key themes:
problem preparation and understanding, managing context and interaction,
testing and validation, and code quality assurance and iterative improvement.
These principles serve to emphasize maintaining human agency in coding
decisions, establishing robust validation procedures, and preserving the domain
expertise essential for methodologically sound research. These rules are
intended to help researchers harness AI's transformative potential for faster
software development while ensuring that their code meets the standards of
reliability, reproducibility, and scientific validity that research integrity
demands.

</details>


### [11] [Harnessing the Power of Large Language Models for Software Testing Education: A Focus on ISTQB Syllabus](https://arxiv.org/abs/2510.22318)
*Tuan-Phong Ngo,Bao-Ngoc Duong,Tuan-Anh Hoang,Joshua Dwight,Ushik Shrestha Khwakhali*

Main category: cs.SE

TL;DR: 本文探讨了如何将大型语言模型与ISTQB认证框架结合用于高等教育，创建了ISTQB对齐数据集并开发了优化的提示方法，评估了LLMs在软件测试教育中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 软件测试在软件工程教育中至关重要，但ISTQB认证框架与最新生成式人工智能的结合应用尚未充分探索，需要研究LLMs如何补充ISTQB框架以改进高等教育方法。

Method: 创建了涵盖10多年、包含28个样本考试和1145个问题的ISTQB对齐数据集，开发了领域优化的提示方法，并系统评估了最先进的LLMs在该数据集上的表现。

Result: 研究展示了LLMs在支持ISTQB认证准备方面的潜力，提供了增强LLM精度和解释质量的优化提示方法，以及将LLMs整合到软件测试教育中的可行建议。

Conclusion: LLMs在支持ISTQB认证准备方面具有良好前景，为在高等教育中更广泛地应用LLMs于软件工程领域奠定了基础。

Abstract: Software testing is a critical component in the software engineering field
and is important for software engineering education. Thus, it is vital for
academia to continuously improve and update educational methods to reflect the
current state of the field. The International Software Testing Qualifications
Board (ISTQB) certification framework is globally recognized and widely adopted
in industry and academia. However, ISTQB-based learning has been rarely applied
with recent generative artificial intelligence advances. Despite the growing
capabilities of large language models (LLMs), ISTQB-based learning and
instruction with LLMs have not been thoroughly explored. This paper explores
and evaluates how LLMs can complement the ISTQB framework for higher education.
The findings present four key contributions: (i) the creation of a
comprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28
sample exams and 1,145 questions; (ii) the development of a domain-optimized
prompt that enhances LLM precision and explanation quality on ISTQB tasks;
(iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and
(iv) actionable insights and recommendations for integrating LLMs into software
testing education. These findings highlight the promise of LLMs in supporting
ISTQB certification preparation and offer a foundation for their broader use in
software engineering at higher education.

</details>


### [12] [Operationalizing Large Language Models with Design-Aware Contexts for Code Comment Generation](https://arxiv.org/abs/2510.22338)
*Aritra Mitra,Srijoni Majumdar,Anamitra Mukhopadhyay,Partha Pratim Das,Paul D Clough,Partha Pratim Chakrabarti*

Main category: cs.SE

TL;DR: 研究探索使用大型语言模型(LLMs)为新手程序员编写的代码生成更有用的注释，特别关注设计文档作为上下文是否能提升注释质量。


<details>
  <summary>Details</summary>
Motivation: 新手程序员编写的代码库数量增加，但由于缺乏注释标准，他们的注释往往无用，增加了后续维护时间。

Method: 使用大型语言模型生成注释，重点关注设计文档作为上下文是否能帮助生成更有用的注释。

Result: 论文探讨了设计文档作为LLM上下文来生成更好注释的可行性。

Conclusion: 设计文档可能为LLMs提供有价值的上下文，以生成对代码维护更有用的注释。

Abstract: Comments are very useful to the flow of code development. With the increasing
commonality of code, novice coders have been creating a significant amount of
codebases. Due to lack of commenting standards, their comments are often
useless, and increase the time taken to further maintain codes. This study
intends to find the usefulness of large language models (LLMs) in these cases
to generate potentially better comments. This study focuses on the feasibility
of design documents as a context for the LLMs to generate more useful comments,
as design documents are often used by maintainers to understand code when
comments do not suffice.

</details>


### [13] [A First Look at the Self-Admitted Technical Debt in Test Code: Taxonomy and Detection](https://arxiv.org/abs/2510.22409)
*Shahidul Islam,Md Nahidul Islam Opu,Shaowei Wang,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 首次对测试代码中的自承认技术债务(SATD)进行大规模研究，分析了50,000个注释，识别出615个SATD注释并构建了15个分类，发现现有工具和LLMs在检测测试代码SATD方面效果不佳。


<details>
  <summary>Details</summary>
Motivation: 虽然已有大量研究关注源代码中的SATD，但测试代码中的SATD及其影响尚未得到专门研究，存在显著的知识空白。

Method: 从1,000个开源Java项目的160万条注释中随机抽取50,000条进行手动分析，识别和分类SATD，并评估现有SATD检测工具和LLMs的性能。

Result: 识别出615个SATD注释并构建了15个分类的测试代码SATD分类法；现有工具中MAT表现最佳但召回率一般；开源和专有LLMs检测准确率都很低，主要问题是精度不足。

Conclusion: 这是首个针对测试代码SATD的大规模分析，提供了对其类型的细致理解，并揭示了当前SATD检测方法的局限性，为未来测试代码特定SATD研究奠定了基础。

Abstract: Self-admitted technical debt (SATD) refers to comments in which developers
explicitly acknowledge code issues, workarounds, or suboptimal solutions. SATD
is known to significantly increase software maintenance effort. While extensive
research has examined SATD in source code, its presence and impact in test code
have received no focused attention, leaving a significant gap in our
understanding of how SATD manifests in testing contexts.
  This study, the first of its kind, investigates SATD in test code by manually
analyzing 50,000 comments randomly sampled from 1.6 million comments across
1,000 open-source Java projects. From this sample, after manual analysis and
filtering, we identified 615 SATD comments and classified them into 15 distinct
categories, building a taxonomy of test code SATD. To investigate whether test
code SATD can be detected automatically, we evaluated existing SATD detection
tools, as well as both open-source and proprietary LLMs. Among the existing
tools, MAT performed the best, albeit with moderate recall. To our surprise,
both open-source and proprietary LLMs exhibited poor detection accuracy,
primarily due to low precision. These results indicate that neither existing
approaches nor current LLMs can reliably detect SATD in test code.
  Overall, this work provides the first large-scale analysis of SATD in test
code, a nuanced understanding of its types, and the limitations of current SATD
detection methods. Our findings lay the groundwork for future research on test
code-specific SATD.

</details>


### [14] [A Multifaceted View on Discrimination in Software Development Careers](https://arxiv.org/abs/2510.22457)
*Shalini Chakraborty,Sebastian Baltes*

Main category: cs.SE

TL;DR: 该研究分析了软件开发中的多样性歧视问题，发现除了常见的性别和种族歧视外，年龄、政治观点、残疾和神经多样性等歧视同样普遍但关注较少。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示软件工程中除性别和种族外其他形式的歧视问题，这些歧视虽然普遍但较少受到关注，旨在提高研究社区对多元化歧视问题的认识。

Method: 采用二次分析方法，对800份开放式调查回复进行分析，考察感知歧视模式及相关挑战和负面影响，涵盖年龄、性别、种族、残疾等多个身份维度。

Result: 研究发现年龄和性别相关歧视是最常见的工作场所问题，政治和宗教观点歧视也是重要关切。女性参与者主要报告性别歧视，常与种族、政治观点、年龄或性取向等交叉因素相关。所有性别身份都报告了与照顾责任相关的歧视。

Conclusion: 软件工程中的歧视具有多面性，研究人员在设计研究时应选择评估除年龄和性别外的其他相关维度，以更全面地理解多样性问题。

Abstract: Conversations around diversity and inclusion in software engineering often
focus on gender and racial disparities. However, the State of the Developer
Nation 2025 survey with 8,717 participants revealed that other forms of
discrimination are similarly prevalent but receive considerably less attention.
This includes discrimination based on age, political perspective, disabilities,
or cognitive differences such as neurodivergence. We conducted a secondary
analysis of 800 open-ended survey responses to examine patterns of perceived
discrimination, as well as related challenges and negative impacts. Our study
covers multiple identity facets, including age, gender, race, and disability.
We found that age- and gender-related discrimination was the most frequently
reported workplace issue, but discrimination based on political and religious
views emerged as further notable concerns. Most of the participants who
identified as female cited gender as the primary source of discrimination,
often accompanied by intersectional factors such as race, political views, age,
or sexual orientation. Discrimination related to caregiving responsibilities
was reported by all gender identities. Regarding the negative impacts of
workplace issues, many participants described modifying their appearance or
behavior in response to gender biases. Gender also appeared to influence
broader career challenges, as women and non-binary respondents reported
experiencing almost all workplace issues at higher rates, particularly
discrimination (35%) and mental health challenges (62%). Our goal is to raise
awareness in the research community that discrimination in software development
is multifaceted, and to encourage researchers to select and assess relevant
facets beyond age and gender when designing software engineering studies.

</details>


### [15] [Finding the Needle in the Crash Stack: Industrial-Scale Crash Root Cause Localization with AutoCrashFL](https://arxiv.org/abs/2510.22530)
*Sungmin Kang,Sumi Yun,Jingun Hong,Shin Yoo,Gabin An*

Main category: cs.SE

TL;DR: AutoCrashFL是一个基于LLM代理的故障定位方法，仅需崩溃转储和源代码仓库就能在工业级软件中定位程序崩溃原因，在SAP HANA的实验中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统故障定位方法需要动态分析（如覆盖率分析），在大型工业软件中成本过高，难以应用。需要一种仅依赖崩溃转储和源代码的轻量级故障定位方案。

Method: 提出AutoCrashFL LLM代理，仅使用程序崩溃转储和对应的源代码仓库进行故障定位，无需昂贵的动态分析。

Result: 在SAP HANA（超过3500万行代码）的真实崩溃测试中，AutoCrashFL在top位置识别了30%的崩溃，而基线方法仅为17%。对复杂bug更有效，并能提供结果置信度。

Conclusion: LLM代理在工业规模部署具有实用性，AutoCrashFL展示了仅依赖崩溃转储和源代码的轻量级故障定位方法的可行性。

Abstract: Fault Localization (FL) aims to identify root causes of program failures. FL
typically targets failures observed from test executions, and as such, often
involves dynamic analyses to improve accuracy, such as coverage profiling or
mutation testing. However, for large industrial software, measuring coverage
for every execution is prohibitively expensive, making the use of such
techniques difficult. To address these issues and apply FL in an industrial
setting, this paper proposes AutoCrashFL, an LLM agent for the localization of
crashes that only requires the crashdump from the Program Under Test (PUT) and
access to the repository of the corresponding source code. We evaluate
AutoCrashFL against real-world crashes of SAP HANA, an industrial software
project consisting of more than 35 million lines of code. Experiments reveal
that AutoCrashFL is more effective in localization, as it identified 30%
crashes at the top, compared to 17% achieved by the baseline. Through thorough
analysis, we find that AutoCrashFL has attractive practical properties: it is
relatively more effective for complex bugs, and it can indicate confidence in
its results. Overall, these results show the practicality of LLM agent
deployment on an industrial scale.

</details>


### [16] [DynaCausal: Dynamic Causality-Aware Root Cause Analysis for Distributed Microservices](https://arxiv.org/abs/2510.22613)
*Songhan Zhang,Aoyang Fang,Yifan Yang,Ruiyi Cheng,Xiaoying Tang,Pinjia He*

Main category: cs.SE

TL;DR: DynaCausal是一个用于分布式微服务系统根因分析的动态因果感知框架，通过多模态动态信号统一、动态对比机制和因果优先排序目标，解决了现有方法在故障传播建模、噪声干扰和概念漂移方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 云原生微服务虽然支持快速迭代和可扩展部署，但产生了复杂且快速演化的依赖关系，给可靠诊断带来挑战。现有根因分析方法在多模态融合方面仍有局限，无法充分捕捉动态行为和变化的服务关系。

Method: DynaCausal通过交互感知表示学习统一多模态动态信号来捕捉时变时空依赖，引入动态对比机制从上下文噪声中分离真实故障指标，并采用因果优先成对排序目标来显式优化因果归因。

Result: 在公共基准测试上的综合评估表明，DynaCausal持续超越最先进方法，平均AC@1达到0.63，绝对增益从0.25到0.46，在高度动态的微服务环境中提供准确且可解释的诊断。

Conclusion: DynaCausal框架有效解决了微服务系统中根因分析的三个关键挑战，在动态环境下实现了更准确和可解释的故障诊断，为云原生系统的可靠运维提供了有力支持。

Abstract: Cloud-native microservices enable rapid iteration and scalable deployment but
also create complex, fast-evolving dependencies that challenge reliable
diagnosis. Existing root cause analysis (RCA) approaches, even with multi-modal
fusion of logs, traces, and metrics, remain limited in capturing dynamic
behaviors and shifting service relationships. Three critical challenges
persist: (i) inadequate modeling of cascading fault propagation, (ii)
vulnerability to noise interference and concept drift in normal service
behavior, and (iii) over-reliance on service deviation intensity that obscures
true root causes. To address these challenges, we propose DynaCausal, a dynamic
causality-aware framework for RCA in distributed microservice systems.
DynaCausal unifies multi-modal dynamic signals to capture time-varying
spatio-temporal dependencies through interaction-aware representation learning.
It further introduces a dynamic contrastive mechanism to disentangle true fault
indicators from contextual noise and adopts a causal-prioritized pairwise
ranking objective to explicitly optimize causal attribution. Comprehensive
evaluations on public benchmarks demonstrate that DynaCausal consistently
surpasses state-of-the-art methods, attaining an average AC@1 of 0.63 with
absolute gains from 0.25 to 0.46, and delivering both accurate and
interpretable diagnoses in highly dynamic microservice environments.

</details>


### [17] [Does In-IDE Calibration of Large Language Models work at Scale?](https://arxiv.org/abs/2510.22614)
*Roham Koohestani,Agnia Sergeyuk,David Gros,Claudio Spiess,Sergey Titov,Prem Devanbu,Maliheh Izadi*

Main category: cs.SE

TL;DR: 研究探讨在IDE环境中对代码生成模型进行置信度校准的可行性，发现通用后校准方法效果有限，个性化校准需要大量用户数据，且开发者偏好使用颜色编码而非数值来显示可靠性信号。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在IDE中的集成正在改变软件工程，但AI生成代码的可靠性和实用性面临挑战。置信度校准旨在使模型概率与可接受性度量对齐，但大规模证据有限。

Method: 开发可扩展的校准框架，使用Platt缩放进行后校准；分析2400万次真实开发者交互；进行多阶段设计研究，包括场景设计、半结构化访谈和调查验证。

Result: 通用后校准模型平均上未能改善置信度信号的可靠性；个性化校准有效但依赖大量用户交互数据；开发者偏好使用颜色编码的非数值可靠性指示器。

Conclusion: 在IDE环境中应用置信度校准具有挑战性，需要个性化方法，且可靠性信号的呈现方式应优先考虑非数值、颜色编码的视觉指示器。

Abstract: The introduction of large language models into integrated development
environments (IDEs) is revolutionizing software engineering, yet it poses
challenges to the usefulness and reliability of Artificial
Intelligence-generated code. Post-hoc calibration of internal model confidences
aims to align probabilities with an acceptability measure. Prior work suggests
calibration can improve alignment, but at-scale evidence is limited. In this
work, we investigate the feasibility of applying calibration of code models to
an in-IDE context. We study two aspects of the problem: (1) the technical
method for implementing confidence calibration and improving the reliability of
code generation models, and (2) the human-centered design principles for
effectively communicating reliability signal to developers. First, we develop a
scalable and flexible calibration framework which can be used to obtain
calibration weights for open-source models using any dataset, and evaluate
whether calibrators improve the alignment between model confidence and
developer acceptance behavior. Through a large-scale analysis of over 24
million real-world developer interactions across multiple programming
languages, we find that a general, post-hoc calibration model based on
Platt-scaling does not, on average, improve the reliability of model confidence
signals. We also find that while dynamically personalizing calibration to
individual users can be effective, its effectiveness is highly dependent on the
volume of user interaction data. Second, we conduct a multi-phase design study
with 3 expert designers and 153 professional developers, combining
scenario-based design, semi-structured interviews, and survey validation,
revealing a clear preference for presenting reliability signals via
non-numerical, color-coded indicators within the in-editor code generation
workflow.

</details>


### [18] [Collaborative LLM Agents for C4 Software Architecture Design Automation](https://arxiv.org/abs/2510.22787)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.SE

TL;DR: 提出基于LLM的多智能体系统，通过角色专家对话自动生成C4软件架构模型，使用混合评估框架验证质量。


<details>
  <summary>Details</summary>
Motivation: 软件架构设计是系统开发的基础，但创建C4模型目前仍依赖手动且耗时，需要自动化解决方案。

Method: 使用LLM多智能体系统模拟角色专家对话，分析需求并生成C4模型的Context、Container和Component视图，采用混合评估框架（确定性检查+LLM作为评判者）进行质量评估。

Result: 在五个典型系统简介上测试，工作流能快速创建C4模型，保持高编译成功率并提供语义保真度；比较四种先进LLM显示在架构设计方面的不同优势。

Conclusion: 该研究为自动化软件架构设计及其评估方法做出了贡献。

Abstract: Software architecture design is a fundamental part of creating every software
system. Despite its importance, producing a C4 software architecture model, the
preferred notation for such architecture, remains manual and time-consuming. We
introduce an LLM-based multi-agent system that automates this task by
simulating a dialogue between role-specific experts who analyze requirements
and generate the Context, Container, and Component views of the C4 model.
Quality is assessed with a hybrid evaluation framework: deterministic checks
for structural and syntactic integrity and C4 rule consistency, plus semantic
and qualitative scoring via an LLM-as-a-Judge approach. Tested on five
canonical system briefs, the workflow demonstrates fast C4 model creation,
sustains high compilation success, and delivers semantic fidelity. A comparison
of four state-of-the-art LLMs shows different strengths relevant to
architectural design. This study contributes to automated software architecture
design and its evaluation methods.

</details>


### [19] [On the Freshness of Pinned Dependencies in Maven](https://arxiv.org/abs/2510.22815)
*Vasudev Vikram,Yuvraj Agarwal,Rohan Padhye*

Main category: cs.SE

TL;DR: 该论文研究了Maven库依赖版本固定的问题，发现超过60%的项目使用过时的依赖版本，存在安全风险。作者提出了Pin-Freshener方法，利用同行项目的众包测试来提供升级安全性信号，帮助开发者安全更新依赖。


<details>
  <summary>Details</summary>
Motivation: 软件依赖版本固定虽然能确保构建可重现性，但会导致使用包含漏洞的过时依赖。需要理解依赖固定的频率和后果，并提供解决方案来鼓励开发者更新依赖。

Method: 定义了陈旧和新鲜固定的概念，基于依赖相对于项目发布日期的过时程度。开发了Pin-Freshener原型，利用同行项目的众包测试为依赖升级提供额外安全信号。

Result: 60%以上的流行Maven库使用者包含陈旧的依赖固定，有些版本超过一年。10%的依赖升级到最新次要或补丁版本可减少安全漏洞。Pin-Freshener仅需1-5个额外测试套件就能提供35-100%的额外覆盖率。

Conclusion: Pin-Freshener通过提供超越单个项目测试套件的额外信号，为开发者提供实际信心来安全执行依赖升级，减少安全漏洞，是对当前实践的改进。

Abstract: Library dependencies in software ecosystems play a crucial role in the
development of software. As newer releases of these libraries are published,
developers may opt to pin their dependencies to a particular version. While
pinning may have benefits in ensuring reproducible builds and avoiding breaking
changes, it bears larger risks in using outdated dependencies that may contain
bugs and security vulnerabilities. To understand the frequency and consequences
of dependency pinning, we first define the concepts of stale and fresh pins,
which are distinguished based on how outdated the dependency is relative to the
release date of the project. We conduct an empirical study to show that over
60% of consumers of popular Maven libraries contain stale pins to their
dependencies, with some outdated versions over a year old. These pinned
versions often miss out on security fixes; we find that 10% of all dependency
upgrades in our dataset to the latest minor or patch version would reduce
security vulnerabilities.
  We prototype an approach called Pin-Freshener that can encourage developers
to freshen their pins by leveraging the insight that crowdsourced tests of peer
projects can provide additional signal for the safety of an upgrade. Running
Pin-Freshener on dependency upgrades shows that just 1-5 additional test suites
can provide 35-100% more coverage of a dependency, compared to that of a single
consumer test suite. Our evaluation on real-world pins to the top 500 popular
libraries in Maven shows that Pin-Freshener can provide an additional signal of
at least 5 passing crowdsourced test suites to over 3,000 consumers to safely
perform an upgrade that reduces security vulnerabilities. Pin-Freshener can
provide practical confidence to developers by offering additional signal beyond
their own test suites, representing an improvement over current practices.

</details>


### [20] [CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs](https://arxiv.org/abs/2510.22986)
*Junjie Huang,Minghua He,Jinyang Liu,Yintong Huo,Domenico Bianculli,Michael R. Lyu*

Main category: cs.SE

TL;DR: CodeAD是一个使用LLMs自动合成轻量级Python规则函数进行日志异常检测的新框架，通过分层聚类和锚点采样策略构建对比日志窗口，采用迭代生成-测试-修复流程确保规则质量，在三个公开数据集上相比SOTA方法F1分数提升3.6%，处理速度快4倍且成本极低。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习、深度学习和LLMs的日志异常检测方法存在可解释性差、推理成本高、预处理复杂等问题，而基于规则的系统虽然高效透明但需要大量人工工作且难以扩展。

Method: CodeAD采用分层聚类和锚点采样策略构建代表性对比日志窗口，使用LLMs识别判别性异常模式，通过代理工作流迭代生成、测试、修复和精炼规则，直到满足正确性和抽象性要求。

Result: 在三个公开数据集(BGL、Hadoop、Thunderbird)上的实验表明，CodeAD相比最先进基线方法平均F1分数绝对提升3.6%，处理大型数据集速度快4倍，每个数据集的LLM调用总成本低于4美元。

Conclusion: CodeAD为在线监控系统提供了一个实用且可扩展的解决方案，能够在真实环境中实现可解释、高效和自动化的日志异常检测。

Abstract: Log-based anomaly detection (LogAD) is critical for maintaining the
reliability and availability of large-scale online service systems. While
machine learning, deep learning, and large language models (LLMs)-based methods
have advanced the LogAD, they often suffer from limited interpretability, high
inference costs, and extensive preprocessing requirements, limiting their
practicality for real-time, high-volume log analysis. In contrast, rule-based
systems offer efficiency and transparency, but require significant manual
effort and are difficult to scale across diverse and evolving environments. In
this paper, We present CodeAD, a novel framework that automatically synthesizes
lightweight Python rule functions for LogAD using LLMs. CodeAD introduces a
hierarchical clustering and anchor-grounded sampling strategy to construct
representative contrastive log windows, enabling LLMs to discern discriminative
anomaly patterns. To ensure robustness and generalizability, CodeAD employs an
agentic workflow that iteratively generates, tests, repairs, and refines the
rules until it meets correctness and abstraction requirements. The synthesized
rules are interpretable, lightweight, and directly executable on raw logs,
supporting efficient and transparent online anomaly detection. Our
comprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)
demonstrate that CodeAD achieves an average absolute improvement of 3.6% F1
score over the state-of-the-art baselines, while processing large datasets up
to 4x faster and at a fraction of the cost (total LLM invocation cost under 4
USD per dataset). These results highlight CodeAD as a practical and scalable
solution for online monitoring systems, enabling interpretable, efficient, and
automated LogAD in real-world environment.

</details>


### [21] [TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term Memory for Scalable Code Generation](https://arxiv.org/abs/2510.23010)
*Ming-Tung Shen,Yuh-Jzer Joung*

Main category: cs.SE

TL;DR: 提出了TALM框架，通过树形多智能体结构、长期记忆机制和局部重推理，解决了现有多智能体框架在代码生成中工作流程僵化和推理恢复成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于协作的多智能体框架在代码生成任务中存在工作流程僵化和推理恢复成本高的问题，需要更灵活高效的解决方案。

Method: 采用树形多智能体协作结构，结合分治策略实现动态任务分解，集成长期记忆模块支持语义查询和经验复用，通过局部重推理机制提高错误修正效率。

Result: 在HumanEval、BigCodeBench和ClassEval基准测试中，TALM展现出强大的推理性能和高效的token利用率。

Conclusion: TALM框架在复杂代码生成任务中具有鲁棒性和实用价值，能够有效提升智能体代码生成的灵活性和效率。

Abstract: Agentic code generation requires large language models (LLMs) capable of
complex context management and multi-step reasoning. Prior multi-agent
frameworks attempt to address these challenges through collaboration, yet they
often suffer from rigid workflows and high reasoning recovery costs. To
overcome these limitations, we propose TALM (Tree-Structured Multi-Agent
Framework with Long-Term Memory), a dynamic framework that integrates
structured task decomposition, localized re-reasoning, and long-term memory
mechanisms. TALM employs an extensible tree-based collaboration structure. The
parent-child relationships, when combined with a divide-and-conquer strategy,
enhance reasoning flexibility and enable efficient error correction across
diverse task scopes. Furthermore, a long-term memory module enables semantic
querying and integration of prior knowledge, supporting implicit
self-improvement through experience reuse. Experimental results on HumanEval,
BigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently
delivers strong reasoning performance and high token efficiency, highlighting
its robustness and practical utility in complex code generation tasks.

</details>


### [22] [From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks](https://arxiv.org/abs/2510.23055)
*Manjeshwar Aniruddh Mallya,Alessio Ferrari,Mohammad Amin Zadenoori,Jacek Dąbrowski*

Main category: cs.SE

TL;DR: 评估5个轻量级开源LLM在三个需求工程任务上的表现：用户请求分类、非功能性需求分类和需求规范生成，发现LLM在分类任务上达到中等至高准确率，在规范生成上获得中等质量评分。


<details>
  <summary>Details</summary>
Motivation: 在线用户反馈为需求工程提供有价值信息，但分析面临数据量大和噪声多的挑战。LLM有潜力自动化这一过程，但目前LLM在需求工程中的应用研究不足，缺乏充分的实证评估。

Method: 在两个反馈数据集上评估五个轻量级开源LLM，对分类任务使用性能指标评估，对规范生成任务进行人工质量评估。

Result: LLM在分类任务上达到中等至高准确率（F1分数0.47-0.68），在需求规范生成上获得中等质量评分（平均3/5分）。

Conclusion: 轻量级LLM在需求工程任务中表现出潜力，能够以中等至高准确率执行分类任务，并生成中等质量的需求规范，为反馈驱动的需求开发提供了新可能性。

Abstract: [Context and Motivation] Online user feedback provides valuable information
to support requirements engineering (RE). However, analyzing online user
feedback is challenging due to its large volume and noise. Large language
models (LLMs) show strong potential to automate this process and outperform
previous techniques. They can also enable new tasks, such as generating
requirements specifications.
  [Question-Problem] Despite their potential, the use of LLMs to analyze user
feedback for RE remains underexplored. Existing studies offer limited empirical
evidence, lack thorough evaluation, and rarely provide replication packages,
undermining validity and reproducibility.
  [Principal Idea-Results] We evaluate five lightweight open-source LLMs on
three RE tasks: user request classification, NFR classification, and
requirements specification generation. Classification performance was measured
on two feedback datasets, and specification quality via human evaluation. LLMs
achieved moderate-to-high classification accuracy (F1 ~ 0.47-0.68) and
moderately high specification quality (mean ~ 3/5).
  [Contributions] We newly explore lightweight LLMs for feedback-driven
requirements development. Our contributions are: (i) an empirical evaluation of
lightweight LLMs on three RE tasks, (ii) a replication package, and (iii)
insights into their capabilities and limitations for RE.

</details>


### [23] [Checkstyle+: Reducing Technical Debt Through The Use of Linters with LLMs](https://arxiv.org/abs/2510.23068)
*Ella Dodor,Cristina V. Lopes*

Main category: cs.SE

TL;DR: Checkstyle+ 通过结合传统规则检查和LLM能力，改进代码风格检测，特别针对需要语义理解的复杂风格规则。


<details>
  <summary>Details</summary>
Motivation: 传统linter工具基于规则机制，无法有效检测需要语义理解的复杂代码风格问题，开发者在实践中经常忽略这些规则。

Method: 提出混合方法Checkstyle+，在Checkstyle基础上集成大语言模型能力，识别传统规则分析无法检测的风格违规。

Result: 在380个Java代码文件上的评估显示，Checkstyle+在检测语义复杂规则违规方面优于标准Checkstyle。

Conclusion: LLM增强的混合方法能有效提升代码风格检测能力，特别是在需要语义理解的复杂规则方面。

Abstract: Good code style improves program readability, maintainability, and
collaboration, and is an integral component of software quality. Developers,
however, often cut corners when following style rules, leading to the wide
adoption of tools such as linters in professional software development
projects. Traditional linters like Checkstyle operate using rigid, rule-based
mechanisms that effectively detect many surface-level violations. However, in
most programming languages, there is a subset of style rules that require a
more nuanced understanding of code, and fall outside the scope of such static
analysis. In this paper, we propose Checkstyle+, a hybrid approach that
augments Checkstyle with large language model (LLM) capabilities, to identify
style violations that elude the conventional rule-based analysis. Checkstyle+
is evaluated on a sample of 380 Java code files, drawn from a broader dataset
of 30,800 real-world Java programs sourced from accepted Codeforces
submissions. The results show that Checkstyle+ achieves superior performance
over standard Checkstyle in detecting violations of the semantically nuanced
rules.

</details>


### [24] [Validating Formal Specifications with LLM-generated Test Cases](https://arxiv.org/abs/2510.23350)
*Alcino Cunha,Nuno Macedo*

Main category: cs.SE

TL;DR: 评估使用预训练大语言模型（LLMs）从自然语言需求自动生成测试用例的效果，特别关注为Alloy规范语言中的结构需求生成测试用例。


<details>
  <summary>Details</summary>
Motivation: 验证是开发形式规范的核心活动，但手动指定测试用例繁琐且容易出错，导致用户可能跳过此验证任务。

Method: 使用GPT-5等大语言模型从自然语言需求自动生成测试用例，重点关注Alloy规范语言中的结构需求，评估多种闭源和开源LLMs。

Result: GPT-5在生成语法正确且满足（或不满足）给定需求的正面和负面测试用例方面相当有效，能够检测出许多人工编写的错误规范。

Conclusion: 在此背景下，GPT-5已经能够有效自动生成测试用例，有助于改进形式规范的验证过程。

Abstract: Validation is a central activity when developing formal specifications.
Similarly to coding, a possible validation technique is to define upfront test
cases or scenarios that a future specification should satisfy or not.
Unfortunately, specifying such test cases is burdensome and error prone, which
could cause users to skip this validation task. This paper reports the results
of an empirical evaluation of using pre-trained large language models (LLMs) to
automate the generation of test cases from natural language requirements. In
particular, we focus on test cases for structural requirements of simple domain
models formalized in the Alloy specification language. Our evaluation focuses
on the state-of-art GPT-5 model, but results from other closed- and open-source
LLMs are also reported. The results show that, in this context, GPT-5 is
already quite effective at generating positive (and negative) test cases that
are syntactically correct and that satisfy (or not) the given requirement, and
that can detect many wrong specifications written by humans.

</details>


### [25] [Floating-Point Neural Network Verification at the Software Level](https://arxiv.org/abs/2510.23389)
*Edoardo Manino,Bruno Farias,Rafael Sá Menezes,Fedor Shmarov,Lucas C. Cordeiro*

Main category: cs.SE

TL;DR: 该论文构建了NeuroCodeBench 2.0基准测试集，包含912个神经网络验证案例，用于评估软件验证工具在神经网络代码上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证技术无法在软件层面证明神经网络组件的正确性，特别是在安全关键系统中部署时需要确保其安全性。

Method: 通过显式推理神经网络的浮点实现来指定和验证其安全性，构建了兼容SV-COMP格式的C语言验证套件。

Result: 评估8个最先进的软件验证工具，发现它们平均只能正确解决基准测试中11%的问题，同时产生约3%的错误判断。但基准测试的发布已对工具改进产生积极影响。

Conclusion: 现有自动化验证工具在神经网络代码验证方面能力有限，但通过标准化的基准测试可以推动该领域的发展。

Abstract: The behaviour of neural network components must be proven correct before
deployment in safety-critical systems. Unfortunately, existing neural network
verification techniques cannot certify the absence of faults at the software
level. In this paper, we show how to specify and verify that neural networks
are safe, by explicitly reasoning about their floating-point implementation. In
doing so, we construct NeuroCodeBench 2.0, a benchmark comprising 912 neural
network verification examples that cover activation functions, common layers,
and full neural networks of up to 170K parameters. Our verification suite is
written in plain C and is compatible with the format of the International
Competition on Software Verification (SV-COMP). Thanks to it, we can conduct
the first rigorous evaluation of eight state-of-the-art software verifiers on
neural network code. The results show that existing automated verification
tools can correctly solve an average of 11% of our benchmark, while producing
around 3% incorrect verdicts. At the same time, a historical analysis reveals
that the release of our benchmark has already had a significantly positive
impact on the latter.

</details>


### [26] [Tracing Distribution Shifts with Causal System Maps](https://arxiv.org/abs/2510.23528)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 提出ML系统地图——通过分层视图显示环境与ML系统内部之间传播路径的因果地图，用于系统性地归因分布偏移


<details>
  <summary>Details</summary>
Motivation: 监控机器学习系统很困难，标准实践主要关注检测分布偏移而非其原因，根本原因分析通常依赖手动追踪来确定偏移是由软件故障、数据质量问题还是自然变化引起的

Method: ML系统地图方法，通过因果地图和分层视图，明确环境与ML系统内部之间的传播路径

Result: 该方法能够系统性地归因分布偏移，使偏移原因分析更加系统化

Conclusion: 提出了ML系统地图方法并制定了其开发和评估的研究议程

Abstract: Monitoring machine learning (ML) systems is hard, with standard practice
focusing on detecting distribution shifts rather than their causes. Root-cause
analysis often relies on manual tracing to determine whether a shift is caused
by software faults, data-quality issues, or natural change. We propose ML
System Maps -- causal maps that, through layered views, make explicit the
propagation paths between the environment and the ML system's internals,
enabling systematic attribution of distribution shifts. We outline the approach
and a research agenda for its development and evaluation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [27] [Possibilistic Computation Tree Logic: Decidability and Complete Axiomatization](https://arxiv.org/abs/2510.23075)
*Yongming Li*

Main category: cs.LO

TL;DR: 本文研究了可能性计算树逻辑(PoCTL)的可满足性问题，证明了该问题在指数时间内可判定，并给出了PoCTL的完整公理化系统。


<details>
  <summary>Details</summary>
Motivation: PoCTL是结合可能性理论中不确定信息的时序逻辑，用于处理具有不确定信息的系统验证。虽然PoCTL的模型检测问题已有研究，但其可满足性问题尚未讨论。

Method: 通过引入从PoCTL公式中提取可能性信息的技术，并构建其可能性Hintikka结构。

Result: 证明了PoCTL的可满足性问题在指数时间内可判定。

Conclusion: 成功解决了PoCTL的可满足性问题，并建立了完整的公理化系统，为PoCTL的推理提供了理论基础。

Abstract: Possibilistic computation tree Logic (PoCTL) is one kind of branching
temporal logic combined with uncertain information in possibility theory, which
was introduced in order to cope with the systematic verification on systems
with uncertain information in possibility theory. There are two decision
problems related to PoCTL: the model checking problem and the satisfiability
problem. The model checking problem of PoCTL has been studied, while the
satisfiability problem of PoCTL was not discussed. One of the purpose of this
work is to study the satisfiability problem of PoCTL. By introducing some
techniques to extract possibility information from PoCTL formulae and
constructing their possibilistic Hintikka structures, we show that the
satisfiability problem of PoCTL is decidable in exponential time. Furthermore,
we give a complete axiomatization of PoCTL, which is another important
inference problem of PoCTL.

</details>


### [28] [Proceedings of the Combined 32nd International Workshop on Expressiveness in Concurrency and 22nd Workshop on Structural Operational Semantics](https://arxiv.org/abs/2510.23211)
*Cinzia Di Giusto,Giorgio Bacci*

Main category: cs.LO

TL;DR: EXPRESS/SOS 2025会议论文集，包含第32届并发表达性国际研讨会和第22届结构操作语义研讨会的论文


<details>
  <summary>Details</summary>
Motivation: 汇集对系统形式语义、编程概念和计算模型表达性感兴趣的研究人员

Method: 作为CONFEST 2025的附属研讨会，在丹麦奥胡斯举办

Result: 出版了包含相关研究成果的会议论文集

Conclusion: 该研讨会系列持续促进形式语义和计算模型表达性研究领域的交流与合作

Abstract: This volume contains the proceedings of EXPRESS/SOS 2025: the Combined 32nd
International Workshop on Expressiveness in Concurrency and the 22nd Workshop
on Structural Operational Semantics, which was held in Aarhus, Denmark, as an
affiliated workshop of CONFEST 2025. The EXPRESS/SOS workshop series aims at
bringing together researchers interested in the formal semantics of systems and
programming concepts, and in the expressiveness of computational models.

</details>


### [29] [Parametric Iteration in Resource Theories](https://arxiv.org/abs/2510.23413)
*Alessandro Di Giorgio,Pawel Sobocinski,Niels Voorneveld*

Main category: cs.LO

TL;DR: 本文提出了一个参数化迭代构造，用于在资源理论中捕获算法中的固定但未指定参数（如密码学中的安全参数），并通过在概率布尔电路的马尔可夫范畴中实例化该构造，以组合方式捕捉可忽略性概念。


<details>
  <summary>Details</summary>
Motivation: 许多算法都依赖于固定但未指定的参数，这在密码学中尤为常见（如密钥位长作为安全参数）。本文旨在在更抽象的设置中捕获这一现象，特别是在资源理论中。

Method: 在资源理论中引入通用的参数化迭代构造，并在概率布尔电路的马尔可夫范畴中实例化该构造，配备适当的度量来通过渐近等价捕捉可忽略性。

Result: 该方法能够以组合方式捕捉可忽略性概念，使得能够使用图示推理来证明简单的密码学定理，例如证明猜测随机生成密钥的成功率是可忽略的。

Conclusion: 提出的参数化迭代构造为在资源理论中处理算法参数提供了一种抽象框架，特别是在密码学应用中，能够通过图示推理进行形式化证明。

Abstract: Many algorithms are specified with respect to a fixed but unspecified
parameter. Examples of this are especially common in cryptography, where
protocols often feature a security parameter such as the bit length of a secret
key.
  Our aim is to capture this phenomenon in a more abstract setting. We focus on
resource theories -- general calculi of processes with a string diagrammatic
syntax -- introducing a general parametric iteration construction. By
instantiating this construction within the Markov category of probabilistic
Boolean circuits and equipping it with a suitable metric, we are able to
capture the notion of negligibility via asymptotic equivalence, in a
compositional way. This allows us to use diagrammatic reasoning to prove simple
cryptographic theorems -- for instance, proving that guessing a randomly
generated key has negligible success.

</details>


### [30] [On the entailment problem for DL-Lite$_{core}$ ontologies and conjunctive queries with negation](https://arxiv.org/abs/2510.23490)
*Jerzy Marcinkowski,Piotr Ostropolski-Nalewaja*

Main category: cs.LO

TL;DR: DL-Lite$_{core}$本体论中，包含不等式或安全否定的合取查询的蕴含问题是不可判定的


<details>
  <summary>Details</summary>
Motivation: 研究DL-Lite$_{core}$本体论中复杂查询（包含不等式或安全否定）的蕴含问题的可判定性

Method: 通过理论证明和逻辑推理，分析DL-Lite$_{core}$本体论中合取查询蕴含问题的计算复杂性

Result: 证明了对于DL-Lite$_{core}$本体论，包含不等式的合取查询蕴含问题是不可判定的；同样，包含安全否定的合取查询蕴含问题也是不可判定的

Conclusion: 在DL-Lite$_{core}$本体论框架下，处理包含不等式或安全否定的合取查询的蕴含问题是不可判定的

Abstract: We show that the entailment problem, for a given entailment problem for
DL-Lite$_{core}$ ontology, and given conjunctive query with inequalities, is
undecidable.
  We also show that this problem remains undecidable if conjunctive queries
with safe negation are considered instead of conjunctive queries with
inequalities.

</details>


### [31] [Generalized Kantorovich-Rubinstein Duality beyond Hausdorff and Kantorovich](https://arxiv.org/abs/2510.23552)
*Paul Wild,Lutz Schröder,Karla Messing,Barbara König,Jonas Forster*

Main category: cs.LO

TL;DR: 该论文研究了Kantorovich-Rubinstein对偶在集合函子层面上的推广，证明了对于某些重要情况（如Lévy-Prokhorov距离和凸分布集的标准度量）可以使用相同模态满足广义对偶性。


<details>
  <summary>Details</summary>
Motivation: 经典的Kantorovich-Rubinstein对偶在概率分布空间上建立了基于传输计划和价格函数的度量等价性，但将其推广到集合函子层面时，通常需要使用额外模态。本文旨在确定哪些重要案例可以使用相同模态满足广义对偶性。

Method: 通过理论分析，研究了Wasserstein提升和Kantorovich提升在集合函子层面上的关系，并给出了具体例子说明一般情况下的模态需求差异。

Result: 证明了Lévy-Prokhorov距离和凸分布集的标准度量（结合Hausdorff和Wasserstein距离）满足广义Kantorovich-Rubinstein对偶性，即可以使用相同模态。

Conclusion: 虽然一般情况下Wasserstein提升需要额外模态才能表示为Kantorovich提升，但对于某些重要应用场景（如Lévy-Prokhorov距离和凸分布集度量），可以使用相同模态实现广义对偶性。

Abstract: The classical Kantorovich-Rubinstein duality guarantees coincidence between
metrics on the space of probability distributions defined on the one hand via
transport plans (couplings) and on the other hand via price functions. Both
constructions have been lifted to the level of generality of set functors, with
the coupling-based construction referred to as the Wasserstein lifting, and the
price-function-based construction as the Kantorovich lifting, both based on a
choice of quantitative modalities for the given functor. It is known that every
Wasserstein lifting can be expressed as a Kantorovich lifting; however, the
latter in general needs to use additional modalities. We give an example
showing that this cannot be avoided in general. We refer to cases in which the
same modalities can be used as satisfying the generalized
Kantorovich-Rubinstein duality. We establish the generalized
Kantorovich-Rubinstein duality in this sense for two important cases: The
L\'evy-Prokhorov distance on distributions, which finds wide-spread
applications in machine learning due to its favourable stability properties,
and the standard metric on convex sets of distributions that arises by
combining the Hausdorff and Wasserstein distances.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [32] [Synthesis of State-Attack Strategies for Anonymity and Opacity Violation in Discrete Event Systems](https://arxiv.org/abs/2510.22657)
*Xiaoyan Li,Christoforos N. Hadjicostis*

Main category: cs.FL

TL;DR: 该论文研究离散事件系统中状态攻击对当前状态匿名性和不透明性的影响，分析攻击者如何利用有限次数的状态攻击来破坏系统隐私，并提供相应的验证算法和攻击策略。


<details>
  <summary>Details</summary>
Motivation: 自动化系统中的传感器读数操纵和执行器命令修改等攻击对系统安全和隐私构成重大挑战，特别是状态攻击能让入侵者了解系统当前状态是否属于特定子集，从而破坏系统的匿名性和不透明性。

Method: 使用非确定性有限状态自动机对系统建模，考虑入侵者可以在任意时刻发起有限次数的状态攻击，基于系统观测序列和状态攻击结果来分析当前状态匿名性和不透明性的违反情况。

Result: 提出了验证系统在有限状态攻击下是否违反当前状态匿名性和不透明性的算法，并设计了保证系统达到违反情况的攻击策略，同时进行了相应的复杂度分析。

Conclusion: 状态攻击对离散事件系统的隐私保护构成严重威胁，论文提供的方法能够有效分析和应对这类攻击，确保系统安全性和隐私性。

Abstract: Attacks, including the manipulation of sensor readings and the modification
of actuator commands, pose a significant challenge to the security and privacy
of automated systems. This paper considers discrete event systems that can be
modeled with nondeterministic finite state automata that are susceptible to
state attacks. A state attack allows an intruder to learn whether or not the
current state of a system falls into certain subsets of states. The intruder
has a limited total number of state attacks at its disposal, but can launch
state attacks at arbitrary instants of its choosing. We are interested on
violations of current-state anonymity (resp. opacity), i.e., situations where
the intruder, based on the sequence of observations generated by the system and
the outcome of any performed state attacks, can ascertain the exact current
state of the system (resp. that the current state of the system definitely
resides in a subset of secret states). When the system violates current-state
anonymity (resp. opacity) under a bounded number of state attacks, a subsequent
question is whether the intruder can design an attack strategy such that
anonymity-violating (resp. opacity-violating) situations will always be
reached. In this latter case, we also design an attack strategy that guarantees
that the system will reach a violating situation regardless of system actions.
We provide pertinent complexity analysis of the corresponding verification
algorithms and examples to illustrate the proposed methods.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [33] [Linear effects, exceptions, and resource safety: a Curry-Howard correspondence for destructors](https://arxiv.org/abs/2510.23517)
*Sidney Congard,Guillaume Munch-Maccagnoni,Rémi Douence*

Main category: cs.PL

TL;DR: 该论文研究在线性设置中结合线性、效果和异常的问题，通过为分配monad提供某种强度来建模资源安全属性，并开发了两个线性效果演算来验证资源安全性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在抽象编程语言模型中结合线性、效果和异常，特别关注资源安全属性的建模和分析，受C++/Rust析构器启发。

Method: 引入分配monad来建模资源安全，开发了两个线性效果演算：第一个是线性call-by-push-value语言，具有new和delete分配效果；第二个是仿射有序call-by-push-value语言，集成了异常和析构器。

Result: 建立了第一个演算的资源安全属性（源于线性类型规则），并在第二个演算中通过析构器和移动操作实现了随机顺序资源释放。

Conclusion: 通过为分配monad提供强度，成功在线性设置中结合了效果和异常，验证了资源安全属性，并为类似C++/Rust的资源管理提供了理论基础。

Abstract: We analyse the problem of combining linearity, effects, and exceptions, in
abstract models of programming languages, as the issue of providing some kind
of strength for a monad $T(- \oplus E)$ in a linear setting. We consider in
particular for $T$ the allocation monad, which we introduce to model and study
resource-safety properties. We apply these results to a series of two linear
effectful calculi for which we establish their resource-safety properties.
  The first calculus is a linear call-by-push-value language with two
allocation effects $\mathit{new}$ and $\mathit{delete}$. The resource-safety
properties follow from the linear (and even ordered) character of the typing
rules.
  We then explain how to integrate exceptions on top of linearity and effects
by adjoining default destruction actions to types, as inspired by C++/Rust
destructors. We see destructors as objects $\delta : A\rightarrow TI$ in the
slice category over $TI$. This construction gives rise to a second calculus, an
affine ordered call-by-push-value language with exceptions and destructors, in
which the weakening rule performs a side-effect. As in C++/Rust, a ``move''
operation is necessary to allow random-order release of resources, as opposed
to last-in-first-out order. Moving resources is modelled as an exchange rule
that performs a side-effect.

</details>
