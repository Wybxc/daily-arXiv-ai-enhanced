<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Empirical Studies on Quantum Optimization for Software Engineering: A Systematic Analysis](https://arxiv.org/abs/2510.27113)
*Man Zhang,Yuechen Li,Tao Yue,Kai-Yuan Cai*

Main category: cs.SE

TL;DR: 对量子优化在软件工程领域的实证研究现状进行系统分析，识别当前实践中的关键差距，并为设计实证研究提供指导。


<details>
  <summary>Details</summary>
Motivation: 量子、量子启发和混合算法在解决软件工程优化问题方面显示出潜力，但实证研究的最佳实践尚未建立，需要系统分析当前研究现状。

Method: 基于最新系统文献综述确定的主要研究，从实验设计、超参数设置、案例研究、基线、工具和指标等多个方面进行系统分析。

Result: 识别出当前实践中的关键差距：重复次数和shots数量报告有限、噪声处理考虑不足、缺乏标准化评估协议（特别是量子特定指标）。

Conclusion: 需要更多真实世界和开放的案例研究来评估量子启发、量子及混合方法的成本效益和实际效用，本研究为设计和进行相关实证研究提供初步参考。

Abstract: In recent years, quantum, quantum-inspired, and hybrid algorithms are
increasingly showing promise for solving software engineering optimization
problems. However, best-intended practices for conducting empirical studies
have not yet well established. In this paper, based on the primary studies
identified from the latest systematic literature review on quantum optimization
for software engineering problems, we conducted a systematic analysis on these
studies from various aspects including experimental designs, hyperparameter
settings, case studies, baselines, tooling, and metrics. We identify key gaps
in the current practices such as limited reporting of the number of
repetitions, number of shots, and inadequate consideration of noise handling,
as well as a lack of standardized evaluation protocols such as the adoption of
quality metrics, especially quantum-specific metrics. Based on our analysis, we
provide insights for designing empirical studies and highlight the need for
more real-world and open case studies to assess cost-effectiveness and
practical utility of the three types of approaches: quantum-inspired, quantum,
and hybrid. This study is intended to offer an overview of current practices
and serve as an initial reference for designing and conducting empirical
studies on evaluating and comparing quantum, quantum-inspired, and hybrid
algorithms in solving optimization problems in software engineering.

</details>


### [2] [MARIA: A Framework for Marginal Risk Assessment without Ground Truth in AI Systems](https://arxiv.org/abs/2510.27163)
*Jieshan Chen,Suyu Ma,Qinghua Lu,Sung Une Lee,Liming Zhu*

Main category: cs.SE

TL;DR: 提出一个边际风险评估框架，避免依赖真实标签或绝对风险，通过相对评估方法比较AI系统与现有系统的风险差异。


<details>
  <summary>Details</summary>
Motivation: 在部署AI系统替代现有流程时，传统评估依赖真实标签，但实际中往往无法获得，需要更实用的相对风险评估方法。

Method: 提出边际风险评估框架，强调三种相对评估方法：可预测性、能力和交互主导性，从绝对评估转向相对评估。

Result: 该框架为软件团队提供可操作的指导，识别AI改善结果的地方、引入新风险的地方，以及如何负责任地采用此类系统。

Conclusion: 通过关注相对风险而非绝对风险，该框架使团队能够在缺乏真实标签的情况下有效评估AI系统，支持负责任的部署决策。

Abstract: Before deploying an AI system to replace an existing process, it must be
compared with the incumbent to ensure improvement without added risk.
Traditional evaluation relies on ground truth for both systems, but this is
often unavailable due to delayed or unknowable outcomes, high costs, or
incomplete data, especially for long-standing systems deemed safe by
convention. The more practical solution is not to compute absolute risk but the
difference between systems. We therefore propose a marginal risk assessment
framework, that avoids dependence on ground truth or absolute risk. It
emphasizes three kinds of relative evaluation methodology, including
predictability, capability and interaction dominance. By shifting focus from
absolute to relative evaluation, our approach equips software teams with
actionable guidance: identifying where AI enhances outcomes, where it
introduces new risks, and how to adopt such systems responsibly.

</details>


### [3] [On the Marriage of Theory and Practice in Data-Aware Business Processes via Low-Code](https://arxiv.org/abs/2510.27229)
*Ali Nour Eldin,Benjamin Dalmas,Walid Gaaloul*

Main category: cs.SE

TL;DR: BPMN-ProX是一个低代码测试框架，通过将数据注入BPMN模型来增强数据感知BPMN的验证能力，结合理论验证与实践建模。


<details>
  <summary>Details</summary>
Motivation: 业务过程模型缺乏形式化特征但被广泛采用，需要形式化其执行语义。数据和过程密不可分，数据在过程模型执行中至关重要。

Method: 开发BPMN-ProX低代码测试框架，集成先进数据处理功能，通过最先进的模型检查器实现稳健验证机制。

Result: BPMN-ProX显著增强了数据感知BPMN的验证能力，弥合非技术专家与专业人员之间的差距。

Conclusion: 这种创新方法结合理论验证与实践建模，促进更敏捷、可靠和以用户为中心的业务过程管理。

Abstract: In recent years, there has been a growing interest in the verification of
business process models. Despite their lack of formal characterization, these
models are widely adopted in both industry and academia. To address this issue,
formalizing the execution semantics of business process modeling languages is
essential. Since data and process are two facets of the same coin, and data are
critical elements in the execution of process models, this work introduces
Proving an eXecutable BPMN injected with data, BPMN-ProX. BPMN-ProX is a
low-code testing framework that significantly enhances the verification of
data-aware BPMN. This low-code platform helps bridge the gap between
non-technical experts and professionals by proposing a tool that integrates
advanced data handling and employs a robust verification mechanism through
state-of-the-art model checkers. This innovative approach combines theoretical
verification with practical modeling, fostering more agile, reliable, and
user-centric business process management.

</details>


### [4] [Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes](https://arxiv.org/abs/2510.27244)
*Ora Nova Fandina,Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Rami Katan,Alice Podolsky,Orna Raz*

Main category: cs.SE

TL;DR: 提出了SparseAlign框架，用于在稀疏人工标注数据下评估大型语言模型作为评判者的对齐度，解决了传统方法在数据有限时失效的问题。


<details>
  <summary>Details</summary>
Motivation: 传统编程语言现代化面临专家资源短缺和高质量人工评估数据不足的挑战，而未经验证的LaaJ可能产生循环评估风险，需要可靠的对齐度验证方法。

Method: SparseAlign结合了新颖的成对置信度概念和分数敏感的对齐度量，共同捕捉排名一致性和分数接近性，支持在有限标注数据下的可靠评估器选择。

Result: 在COBOL代码解释任务中应用SparseAlign选择了最佳对齐的LaaJ，并将其集成到评估工作流中指导模型发布决策。

Conclusion: SparseAlign为在稀疏人工标注数据下验证LaaJ对齐度提供了有效框架，解决了实际应用中的关键挑战。

Abstract: Application modernization in legacy languages such as COBOL, PL/I, and REXX
faces an acute shortage of resources, both in expert availability and in
high-quality human evaluation data. While Large Language Models as a Judge
(LaaJ) offer a scalable alternative to expert review, their reliability must be
validated before being trusted in high-stakes workflows. Without principled
validation, organizations risk a circular evaluation loop, where unverified
LaaJs are used to assess model outputs, potentially reinforcing unreliable
judgments and compromising downstream deployment decisions. Although various
automated approaches to validating LaaJs have been proposed, alignment with
human judgment remains a widely used and conceptually grounded validation
strategy. In many real-world domains, the availability of human-labeled
evaluation data is severely limited, making it difficult to assess how well a
LaaJ aligns with human judgment. We introduce SparseAlign, a formal framework
for assessing LaaJ alignment with sparse human-labeled data. SparseAlign
combines a novel pairwise-confidence concept with a score-sensitive alignment
metric that jointly capture ranking consistency and score proximity, enabling
reliable evaluator selection even when traditional statistical methods are
ineffective due to limited annotated examples. SparseAlign was applied
internally to select LaaJs for COBOL code explanation. The top-aligned
evaluators were integrated into assessment workflows, guiding model release
decisions. We present a case study of four LaaJs to demonstrate SparseAlign's
utility in real-world evaluation scenarios.

</details>


### [5] [Efficient Integration of cross platform functions onto service-oriented architectures](https://arxiv.org/abs/2510.27344)
*Thomas Schulik,Viswanatha Reddy Batchu,Ramesh Kumar Dharmapuri,Saran Gundlapalli,Parthasarathy Nadarajan,Philipp Pelcz*

Main category: cs.SE

TL;DR: 提出了一个硬件和软件平台无关的汽车应用开发与集成概念，通过标准化接口和机器可读描述实现跨平台应用部署，支持AUTOSAR Adaptive和ROS 2等多个软件架构平台。


<details>
  <summary>Details</summary>
Motivation: 汽车行业E/E架构正从分散式ECU向集成式域控制器和HPCs演进，导致软件平台异构化，需要开发硬件和平台无关的应用以提高开发和集成效率。

Method: 设计硬件和软件平台无关的应用，标准化应用接口，使用机器可读格式描述应用和中间件相关方面，开发工具支持开发和集成过程的半自动化。

Result: 开发了示例应用并成功集成到AUTOSAR Adaptive和ROS 2平台，证明了方法的适用性，并展示了整体概念效率的度量指标。

Conclusion: 该概念能够有效促进软件即产品的应用开发，同时确保在多个软件架构平台上的高效集成，解决了汽车行业软件平台异构化带来的挑战。

Abstract: The automotive industry is currently undergoing a major transformation with
respect to the Electric/Electronic (E/E) and software architecture, driven by a
significant increase in the complexity of the technological stack within a
vehicle. This complexity acts as a driving force for Software-Defined Vehicles
(SDVs) leading to the evolution of the automotive E/E architectures from
decentralized configuration comprising multiple Electronic Control Units (ECUs)
towards a more integrated configuration comprising a smaller number of ECUs,
domain controllers, gateways, and High-Performance Computers (HPCs) [2]. This
transition along with several other reasons have resulted in heterogeneous
software platforms such as AUTOSAR Classic, AUTOSAR Adaptive, and prototypical
frameworks like ROS 2. It is therefore essential to develop applications that
are both hardware- and platform/middleware-agnostic to attain development and
integration efficiency. This work presents an application development and
integration concept to facilitate developing applications as Software as a
Product (SaaP), while simultaneously ensuring efficient integration onto
multiple software architecture platforms. The concept involves designing
applications in a hardware- and software platform-agnostic manner and
standardizing application interfaces [6]. It also includes describing the
relevant aspects of the application and corresponding middleware in a
machine-readable format to aid the integration of developed applications.
Additionally, tools are developed to facilitate semi-automation of the
development and integration processes. An example application has been
developed and integrated onto AUTOSAR Adaptive and ROS 2, demonstrating the
applicability of the approach. Finally, metrics are presented to show the
efficiency of the overall concept.

</details>


### [6] [Agentic LLMs for REST API Test Amplification: A Comparative Study Across Cloud Applications](https://arxiv.org/abs/2510.27417)
*Jarne Besjes,Robbe Nooyens,Tolgahan Bardakci,Mutlu Beyazit,Serge Demeyer*

Main category: cs.SE

TL;DR: 本研究评估了单智能体和多智能体LLM配置在四个云应用中扩展REST API测试的效果，结果显示智能体系统能有效提升端点覆盖率和发现缺陷，同时分析了计算成本、运行时间和能耗之间的权衡。


<details>
  <summary>Details</summary>
Motivation: REST API是现代云原生系统的核心，但设计多样化和边界级别的自动化测试用例仍然具有挑战性且资源密集。

Method: 扩展了基于LLM的测试放大方法，评估了单智能体和多智能体配置在四个云应用中的表现。

Result: 放大的测试套件在最少人工干预下保持语义有效性，智能体LLM系统能有效泛化到异构API架构，提高端点覆盖率和参数覆盖率，同时发现缺陷。

Conclusion: LLM驱动的测试放大在复杂云环境中具有推进REST API测试自动化和可持续性的潜力。

Abstract: Representational State Transfer (REST) APIs are a cornerstone of modern cloud
native systems. Ensuring their reliability demands automated test suites that
exercise diverse and boundary level behaviors. Nevertheless, designing such
test cases remains a challenging and resource intensive endeavor. This study
extends prior work on Large Language Model (LLM) based test amplification by
evaluating single agent and multi agent configurations across four additional
cloud applications. The amplified test suites maintain semantic validity with
minimal human intervention. The results demonstrate that agentic LLM systems
can effectively generalize across heterogeneous API architectures, increasing
endpoint and parameter coverage while revealing defects. Moreover, a detailed
analysis of computational cost, runtime, and energy consumption highlights
trade-offs between accuracy, scalability, and efficiency. These findings
underscore the potential of LLM driven test amplification to advance the
automation and sustainability of REST API testing in complex cloud
environments.

</details>


### [7] [CodeAlignBench: Assessing Code Generation Models on Developer-Preferred Code Adjustments](https://arxiv.org/abs/2510.27565)
*Forough Mehralian,Ryan Shar,James R. Rae,Alireza Hashemi*

Main category: cs.SE

TL;DR: 提出了一个多语言基准测试，用于评估LLM的指令遵循能力，包括对预定义约束的遵循和基于后续指令进行优化的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注功能正确性，忽略了真实世界编码任务的多样性和开发者期望。

Method: 引入一个可扩展的多语言基准测试，使用LiveBench的编程任务，并自动从Python翻译到Java和JavaScript。

Result: 模型在指令遵循的多个维度上表现出不同的性能水平。

Conclusion: 该基准测试管道提供了对代码生成模型更全面的评估，揭示了它们在不同语言和生成目标上的优势和局限性。

Abstract: As large language models become increasingly capable of generating code,
evaluating their performance remains a complex and evolving challenge. Existing
benchmarks primarily focus on functional correctness, overlooking the diversity
of real-world coding tasks and developer expectations. To this end, we
introduce a multi-language benchmark that evaluates LLM instruction-following
capabilities and is extensible to operate on any set of standalone coding
problems. Our benchmark evaluates instruction following in two key settings:
adherence to pre-defined constraints specified with the initial problem, and
the ability to perform refinements based on follow-up instructions. For this
paper's analysis, we empirically evaluated our benchmarking pipeline with
programming tasks from LiveBench, that are also automatically translated from
Python into Java and JavaScript. Our automated benchmark reveals that models
exhibit differing levels of performance across multiple dimensions of
instruction-following. Our benchmarking pipeline provides a more comprehensive
evaluation of code generation models, highlighting their strengths and
limitations across languages and generation goals.

</details>


### [8] [Enhancing software product lines with machine learning components](https://arxiv.org/abs/2510.27640)
*Luz-Viviana Cobaleda,Julián Carvajal,Paola Vallejo,Andrés López,Raúl Mazo*

Main category: cs.SE

TL;DR: 提出一个结构化框架，扩展软件产品线工程以集成机器学习组件，解决ML集成带来的变异性管理挑战


<details>
  <summary>Details</summary>
Motivation: 现代软件系统越来越多地集成机器学习组件，但在软件产品线中管理ML组件的变性和复用变得复杂，现有方法很少探索这两个领域的交叉

Method: 设计一个结构化框架来扩展软件产品线工程，通过VariaMos工具部分实现，支持系统化建模变性和复用

Result: 框架已部分实现，能够促进具有ML能力的软件产品线设计

Conclusion: 该框架填补了软件产品线中机器学习组件集成和变异性管理的空白，为ML增强的软件产品线提供了系统化支持

Abstract: Modern software systems increasingly integrate machine learning (ML) due to
its advancements and ability to enhance data-driven decision-making. However,
this integration introduces significant challenges for software engineering,
especially in software product lines (SPLs), where managing variability and
reuse becomes more complex with the inclusion of ML components. Although
existing approaches have addressed variability management in SPLs and the
integration of ML components in isolated systems, few have explored the
intersection of both domains. Specifically, there is limited support for
modeling and managing variability in SPLs that incorporate ML components. To
bridge this gap, this article proposes a structured framework designed to
extend Software Product Line engineering, facilitating the integration of ML
components. It facilitates the design of SPLs with ML capabilities by enabling
systematic modeling of variability and reuse. The proposal has been partially
implemented with the VariaMos tool.

</details>


### [9] [On Selecting Few-Shot Examples for LLM-based Code Vulnerability Detection](https://arxiv.org/abs/2510.27675)
*Md Abdul Hannan,Ronghao Ni,Chi Zhang,Limin Jia,Ravi Mangal,Corina S. Pasareanu*

Main category: cs.SE

TL;DR: 探索两种选择少样本示例的标准来提高大语言模型在代码漏洞检测任务中的表现：基于模型错误率的标准和基于相似性的k近邻标准。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码漏洞检测方面表现不佳，而合适的少样本示例选择对提升模型性能至关重要。

Method: 使用两种标准选择少样本示例：1) 基于模型在样本上的错误率；2) 基于样本与查询程序的相似性（k近邻方法），并在多种组合下进行评估。

Result: 在多个开源模型和数据集上进行了评估，验证了这些标准对提升代码漏洞检测性能的有效性。

Conclusion: 合适的少样本示例选择标准可以显著提升大语言模型在代码漏洞检测任务中的性能表现。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities for
many coding tasks, including summarization, translation, completion, and code
generation. However, detecting code vulnerabilities remains a challenging task
for LLMs. An effective way to improve LLM performance is in-context learning
(ICL) - providing few-shot examples similar to the query, along with correct
answers, can improve an LLM's ability to generate correct solutions. However,
choosing the few-shot examples appropriately is crucial to improving model
performance. In this paper, we explore two criteria for choosing few-shot
examples for ICL used in the code vulnerability detection task. The first
criterion considers if the LLM (consistently) makes a mistake or not on a
sample with the intuition that LLM performance on a sample is informative about
its usefulness as a few-shot example. The other criterion considers similarity
of the examples with the program under query and chooses few-shot examples
based on the $k$-nearest neighbors to the given sample. We perform evaluations
to determine the benefits of these criteria individually as well as under
various combinations, using open-source models on multiple datasets.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Dependence-Driven, Scalable Quantum Circuit Mapping with Affine Abstractions](https://arxiv.org/abs/2510.27067)
*Marouane Benbetka,Merwan Bekkar,Riyadh Baghdadi,Martin Kong*

Main category: cs.PL

TL;DR: 提出了一种基于传递依赖权重的量子比特映射算法，通过仿射抽象建模量子电路来计算传递依赖，从而优化SWAP门插入策略，显著减少电路深度和SWAP门数量。


<details>
  <summary>Details</summary>
Motivation: 现代量子处理器受限于最近邻交互，需要插入SWAP门来修复双量子比特门的连接性。现有方法未能充分利用依赖信息，导致电路延迟增加。

Method: 使用仿射抽象建模量子电路，计算传递依赖，按依赖距离划分电路层，并为每层计算不同的权重来优化SWAP门插入。

Result: 在IBM和Rigetti量子处理器上评估，使用QUEKO和QASMBench基准测试，相比QMAP、Sabre、Cirq和TKET等工具，在电路深度和SWAP门数量方面有显著改进。

Conclusion: 该方法通过利用传递依赖信息，在保持可扩展性的同时，有效优化了量子电路的映射质量。

Abstract: Qubit Mapping is a critical task in Quantum Compilation, as modern Quantum
Processing Units (QPUs) are constrained to nearest-neighbor interactions
defined by a qubit coupling graph. This compiler pass repairs the connectivity
of two-qubit gates whose operands are not adjacent by inserting SWAP gates that
move the state of qubits between directly connected qubits. Deciding when to
introduce SWAPs while minimizing their count is critical because the error in
quantum programs increases exponentially with the circuit latency, measured in
number of gates along the critical path of the circuit. Prior work for this
problem relied on heuristics and exact methods that partition the circuit into
two or more layers, but failed to exploit valuable dependence information in
any form.
  This paper introduces a novel qubit mapping algorithm based on the weight of
transitive dependences. The introduced mapper models quantum circuits with
affine abstractions thereby yielding the ability to compute transitive
dependences. In turn, the newfound information is used to partition circuits by
dependence distances and compute, efficiently, distinct weights for each layer.
We evaluate the efficiency of our mapper on IBM and Rigetti QPUs, using the
large datasets from the QUEKO and QASMBench benchmark suites, and against four
baseline tools (QMAP, Sabre, Cirq and TKET), demonstrating notable improvements
in circuit depth and swap count while delivering competitive scalability.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [Internalizing Extensions in Lattices of Type Theories](https://arxiv.org/abs/2510.26839)
*Jonathan Chan*

Main category: cs.LO

TL;DR: 该论文探索使用依赖不可区分性演算（DCOI）来改进证明助手中的扩展追踪机制，将扩展追踪内化到类型系统中，从而提供更精确的规范。


<details>
  <summary>Details</summary>
Motivation: 现有证明助手的扩展追踪机制在类型系统外部，无法精确指定定义所依赖的扩展，导致过度近似和无法在存在不兼容扩展时重用定义。

Method: 使用依赖不可区分性演算（DCOI），这是一个具有依赖追踪的依赖类型系统，将每个扩展集对应到依赖级别，通过格结构描述扩展的交互权限。

Result: 提出了将扩展追踪内化到类型系统的方法，能够更精确地指定定义所依赖的扩展集。

Conclusion: DCOI为证明助手提供了一种将扩展追踪内化到类型系统的可行方法，解决了现有外部追踪机制的局限性。

Abstract: Many proof assistants allow the use of features and axioms that increase
their expressive power. However, these extensions must be used with care, as
some combinations are known to lead to logical inconsistencies. Therefore,
proof assistants include mechanisms that track which extensions are used in a
proof development or module, ensuring that incompatible extensions are not used
simultaneously.
  Unfortunately, existing extension tracking mechanisms are external to the
type system. This means that we cannot specify precisely which extensions a
definition depends on. Having the ability to write more precise specifications
means we are not picking an overapproximation of the extensions needed, which
prevents reusing definitions in the presence of incompatible extensions.
Furthermore, we cannot refer to definitions that use incompatible extensions
even if they are never used in inconsistent ways. The reasoning principles of
one extension therefore cannot be used as a metatheory to reason about the
properties of an incompatible extension.
  In this report, I explore the use of the Dependent Calculus of
Indistinguishability (DCOI) by Liu et al. for extension tracking. DCOI is a
dependent type system with dependency tracking, where terms and variables are
assigned dependency levels alongside their types. These dependency levels form
a lattice that describes which levels are permitted to access what. To instead
track extensions, each set of extensions would correspond to a dependency
level, and the lattice would describe how extensions are permitted to interact.

</details>


### [12] [Cut-free Deductive System for Continuous Intuitionistic Logic](https://arxiv.org/abs/2510.26849)
*Guillaume Geoffroy*

Main category: cs.LO

TL;DR: 本文通过代数语义学发展了命题连续直觉主义逻辑和命题连续仿射逻辑，基于AC-代数构建了完整的逻辑系统，并为每种变体（仿射、直觉主义、对合、经典）提供了序列式演绎系统，证明了完备性和切割可容许性。


<details>
  <summary>Details</summary>
Motivation: 开发连续逻辑的代数语义学基础，特别是为直觉主义和仿射变体建立完整的逻辑框架，填补经典连续逻辑在序列式系统方面的空白。

Method: 使用AC-代数作为代数语义学基础，AC-代数是从[0,1]到积分交换剩余完全格的保上确界函数代数。通过Macneille完备化证明每个Archimedean模型都可嵌入某个AC-代数。

Result: 建立了四种连续逻辑变体的代数语义学，给出了序列式演绎系统，证明了完备性和切割可容许性，首次为经典连续逻辑提供了具有切割可容许性的序列式系统。

Conclusion: 成功构建了连续逻辑的代数语义学框架，为直觉主义、仿射、对合和经典变体提供了统一的处理方式，填补了经典连续逻辑序列式系统的空白。

Abstract: We introduce and develop propositional continuous intuitionistic logic and
propositional continuous affine logic via complete algebraic semantics. Our
approach centres on AC-algebras, which are algebras $USC(\mathcal{L})$ of
sup-preserving functions from $[0,1]$ to an integral commutative residuated
complete lattice $\mathcal{L}$ (in the intuitionistic case, $\mathcal{L}$ is a
locale). We give an algebraic axiomatisation of AC-algebras in the language of
continuous logic and prove, using the Macneille completion, that every
Archimedean model embeds into some AC-algebra. We also show that (i)
$USC(\mathcal{L})$ satisfies $v \dot + v = 2v$ exactly when $\mathcal{L}$ is a
locale, (ii) involutiveness of negation in $USC(\mathcal{L})$ corresponds to
that in $\mathcal{L} $, and that (iii) adding those conditions recovers
classical continuous logic. For each variant -affine, intuitionistic,
involutive, classical -we provide a sequent style deductive system and prove
completeness and cut admissibility. This yields the first sequent style
formulation of classical continuous logic enjoying cut admissibility.

</details>


### [13] [The Skolem Problem in rings of positive characteristic](https://arxiv.org/abs/2510.27603)
*Ruiwen Dong,Doron Shafrir*

Main category: cs.LO

TL;DR: 本文证明了在正特征有限生成交换环中，Skolem问题是可判定的。给定一个正特征T的交换环的有限表示和一个线性递推序列，算法可以判断该序列是否包含零项。


<details>
  <summary>Details</summary>
Motivation: Skolem问题在线性递推序列理论中是一个基础性问题，研究序列是否包含零项。在正特征环中该问题的可判定性尚未完全解决，本文旨在填补这一空白。

Method: 基于两个近期结果：Dong和Shafrir关于p^e-挠模上S-单位方程解集的工作，以及Karimov等人关于两个乘法独立数的幂上线性方程求解的工作。

Result: 证明了在正特征有限生成交换环中，Skolem问题是可判定的，并且线性递推序列的零集可以表示为p_i-正规集的有限并。

Conclusion: 本文建立了正特征交换环中Skolem问题的可判定性，为线性递推序列理论提供了重要工具，并揭示了零集的结构性质。

Abstract: We show that the Skolem Problem is decidable in finitely generated
commutative rings of positive characteristic. More precisely, we show that
there exists an algorithm which, given a finite presentation of a (unitary)
commutative ring $\mathcal{R} = \mathbb{Z}_{/T}[X_1, \ldots, X_n]/I$ of
characteristic $T > 0$, and a linear recurrence sequence $(\gamma_n)_{n \in
\mathbb{N}} \in \mathcal{R}^{\mathbb{N}}$, determines whether $(\gamma_n)_{n
\in \mathbb{N}}$ contains a zero term. Our proof is based on two recent
results: Dong and Shafrir (2025) on the solution set of S-unit equations over
$p^e$-torsion modules, and Karimov, Luca, Nieuwveld, Ouaknine, and Worrell
(2025) on solving linear equations over powers of two multiplicatively
independent numbers. Our result implies, moreover, that the zero set of a
linear recurrence sequence over a ring of characteristic $T = p_1^{e_1} \cdots
p_k^{e_k}$ is effectively a finite union of $p_i$-normal sets in the sense of
Derksen (2007).

</details>
