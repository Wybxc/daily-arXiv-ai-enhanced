<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Interpolation for Converse PDL](https://arxiv.org/abs/2508.21485)
*Johannes Kloibhofer,Valentina Trucco Dalmas,Yde Venema*

Main category: cs.LO

TL;DR: Converse PDL的Craig插值性质和Beth可定义性性质证明


<details>
  <summary>Details</summary>
Motivation: 研究Converse PDL（带有程序逆操作的命题动态逻辑）的插值和可定义性性质，这些性质在逻辑学和程序验证中具有重要意义

Method: 基于Maehara的证明论方法，引入了一个健全且完备的循环sequent系统，该系统包含分析切割规则和使用焦点机制识别成功循环

Result: 证明了Converse PDL具有局部Craig插值性质（针对原子程序和命题变量），并由此推导出Beth可定义性性质

Conclusion: 成功建立了Converse PDL的重要元逻辑性质，为程序逻辑的理论基础提供了新的支持

Abstract: Converse PDL is the extension of propositional dynamic logic with a converse
operation on programs. Our main result states that Converse PDL enjoys the
(local) Craig Interpolation Property, with respect to both atomic programs and
propositional variables. As a corollary we establish the Beth Definability
Property for the logic.
  Our interpolation proof is based on an adaptation of Maehara's
proof-theoretic method. For this purpose we introduce a sound and complete
cyclic sequent system for this logic. This calculus features an analytic cut
rule and uses a focus mechanism for recognising successful cycles.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2508.21097)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 本文提出利用检索增强生成(RAG)技术增强大型语言模型(LLM)来进行模型到文本/代码转换的新研究方向，特别针对量子软件系统，通过UML模型实例生成Qiskit量子代码的实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 量子混合软件系统存在平台异构性和开发人员技能缺乏的问题，模型驱动方法可以降低成本和风险。需要探索如何利用LLM和RAG技术来改进量子代码生成。

Method: 采用检索增强生成(RAG)管道，从GitHub仓库中检索Qiskit代码样本，结合精心设计的提示工程来生成量子代码。通过UML模型实例作为输入源进行代码生成验证。

Result: 实验结果显示，经过良好设计的提示可以将CodeBLEU分数提高多达四倍，生成更准确和一致的量子代码。

Conclusion: 该方法为量子代码生成提供了有效途径，但研究方向还有进一步扩展空间，如将软件系统模型实例作为RAG管道的信息源，或用于代码到代码转换等应用场景。

Abstract: This paper introduces a novel research direction for model-to-text/code
transformations by leveraging Large Language Models (LLMs) that can be enhanced
with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum
and hybrid quantum-classical software systems, where model-driven approaches
can help reduce the costs and mitigate the risks associated with the
heterogeneous platform landscape and lack of developers' skills. We validate
one of the proposed ideas regarding generating code out of UML model instances
of software systems. This Python code uses a well-established library, called
Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG
pipeline that we deploy incorporates sample Qiskit code from public GitHub
repositories. Experimental results show that well-engineered prompts can
improve CodeBLEU scores by up to a factor of four, yielding more accurate and
consistent quantum code. However, the proposed research direction can go beyond
this through further investigation in the future by conducting experiments to
address our other research questions and ideas proposed here, such as deploying
software system model instances as the source of information in the RAG
pipelines, or deploying LLMs for code-to-code transformations, for instance,
for transpilation use cases.

</details>


### [3] [Learning to Generate Unit Test via Adversarial Reinforcement Learning](https://arxiv.org/abs/2508.21107)
*Dongjun Lee,Changho Hwang,Kimin Lee*

Main category: cs.SE

TL;DR: UTRLa一种通过强化学习训练LLM生成高质量单元测试的对抗性框架，通过测试生成器和代码生成器的对抗训练提升测试质量


<details>
  <summary>Details</summary>
Motivation: 单元测试对程序评估至关重要，但人工编写全面测试面临挑战，当前LLM自动测试生成方法仍有限

Method: 迭代训练两个LLM（测试生成器和代码生成器），测试生成器通过判别奖励学习生成能曝露代码错误的测试，代码生成器通过代码奖励学习生成能通过测试的代码

Result: UTRLa训练的Qwen3-4B测试质量超过相同模型的监督学习结果，代码评估更接近真实测试，甚至超迈GPT-4.1等领先模型

Conclusion: UTRLa框架通过对抗性训练有效提升LLM的单元测试生成能力，为自动化测试生成提供了新的训练方法

Abstract: Unit testing is a core practice in programming, enabling systematic
evaluation of programs produced by human developers or large language models
(LLMs). Given the challenges in writing comprehensive unit tests, LLMs have
been employed to automate test generation, yet methods for training LLMs to
produce high-quality tests remain underexplored. In this work, we propose UTRL,
a novel reinforcement learning framework that trains an LLM to generate
high-quality unit tests given a programming instruction. Our key idea is to
iteratively train two LLMs, the unit test generator and the code generator, in
an adversarial manner via reinforcement learning. The unit test generator is
trained to maximize a discrimination reward, which reflects its ability to
produce tests that expose faults in the code generator's solutions, and the
code generator is trained to maximize a code reward, which reflects its ability
to produce solutions that pass the unit tests generated by the test generator.
In our experiments, we demonstrate that unit tests generated by Qwen3-4B
trained via UTRL show higher quality compared to unit tests generated by the
same model trained via supervised fine-tuning on human-written ground-truth
unit tests, yielding code evaluations that more closely align with those
induced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL
outperforms frontier models such as GPT-4.1 in generating high-quality unit
tests, highlighting the effectiveness of UTRL in training LLMs for this task.

</details>


### [4] [Automated Bug Triaging using Instruction-Tuned Large Language Models](https://arxiv.org/abs/2508.21156)
*Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan*

Main category: cs.SE

TL;DR: 提出了一个轻量级框架，使用指令调优的大语言模型和LoRA适配器，通过候选约束解码实现有效的bug分配，在EclipseJDT和Mozilla数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型项目中的bug分配任务通常缓慢且不一致，需要一种更高效的自动化解决方案来替代成本高昂的特征工程和图基方法。

Method: 使用指令调优的大语言模型（LLM）配合LoRA适配器，采用候选约束解码技术来确保有效的bug分配。

Result: 在EclipseJDT和Mozilla数据集上，模型在短名单质量方面表现强劲（Hit at 10达到0.753），尽管Top-1准确率一般。在最新快照上准确率显著提升。

Conclusion: 指令调优的LLMs为实际应用中的人机协作bug分配提供了一个实用的替代方案，显示出在现实世界应用的潜力。

Abstract: Bug triaging, the task of assigning new issues to developers, is often slow
and inconsistent in large projects. We present a lightweight framework that
instruction-tuned large language model (LLM) with LoRA adapters and uses
candidate-constrained decoding to ensure valid assignments. Tested on
EclipseJDT and Mozilla datasets, the model achieves strong shortlist quality
(Hit at 10 up to 0.753) despite modest exact Top-1 accuracy. On recent
snapshots, accuracy rises sharply, showing the framework's potential for
real-world, human-in-the-loop triaging. Our results suggest that
instruction-tuned LLMs offer a practical alternative to costly feature
engineering and graph-based methods.

</details>


### [5] [The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management](https://arxiv.org/abs/2508.21433)
*Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov*

Main category: cs.SE

TL;DR: 在SWE-bench Verified上对比了两种上下文管理策略：简单投影和LLM摘要。结果显示简单投影策略在成本上减半的同时，解决率与摘要策略相当或更好。


<details>
  <summary>Details</summary>
Motivation: 识别LLM基代理在解决复杂任务时产生的长上下文压力问题，并探索更简单的上下文管理策略是否能涉及复杂的LLM摘要方法。

Method: 在SWE-agent上使用SWE-bench Verified数据集，系统比较了两种上下文管理策略：简单投影和LLM摘要，测试了五种不同的模型配置。

Result: 简单投影策略将成本减半，同时解决率与摘要策略相当或更好。例如Qwen3-Coder 480B下，投影将解决率从53.8%提升到54.8%，而成本更低。

Conclusion: 在SWE-agent和SWE-bench Verified环境下，最有效和高效的上下文管理策略可能就是最简单的方法，复杂的LLM摘要并没有带来显著的性能优势。

Abstract: Large Language Model (LLM)-based agents solve complex tasks through iterative
reasoning, exploration, and tool-use, a process that can result in long,
expensive context histories. While state-of-the-art Software Engineering ( SE)
agents like OpenHands or Cursor use LLM-based summarization to tackle this
issue, it is unclear whether the increased complexity offers tangible
performance benefits compared to simply omitting older observations. We present
a systematic comparison of these strategies within SWE-agent on SWE-bench
Verified across five diverse model configurations. We find that a simple
observation-masking strategy halves cost relative to a raw agent while
matching, and sometimes slightly exceeding, the solve rate of LLM
summarization. For example, with Qwen3-Coder 480B, masking improves solve rate
from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization
at a lower cost. These results suggest that, at least within SWE-agent on
SWE-bench Verified, the most effective and efficient context management can be
the simplest. We release code and data for reproducibility

</details>


### [6] [Enhancing Semantic Understanding in Pointer Analysis using Large Language Models](https://arxiv.org/abs/2508.21454)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: LMPA是一个将大语言模型集成到指针分析中的新框架，通过LLM识别类似系统API的用户自定义函数并建模，提高分析精度和可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有指针分析框架由于对代码语义理解不足，对用户自定义函数处理过于保守，导致错误事实传播。LLM的发展为解决这一问题提供了新机会

Method: LMPA识别类似系统API的用户自定义函数并相应建模，减少错误的跨调用上下文传播；通过推断初始点集和基于自然语言的摘要策略增强基于摘要的分析

Result: 论文提出了LMPA愿景，讨论了实现该愿景的关键挑战，但未提供具体实验结果

Conclusion: 集成LLM到指针分析中能够显著提升分析精度和可扩展性，为解决传统指针分析的局限性提供了新方向

Abstract: Pointer analysis has been studied for over four decades. However, existing
frameworks continue to suffer from the propagation of incorrect facts. A major
limitation stems from their insufficient semantic understanding of code,
resulting in overly conservative treatment of user-defined functions. Recent
advances in large language models (LLMs) present new opportunities to bridge
this gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a
vision that integrates LLMs into pointer analysis to enhance both precision and
scalability. LMPA identifies user-defined functions that resemble system APIs
and models them accordingly, thereby mitigating erroneous cross-calling-context
propagation. Furthermore, it enhances summary-based analysis by inferring
initial points-to sets and introducing a novel summary strategy augmented with
natural language. Finally, we discuss the key challenges involved in realizing
this vision.

</details>


### [7] [Reusable Test Suites for Reinforcement Learning](https://arxiv.org/abs/2508.21553)
*Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker*

Main category: cs.SE

TL;DR: 提出MPTCS方法，从任何策略测试框架生成的测试用例中，基于可解性、多样性和通用难度选择多样化的策略无关测试用例集合


<details>
  <summary>Details</summary>
Motivation: 现有强化学习策略测试方法生成的测试套件针对特定策略定制，对其他策略的适用性不明确，需要开发可重用的策略无关测试用例选择方法

Method: 使用一组策略基于难度分数从候选池中选择测试用例，采用受质量-多样性算法启发的离散化通用测试用例描述符表面来促进测试套件多样性

Result: 评估了难度分数的有效性，分析了方法效果和成本与策略数量的关系，检验了多样性方法对状态空间的覆盖和触发策略产生错误行为的能力

Conclusion: MPTCS能够选择揭示智能体行为典型缺陷的多样化可重用策略无关测试用例，为强化学习策略测试提供了有效的测试套件选择方法

Abstract: Reinforcement learning (RL) agents show great promise in solving sequential
decision-making tasks. However, validating the reliability and performance of
the agent policies' behavior for deployment remains challenging. Most
reinforcement learning policy testing methods produce test suites tailored to
the agent policy being tested, and their relevance to other policies is
unclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel
automated test suite selection method for RL environments, designed to extract
test cases generated by any policy testing framework based on their
solvability, diversity, and general difficulty. MPTCS uses a set of policies to
select a diverse collection of reusable policy-agnostic test cases that reveal
typical flaws in the agents' behavior. The set of policies selects test cases
from a candidate pool, which can be generated by any policy testing method,
based on a difficulty score. We assess the effectiveness of the difficulty
score and how the method's effectiveness and cost depend on the number of
policies in the set. Additionally, a method for promoting diversity in the test
suite, a discretized general test case descriptor surface inspired by
quality-diversity algorithms, is examined to determine how it covers the state
space and which policies it triggers to produce faulty behaviors.

</details>


### [8] [Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity](https://arxiv.org/abs/2508.21634)
*Domenico Cotroneo,Cristina Improta,Pietro Liguori*

Main category: cs.SE

TL;DR: 大规模对比人类与AI（ChatGPT、DeepSeek-Coder、Qwen-Coder）编写的代码质量，发现AI代码更简单重复但包含更多高风险安全漏洞，人类代码结构更复杂但维护性问题更多


<details>
  <summary>Details</summary>
Motivation: 随着AI代码助手在软件开发中的广泛应用，需要理解AI生成代码与人类编写代码的质量差异，以确保软件的可靠性、可维护性和安全性

Method: 评估超过50万个Python和Java代码样本，使用正交缺陷分类法分析代码缺陷，采用通用弱点枚举评估安全漏洞，从代码缺陷、安全漏洞和结构复杂性三个维度进行比较

Result: AI生成的代码通常更简单和重复，但更容易出现未使用的结构和硬编码调试；人类编写的代码结构更复杂，维护性问题更集中；AI生成的代码包含更多高风险安全漏洞

Conclusion: AI和人类编写的代码具有不同的缺陷特征，需要在AI辅助编程中采用专门的质量保证实践

Abstract: As AI code assistants become increasingly integrated into software
development workflows, understanding how their code compares to human-written
programs is critical for ensuring reliability, maintainability, and security.
In this paper, we present a large-scale comparison of code authored by human
developers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and
Qwen-Coder, on multiple dimensions of software quality: code defects, security
vulnerabilities, and structural complexity. Our evaluation spans over 500k code
samples in two widely used languages, Python and Java, classifying defects via
Orthogonal Defect Classification and security vulnerabilities using the Common
Weakness Enumeration. We find that AI-generated code is generally simpler and
more repetitive, yet more prone to unused constructs and hardcoded debugging,
while human-written code exhibits greater structural complexity and a higher
concentration of maintainability issues. Notably, AI-generated code also
contains more high-risk security vulnerabilities. These findings highlight the
distinct defect profiles of AI- and human-authored code and underscore the need
for specialized quality assurance practices in AI-assisted programming.

</details>


### [9] [The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry](https://arxiv.org/abs/2508.21811)
*Ashley Hourigan,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 这篇论文通过半结构化访谈和主题分析，研究了Agile和DevOps实践在IT行业中的集成可行性，提出了新的理论框架来说明两者的相互关系。


<details>
  <summary>Details</summary>
Motivation: IT行业对软件交付速度的需求日益增长，需要更快速、更高质量的软件产品和服务。Agile和DevOps作为现代软件开发方法论，需要研究它们在实践中的集成可能性和效果。

Method: 采用11个半结构化访谈，访谈对象来自IT行业各个部门的Agile和DevOps实践者。通过主题分析提取了51个唯一代码，综合成19个主题，重点分析DevOps生命周期各阶段中Agile方法的集成和实施情况。

Result: 研究发现了Agile方法在DevOps实践中的可行性和适用性，并提出了一个新的理论理解，详细说明了两者之间的相互关系。这个新理论框架满足了研究目标。

Conclusion: 论文成功证明了Agile方法在DevOps实践中的集成可行性，为IT行业提供了重要的实践指南。研究结果不仅增进了对两种方法论相互关系的理论理解，还为软件开发实践者提供了具体的集成方案和最佳实践。

Abstract: The demand for rapid software delivery in the Information Technology (IT)
industry has significantly intensified, emphasising the need for faster
software products and service releases with enhanced features to meet customer
expectations. Agile methodologies are replacing traditional approaches such as
Waterfall, where flexibility, iterative development and adaptation to change
are favoured over rigid planning and execution. DevOps, a subsequent evolution
from Agile, emphasises collaborative efforts in development and operations
teams, focusing on continuous integration and deployment to deliver resilient
and high-quality software products and services. This study aims to critically
assess both Agile and DevOps practices in the IT industry to identify the
feasibility and applicability of Agile methods in DevOps practices. Eleven
semi-structured interviews were conducted with Agile and DevOps practitioners
in varying capacities across several sectors within the IT industry. Through
thematic analysis, 51 unique codes were extracted and synthesised into 19
themes that reported on each phase of the DevOps lifecycle, specifically
regarding the integration and implementation of Agile methods into DevOps
practices. Based on the findings, a new understanding detailing the
interrelationship of Agile methods in DevOps practices was discussed that met
the research objectives.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [CrossTL: A Universal Programming Language Translator with Unified Intermediate Representation](https://arxiv.org/abs/2508.21256)
*Nripesh Niketan,Vaatsalya Shrivastva*

Main category: cs.PL

TL;DR: CrossTL是一个通用的编程语言翻译器，通过统一的中间表示CrossGL实现多种语言间的双向翻译，支持CUDA、HIP、Metal、HLSL、GLSL、SPIR-V、Rust和Mojo等语言，采用模块化架构，验证了通用代码翻译的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为每种语言对单独构建翻译器，导致复杂度呈指数级增长。CrossTL旨在通过统一的中间表示解决这一问题，实现"一次编写，到处部署"的语言无关编程。

Method: 系统包含：语言特定的词法分析器/解析器将源代码转换为AST；双向CrossGL翻译模块（ToCrossGLConverter类用于导入代码，CodeGen类用于目标代码生成）；完整的后端实现处理全翻译流水线。

Result: 通过跨编程领域的全面评估，在所有支持的后端上实现了成功的编译和执行，证明了系统的有效性。

Conclusion: CrossTL的统一IR设计使得添加新语言只需最少的工作量，仅需要语言特定的前端/后端组件，代表了向语言无关编程迈出的重要一步。

Abstract: We present CrossTL, a universal programming language translator enabling
bidirectional translation between multiple languages through a unified
intermediate representation called CrossGL. Traditional approaches require
separate translators for each language pair, leading to exponential complexity
growth. CrossTL uses a single universal IR to facilitate translations between
CUDA, HIP, Metal, DirectX HLSL, OpenGL GLSL, Vulkan SPIR-V, Rust, and Mojo,
with Slang support in development. Our system consists of: language-specific
lexers/parsers converting source code to ASTs, bidirectional CrossGL
translation modules implementing ToCrossGLConverter classes for importing code
and CodeGen classes for target generation, and comprehensive backend
implementations handling full translation pipelines. We demonstrate
effectiveness through comprehensive evaluation across programming domains,
achieving successful compilation and execution across all supported backends.
The universal IR design enables adding new languages with minimal effort,
requiring only language-specific frontend/backend components. Our contributions
include: (1) a unified IR capturing semantics of multiple programming
paradigms, (2) a modular architecture enabling extensibility, (3) a
comprehensive framework supporting GPU compute, graphics programming, and
systems languages, and (4) empirical validation demonstrating practical
viability of universal code translation. CrossTL represents a significant step
toward language-agnostic programming, enabling write-once, deploy-everywhere
development.

</details>


### [11] [Growing Mathlib: maintenance of a large scale mathematical library](https://arxiv.org/abs/2508.21593)
*Anne Baanen,Matthew Robert Ballard,Johan Commelin,Bryan Gin-ge Chen,Michael Rothgang,Damiano Testa*

Main category: cs.PL

TL;DR: Mathlib是快速增长的数学形式化库，本文描述了管理其增长、处理破坏性变更、提高代码质量、优化编译速度和处理技术债务的策略。


<details>
  <summary>Details</summary>
Motivation: 随着Mathlib数学库的快速增长，需要有效管理库的扩展，同时允许变更并避免维护者过载，确保库的可持续发展和高质量。

Method: 采用多种策略：通过弃用系统处理破坏性变更、使用代码质量分析工具（linters）提供用户反馈、通过库（重新）设计加速编译、处理技术债务以及开发自定义工具协助审查和分类新贡献。

Result: 开发了一套综合的管理策略和工具，能够有效应对大型数学形式化库的快速增长和维护挑战。

Conclusion: 通过系统化的管理策略和定制工具，Mathlib能够在快速增长的同时保持高质量和可维护性，为大型形式化数学库的管理提供了有效解决方案。

Abstract: The Lean mathematical library Mathlib is one of the fastest-growing libraries
of formalised mathematics. We describe various strategies to manage this
growth, while allowing for change and avoiding maintainer overload. This
includes dealing with breaking changes via a deprecation system, using code
quality analysis tools (linters) to provide direct user feedback about common
pitfalls, speeding up compilation times through conscious library (re-)design,
dealing with technical debt as well as writing custom tooling to help with the
review and triage of new contributions.

</details>
