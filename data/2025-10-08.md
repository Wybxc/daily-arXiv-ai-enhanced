<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 3]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 15]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [On the Interplay of Cube Learning and Dependency Schemes in QCDCL Proof Systems](https://arxiv.org/abs/2510.05876)
*Abhimanyu Choudhury,Meena Mahajan*

Main category: cs.LO

TL;DR: 本文形式化了使用立方体学习和依赖方案的QCDCL求解器的证明系统，提出了完备性和可靠性的充分条件，并证明使用标准依赖方案和自反依赖方案可以缩短反驳证明。


<details>
  <summary>Details</summary>
Motivation: 现有的QCDCL证明系统要么没有使用立方体学习，要么只有限使用依赖方案。本文旨在形式化同时使用立方体学习和完全依赖方案的QCDCL推理系统。

Method: 形式化了使用立方体学习和依赖方案的QCDCL证明系统，分析了使用标准依赖方案(D^std)和自反依赖方案(D^rrs)时的系统特性。

Result: 证明了使用依赖方案可以缩短反驳证明，并详细分析了在量化顺序约束下使用依赖方案与立方体学习的证明系统的相对强度。

Conclusion: 本文成功形式化了同时使用立方体学习和依赖方案的QCDCL证明系统，为QBF求解器的理论分析提供了更完整的框架。

Abstract: Quantified Conflict Driven Clause Leaning (QCDCL) is one of the main
approaches to solving Quantified Boolean Formulas (QBF). Cube-learning is
employed in this approach to ensure that true formulas can be verified.
Dependency Schemes help to detect spurious dependencies that are implied by the
variable ordering in the quantifier prefix of QBFs but are not essential for
constructing (counter)models. This detection can provably shorten refutations
in specific proof systems, and is expected to speed up runs of QBF solvers.
  The simplest underlying proof system [BeyersdorffB\"ohm-LMCS2023], formalises
the reasoning in the QCDCL approach on false formulas, when neither cube
learning nor dependency schemes is used. The work of
[B\"ohmPeitlBeyersdorff-AI2024] further incorporates cube-learning. The work of
[ChoudhuryMahajan-JAR2024] incorporates a limited use of dependency schemes,
but without cube-learning.
  In this work, proof systems underlying the reasoning of QCDCL solvers which
use cube learning, and which use dependency schemes at all stages, are
formalised. Sufficient conditions for soundness and completeness are presented,
and it is shown that using the standard and reflexive resolution path
dependency schemes ($D^{std}$ and $D^{rrs}$) to relax the decision order
provably shortens refutations.
  When the decisions are restricted to follow quantification order, but
dependency schemes are used in propagation and learning, in conjunction with
cube-learning, the resulting proof systems using the dependency schemes
$D^{std}$ and $D^{rrs}$ are investigated in detail and their relative strengths
are analysed.

</details>


### [2] [On Equivalent Characterizations of NP in Abstract Models of Computation](https://arxiv.org/abs/2510.05894)
*Jeremy C. Kirn,Lucas Meijer,Tillmann Miltzow,Hans L. Bodlaender*

Main category: cs.LO

TL;DR: 该论文研究了基于一阶结构R的图灵机模型，证明了在弱条件下NP(R)的三个等价特征：多项式时间验证算法、NP(R)-完全问题SAT(R)和存在二阶元有限逻辑。论文还扩展了这些结果到多项式层次和布尔层次。


<details>
  <summary>Details</summary>
Motivation: 扩展传统复杂性理论到基于任意一阶结构的计算模型，建立NP(R)的完整理论框架，解决无限词汇结构下的复杂性分类问题。

Method: 使用R-机器作为计算模型，结合多项式时间验证、完全问题和描述性逻辑三种方法，通过元有限逻辑处理无限词汇结构。

Result: 证明了在弱条件下NP(R)的三个等价特征，即使在无限词汇结构下也能通过描述性逻辑进行刻画，并扩展了结果到多项式层次和布尔层次。

Conclusion: 描述性复杂性理论能很好地处理无限词汇结构，为基于任意一阶结构的复杂性理论提供了统一的框架，扩展了传统复杂性理论的应用范围。

Abstract: We investigate machine models similar to Turing machines that are augmented
by the operations of a first-order structure $\mathcal{R}$, and we show that
under weak conditions on $\mathcal{R}$, the complexity class
$\text{NP}(\mathcal{R})$ may be characterized in three equivalent ways: (1) by
polynomial-time verification algorithms implemented on $\mathcal{R}$-machines,
(2) by the $\text{NP}(\mathcal{R})$-complete problem $\text{SAT}(\mathcal{R})$,
and (3) by existential second-order metafinite logic over $\mathcal{R}$ via
descriptive complexity. By characterizing $\text{NP}(\mathcal{R})$ in these
three ways, we extend previous work and embed it in one coherent framework.
  Some conditions on $\mathcal{R}$ must be assumed in order to achieve the
above trinity because there are infinite-vocabulary structures for which
$\text{NP}(\mathcal{R})$ does not have a complete problem. Surprisingly, even
in these cases, we show that $\text{NP}(\mathcal{R})$ does have a
characterization in terms of existential second-order metafinite logic,
suggesting that descriptive complexity theory is well suited to working with
infinite-vocabulary structures, such as real vector spaces.
  In addition, we derive similar results for $\exists\mathcal{R}$, the
constant-free Boolean part of $\text{NP}(\mathcal{R})$, by showing that
$\exists\mathcal{R}$ may be characterized in three analogous ways. We then
extend our results to the entire polynomial hierarchy over $\mathcal{R}$ and to
its constant-free Boolean counterpart, the Boolean hierarchy over
$\mathcal{R}$. Finally, we give a characterization of the polynomial and
Boolean hierarchies over $\mathcal{R}$ in terms of oracle
$\mathcal{R}$-machines.

</details>


### [3] [A Timed Obstruction Logic for Dynamic Game Models](https://arxiv.org/abs/2510.06045)
*David Cortes,Jean Leneutre,Vadim Malvone,James Ortiz*

Main category: cs.LO

TL;DR: 本文提出了Timed Obstruction Logic (TOL)，这是Obstruction Logic (OL)的扩展，用于验证具有实时目标的定时博弈。TOL能够描述网络安全博弈的重要定时属性，其验证复杂度为PSPACE-complete，与经典定时时序逻辑相同。


<details>
  <summary>Details</summary>
Motivation: 实时网络安全应用需要可靠的验证方法和系统设计工具来确保正确性。许多嵌入在基础设施中的反应式实时应用容易受到恶意网络攻击，需要建模攻击者和防御者之间的战略互动。

Method: 扩展Obstruction Logic (OL)为Timed Obstruction Logic (TOL)，这是一种用于验证动态模型中具有实时目标的特定定时博弈的形式化方法。这些博弈涉及玩家，其离散和连续动作可以影响底层定时博弈模型。

Result: TOL能够描述实时网络安全博弈的重要定时属性。提供了TOL的验证程序，并证明其复杂度为PSPACE-complete，与经典定时时序逻辑如TCTL相同。

Conclusion: 通过引入TOL并将其适应于网络安全环境中的属性规范，在不增加复杂度的情况下提高了属性的表达能力，为实时网络安全应用提供了更强大的验证工具。

Abstract: Real-time cybersecurity and privacy applications require reliable
verification methods and system design tools to ensure their correctness. Many
of these reactive real-time applications embedded in various infrastructures,
such as airports, hospitals, and oil pipelines, are potentially vulnerable to
malicious cyber-attacks. Recently, a growing literature has recognized Timed
Game Theory as a sound theoretical foundation for modeling strategic
interactions between attackers and defenders. This paper proposes Timed
Obstruction Logic (TOL), an extension of Obstruction Logic (OL), a formalism
for verifying specific timed games with real-time objectives unfolding in
dynamic models. These timed games involve players whose discrete and continuous
actions can impact the underlying timed game model. We show that TOL can be
used to describe important timed properties of real-time cybersecurity games.
Finally, in addition to introducing our new logic and adapting it to specify
properties in the context of cybersecurity, we provide a verification procedure
for TOL and show that its complexity is PSPACE-complete, meaning that it is not
higher than that of classical timed temporal logics like TCTL. Thus, we
increase the expressiveness of properties without incurring any cost in terms
of complexity.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [4] [Iterating Non-Aggregative Structure Compositions](https://arxiv.org/abs/2510.06019)
*Marius Bozga,Radu Iosif,Florian Zuleger*

Main category: cs.FL

TL;DR: 本文研究了一种称为融合的非聚合性组合操作，证明了在给定集合通过融合闭包时树宽有界性的可判定性，并展示了当树宽有界时如何有效构造HR文法。


<details>
  <summary>Details</summary>
Motivation: 传统图代数基于聚合性组合操作，而本文探索非聚合性融合操作的理论性质，特别是其对树宽的影响以及相关的逻辑可判定性问题。

Method: 使用超边替换(HR)文法描述输入集合，分析融合操作对树宽的影响，并开发算法来判定树宽有界性及构造相应的HR文法。

Result: 证明了在HR文法描述的上下文无关集合下，融合闭包的树宽有界性问题是可判定的，且当树宽有界时可有效构造HR文法。

Conclusion: 非聚合性融合操作虽然可能导致树宽无界，但在树宽有界的情况下，可以有效地处理相关的逻辑验证问题，扩展了形式图语言理论的应用范围。

Abstract: An aggregative composition is a binary operation obeying the
  principle that the whole is determined by the sum of its parts. The
  development of graph algebras, on which the theory of formal graph
  languages is built, relies on aggregative compositions that behave
  like disjoint union, except for a set of well-marked interface
  vertices from both sides, that are joined. The same style of
  composition has been considered in the context of relational
  structures, that generalize graphs and use constant symbols to label
  the interface.
  In this paper, we study a non-aggregative composition operation,
  called \emph{fusion}, that joins non-deterministically chosen
  elements from disjoint structures. The sets of structures obtained
  by iteratively applying fusion do not always have bounded
  tree-width, even when starting from a tree-width bounded set.
  First, we prove that the problem of the existence of a bound on the
  tree-width of the closure of a given set under fusion is decidable,
  when the input set is described inductively by a finite
  \emph{hyperedge-replacement} (HR) grammar, written using the
  operations of aggregative composition, forgetting and renaming of
  constants. Such sets are usually called \emph{context-free}.
  Second, assuming that the closure under fusion of a context-free set
  has bounded tree-width, we show that it is the language of an
  effectively constructible HR grammar. A possible application of the
  latter result is the possiblity of checking whether all structures
  from a non-aggregatively closed set having bounded tree-width
  satisfy a given monadic second order logic formula.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Adaptive Reinforcement Learning for Dynamic Configuration Allocation in Pre-Production Testing](https://arxiv.org/abs/2510.05147)
*Yu Zhu*

Main category: cs.SE

TL;DR: 本文提出了一种基于强化学习的自适应配置分配框架，用于解决非平稳环境下软件测试资源配置的优化问题。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统需要在高度异构和动态变化的环境中进行严格的预生产测试，但传统组合优化方法无法有效应对概率漂移的非平稳环境。

Method: 采用Q-learning强化学习框架，结合混合奖励设计（融合模拟结果和实时反馈），并开发了自适应在线-离线训练方案来快速跟踪概率变化。

Result: 广泛的仿真研究表明，该方法持续优于静态和基于优化的基线方法，接近oracle性能。

Conclusion: 这项工作确立了强化学习作为自适应配置分配的新范式，超越了传统方法，在动态测试和资源调度领域具有广泛适用性。

Abstract: Ensuring reliability in modern software systems requires rigorous
pre-production testing across highly heterogeneous and evolving environments.
Because exhaustive evaluation is infeasible, practitioners must decide how to
allocate limited testing resources across configurations where failure
probabilities may drift over time. Existing combinatorial optimization
approaches are static, ad hoc, and poorly suited to such non-stationary
settings. We introduce a novel reinforcement learning (RL) framework that
recasts configuration allocation as a sequential decision-making problem. Our
method is the first to integrate Q-learning with a hybrid reward design that
fuses simulated outcomes and real-time feedback, enabling both sample
efficiency and robustness. In addition, we develop an adaptive online-offline
training scheme that allows the agent to quickly track abrupt probability
shifts while maintaining long-run stability. Extensive simulation studies
demonstrate that our approach consistently outperforms static and
optimization-based baselines, approaching oracle performance. This work
establishes RL as a powerful new paradigm for adaptive configuration
allocation, advancing beyond traditional methods and offering broad
applicability to dynamic testing and resource scheduling domains.

</details>


### [6] [VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation](https://arxiv.org/abs/2510.05156)
*Lesly Miculicich,Mihir Parmar,Hamid Palangi,Krishnamurthy Dj Dvijotham,Mirko Montanari,Tomas Pfister,Long T. Le*

Main category: cs.SE

TL;DR: VeriGuard是一个为LLM智能体提供形式化安全保障的双阶段框架，通过离线验证和在线监控确保智能体行为符合安全约束。


<details>
  <summary>Details</summary>
Motivation: 在医疗等敏感领域部署自主AI智能体存在安全风险，现有系统无法充分保证智能体行为符合预定义安全约束。

Method: 采用双阶段架构：离线阶段通过意图澄清、策略合成和形式化验证来确保策略正确性；在线阶段作为运行时监控器验证每个动作。

Result: 该框架能够实际应用形式化保证，显著提高LLM智能体的可信度。

Conclusion: VeriGuard通过分离离线验证和在线监控，为LLM智能体提供了实用的形式化安全保障机制。

Abstract: The deployment of autonomous AI agents in sensitive domains, such as
healthcare, introduces critical risks to safety, security, and privacy. These
agents may deviate from user objectives, violate data handling policies, or be
compromised by adversarial attacks. Mitigating these dangers necessitates a
mechanism to formally guarantee that an agent's actions adhere to predefined
safety constraints, a challenge that existing systems do not fully address. We
introduce VeriGuard, a novel framework that provides formal safety guarantees
for LLM-based agents through a dual-stage architecture designed for robust and
verifiable correctness. The initial offline stage involves a comprehensive
validation process. It begins by clarifying user intent to establish precise
safety specifications. VeriGuard then synthesizes a behavioral policy and
subjects it to both testing and formal verification to prove its compliance
with these specifications. This iterative process refines the policy until it
is deemed correct. Subsequently, the second stage provides online action
monitoring, where VeriGuard operates as a runtime monitor to validate each
proposed agent action against the pre-verified policy before execution. This
separation of the exhaustive offline validation from the lightweight online
monitoring allows formal guarantees to be practically applied, providing a
robust safeguard that substantially improves the trustworthiness of LLM agents.

</details>


### [7] [Test Case Generation from Bug Reports via Large Language Models: A Cognitive Layered Evaluation Framework](https://arxiv.org/abs/2510.05365)
*Irtaza Sajid Qureshi,Zhen Ming,Jiang*

Main category: cs.SE

TL;DR: 本文系统评估了LLM在测试用例生成中的推理能力，基于Bloom认知分类学框架，发现LLM能记忆和部分理解任务，但在应用层面存在严重性能下降，而提供示例和结构化技术元素能显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在自动化软件测试中的泛化能力，特别是超越记忆模式、理解自然语言错误报告并进行推理的能力。

Method: 基于LIBRO框架，使用Bloom认知分类学的六个层次（记忆、理解、应用、分析、评估、创造）来评估StarCoder和GPT-4o在Defects4J、GHRB及其变异数据集上的表现。

Result: LLM能重现先前结果（记忆层），对语言重述和翻译具有部分鲁棒性（理解层），但在标识符变异下性能下降超过60%（应用层）。提供少量示例可将成功率提升三倍，结构化技术元素比叙述性描述对测试生成更有效。

Conclusion: 揭示了LLM生成测试的认知过程，为改进性能提供了具体方向，并为此任务建立了稳健现实的评估范式。

Abstract: Large Language Models (LLMs) are increasingly applied to automated software
testing, yet their ability to generalize beyond memorized patterns and reason
about natural language bug reports remains unclear. We present a systematic
evaluation of LLM reasoning in test case generation, structured around the
cognitive layers of Bloom's taxonomy: \textit{Remember}, \textit{Understand},
\textit{Apply}, \textit{Analyze}, \textit{Evaluate}, and \textit{Create}, which
progressively assess higher levels of cognitive and reasoning capabilities.
Building on the LIBRO framework, we evaluate StarCoder and GPT-4o on Defects4J,
GHRB, and mutated variants that introduce linguistic and semantic challenges.
Our findings show that both models largely reproduce prior results with minor
deviations (\textit{Remember}), exhibit partial robustness to linguistic
rephrasings and translations while uncovering unique reproducible bugs
(\textit{Understand}), but suffer severe performance drops exceeding 60\% under
identifier mutations (\textit{Apply}). Conversely, providing near-identical
few-shot examples in an open-book setting improves success rates by up to three
times, and component-level analysis reveals that structured technical elements,
such as test code and method names, are far more impactful than narrative
descriptions for successful test generation (\textit{Analyze}). These insights
illuminate the cognitive processes underlying LLM-generated tests, suggest
concrete directions for improving performance, and establish a robust and
realistic evaluation paradigm for this task.

</details>


### [8] [Who Do You Think You Are? Creating RSE Personas from GitHub Interactions](https://arxiv.org/abs/2510.05390)
*Felicity Anderson,Julien Sindt,Neil Chue Hong*

Main category: cs.SE

TL;DR: 本文提出了一种结合软件仓库挖掘和数据驱动角色的方法，用于识别研究软件工程中的常见和罕见开发模式，通过分析GitHub上115,174名贡献者在1,284个研究软件仓库中的行为，识别出7种不同的角色类型。


<details>
  <summary>Details</summary>
Motivation: 研究软件工程（RSE）领域缺乏系统化的贡献者行为分析框架，需要一种方法来理解和描述RSE开发中的协作模式，帮助个人和项目团队评估其贡献、影响和仓库动态。

Method: 结合软件仓库挖掘和数据驱动角色方法，对GitHub上中等规模（10-300名提交者）的公共研究软件仓库进行协作交互行为模式分析，从Zenodo查询的42,284个候选软件仓库记录中采样1,284个仓库。

Result: 成功识别并命名了7种从低到高互动性的不同角色：临时贡献者、偶尔贡献者、项目组织者、适度贡献者、低流程终结者、低编码终结者和活跃贡献者。

Conclusion: 该方法证明了大数据集分析的可能性，尽管存在项目管理因素、研究领域和贡献者背景的差异，但仍能有效识别研究软件工程中的协作模式。

Abstract: We describe data-driven RSE personas: an approach combining software
repository mining and data-driven personas applied to research software (RS),
an attempt to describe and identify common and rare patterns of Research
Software Engineering (RSE) development. This allows individuals and RS project
teams to understand their contributions, impact and repository dynamics - an
important foundation for improving RSE. We evaluate the method on different
patterns of collaborative interaction behaviours by contributors to mid-sized
public RS repositories (those with 10-300 committers) on GitHub. We demonstrate
how the RSE personas method successfully characterises a sample of 115,174
repository contributors across 1,284 RS repositories on GitHub, sampled from
42,284 candidate software repository records queried from Zenodo. We identify,
name and summarise seven distinct personas from low to high interactivity:
Ephemeral Contributor; Occasional Contributor; Project Organiser; Moderate
Contributor; Low-Process Closer; Low-Coding Closer; and Active Contributor.
This demonstrates that large datasets can be analysed despite difficulties of
comparing software projects with different project management factors, research
domains and contributor backgrounds.

</details>


### [9] [UnitTenX: Generating Tests for Legacy Packages with AI Agents Powered by Formal Verification](https://arxiv.org/abs/2510.05441)
*Yiannis Charalambous,Claudionor N. Coelho Jr,Luis Lamb,Lucas C. Cordeiro*

Main category: cs.SE

TL;DR: UnitTenX是一个开源的AI多智能体系统，专门为遗留代码生成单元测试，提高测试覆盖率和关键值测试能力。


<details>
  <summary>Details</summary>
Motivation: 解决复杂和遗留代码库中单元测试生成的挑战，提高软件可靠性和可维护性。

Method: 结合AI智能体、形式化方法和大型语言模型(LLMs)来自动化测试生成。

Result: 能够生成高质量测试并识别潜在问题，同时提高遗留代码的可读性和文档质量。

Conclusion: 尽管LLMs在错误检测方面存在局限性，但UnitTenX提供了一个强大的框架来改善软件测试过程。

Abstract: This paper introduces UnitTenX, a state-of-the-art open-source AI multi-agent
system designed to generate unit tests for legacy code, enhancing test coverage
and critical value testing. UnitTenX leverages a combination of AI agents,
formal methods, and Large Language Models (LLMs) to automate test generation,
addressing the challenges posed by complex and legacy codebases. Despite the
limitations of LLMs in bug detection, UnitTenX offers a robust framework for
improving software reliability and maintainability. Our results demonstrate the
effectiveness of this approach in generating high-quality tests and identifying
potential issues. Additionally, our approach enhances the readability and
documentation of legacy code.

</details>


### [10] [What Types of Code Review Comments Do Developers Most Frequently Resolve?](https://arxiv.org/abs/2510.05450)
*Saul Goldman,Hong Yi Lin,Jirat Pasuksmit,Patanamon Thongtanunam,Kla Tantithamthavorn,Zhe Wang,Ray Zhang,Ali Behnaz,Fan Jiang,Michael Siers,Ryan Jiang,Mike Buller,Minwoo Jeong,Ming Wu*

Main category: cs.SE

TL;DR: 研究LLM生成的代码审查评论中哪些类型最可能触发代码变更，发现可读性、bug和维护性相关的评论比代码设计相关的评论有更高的解决率。


<details>
  <summary>Details</summary>
Motivation: 理解LLM生成的代码审查评论中哪些类型最可能被开发者采纳和解决，以识别可操作的评论。

Method: 开发LLM-as-a-Judge自动分类评论，基于五类分类法进行实证研究。

Result: LLM和人类审查员在不同项目背景下各有优势；可读性、bug和维护性相关的评论解决率高于代码设计相关的评论。

Conclusion: 大部分LLM生成的评论是可操作的，LLM与人类审查员具有互补性，为改进LLM驱动的代码审查工具提供了建议。

Abstract: Large language model (LLM)-powered code review automation tools have been
introduced to generate code review comments. However, not all generated
comments will drive code changes. Understanding what types of generated review
comments are likely to trigger code changes is crucial for identifying those
that are actionable. In this paper, we set out to investigate (1) the types of
review comments written by humans and LLMs, and (2) the types of generated
comments that are most frequently resolved by developers. To do so, we
developed an LLM-as-a-Judge to automatically classify review comments based on
our own taxonomy of five categories. Our empirical study confirms that (1) the
LLM reviewer and human reviewers exhibit distinct strengths and weaknesses
depending on the project context, and (2) readability, bugs, and
maintainability-related comments had higher resolution rates than those focused
on code design. These results suggest that a substantial proportion of
LLM-generated comments are actionable and can be resolved by developers. Our
work highlights the complementarity between LLM and human reviewers and offers
suggestions to improve the practical effectiveness of LLM-powered code review
tools.

</details>


### [11] [An Empirical Study of Security-Policy Related Issues in Open Source Projects](https://arxiv.org/abs/2510.05604)
*Rintaro Kanaji,Brittany Reid,Yutaro Kashiwa,Raula Gaikovina Kula,Hajimu Iida*

Main category: cs.SE

TL;DR: 该研究分析了GitHub项目中SECURITY.md文件在漏洞报告过程中的有效性，发现79.5%的相关问题是添加文件的请求，包含链接的报告关闭时间中位数缩短2天。


<details>
  <summary>Details</summary>
Motivation: GitHub推荐项目采用SECURITY.md文件来规范漏洞报告流程，但这类文件的有效性和操作挑战尚未完全了解，需要研究其在开源社区漏洞报告过程中的实际挑战。

Method: 对711个随机抽样的SECURITY.md相关问题进行分类分析，并对包括SECURITY.md在内的6个社区健康文件相关问题的关闭时间和回复数量进行定量比较分析。

Result: 79.5%的SECURITY.md相关问题都是请求添加该文件，包含链接的报告关闭时间中位数缩短2天。

Conclusion: 研究结果为改进安全报告政策和社区管理提供了实用见解，有助于构建更安全的开源生态系统。

Abstract: GitHub recommends that projects adopt a SECURITY.md file that outlines
vulnerability reporting procedures. However, the effectiveness and operational
challenges of such files are not yet fully understood. This study aims to
clarify the challenges that SECURITY.md files face in the vulnerability
reporting process within open-source communities. Specifically, we classified
and analyzed the content of 711 randomly sampled issues related to SECURITY.md.
We also conducted a quantitative comparative analysis of the close time and
number of responses for issues concerning six community health files, including
SECURITY.md. Our analysis revealed that 79.5% of SECURITY.md-related issues
were requests to add the file, and reports that included links were closed,
with a median time that was 2 days shorter. These findings offer practical
insights for improving security reporting policies and community management,
ultimately contributing to a more secure open-source ecosystem.

</details>


### [12] [The Software Observatory: aggregating and analysing software metadata for trend computation and FAIR assessment](https://arxiv.org/abs/2510.05705)
*Eva Martín del Pico,Josep Lluís Gelpí,Salvador Capella-Gutiérrez*

Main category: cs.SE

TL;DR: Software Observatory是一个整合软件元数据的网络平台，用于分析生命科学研究软件生态系统的趋势和FAIR原则遵守情况。


<details>
  <summary>Details</summary>
Motivation: 在快速变化的研究软件开发领域，科学界需要了解当前趋势以识别可能阻碍科学进展的差距，FAIR原则可以作为理解这些趋势的代理指标。

Method: 通过OpenEBench的Software Observatory门户网站整合来自多个来源的软件元数据，提供不同粒度的可视化分析，并使用FAIRsoft评估器对研究软件进行FAIR原则评估。

Result: 该平台能够分析趋势、识别模式、评估软件FAIR程度，并为开发者提供改进指导。

Conclusion: Software Observatory是研究人员、软件开发者和利益相关者的宝贵资源，有助于促进更好的软件开发实践和FAIR原则的遵守。

Abstract: In the ever-changing realm of research software development, it is crucial
for the scientific community to grasp current trends to identify gaps that can
potentially hinder scientific progress. The adherence to the FAIR (Findable,
Accessible, Interoperable, Reusable) principles can serve as a proxy to
understand those trends and provide a mechanism to propose specific actions.
  The Software Observatory at OpenEBench
(https://openebench.bsc.es/observatory) is a novel web portal that consolidates
software metadata from various sources, offering comprehensive insights into
critical research software aspects. Our platform enables users to analyse
trends, identify patterns and advancements within the Life Sciences research
software ecosystem, and understand its evolution over time. It also evaluates
research software according to FAIR principles for research software, providing
scores for different indicators.
  Users have the ability to visualise this metadata at different levels of
granularity, ranging from the entire software landscape to specific communities
to individual software entries through the FAIRsoft Evaluator. Indeed, the
FAIRsoft Evaluator component streamlines the assessment process, helping
developers efficiently evaluate and obtain guidance to improve their software's
FAIRness.
  The Software Observatory represents a valuable resource for researchers and
software developers, as well as stakeholders, promoting better software
development practices and adherence to FAIR principles for research software.

</details>


### [13] [Digital Twins for Software Engineering Processes](https://arxiv.org/abs/2510.05768)
*Robin Kimmel,Judith Michael,Andreas Wortmann,Jingxi Zhang*

Main category: cs.SE

TL;DR: 本文提出利用数字孪生技术来更好地表示、理解和优化软件工程过程，以应对软件工程师短缺问题，帮助软件专家高效利用时间并支持领域专家开发高质量软件。


<details>
  <summary>Details</summary>
Motivation: 软件工程是一个复杂的多领域协作过程，面临熟练软件工程师短缺的挑战。数字孪生技术能够实时表示和控制系统，因此作者希望将其应用于软件工程过程，以改善流程理解和优化。

Method: 本文主要提出概念框架，探讨了软件工程数字孪生的可能形态，包括如何表示软件工程过程、与系统交互以控制流程，以及需要解决的关键技术问题。

Result: 论文提出了软件工程数字孪生的愿景框架，明确了其潜在益处，包括提升软件专家工作效率和支持领域专家开发高质量软件，但尚未提供具体实现或实证结果。

Conclusion: 软件工程数字孪生具有巨大潜力，但需要进一步研究解决实现和部署所需的技术挑战，包括如何有效建模软件工程过程、与现有工具集成等关键问题。

Abstract: Digital twins promise a better understanding and use of complex systems. To
this end, they represent these systems at their runtime and may interact with
them to control their processes. Software engineering is a wicked challenge in
which stakeholders from many domains collaborate to produce software artifacts
together. In the presence of skilled software engineer shortage, our vision is
to leverage DTs as means for better rep- resenting, understanding, and
optimizing software engineering processes to (i) enable software experts making
the best use of their time and (ii) support domain experts in producing
high-quality software. This paper outlines why this would be beneficial, what
such a digital twin could look like, and what is missing for realizing and
deploying software engineering digital twins.

</details>


### [14] [Mellum: Production-Grade in-IDE Contextual Code Completion with Multi-File Project Understanding](https://arxiv.org/abs/2510.05788)
*Nikita Pavlichenko,Iurii Nazarov,Ivan Dolgov,Ekaterina Garanina,Dmitry Ustalov,Ivan Bondyrev,Kseniia Lysaniuk,Evgeniia Vu,Kirill Chekmenev,Joseph Shtok,Yaroslav Golubev,Anton Semenkin,Uladzislau Sazanovich*

Main category: cs.SE

TL;DR: Mellum模型是专为JetBrains IDE设计的4B参数代码补全模型，采用多阶段训练方法，在4T多语言代码数据上预训练，满足交互式使用的成本和延迟要求。


<details>
  <summary>Details</summary>
Motivation: 为JetBrains IDE提供高质量的交互式代码补全功能，同时满足成本效益和低延迟的工业级部署需求。

Method: 采用端到端工业流水线，包括严格的数据治理、多阶段训练（包含中间填充和项目上下文监督微调），以及基于真实场景反馈的直接偏好优化对齐。

Result: 模型在离线基准测试和生产环境在线遥测中都表现出高质量，已成功部署到数十万用户的生产环境中。

Conclusion: Mellum模型提供了一个实用的蓝图，展示了如何将专注的开放模型从研究原型扩展到大规模生产部署。

Abstract: We present the Mellum models family, open-weight code completion models
designed for interactive use in JetBrains IDEs. Mellums have 4B parameters,
adopt a Llama-style architecture, and are pre-trained on ~4T tokens of
permissively licensed, multi-language code. Our studies show that (i) careful
data curation and staged training significantly improve the model's quality,
(ii) editor-critical capabilities such as context packing are necessary for
high-quality suggestions, and (iii) a compact, task-focused model can meet the
cost and latency constraints of interactive completion.
  In the paper, we describe an end-to-end industrial pipeline for producing
contextualized in-editor completion: disciplined data governance, multi-stage
training that includes fill-in-the-middle and project context via supervised
fine-tuning, and alignment via direct preference optimization using feedback
from real-world scenarios. Our quality evaluations include both large-scale
offline benchmarks and online telemetry from production deployments in
JetBrains IDEs. Mellums are released under the Apache-2.0 license on
HuggingFace, with a public model card providing a reproducible reference for
practitioners. Our experience offers a pragmatic blueprint for taking a
focused, open model from a research prototype to at scale production for
hundreds of thousands of users.

</details>


### [15] [A Wave of Resignations in the Aftermath of Remote Onboarding](https://arxiv.org/abs/2510.05878)
*Darja Smite,Franz Zieris,Lars-Ola Damm*

Main category: cs.SE

TL;DR: 该研究分析了爱立信公司在疫情前后的员工离职模式，发现远程入职显著增加了员工在头三年内的离职率，而成功的混合工作模式需要确保新员工与团队成员共同在办公室工作以建立组织归属感。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情永久改变了工作结构，但完全远程工作对软件团队存在挑战。本研究旨在调查不同工作模式（现场、远程、混合）对员工保留的影响。

Method: 使用爱立信瑞典公司2016-2025年的人力资源数据，分析疫情前、期间和后的员工离职模式，特别关注不同工作模式下的保留率。

Result: 研究发现2021年夏季至2023年夏季离职率显著上升，尤其是工龄少于5年的员工。疫情期间远程入职的员工在头三年内离职可能性显著更高，即使返回办公室后。成功的混合模式需要新员工与团队成员共同在场。

Conclusion: 精心设计的混合工作模式，基于组织归属感和导师制，能够维持知识密集型公司的员工保留。新员工需要与团队成员共同在办公室工作以获得更好的整合。

Abstract: The COVID-19 pandemic has permanently altered workplace structures,
normalizing remote work. However, critical evidence highlights challenges with
fully remote arrangements, particularly for software teams. This study
investigates employee resignation patterns at Ericsson, a global developer of
software-intensive systems, before, during, and after the pandemic. Using HR
data from 2016-2025 in Ericsson Sweden, we analyze how different work
modalities (onsite, remote, and hybrid) influence employee retention. Our
findings show a marked increase in resignations from summer 2021 to summer
2023, especially among employees with less than five years of tenure. Employees
onboarded remotely during the pandemic were significantly more likely to resign
within their first three years, even after returning to the office. Exit
surveys suggest that remote onboarding may fail to establish the necessary
organizational attachment, the feeling of belonging and long-term retention. By
contrast, the company's eventual successful return to pre-pandemic retention
rates illustrates the value of differentiated work policies and supports
reconsidering selective return-to-office (RTO) mandates. Our study demonstrates
the importance of employee integration practices in hybrid environments where
the requirement for in-office presence for recent hires shall be accompanied by
in-office presence from their team members and more senior staff whose
mentoring and social interactions contribute to integration into the corporate
work environment. We hope these actionable insights will inform HR leaders and
policymakers in shaping post-pandemic work practices, demonstrating that
carefully crafted hybrid models anchored in organizational attachment and
mentorship can sustain retention in knowledge-intensive companies.

</details>


### [16] [Extending ResourceLink: Patterns for Large Dataset Processing in MCP Applications](https://arxiv.org/abs/2510.05968)
*Scott Frees*

Main category: cs.SE

TL;DR: 提出了构建LLM驱动的报表系统的模式，通过分离查询生成和数据检索来解决上下文窗口限制问题，扩展ResourceLink支持迭代查询优化和带外数据访问。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能将自然语言转换为数据库查询，但在报表系统中完整数据集会耗尽可用token，上下文窗口限制阻碍了直接部署。Model Context Protocol定义了ResourceLink但缺乏可扩展报表架构的实现模式。

Method: 引入双响应模式扩展ResourceLink，支持迭代查询优化和带外数据访问，同时提供多租户安全和资源生命周期管理模式。

Result: 开发了解决LLM驱动报表应用基本挑战的实用模式，为开发者提供构建此类系统的实践指导。

Conclusion: 这些模式解决了LLM驱动报表应用中的基本挑战，为构建可扩展报表系统提供了实用的架构指导。

Abstract: Large language models translate natural language into database queries, yet
context window limitations prevent direct deployment in reporting systems where
complete datasets exhaust available tokens. The Model Context Protocol
specification defines ResourceLink for referencing external resources, but
practical patterns for implementing scalable reporting architectures remain
undocumented. This paper presents patterns for building LLM-powered reporting
systems that decouple query generation from data retrieval. We introduce a
dual-response pattern extending ResourceLink to support both iterative query
refinement and out-of-band data access, accompanied by patterns for
multi-tenant security and resource lifecycle management. These patterns address
fundamental challenges in LLM-driven reporting applications and provide
practical guidance for developers building them.

</details>


### [17] [Prompting in Practice: Investigating Software Developers' Use of Generative AI Tools](https://arxiv.org/abs/2510.06000)
*Daniel Otten,Trevor Stalnaker,Nathan Wintersgill,Oscar Chaparro,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 该研究通过调查91名软件工程师，系统分析了GenAI工具在软件开发中的实际应用模式，发现代码生成普遍但熟练度与复杂任务使用相关，开发者偏好多轮对话，文档任务最可靠。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注个别提示工程技术，而非开发者的完整工作流程，需要系统了解软件工程师如何将GenAI工具整合到专业实践中。

Method: 通过大规模调查91名软件工程师（其中72名活跃GenAI用户），分析提示策略、对话模式和可靠性评估在不同软件工程任务中的应用。

Result: 14个关键发现显示：代码生成几乎普遍，熟练度与调试和代码审查等复杂任务使用强相关；开发者偏好迭代式多轮对话而非单次提示；文档任务被认为最可靠，复杂代码生成和调试面临挑战。

Conclusion: 研究为当前开发者实践提供了经验基准，从简单代码生成到深度工作流程整合，为未来改进提供了可行见解。

Abstract: The integration of generative artificial intelligence (GenAI) tools has
fundamentally transformed software development. Although prompt engineering has
emerged as a critical skill, existing research focuses primarily on individual
techniques rather than software developers' broader workflows. This study
presents a systematic investigation of how software engineers integrate GenAI
tools into their professional practice through a large-scale survey examining
prompting strategies, conversation patterns, and reliability assessments across
various software engineering tasks.
  We surveyed 91 software engineers, including 72 active GenAI users, to
understand AI usage patterns throughout the development process. Our 14 key
findings show that while code generation is nearly universal, proficiency
strongly correlates with using AI for more nuanced tasks such as debugging and
code review, and that developers prefer iterative multi-turn conversations to
single-shot prompting. Documentation tasks are perceived as most reliable,
while complex code generation and debugging present sizable challenges. Our
insights provide an empirical baseline of current developer practices, from
simple code generation to deeper workflow integration, with actionable insights
for future improvements.

</details>


### [18] [Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations](https://arxiv.org/abs/2510.06104)
*Elijah Kayode Adejumo,Brittany Johnson*

Main category: cs.SE

TL;DR: 该研究探讨使用大语言模型将静态分析工具生成的故障预测指标转化为清晰、可读的风险解释和行动指导，以帮助开源软件贡献者更好地理解和修改代码。


<details>
  <summary>Details</summary>
Motivation: 开源软件贡献者（特别是新手）难以理解静态分析工具生成的复杂指标，需要将这些技术指标转化为易于理解的风险解释和行动指导。

Method: 提出使用大语言模型将故障预测指标转化为三类解释：描述性解释、上下文解释和可操作解释，并通过任务研究评估其有效性。

Result: 研究处于规划阶段，提出了LLM生成解释的方法框架，下一步将通过实证研究评估其效果。

Conclusion: 大语言模型有潜力将技术性的故障预测指标转化为对开源软件贡献者有用的风险解释和指导，从而提高代码修改的质量和效率。

Abstract: Open Source Software (OSS) has become a very important and crucial
infrastructure worldwide because of the value it provides. OSS typically
depends on contributions from developers across diverse backgrounds and levels
of experience. Making safe changes, such as fixing a bug or implementing a new
feature, can be challenging, especially in object-oriented systems where
components are interdependent. Static analysis and defect-prediction tools
produce metrics (e.g., complexity,coupling) that flag potentially fault-prone
components, but these signals are often hard for contributors new or unfamiliar
with the codebase to interpret. Large Language Models (LLMs) have shown strong
performance on software engineering tasks such as code summarization and
documentation generation. Building on this progress, we investigate whether
LLMs can translate fault-prediction metrics into clear, human-readable risk
explanations and actionable guidance to help OSS contributors plan and review
code modifications. We outline explanation types that an LLM-generated
assistant could provide (descriptive, contextual, and actionable explanations).
We also outline our next steps to assess usefulness through a task-based study
with OSS contributors, comparing metric-only baselines to LLM-generated
explanations on decision quality, time-to-completion, and error rates

</details>


### [19] [Automated Program Repair of Uncompilable Student Code](https://arxiv.org/abs/2510.06187)
*Griffin Pitts,Aum Pandya,Darsh Rank,Tirth Bhatt,Muntasir Hoq,Bita Akram*

Main category: cs.SE

TL;DR: 使用大型语言模型自动修复CS1课程中无法编译的学生代码，以保留学生结构意图并用于学生建模。


<details>
  <summary>Details</summary>
Motivation: CS1学习环境中大量学生编程提交无法编译，限制了其在学生建模和知识追踪中的应用，传统建模流程往往排除这些案例，丢失了学生学习观察。

Method: 评估GPT-5、Claude 3.5 Haiku和Gemini 2.5 Flash等LLM在高、低上下文提示条件下作为修复代理的能力，通过编译性、编辑距离、结构保留等指标评估修复效果。

Result: 所有三个LLM都能产生可编译的修复，但在保留学生控制流和代码结构方面表现不同，影响其教学效用。

Conclusion: 通过修复无法编译的提交，这项工作能够对学习者的编码过程和随时间发展进行更丰富全面的分析。

Abstract: A significant portion of student programming submissions in CS1 learning
environments are uncompilable, limiting their use in student modeling and
downstream knowledge tracing. Traditional modeling pipelines often exclude
these cases, discarding observations of student learning. This study
investigates automated program repair as a strategy to recover uncompilable
code while preserving students' structural intent for use in student modeling.
Within this framework, we assess large language models (LLMs) as repair agents,
including GPT-5 (OpenAI), Claude 3.5 Haiku (Anthropic), and Gemini 2.5 Flash
(Google), under high- and low-context prompting conditions. Repairs were
evaluated for compilability, edit distance, and preservation of students'
original structure and logic. We find that while all three LLMs are capable of
producing compilable repairs, their behavior diverges in how well they preserve
students' control flow and code structure, which affects their pedagogical
utility. By recovering uncompilable submissions, this work enables richer and
more comprehensive analyses of learners' coding processes and development over
time.

</details>
