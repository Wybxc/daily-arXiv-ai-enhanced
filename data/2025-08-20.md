<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.LO](#cs.LO) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Reactive Semantics for User Interface Description Languages](https://arxiv.org/abs/2508.13610)
*Basile Pesin,Celia Picard,Cyril Allignol*

Main category: cs.PL

TL;DR: 本文提出了一种用于核心反应式用户界面描述语言Smalite的记号语义模型，以支持形式化验证和编译器验证


<details>
  <summary>Details</summary>
Motivation: 虽然用户界面描述语言(UIDL)已广泛用于安全关键GUI开发，但少有工作注重其形式化和验证

Method: 为核心反应式UIDL语言Smalite建立记号语义模型，该语言足够表达更实际语言的构造

Result: 提出的语义模型为形式验证提供了基础

Conclusion: 这项预研究工作可作为开发形式验证的UIDL编译器的基础

Abstract: User Interface Description Languages (UIDLs) are high-level languages that
facilitate the development of Human-Machine Interfaces, such as Graphical User
Interface (GUI) applications. They usually provide first-class primitives to
specify how the program reacts to an external event (user input, network
message), and how data flows through the program. Although these
domain-specific languages are now widely used to implement safety-critical
GUIs, little work has been invested in their formalization and verification.
  In this paper, we propose a denotational semantic model for a core reactive
UIDL, Smalite, which we argue is expressive enough to encode constructs from
more realistic languages. This preliminary work may be used as a stepping stone
to produce a formally verified compiler for UIDLs.

</details>


### [2] [Bisimilarity and Simulatability of Processes Parameterized by Join Interactions](https://arxiv.org/abs/2508.13611)
*Clemens Grabmayer,Maurizio Murgia*

Main category: cs.PL

TL;DR: 本文提出了ji-parameterized bisimilarity作为Larsen参数化互模拟的自然弱化版本，通过连接交互过程来比较进程在环境中的行为等价性


<details>
  <summary>Details</summary>
Motivation: 从Larsen的参数化互模拟概念出发，探索其在无限制连接交互环境下的自然弱化形式，研究进程与环境交互的等价关系

Method: 定义连接交互过程p & e和q & e的互模拟关系，通过'确定性化'交互来恢复Larsen的概念，并扩展到模拟关系(ji-parameterized simulatability)

Result: ji-parameterized bisimilarity在确定性环境下与参数化互模拟一致，但在一般情况下是更粗的等价关系；参数化模拟与ji-参数化模拟完全一致；获得了环境区分预序的相同结果；给出了模态逻辑特征化

Conclusion: ji-parameterized bisimilarity是参数化互模拟的有意义弱化，在模拟关系层面两者完全一致，为进程与环境交互的等价性研究提供了新的理论框架

Abstract: Departing from Larsen's concept of parameterized bisimilarity of processes
with respect to interaction with environments, we start an exploration of its
natural weakening: bisimilarity of unrestricted join interactions with
environments. Parameterized bisimilarity relates processes p and q with respect
to an environment e if p and q behave bi-similarly while joining --
respectively the same -- transitions from e. The weakened variant relates
processes p and q with respect to environment e if the join-interaction
processes p & e and q & e of p and q with e are bisimilar. (Hereby join
interactions r & f facilitate a step with label a to r' & f' if and only if r
and f permit a-steps to r' and f' , respectively.) Join-interaction
parameterized (ji-parameterized) bisimilarity coincides with parameterized
bisimilarity for deterministic environments, but that it is a coarser
equivalence in general. We explain how Larsen's concept can be recovered from
ji-parameterized bisimilarity by 'determinizing' interactions. We show that by
adaptation to simulatability (simulation preorder) the same concept arises:
parameterized simulatability coincides with ji-parameterized simulatability.
For the discrimination preorder of (ji-)parameterized simulatability on
environments we obtain the same result as Larsen did for parameterized
bisimilarity. Also, we give a modal-logic characterization of
(ji-)parameterized simulatability. Finally we gather open problems, and provide
an outlook on our current related work.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [A Comparative Study of Delta Parquet, Iceberg, and Hudi for Automotive Data Engineering Use Cases](https://arxiv.org/abs/2508.13396)
*Dinesh Eswararaj,Ajay Babu Nellipudi,Vandana Kollati*

Main category: cs.SE

TL;DR: 这篇论文对汽车行业的三种主流数据湖仓格式(Delta Parquet、Apache Iceberg、Apache Hudi)进行了实际性能比较分析，为汽车数据管理提供了选型指南


<details>
  <summary>Details</summary>
Motivation: 汽车行业产生大量传感器数据，需要高效数据工程处理解决延迟、可扩展性和一致性挑战

Method: 使用真实世界时间序列汽车远程测量数据，评估模型策略、分区、CDC支持、查询性能、可扩展性等指标

Result: Delta Parquet在ML准备和数据管理方面显著，Iceberg在批处理分析和云原生工作负载上表现优异，Hudi优化了实时数据吸收和增量处理

Conclusion: 不同数据湖仓格式各有优势，需根据具体应用场景选择或组合使用，以支持车队管理、预测性维护等汽车应用

Abstract: The automotive industry generates vast amounts of data from sensors,
telemetry, diagnostics, and real-time operations. Efficient data engineering is
critical to handle challenges of latency, scalability, and consistency. Modern
data lakehouse formats Delta Parquet, Apache Iceberg, and Apache Hudi offer
features such as ACID transactions, schema enforcement, and real-time
ingestion, combining the strengths of data lakes and warehouses to support
complex use cases. This study presents a comparative analysis of Delta Parquet,
Iceberg, and Hudi using real-world time-series automotive telemetry data with
fields such as vehicle ID, timestamp, location, and event metrics. The
evaluation considers modeling strategies, partitioning, CDC support, query
performance, scalability, data consistency, and ecosystem maturity. Key
findings show Delta Parquet provides strong ML readiness and governance,
Iceberg delivers high performance for batch analytics and cloud-native
workloads, while Hudi is optimized for real-time ingestion and incremental
processing. Each format exhibits tradeoffs in query efficiency, time-travel,
and update semantics. The study offers insights for selecting or combining
formats to support fleet management, predictive maintenance, and route
optimization. Using structured datasets and realistic queries, the results
provide practical guidance for scaling data pipelines and integrating machine
learning models in automotive applications.

</details>


### [4] [The Hidden Cost of Readability: How Code Formatting Silently Consumes Your LLM Budget](https://arxiv.org/abs/2508.13666)
*Dangfeng Pan,Zhensu Sun,Cenyuan Zhang,David Lo,Xiaoning Du*

Main category: cs.SE

TL;DR: 代码格式化元素如缩进和换行对LLMs并无实质帮助，去除后可减少24.5%输入token而保持性能，是一种有效的LLM优化策略


<details>
  <summary>Details</summary>
Motivation: 代码格式化元素主要服务于人类可读性，但对LLMs处理代码作为线性token序列时可能会增加计算成本和响应时间，需要研究这些格式元素的实际作用

Method: 通过在四种编程语言(Java、Python、C++、C#)和十个LLMs上进行大规模的Fill-in-the-Middle代码完成任务实验，系统分析格式化元素移除后的token数量和性能变化

Result: LLMs在格式化代码和非格式化代码上都能保持相似性能，平均减少24.5%输入token而输出token减少可忽略；通过提示和微调还可以进一步减少36.1%的输出代码长度

Conclusion: 代码格式移除是一种实用的LLM效率优化策略，研究还发展了双向代码转换工具，能够无缝集成到现有LLM推理流程中，同时保证人类可读性和LLM效率

Abstract: Source code is usually formatted with elements like indentation and newlines
to improve readability for human developers. However, these visual aids do not
seem to be beneficial for large language models (LLMs) in the same way since
the code is processed as a linear sequence of tokens. Furthermore, these
additional tokens can lead to increased computational costs and longer response
times for LLMs. If such formatting elements are non-essential to LLMs, we can
reduce such costs by removing them from the code. To figure out the role played
by formatting elements, we conduct a comprehensive empirical study to evaluate
the impact of code formatting on LLM performance and efficiency. Through
large-scale experiments on Fill-in-the-Middle Code Completion tasks across four
programming languages (Java, Python, C++, C\#) and ten LLMs-including both
commercial and open-source models-we systematically analyze token count and
performance when formatting elements are removed. Key findings indicate that
LLMs can maintain performance across formatted code and unformatted code,
achieving an average input token reduction of 24.5\% with negligible output
token reductions. This makes code format removal a practical optimization
strategy for improving LLM efficiency. Further exploration reveals that both
prompting and fine-tuning LLMs can lead to significant reductions (up to
36.1\%) in output code length without compromising correctness. To facilitate
practical applications, we develop a bidirectional code transformation tool for
format processing, which can be seamlessly integrated into existing LLM
inference workflows, ensuring both human readability and LLM efficiency.

</details>


### [5] [COMPASS: A Multi-Dimensional Benchmark for Evaluating Code Generation in Large Language Models](https://arxiv.org/abs/2508.13757)
*James Meaden,Michał Jarosz,Piotr Jodłowski,Grigori Melnik*

Main category: cs.SE

TL;DR: COMPASS是一个多维代码生成评估框架，不仅评估功能正确性，还评估算法效率和代码质量，发现当前模型在正确性得分高时不一定能产生高效算法或可维护代码。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准主要关注功能正确性，忽略了真实编程中算法效率和代码质量这两个关键方面，需要更全面的评估框架。

Method: 使用50个来自真实Codility竞赛的编程问题，收集393,150份人工提交作为基线，使用行业标准分析工具系统评估运行时效率和代码质量。

Result: 对三个领先推理增强模型（Claude Opus 4、Gemini 2.5 Pro、O4-Mini-High）的评估显示，高正确性得分的模型不一定能产生高效算法或可维护代码。

Conclusion: 仅评估正确性不足以真正理解代码生成模型的真实能力，需要多维评估来推动AI系统向健壮、可靠、生产就绪的方向发展。

Abstract: Current code generation benchmarks focus primarily on functional correctness
while overlooking two critical aspects of real-world programming: algorithmic
efficiency and code quality. We introduce COMPASS (COdility's Multi-dimensional
Programming ASSessment), a comprehensive evaluation framework that assesses
code generation across three dimensions: correctness, efficiency, and quality.
COMPASS consists of 50 competitive programming problems from real Codility
competitions, providing authentic human baselines from 393,150 submissions.
Unlike existing benchmarks that treat algorithmically inefficient solutions
identically to optimal ones provided they pass test cases, COMPASS
systematically evaluates runtime efficiency and code quality using
industry-standard analysis tools. Our evaluation of three leading
reasoning-enhanced models, Anthropic Claude Opus 4, Google Gemini 2.5 Pro, and
OpenAI O4-Mini-High, reveals that models achieving high correctness scores do
not necessarily produce efficient algorithms or maintainable code. These
findings highlight the importance of evaluating more than just correctness to
truly understand the real-world capabilities of code generation models. COMPASS
serves as a guiding framework, charting a path for future research toward AI
systems that are robust, reliable, and ready for production use.

</details>


### [6] [Agentic DraCor and the Art of Docstring Engineering: Evaluating MCP-empowered LLM Usage of the DraCor API](https://arxiv.org/abs/2508.13774)
*Peer Trilcke,Ingo Börner,Henny Sluyter-Gäthje,Daniil Skorinkin,Frank Fischer,Carsten Milling*

Main category: cs.SE

TL;DR: 通过实现和评估一个为DraCor的MCP服务器，让LLM能够自主与DraCor API交互，并通过定性实验分析了LLM在使用MCP工具时的行为特征和性能指标。


<details>
  <summary>Details</summary>
Motivation: 探索以代理为中心的AI在计算文学研究中的应用潜力，以及为可靠的数字人文科学基础设施提供必要的技术支撑。

Method: 实现DraCor的MCP服务器，进行实验重点关注工具选择和应用，采用定性方法包括系统观察prompt行为，评估工具正确性、工具调用效率和工具使用可靠性。

Result: 发现文档工程（Docstring Engineering）对优化LLM-工具交互至关重要，实验证明以代理为中心的AI在计算文学研究中具有应用前景。

Conclusion: 以代理为中心的AI为计算文学研究带来了希望，同时强调了为可靠数字人文基础设施进行基础设施开发的必要性。

Abstract: This paper reports on the implementation and evaluation of a Model Context
Protocol (MCP) server for DraCor, enabling Large Language Models (LLM) to
autonomously interact with the DraCor API. We conducted experiments focusing on
tool selection and application by the LLM, employing a qualitative approach
that includes systematic observation of prompts to understand how LLMs behave
when using MCP tools, evaluating "Tool Correctness", "Tool-Calling Efficiency",
and "Tool-Use Reliability". Our findings highlight the importance of "Docstring
Engineering", defined as reflexively crafting tool documentation to optimize
LLM-tool interaction. Our experiments demonstrate both the promise of agentic
AI for research in Computational Literary Studies and the essential
infrastructure development needs for reliable Digital Humanities
infrastructures.

</details>


### [7] [Structural and Connectivity Patterns in the Maven Central Software Dependency Network](https://arxiv.org/abs/2508.13819)
*Daniel Ogenrwot,John Businge,Shaikh Arifuzzaman*

Main category: cs.SE

TL;DR: 通过网络科学技术分析Maven Central依赖图，发现其具有尺度自由的小世界拨扬特征，由少数核心库支撑整个生态系统，同时带来系统性风险。


<details>
  <summary>Details</summary>
Motivation: 理解大规模软件生态系统的结构特征和连接模式，以提高软件重用性、增强生态系统弹性和减少安全风险。

Method: 使用Goblin框架提取Maven Central中基于度中心性的前5000个高连接库，通过广度优先搜索扩展获得130万个节点和2090万条边的依赖图，计算度分布、中间中心性、PageRank中心性等图论指标。

Result: 发现Maven Central呈现高度互联的尺度自由小世界拨扬，由少数基础设施中心节点支撑大部分项目，这些核心节点主要是测试框架和通用库。

Conclusion: 核心中心节点虽然提高了软件重用效率，但也带来系统性风险，关键节点的故障或漏洞可能导致全局性的潜在影响。

Abstract: Understanding the structural characteristics and connectivity patterns of
large-scale software ecosystems is critical for enhancing software reuse,
improving ecosystem resilience, and mitigating security risks. In this paper,
we investigate the Maven Central ecosystem, one of the largest repositories of
Java libraries, by applying network science techniques to its dependency graph.
Leveraging the Goblin framework, we extracted a sample consisting of the top
5,000 highly connected artifacts based on their degree centrality and then
performed breadth-first search (BFS) expansion from each selected artifact as a
seed node, traversing the graph outward to capture all libraries and releases
reachable those seed nodes. This sampling strategy captured the immediate
structural context surrounding these libraries resulted in a curated graph
comprising of 1.3 million nodes and 20.9 million edges. We conducted a
comprehensive analysis of this graph, computing degree distributions,
betweenness centrality, PageRank centrality, and connected components
graph-theoretic metrics. Our results reveal that Maven Central exhibits a
highly interconnected, scale-free, and small-world topology, characterized by a
small number of infrastructural hubs that support the majority of projects.
Further analysis using PageRank and betweenness centrality shows that these
hubs predominantly consist of core ecosystem infrastructure, including testing
frameworks and general-purpose utility libraries. While these hubs facilitate
efficient software reuse and integration, they also pose systemic risks;
failures or vulnerabilities affecting these critical nodes can have widespread
and cascading impacts throughout the ecosystem.

</details>


### [8] [Tight Inter-Core Cache Contention Analysis for WCET Estimation on Multicore Systems](https://arxiv.org/abs/2508.13863)
*Shuai Zhao,Jieyu Jiang,Shenlin Cai,Yaowei Liang,Chen Jie,Yinjie Fang,Wei Zhang,Guoquan Zhang,Yaoyao Gu,Xiang Xiao,Wei Qin,Xiangzhen Ouyang,Wanli Chang*

Main category: cs.SE

TL;DR: 基于程序区域顺序的细粒度竞争分析，通过动态规划计算缓存失效数量，显著降低多核缓存干扰和WCET估计


<details>
  <summary>Details</summary>
Motivation: 现有多核WCET估计方法在评估缓存失效时过于简化，没有考虑实际缓存状态和访问次数，导致估计过高

Method: 首先识别可能受远程访问影响的内存引用，然后构建细粒度竞争分析模型，基于本地和远程块的访问数量计算缓存失效数量，通过动态规划求解整体干扰

Result: 实验结果显示，与现有方法相比，竞争干扰降低52.31%，WCET估计降低8.94%，计算开销没有显著增加

Conclusion: 该方法通过更精确的缓存状态和访问数量模型，有效减少多核缓存干扰过估计，提高了WCET分析的准确性

Abstract: WCET (Worst-Case Execution Time) estimation on multicore architecture is
particularly challenging mainly due to the complex accesses over cache shared
by multiple cores. Existing analysis identifies possible contentions between
parallel tasks by leveraging the partial order of the tasks or their program
regions. Unfortunately, they overestimate the number of cache misses caused by
a remote block access without considering the actual cache state and the number
of accesses. This paper reports a new analysis for inter-core cache contention.
Based on the order of program regions in a task, we first identify memory
references that could be affected if a remote access occurs in a region.
Afterwards, a fine-grained contention analysis is constructed that computes the
number of cache misses based on the access quantity of local and remote blocks.
We demonstrate that the overall inter-core cache interference of a task can be
obtained via dynamic programming. Experiments show that compared to existing
methods, the proposed analysis reduces inter-core cache interference and WCET
estimations by 52.31% and 8.94% on average, without significantly increasing
computation overhead.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Arithmetics within the Linear Time Hierarchy](https://arxiv.org/abs/2508.13195)
*Chris Pollett*

Main category: cs.LO

TL;DR: 该论文研究了算术理论S₁的片段，定义了新的语法类和算术理论(Ŝ₁ⁱ, TLS₁ⁱ, TSC₁ⁱ)，证明了它们之间的包含关系和可定义多函数特征，并获得了与MRDP定理相关的独立性结果。


<details>
  <summary>Details</summary>
Motivation: 研究S₁算术理论的片段，探索具有良好闭包性质的可定义多函数特征，建立不同复杂度类与逻辑理论之间的对应关系。

Method: 在S₁语言中，从忽略尖锐有界量词的Σᵇᵢ公式类出发，通过计数有界存在尖锐有界全称量词块来定义新的语法类，进而构建新的算术理论并证明它们之间的关系。

Result: 证明了TLS₁ⁱ ⊆ TSC₁ⁱ ⊆ Ŝ₁ⁱ ≼ TLS₁ⁱ⁺¹，并精确刻画了在这些理论中可定义的多函数类对应于具有特定见证预言机的对数空间或SC可计算函数。

Conclusion: 成功建立了算术理论与计算复杂度类之间的精确对应关系，为理解不同复杂度类在逻辑理论中的可定义性提供了新的理论框架，并获得了重要的独立性结果。

Abstract: We identify fragments of the arithmetic $S_1$ that enjoy nice closure
properties and have exact characterization of their definable multifunctions.
To do this, in the language of $S_1$, $L_1$, starting from the formula classes,
$\Sigma^{\mathsf b}_{i}$, which ignore sharply bounded quantifiers when
determining quantifier alternations, we define new syntactic classes by
counting bounded existential sharply bounded universal quantifiers blocks.
Using these, we define arithmetics: $\breve{S}^{i}_{1}$, $TLS^i_1$ and
$TSC^i_1$. $\breve{S}^{i}_{1}$ consists of open axioms for the language symbols
and length induction for one of our new classes, $SIUT_{i,1}^{\{p(|id|)\}}$.
$TLS^i_1$ and $TSC^i_1$ are defined using axioms related to dependent choice
sequences for formulas from two other classes within $\Sigma^{\mathsf b}_{i}$.
We prove for $i \geq 1$ that $$TLS^i_1 \subseteq TSC^i_1 \subseteq
\breve{S}^{i}_{1} \preceq_{\forall B(SITT_{i+1}^{\{p(|id|)\}})} TLS^{i+1}_1$$
and that the $SITT_{i}^{\{p(|id|)\}}$-definable in $TLS^i_1$ (resp.
$SITT_{i}^{\{2^{p(||id||)}\}}$-definable in $TSC^i_1$) multifunctions are
$L_1$-$FLOGSPACE^{SIT_{i,1}}[wit]$ (resp. $L_1$-$FSC^{SIT_{i,1}}[wit]$). These
multifunction classes are respectively the logspace or $SC$ (poly-time,
polylog-space) computable multifunctions whose output is bound by a term in
$L_1$ and that have access to a witness oracle for another restriction on the
$\Sigma^{\mathsf b}_{i}$ formulas, $SIT_{i,1}$. For the $i=1$ cases, this
simplifies respectively to the functions in logspace and $SC$, Steve's Class,
poly-time, polylog-space. We prove independence results related to the
Matiyasevich Robinson Davis Putnam Theorem (MRDP) and to whether our theories
prove simultaneous nondeterministic polynomial time, sublinear space is equal
to co-nondeterministic polynomial time, sublinear space.

</details>


### [10] [A Formalization of the Reversible Concurrent Calculus CCSKP in Beluga](https://arxiv.org/abs/2508.13612)
*Gabriele Cecilia*

Main category: cs.LO

TL;DR: 首个Beluga形式化的可逆并发计算模型CCSKP，包括语法、语义和证明标签关系的机器检查验证


<details>
  <summary>Details</summary>
Motivation: 虽然可逆并发计算模型开发多年，但无一在证明助手中实现机器检查验证，需要完善的形式化基础

Method: 使用Beluga证明助手对CCSKP计算模型进行形式化，包括语法、操作语义和证明标签的依赖、独立、连通性关系

Result: 实现了首个机器检查的可逆并发计算形式化，更清晰地揭示事件因果性和并发性，对原非形式证明进行了调整和补充

Conclusion: 为未来可逆并发计算模型的形式化研究奠定了基础，显示了形式化过程中的挑战和价值

Abstract: Reversible concurrent calculi are abstract models for concurrent systems in
which any action can potentially be undone. Over the last few decades,
different formalisms have been developed and their mathematical properties have
been explored; however, none have been machine-checked within a proof
assistant. This paper presents the first Beluga formalization of the Calculus
of Communicating Systems with Keys and Proof labels (CCSKP), a reversible
extension of CCS. Beyond the syntax and semantics of the calculus, the encoding
covers state-of-the-art results regarding three relations over proof labels --
namely, dependence, independence and connectivity -- which offer new insights
into the notions of causality and concurrency of events. As is often the case
with formalizations, our encoding introduces adjustments to the informal proof
and makes explicit details which were previously only sketched, some of which
reveal to be less straightforward than initially assumed. We believe this work
lays the foundations for future reversible concurrent calculi formalizations.

</details>


### [11] [Modular Multiparty Sessions with Mixed Choice](https://arxiv.org/abs/2508.13616)
*Franco Barbanera,Mariangiola Dezani-Ciancaglini*

Main category: cs.LO

TL;DR: 该论文提出了一种基于多参与方会话类型(MPST)的类型分配方法，通过模块化会话和混合选择来增强并发系统的安全性和表达能力


<details>
  <summary>Details</summary>
Motivation: 混合选择(mixed choice)虽然能增强MPST的表达能力，但也增加了通信安全的控制难度。需要在模块化系统中更好地控制安全性，并充分利用混合选择的优势

Method: 采用类型分配方法处理多参与方会话，将混合选择完全限制在松散耦合的模块内部使用

Result: 模块化会话的类型化确保了主题归约(Subject Reduction)、会话保真度(Session Fidelity)和无锁自由(Lock Freedom)等安全属性

Conclusion: 通过模块化设计和类型系统约束，可以在保持MPST表达能力的同时确保并发通信的安全性

Abstract: MultiParty Session Types (MPST) provide a useful framework for safe
concurrent systems. Mixed choice (enabling a participant to play at the same
time the roles of sender and receiver) increases the expressive power of MPST
as well as the difficulty in controlling safety of communications. Such a
control is more viable when modular systems are considered and the power of
mixed choice fully exploited only inside loosely coupled modules. We carry over
such idea in a type assignment approach to multiparty sessions. Typability for
modular sessions entails Subject Reductions, Session Fidelity and Lock Freedom.

</details>


### [12] [On a Second-Order Version of Russellian Theory of Definite Descriptions](https://arxiv.org/abs/2508.13928)
*Yaroslav Petrukhin*

Main category: cs.LO

TL;DR: 提出二阶定指描述理论，用于指代对象间的唯一关系，在Henkin广义模型框架下建立形式化系统


<details>
  <summary>Details</summary>
Motivation: 扩展罗素的定指描述理论到二阶逻辑，处理关系唯一性的指代问题

Method: 在Henkin广义模型框架下构建理论，使用无切割序列演算进行形式化

Result: 建立了二阶定指描述的形式化理论框架

Conclusion: 成功将定指描述概念扩展到二阶逻辑关系领域

Abstract: Definite descriptions are first-order expressions that denote unique objects.
In this paper, we propose a second-order counterpart, designed to refer to
unique relations between objects. We investigate this notion within the
framework of Russell's theory of definite descriptions. While full second-order
logic is incomplete, its fragment defined by Henkin's general models admits
completeness. We develop our theory within this fragment and formalize it using
a cut-free sequent calculus.

</details>
