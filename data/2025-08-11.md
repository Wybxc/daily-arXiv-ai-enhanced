<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Hybrid Game Control Envelope Synthesis](https://arxiv.org/abs/2508.05997)
*Aditi Kabra,Jonathan Laurent,Stefan Mitsch,André Platzer*

Main category: cs.PL

TL;DR: 本文提出了一种合成混合游戏中尽可能宽松的非确定性获胜策略的方法，引入了子值映射作为策略的组成表示，并通过微分博弈逻辑（dGL）验证其正确性。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统（如汽车和火车）的控制问题可以建模为双人混合游戏，需要找到安全的控制解决方案。

Method: 使用子值映射作为策略的组成表示，并通过dGL进行逻辑验证，确保策略始终获胜。

Result: 证明了最大子值映射的存在性，并开发了基于子值映射的非确定性策略合成算法。

Conclusion: 该方法在多样化的控制挑战中表现出色，验证了其有效性和实用性。

Abstract: Control problems for embedded systems like cars and trains can be modeled by
two-player hybrid games. Control envelopes, which are families of safe control
solutions, correspond to nondeterministic winning policies of hybrid games,
where each deterministic specialization of the policy is a control solution.
This paper synthesizes nondeterministic winning policies for hybrid games that
are as permissive as possible. It introduces subvalue maps, a compositional
representation of such policies that enables verification and synthesis along
the structure of the game. An inductive logical characterization in
differential game logic (dGL) checks whether a subvalue map induces a sound
control envelope which always induces a winning play. A policy is said to win
if it always achieves the desirable outcome when the player follows it, no
matter what actions the opponent plays. The maximal subvalue map, which allows
the most action options while still winning, is shown to exist and satisfy a
logical characterization. A family of algorithms for nondeterministic policy
synthesis can be obtained from the inductive subvalue map soundness
characterization. An implementation of these findings is evaluated on examples
that use the expressivity of dGL to model a range of diverse control
challenges.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach](https://arxiv.org/abs/2508.05693)
*Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan*

Main category: cs.SE

TL;DR: 论文提出了一种基于多准则决策（MCDM）的数据驱动框架PySelect，用于解决开源生态系统中第三方软件包选择的挑战，结合AI辅助意图建模，显著提升了推荐质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 开源生态系统中软件包选择因数量庞大和透明度不足而困难，现有AI工具依赖流行度而非适用性，缺乏可重复性。

Method: 通过自动化数据管道收集软件元数据、使用趋势、漏洞信息和开发者情感，构建决策模型，并开发PySelect系统结合大语言模型进行意图解析和推荐。

Result: 实验基于798,669个Python脚本和用户研究，显示高数据提取精度、优于生成式AI基线的推荐质量，以及用户对实用性和易用性的积极评价。

Conclusion: 该框架为软件包选择提供了可扩展、可解释且可重复的解决方案，结合MCDM原则和实证数据，支持基于证据的决策。

Abstract: Selecting third-party software packages in open-source ecosystems like Python
is challenging due to the large number of alternatives and limited transparent
evidence for comparison. Generative AI tools are increasingly used in
development workflows, but their suggestions often overlook dependency
evaluation, emphasize popularity over suitability, and lack reproducibility.
This creates risks for projects that require transparency, long-term
reliability, maintainability, and informed architectural decisions. This study
formulates software package selection as a Multi-Criteria Decision-Making
(MCDM) problem and proposes a data-driven framework for technology evaluation.
Automated data pipelines continuously collect and integrate software metadata,
usage trends, vulnerability information, and developer sentiment from GitHub,
PyPI, and Stack Overflow. These data are structured into a decision model
representing relationships among packages, domain features, and quality
attributes. The framework is implemented in PySelect, a decision support system
that uses large language models to interpret user intent and query the model to
identify contextually appropriate packages. The approach is evaluated using
798,669 Python scripts from 16,887 GitHub repositories and a user study based
on the Technology Acceptance Model. Results show high data extraction
precision, improved recommendation quality over generative AI baselines, and
positive user evaluations of usefulness and ease of use. This work introduces a
scalable, interpretable, and reproducible framework that supports
evidence-based software selection using MCDM principles, empirical data, and
AI-assisted intent modeling.

</details>


### [3] [Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning](https://arxiv.org/abs/2508.05710)
*Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.SE

TL;DR: Klear-CodeTest是一个用于代码强化学习的测试用例合成框架，通过Generator-Validation（G-V）机制确保测试用例的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 高质量的测试用例对训练大型语言模型至关重要，但目前合成高质量测试用例仍是一个未解决的难题。

Method: 采用G-V框架生成和验证测试用例，包括常规和边界情况，并通过多层安全沙箱系统确保代码执行安全。

Result: 实验表明，该方法显著提升了模型性能和训练稳定性。

Conclusion: Klear-CodeTest为代码强化学习提供了一种高效、可靠的测试用例合成解决方案。

Abstract: Precise, correct feedback is crucial for effectively training large language
models (LLMs) in code reinforcement learning. However, synthesizing
high-quality test cases remains a profoundly challenging and unsolved problem.
In this work, we present Klear-CodeTest, a comprehensive test case synthesis
framework featuring rigorous verification to ensure quality and reliability of
test cases. Our approach achieves broad coverage of programming problems via a
novel Generator-Validation (G-V) framework, ensuring correctness through a
consistency validation mechanism that verifies outputs against gold solutions.
The proposed G-V framework generates comprehensive test cases including both
regular and corner cases, enhancing test coverage and discriminative power for
solution correctness assessment in code reinforcement learning. In addition, we
design a multi-layered security sandbox system optimized for online
verification platforms, guaranteeing safe and reliable code execution. Through
comprehensive experiments, we demonstrate the effectiveness of our curated
dataset, showing significant improvements in model performance and training
stability. The source codes, curated dataset and sandbox system are available
at: https://github.com/Kwai-Klear/CodeTest.

</details>


### [4] [Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework](https://arxiv.org/abs/2508.05747)
*Rohaizah Abdul Wahid,Muhamad Said Nizamuddin Nadim,Suliana Sulaiman,Syahmi Akmal Shaharudin,Muhammad Danial Jupikil,Iqqwan Jasman Su Azlan Su*

Main category: cs.SE

TL;DR: 论文探讨了在Laravel教学中引入Composer及其包以提升开发效率，同时强调代码质量和概念理解的重要性，并提供了最佳实践建议。


<details>
  <summary>Details</summary>
Motivation: 学生在有限时间内完成Laravel项目存在困难，希望通过Composer及其包减少开发工作量，同时培养专业软件实践能力。

Method: 介绍Composer及其精选包，结合教学实践说明如何策略性使用这些工具，并讨论潜在风险及应对措施。

Result: Composer包能显著提升开发效率，但需注意避免过度依赖和包冲突，需结合教学指导确保学生理解工具的原理和适用场景。

Conclusion: Composer包的合理使用能加速开发并增强专业能力，但需通过教学设计确保学生深入理解工具，避免浅层学习。

Abstract: Laravel has emerged as a foundational framework in university web development
curricula. However, despite its scaffolding capabilities, students often
struggle to complete projects within limited academic timelines. This
conceptual paper introduces Composer, PHP's standard dependency manager, and
categorizes a curated selection of Composer packages that significantly reduce
development effort while fostering professional software practices. Grounded in
practical and pedagogical considerations, the paper illustrates how educators
and learners can strategically leverage these tools to build typical academic
or personal Laravel-based systems. Central to this approach is maintaining code
quality and reinforcing conceptual understanding. The paper also addresses
potential risks such as package conflicts and over-reliance on tools, providing
best-practice recommendations to mitigate them. While the goal is to accelerate
development, the deeper objective is to reinforce professional workflows and
industry readiness. Exposure to Composer packages enhances curriculum relevance
and smooths the transition from academia to the workplace. However, effective
integration requires deliberate instructional design aligned with learning
objectives. Without guidance, students may treat packages as black boxes. Thus,
educators must teach not only how to use these tools, but also when and why,
encouraging critical evaluation of their utility and limitations. This ensures
that practical convenience supports rather than supplants deep learning.

</details>


### [5] [AI-Guided Exploration of Large-Scale Codebases](https://arxiv.org/abs/2508.05799)
*Yoseph Berhanu Alebachew*

Main category: cs.SE

TL;DR: 论文提出了一种结合确定性逆向工程与LLM引导的意图感知可视化探索的混合方法，以提升代码理解效率。


<details>
  <summary>Details</summary>
Motivation: 开发者在理解复杂软件系统时面临挑战，传统工具缺乏交互性和上下文整合，LLM虽提供新机会但缺乏结构化视图的整合。

Method: 结合UML可视化、动态用户界面、历史上下文和协作功能，通过LLM解析用户查询和交互模式。

Result: 原型实现展示了该方法的可行性，未来工作包括实证评估和多语言系统扩展。

Conclusion: 研究为智能、交互式开发环境奠定了基础，支持开发者认知和协作工作流。

Abstract: Understanding large-scale, complex software systems is a major challenge for
developers, who spend a significant portion of their time on program
comprehension. Traditional tools such as static visualizations and reverse
engineering techniques provide structural insights but often lack
interactivity, adaptability, and integration with contextual information.
Recent advancements in large language models (LLMs) offer new opportunities to
enhance code exploration workflows, yet their lack of grounding and integration
with structured views limits their effectiveness. This work introduces a hybrid
approach that integrates deterministic reverse engineering with LLM-guided,
intent-aware visual exploration. The proposed system combines UML-based
visualization, dynamic user interfaces, historical context, and collaborative
features into an adaptive tool for code comprehension. By interpreting user
queries and interaction patterns, the LLM helps developers navigate and
understand complex codebases more effectively. A prototype implementation for
Java demonstrates the feasibility of this approach. Future work includes
empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM
interaction models. This research lays the groundwork for intelligent,
interactive environments that align with developer cognition and collaborative
workflows.

</details>


### [6] [Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm](https://arxiv.org/abs/2508.05923)
*Yanusha Mehendran,Maolin Tang,Yi Lu*

Main category: cs.SE

TL;DR: 论文提出了一种基于遗传算法的测试输入生成方法，结合遗传操作和自适应学习，显著提升了软件漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞威胁现代系统的可靠性，传统检测方法难以应对日益复杂的软件。

Method: 采用遗传算法生成测试输入，结合交叉操作和自适应反馈机制，动态优化输入生成。

Result: 在九个开源JSON处理库中测试，覆盖率显著提升，最高达166%。

Conclusion: 该方法能有效检测更深层次的漏洞，为软件安全测试提供了可扩展的解决方案。

Abstract: Software vulnerabilities continue to undermine the reliability and security
of modern systems, particularly as software complexity outpaces the
capabilities of traditional detection methods. This study introduces a genetic
algorithm-based method for test input generation that innovatively integrates
genetic operators and adaptive learning to enhance software vulnerability
detection. A key contribution is the application of the crossover operator,
which facilitates exploration by searching across a broader space of potential
test inputs. Complementing this, an adaptive feedback mechanism continuously
learns from the system's execution behavior and dynamically guides input
generation toward promising areas of the input space. Rather than relying on
fixed or randomly selected inputs, the approach evolves a population of
structurally valid test cases using feedback-driven selection, enabling deeper
and more effective code traversal. This strategic integration of exploration
and exploitation ensures that both diverse and targeted test inputs are
developed over time. Evaluation was conducted across nine open-source
JSON-processing libraries. The proposed method achieved substantial
improvements in coverage compared to a benchmark evolutionary fuzzing method,
with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%
in line coverage, 114.0% in instruction coverage, and 166.0% in branch
coverage. These results highlight the method's capacity to detect deeper and
more complex vulnerabilities, offering a scalable and adaptive solution to
software security testing.

</details>


### [7] [A Survey on Task Scheduling in Carbon-Aware Container Orchestration](https://arxiv.org/abs/2508.05949)
*Jialin Yang,Zainab Saad,Jiajun Wu,Xiaoguang Niu,Henry Leung,Steve Drew*

Main category: cs.SE

TL;DR: 本文系统综述了Kubernetes调度策略，分类为硬件中心和软件中心，并分析了其可持续性目标，提出了一种针对环境可持续性的云任务调度分类法。


<details>
  <summary>Details</summary>
Motivation: 大规模软件生态系统和云数据中心的能源需求激增，尤其是大型语言模型的训练和部署，导致能源消耗和碳足迹达到前所未有的水平，亟需减少碳排放。

Method: 通过系统综述Kubernetes调度策略，分类为硬件中心和软件中心，并标注其可持续性目标，提出了一种针对环境可持续性的云任务调度分类法。

Result: 分析了新兴研究趋势和开放挑战，为下一代云计算系统设计可持续调度解决方案提供了关键见解。

Conclusion: 本文为可持续云计算调度提供了系统化的分类和分析，为未来研究指明了方向。

Abstract: The soaring energy demands of large-scale software ecosystems and cloud data
centers, accelerated by the intensive training and deployment of large language
models, have driven energy consumption and carbon footprint to unprecedented
levels. In response, both industry and academia are increasing efforts to
reduce the carbon emissions associated with cloud computing through more
efficient task scheduling and infrastructure orchestration. In this work, we
present a systematic review of various Kubernetes scheduling strategies,
categorizing them into hardware-centric and software-centric, annotating each
with its sustainability objectives, and grouping them according to the
algorithms they use. We propose a comprehensive taxonomy for cloud task
scheduling studies, with a particular focus on the environmental sustainability
aspect. We analyze emerging research trends and open challenges, and our
findings provide critical insight into the design of sustainable scheduling
solutions for next-generation cloud computing systems.

</details>


### [8] [Impact-driven Context Filtering For Cross-file Code Completion](https://arxiv.org/abs/2508.05970)
*Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu*

Main category: cs.SE

TL;DR: 论文提出了一种基于检索增强生成（RAG）的代码补全方法CODEFILTER，通过评估检索代码块对补全的影响，构建数据集并训练过滤框架，显著提升了补全准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究检索到的跨文件代码块对代码补全的实际贡献，发现部分检索块对补全有害，需解决这一问题。

Method: 引入基于似然的度量评估检索块影响，构建标记数据集，提出自适应过滤框架CODEFILTER。

Result: CODEFILTER在多个基准测试中显著提升补全准确性，减少输入提示长度，提高计算效率。

Conclusion: CODEFILTER能有效提升代码补全的准确性、效率和可归因性，具有广泛适用性。

Abstract: Retrieval-augmented generation (RAG) has recently demonstrated considerable
potential for repository-level code completion, as it integrates cross-file
knowledge with in-file preceding code to provide comprehensive contexts for
generation. To better understand the contribution of the retrieved cross-file
contexts, we introduce a likelihood-based metric to evaluate the impact of each
retrieved code chunk on the completion. Our analysis reveals that, despite
retrieving numerous chunks, only a small subset positively contributes to the
completion, while some chunks even degrade performance. To address this issue,
we leverage this metric to construct a repository-level dataset where each
retrieved chunk is labeled as positive, neutral, or negative based on its
relevance to the target completion. We then propose an adaptive retrieval
context filtering framework, CODEFILTER, trained on this dataset to mitigate
the harmful effects of negative retrieved contexts in code completion.
Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks
demonstrates that CODEFILTER consistently improves completion accuracy compared
to approaches without filtering operations across various tasks. Additionally,
CODEFILTER significantly reduces the length of the input prompt, enhancing
computational efficiency while exhibiting strong generalizability across
different models. These results underscore the potential of CODEFILTER to
enhance the accuracy, efficiency, and attributability of repository-level code
completion.

</details>


### [9] [Position: Intelligent Coding Systems Should Write Programs with Justifications](https://arxiv.org/abs/2508.06017)
*Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 智能编码系统通过自然语言生成代码，但其不透明的决策过程引发信任问题。论文主张系统应生成清晰、一致的代码解释，并提出神经符号方法以实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 解决AI驱动编码系统因决策不透明导致的信任和可用性问题，特别是对非专家用户。

Method: 提出神经符号方法，结合符号约束和神经表示，生成认知对齐和语义忠实的代码解释。

Result: 现有方法（如形式验证、静态分析）在生成解释方面存在局限，神经符号方法有望改进。

Conclusion: 智能编码系统需生成可理解的解释，神经符号方法是实现这一目标的有前景的方向。

Abstract: Intelligent coding systems are transforming software development by enabling
users to specify code behavior in natural language. However, the opaque
decision-making of AI-driven coders raises trust and usability concerns,
particularly for non-expert users who cannot inspect low-level implementations.
We argue that these systems should not only generate code but also produce
clear, consistent justifications that bridge model reasoning and user
understanding. To this end, we identify two critical justification
properties-cognitive alignment and semantic faithfulness-and highlight the
limitations of existing methods, including formal verification, static
analysis, and post-hoc explainability. We advocate exploring neuro-symbolic
approaches for justification generation, where symbolic constraints guide model
behavior during training and program semantics are enriched through neural
representations, enabling automated consistency checks at inference time.

</details>


### [10] [Understanding Inconsistent State Update Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2508.06192)
*Lantian Li,Yuyu Chen,Jingwen Wu,Yue Pan,Zhongxing Yu*

Main category: cs.SE

TL;DR: 本文首次对智能合约中的不一致状态更新漏洞进行了大规模实证研究，总结了其根本原因、修复策略和利用方法，并提出了11项重要发现。


<details>
  <summary>Details</summary>
Motivation: 智能合约的状态更新问题可能导致安全漏洞，现有检测工具难以有效识别，因此需要深入研究以提供解决方案。

Method: 系统调查了352个真实智能合约项目中的116个不一致状态更新漏洞，分析其根因、修复策略和利用方式。

Result: 研究提出了11项重要发现，并开发了一个概念验证检测工具，成功在64个GitHub项目中发现问题。

Conclusion: 研究结果对开发者、研究人员和工具设计者避免智能合约中的不一致状态更新漏洞具有重要价值。

Abstract: Smart contracts enable contract terms to be automatically executed and
verified on the blockchain, and recent years have witnessed numerous
applications of them in areas such as financial institutions and supply chains.
The execution logic of a smart contract is closely related to the contract
state, and thus the correct and safe execution of the contract depends heavily
on the precise control and update of the contract state. However, the contract
state update process can have issues. In particular, inconsistent state update
issues can arise for reasons such as unsynchronized modifications. Inconsistent
state update bugs have been exploited by attackers many times, but existing
detection tools still have difficulty in effectively identifying them. This
paper conducts the first large-scale empirical study about inconsistent state
update vulnerabilities (that is, inconsistent state update bugs that are
exploitable) in smart contracts, aiming to shed light for developers,
researchers, tool builders, and language or library designers in order to avoid
inconsistent state update vulnerabilities. We systematically investigate 116
inconsistent state update vulnerabilities in 352 real-world smart contract
projects, summarizing their root causes, fix strategies, and exploitation
methods. Our study provides 11 original and important findings, and we also
give the implications of our findings. To illustrate the potential benefits of
our research, we also develop a proof-of-concept checker based on one of our
findings. The checker effectively detects issues in 64 popular GitHub projects,
and 19 project owners have confirmed the detected issues at the time of
writing. The result demonstrates the usefulness and importance of our findings
for avoiding inconsistent state update vulnerabilities in smart contracts.

</details>


### [11] [Improving the Developer Experience with a Low-Code Process Modelling Language](https://arxiv.org/abs/2508.06299)
*Henrique Henriques,Hugo Lourenço,Vasco Amaral,Miguel Goulão*

Main category: cs.SE

TL;DR: 研究改进了OutSystems平台的BPT DSL，通过用户反馈和评估工具提升了其可用性和语义透明度。


<details>
  <summary>Details</summary>
Motivation: BPT DSL的采用率低且存在可用性问题，增加了维护成本，因此需要改进。

Method: 结合访谈、"Physics of Notation"评审及SUS和NASA TLX评估工具，开发新版本BPT。

Result: 新版本显著提升了语义透明度（31%到69%）、正确率（51%到89%）、SUS分数（42.25到64.78），并降低了TLX分数（36.50到20.78）。

Conclusion: 新版本BPT显著改善了开发者体验，用户背景对最终语法选择和可用性指标有重要影响。

Abstract: Context: The OutSystems Platform is a development environment composed of
several DSLs, used to specify, quickly build, and validate web and mobile
applications. The DSLs allow users to model different perspectives such as
interfaces and data models, define custom business logic and construct process
models. Problem: The DSL for process modelling (Business Process Technology
(BPT)), has a low adoption rate and is perceived as having usability problems
hampering its adoption. This is problematic given the language maintenance
costs. Method: We used a combination of interviews, a critical review of BPT
using the "Physics of Notation" and empirical evaluations of BPT using the
System Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a
new version of BPT, taking these inputs and Outsystems' engineers' culture into
account. Results: Evaluations conducted with 25 professional software engineers
showed an increase of the semantic transparency on the new version, from 31% to
69%, an increase in the correctness of responses, from 51% to 89%, an increase
in the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from
36.50 to 20.78. These differences were statistically significant. Conclusions:
These results suggest that the new version of BPT significantly improved the
developer experience of the previous version. The end users' background with
OutSystems had a relevant impact on the final concrete syntax choices and
achieved usability indicators.

</details>


### [12] [Execution-Feedback Driven Test Generation from SWE Issues](https://arxiv.org/abs/2508.06365)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 论文提出了一种自动生成软件问题复现测试的方法，解决了代码缺失或错误时的测试生成难题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大多数软件问题缺乏复现测试，而现有方法因代码错误或缺失难以生成有效测试，因此需要新方法解决这一问题。

Method: 论文提出了一种利用执行反馈的新技术，并开发了名为e-Otter++的测试生成工具。

Result: 在TDD-Bench Verified基准测试中，e-Otter++的平均失败转通过率为63%，显著优于现有技术。

Conclusion: e-Otter++在自动生成复现测试方面取得了突破，为软件工程问题提供了更高效的解决方案。

Abstract: A software engineering issue (SWE issue) is easier to resolve when
accompanied by a reproduction test. Unfortunately, most issues do not come with
functioning reproduction tests, so this paper explores how to generate them
automatically. The primary challenge in this setting is that the code to be
tested is either missing or wrong, as evidenced by the existence of the issue
in the first place. This has held back test generation for this setting:
without the correct code to execute, it is difficult to leverage execution
feedback to generate good tests. This paper introduces novel techniques for
leveraging execution feedback to get around this problem, implemented in a new
reproduction test generator called e-Otter++. Experiments show that e-Otter++
represents a leap ahead in the state-of-the-art for this problem, generating
tests with an average fail-to-pass rate of 63% on the TDD-Bench Verified
benchmark.

</details>


### [13] [What Builds Effective In-Context Examples for Code Generation?](https://arxiv.org/abs/2508.06414)
*Dongze Li,Songqiang Chen,Jialun Cao,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: 本文研究了代码示例中不同特征对In-Context Learning（ICL）在代码生成任务中效果的影响，发现变量和函数命名对性能至关重要，而LLMs更关注语义而非格式。


<details>
  <summary>Details</summary>
Motivation: 探索代码示例中哪些具体特征（如命名风格、代码格式等）对ICL在代码生成任务中的有效性起关键作用。

Method: 通过控制变量实验（ablation studies）分析不同代码特征对ICL效果的影响。

Result: 变量和函数命名的适当性对性能影响显著（性能下降达30%），LLMs更偏好语义明确的命名而非格式规范。此外，LLMs难以从相似代码中提取通用问题解决思路。

Conclusion: 研究结果为优化代码生成中的ICL系统提供了重要参考，同时揭示了基于反思学习的代码生成任务中的根本挑战。

Abstract: In-Context Learning (ICL) has emerged as a promising solution to enhance the
code generation capabilities of Large Language Models (LLMs), which
incorporates code examples inside the prompt to let LLMs learn from
demonstrations. However, despite the substantial effectiveness of the code
example-based ICL approach, the specific features (e.g., identifier naming
styles, code formatting, solution insight) within the ICL-provided code
examples that significantly contribute to the ICL's effectiveness remain
unclear. This paper systematically investigates the impact of various code
features on ICL with code examples through controlled ablation studies. Our
findings reveal that the appropriate naming of variables and functions is
crucial for effective code generation, with their elimination leading to
performance decreases of up to 30 percentage points. We further demonstrate
that LLMs prioritize semantically meaningful identifier names over formatting
conventions, with language-specific preferences regarding identifier verbosity.
Additionally, our investigation into ICL's potential for enhancing reflection
and inference capabilities reveals that current LLMs struggle to extract
generalizable problem-solving insights from similar code solutions, despite
being capable of utilizing direct information effectively. These findings are
expected to provide valuable insights for optimizing ICL systems in code
generation applications and highlight fundamental challenges in
reflection-based learning for code generation tasks.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [14] [Basic interactive algorithms: Preview](https://arxiv.org/abs/2508.05798)
*Yuri Gurevich*

Main category: cs.LO

TL;DR: 本文预览了即将提出的基本交互式算法的公理化工作，并讨论了算法的现代概念及其扩展。


<details>
  <summary>Details</summary>
Motivation: 探讨算法的现代概念及其扩展，特别是从基本算法到概率、量子等算法的演变，以及两种Church-Turing论题的区别。

Method: 通过公理化基本算法，并引入适当的预言机，将非确定性和概率算法视为基本算法的扩展。

Result: 展示了如何将多种算法类（如量子电路算法）视为基本算法的扩展，并强调了两种Church-Turing论题的区别。

Conclusion: 基本算法的公理化框架可以扩展到更广泛的算法类，为理解现代算法提供了理论基础。

Abstract: This dialog paper offers a preview and provides a foretaste of an upcoming
work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was
axiomatized a quarter of a century ago as the notion of ``sequential
algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm"
now. The axiomatization was used to show that for every basic algorithm there
is a behaviorally equivalent abstract state machine. It was also used to prove
the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded --
probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of
a much more ambitious version of the Church-Turing thesis commonly known as the
``physical thesis.'' We emphasize the difference between the two versions of
the Church-Turing thesis and illustrate how nondeterministic and probabilistic
algorithms can be viewed as basic algorithms with appropriate oracles. The same
view applies to quantum circuit algorithms and many other classes of
algorithms.

</details>


### [15] [Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games](https://arxiv.org/abs/2508.06088)
*Kittiphon Phalakarn,Yun Chen Tsai,Ichiro Hasuo*

Main category: cs.LO

TL;DR: 论文提出了一种基于双玩家最宽路径游戏的BVI算法（2WP-BVI），解决了传统BVI在随机游戏中因终组件导致的收敛问题，并通过理论证明和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统BVI算法在处理随机游戏中的终组件时可能无法收敛，现有方法通常计算成本高。1WP-BVI虽表现优异但理论基础不足，因此需要一种更理论化的改进方法。

Method: 提出2WP-BVI算法，基于双玩家最宽路径游戏，利用最大继承性原则证明其正确性。

Result: 实验结果表明2WP-BVI具有实际应用潜力。

Conclusion: 2WP-BVI不仅解决了传统BVI的收敛问题，还提供了更坚实的理论基础，为随机游戏模型检查提供了高效方法。

Abstract: For model checking stochastic games (SGs), bounded value iteration (BVI)
algorithms have gained attention as efficient approximate methods with rigorous
precision guarantees. However, BVI may not terminate or converge when the
target SG contains end components. Most existing approaches address this issue
by explicitly detecting and processing end components--a process that is often
computationally expensive. An exception is the widest path-based BVI approach
previously studied by Phalakarn et al., which we refer to as 1WP-BVI. The
method performs particularly well in the presence of numerous end components.
Nonetheless, its theoretical foundations remain somewhat ad hoc. In this paper,
we identify and formalize the core principles underlying the widest path-based
BVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on
(2-player) widest path games, and (ii) proving its correctness using what we
call the maximality inheritance principle--a proof principle previously
employed in a well-known result in probabilistic model checking. Our
experimental results demonstrate the practical relevance and potential of our
proposed 2WP-BVI algorithm.

</details>
