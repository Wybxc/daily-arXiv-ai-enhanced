<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 42]
- [cs.PL](#cs.PL) [Total: 5]
- [cs.LO](#cs.LO) [Total: 8]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [ScaleCall - Agentic Tool Calling at Scale for Fintech: Challenges, Methods, and Deployment Insights](https://arxiv.org/abs/2511.00074)
*Richard Osuagwu,Thomas Cook,Maraim Masoud,Koustav Ghosal,Riccardo Mattivi*

Main category: cs.SE

TL;DR: 该论文研究了企业环境中工具检索方法，开发了ScaleCall框架，评估了嵌入检索、列表排序和混合方法，发现方法效果取决于领域特定因素而非算法优势。


<details>
  <summary>Details</summary>
Motivation: 在受监管的企业环境（如金融科技）中部署LLM工具调用功能面临独特挑战，包括本地约束、合规要求和大型功能重叠工具集的歧义消除需求。

Method: 开发ScaleCall原型框架，系统评估嵌入检索、基于提示的列表排序和混合方法，在企业基准上进行实证研究。

Result: 嵌入方法在大工具库中延迟更低，列表排序在功能重叠时歧义消除更好，混合方法在特定情境中表现有潜力。

Conclusion: 研究提供了检索准确性、计算效率和操作需求之间的权衡见解，为企业级工具调用系统设计提供了实践指导。

Abstract: While Large Language Models (LLMs) excel at tool calling, deploying these
capabilities in regulated enterprise environments such as fintech presents
unique challenges due to on-premises constraints, regulatory compliance
requirements, and the need to disambiguate large, functionally overlapping
toolsets. In this paper, we present a comprehensive study of tool retrieval
methods for enterprise environments through the development and deployment of
ScaleCall, a prototype tool-calling framework within Mastercard designed for
orchestrating internal APIs and automating data engineering workflows. We
systematically evaluate embedding-based retrieval, prompt-based listwise
ranking, and hybrid approaches, revealing that method effectiveness depends
heavily on domain-specific factors rather than inherent algorithmic
superiority. Through empirical investigation on enterprise-derived benchmarks,
we find that embedding-based methods offer superior latency for large tool
repositories, while listwise ranking provides better disambiguation for
overlapping functionalities, with hybrid approaches showing promise in specific
contexts. We integrate our findings into ScaleCall's flexible architecture and
validate the framework through real-world deployment in Mastercard's regulated
environment. Our work provides practical insights into the trade-offs between
retrieval accuracy, computational efficiency, and operational requirements,
contributing to the understanding of tool-calling system design for enterprise
applications in regulated industries.

</details>


### [2] [Adding New Capability in Existing Scientific Application with LLM Assistance](https://arxiv.org/abs/2511.00087)
*Anshu Dubey,Akash Dhruv*

Main category: cs.SE

TL;DR: 提出使用LLM辅助从零开始编写新算法代码的方法论，并改进了现有的代码翻译工具Code-Scribe用于新代码生成


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注代码生成的有效性，但对于训练数据中不包含类似代码的新算法代码生成研究较少

Method: 提出新的方法论，使用LLM辅助从零编写新算法代码，并增强现有的Code-Scribe代码翻译工具

Result: 开发了改进后的Code-Scribe工具，能够支持新代码生成

Conclusion: 该方法为LLM在新算法代码生成方面的应用提供了新的解决方案

Abstract: With the emergence and rapid evolution of large language models (LLM),
automating coding tasks has become an im- portant research topic. Many efforts
are underway and liter- ature abounds about the efficacy of models and their
ability to generate code. A less explored aspect of code generation is for new
algorithms, where the training data-set would not have included any previous
example of similar code. In this paper we propose a new methodology for writing
code from scratch for a new algorithm using LLM assistance, and describe
enhancement of a previously developed code- translation tool, Code-Scribe, for
new code generation.

</details>


### [3] [Inferring multiple helper Dafny assertions with LLMs](https://arxiv.org/abs/2511.00125)
*Álvaro Silva,Alexandra Mendes,Ruben Martins*

Main category: cs.SE

TL;DR: 使用大型语言模型自动推断Dafny程序中缺失的辅助断言，特别是多断言缺失的情况，开发了DAISY工具，能显著减少验证工程工作量。


<details>
  <summary>Details</summary>
Motivation: Dafny验证器虽然提供强正确性保证，但需要大量手动辅助断言，这成为采用的主要障碍。

Method: 扩展DafnyBench基准测试集，引入断言类型分类法，通过结合LLM预测和错误消息启发式的混合方法进行故障定位，开发DAISY系统。

Result: DAISY在单断言缺失情况下验证了63.4%的程序，在多断言缺失情况下验证了31.7%的程序，且许多程序可以用比原始更少的断言完成验证。

Conclusion: 自动断言推断能显著减少证明工程工作量，是实现更可扩展和可访问的形式验证的重要一步。

Abstract: The Dafny verifier provides strong correctness guarantees but often requires
numerous manual helper assertions, creating a significant barrier to adoption.
We investigate the use of Large Language Models (LLMs) to automatically infer
missing helper assertions in Dafny programs, with a primary focus on cases
involving multiple missing assertions. To support this study, we extend the
DafnyBench benchmark with curated datasets where one, two, or all assertions
are removed, and we introduce a taxonomy of assertion types to analyze
inference difficulty. Our approach refines fault localization through a hybrid
method that combines LLM predictions with error-message heuristics. We
implement this approach in a new tool called DAISY (Dafny Assertion Inference
SYstem). While our focus is on multiple missing assertions, we also evaluate
DAISY on single-assertion cases. DAISY verifies 63.4% of programs with one
missing assertion and 31.7% with multiple missing assertions. Notably, many
programs can be verified with fewer assertions than originally present,
highlighting that proofs often admit multiple valid repair strategies and that
recovering every original assertion is unnecessary. These results demonstrate
that automated assertion inference can substantially reduce proof engineering
effort and represent a step toward more scalable and accessible formal
verification.

</details>


### [4] [What a diff makes: automating code migration with large language models](https://arxiv.org/abs/2511.00160)
*Katherine A. Rosenfeld,Cliff C. Kerr,Jessica Lundin*

Main category: cs.SE

TL;DR: 使用包含差异信息的上下文可以显著提升大型语言模型在代码迁移任务中的性能，特别是在处理依赖项语义版本变更时。


<details>
  <summary>Details</summary>
Motivation: 现代软件程序依赖的堆栈经常更新，这些变更可能破坏依赖项目。需要解决在依赖项经历主要和次要语义版本变更时保持兼容性的问题。

Method: 使用包含差异信息的上下文来增强大型语言模型的代码迁移能力，通过测试覆盖率和变更比较等指标评估性能。

Result: 在TYPHOIDSIM从STARSIM版本迁移的真实案例中，AIMigrate在单次运行中正确识别了65%的必要变更，多次运行后提升至80%，其中47%的变更生成完美。

Conclusion: 包含差异信息的上下文可以显著提升LLM在代码迁移任务中的表现，在某些情况下甚至优于使用纯代码的方法。

Abstract: Modern software programs are built on stacks that are often undergoing
changes that introduce updates and improvements, but may also break any project
that depends upon them. In this paper we explore the use of Large Language
Models (LLMs) for code migration, specifically the problem of maintaining
compatibility with a dependency as it undergoes major and minor semantic
version changes. We demonstrate, using metrics such as test coverage and change
comparisons, that contexts containing diffs can significantly improve
performance against out of the box LLMs and, in some cases, perform better than
using code. We provide a dataset to assist in further development of this
problem area, as well as an open-source Python package, AIMigrate, that can be
used to assist with migrating code bases. In a real-world migration of
TYPHOIDSIM between STARSIM versions, AIMigrate correctly identified 65% of
required changes in a single run, increasing to 80% with multiple runs, with
47% of changes generated perfectly.

</details>


### [5] [Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt](https://arxiv.org/abs/2511.01529)
*Murali Sridharan,Mikel Robredo,Leevi Rantala,Matteo Esposito,Valentina Lenarduzzi,Mika Mantyla*

Main category: cs.SE

TL;DR: 该研究通过分析超过225,000个SATD注释，发现技术债务主要出现在内联代码中的定义、条件判断和异常处理附近，表明这是开发者在变更过程中的有意信号而非疏忽。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注检测和优先处理SATD，但很少关注受SATD影响的源代码。本研究旨在将SATD注释与其周围的源代码结构联系起来。

Method: 利用包含9000多个Java开源软件仓库代码注释的PENTACET数据集，定量推断SATD最常见出现的位置及其最常影响的代码结构/语句。

Result: 大规模研究显示SATD主要出现在内联代码中的定义、条件判断和异常处理附近，这些地方开发者面临不确定性和权衡取舍。

Conclusion: SATD是开发者在变更过程中有意识的信号，表明他们对问题的认识，而不仅仅是疏忽的表现。

Abstract: Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for
proactive software maintenance. Previous research has primarily targeted
detecting and prioritizing SATD, with little focus on the source code afflicted
with SATD. Our goal in this work is to connect the SATD comments with source
code constructs that surround them.
  Method. We leverage the extensive SATD dataset PENTACET, containing code
comments from over 9000 Java Open Source Software (OSS) repositories. We
quantitatively infer where SATD most commonly occurs and which code
constructs/statements it most frequently affects.
  Results and Conclusions. Our large-scale study links over 225,000 SATD
comments to their surrounding code, showing that SATD mainly arises in inline
code near definitions, conditionals, and exception handling, where developers
face uncertainty and trade-offs, revealing it as an intentional signal of
awareness during change rather than mere neglect.

</details>


### [6] [Understanding Code Agent Behaviour: An Empirical Study of Success and Failure Trajectories](https://arxiv.org/abs/2511.00197)
*Oorja Majgaonkar,Zhiwei Fei,Xiang Li,Federica Sarro,He Ye*

Main category: cs.SE

TL;DR: 对三种先进代码代理在SWE-Bench基准测试中的执行轨迹进行实证研究，揭示了代理在软件问题解决中的行为模式、成功与失败轨迹的差异，以及故障定位能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在复杂软件工程任务中的部署增加，需要超越简单成功指标来理解其问题解决行为，因为其决策过程仍然不透明。

Method: 分析三种最先进代码代理（OpenHands、SWE-agent、Prometheus）在SWE-Bench基准测试中的执行轨迹，包括成功和失败的尝试。

Result: 发现不同问题解决策略在不同场景中促进成功；失败轨迹比成功轨迹更长且方差更高；大多数轨迹能正确识别问题文件（72-81%），但成功更依赖于实现近似而非精确的代码修改。

Conclusion: 通过轨迹分析为理解代理行为提供了基础，有助于开发更稳健和可解释的自主软件工程系统。

Abstract: The increasing deployment of Large Language Model (LLM) agents for complex
software engineering tasks has created a need to understand their
problem-solving behaviours beyond simple success metrics. While these agents
demonstrate impressive capabilities in automated issue resolution, their
decision-making processes remain largely opaque. This paper presents an
empirical study of agent trajectories, namely the execution traces capturing
the steps agents take when attempting to resolve software issues. We analyse
trajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and
Prometheus) on the SWE-Bench benchmark, examining both successful and failed
attempts. Our investigation reveals several key insights into agent behaviour.
First, we identify how distinct problem-solving strategies, such as defensive
programming and context gathering, enable success in different scenarios.
Second, we find that failed trajectories are consistently longer and exhibit
higher variance than successful ones, with failure patterns differing
significantly between agents. Third, our fault localisation analysis shows that
while most trajectories correctly identify problematic files (72-81\% even in
failures), success depends more on achieving approximate rather than exact code
modifications. These and other findings unveiled by our study, provide a
foundation for understanding agent behaviour through trajectory analysis,
contributing to the development of more robust and interpretable autonomous
software engineering systems.

</details>


### [7] [Position: Vibe Coding Needs Vibe Reasoning: Improving Vibe Coding with Formal Verification](https://arxiv.org/abs/2511.00202)
*Jacqueline Mitchell,Yasser Shaaban*

Main category: cs.SE

TL;DR: 论文分析了"氛围编程"的局限性，提出通过形式化方法结合侧挂系统来解决LLM编程中的技术债务、安全问题和代码波动问题。


<details>
  <summary>Details</summary>
Motivation: 氛围编程虽然流行，但存在技术债务积累、安全问题和代码波动等限制，这些源于LLM无法在编程过程中协调人类施加的约束，且优先用户指令而非代码一致性。

Method: 提出在整个氛围编程过程中使用侧挂系统，包括：(1)自动形式化规范，(2)针对目标进行验证，(3)向LLM提供可操作的反馈，(4)允许开发者直观影响规范。

Result: 通过形式化方法可以缓解氛围编程的陷阱，使其更加可靠，但需要超越现有的形式化方法与LLM结合方法。

Conclusion: 形式化方法能够有效改善氛围编程的可靠性，但需要创新的集成方式，特别是通过侧挂系统在整个编程过程中提供自动形式化、验证和可操作反馈。

Abstract: ``Vibe coding'' -- the practice of developing software through iteratively
conversing with a large language model (LLM) -- has exploded in popularity
within the last year. However, developers report key limitations including the
accumulation of technical debt, security issues, and code churn to achieve
satisfactory results. We argue that these pitfalls result from LLMs' inability
to reconcile accumulating human-imposed constraints during vibe coding, with
developers inadvertently failing to resolve contradictions because LLMs
prioritize user commands over code consistency. Given LLMs' receptiveness to
verification-based feedback, we argue that formal methods can mitigate these
pitfalls, making vibe coding more reliable. However, we posit that integrating
formal methods must transcend existing approaches that combine formal methods
and LLMs. We advocate for a side-car system throughout the vibe coding process
which: (1) \emph{Autoformalizes} specifications (2) Validates against targets,
(3) Delivers \emph{actionable} feedback to the LLM, and (4) Allows intuitive
developer influence on specifications.

</details>


### [8] [DocPrism: Local Categorization and External Filtering to Identify Relevant Code-Documentation Inconsistencies](https://arxiv.org/abs/2511.00215)
*Xiaomeng Xu,Zahin Wahab,Reid Holmes,Caroline Lemieux*

Main category: cs.SE

TL;DR: DocPrism是一个多语言代码文档一致性检测工具，使用标准大语言模型分析文档不一致性，通过LCEF方法显著降低误报率。


<details>
  <summary>Details</summary>
Motivation: 代码与文档不一致是常见问题，会导致开发者误解和软件缺陷，需要有效的自动化检测工具。

Method: 采用LCEF（本地分类外部过滤）方法，利用LLM的本地补全能力而非长期推理能力来减少误报。

Result: LCEF将不一致标记率从98%降至14%，准确率从14%提升至94%；在Python、TypeScript、C++和Java上保持15%的低标记率和0.62的精确度。

Conclusion: DocPrism能够有效检测多语言代码文档不一致性，无需微调即可实现高准确率和低误报率。

Abstract: Code-documentation inconsistencies are common and undesirable: they can lead
to developer misunderstandings and software defects. This paper introduces
DocPrism, a multi-language, code-documentation inconsistency detection tool.
DocPrism uses a standard large language model (LLM) to analyze and explain
inconsistencies. Plain use of LLMs for this task yield unacceptably high false
positive rates: LLMs identify natural gaps between high-level documentation and
detailed code implementations as inconsistencies. We introduce and apply the
Local Categorization, External Filtering (LCEF) methodology to reduce false
positives. LCEF relies on the LLM's local completion skills rather than its
long-term reasoning skills. In our ablation study, LCEF reduces DocPrism's
inconsistency flag rate from 98% to 14%, and increases accuracy from 14% to
94%. On a broad evaluation across Python, TypeScript, C++, and Java, DocPrism
maintains a low flag rate of 15%, and achieves a precision of 0.62 without
performing any fine-tuning.

</details>


### [9] [LLM-Driven Cost-Effective Requirements Change Impact Analysis](https://arxiv.org/abs/2511.00262)
*Romina Etezadi,Sallam Abualhaija,Chetan Arora,Lionel Briand*

Main category: cs.SE

TL;DR: ProReFiCIA是一个基于大语言模型的自动化方法，用于识别需求变更对其他需求的影响，显著提高了召回率并降低了人工审查成本。


<details>
  <summary>Details</summary>
Motivation: 需求在软件开发周期中经常变更，人工识别变更影响既容易出错又耗费精力，可能导致遗漏重要影响需求，进而引发下游任务严重问题。

Method: 使用大语言模型和针对该任务定制的多种提示变体，自动识别需求变更的影响。

Result: 在基准数据集上达到93.3%的召回率，在新建的工业数据集上达到95.8%的召回率，工程师只需审查2.1%-8.5%的需求集。

Conclusion: ProReFiCIA能有效识别受影响需求，成本低且准确率高，具有实际应用价值。

Abstract: Requirements are inherently subject to changes throughout the software
development lifecycle. Within the limited budget available to requirements
engineers, manually identifying the impact of such changes on other
requirements is both error-prone and effort-intensive. That might lead to
overlooked impacted requirements, which, if not properly managed, can cause
serious issues in the downstream tasks. Inspired by the growing potential of
large language models (LLMs) across diverse domains, we propose ProReFiCIA, an
LLM-driven approach for automatically identifying the impacted requirements
when changes occur. We conduct an extensive evaluation of ProReFiCIA using
several LLMs and prompts variants tailored to this task. Using the best
combination of an LLM and a prompt variant, ProReFiCIA achieves a recall of
93.3% on a benchmark dataset and 95.8% on a newly created industry dataset,
demonstrating its strong effectiveness in identifying impacted requirements.
Further, the cost of applying ProReFiCIA remains small, as the engineer only
needs to review the generated results, which represent between 2.1% and 8.5% of
the entire set of requirements.

</details>


### [10] [Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework](https://arxiv.org/abs/2511.00417)
*Marcel Valovy*

Main category: cs.SE

TL;DR: 该论文提出了ROMA框架，通过人格心理学和自我决定理论优化人类与AI在编程中的协作角色，实证研究表明人格驱动的角色分配能显著提升动机和团队动力。


<details>
  <summary>Details</summary>
Motivation: 随着AI改变软件开发，需要探索开发者与AI系统如何最有效地协作，通过人格特质和角色偏好来优化人机协作效果。

Method: 采用设计科学研究方法，经过五个周期，涉及200名实验参与者和46名访谈对象，建立人格特质、编程角色偏好与协作结果之间的实证联系。

Result: 人格驱动的角色优化显著提升了自我决定和团队动力，专业人士平均动机提升23%，本科生最高达65%。识别出五种人格原型：探索者、协调者、工匠、架构师和适应者，每种都有特定的编程角色偏好。

Conclusion: 贡献包括：(1)经验证的人格特质与角色偏好框架；(2)人格特征与AI协作模式的分类；(3)ISO/IEC 29110扩展，使小型实体能够在标准中实施人格驱动的角色优化。

Abstract: As artificial intelligence transforms software development, a critical
question emerges: how can developers and AI systems collaborate most
effectively? This dissertation optimizes human-AI programming roles through
self-determination theory and personality psychology, introducing the Role
Optimization Motivation Alignment (ROMA) framework.
  Through Design Science Research spanning five cycles, this work establishes
empirically-validated connections between personality traits, programming role
preferences, and collaborative outcomes, engaging 200 experimental participants
and 46 interview respondents.
  Key findings demonstrate that personality-driven role optimization
significantly enhances self-determination and team dynamics, yielding 23%
average motivation increases among professionals and up to 65% among
undergraduates. Five distinct personality archetypes emerge: The Explorer (high
Openness/low Agreeableness), The Orchestrator (high
Extraversion/Agreeableness), The Craftsperson (high Neuroticism/low
Extraversion), The Architect (high Conscientiousness), and The Adapter
(balanced profile). Each exhibits distinct preferences for programming roles
(Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for
satisfaction.
  The dissertation contributes: (1) an empirically-validated framework linking
personality traits to role preferences and self-determination outcomes; (2) a
taxonomy of AI collaboration modalities mapped to personality profiles while
preserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small
Entities to implement personality-driven role optimization within established
standards.
  Keywords: artificial intelligence, human-computer interaction, behavioral
software engineering, self-determination theory, personality psychology,
phenomenology, intrinsic motivation, pair programming, design science research,
ISO/IEC 29110

</details>


### [11] [SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin](https://arxiv.org/abs/2511.00450)
*Vahid Etemadi,Gregorio Robles*

Main category: cs.SE

TL;DR: SmartDoc是一个IntelliJ IDEA插件，使用AI代理生成上下文感知的方法注释，通过分析目标方法及其嵌套方法调用的完整上下文来提升代码注释质量。


<details>
  <summary>Details</summary>
Motivation: 软件维护阶段需要程序理解，但阅读完整方法语句具有挑战性。精确且最新的注释对于代码理解至关重要，因此需要自动化工具来生成上下文感知的方法注释。

Method: 作为AI代理插件，使用目标方法内容及其所有嵌套方法调用生成注释。首先生成调用图，通过深度优先搜索遍历提供完整上下文来丰富LLM提示。

Result: 开发了适用于Java代码库的IntelliJ IDEA插件，支持并发处理多个方法的注释更新，并共享内存以避免冗余调用。在BERTScore指标上获得了0.80-0.90的准确率。

Conclusion: SmartDoc插件能够有效生成准确的方法注释，通过利用完整上下文信息显著提升了注释生成的质量和准确性。

Abstract: Context: The software maintenance phase involves many activities such as code
refactoring, bug fixing, code review or testing. Program comprehension is key
to all these activities, as it demands developers to grasp the knowledge (e.g.,
implementation details) required to modify the codebase. Methods as main
building blocks in a program can offer developers this knowledge source for
code comprehension. However, reading entire method statements can be
challenging, which necessitates precise and up-to-date comments. Objective: We
propose a solution as an IntelliJ IDEA plugin, named SmartDoc, that assists
developers in generating context-aware method comments. Method: This plugin
acts as an Artificial Intelligence (AI) agent that has its own memory and is
augmented by target methods' context. When a request is initiated by the
end-user, the method content and all its nested method calls are used in the
comment generation. At the beginning, these nested methods are visited and a
call graph is generated. This graph is then traversed using depth-first search
(DFS), enabling the provision of full-context to enrich Large Language Model
(LLM) prompts. Result: The product is a software, as a plugin, developed for
Java codebase and installable on IntelliJ IDEA. This plugin can serve
concurrently for methods whose comments are being updated , and it shares
memory across all flows to avoid redundant calls. o measure the accuracy of
this solution, a dedicated test case is run to record SmartDoc generated
comments and their corresponding ground truth. For each collected result-set,
three metrics are computed, BERTScore, BLEU and ROUGE-1. These metrics will
determine how accurate the generated comments are in comparison to the ground
truth. Result: The obtained accuracy, in terms of the precision, recall and F1,
is promising, and lies in the range of 0.80 to 0.90 for BERTScore.

</details>


### [12] [A Big Step Forward? A User-Centric Examination of iOS App Privacy Report and Enhancements](https://arxiv.org/abs/2511.00467)
*Liu Wang,Dong Wang,Shidong Pan,Zheng Jiang,Haoyu Wang,Yi Wang*

Main category: cs.SE

TL;DR: 该研究评估了iOS 15.2引入的App隐私报告功能的实际效果，发现其因缺乏重要细节而实际影响有限，并提出基于LLM的增强方案来解决用户对数据访问目的和域名描述的困惑。


<details>
  <summary>Details</summary>
Motivation: 苹果推出的App隐私报告功能被宣传为用户隐私的重大进步，但其对用户隐私和控制的真实影响尚未得到检验。研究旨在评估该功能的实际效益和局限性。

Method: 采用端到端研究方法，包括系统评估App隐私报告的现实效益和限制、LLM驱动的多技术合成增强方案，以及从系统和用户角度进行全面评估。通过结构化焦点小组研究（12名日常iOS用户）探索用户体验、理解和感知。

Result: 研究发现App隐私报告的实际影响有限，主要因为缺少重要细节。识别出用户的两个主要关切点：数据访问目的的清晰度和域名描述。提出的增强方案（目的推断框架和域名澄清管道）被证明对移动应用用户有效且有益。

Conclusion: 这项工作提供了有助于增强用户隐私透明度的实用见解，并讨论了未来研究的方向。App隐私报告虽然是一个进步，但需要进一步改进才能真正提升用户隐私控制。

Abstract: The prevalent engagement with mobile apps underscores the importance of
understanding their data practices. Transparency plays a crucial role in this
context, ensuring users to be informed and give consent before any data access
occurs. Apple introduced a new feature since iOS 15.2, App Privacy Report, to
inform users about detailed insights into apps' data access and sharing. This
feature continues Apple's trend of privacy-focused innovations (following
Privacy Nutrition Labels), and has been marketed as a big step forward in user
privacy. However, its real-world impacts on user privacy and control remain
unexamined. We thus proposed an end-to-end study involving systematic
assessment of the App Privacy Report's real-world benefits and limitations,
LLM-enabled and multi-technique synthesized enhancements, and comprehensive
evaluation from both system and user perspectives. Through a structured focus
group study with twelve everyday iOS users, we explored their experiences,
understanding, and perceptions of the feature, suggesting its limited practical
impact resulting from missing important details. We identified two primary user
concerns: the clarity of data access purpose and domain description. In
response, we proposed enhancements including a purpose inference framework and
domain clarification pipeline. We demonstrated the effectiveness and benefits
of such enhancements for mobile app users. This work provides practical
insights that could help enhance user privacy transparency and discusses areas
for future research.

</details>


### [13] [Issue-Oriented Agent-Based Framework for Automated Review Comment Generation](https://arxiv.org/abs/2511.00517)
*Shuochuan Li,Dong Wang,Patanamon Thongtanunam,Zan Wang,Jiuqiao Yu,Junjie Chen*

Main category: cs.SE

TL;DR: RevAgent是一个基于代理的问题导向代码审查框架，通过分解为生成、判别和训练三个阶段，显著提升了代码审查评论的质量和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有代码审查技术依赖单一模型处理各种问题，难以应对代码变更的多样性，特别是在复杂场景（如bug修复）中产生非信息性评论。

Method: 采用代理框架，包含五个类别特定的评论代理从不同问题角度分析代码变更，批评代理选择最佳问题-评论对，所有代理在特定类别数据上微调。

Result: RevAgent在BLEU、ROUGE-L、METEOR和SBERT指标上分别提升12.90%、10.87%、6.32%和8.57%，在问题类别识别上表现更佳，人类评估验证其实用性。

Conclusion: RevAgent通过问题导向的代理框架有效解决了现有方法的局限性，在性能和效率之间取得了良好平衡，为自动化代码审查提供了实用解决方案。

Abstract: Code review (CR) is a crucial practice for ensuring software quality. Various
automated review comment generation techniques have been proposed to streamline
the labor-intensive process. However, existing approaches heavily rely on a
single model to identify various issues within the code, limiting the model's
ability to handle the diverse, issue-specific nature of code changes and
leading to non-informative comments, especially in complex scenarios such as
bug fixes. To address these limitations, we propose RevAgent, a novel
agent-based issue-oriented framework, decomposes the task into three stages:
(1) Generation Stage, where five category-specific commentator agents analyze
code changes from distinct issue perspectives and generate candidate comments;
(2) Discrimination Stage, where a critic agent selects the most appropriate
issue-comment pair; and (3) Training Stage, where all agents are fine-tuned on
curated, category-specific data to enhance task specialization. Evaluation
results show that RevAgent significantly outperforms state-of-the-art PLM- and
LLM-based baselines, with improvements of 12.90\%, 10.87\%, 6.32\%, and 8.57\%
on BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively
higher accuracy in issue-category identification, particularly for challenging
scenarios. Human evaluations further validate the practicality of RevAgent in
generating accurate, readable, and context-aware review comments. Moreover,
RevAgent delivers a favorable trade-off between performance and efficiency.

</details>


### [14] [HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models](https://arxiv.org/abs/2511.00527)
*Robab Aghazadeh-Chakherlou,Qing Guo,Siddartha Khastgir,Peter Popov,Xiaoge Zhang,Xingyu Zhao*

Main category: cs.SE

TL;DR: HIP-LLM是一个基于层次不精确概率框架的LLM可靠性评估方法，通过定义LLM在特定操作配置文件下的无故障运行概率，提供比现有基准测试更准确的可靠性表征。


<details>
  <summary>Details</summary>
Motivation: 现有基于基准测试的评估方法主要提供模型在数据集上的准确性描述统计，对LLM在实际操作条件下的概率行为提供有限洞察，需要更严谨的可靠性评估方法。

Method: 基于软件可靠性工程基础，HIP-LLM定义LLM可靠性为在给定操作配置文件下未来特定数量任务的无故障运行概率，采用层次结构表示跨（子）域的依赖关系，嵌入不精确先验捕捉认知不确定性，并整合操作配置文件反映使用环境。

Result: 在多个基准数据集上的实验表明，HIP-LLM比现有基准测试和最先进方法提供了更准确和标准化的可靠性表征。

Conclusion: HIP-LLM框架为LLM可靠性评估提供了更严谨的方法，能够量化跨先验和数据的可靠性包络，并提供了公开可访问的代码库。

Abstract: Large Language Models (LLMs) are increasingly deployed across diverse
domains, raising the need for rigorous reliability assessment methods. Existing
benchmark-based evaluations primarily offer descriptive statistics of model
accuracy over datasets, providing limited insight into the probabilistic
behavior of LLMs under real operational conditions. This paper introduces
HIP-LLM, a Hierarchical Imprecise Probability framework for modeling and
inferring LLM reliability. Building upon the foundations of software
reliability engineering, HIP-LLM defines LLM reliability as the probability of
failure-free operation over a specified number of future tasks under a given
Operational Profile (OP). HIP-LLM represents dependencies across (sub-)domains
hierarchically, enabling multi-level inference from subdomain to system-level
reliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty
and incorporates OPs to reflect usage contexts. It derives posterior
reliability envelopes that quantify uncertainty across priors and data.
Experiments on multiple benchmark datasets demonstrate that HIP-LLM offers a
more accurate and standardized reliability characterization than existing
benchmark and state-of-the-art approaches. A publicly accessible repository of
HIP-LLM is provided.

</details>


### [15] [Employee Performance when Implementing Agile Practices in an IT Workforce](https://arxiv.org/abs/2511.00528)
*Muhammad Hamid Raza Mookadam,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 该研究探讨了南非IT工作环境中敏捷实践对员工绩效的影响，发现敏捷实践显著影响员工绩效，但也面临采用、团队参与等挑战。


<details>
  <summary>Details</summary>
Motivation: 非洲背景下缺乏关于敏捷实践对员工绩效影响的全面研究，本研究旨在填补这一空白。

Method: 采用解释主义单方法定性研究，通过17个半结构化访谈收集敏捷从业者的数据。

Result: 敏捷实践显著影响员工绩效，涉及规划、沟通、员工发展等方面，但也存在采用障碍、团队参与度等挑战。

Conclusion: 如果能够解决敏捷挑战并提供额外支持，员工绩效可以显著提高。

Abstract: Adoption of agile practices has increased in IT workforces. However, there is
a lack of comprehensive studies in the African context on employee performance
when implementing agile practices. This study addresses this gap by exploring
employee performance in agile environments for IT workforces in South Africa.
An interpretivist mono-method qualitative approach was used, with the use of
interviews as a research strategy. Seventeen semi-structured interviews were
conducted with agile practitioners from various roles. Our results indicated
that agile practices influence employee performance significantly, with
participants reporting on aspects which included planning, communication,
employee development and well-being, collaboration, team culture and progress.
Additionally, our results reported obstacles when using agile practices that
included adoption, team engagement, leadership and instilling an agile mindset.
Agile practices influence employee performance in IT workforces by fostering
improved team dynamics, enhanced collaboration, improved efficiencies, risk
management, planning, continuous improvement, learning, personal development
and well-being. Conclusively, our findings suggest that if agile challenges are
addressed and additional support is provided, employee performance can be
significantly improved.

</details>


### [16] [GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance Detection in Android](https://arxiv.org/abs/2511.00619)
*Huaijin Ran,Haoyi Zhang,Xunzhu Tang*

Main category: cs.SE

TL;DR: 提出了GDPR-Bench-Android基准，用于评估Android应用中GDPR合规性检测的自动化方法，包含1951个手动标注的违规实例，并比较了11种方法在不同任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 自动化检测源代码中的GDPR违规是一个关键但未被充分探索的挑战，需要建立全面的评估基准。

Method: 创建了GDPR-Bench-Android基准，包含1951个手动标注的违规实例；提出了Formal-AST形式化方法作为确定性基线；定义了多粒度违规定位和片段级多标签分类两个任务；评估了11种方法包括8个LLM、Formal-AST、RAG和ReAct方法。

Result: 不同范式在不同任务上表现各异：Task 1中ReAct代理在文件级Accuracy@1最高(17.38%)，Qwen2.5-72B在行级最高(61.60%)；Task 2中Claude-Sonnet-4.5的Macro-F1最佳(5.75%)，RAG方法的Macro-Precision最高(7.10%)。

Conclusion: 没有单一范式在所有任务上都表现优异，不同自动化方法在不同任务上各有优势，该基准有助于诊断各种方法的能力。

Abstract: Automating the detection of EU General Data Protection Regulation (GDPR)
violations in source code is a critical but underexplored challenge. We
introduce \textbf{GDPR-Bench-Android}, the first comprehensive benchmark for
evaluating diverse automated methods for GDPR compliance detection in Android
applications. It contains \textbf{1951} manually annotated violation instances
from \textbf{15} open-source repositories, covering 23 GDPR articles at file-,
module-, and line-level granularities. To enable a multi-paradigm evaluation,
we contribute \textbf{Formal-AST}, a novel, source-code-native formal method
that serves as a deterministic baseline. We define two tasks: (1)
\emph{multi-granularity violation localization}, evaluated via
Accuracy@\textit{k}; and (2) \emph{snippet-level multi-label classification},
assessed by macro-F1 and other classification metrics. We benchmark 11 methods,
including eight state-of-the-art LLMs, our Formal-AST analyzer, a
retrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings
reveal that no single paradigm excels across all tasks. For Task 1, the ReAct
agent achieves the highest file-level Accuracy@1 (17.38%), while the
Qwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the
Formal-AST method's 1.86%. For the difficult multi-label Task 2, the
Claude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method
yields the highest Macro-Precision (7.10%). These results highlight the
task-dependent strengths of different automated approaches and underscore the
value of our benchmark in diagnosing their capabilities. All resources are
available at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.

</details>


### [17] [Can Large Language Models Detect Real-World Android Software Compliance Violations?](https://arxiv.org/abs/2511.00624)
*Haoyi Zhang,Huaijin Ran,Xunzhu Tang*

Main category: cs.SE

TL;DR: 提出了CompliBench评估框架，用于评估大语言模型在检测Android应用合规性违规方面的能力，涵盖LGPD、PDPA和PIPEDA等法规。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在跨不同法律框架检测Android应用合规性违规方面存在困难，需要专门的评估框架来提升其性能。

Method: 定义了两个任务：任务1评估文件、模块和行级别的检索与定位能力；任务2评估代码片段的多标签判断能力。引入了稳定性感知复合指标（SGS、RCS、CRGS、OCS）进行综合评估。

Result: 在六个模型（包括GPT-4O和Claude-3.5）上的实验显示，Claude-3.5-sonnet-20241022获得最高OCS分数（0.3295），Gemini-2.5-pro最低（0.0538）。

Conclusion: CompliBench框架能够提升大语言模型在合规性检测任务中的表现，为未来符合数据保护标准的工具开发奠定了基础。

Abstract: The rapid development of Large Language Models (LLMs) has transformed
software engineering, showing promise in tasks like code generation, bug
detection, and compliance checking. However, current models struggle to detect
compliance violations in Android applications across diverse legal frameworks.
We propose \emph{CompliBench}, a novel evaluation framework for assessing LLMs'
ability to detect compliance violations under regulations like LGPD, PDPA, and
PIPEDA. The framework defines two tasks: Task 1 evaluates \emph{retrieval and
localization} at file, module, and line granularities, and Task 2 assesses
\emph{multi-label judgment} for code snippets. These tasks mirror the audit
process, where auditors locate problematic code and determine implicated
provisions. Traditional metrics fail to capture important aspects like
cross-granularity stability and jurisdictional consistency. Thus, we introduce
stability-aware composites (SGS, RCS, CRGS, and OCS) for a more comprehensive
assessment. Experiments with six models, including GPT-4O and Claude-3.5, show
\emph{CompliBench} improves compliance detection, with
Claude-3.5-sonnet-20241022 achieving the highest OCS score (0.3295), and
Gemini-2.5-pro the lowest (0.0538). This work demonstrates \emph{CompliBench}'s
potential for improving LLM performance in compliance tasks and provides a
foundation for future tools aligned with data protection standards. Our project
is available at https://github.com/Haoyi-Zhang/CompliBench.

</details>


### [18] [Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare](https://arxiv.org/abs/2511.00658)
*Guilherme H. Travassos,Sabrina Rocha,Rodrigo Feitosa,Felipe Assis,Patricia Goncalves,Andre Gheventer,Larissa Galeno,Arthur Sasse,Julio Cesar Guimaraes,Carlos Brito,Joao Pedro Wieland*

Main category: cs.SE

TL;DR: 本文分享了在临床试验软件系统开发中使用生成式AI的经验报告，记录了开发团队在项目管理、需求规范、设计、开发和质量保证等活动中应用生成式AI的学习过程。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在软件工程中的应用仍处于早期阶段，但作者希望通过实际项目经验来探索这些技术如何提升软件开发的生产力和质量。

Method: 通过在临床试验软件系统开发项目中实际应用生成式AI技术，涵盖项目管理、需求规范、设计、开发和质量保证等完整开发流程。

Result: 虽然尚未获得决定性的技术证据来显著改进开发过程，但获得了有价值的见解和建议。

Conclusion: 这项经验为寻求通过生成式AI创新开发实践以实现软件质量的组织提供了宝贵的参考价值。

Abstract: The advances and availability of technologies involving Generative Artificial
Intelligence (AI) are evolving clearly and explicitly, driving immediate
changes in various work activities. Software Engineering (SE) is no exception
and stands to benefit from these new technologies, enhancing productivity and
quality in its software development processes. However, although the use of
Generative AI in SE practices is still in its early stages, considering the
lack of conclusive results from ongoing research and the limited technological
maturity, we have chosen to incorporate these technologies in the development
of a web-based software system to be used in clinical trials by a thoracic
diseases research group at our university. For this reason, we decided to share
this experience report documenting our development team's learning journey in
using Generative AI during the software development process. Project
management, requirements specification, design, development, and quality
assurance activities form the scope of observation. Although we do not yet have
definitive technological evidence to evolve our development process
significantly, the results obtained and the suggestions shared here represent
valuable insights for software organizations seeking to innovate their
development practices to achieve software quality with generative AI.

</details>


### [19] [Repairing Responsive Layout Failures Using Retrieval Augmented Generation](https://arxiv.org/abs/2511.00678)
*Tasmia Zerin,Moumita Asad,B. M. Mainul Hossain,Kazi Sakib*

Main category: cs.SE

TL;DR: ReDeFix是一种基于检索增强生成(RAG)的自动化方法，利用Stack Overflow知识指导LLM修复响应式布局故障(RLFs)，准确率达88%


<details>
  <summary>Details</summary>
Motivation: 响应式网站在特定屏幕尺寸下经常出现布局扭曲问题(RLFs)，手动修复需要繁琐的试错调整HTML元素和CSS属性

Method: 结合领域特定知识，利用RAG框架从Stack Overflow讨论中检索相关知识，增强RLF特定上下文，创建提示发送给LLM生成CSS补丁

Result: 评估显示该方法修复RLFs的准确率达到88%，软件工程师研究表明生成的修复能产生视觉正确的布局并保持美观性

Conclusion: ReDeFix通过结合LLM和Stack Overflow知识，有效自动化了响应式布局故障的修复过程

Abstract: Responsive websites frequently experience distorted layouts at specific
screen sizes, called Responsive Layout Failures (RLFs). Manually repairing
these RLFs involves tedious trial-and-error adjustments of HTML elements and
CSS properties. In this study, an automated repair approach, leveraging LLM
combined with domain-specific knowledge is proposed. The approach is named
ReDeFix, a Retrieval-Augmented Generation (RAG)-based solution that utilizes
Stack Overflow (SO) discussions to guide LLM on CSS repairs. By augmenting
relevant SO knowledge with RLF-specific contexts, ReDeFix creates a prompt that
is sent to the LLM to generate CSS patches. Evaluation demonstrates that our
approach achieves an 88\% accuracy in repairing RLFs. Furthermore, a study from
software engineers reveals that generated repairs produce visually correct
layouts while maintaining aesthetics.

</details>


### [20] [An Empirical Investigation of the Experiences of Dyslexic Software Engineers](https://arxiv.org/abs/2511.00706)
*Marcos Vinicius Cruz,Pragya Verma,Grischa Liebel*

Main category: cs.SE

TL;DR: 本研究通过定性方法探讨了阅读障碍软件工程师的经验，发现他们在编程学习阶段面临挑战，但掌握后能在SE任务中表现出色，并具有视觉思维和创造力等优势。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对阅读障碍软件工程师经验的研究，特别是将他们的优势与困难联系起来。阅读障碍可能影响SE核心任务如编程，但相关优势可能在编程和设计领域特别有价值。

Method: 采用社会技术扎根理论方法，基于10次访谈、3篇博客文章和153个Reddit帖子的数据进行分析。

Result: 阅读障碍软件工程师在编程学习阶段特别困难，但掌握后能在SE任务中成功并表现出色；代码补全和linter等工具能有效缓解困难；他们在视觉思维和创造力方面具有优势。

Conclusion: 研究结果对SE实践有启示，并推动未来研究方向，如调查什么使代码对阅读障碍者更易/更难理解。

Abstract: Dyslexia is a common learning disorder that primarily impairs an individual's
reading and writing abilities. In adults, dyslexia can affect both professional
and personal lives, often leading to mental challenges and difficulties
acquiring and keeping work. In Software Engineering (SE), reading and writing
difficulties appear to pose substantial challenges for core tasks such as
programming. However, initial studies indicate that these challenges may not
significantly affect their performance compared to non-dyslexic colleagues.
Conversely, strengths associated with dyslexia could be particularly valuable
in areas like programming and design. However, there is currently no work that
explores the experiences of dyslexic software engineers, and puts their
strengths into relation with their difficulties. To address this, we present a
qualitative study of the experiences of dyslexic individuals in SE. We followed
the basic stage of the Socio-Technical Grounded Theory method and base our
findings on data collected through 10 interviews with dyslexic software
engineers, 3 blog posts and 153 posts on the social media platform Reddit. We
find that dyslexic software engineers especially struggle at the programming
learning stage, but can succeed and indeed excel at many SE tasks once they
master this step. Common SE-specific support tools, such as code completion and
linters are especially useful to these individuals and mitigate many of the
experienced difficulties. Finally, dyslexic software engineers exhibit
strengths in areas such as visual thinking and creativity. Our findings have
implications to SE practice and motivate several areas of future research in
SE, such as investigating what makes code less/more understandable to dyslexic
individuals.

</details>


### [21] [A Systematic Literature Review of Code Hallucinations in LLMs: Characterization, Mitigation Methods, Challenges, and Future Directions for Reliable AI](https://arxiv.org/abs/2511.00776)
*Cuiyun Gao,Guodong Fan,Chun Yong Chong,Shizhan Chen,Chao Liu,David Lo,Zibin Zheng,Qing Liao*

Main category: cs.SE

TL;DR: 本文系统综述了代码导向大语言模型中的幻觉现象，从定义、原因、缓解策略到评估基准进行全面分析，重点关注代码智能任务中的特殊挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件工程任务中的广泛应用，理解和缓解代码生成中的幻觉问题变得至关重要，特别是在高风险代码智能任务中。

Method: 通过综述60篇论文，从四个关键角度系统分析：定义代码幻觉及其原因；总结通用幻觉缓解策略；分析代码特定挑战和检测方法；评估现有基准并提出需求。

Result: 识别了代码幻觉的主要成因（数据噪声、暴露偏差、语义基础不足），总结了缓解策略（知识增强生成、约束解码、后编辑），并强调了代码特定挑战（语法敏感性、严格类型系统、外部库依赖）。

Conclusion: 需要开发专门的幻觉导向评估基准，结合静态指标和动态检查（编译和执行正确性），以更好地检测和缓解代码智能任务中的模型幻觉问题。

Abstract: Model hallucination is one of the most critical challenges faced by Large
Language Models (LLMs), especially in high-stakes code intelligence tasks. As
LLMs become increasingly integrated into software engineering tasks,
understanding and mitigating hallucination in code becomes essential. In this
survey, we provide a systematic review of hallucination phenomena in
code-oriented LLMs from four key perspectives. First, we begin by surveying 60
papers to define hallucination in the context of code and summarize its primary
causes, such as data noise, exposure bias, and insufficient semantic grounding,
while also tracing recent trends in literature across natural language
processing (NLP) and software engineering communities. Second, we review model
hallucination surveys in a broader span and summarize representative
hallucination mitigation strategies, such as knowledge-enhanced generation,
constrained decoding, and post-editing. Third, we review approaches targeted
for code intelligence and highlight code-specific challenges that aggravate
hallucination, including syntax sensitivity, strict type systems, and
dependence on external libraries. Meanwhile, we analyze how emerging code
intelligence tasks, e.g., program analysis, symbolic execution, and unit
testing, are utilized to detect and mitigate hallucinations. Fourth, we
summarize current evaluation benchmarks, ranging from static metrics to dynamic
checks, e.g., compilation and execution correctness, and emphasize the need for
hallucination-oriented benchmarks.

</details>


### [22] [Can Language Models Go Beyond Coding? Assessing the Capability of Language Models to Build Real-World Systems](https://arxiv.org/abs/2511.00780)
*Chenyu Zhao,Shenglin Zhang,Zeshun Huang,Weilin Jin,Yongqian Sun,Dan Pei,Chaoyun Zhang,Qingwei Lin,Chetan Bansal,Saravan Rajmohan,Minghua Ma*

Main category: cs.SE

TL;DR: Build-bench是一个端到端的基准测试，用于评估大语言模型在跨指令集架构迁移中修复软件构建失败的能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估LLMs在跨ISA迁移中修复软件构建失败的基准测试，而跨ISA迁移需要处理复杂依赖、异构工具链和长构建日志等挑战。

Method: 收集268个真实世界失败软件包，集成结构提取、文件内容提取、内容修改和构建验证等辅助工具，采用迭代循环修复过程。

Result: 六个代表性LLMs的最高构建成功率为63%，不同模型的工具使用模式差异显著。

Conclusion: Build-bench建立了首个架构感知的基准测试，用于研究基于LLM的软件构建和修复。

Abstract: Large language models (LLMs) have shown growing potential in software
engineering, yet few benchmarks evaluate their ability to repair software
during migration across instruction set architectures (ISAs). Cross-ISA
migration, such as between x86_64 and aarch64, requires handling complex
dependencies, heterogeneous toolchains, and long build logs while ensuring
executable verification. To address this challenge, we present Build-bench, an
end-to-end benchmark that systematically evaluates the capability of LLMs to
repair build failures in cross-ISA settings. Build-bench collects 268
real-world failed packages and integrates auxiliary tools including Structure
Extraction, File Content Extraction, Content Modification, and Build
Verification to support autonomous, tool-augmented reasoning. The repair
process operates in an iterative loop where, upon failure, the model receives
updated build logs and previous repair outcomes to refine subsequent attempts.
Through a comparative evaluation of six representative LLMs, Build-bench
reveals that current models achieve a maximum build success rate of 63% and
tool usage patterns differ significantly across models. By coupling real build
environments with verifiable outcomes, Build-bench establishes the first
architecture-aware benchmark for studying LLM-based software build and repair.

</details>


### [23] [GrowthHacker: Automated Off-Policy Evaluation Optimization Using Code-Modifying LLM Agents](https://arxiv.org/abs/2511.00802)
*Jie JW Wu,Ayanda Patrick Herlihy,Ahmad Saleem Mirza,Ali Afoud,Fatemeh Fard*

Main category: cs.SE

TL;DR: 本文提出了GrowthHacker基准测试，使用LLM和基于LLM的智能体通过代码优化来改进离线策略评估(OPE)性能，开发了two_agent框架，在真实世界数据集上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试需要大量资源且可能对用户产生负面影响，而离线策略评估(OPE)使用日志数据评估技术，在医疗、推荐系统等高成本或高风险领域至关重要。但现有研究很少探索如何利用LLM优化OPE结果。

Method: 提出了GrowthHacker基准测试，在Open Bandit Pipeline和Scope-RL上实现基线方法，开发了two_agent框架，通过迭代优化代码、评估结果并开始新的优化循环来提升OPE性能。

Result: two_agent框架实现了100%的可靠性和106.7%的平均改进率，two_agent和CrewAI达到45%的成功率，优于AutoGen的34%。

Conclusion: 基于LLM的智能体可以作为自动化的"增长黑客"来增强OPE系统，为在生产环境中扩展数据驱动决策提供了可行性。

Abstract: With the software industry shifting toward a data-driven culture, online A/B
testing is a key tool for evaluating new technologies. However, deploying such
experiments requires substantial resources, may negatively impact users, and
involves long data collection periods. To address this, \textit{off-policy
evaluation (OPE)}, or offline A/B testing, uses logged data to assess
technologies and is fundamental in Reinforcement Learning, making it crucial in
domains where online testing is costly or risky, such as healthcare,
recommender systems, education, dialog systems, and robotics. Despite advances
in coding LLMs and agentic AI, little is known about leveraging them to
optimize OPE results. We investigate whether LLMs and LLM-based agents can
improve OPE performance via code optimization. We propose
\textit{GrowthHacker}, a benchmark with agent and baseline methods on
large-scale real-world datasets, which iteratively optimizes code, evaluates
results, and begins new optimization cycles. We collected datasets, established
protocols, implemented baselines for OPE on the Open Bandit Pipeline
(OBP)~\cite{saito2021openbanditdatasetpipeline} and
Scope-RL~\cite{kiyohara2023scope}, and developed the \textit{two_agent}
framework, which reduces system complexity while preserving optimization
effectiveness. Results show the two_agent framework achieves 100% reliability
and the highest average improvement of 106.7% among positive outcomes. Both
two_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%.
These findings demonstrate the feasibility of LLM-based agents as automated
"growth hackers" to enhance OPE systems, with implications for scaling
data-driven decision-making in production.

</details>


### [24] [CodeClash: Benchmarking Goal-Oriented Software Engineering](https://arxiv.org/abs/2511.00839)
*John Yang,Kilian Lieret,Joyce Yang,Carlos E. Jimenez,Ofir Press,Ludwig Schmidt,Diyi Yang*

Main category: cs.SE

TL;DR: CodeClash是一个新的基准测试，让语言模型在多轮锦标赛中竞争，通过迭代开发代码来实现竞争性目标，评估模型在无明确指导下的自主代码开发能力。


<details>
  <summary>Details</summary>
Motivation: 现有编码基准测试主要评估模型在具体、明确任务上的表现，但真实软件开发是围绕高层次目标进行的。需要评估语言模型是否能在无明确指导的情况下迭代开发代码以实现开放目标。

Method: 设计CodeClash基准测试，模型在多轮锦标赛中竞争：每轮分为编辑代码阶段和代码竞技场对抗阶段。模型自主决定如何改进代码库，包括写注释、分析文档、创建测试套件等。

Result: 运行1680场锦标赛（共25200轮）评估8个语言模型在6个竞技场中的表现。模型展现出多样化的开发风格，但在战略推理方面存在根本性限制，且难以维护长期代码库质量。

Conclusion: 当前语言模型在自主、目标导向的代码开发方面仍有显著局限性，顶级模型在与人类专家程序员的对抗中全部失败。开源CodeClash以推进自主代码开发研究。

Abstract: Current benchmarks for coding evaluate language models (LMs) on concrete,
well-specified tasks such as fixing specific bugs or writing targeted tests.
However, human programmers do not spend all day incessantly addressing isolated
tasks. Instead, real-world software development is grounded in the pursuit of
high-level goals, like improving user retention or reducing costs. Evaluating
whether LMs can also iteratively develop code to better accomplish open-ended
objectives without any explicit guidance remains an open challenge. To address
this, we introduce CodeClash, a benchmark where LMs compete in multi-round
tournaments to build the best codebase for achieving a competitive objective.
Each round proceeds in two phases: agents edit their code, then their codebases
compete head-to-head in a code arena that determines winners based on
objectives like score maximization, resource acquisition, or survival. Whether
it's writing notes, scrutinizing documentation, analyzing competition logs, or
creating test suites, models must decide for themselves how to improve their
codebases both absolutely and against their opponents. We run 1680 tournaments
(25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal
that while models exhibit diverse development styles, they share fundamental
limitations in strategic reasoning. Models also struggle with long-term
codebase maintenance, as repositories become progressively messy and redundant.
These limitations are stark: top models lose every round against expert human
programmers. We open-source CodeClash to advance the study of autonomous,
goal-oriented code development.

</details>


### [25] [A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Software Engineering Tasks](https://arxiv.org/abs/2511.00872)
*Zhuowen Yin,Cuifeng Gao,Chunsong Fan,Wenzhang Yang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: 对7个通用智能体框架在软件开发、漏洞检测和程序修复三个代码中心任务上的综合实证研究，从有效性、效率和开销三个维度系统评估智能体性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注特定任务或孤立方面，无法全面了解智能体在实际软件工程中的能力，需要进行系统性的实证评估。

Method: 使用标准基准测试评估7个通用智能体框架在三个代表性代码任务上的表现，从有效性（任务成功率）、效率（执行过程）和开销（token消耗）三个维度进行分析。

Result: 智能体整体表现中等；AgentOrchestra轨迹最长且修正尝试最多，OpenHands具有更强的反思推理能力；软件开发成本最高，GPTswarm最经济高效。

Conclusion: 研究揭示了不同框架的能力模式和权衡关系，为智能体在软件工程中的实际应用和未来研究提供了指导。

Abstract: Unlike traditional automation tools or static LLM-based systems, agents
combine decision-making and tool utilization to accomplish complex tasks,
showing great potential in software engineering. However, existing studies
largely focus on specific tasks or isolated aspects, providing an incomplete
picture of agents' practical capabilities. To address this, we conduct a
comprehensive empirical study evaluating seven general-purpose agent frameworks
across three representative code-centric tasks: software development,
vulnerability detection, and program repair. Each task is assessed using
standard, widely adopted benchmarks to ensure objective and comparable
evaluation. Agent performance is systematically analyzed from three
complementary perspectives: effectiveness (task success), efficiency (execution
process), and overhead (token consumption). Our findings reveal distinct
capability patterns and trade-offs among the evaluated frameworks. In terms of
effectiveness, agents achieve moderate overall performance. Regarding
efficiency, AgentOrchestra tends to exhibit the longest trajectories and the
most correction attempts due to coordination overhead, whereas OpenHands
demonstrate stronger reflective reasoning abilities. For overhead, software
development incurs the highest monetary cost, while GPTswarm remains the most
cost-efficient. Furthermore, we conduct an in-depth cross-analysis of the
relationship between effectiveness and efficiency, exploring the underlying
reasons behind their interplay. These findings guide both practical adoption
and future research toward more efficient software engineering agents.

</details>


### [26] [Sustainability of Machine Learning-Enabled Systems: The Machine Learning Practitioner's Perspective](https://arxiv.org/abs/2511.00901)
*Vincenzo De Martino,Stefano Lambiase,Fabiano Pecorelli,Willem-Jan van den Heuvel,Filomena Ferrucci,Fabio Palomba*

Main category: cs.SE

TL;DR: 该研究通过访谈和问卷调查，从实践者角度探讨了机器学习系统中可持续性的认知、实践和挑战，发现可持续性意识与系统实施之间存在显著脱节。


<details>
  <summary>Details</summary>
Motivation: 软件可持续性是机器学习系统的重要非功能性需求，但现有研究主要关注环境可持续性，缺乏对可持续性多维度及实践挑战的实证研究。

Method: 采用混合方法：首先对8名经验丰富的机器学习工程师进行定性访谈分析，然后对203名机器学习从业者进行大规模定量调查。

Result: 研究发现可持续性意识与系统实施存在显著脱节，需要更结构化的指南、测量框架和监管支持。

Conclusion: 机器学习系统的可持续性实施需要更系统的工程实践、测量工具和政策支持，以弥合认知与实践之间的差距。

Abstract: Software sustainability is a key multifaceted non-functional requirement that
encompasses environmental, social, and economic concerns, yet its integration
into the development of Machine Learning (ML)-enabled systems remains an open
challenge. While previous research has explored high-level sustainability
principles and policy recommendations, limited empirical evidence exists on how
sustainability is practically managed in ML workflows. Existing studies
predominantly focus on environmental sustainability, e.g., carbon footprint
reduction, while missing the broader spectrum of sustainability dimensions and
the challenges practitioners face in real-world settings. To address this gap,
we conduct an empirical study to characterize sustainability in ML-enabled
systems from a practitioner's perspective. We investigate (1) how ML engineers
perceive and describe sustainability, (2) the software engineering practices
they adopt to support it, and (3) the key challenges hindering its adoption. We
first perform a qualitative analysis based on interviews with eight experienced
ML engineers, followed by a large-scale quantitative survey with 203 ML
practitioners. Our key findings reveal a significant disconnection between
sustainability awareness and its systematic implementation, highlighting the
need for more structured guidelines, measurement frameworks, and regulatory
support.

</details>


### [27] [Empirical Derivations from an Evolving Test Suite](https://arxiv.org/abs/2511.00915)
*Jukka Ruohonen,Abhishek Tiwari*

Main category: cs.SE

TL;DR: 对NetBSD操作系统自动化测试套件从2010年代初到2025年的纵向实证分析，显示测试套件持续增长至超过1万个测试用例，失败情况总体稳定但存在波动期，代码变更和内核修改对失败的影响较小。


<details>
  <summary>Details</summary>
Motivation: 通过对大型且不断演化的软件测试套件进行长期观察，为从大规模测试套件中得出结论提供实证基础。

Method: 采用纵向实证分析方法，观察NetBSD操作系统自动化测试套件从2010年代初到2025年的运行数据。

Result: 测试套件持续增长至超过1万个测试用例；失败测试用例总体稳定但存在波动期；代码变更和内核修改对失败的影响较小且不一致。

Conclusion: 虽然只是探索性分析，但这些实证观察为从大规模演化软件测试套件中得出结论提供了有价值的见解。

Abstract: The paper presents a longitudinal empirical analysis of the automated,
continuous, and virtualization-based software test suite of the NetBSD
operating system. The longitudinal period observed spans from the initial roll
out of the test suite in the early 2010s to late 2025. According to the
results, the test suite has grown continuously, currently covering over ten
thousand individual test cases. Failed test cases exhibit overall stability,
although there have been shorter periods marked with more frequent failures. A
similar observation applies to build failures, failures of the test suite to
complete, and installation failures, all of which are also captured by the
NetBSD's testing framework. Finally, code churn and kernel modifications do not
provide longitudinally consistent statistical explanations for the failures.
Although some periods exhibit larger effects, including particularly with
respect to the kernel modifications, the effects are small on average. Even
though only in an exploratory manner, these empirical observations contribute
to efforts to draw conclusions from large-scale and evolving software test
suites.

</details>


### [28] [DPO-F+: Aligning Code Repair Feedback with Developers' Preferences](https://arxiv.org/abs/2511.01043)
*Zihan Fang,Yifan Zhang,Yueke Zhang,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: DPO-f+是一个新颖的框架，通过直接偏好优化和轻量级边界信号来对齐代码修复反馈与开发者需求，提升LLM在软件工程任务中的协作效果。


<details>
  <summary>Details</summary>
Motivation: 开发者在解释LLM输出时遇到困难，限制了有效的人机协作。现有工作主要优化修复代码，而忽视了使理解和迭代改进成为可能的自然语言反馈。

Method: DPO-f+框架：(1)形式化开发者配置的领域特定指标；(2)从代码修复任务自动构建成对偏好数据集；(3)使用增强轻量级边界信号的DPO进行微调；(4)提供自动反馈评估协议。

Result: 在初学者编程任务中，DPO-f+将top-1通过率比基线提高5.71个百分点，比标准DPO提高3.30个百分点。在SWE-bench Lite基准测试中，问题解决率比DPO提高1.67个百分点，比基线提高4.67个百分点。

Conclusion: 通过更紧密地对齐反馈与开发者需求，DPO-f+将LLM辅助修复从一次性输出转变为协作理解工作流程，为增强代码理解和促进更有效的软件工程中人机协作提供了实用方法。

Abstract: Large Language Models (LLMs) are increasingly applied to software engineering
tasks, especially code repair. However, developers often struggle to interpret
model outputs, limiting effective human-AI teaming. Prior work largely
optimizes repaired code while under-addressing the natural-language feedback
that enables comprehension and iterative improvement. We present DPO-f+, a
novel framework that aligns code-repair feedback with developer needs and
profiles. It (1) formalizes developer-profiled, domain-specific metrics for
feedback alignment; (2) automatically constructs pairwise preference datasets
from code-repair tasks; (3) fine-tunes using Direct Preference Optimization
(DPO) augmented with a lightweight margin signal; and (4) provides an automated
feedback evaluation protocol. Empirically, DPO-f+ outperforms both the baseline
and standard DPO on generated-code accuracy and overall feedback alignment. On
novice programming tasks, DPO-f+ raises the top-1 pass rate by 5.71 percentage
points (pp) over the baseline and by 3.30 pp over DPO. On the more challenging
SWE-bench Lite benchmark, it increases the issue-resolution rate by 1.67 pp
over DPO and by 4.67 pp over the baseline. It also achieves the largest
improvement in feedback alignment, outperforming DPO and the baseline. By
aligning feedback more closely with developer needs, DPO-f+ turns LLM-assisted
repair from one-shot outputs into a collaborative sensemaking workflow,
providing a practical approach to enhancing code comprehension and fostering
more effective human-AI teaming in software engineering.

</details>


### [29] [HAFixAgent: History-Aware Automated Program Repair Agent](https://arxiv.org/abs/2511.01047)
*Yu Shi,Hao Li,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: HAFixAgent是一个历史感知的自动程序修复代理系统，通过引入版本控制历史信息来提升多文件多补丁复杂bug的修复效果，相比现有方法显著提升了修复成功率。


<details>
  <summary>Details</summary>
Motivation: 现有自动程序修复系统主要依赖本地快照上下文，忽略了仓库历史信息。研究表明仓库历史有助于修复单行bug，但能否提升基于代理的APR系统处理复杂多补丁bug的能力尚不明确。

Method: 提出HAFixAgent系统，在修复循环中注入基于blame的仓库启发式信息。通过分析Defects4J中854个真实bug，发现bug相关历史信息广泛可用且高度集中。

Result: HAFixAgent显著优于基于代理的基线方法（提升212.3%）和多补丁基线方法（提升29.9%）。历史信息未显著增加代理步骤，保持令牌成本可比，对复杂多文件多补丁bug的中位成本更低。

Conclusion: HAFixAgent提供了历史感知代理APR的实用方案：基于版本控制历史锚定代理，优先使用基于diff的历史上下文，并在需要时集成互补启发式方法。

Abstract: Automated program repair (APR) has recently shifted toward large language
models and agent-based systems, yet most systems rely on local snapshot
context, overlooking repository history. Prior work shows that repository
history helps repair single-line bugs, since the last commit touching the buggy
line is often the bug-introducing one. In this paper, we investigate whether
repository history can also improve agentic APR systems at scale, especially
for complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing
Agent that injects blame-derived repository heuristics into its repair loop. A
preliminary study of all 854 real-world bugs from Defects4J motivates our
design, showing that bug-relevant history is both widely available and highly
concentrated. Empirical comparison of HAFixAgent with two state-of-the-art
baselines shows: (1) Effectiveness: HAFixAgent significantly improves over the
agent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)
Efficiency: history does not significantly increase agent steps and keeps token
costs comparable, with notably lower median costs for complex
multi-file-multi-hunk bugs. (3) Practicality: combining different historical
heuristics repairs more bugs, offering a clear cost-benefit trade-off.
HAFixAgent offers a practical recipe for history-aware agentic APR: ground the
agent in version control history, prioritize diff-based historical context, and
integrate complementary heuristics when needed.

</details>


### [30] [HarnessLLM: Automatic Testing Harness Generation via Reinforcement Learning](https://arxiv.org/abs/2511.01104)
*Yujian Liu,Jiabao Ji,Yang Zhang,Wenbo Guo,Tommi Jaakkola,Shiyu Chang*

Main category: cs.SE

TL;DR: HarnessLLM是一个两阶段训练框架，使LLM能够编写测试工具代码，生成包含输入合成和输出验证的复杂测试用例，超越了传统的输入-输出对测试方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的测试生成方法主要产生输入-输出对来测试正确程序，但测试多样性有限且无法提供足够的调试信息。

Method: 采用两阶段训练流程：先进行监督微调（SFT），然后使用强化学习与验证奖励（RLVR）和定制化奖励设计。

Result: 实验表明HarnessLLM在错误发现和测试策略多样性方面优于基于输入-输出的测试方法，并能通过测试时扩展提升代码生成性能。

Conclusion: HarnessLLM能够生成更复杂的测试用例和灵活的验证方法，为代码测试提供了更有效的解决方案。

Abstract: Existing LLM-based automatic test generation methods mainly produce input and
expected output pairs to categorize the intended behavior of correct programs.
Although straightforward, these methods have limited diversity in generated
tests and cannot provide enough debugging information. We propose HarnessLLM, a
two-stage training pipeline that enables LLMs to write harness code for
testing. Particularly, LLMs generate code that synthesizes inputs and validates
the observed outputs, allowing complex test cases and flexible output
validation such as invariant checking. To achieve this, we train LLMs with SFT
followed by RLVR with a customized reward design. Experiments show that
HarnessLLM outperforms input-output-based testing in bug finding and testing
strategy diversity. HarnessLLM further benefits the code generation performance
through test-time scaling with our generated test cases as inference-phase
validation. Our code is available at
https://github.com/UCSB-NLP-Chang/HarnessLLM.git.

</details>


### [31] [An Empirical Study of LLM-Based Code Clone Detection](https://arxiv.org/abs/2511.01176)
*Wenqing Zhu,Norihiro Yoshida,Eunjong Choi,Yutaka Matsubara,Hiroaki Takada*

Main category: cs.SE

TL;DR: 该论文评估了大型语言模型在代码克隆检测中的跨数据集性能和响应一致性，发现LLMs在CodeNet数据集上表现优异但在BigCloneBench上性能显著下降，同时大多数模型具有超过90%的响应一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究证明了LLMs在代码克隆检测中的有效性，但两个关键问题未解决：LLMs在不同数据集上的可比性能能力，以及LLMs在代码克隆检测中的响应一致性。

Method: 构建了七个代码克隆数据集，使用Levenshtein比率从CodeNet和BigCloneBench两个代码集合中采样代码对，然后评估了五个LLM在四种现有提示下的表现。

Result: LLMs在CodeNet相关数据集上表现良好（o3-mini达到0.943 F1分数），但在BigCloneBench相关数据集上性能显著下降。大多数模型具有高响应一致性（超过90%的判断在所有五次提交中保持一致），F1分数因不一致性产生的波动很小（变化小于0.03）。

Conclusion: LLMs在代码克隆检测中具有高响应一致性，但其性能在不同数据集上存在显著差异，表明需要进一步研究如何提高LLMs在不同代码库上的泛化能力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
various software engineering tasks, such as code generation and debugging,
because of their ability to translate between programming languages and natural
languages. Existing studies have demonstrated the effectiveness of LLMs in code
clone detection. However, two crucial issues remain unaddressed: the ability of
LLMs to achieve comparable performance across different datasets and the
consistency of LLMs' responses in code clone detection. To address these
issues, we constructed seven code clone datasets and then evaluated five LLMs
in four existing prompts with these datasets. The datasets were created by
sampling code pairs using their Levenshtein ratio from two different code
collections, CodeNet and BigCloneBench. Our evaluation revealed that although
LLMs perform well in CodeNet-related datasets, with o3-mini achieving a 0.943
F1 score, their performance significantly decreased in BigCloneBench-related
datasets. Most models achieved a high response consistency, with over 90\% of
judgments remaining consistent across all five submissions. The fluctuations of
the F1 score affected by inconsistency are also tiny; their variations are less
than 0.03.

</details>


### [32] [Lares: LLM-driven Code Slice Semantic Search for Patch Presence Testing](https://arxiv.org/abs/2511.01252)
*Siyuan Li,Yaowen Zheng,Hong Li,Jingdong Guo,Chaopeng Dong,Chunpeng Yan,Weijie Wang,Yimo Ren,Limin Sun,Hongsong Zhu*

Main category: cs.SE

TL;DR: Lares是一种可扩展且准确的补丁存在性测试方法，通过代码切片语义搜索直接从补丁源代码提取特征，在目标二进制文件的伪代码中识别语义等效的代码切片。


<details>
  <summary>Details</summary>
Motivation: 现代软件生态系统中，1天漏洞由于广泛的代码重用构成重大安全风险。现有方法存在可用性和准确性限制，依赖编译过程提取特征，需要大量手动工作，且无法可靠区分补丁或编译变化引起的代码更改。

Method: Lares引入代码切片语义搜索，直接从补丁源代码提取特征，在目标二进制文件的伪代码中识别语义等效的代码切片。利用大型语言模型进行代码分析和SMT求解器进行逻辑推理，无需编译过程。

Result: 实验结果显示Lares实现了优越的精度、召回率和可用性。这是首个在优化级别、架构和编译器之间评估补丁存在性测试的工作。

Conclusion: Lares通过消除对编译过程的依赖提高了可用性，同时利用LLM和SMT求解器增强了准确性，为补丁存在性测试提供了有效的解决方案。

Abstract: In modern software ecosystems, 1-day vulnerabilities pose significant
security risks due to extensive code reuse. Identifying vulnerable functions in
target binaries alone is insufficient; it is also crucial to determine whether
these functions have been patched. Existing methods, however, suffer from
limited usability and accuracy. They often depend on the compilation process to
extract features, requiring substantial manual effort and failing for certain
software. Moreover, they cannot reliably differentiate between code changes
caused by patches or compilation variations. To overcome these limitations, we
propose Lares, a scalable and accurate method for patch presence testing. Lares
introduces Code Slice Semantic Search, which directly extracts features from
the patch source code and identifies semantically equivalent code slices in the
pseudocode of the target binary. By eliminating the need for the compilation
process, Lares improves usability, while leveraging large language models
(LLMs) for code analysis and SMT solvers for logical reasoning to enhance
accuracy. Experimental results show that Lares achieves superior precision,
recall, and usability. Furthermore, it is the first work to evaluate patch
presence testing across optimization levels, architectures, and compilers. The
datasets and source code used in this article are available at
https://github.com/Siyuan-Li201/Lares.

</details>


### [33] [Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation](https://arxiv.org/abs/2511.01316)
*Chong Wang,Chen Zhang,Jiajun Wu,Wunan Guo,Jianfeng Qu,Yewen Tian,Yang Liu*

Main category: cs.SE

TL;DR: 本研究探讨了使用大语言模型进行CI配置迁移，特别是从Travis CI到GitHub Actions的转换。研究发现迁移过程复杂，需要大量人工干预，并提出了结合指导性提示和迭代优化的增强策略，将构建成功率提升至75.5%。


<details>
  <summary>Details</summary>
Motivation: CI平台迁移是常见实践，但配置转换面临语义差异和复杂性的挑战。随着大语言模型的发展，探索其在CI配置翻译中的潜力成为研究动机。

Method: 基于811个迁移记录分析迁移工作量，评估四种LLM的翻译效果，识别了1121个问题，并测试了三种增强策略。

Result: 开发者平均需要阅读38行Travis配置并编写58行GitHub Actions配置，近半数迁移需要多次提交。LLM翻译存在逻辑不一致(38%)、平台差异(32%)、环境错误(25%)和语法错误(5%)等问题。最佳策略将构建成功率提升至75.5%。

Conclusion: LLM在CI配置翻译中具有潜力，但需要结合指导性提示和迭代优化策略来克服翻译过程中的各类问题，才能实现有效的自动化迁移。

Abstract: Continuous Integration (CI) is a cornerstone of modern collaborative software
development, and numerous CI platforms are available. Differences in
maintenance overhead, reliability, and integration depth with code-hosting
platforms make migration between CI platforms a common practice. A central step
in migration is translating CI configurations, which is challenging due to the
intrinsic complexity of CI configurations and the need to understand semantic
differences and relationships across CI platforms.
  With the advent of large language models (LLMs), recent advances in software
engineering highlight their potential for CI configuration translation. In this
paper, we present a study on LLM-based CI configuration translation, focusing
on the migration from Travis CI to GitHub Actions. First, using 811 migration
records, we quantify the effort involved and find that developers read an
average of 38 lines of Travis configuration and write 58 lines of GitHub
Actions configuration, with nearly half of the migrations requiring multiple
commits. We further analyze translations produced by each of the four LLMs and
identify 1,121 issues grouped into four categories: logic inconsistencies
(38%), platform discrepancies (32%), environment errors (25%), and syntax
errors (5%). Finally, we evaluate three enhancement strategies and show that
combining guideline-based prompting with iterative refinement achieves the best
performance, reaching a Build Success Rate of 75.5%-nearly a threefold
improvement over GPT-4o with a basic prompt.

</details>


### [34] [AI for Requirements Engineering: Industry adoption and Practitioner perspectives](https://arxiv.org/abs/2511.01324)
*Lekshmi Murali Rani,Richard Berntsson Svensson,Robert Feldt*

Main category: cs.SE

TL;DR: 对55名软件从业者的调查显示，58.2%已在需求工程中使用AI，69.1%认为其影响积极。人机协作(HAIC)占主导地位(54.4%)，而全自动化(5.4%)和被动验证(4.4-6.2%)使用较少。


<details>
  <summary>Details</summary>
Motivation: 尽管需求工程对软件工程至关重要，但关于AI在RE中应用的研究有限。需要了解当前AI在需求工程各阶段的实际应用情况和从业者态度。

Method: 通过调查55名软件从业者，分析AI在需求工程四个阶段(需求获取、分析、规约、验证)和四种决策方法(纯人工、AI验证、人机协作、全自动化)中的使用情况。

Result: 58.2%的受访者已在RE中使用AI，69.1%持积极态度。人机协作(HAIC)是最主要的使用方式(54.4%)，全自动化和被动验证使用率很低。从业者更看重AI的主动支持而非被动监督。

Conclusion: AI在需求工程中最有效的定位是作为人类专家的协作伙伴而非替代品。随着AI在RE中的采用增长，需要开发专门的HAIC框架和健全负责的AI治理机制。

Abstract: The integration of AI for Requirements Engineering (RE) presents significant
benefits but also poses real challenges.Although RE is fundamental to software
engineering, limited research has examined AI adoption in RE.We surveyed 55
software practitioners to map AI usage across four RE phases:Elicitation,
Analysis, Specification, and Validation, and four approaches for decision
making: human only decisions, AI validation, Human AI Collaboration (HAIC), and
full AI automation.Participants also shared their perceptions, challenges, and
opportunities when applying AI for RE tasks.Our data show that 58.2% of
respondents already use AI in RE, and 69.1% view its impact as positive or very
positive.HAIC dominates practice, accounting for 54.4% of all RE techniques,
while full AI automation remains minimal at 5.4%.Passive AI validation (4.4 to
6.2%) lags even further behind, indicating that practitioners value AI's active
support over passive oversight.These findings suggest that AI is most effective
when positioned as a collaborative partner rather than a replacement for human
expertise.It also highlights the need for RE specific HAIC frameworks along
with robust and responsible AI governance as AI adoption in RE grows.

</details>


### [35] [The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project](https://arxiv.org/abs/2511.01348)
*Robin Gröpler,Steffen Klepke,Jack Johns,Andreas Dreschinski,Klaus Schmid,Benedikt Dornauer,Eray Tüzün,Joost Noppen,Mohammad Reza Mousavi,Yongjian Tang,Johannes Viehmann,Selin Şirin Aslangül,Beum Seuk Lee,Adam Ziolkowski,Eric Zie*

Main category: cs.SE

TL;DR: GENIUS项目旨在解决生成式AI在整个软件开发生命周期中应用的关键挑战，包括可靠性、问责制、安全性和数据隐私问题，通过开发创新工具和制定研究议程来推动AI在软件工程中的集成。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在软件工程中展现出巨大潜力，但在整个软件开发生命周期的应用尚未充分探索，存在可靠性、问责制、安全性和数据隐私等关键不确定性，需要深入研究和协调行动。

Method: 基于GENIUS联盟的跨部门对话和经验，结合探索性文献综述，提出了四个核心要素：当前挑战的结构化概述、未来五年技术和方法进展的愿景、软件专业人员角色和技能集的预期变化、GENIUS通过实际工具和工业验证实现转型的贡献。

Result: 提出了一个前瞻性的愿景，将技术创新与业务相关性相结合，为可靠、可扩展且适合工业应用的生成式AI解决方案提供基础，旨在指导研究议程和工业战略。

Conclusion: 通过GENIUS项目的努力，可以推动生成式AI在软件工程中的全面集成，实现软件开发的转型，为软件工程团队提供可靠、可扩展的AI解决方案。

Abstract: Generative AI (GenAI) has recently emerged as a groundbreaking force in
Software Engineering, capable of generating code, suggesting fixes, and
supporting quality assurance. While its use in coding tasks shows considerable
promise, applying GenAI across the entire Software Development Life Cycle
(SDLC) has not yet been fully explored. Critical uncertainties in areas such as
reliability, accountability, security, and data privacy demand deeper
investigation and coordinated action. The GENIUS project, comprising over 30
European industrial and academic partners, aims to address these challenges by
advancing AI integration across all SDLC phases. It focuses on GenAI's
potential, the development of innovative tools, and emerging research
challenges, actively shaping the future of software engineering. This vision
paper presents a shared perspective on the future of GenAI-based software
engineering, grounded in cross-sector dialogue and experience within the GENIUS
consortium, supported by an exploratory literature review. The paper explores
four central elements: (1) a structured overview of current challenges in GenAI
adoption across the SDLC; (2) a forward-looking vision outlining key
technological and methodological advances expected over the next five years;
(3) anticipated shifts in the roles and required skill sets of software
professionals; and (4) the contribution of GENIUS in realizing this
transformation through practical tools and industrial validation. By aligning
technical innovation with business relevance, this paper aims to inform both
research agendas and industrial strategies, providing a foundation for
reliable, scalable, and industry-ready GenAI solutions for software engineering
teams.

</details>


### [36] [Characterizing Build Compromises Through Vulnerability Disclosure Analysis](https://arxiv.org/abs/2511.01395)
*Maimouna Tamah Diao,Moustapha Awwalou Diouf,Iyiola Emmanuel Olatunji,Abdoul Kader Kaboré,Gervais Mendy,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.SE

TL;DR: 本文通过分析621个CVE漏洞披露，构建了针对软件构建过程的攻击向量分类法，发现23.8%的软件供应链攻击利用构建漏洞，其中依赖混淆和构建脚本注入是最常见的攻击方式。


<details>
  <summary>Details</summary>
Motivation: 软件构建过程是软件开发中关键但脆弱的环节，面临多组件系统复杂性、编译期间入侵检测困难以及构建非确定性等独特安全挑战。安全社区缺乏对构建特定攻击向量的系统理解，阻碍了有效防御设计。

Method: 通过大规模CVE挖掘（从NVD数据库中提取621个漏洞披露），构建了经验驱动的构建过程攻击向量分类法，并按构建流水线中的注入点进行分类。通过分析168个已记录的软件供应链攻击来验证分类法。

Result: 在分析的软件供应链攻击中，40个事件专门针对构建阶段，23.8%的供应链攻击利用构建漏洞。依赖混淆和构建脚本注入是最普遍的攻击向量。

Conclusion: 构建过程安全是一个被低估但重要的安全问题，需要系统性的防御措施来应对已识别的攻击向量。

Abstract: The software build process transforms source code into deployable artifacts,
representing a critical yet vulnerable stage in software development. Build
infrastructure security poses unique challenges: the complexity of
multi-component systems (source code, dependencies, build tools), the
difficulty of detecting intrusions during compilation, and prevalent build
non-determinism that masks malicious modifications. Despite these risks, the
security community lacks a systematic understanding of build-specific attack
vectors, hindering effective defense design.
  This paper presents an empirically-derived taxonomy of attack vectors
targeting the build process, constructed through a large-scale CVE mining (of
621 vulnerability disclosures from the NVD database). We categorize attack
vectors by their injection points across the build pipeline, from source code
manipulation to compiler compromise. To validate our taxonomy, we analyzed 168
documented software supply chain attacks, identifying 40 incidents specifically
targeting build phases. Our analysis reveals that 23.8\% of supply chain
attacks exploit build vulnerabilities, with dependency confusion and build
script injection representing the most prevalent vectors.
  Dataset available at:
https://anonymous.4open.science/r/Taxonomizing-Build-Attacks-8BB0.

</details>


### [37] [VeriODD: From YAML to SMT-LIB - Automating Verification of Operational Design Domains](https://arxiv.org/abs/2511.01417)
*Bassel Rafie,Christian Schindler,Andreas Rausch*

Main category: cs.SE

TL;DR: VeriODD是一个自动化工具，可将YAML格式的ODD/COD规范转换为可验证的SMT-LIB格式，实现自动驾驶系统操作域的形式化验证。


<details>
  <summary>Details</summary>
Motivation: 当前ODD和COD规范通常用YAML编写以便利益相关者理解，但这种格式不适合基于求解器的验证。手动转换为形式化语言（如SMT-LIB）既缓慢又容易出错。

Method: 使用ANTLR编译器技术将YAML规范转换为人类可读的命题逻辑和求解器就绪的SMT-LIB格式，集成Z3等SMT求解器进行一致性检查和符合性验证。

Result: 开发了VeriODD工具，提供图形用户界面支持规范编辑、公式检查和一键验证，填补了利益相关者友好表示与形式化验证之间的差距。

Conclusion: VeriODD实现了自动驾驶操作边界的可扩展自动化保证，使ODD/COD规范的形式化验证变得可行和高效。

Abstract: Operational Design Domains (ODDs) define the conditions under which an
Automated Driving System (ADS) is allowed to operate, while Current Operational
Domains (CODs) capture the actual runtime situation. Ensuring that a COD
instance lies within the ODD is a crucial step in safety assurance. Today, ODD
and COD specifications are frequently expressed in YAML to remain accessible
for stakeholders, but such descriptions are not directly suitable for
solver-based verification. Manual translation into formal languages such as
SMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this
translation. VeriODD uses ANTLR-based compiler technology to transform
YAML-based ODD/COD specifications into both human-readable propositional logic,
for lightweight review on a simple basis, and solver-ready SMT-LIB. The tool
integrates with SMT solvers such as Z3 to provide automated consistency checks
of ODD specifications and verification of COD conformance. A graphical user
interface supports editing specifications, inspecting generated formulas, and
performing verification with a single click. VeriODD thereby closes the gap
between stakeholder-friendly ODD/COD notations and formal verification,
enabling scalable and automated assurance of operational boundaries in
autonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool
available at: https://github.com/BasselRafie/VeriODD

</details>


### [38] [LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations](https://arxiv.org/abs/2511.01423)
*Ruidi He,Yu Zhang,Meng Zhang,Andreas Rausch*

Main category: cs.SE

TL;DR: 提出了一种基于LLM的辅助流水线，用于自动生成逻辑公式和可执行谓词，以验证高精地图转换的语义正确性，减少人工工程工作量。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的框架依赖手动编写公式和领域特定函数，限制了可扩展性，需要更高效的自动化验证方法。

Method: 使用基于提示的LLM生成语法合规的规则和谓词，在计算FOL框架中联合生成逻辑公式和可执行谓词，扩展了CommonRoad场景设计器的地图验证器并支持高程。

Result: 在合成的桥梁和斜坡场景上评估原型，结果表明减少了人工工程工作量，同时保持了正确性。

Conclusion: 证明了可扩展的半自动化人机协同方法在地图转换验证中的可行性。

Abstract: High-definition map transformations are essential in autonomous driving
systems, enabling interoperability across tools. Ensuring their semantic
correctness is challenging, since existing rule-based frameworks rely on
manually written formulas and domain-specific functions, limiting scalability.
  In this paper, We present an LLM-assisted pipeline that jointly generates
logical formulas and corresponding executable predicates within a computational
FOL framework, extending the map verifier in CommonRoad scenario designer with
elevation support. The pipeline leverages prompt-based LLM generation to
produce grammar-compliant rules and predicates that integrate directly into the
existing system.
  We implemented a prototype and evaluated it on synthetic bridge and slope
scenarios. The results indicate reduced manual engineering effort while
preserving correctness, demonstrating the feasibility of a scalable,
semi-automated human-in-the-loop approach to map-transformation verification.

</details>


### [39] [From Pre-labeling to Production: Engineering Lessons from a Machine Learning Pipeline in the Public Sector](https://arxiv.org/abs/2511.01545)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 在公共部门部署机器学习系统面临准确性和可审计性的挑战，需要将ML管道视为公民基础设施，强调透明、可重现和负责任的数据治理。


<details>
  <summary>Details</summary>
Motivation: 研究公共部门机器学习系统在准确性、可审计性和运营可持续性方面的挑战，特别是在政府数字平台中的实际应用问题。

Method: 通过研究Brasil Participativo平台，分析常见工程选择（如使用LLM预标注、路由分类器、生成合成数据）的影响，强调数据治理和人工验证的重要性。

Result: 研究发现，虽然常见工程选择能加速开发，但如果没有严格的数据治理和人工验证，会引入可追溯性、可靠性和成本风险。

Conclusion: 公共部门负责任机器学习不仅是建模问题，更是制度工程问题，成功取决于构建透明、可重现和可信赖的数据基础设施的能力。

Abstract: Machine learning is increasingly being embedded into government digital
platforms, but public-sector constraints make it difficult to build ML systems
that are accurate, auditable, and operationally sustainable. In practice, teams
face not only technical issues like extreme class imbalance and data drift, but
also organizational barriers such as bureaucratic data access, lack of
versioned datasets, and incomplete governance over provenance and monitoring.
Our study of the Brasil Participativo (BP) platform shows that common
engineering choices -- like using LLMs for pre-labeling, splitting models into
routed classifiers, and generating synthetic data -- can speed development but
also introduce new traceability, reliability, and cost risks if not paired with
disciplined data governance and human validation. This means that, in the
public sector, responsible ML is not just a modeling problem but an
institutional engineering problem, and ML pipelines must be treated as civic
infrastructure. Ultimately, this study shows that the success of machine
learning in the public sector will depend less on breakthroughs in model
accuracy and more on the ability of institutions to engineer transparent,
reproducible, and accountable data infrastructures that citizens can trust.

</details>


### [40] [Towards LLM-Powered Task-Aware Retrieval of Scientific Workflows for Galaxy](https://arxiv.org/abs/2511.01757)
*Shamse Tasnim Cynthia,Banani Roy*

Main category: cs.SE

TL;DR: 提出一个任务感知的两阶段检索框架，结合密集向量搜索和基于大语言模型的重新排序，显著提升了Galaxy科学工作流管理系统中工作流的检索性能。


<details>
  <summary>Details</summary>
Motivation: Galaxy现有的基于关键词的检索系统在语义查询解释方面支持有限，当缺乏精确术语匹配时经常无法找到相关工作流。

Method: 使用最先进的嵌入模型检索候选工作流，然后使用指令调优的生成式大语言模型（GPT-4o、Mistral-7B）基于语义任务对齐进行重新排序。构建了带有语义主题注释的基准数据集，并使用LLM合成真实的任务导向查询。

Result: 该方法显著提高了top-k准确性和相关性，特别是对于长查询或未充分指定的查询。在Galaxy生态系统中集成了原型工具。

Conclusion: 这项工作通过LLM增强的工作流搜索，提升了科学工作流的可用性和可访问性，特别是对新手用户和跨学科研究人员。

Abstract: Scientific Workflow Management Systems (SWfMSs) such as Galaxy have become
essential infrastructure in bioinformatics, supporting the design, execution,
and sharing of complex multi-step analyses. Despite hosting hundreds of
reusable workflows across domains, Galaxy's current keyword-based retrieval
system offers limited support for semantic query interpretation and often fails
to surface relevant workflows when exact term matches are absent. To address
this gap, we propose a task-aware, two-stage retrieval framework that
integrates dense vector search with large language model (LLM)-based reranking.
Our system first retrieves candidate workflows using state-of-the-art embedding
models and then reranks them using instruction-tuned generative LLMs (GPT-4o,
Mistral-7B) based on semantic task alignment. To support robust evaluation, we
construct a benchmark dataset of Galaxy workflows annotated with semantic
topics via BERTopic and synthesize realistic task-oriented queries using LLMs.
We conduct a comprehensive comparison of lexical, dense, and reranking models
using standard IR metrics, presenting the first systematic evaluation of
retrieval performance in the Galaxy ecosystem. Results show that our approach
significantly improves top-k accuracy and relevance, particularly for long or
under-specified queries. We further integrate our system as a prototype tool
within Galaxy, providing a proof-of-concept for LLM-enhanced workflow search.
This work advances the usability and accessibility of scientific workflows,
especially for novice users and interdisciplinary researchers.

</details>


### [41] [Context-Guided Decompilation: A Step Towards Re-executability](https://arxiv.org/abs/2511.01763)
*Xiaohan Wang,Yuxin Hu,Kevin Leach*

Main category: cs.SE

TL;DR: ICL4Decomp是一个基于上下文学习的混合反编译框架，通过指导大语言模型生成可重新执行的反编译代码，在可重编译性方面相比现有方法提升约40%。


<details>
  <summary>Details</summary>
Motivation: 现有反编译技术难以生成可成功重编译和重执行的源代码，特别是针对优化后的二进制文件。神经网络方法生成的反编译代码通常只是语义上合理而非真正可执行，限制了实际可靠性。

Method: 提出ICL4Decomp混合反编译框架，利用上下文学习(ICL)来指导大语言模型生成可重新执行的源代码。

Result: 在多个数据集、优化级别和编译器上评估，相比最先进的反编译方法，可重执行性提升约40%，同时保持鲁棒性。

Conclusion: ICL4Decomp通过上下文学习有效提升了反编译代码的可执行性，解决了现有方法在编译器优化和语义信息丢失方面的挑战。

Abstract: Binary decompilation plays an important role in software security analysis,
reverse engineering, and malware understanding when source code is unavailable.
However, existing decompilation techniques often fail to produce source code
that can be successfully recompiled and re-executed, particularly for optimized
binaries. Recent advances in large language models (LLMs) have enabled neural
approaches to decompilation, but the generated code is typically only
semantically plausible rather than truly executable, limiting their practical
reliability. These shortcomings arise from compiler optimizations and the loss
of semantic cues in compiled code, which LLMs struggle to recover without
contextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid
decompilation framework that leverages in-context learning (ICL) to guide LLMs
toward generating re-executable source code. We evaluate our method across
multiple datasets, optimization levels, and compilers, demonstrating around
40\% improvement in re-executability over state-of-the-art decompilation
methods while maintaining robustness.

</details>


### [42] [SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring](https://arxiv.org/abs/2511.01850)
*Jiawei Jin,Yingxin Su,Xiaotong Zhu*

Main category: cs.SE

TL;DR: 提出LLM集成IDE与自动化MLOps管道的设计，将模型开发、部署和监控统一在单一环境中，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 传统IDE主要关注代码编写，缺乏对完整ML生命周期的智能支持，而现有MLOps平台与编码工作流脱节，需要弥合这一差距。

Method: 设计嵌入LLM助手的IDE系统，具备代码生成、调试建议和自动管道配置功能，后端集成数据验证、特征存储、漂移检测、重训练触发和CI/CD部署编排。

Result: 在UCI Adult和M5数据集上的实验表明，SmartMLOps Studio原型将管道配置时间减少61%，实验可复现性提高45%，漂移检测准确率提升14%。

Conclusion: 通过桥接智能代码辅助和自动化操作管道，该研究为AI工程建立了新范式，将IDE从静态编码工具转变为动态、生命周期感知的智能平台。

Abstract: The rapid expansion of artificial intelligence and machine learning (ML)
applications has intensified the demand for integrated environments that unify
model development, deployment, and monitoring. Traditional Integrated
Development Environments (IDEs) focus primarily on code authoring, lacking
intelligent support for the full ML lifecycle, while existing MLOps platforms
remain detached from the coding workflow. To address this gap, this study
proposes the design of an LLM-Integrated IDE with automated MLOps pipelines
that enables continuous model development and monitoring within a single
environment. The proposed system embeds a Large Language Model (LLM) assistant
capable of code generation, debugging recommendation, and automatic pipeline
configuration. The backend incorporates automated data validation, feature
storage, drift detection, retraining triggers, and CI/CD deployment
orchestration. This framework was implemented in a prototype named SmartMLOps
Studio and evaluated using classification and forecasting tasks on the UCI
Adult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio
reduces pipeline configuration time by 61%, improves experiment reproducibility
by 45%, and increases drift detection accuracy by 14% compared to traditional
workflows. By bridging intelligent code assistance and automated operational
pipelines, this research establishes a novel paradigm for AI engineering -
transforming the IDE from a static coding tool into a dynamic, lifecycle-aware
intelligent platform for scalable and efficient model development.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [43] [Equality Saturation Guided by Large Language Models](https://arxiv.org/abs/2511.00403)
*Wentao Peng,Ruyi Ji,Yingfei Xiong*

Main category: cs.PL

TL;DR: LGuess通过将e-graphs作为LLMs和重写系统之间的中间层，解决了LLMs无法保证正确性的问题。它只向LLM查询高级重写检查点，并使用e-graphs提供这些检查点之间的低级重写链。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型无法保证正确性的关键问题，虽然可以通过将LLMs应用于形式重写系统来解决，但当前LLMs在生成可靠重写链方面仍然不足。

Method: 提出LLM引导的等式饱和方法LGuess，通过将e-graphs作为中间层，从LLM获取高级重写检查点，使用e-graphs生成检查点间的重写链，并学习概率模型来有效提取合适的检查点。

Result: 在多元多项式因式分解问题上，LGuess相比直接等式饱和和直接查询LLM重写链的方法展现出显著优势。

Conclusion: LGuess成功地将LLMs与形式重写系统相结合，通过中间层设计解决了LLMs正确性保证的问题，在复杂代数问题处理上表现出色。

Abstract: One critical issue with large language models (LLMs) is their inability to
guarantee correctness. Although this problem can be addressed by applying LLMs
to formal rewrite systems, current LLMs are still far from adequate to generate
sound rewrite chains. To bridge this gap, this paper proposes LLM-guided
equality saturation, dubbed LGuess, by incorporating e-graphs as an
intermediate layer between LLMs and rewrite systems. LGuess queries LLMs only
for high-level rewrite checkpoints and uses e-graphs to supply low-level
rewrite chains between these checkpoints. The key technical challenge in this
procedure lies in effectively extracting a suitable checkpoint from a saturated
e-graph, which LGuess addresses by learning a probabilistic model from the LLM.
The model predicts probable checkpoints while remaining simple enough for
effective extraction. We implement a prototype of LGuess and evaluate it on the
problem of factorizing multivariable polynomials. The results demonstrate a
significant advantage of LGuess compared to both straightforward equality
saturation and the approach that queries the LLM directly for the rewrite
chain.

</details>


### [44] [\texttt{ReMind}: Understanding Deductive Code Reasoning in LLMs](https://arxiv.org/abs/2511.00488)
*Jun Gao,Yun Peng,Xiaoxue Ren*

Main category: cs.PL

TL;DR: 本文提出ReMind多智能体框架，通过Mutator、Executor和Inspector的协同工作，解决大语言模型在演绎代码推理中的三个关键挑战，显著提升推理能力和零样本泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码相关任务上取得显著进展，但实证研究表明它们在演绎代码推理（理解程序执行过程）方面仍存在困难。现有研究认识到这一局限性，但根本原因尚未深入探索。

Method: 提出ReMind多智能体框架，包含三个组件：Mutator生成代码变体以减少对代码源的偏见；Executor逐步跟踪变量状态以暴露不一致性；Inspector识别有问题的推理步骤并提供控制流细化来弥合推理差距。

Result: 在两个基准测试和五个大语言模型上的广泛实验表明，ReMind在演绎代码推理方面相比基线方法具有显著优势，实现了出色的性能和稳健的零样本泛化。

Conclusion: ReMind框架通过多智能体协作系统性地识别和优化推理缺陷，有效解决了大语言模型在演绎代码推理中的关键挑战，为提升代码推理能力提供了有效解决方案。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in
code-related tasks. Despite their advancement, empirical evidence reveals that
they still struggle with \emph{deductive code reasoning}, the ability to reason
about the program execution process. While prior studies have recognized this
limitation, the underlying causes remain largely underexplored. In this paper,
we begin by presenting a comprehensive empirical study that reveals three key
challenges undermining deductive code reasoning: (1) an intrinsic gap between
generation and reasoning abilities, (2) a consistent bias towards code sources,
and (3) weak zero-shot generalization on complex benchmarks. In light of these
challenges, we propose \texttt{ReMind}, a multi-agent framework composed of
\texttt{Mutator}, \texttt{Executor}, and \texttt{Inspector}. The
\texttt{Mutator} generates code variants to mitigate bias towards code sources,
the \texttt{Executor} traces variable states step-by-step to expose
inconsistency, and the \texttt{Inspector} identifies problematic reasoning
steps and provides control-flow refinement to bridge the intrinsic reasoning
gap. Through their coordinated collaboration, \texttt{ReMind} systematically
identifies and refines reasoning flaws, achieving outstanding performance and
enabling robust zero-shot generalization. Extensive experiments on two
benchmarks with five LLMs demonstrate the superior advantages of
\texttt{ReMind} compared to baseline approaches in deductive code reasoning.

</details>


### [45] [Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization](https://arxiv.org/abs/2511.00592)
*Massinissa Merouani,Islem Kara Bernou,Riyadh Baghdadi*

Main category: cs.PL

TL;DR: ComPilot是一个利用大型语言模型作为交互式优化代理的框架，通过与编译器建立反馈循环来优化代码，在PolyBench基准测试中实现了2.66-3.54倍的几何平均加速。


<details>
  <summary>Details</summary>
Motivation: 自动代码优化在现代硬件上仍然是一个困难挑战，特别是对于复杂的循环嵌套。本文研究如何利用大型语言模型通过闭环交互指导代码优化过程。

Method: 提出ComPilot框架，利用现成的LLM作为交互式优化代理，建立反馈循环：LLM提出循环嵌套的转换建议，编译器尝试转换并反馈合法性和性能结果，LLM根据反馈迭代优化策略。

Result: 在PolyBench基准测试中，ComPilot实现了2.66倍（单次运行）和3.54倍（5次运行最佳）的几何平均加速，并且在许多情况下优于最先进的Pluto多面体优化器。

Conclusion: 实验研究表明，当通过编译器反馈进行基础时，通用LLM可以有效指导代码优化过程，为代码优化中的代理AI开辟了有前景的研究方向。

Abstract: Automatic code optimization remains a difficult challenge, particularly for
complex loop nests on modern hardware. This paper investigates a novel approach
to code optimization where Large Language Models (LLMs) guide the process
through a closed-loop interaction with a compiler. We present ComPilot, an
experimental framework that leverages off-the-shelf LLMs, without any
task-specific fine-tuning, as interactive optimization agents. ComPilot
establishes a feedback loop where an LLM proposes transformations for a given
loop nest to a compiler. The compiler attempts the transformations, reporting
back legality status and measured speedup or slowdown. The LLM utilizes this
concrete feedback to iteratively refine its optimization strategy. Our
extensive evaluation across the PolyBench benchmark suite demonstrates the
effectiveness of this zero-shot approach. ComPilot achieves geometric mean
speedups of 2.66x (single run) and 3.54x (best-of-5 runs) over the original
code. Furthermore, ComPilot demonstrates competitive performance against the
state-of-the-art Pluto polyhedral optimizer, outperforming it in many cases.
This experimental study demonstrates that general-purpose LLMs can effectively
guide the code optimization process when grounded by compiler feedback, opening
promising research directions for agentic AI in code optimization.

</details>


### [46] [Typed Embedding of miniKanren for Functional Conversion](https://arxiv.org/abs/2511.00740)
*Igor Engel,Ekaterina Verbitskaia*

Main category: cs.PL

TL;DR: 本文提出了一种类型化的无标签最终嵌入方法，将miniKanren嵌入到Haskell中，解决了之前转换方法存在的类型不敏感、需要确定性注解和隐式生成器线程等问题。


<details>
  <summary>Details</summary>
Motivation: 之前的关系编程功能转换方法存在性能开销问题，且实现不够优雅：对类型不敏感、需要确定性注解、存在隐式生成器线程。本文旨在解决这些问题。

Method: 采用类型化的无标签最终嵌入方法，将miniKanren嵌入到Haskell编程语言中。

Result: 新方法显著减少了样板代码，同时保持甚至增强了之前的性能提升。

Conclusion: 通过类型化的无标签最终嵌入方法，成功解决了之前转换方法的缺陷，实现了更优雅和高效的miniKanren嵌入。

Abstract: Relational programming enables program synthesis through a verifier-to-solver
approach. An earlier paper introduced a functional conversion that mitigated
some of the inherent performance overhead. However, the conversion was
inelegant: it was oblivious to types, demanded determinism annotations, and
implicit generator threading. In this paper, we address these issues by
providing a typed tagless-final embedding of miniKanren into Haskell. This
improvement significantly reduces boilerplate while preserving, and sometimes
enhancing, earlier speedups.

</details>


### [47] [Cobble: Compiling Block Encodings for Quantum Computational Linear Algebra](https://arxiv.org/abs/2511.01736)
*Charles Yuan*

Main category: cs.PL

TL;DR: Cobble是一个用于量子计算线性代数编程的语言，它通过高级表示法自动编译为正确的量子电路，相比现有电路优化器在基准测试中实现了2.6x-25.4x的加速。


<details>
  <summary>Details</summary>
Motivation: 量子线性代数算法虽然承诺指数级加速，但开发人员需要实现复杂的矩阵运算量子电路，且传统优化方法如子表达式重用可能不适用或不划算。

Method: 开发Cobble语言，支持开发者使用高级表示法表达和操作矩阵的量子表示（块编码），自动编译为量子电路，包含时间空间使用分析以及使用量子奇异值变换等领先技术的优化。

Result: 在模拟、回归、搜索等应用的基准测试中，Cobble相比现有电路优化器实现了2.6倍到25.4倍的加速。

Conclusion: Cobble通过提供高级编程抽象和自动优化，显著简化了量子线性代数算法的开发，并实现了显著的性能提升。

Abstract: Quantum algorithms for computational linear algebra promise up to exponential
speedups for applications such as simulation and regression, making them prime
candidates for hardware realization. But these algorithms execute in a model
that cannot efficiently store matrices in memory like a classical algorithm
does, instead requiring developers to implement complex expressions for matrix
arithmetic in terms of correct and efficient quantum circuits. Among the
challenges for the developer is navigating a cost model in which conventional
optimizations for linear algebra, such as subexpression reuse, can be
inapplicable or unprofitable.
  In this work, we present Cobble, a language for programming with quantum
computational linear algebra. Cobble enables developers to express and
manipulate the quantum representations of matrices, known as block encodings,
using high-level notation that automatically compiles to correct quantum
circuits. Cobble features analyses that estimate leading factors in time and
space usage of programs, as well as optimizations that reduce overhead and
generate efficient circuits using leading techniques such as the quantum
singular value transformation. We evaluate Cobble on benchmark kernels for
simulation, regression, search, and other applications, showing 2.6x-25.4x
speedups not achieved by existing circuit optimizers on these benchmarks.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [48] [Runtime Verification of Interactions Using Automata](https://arxiv.org/abs/2511.00531)
*Chana Weil-Kennedy,Darine Rammal,Christophe Gaston,Arnault Lapitre*

Main category: cs.LO

TL;DR: 提出了两种基于自动机理论的分布式系统运行时验证方法，用于检查多轨迹是否满足交互规范，其中第二种方法提供错误类型信息并支持预处理重用。


<details>
  <summary>Details</summary>
Motivation: 分布式系统的子系统通过消息传递通信，没有共享全局时钟，需要验证本地执行轨迹是否满足指定的交互模型规范。

Method: 使用基于自动机理论的两个验证程序：第一个直接验证多轨迹是否满足交互规范；第二个提供错误类型信息并支持预处理重用。

Result: 实现了两种验证程序并进行比较，第二种方法在重复验证相同交互规范时效率更高。

Conclusion: 提出的两种方法都能有效验证分布式系统的多轨迹是否符合交互规范，其中第二种方法在错误诊断和预处理重用方面具有优势。

Abstract: Runtime verification consists in observing and collecting the execution
traces of a system and checking them against a specification, with the
objective of raising an error when a trace does not satisfy the specification.
We consider distributed systems consisting of subsystems which communicate by
message-passing. Local execution traces consisting of send and receive events
are collected on each subsystem. We do not assume that the subsystems have a
shared global clock, which would allow a reordering of the local traces.
Instead, we manipulate multitraces, which are collections of local traces. We
use interaction models as specifications: they describe communication scenarios
between multiple components, and thus specify a desired global behaviour. We
propose two procedures to decide whether a multitrace satisfies an interaction,
based on automata-theoretic techniques. The first procedure is straightforward,
while the second provides more information on the type of error and integrates
the idea of reusability: because many multitraces are compared against one
interaction, some preprocessing can be done once at the beginning. We implement
both procedures and compare them.

</details>


### [49] [Proceedings Twelfth Workshop on Fixed Points in Computer Science](https://arxiv.org/abs/2511.00626)
*Alexis Saurin*

Main category: cs.LO

TL;DR: 这是第十二届计算机科学中不动点国际研讨会的论文集，包含2024年2月19-20日在意大利那不勒斯举行的研讨会精选论文


<details>
  <summary>Details</summary>
Motivation: 收集和出版计算机科学中不动点理论相关的最新研究成果，作为CSL 2024会议的卫星活动

Method: 通过国际研讨会形式征集论文，经过评审后精选出版会议论文集

Result: 成功举办了第十二届不动点理论研讨会，并出版了包含精选论文的EPTCS卷

Conclusion: 该卷论文集代表了计算机科学中不动点理论领域的最新研究进展，为该领域学者提供了重要的学术交流平台

Abstract: This EPTCS volume contains the post-proceedings of the Twelfth International
Workshop on Fixed Points in Computer Science, presenting a selection of the
works presented during the workshop that took place in Naples (Italy) on the
19th and 20th of February 2024 as a satellite of the International Conference
on Computer Science Logic (CSL 2024).

</details>


### [50] [A Simple Logic of Cohesive Group Agency](https://arxiv.org/abs/2511.00888)
*Nicolas Troquard*

Main category: cs.LO

TL;DR: 提出了一种表示群体社会结构的"凝聚力网络"概念，将其建模为子群之间的图结构，其中边表示子群间的亲社会行为。


<details>
  <summary>Details</summary>
Motivation: 研究群体凝聚力和社会结构的形式化表示，为分析群体行动能力提供理论基础。

Method: 基于"带来"逻辑构建形式化框架，将亲社会行为具体化为子群间的"成功协助"关系。

Result: 开发了一套凝聚力群体行动逻辑家族，每个逻辑对应一类凝聚力网络。

Conclusion: 建立了一个能够形式化表示和分析群体凝聚力与社会结构的逻辑框架。

Abstract: We propose a structure to represent the social fabric of a group. We call it
the `cohesion network' of the group. It can be seen as a graph whose vertices
are strict subgroups and whose edges indicate a prescribed `pro-social
behaviour' from one subgroup towards another. In social psychology, pro-social
behaviours are building blocks of full-blown cooperation, which we assimilate
here with `group cohesiveness'. We then define a formal framework to study
cohesive group agency. To do so, we simply instantiate pro-social behaviour
with the more specific relation of `successful assistance' between acting
entities in a group. The relations of assistance within a group at the moment
of agency constitute the social fabric of the cohesive group agency. We build
our logical theory upon the logic of agency "bringing-it-about". We obtain a
family of logics of cohesive group agency, one for every class of cohesion
networks.

</details>


### [51] [Dynamic Logic of Trust-Based Beliefs](https://arxiv.org/abs/2511.00899)
*Junli Jiang,Pavel Naumov,Wenxuan Zhang*

Main category: cs.LO

TL;DR: 本文研究了结合数据公告模态的数据驱动信念动态逻辑，提供了完整的公理化系统和多项式模型检测算法。


<details>
  <summary>Details</summary>
Motivation: 传统上，代理的信念来自其感知能力，而现代世界中信念往往基于可用数据。需要研究数据公告如何影响代理的信念形成。

Method: 开发了一个结合数据公告模态的数据驱动信念动态逻辑系统，建立了完整的公理化系统，并设计了多项式时间复杂度的模型检测算法。

Result: 成功构建了数据驱动信念与数据公告模态交互的逻辑系统，证明了该系统的可靠性和完备性，并实现了高效的模型检测。

Conclusion: 该研究为理解数据公告如何影响代理信念提供了形式化框架，其公理系统和高效算法为实际应用奠定了基础。

Abstract: Traditionally, an agent's beliefs would come from what the agent can see,
hear, or sense. In the modern world, beliefs are often based on the data
available to the agents. In this work, we investigate a dynamic logic of such
beliefs that incorporates public announcements of data. The main technical
contribution is a sound and complete axiomatisation of the interplay between
data-informed beliefs and data announcement modalities. We also describe a
non-trivial polynomial model checking algorithm for this logical system.

</details>


### [52] [pacSTL: PAC-Bounded Signal Temporal Logic from Data-Driven Reachability Analysis](https://arxiv.org/abs/2511.00934)
*Elizabeth Dietrich,Hanna Krasowski,Emir Cem Gezer,Roger Skjetne,Asgeir Johan Sørensen,Murat Arcak*

Main category: cs.LO

TL;DR: 提出pacSTL框架，将概率近似正确(PAC)边界集预测与STL的区间扩展相结合，为存在不确定性的机器人系统提供规范级别的PAC边界鲁棒性区间。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人系统需要在存在不确定性的情况下满足安全要求，但标准信号时序逻辑(STL)无法处理不确定性。

Method: 结合PAC边界集预测与STL的区间扩展，在原子命题级别通过优化问题提供PAC边界鲁棒性区间。

Result: 通过海上导航案例验证了方法的有效性，并通过仿真和真实模型船只实验分析了效率和可扩展性。

Conclusion: pacSTL框架能够为存在不确定性的机器人系统提供数学严谨的安全要求定义和测量方法。

Abstract: Real-world robotic systems must comply with safety requirements in the
presence of uncertainty. To define and measure requirement adherence, Signal
Temporal Logic (STL) offers a mathematically rigorous and expressive language.
However, standard STL cannot account for uncertainty. We address this problem
by presenting pacSTL, a framework that combines Probably Approximately Correct
(PAC) bounded set predictions with an interval extension of STL through
optimization problems on the atomic proposition level. pacSTL provides
PAC-bounded robustness intervals on the specification level that can be
utilized in monitoring. We demonstrate the effectiveness of this approach
through maritime navigation and analyze the efficiency and scalability of
pacSTL through simulation and real-world experimentation on model vessels.

</details>


### [53] [SM-based Semantics for Answer Set Programs Containing Conditional Literals and Arithmetic](https://arxiv.org/abs/2511.01753)
*Zachary Hansen,Yuliya Lierler*

Main category: cs.LO

TL;DR: 本文提出了基于SM算子的逻辑程序语义，支持条件文字和算术运算，无需依赖传统基于无穷命题逻辑的翻译方法。


<details>
  <summary>Details</summary>
Motivation: 现代ASP求解器如CLINGO支持高级语言构造如条件文字，提高了逻辑程序的表达性和简洁性。这些构造使规则形式更接近一阶逻辑的语法，是知识表示的有用工具。

Method: 基于SM算子提出逻辑程序语义，支持条件文字和算术运算，不依赖传统基于无穷命题逻辑的翻译方法。

Result: 建立了所提语义与现有语义之间的精确对应关系。

Conclusion: 提出的语义为包含条件文字和算术的逻辑程序提供了无需基础化的语义框架，并与现有语义保持一致性。

Abstract: Modern answer set programming solvers such as CLINGO support advanced
language constructs that improve the expressivity and conciseness of logic
programs. Conditional literals are one such construct. They form "subformulas"
that behave as nested implications within the bodies of logic rules. Their
inclusion brings the form of rules closer to the less restrictive syntax of
first-order logic. These qualities make conditional literals useful tools for
knowledge representation. In this paper, we propose a semantics for logic
programs with conditional literals and arithmetic based on the SM operator.
These semantics do not require grounding, unlike the established semantics for
such programs that relies on a translation to infinitary propositional logic.
The main result of this paper establishes the precise correspondence between
the proposed and existing semantics.

</details>


### [54] [A Physical Analogy between Molecular Ordering and SAT-to-Ising Annealing](https://arxiv.org/abs/2511.01216)
*ShivKishan Dubey,Rohit Sharma*

Main category: cs.LO

TL;DR: 该研究展示了分子系统热力学有序化与计算复杂问题中逻辑一致性发展之间的直接类比，通过将布尔SAT问题映射到Ising哈密顿模型，使用模拟退火方法证明了可满足逻辑配置类似于分子系统中的低能晶态。


<details>
  <summary>Details</summary>
Motivation: 探索分子系统在降温时的自发有序化现象与计算复杂问题中逻辑一致性发展之间的类比关系，为计算相干性和复杂性提供统一的热力学视角。

Method: 将布尔SAT问题实例映射到成对Ising哈密顿模型，使用模拟退火方法通过热演化从高熵随机分配到低熵有序分配（能量最小值），应用分子冷却类比。

Result: 发现了可满足逻辑配置的快速"一阶"或"逻辑结晶"现象，骨干刚性程度与系统物理有序化水平没有强相关性，主要发生的是约束满足的局部对齐。

Conclusion: 提供了经验证据表明可满足逻辑配置类似于分子系统中观察到的低能晶态，支持计算相干性和复杂性的统一热力学观点。

Abstract: As temperature drops, molecular systems may undergo spontaneous ordering,
moving from random behavior to orderly structure. This research demonstrates a
direct analogy between this type of thermodynamic ordering in molecular systems
and the development of coherent logic in computationally complex problem sets.
We have proposed a mapping of Boolean SAT problem instances to pairwise Ising
Hamiltonian models. Using simulated annealing, we then applied phenomenal
cooling to the system through thermal evolution from high entropy random
assignment to lower entropy, ordered assignments (the energy minima) using
molecular cooling analogs. This indicated that there was a rapid "first-order"
or "logical crystallization" of satisfiable logical configurations. The degree
of backbone rigidity did not strongly correlate with the level of physical
ordering observed in the system; thus, it appears that there is primarily a
local alignment of constraint satisfaction occurring in the system. Thus, we
have provided empirical evidence that satisfiable logical configurations are
analogous to the low energy crystalline states observed in molecular systems
and provide evidence for a unified thermodynamic view of computational
coherence and complexity.

</details>


### [55] [Access Hoare Logic](https://arxiv.org/abs/2511.01754)
*Arnold Beckmann,Anton Setzer*

Main category: cs.LO

TL;DR: 提出了访问Hoare逻辑，这是一种基于Hoare逻辑但用于程序访问安全性的形式化验证方法，证明了其可靠性和完备性，并与标准Hoare逻辑建立了联系。


<details>
  <summary>Details</summary>
Motivation: 受Hoare逻辑启发，但专注于程序访问控制的安全性验证，解决传统Hoare逻辑在访问安全方面的局限性。

Method: 定义访问Hoare逻辑的形式化框架，通过示例展示其应用，证明该逻辑的可靠性和完备性，并与标准Hoare逻辑建立理论联系。

Result: 成功构建了访问Hoare逻辑的形式化系统，证明了其可靠性和完备性，展示了在访问控制验证中的实用性。

Conclusion: 访问Hoare逻辑为程序访问安全性提供了有效的形式化验证工具，是对Hoare逻辑的重要扩展，在访问控制领域具有重要应用价值。

Abstract: Following Hoare's seminal invention, later called Hoare logic, to reason
about correctness of computer programs, we advocate a related but fundamentally
different approach to reason about access security of computer programs such as
access control. We define the formalism, which we denote access Hoare logic,
and present examples which demonstrate its usefulness and fundamental
difference to Hoare logic. We prove soundness and completeness of access Hoare
logic, and provide a link between access Hoare logic and standard Hoare logic.

</details>
