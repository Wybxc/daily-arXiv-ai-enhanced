{"id": "2509.13429", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13429", "abs": "https://arxiv.org/abs/2509.13429", "authors": ["Anthony Arnold", "Mark Marron"], "title": "Catalpa: GC for a Low-Variance Software Stack", "comment": null, "summary": "The performance of an application/runtime is usually conceptualized as a\ncontinuous function where, the lower the amount of memory/time used on a given\nworkload, then the better the compiler/runtime is. However, in practice, good\nperformance of an application is viewed as more of a binary function - either\nthe application responds in under, say 100 ms, and is fast enough for a user to\nbarely notice, or it takes a noticeable amount of time, leaving the user\nwaiting and potentially abandoning the task. Thus, performance really means how\noften the application is fast enough to be usable, leading industrial\ndevelopers to focus on the 95th and 99th percentile tail-latencies as heavily,\nor moreso, than average response time. Our vision is to create a software stack\nthat actively supports these needs via programming language and runtime system\ndesign. In this paper we present a novel garbage-collector design, the Catalpa\ncollector, for the Bosque programming language and runtime. This allocator is\ndesigned to minimize latency and variability while maintaining high-throughput\nand incurring small memory overheads. To achieve these goals we leverage\nvarious features of the Bosque language, including immutability and\nreference-cycle freedom, to construct a collector that has bounded collection\npauses, incurs fixed-constant memory overheads, and does not require any\nbarriers or synchronization with application code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCatalpa\u7684\u65b0\u578b\u5783\u573e\u6536\u96c6\u5668\u8bbe\u8ba1\uff0c\u4e13\u4e3aBosque\u7f16\u7a0b\u8bed\u8a00\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u5f00\u53d1\uff0c\u65e8\u5728\u901a\u8fc7\u5229\u7528\u8bed\u8a00\u7279\u6027\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u53d8\u5f02\u6027\u7684\u9ad8\u6027\u80fd\u5783\u573e\u56de\u6536\u3002", "motivation": "\u5b9e\u9645\u5e94\u7528\u4e2d\u6027\u80fd\u5f80\u5f80\u88ab\u89c6\u4e3a\u4e8c\u5143\u51fd\u6570\uff08\u8981\u4e48\u8db3\u591f\u5feb\uff0c\u8981\u4e48\u7528\u6237\u53ef\u611f\u77e5\u5ef6\u8fdf\uff09\uff0c\u5de5\u4e1a\u5f00\u53d1\u8005\u66f4\u5173\u6ce895%\u548c99%\u767e\u5206\u4f4d\u5c3e\u5ef6\u8fdf\u800c\u975e\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u3002\u9700\u8981\u6784\u5efa\u80fd\u591f\u4e3b\u52a8\u652f\u6301\u8fd9\u4e9b\u9700\u6c42\u7684\u8f6f\u4ef6\u6808\u3002", "method": "\u5229\u7528Bosque\u8bed\u8a00\u7684\u4e0d\u53d8\u6027\u548c\u65e0\u5f15\u7528\u73af\u7279\u6027\uff0c\u8bbe\u8ba1\u65e0\u9700\u5c4f\u969c\u6216\u5e94\u7528\u4ee3\u7801\u540c\u6b65\u7684\u5783\u573e\u6536\u96c6\u5668\uff0c\u5b9e\u73b0\u6709\u754c\u6536\u96c6\u6682\u505c\u548c\u56fa\u5b9a\u5e38\u6570\u5185\u5b58\u5f00\u9500\u3002", "result": "Catalpa\u6536\u96c6\u5668\u80fd\u591f\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c\u53d8\u5f02\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u548c\u5c0f\u5185\u5b58\u5f00\u9500\uff0c\u5177\u6709\u6709\u754c\u6536\u96c6\u6682\u505c\u548c\u56fa\u5b9a\u5e38\u6570\u5185\u5b58\u5f00\u9500\u7279\u6027\u3002", "conclusion": "\u901a\u8fc7\u7f16\u7a0b\u8bed\u8a00\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u8bbe\u8ba1\u53ef\u4ee5\u6784\u5efa\u51fa\u80fd\u591f\u6ee1\u8db3\u5de5\u4e1a\u7ea7\u6027\u80fd\u9700\u6c42\u7684\u5783\u573e\u6536\u96c6\u5668\uff0cCatalpa\u6536\u96c6\u5668\u4e3aBosque\u8bed\u8a00\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u5185\u5b58\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13436", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13436", "abs": "https://arxiv.org/abs/2509.13436", "authors": ["Evan Eisinger", "Michael A. Heroux"], "title": "Is Research Software Science a Metascience?", "comment": "5 pages", "summary": "As research increasingly relies on computational methods, the reliability of\nscientific results depends on the quality, reproducibility, and transparency of\nresearch software. Ensuring these qualities is critical for scientific\nintegrity and discovery. This paper asks whether Research Software Science\n(RSS)--the empirical study of how research software is developed and\nused--should be considered a form of metascience, the science of science.\nClassification matters because it could affect recognition, funding, and\nintegration of RSS into research improvement. We define metascience and RSS,\ncompare their principles and objectives, and examine their overlaps. Arguments\nfor classification highlight shared commitments to reproducibility,\ntransparency, and empirical study of research processes. Arguments against\nportraying RSS as a specialized domain focused on a tool rather than the\nbroader scientific enterprise. Our analysis finds RSS advances core goals of\nmetascience, especially in computational reproducibility, and bridges\ntechnical, social, and cognitive aspects of research. Its classification\ndepends on whether one adopts a broad definition of metascience--any empirical\neffort to improve science--or a narrow one focused on systemic and\nepistemological structures. We argue RSS is best understood as a distinct\ninterdisciplinary domain that aligns with, and in some definitions fits within,\nmetascience. Recognizing it as such can strengthen its role in improving\nreliability, justify funding, and elevate software development in research\ninstitutions. Regardless of classification, applying scientific rigor to\nresearch software ensures the tools of discovery meet the standards of the\ndiscoveries themselves.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7814\u7a76\u8f6f\u4ef6\u79d1\u5b66(RSS)\u662f\u5426\u5e94\u88ab\u89c6\u4e3a\u5143\u79d1\u5b66\u7684\u4e00\u79cd\u5f62\u5f0f\uff0c\u5206\u6790\u4e86\u4e24\u8005\u7684\u5173\u7cfb\u3001\u91cd\u53e0\u9886\u57df\u4ee5\u53ca\u5206\u7c7b\u5bf9\u8ba4\u53ef\u5ea6\u3001\u8d44\u91d1\u548c\u7814\u7a76\u6574\u5408\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u7814\u7a76\u65e5\u76ca\u4f9d\u8d56\u8ba1\u7b97\u65b9\u6cd5\uff0c\u79d1\u5b66\u7ed3\u679c\u7684\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u7814\u7a76\u8f6f\u4ef6\u7684\u8d28\u91cf\u3001\u53ef\u91cd\u590d\u6027\u548c\u900f\u660e\u5ea6\u3002\u786e\u4fdd\u8fd9\u4e9b\u54c1\u8d28\u5bf9\u79d1\u5b66\u5b8c\u6574\u6027\u548c\u53d1\u73b0\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u660e\u786eRSS\u5728\u79d1\u5b66\u4f53\u7cfb\u4e2d\u7684\u5b9a\u4f4d\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u5143\u79d1\u5b66\u548c\u7814\u7a76\u8f6f\u4ef6\u79d1\u5b66\uff0c\u6bd4\u8f83\u4e24\u8005\u7684\u539f\u5219\u548c\u76ee\u6807\uff0c\u68c0\u9a8c\u5b83\u4eec\u7684\u91cd\u53e0\u9886\u57df\uff0c\u5206\u6790\u652f\u6301\u4e0e\u53cd\u5bf9\u5c06RSS\u5f52\u7c7b\u4e3a\u5143\u79d1\u5b66\u7684\u8bba\u70b9\u3002", "result": "\u5206\u6790\u53d1\u73b0RSS\u63a8\u8fdb\u4e86\u5143\u79d1\u5b66\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u65b9\u9762\uff0c\u5e76\u8fde\u63a5\u4e86\u7814\u7a76\u7684\u6280\u672f\u3001\u793e\u4f1a\u548c\u8ba4\u77e5\u5c42\u9762\u3002RSS\u662f\u5426\u5c5e\u4e8e\u5143\u79d1\u5b66\u53d6\u51b3\u4e8e\u91c7\u7528\u5e7f\u4e49\u8fd8\u662f\u72ed\u4e49\u7684\u5143\u79d1\u5b66\u5b9a\u4e49\u3002", "conclusion": "RSS\u6700\u597d\u88ab\u7406\u89e3\u4e3a\u4e00\u4e2a\u72ec\u7279\u7684\u8de8\u5b66\u79d1\u9886\u57df\uff0c\u4e0e\u5143\u79d1\u5b66\u4fdd\u6301\u4e00\u81f4\u5e76\u5728\u67d0\u4e9b\u5b9a\u4e49\u4e0b\u5c5e\u4e8e\u5143\u79d1\u5b66\u3002\u65e0\u8bba\u5206\u7c7b\u5982\u4f55\uff0c\u5c06\u79d1\u5b66\u4e25\u8c28\u6027\u5e94\u7528\u4e8e\u7814\u7a76\u8f6f\u4ef6\u80fd\u786e\u4fdd\u53d1\u73b0\u5de5\u5177\u7b26\u5408\u53d1\u73b0\u672c\u8eab\u7684\u6807\u51c6\u3002"}}
{"id": "2509.13489", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.13489", "abs": "https://arxiv.org/abs/2509.13489", "authors": ["Chester J. F. Gould", "William J. Bowman"], "title": "Extended Abstract: Towards a Performance Comparison of Syntax and Type-Directed NbE", "comment": "Submitted to TyDe 2025", "summary": "A key part of any dependent type-checker is the method for checking whether\ntwo types are equal. A common claim is that syntax-directed equality is more\nperformant, although type-directed equality is more expressive. However, this\nclaim is difficult to make precise, since implementations choose only one or\nthe other approach, making a direct comparison impossible. We present some\nwork-in-progress developing a realistic platform for direct, apples-to-apples,\ncomparison of the two approaches, quantifying how much slower type-directed\nequality checking is, and analyzing why and how it can be improved.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u76f4\u63a5\u6bd4\u8f83\u8bed\u6cd5\u5bfc\u5411\u548c\u7c7b\u578b\u5bfc\u5411\u4e24\u79cd\u7c7b\u578b\u76f8\u7b49\u6027\u68c0\u67e5\u65b9\u6cd5\u7684\u5b9e\u9a8c\u5e73\u53f0\uff0c\u65e8\u5728\u91cf\u5316\u7c7b\u578b\u5bfc\u5411\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u5e76\u5206\u6790\u6539\u8fdb\u9014\u5f84", "motivation": "\u4f9d\u8d56\u7c7b\u578b\u68c0\u67e5\u5668\u4e2d\u7c7b\u578b\u76f8\u7b49\u6027\u68c0\u67e5\u662f\u5173\u952e\u90e8\u5206\uff0c\u73b0\u6709\u7814\u7a76\u58f0\u79f0\u8bed\u6cd5\u5bfc\u5411\u65b9\u6cd5\u6027\u80fd\u66f4\u597d\u800c\u7c7b\u578b\u5bfc\u5411\u65b9\u6cd5\u66f4\u8868\u8fbe\u6027\u5f3a\uff0c\u4f46\u7f3a\u4e4f\u76f4\u63a5\u6bd4\u8f83\u7684\u5b9e\u9a8c\u5e73\u53f0", "method": "\u5f00\u53d1\u4e00\u4e2a\u73b0\u5b9e\u7684\u5b9e\u9a8c\u5e73\u53f0\uff0c\u652f\u6301\u5bf9\u4e24\u79cd\u65b9\u6cd5\u8fdb\u884c\u76f4\u63a5\u3001\u516c\u5e73\u7684\u6bd4\u8f83\uff0c\u91cf\u5316\u7c7b\u578b\u5bfc\u5411\u68c0\u67e5\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u5206\u6790\u6539\u8fdb\u65b9\u6cd5", "result": "\u5de5\u4f5c\u6b63\u5728\u8fdb\u884c\u4e2d\uff0c\u65e8\u5728\u63d0\u4f9b\u91cf\u5316\u6570\u636e\u548c\u6027\u80fd\u5206\u6790", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u76f4\u63a5\u6bd4\u8f83\u5e73\u53f0\uff0c\u53ef\u4ee5\u7cbe\u786e\u8bc4\u4f30\u4e24\u79cd\u7c7b\u578b\u76f8\u7b49\u6027\u68c0\u67e5\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4e3a\u4f18\u5316\u7c7b\u578b\u5bfc\u5411\u65b9\u6cd5\u63d0\u4f9b\u4f9d\u636e"}}
{"id": "2509.13471", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13471", "abs": "https://arxiv.org/abs/2509.13471", "authors": ["Sina Gogani-Khiabani", "Ashutosh Trivedi", "Diptikalyan Saha", "Saeid Tizpaz-Niari"], "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "comment": "To appear at ICSE 26. 12 pages", "summary": "Large language models (LLMs) show promise for translating natural-language\nstatutes into executable logic, but reliability in legally critical settings\nremains challenging due to ambiguity and hallucinations. We present an agentic\napproach for developing legal-critical software, using U.S. federal tax\npreparation as a case study. The key challenge is test-case generation under\nthe oracle problem, where correct outputs require interpreting law. Building on\nmetamorphic testing, we introduce higher-order metamorphic relations that\ncompare system outputs across structured shifts among similar individuals.\nBecause authoring such relations is tedious and error-prone, we use an\nLLM-driven, role-based framework to automate test generation and code\nsynthesis. We implement a multi-agent system that translates tax code into\nexecutable software and incorporates a metamorphic-testing agent that searches\nfor counterexamples. In experiments, our framework using a smaller model\n(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier\nmodels (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results\nsupport agentic LLM methodologies as a path to robust, trustworthy\nlegal-critical software from natural-language specifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u9ad8\u9636\u8715\u53d8\u5173\u7cfb\u6765\u6d4b\u8bd5\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u6846\u67b6\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u548c\u4ee3\u7801\u5408\u6210\uff0c\u5728\u590d\u6742\u7a0e\u6cd5\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u524d\u6cbf\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u6cd5\u89c4\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u903b\u8f91\u65b9\u9762\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u5728\u6cd5\u5f8b\u5173\u952e\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u4ecd\u9762\u4e34\u6b67\u4e49\u548c\u5e7b\u89c9\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f8e\u56fd\u8054\u90a6\u7a0e\u52a1\u51c6\u5907\u8fd9\u6837\u7684\u6848\u4f8b\u4e2d\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4f7f\u7528\u9ad8\u9636\u8715\u53d8\u5173\u7cfb\u8fdb\u884c\u8715\u53d8\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u76f8\u4f3c\u4e2a\u4f53\u7ed3\u6784\u5316\u53d8\u5316\u4e0b\u7684\u7cfb\u7edf\u8f93\u51fa\uff0c\u5e76\u5229\u7528LLM\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u548c\u4ee3\u7801\u5408\u6210\u3002", "result": "\u4f7f\u7528\u8f83\u5c0f\u6a21\u578b(GPT-4o-mini)\u7684\u6846\u67b6\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u8fbe\u523045%\u7684\u901a\u8fc7\u7387\uff0c\u4f18\u4e8e\u524d\u6cbf\u6a21\u578b(GPT-4o\u548cClaude 3.5\u76849-15%)\u5728\u590d\u6742\u7a0e\u6cd5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u667a\u80fd\u4ee3\u7406LLM\u65b9\u6cd5\u4e3a\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5f00\u53d1\u7a33\u5065\u3001\u53ef\u4fe1\u8d56\u7684\u6cd5\u5f8b\u5173\u952e\u8f6f\u4ef6\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.13982", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.13982", "abs": "https://arxiv.org/abs/2509.13982", "authors": ["Boyu Zhang", "Ping He", "Tianyu Du", "Xuhong Zhang", "Lei Yun", "Kingsum Chow", "Jianwei Yin"], "title": "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing", "comment": null, "summary": "With the widespread adoption of open-source code language models (code LMs),\nintellectual property (IP) protection has become an increasingly critical\nconcern. While current watermarking techniques have the potential to identify\nthe code LM to protect its IP, they have limitations when facing the more\npractical and complex demand, i.e., offering the individual user-level tracing\nin the black-box setting. This work presents CLMTracing, a black-box code LM\nwatermarking framework employing the rule-based watermarks and\nutility-preserving injection method for user-level model tracing. CLMTracing\nfurther incorporates a parameter selection algorithm sensitive to the robust\nwatermark and adversarial training to enhance the robustness against watermark\nremoval attacks. Comprehensive evaluations demonstrate CLMTracing is effective\nacross multiple state-of-the-art (SOTA) code LMs, showing significant harmless\nimprovements compared to existing SOTA baselines and strong robustness against\nvarious removal attacks.", "AI": {"tldr": "CLMTracing\u662f\u4e00\u4e2a\u9ed1\u76d2\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5219\u6c34\u5370\u548c\u4fdd\u6301\u6548\u7528\u7684\u6ce8\u5165\u65b9\u6cd5\u5b9e\u73b0\u7528\u6237\u7ea7\u8ffd\u8e2a\uff0c\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u5bf9\u6297\u79fb\u9664\u653b\u51fb", "motivation": "\u968f\u7740\u5f00\u6e90\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u91c7\u7528\uff0c\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u73b0\u6709\u6c34\u5370\u6280\u672f\u5728\u9762\u5bf9\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u7684\u7528\u6237\u7ea7\u8ffd\u8e2a\u9700\u6c42\u65f6\u5b58\u5728\u5c40\u9650", "method": "\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u6c34\u5370\u548c\u4fdd\u6301\u6548\u7528\u7684\u6ce8\u5165\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bf9\u9c81\u68d2\u6c34\u5370\u654f\u611f\u7684\u53c2\u6570\u9009\u62e9\u7b97\u6cd5\u548c\u5bf9\u6297\u8bad\u7ec3\u6765\u589e\u5f3a\u9c81\u68d2\u6027", "result": "\u5728\u591a\u4e2a\u6700\u5148\u8fdb\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e0a\u6709\u6548\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u663e\u8457\u65e0\u5bb3\u6539\u8fdb\uff0c\u5bf9\u5404\u79cd\u79fb\u9664\u653b\u51fb\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027", "conclusion": "CLMTracing\u4e3a\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9ed1\u76d2\u7528\u6237\u7ea7\u8ffd\u8e2a\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u9700\u6c42"}}
{"id": "2509.13487", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13487", "abs": "https://arxiv.org/abs/2509.13487", "authors": ["Abubakari Alidu", "Michele Ciavotta", "Flavio DePaoli"], "title": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "comment": null, "summary": "Developing reliable data enrichment pipelines demands significant engineering\nexpertise. We present Prompt2DAG, a methodology that transforms natural\nlanguage descriptions into executable Apache Airflow DAGs. We evaluate four\ngeneration approaches -- Direct, LLM-only, Hybrid, and Template-based -- across\n260 experiments using thirteen LLMs and five case studies to identify optimal\nstrategies for production-grade automation. Performance is measured using a\npenalized scoring framework that combines reliability with code quality (SAT),\nstructural integrity (DST), and executability (PCT). The Hybrid approach\nemerges as the optimal generative method, achieving a 78.5% success rate with\nrobust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly\noutperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.\nOur findings show that reliability, not intrinsic code quality, is the primary\ndifferentiator. Cost-effectiveness analysis reveals the Hybrid method is over\ntwice as efficient as Direct prompting per successful DAG. We conclude that a\nstructured, hybrid approach is essential for balancing flexibility and\nreliability in automated workflow generation, offering a viable path to\ndemocratize data pipeline development.", "AI": {"tldr": "Prompt2DAG\u662f\u4e00\u79cd\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884cApache Airflow DAG\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5b9e\u73b0\u4e8678.5%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u53ef\u9760\u7684\u6570\u636e\u4e30\u5bcc\u7ba1\u9053\u9700\u8981\u5927\u91cf\u5de5\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u81ea\u52a8\u5316\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "method": "\u8bc4\u4f30\u4e86\u56db\u79cd\u751f\u6210\u65b9\u6cd5\uff08\u76f4\u63a5\u3001\u4ec5LLM\u3001\u6df7\u5408\u548c\u57fa\u4e8e\u6a21\u677f\uff09\uff0c\u5728260\u4e2a\u5b9e\u9a8c\u4e2d\u4f7f\u752813\u4e2aLLM\u548c5\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u91c7\u7528\u60e9\u7f5a\u8bc4\u5206\u6846\u67b6\u8861\u91cf\u53ef\u9760\u6027\u3001\u4ee3\u7801\u8d28\u91cf\u3001\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u53ef\u6267\u884c\u6027\u3002", "result": "\u6df7\u5408\u65b9\u6cd5\u662f\u6700\u4f73\u751f\u6210\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u8fbe78.5%\uff0c\u8d28\u91cf\u5f97\u5206\u7a33\u5065\uff08SAT:6.79, DST:7.67, PCT:7.76\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u4ec5LLM\u65b9\u6cd5\uff0866.2%\uff09\u548c\u76f4\u63a5\u65b9\u6cd5\uff0829.2%\uff09\u3002\u53ef\u9760\u6027\u662f\u4e3b\u8981\u533a\u5206\u56e0\u7d20\uff0c\u6df7\u5408\u65b9\u6cd5\u7684\u6210\u672c\u6548\u76ca\u662f\u76f4\u63a5\u63d0\u793a\u7684\u4e24\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u7ed3\u6784\u5316\u6df7\u5408\u65b9\u6cd5\u5bf9\u4e8e\u5728\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u4e2d\u5e73\u8861\u7075\u6d3b\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u6c11\u4e3b\u5316\u6570\u636e\u7ba1\u9053\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.14092", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.14092", "abs": "https://arxiv.org/abs/2509.14092", "authors": ["Michele Boreale", "Luisa Collodi"], "title": "Parallelizable Feynman-Kac Models for Universal Probabilistic Programming", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "We study provably correct and efficient instantiations of Sequential Monte\nCarlo (SMC) inference in the context of formal operational semantics of\nProbabilistic Programs (PPs). We focus on universal PPs featuring sampling from\narbitrary measures and conditioning/reweighting in unbounded loops. We first\nequip Probabilistic Program Graphs (PPGs), an automata-theoretic description\nformat of PPs, with an expectation-based semantics over infinite execution\ntraces, which also incorporates trace weights. We then prove a finite\napproximation theorem that provides bounds to this semantics based on\nexpectations taken over finite, fixed-length traces. This enables us to frame\nour semantics within a Feynman-Kac (FK) model, and ensures the consistency of\nthe Particle Filtering (PF) algorithm, an instance of SMC, with respect to our\nsemantics. Building on these results, we introduce VPF, a vectorized version of\nthe PF algorithm tailored to PPGs and our semantics. Experiments conducted with\na proof-of-concept implementation of VPF show very promising results compared\nto state-of-the-art PP inference tools.", "AI": {"tldr": "\u672c\u6587\u4e3a\u6982\u7387\u7a0b\u5e8f\u5f00\u53d1\u4e86\u57fa\u4e8eSequential Monte Carlo\u7684\u5411\u91cf\u5316\u7c92\u5b50\u6ee4\u6ce2\u7b97\u6cd5VPF\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u65e0\u9650\u6267\u884c\u8f68\u8ff9\u4e0a\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u6709\u9650\u8fd1\u4f3c\u5b9a\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u901a\u7528\u6982\u7387\u7a0b\u5e8f\u4e2d\u4efb\u610f\u6d4b\u5ea6\u91c7\u6837\u548c\u65e0\u754c\u5faa\u73af\u6761\u4ef6/\u91cd\u52a0\u6743\u64cd\u4f5c\u7684\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u5efa\u7acb\u5f62\u5f0f\u5316\u7684\u64cd\u4f5c\u8bed\u4e49\u5e76\u5f00\u53d1\u53ef\u8bc1\u660e\u6b63\u786e\u9ad8\u6548\u7684\u63a8\u7406\u7b97\u6cd5\u3002", "method": "\u9996\u5148\u4e3a\u6982\u7387\u7a0b\u5e8f\u56fe(PPG)\u5efa\u7acb\u57fa\u4e8e\u65e0\u9650\u6267\u884c\u8f68\u8ff9\u7684\u671f\u671b\u8bed\u4e49\uff0c\u7136\u540e\u8bc1\u660e\u6709\u9650\u8fd1\u4f3c\u5b9a\u7406\uff0c\u5c06\u8bed\u4e49\u6846\u67b6\u7eb3\u5165Feynman-Kac\u6a21\u578b\uff0c\u786e\u4fdd\u7c92\u5b50\u6ee4\u6ce2\u7b97\u6cd5\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u6700\u540e\u63d0\u51fa\u5411\u91cf\u5316\u7c92\u5b50\u6ee4\u6ce2\u7b97\u6cd5VPF\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eVPF\u7b97\u6cd5\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6982\u7387\u7a0b\u5e8f\u63a8\u7406\u5de5\u5177\u8868\u73b0\u51fa\u975e\u5e38\u6709\u524d\u666f\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u4e3a\u6982\u7387\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u8bed\u4e49\u57fa\u7840\u548c\u53ef\u8bc1\u660e\u6b63\u786e\u7684SMC\u63a8\u7406\u7b97\u6cd5\uff0cVPF\u7b97\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2509.13535", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13535", "abs": "https://arxiv.org/abs/2509.13535", "authors": ["S M Farah Al Fahim", "Md Nakhla Rafi", "Zeyang Ma", "Dong Jae Kim", "Tse-Hsun", "Chen"], "title": "Crash Report Enhancement with Large Language Models: An Empirical Study", "comment": null, "summary": "Crash reports are central to software maintenance, yet many lack the\ndiagnostic detail developers need to debug efficiently. We examine whether\nlarge language models can enhance crash reports by adding fault locations,\nroot-cause explanations, and repair suggestions. We study two enhancement\nstrategies: Direct-LLM, a single-shot approach that uses stack-trace context,\nand Agentic-LLM, an iterative approach that explores the repository for\nadditional evidence. On a dataset of 492 real-world crash reports, LLM-enhanced\nreports improve Top-1 problem-localization accuracy from 10.6% (original\nreports) to 40.2-43.1%, and produce suggested fixes that closely resemble\ndeveloper patches (CodeBLEU around 56-57%). Both our manual evaluations and\nLLM-as-a-judge assessment show that Agentic-LLM delivers stronger root-cause\nexplanations and more actionable repair guidance. A user study with 16\nparticipants further confirms that enhanced reports make crashes easier to\nunderstand and resolve, with the largest improvement in repair guidance. These\nresults indicate that supplying LLMs with stack traces and repository code\nyields enhanced crash reports that are substantially more useful for debugging.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\uff0c\u901a\u8fc7\u6dfb\u52a0\u6545\u969c\u4f4d\u7f6e\u3001\u6839\u56e0\u89e3\u91ca\u548c\u4fee\u590d\u5efa\u8bae\uff0c\u663e\u8457\u63d0\u5347\u8c03\u8bd5\u6548\u7387", "motivation": "\u5d29\u6e83\u62a5\u544a\u901a\u5e38\u7f3a\u4e4f\u8db3\u591f\u7684\u8bca\u65ad\u7ec6\u8282\uff0c\u5bfc\u81f4\u5f00\u53d1\u8005\u8c03\u8bd5\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5229\u7528LLM\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\u7684\u6709\u7528\u6027", "method": "\u7814\u7a76\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\uff1aDirect-LLM\uff08\u5355\u6b21\u4f7f\u7528\u5806\u6808\u8ddf\u8e2a\u4e0a\u4e0b\u6587\uff09\u548cAgentic-LLM\uff08\u8fed\u4ee3\u63a2\u7d22\u4ee3\u7801\u5e93\u83b7\u53d6\u989d\u5916\u8bc1\u636e\uff09", "result": "\u5728492\u4e2a\u771f\u5b9e\u5d29\u6e83\u62a5\u544a\u6570\u636e\u96c6\u4e0a\uff0cLLM\u589e\u5f3a\u62a5\u544a\u5c06Top-1\u95ee\u9898\u5b9a\u4f4d\u51c6\u786e\u7387\u4ece10.6%\u63d0\u5347\u81f340.2-43.1%\uff0c\u4fee\u590d\u5efa\u8bae\u4e0e\u5f00\u53d1\u8005\u8865\u4e01\u9ad8\u5ea6\u76f8\u4f3c\uff08CodeBLEU\u7ea656-57%\uff09", "conclusion": "\u4e3aLLM\u63d0\u4f9b\u5806\u6808\u8ddf\u8e2a\u548c\u4ee3\u7801\u5e93\u4fe1\u606f\u53ef\u4ee5\u751f\u6210\u663e\u8457\u66f4\u6709\u7528\u7684\u589e\u5f3a\u5d29\u6e83\u62a5\u544a\uff0c\u7279\u522b\u662fAgentic-LLM\u5728\u6839\u56e0\u89e3\u91ca\u548c\u4fee\u590d\u6307\u5bfc\u65b9\u9762\u8868\u73b0\u66f4\u4f18"}}
{"id": "2509.13699", "categories": ["cs.LO", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13699", "abs": "https://arxiv.org/abs/2509.13699", "authors": ["Max Barth", "Marie-Christine Jakobs"], "title": "Multi-Threaded Software Model Checking via Parallel Trace Abstraction Refinement", "comment": null, "summary": "Automatic software verification is a valuable means for software quality\nassurance. However, automatic verification and in particular software model\nchecking can be time-consuming, which hinders their practical applicability\ne.g., the use in continuous integration. One solution to address the issue is\nto reduce the response time of the verification procedure by leveraging today's\nmulti-core CPUs.\n  In this paper, we propose a solution to parallelize trace abstraction, an\nabstraction-based approach to software model checking. The underlying idea of\nour approach is to parallelize the abstraction refinement. More concretely, our\napproach analyzes different traces (syntactic program paths) that could violate\nthe safety property in parallel. We realize our parallelized version of trace\nabstraction in the verification tool Ulti mate Automizer and perform a thorough\nevaluation. Our evaluation shows that our parallelization is more effective\nthan sequential trace abstraction and can provide results significantly faster\non many time-consuming tasks. Also, our approach is more effective than DSS, a\nrecent parallel approach to abstraction-based software model checking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u5316trace abstraction\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u5206\u6790\u53ef\u80fd\u8fdd\u53cd\u5b89\u5168\u5c5e\u6027\u7684\u4e0d\u540c\u7a0b\u5e8f\u8def\u5f84\u6765\u52a0\u901f\u8f6f\u4ef6\u6a21\u578b\u68c0\u6d4b\uff0c\u5728Ultimate Automizer\u5de5\u5177\u4e2d\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\uff08\u7279\u522b\u662f\u8f6f\u4ef6\u6a21\u578b\u68c0\u6d4b\uff09\u8017\u65f6\u4e25\u91cd\uff0c\u963b\u788d\u4e86\u5728\u5b9e\u9645\u5e94\u7528\uff08\u5982\u6301\u7eed\u96c6\u6210\uff09\u4e2d\u7684\u4f7f\u7528\u3002\u4e3a\u5229\u7528\u591a\u6838CPU\u4f18\u52bf\uff0c\u9700\u8981\u51cf\u5c11\u9a8c\u8bc1\u8fc7\u7a0b\u7684\u54cd\u5e94\u65f6\u95f4\u3002", "method": "\u5e76\u884c\u5316trace abstraction\u7684\u62bd\u8c61\u7cbe\u5316\u8fc7\u7a0b\uff0c\u5177\u4f53\u901a\u8fc7\u5e76\u884c\u5206\u6790\u53ef\u80fd\u8fdd\u53cd\u5b89\u5168\u5c5e\u6027\u7684\u4e0d\u540c\u7a0b\u5e8f\u8def\u5f84\uff08\u8bed\u6cd5\u8def\u5f84\uff09\u6765\u5b9e\u73b0\u3002\u5728Ultimate Automizer\u9a8c\u8bc1\u5de5\u5177\u4e2d\u5b9e\u73b0\u4e86\u8be5\u5e76\u884c\u5316\u7248\u672c\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u5e76\u884c\u5316\u65b9\u6cd5\u6bd4\u987a\u5e8ftrace abstraction\u66f4\u6709\u6548\uff0c\u5728\u8bb8\u591a\u8017\u65f6\u4efb\u52a1\u4e0a\u80fd\u663e\u8457\u66f4\u5feb\u5730\u63d0\u4f9b\u7ed3\u679c\u3002\u540c\u65f6\u6bd4\u6700\u8fd1\u7684\u5e76\u884c\u62bd\u8c61\u8f6f\u4ef6\u6a21\u578b\u68c0\u6d4b\u65b9\u6cd5DSS\u66f4\u6709\u6548\u3002", "conclusion": "\u5e76\u884c\u5316trace abstraction\u662f\u89e3\u51b3\u8f6f\u4ef6\u6a21\u578b\u68c0\u6d4b\u8017\u65f6\u95ee\u9898\u7684\u6709\u6548\u65b9\u6848\uff0c\u80fd\u591f\u5145\u5206\u5229\u7528\u591a\u6838CPU\u8d44\u6e90\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\u3002"}}
{"id": "2509.14087", "categories": ["cs.FL", "cs.LO", "F.1.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2509.14087", "abs": "https://arxiv.org/abs/2509.14087", "authors": ["R\u00fcdiger Ehlers"], "title": "How Concise are Chains of co-B\u00fcchi Automata?", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "Chains of co-B\\\"uchi automata (COCOA) have recently been introduced as a new\ncanonical model for representing arbitrary omega-regular languages. They can be\nminimized in polynomial time and are hence an attractive language\nrepresentation for applications in which normally, deterministic omega-automata\nare used. While it is known how to build COCOA from deterministic parity\nautomata, little is currently known about their relationship to automaton\nmodels introduced earlier than COCOA.\n  In this paper, we analyze the conciseness of chains of co-B\\\"uchi automata.\nWe show that even in the case that all automata in the chain are deterministic,\nchains of co-B\\\"uchi automata can be exponentially more concise than\ndeterministic parity automata. We then answer the question if this conciseness\nis retained when performing Boolean operations (such as disjunction and\nconjunction) over COCOA by showing that there exist families of languages for\nwhich these operations lead to an exponential growth of the sizes of the\nautomata. The families have the property that when representing them using\ndeterministic parity automata, taking the disjunction or conjunction of them\nonly requires a polynomial blow-up, which shows that Boolean operations over\nCOCOA do not retain their conciseness in general.", "AI": {"tldr": "COCOA\uff08co-B\u00fcchi\u81ea\u52a8\u673a\u94fe\uff09\u662f\u03c9-\u6b63\u5219\u8bed\u8a00\u7684\u65b0\u89c4\u8303\u8868\u793a\u6a21\u578b\uff0c\u672c\u6587\u5206\u6790\u5176\u7b80\u6d01\u6027\uff0c\u8bc1\u660e\u5373\u4f7f\u6240\u6709\u81ea\u52a8\u673a\u90fd\u662f\u786e\u5b9a\u6027\u7684\uff0cCOCOA\u4e5f\u6bd4\u786e\u5b9a\u6027\u5947\u5076\u81ea\u52a8\u673a\u6307\u6570\u7ea7\u66f4\u7b80\u6d01\uff0c\u4f46\u5e03\u5c14\u8fd0\u7b97\u4f1a\u5bfc\u81f4\u6307\u6570\u7ea7\u589e\u957f\u3002", "motivation": "\u7814\u7a76COCOA\u4f5c\u4e3a\u03c9-\u6b63\u5219\u8bed\u8a00\u89c4\u8303\u8868\u793a\u6a21\u578b\u7684\u7b80\u6d01\u6027\u7279\u6027\uff0c\u7279\u522b\u662f\u4e0e\u65e9\u671f\u81ea\u52a8\u673a\u6a21\u578b\u7684\u5173\u7cfb\u4ee5\u53ca\u5e03\u5c14\u8fd0\u7b97\u5bf9\u5176\u7b80\u6d01\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6784\u9020\u6027\u8bc1\u660e\uff0c\u6bd4\u8f83COCOA\u4e0e\u786e\u5b9a\u6027\u5947\u5076\u81ea\u52a8\u673a\u5728\u8868\u793a\u76f8\u540c\u8bed\u8a00\u65f6\u7684\u72b6\u6001\u590d\u6742\u5ea6\uff0c\u5e76\u5206\u6790\u5e03\u5c14\u8fd0\u7b97\uff08\u6790\u53d6\u548c\u5408\u53d6\uff09\u5bf9COCOA\u5927\u5c0f\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u786e\u5b9a\u6027COCOA\u53ef\u4ee5\u6307\u6570\u7ea7\u66f4\u7b80\u6d01\u5730\u8868\u793a\u67d0\u4e9b\u8bed\u8a00\uff0c\u4f46\u5e03\u5c14\u8fd0\u7b97\u4f1a\u5bfc\u81f4COCOA\u5927\u5c0f\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u800c\u540c\u6837\u7684\u8fd0\u7b97\u5728\u786e\u5b9a\u6027\u5947\u5076\u81ea\u52a8\u673a\u4e0a\u53ea\u9700\u8981\u591a\u9879\u5f0f\u589e\u957f\u3002", "conclusion": "\u867d\u7136COCOA\u5728\u5355\u72ec\u8868\u793a\u8bed\u8a00\u65f6\u5177\u6709\u6307\u6570\u7ea7\u7b80\u6d01\u6027\u4f18\u52bf\uff0c\u4f46\u8fd9\u79cd\u4f18\u52bf\u5728\u8fdb\u884c\u5e03\u5c14\u8fd0\u7b97\u65f6\u65e0\u6cd5\u4fdd\u6301\uff0c\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u590d\u6742\u8fd0\u7b97\u7684\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.13650", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13650", "abs": "https://arxiv.org/abs/2509.13650", "authors": ["Amena Amro", "Manar H. Alalfi"], "title": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "comment": null, "summary": "As software development practices increasingly adopt AI-powered tools,\nensuring that such tools can support secure coding has become critical. This\nstudy evaluates the effectiveness of GitHub Copilot's recently introduced code\nreview feature in detecting security vulnerabilities. Using a curated set of\nlabeled vulnerable code samples drawn from diverse open-source projects\nspanning multiple programming languages and application domains, we\nsystematically assessed Copilot's ability to identify and provide feedback on\ncommon security flaws. Contrary to expectations, our results reveal that\nCopilot's code review frequently fails to detect critical vulnerabilities such\nas SQL injection, cross-site scripting (XSS), and insecure deserialization.\nInstead, its feedback primarily addresses low-severity issues, such as coding\nstyle and typographical errors. These findings expose a significant gap between\nthe perceived capabilities of AI-assisted code review and its actual\neffectiveness in supporting secure development practices. Our results highlight\nthe continued necessity of dedicated security tools and manual code audits to\nensure robust software security.", "AI": {"tldr": "GitHub Copilot\u7684\u4ee3\u7801\u5ba1\u67e5\u529f\u80fd\u5728\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u4e3b\u8981\u5173\u6ce8\u4f4e\u4e25\u91cd\u6027\u95ee\u9898\u800c\u975e\u5173\u952e\u5b89\u5168\u6f0f\u6d1e", "motivation": "\u968f\u7740AI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bc4\u4f30AI\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728\u5b89\u5168\u7f16\u7801\u652f\u6301\u65b9\u9762\u7684\u5b9e\u9645\u6709\u6548\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981", "method": "\u4f7f\u7528\u6765\u81ea\u591a\u4e2a\u7f16\u7a0b\u8bed\u8a00\u548c\u5e94\u7528\u9886\u57df\u7684\u5f00\u6e90\u9879\u76ee\u4e2d\u7cbe\u9009\u7684\u6807\u8bb0\u6f0f\u6d1e\u4ee3\u7801\u6837\u672c\uff0c\u7cfb\u7edf\u8bc4\u4f30Copilot\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u7684\u80fd\u529b", "result": "Copilot\u4ee3\u7801\u5ba1\u67e5\u7ecf\u5e38\u65e0\u6cd5\u68c0\u6d4bSQL\u6ce8\u5165\u3001XSS\u548c\u4e0d\u5b89\u5168\u53cd\u5e8f\u5217\u5316\u7b49\u5173\u952e\u6f0f\u6d1e\uff0c\u4e3b\u8981\u53cd\u9988\u96c6\u4e2d\u5728\u7f16\u7801\u98ce\u683c\u548c\u62fc\u5199\u9519\u8bef\u7b49\u4f4e\u4e25\u91cd\u6027\u95ee\u9898", "conclusion": "AI\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u7684\u5b9e\u9645\u6548\u679c\u4e0e\u9884\u671f\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4ecd\u9700\u4e13\u7528\u5b89\u5168\u5de5\u5177\u548c\u4eba\u5de5\u4ee3\u7801\u5ba1\u8ba1\u6765\u786e\u4fdd\u8f6f\u4ef6\u5b89\u5168"}}
{"id": "2509.13871", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.13871", "abs": "https://arxiv.org/abs/2509.13871", "authors": ["Dror Fried", "Etay Segal", "Gad E. Yaron"], "title": "Algorithmic Perspective on Toda's Theorem", "comment": null, "summary": "Toda's Theorem is a fundamental result in computational complexity theory,\nwhose proof relies on a reduction from a QBF problem with a constant number of\nquantifiers to a model counting problem. While this reduction, henceforth\ncalled Toda's reduction, is of a purely theoretical nature, the recent progress\nof model counting tools raises the question of whether the reduction can be\nutilized to an efficient algorithm for solving QBF. In this work, we address\nthis question by looking at Toda's reduction from an algorithmic perspective.\nWe first convert the reduction into a concrete algorithm that given a QBF\nformula and a probability measure, produces the correct result with a\nconfidence level corresponding to the given measure. Beyond obtaining a naive\nprototype, our algorithm and the analysis that follows shed light on the fine\ndetails of the reduction that are so far left elusive. Then, we improve this\nprototype through various theoretical and algorithmic refinements. While our\nresults show a significant progress over the naive prototype, they also provide\na clearer understanding of the remaining challenges in turning Toda's reduction\ninto a competitive solver.", "AI": {"tldr": "\u672c\u6587\u4ece\u7b97\u6cd5\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6Toda\u5b9a\u7406\u7684\u5f52\u7ea6\u8fc7\u7a0b\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u5177\u4f53\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u7b97\u6cd5\u6539\u8fdb\u63d0\u5347\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u5c06\u7406\u8bba\u5f52\u7ea6\u8f6c\u5316\u4e3a\u5b9e\u7528QBF\u6c42\u89e3\u5668\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u8ba1\u6570\u5de5\u5177\u7684\u8fdb\u6b65\uff0c\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u5229\u7528Toda\u7684\u7406\u8bba\u5f52\u7ea6\u6765\u5f00\u53d1\u9ad8\u6548\u7684QBF\u6c42\u89e3\u7b97\u6cd5", "method": "\u9996\u5148\u5c06Toda\u5f52\u7ea6\u8f6c\u5316\u4e3a\u5177\u4f53\u7b97\u6cd5\uff0c\u7ed9\u5b9aQBF\u516c\u5f0f\u548c\u6982\u7387\u5ea6\u91cf\u4ea7\u751f\u7f6e\u4fe1\u7ed3\u679c\uff1b\u7136\u540e\u901a\u8fc7\u7406\u8bba\u548c\u7b97\u6cd5\u6539\u8fdb\u4f18\u5316\u539f\u578b", "result": "\u76f8\u6bd4\u521d\u59cb\u539f\u578b\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u540c\u65f6\u4e5f\u66f4\u6e05\u695a\u5730\u8ba4\u8bc6\u5230\u5c06Toda\u5f52\u7ea6\u8f6c\u5316\u4e3a\u6709\u7ade\u4e89\u529b\u6c42\u89e3\u5668\u6240\u9762\u4e34\u7684\u6311\u6218", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3Toda\u5f52\u7ea6\u7684\u7ec6\u8282\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u6307\u51fa\u4e86\u7406\u8bba\u5f52\u7ea6\u5b9e\u7528\u5316\u8fc7\u7a0b\u4e2d\u9700\u8981\u89e3\u51b3\u7684\u5173\u952e\u95ee\u9898"}}
{"id": "2509.13656", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13656", "abs": "https://arxiv.org/abs/2509.13656", "authors": ["Yingao Elaine Yao", "Vedant Nimje", "Varun Viswanath", "Saikat Dutta"], "title": "A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks", "comment": "22 pages, 2 figures, 6 tables", "summary": "Notebooks have become the de-facto choice for data scientists and machine\nlearning engineers for prototyping and experimenting with machine learning (ML)\npipelines. Notebooks provide an interactive interface for code, data, and\nvisualization. However, notebooks provide very limited support for testing.\nThus, during continuous development, many subtle bugs that do not lead to\ncrashes often go unnoticed and cause silent errors that manifest as performance\nregressions.\n  To address this, we introduce NBTest - the first regression testing framework\nthat allows developers to write cell-level assertions in notebooks and run such\nnotebooks in pytest or in continuous integration (CI) pipelines. NBTest offers\na library of assertion APIs, and a JupyterLab plugin that enables executing\nassertions. We also develop the first automated approach for generating\ncell-level assertions for key components in ML notebooks, such as data\nprocessing, model building, and model evaluation. NBTest aims to improve the\nreliability and maintainability of ML notebooks without adding developer\nburden.\n  We evaluate NBTest on 592 Kaggle notebooks. Overall, NBTest generates 21163\nassertions (35.75 on average per notebook). The generated assertions obtain a\nmutation score of 0.57 in killing ML-specific mutations. NBTest can catch\nregression bugs in previous versions of the Kaggle notebooks using assertions\ngenerated for the latest versions. Because ML pipelines involve non\ndeterministic computations, the assertions can be flaky. Hence, we also show\nhow NBTest leverages statistical techniques to minimize flakiness while\nretaining high fault-detection effectiveness. NBTest has been adopted in the CI\nof a popular ML library. Further, we perform a user study with 17 participants\nthat shows that notebook users find NBTest intuitive (Rating 4.3/5) and useful\nin writing assertions and testing notebooks (Rating 4.24/5).", "AI": {"tldr": "NBTest\u662f\u4e00\u4e2a\u9488\u5bf9Jupyter\u7b14\u8bb0\u672c\u7684\u56de\u5f52\u6d4b\u8bd5\u6846\u67b6\uff0c\u63d0\u4f9b\u5355\u5143\u683c\u7ea7\u65ad\u8a00\u548c\u81ea\u52a8\u5316\u65ad\u8a00\u751f\u6210\uff0c\u65e8\u5728\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u7684\u53ef\u9760\u6027\u800c\u4e0d\u589e\u52a0\u5f00\u53d1\u8005\u8d1f\u62c5\u3002", "motivation": "Jupyter\u7b14\u8bb0\u672c\u5728\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u6d4b\u8bd5\u652f\u6301\uff0c\u5bfc\u81f4\u8bb8\u591a\u4e0d\u6613\u5bdf\u89c9\u7684bug\u548c\u6027\u80fd\u56de\u5f52\u95ee\u9898\u96be\u4ee5\u88ab\u53d1\u73b0\u3002", "method": "\u5f00\u53d1NBTest\u6846\u67b6\uff0c\u5305\u62ec\u65ad\u8a00API\u5e93\u3001JupyterLab\u63d2\u4ef6\u548c\u81ea\u52a8\u5316\u65ad\u8a00\u751f\u6210\u65b9\u6cd5\uff0c\u652f\u6301\u5728pytest\u548cCI\u6d41\u6c34\u7ebf\u4e2d\u8fd0\u884c\u7b14\u8bb0\u672c\u6d4b\u8bd5\u3002", "result": "\u5728592\u4e2aKaggle\u7b14\u8bb0\u672c\u4e0a\u751f\u621021,163\u4e2a\u65ad\u8a00\uff08\u5e73\u5747\u6bcf\u4e2a\u7b14\u8bb0\u672c35.75\u4e2a\uff09\uff0c\u53d8\u5f02\u5f97\u5206\u4e3a0.57\uff0c\u80fd\u591f\u6355\u83b7\u56de\u5f52bug\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u6613\u7528\u6027\u8bc4\u52064.3/5\uff0c\u5b9e\u7528\u6027\u8bc4\u52064.24/5\u3002", "conclusion": "NBTest\u6709\u6548\u63d0\u9ad8\u4e86\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u7684\u6d4b\u8bd5\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u8ba1\u6280\u672f\u51cf\u5c11\u975e\u786e\u5b9a\u6027\u8ba1\u7b97\u5e26\u6765\u7684\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\uff0c\u5df2\u88ab\u5b9e\u9645ML\u5e93\u91c7\u7528\u3002"}}
{"id": "2509.14089", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.14089", "abs": "https://arxiv.org/abs/2509.14089", "authors": ["Luca Aceto", "Antonis Achilleos", "Aggeliki Chalki", "Anna Ing\u00f3lfsd\u00f3ttir"], "title": "The Complexity of Deciding Characteristic Formulae Modulo Nested Simulation (extended abstract)", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258. A full version of this\n  paper, containing all proofs, appears at arXiv:2505.22277", "summary": "This paper studies the complexity of determining whether a formula in the\nmodal logics characterizing the nested-simulation semantics is characteristic\nfor some process, which is equivalent to determining whether the formula is\nsatisfiable and prime. The main results are that the problem of determining\nwhether a formula is prime in the modal logic characterizing the\n2-nested-simulation preorder is coNP-complete and is PSPACE-complete in the\ncase of the n-nested-simulation preorder, when n>=3. This establishes that\ndeciding characteristic formulae for the n-nested simulation semantics is\nPSPACE-complete, when n>=3. In the case of the 2-nested simulation semantics,\nthat problem lies in the complexity class DP, which consists of languages that\ncan be expressed as the intersection of one language in NP and of one in coNP.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6a21\u6001\u903b\u8f91\u4e2d\u516c\u5f0f\u662f\u5426\u4e3a\u67d0\u4e2a\u8fc7\u7a0b\u7684\u7279\u5f81\u516c\u5f0f\u7684\u590d\u6742\u6027\uff0c\u8be5\u95ee\u9898\u7b49\u4ef7\u4e8e\u5224\u65ad\u516c\u5f0f\u662f\u5426\u53ef\u6ee1\u8db3\u4e14\u4e3a\u7d20\u516c\u5f0f\u3002\u4e3b\u8981\u7ed3\u679c\u662f\uff1a\u5224\u65ad\u516c\u5f0f\u57282-\u5d4c\u5957\u6a21\u62df\u9884\u5e8f\u6a21\u6001\u903b\u8f91\u4e2d\u662f\u5426\u4e3a\u7d20\u516c\u5f0f\u662fcoNP\u5b8c\u5168\u7684\uff0c\u5728n-\u5d4c\u5957\u6a21\u62df\u9884\u5e8f\u4e2d\uff08n\u22653\uff09\u662fPSPACE\u5b8c\u5168\u7684\u3002", "motivation": "\u7814\u7a76\u6a21\u6001\u903b\u8f91\u4e2d\u7279\u5f81\u516c\u5f0f\u5224\u5b9a\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5d4c\u5957\u6a21\u62df\u8bed\u4e49\u7684\u7279\u5f81\u516c\u5f0f\u5224\u5b9a\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u5f62\u5f0f\u9a8c\u8bc1\u548c\u8fdb\u7a0b\u4ee3\u6570\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u590d\u6742\u5ea6\u8bc1\u660e\uff0c\u7814\u7a76\u4e86\u4e0d\u540c\u5d4c\u5957\u5c42\u6b21\uff082-\u5d4c\u5957\u548cn\u22653\u5d4c\u5957\uff09\u6a21\u62df\u9884\u5e8f\u6a21\u6001\u903b\u8f91\u4e2d\u516c\u5f0f\u7d20\u6027\u5224\u5b9a\u95ee\u9898\u7684\u590d\u6742\u5ea6\u5206\u7c7b\u3002", "result": "2-\u5d4c\u5957\u6a21\u62df\u9884\u5e8f\u7684\u7d20\u516c\u5f0f\u5224\u5b9a\u662fcoNP\u5b8c\u5168\u7684\uff1bn\u22653\u5d4c\u5957\u6a21\u62df\u9884\u5e8f\u7684\u7d20\u516c\u5f0f\u5224\u5b9a\u662fPSPACE\u5b8c\u5168\u7684\uff1b2-\u5d4c\u5957\u6a21\u62df\u8bed\u4e49\u7684\u7279\u5f81\u516c\u5f0f\u5224\u5b9a\u95ee\u9898\u5c5e\u4e8eDP\u590d\u6742\u5ea6\u7c7b\u3002", "conclusion": "\u5bf9\u4e8en\u22653\u7684\u5d4c\u5957\u6a21\u62df\u8bed\u4e49\uff0c\u5224\u5b9a\u7279\u5f81\u516c\u5f0f\u662fPSPACE\u5b8c\u5168\u7684\uff0c\u8fd9\u4e3a\u76f8\u5173\u6a21\u6001\u903b\u8f91\u95ee\u9898\u7684\u590d\u6742\u5ea6\u8fb9\u754c\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2509.13680", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13680", "abs": "https://arxiv.org/abs/2509.13680", "authors": ["Wei Ma", "Yixiao Yang", "Jingquan Ge", "Xiaofei Xie", "Lingxiao Jiang"], "title": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "comment": null, "summary": "Code generation models are widely used in software development, yet their\nsensitivity to prompt phrasing remains under-examined. Identical requirements\nexpressed with different emotions or communication styles can yield divergent\noutputs, while most benchmarks emphasize only peak performance. We present\nPromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically\nequivalent prompt variants with emotion and personality templates, and that\nevaluates stability using probability aware continuous scoring or using binary\npass rates when logits are unavailable. The results are aggregated into a\nproposed area under curve metric (AUC-E) for cross model comparison. Across 14\nmodels from three families (Llama, Qwen, and DeepSeek), our study shows that\nperformance and stability behave as largely decoupled optimization objectives,\nand it reveals architectural and scale related patterns that challenge common\nassumptions about model robustness. The framework supports rapid screening for\nclosed-source models as well as detailed stability analysis in research\nsettings. PromptSE enables practitioners to quantify performance stability\ntrade offs for deployment and model selection, positioning prompt stability as\na complementary evaluation dimension alongside performance and fairness, and\ncontributing to more trustworthy AI-assisted software development tools.", "AI": {"tldr": "PromptSE\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5bf9\u63d0\u793a\u8bcd\u8868\u8fbe\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u521b\u5efa\u8bed\u4e49\u76f8\u540c\u4f46\u60c5\u611f\u548c\u98ce\u683c\u4e0d\u540c\u7684\u63d0\u793a\u53d8\u4f53\uff0c\u53d1\u73b0\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u662f\u89e3\u8026\u7684\u4f18\u5316\u76ee\u6807", "motivation": "\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5bf9\u63d0\u793a\u8bcd\u8868\u8fbe\u7684\u654f\u611f\u6027\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u76f8\u540c\u9700\u6c42\u7528\u4e0d\u540c\u60c5\u611f\u6216\u6c9f\u901a\u98ce\u683c\u8868\u8fbe\u4f1a\u4ea7\u751f\u4e0d\u540c\u8f93\u51fa\uff0c\u800c\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5cf0\u503c\u6027\u80fd", "method": "\u63d0\u51faPromptSE\u6846\u67b6\uff0c\u4f7f\u7528\u60c5\u611f\u548c\u4e2a\u6027\u6a21\u677f\u521b\u5efa\u8bed\u4e49\u7b49\u4ef7\u7684\u63d0\u793a\u53d8\u4f53\uff0c\u91c7\u7528\u6982\u7387\u611f\u77e5\u8fde\u7eed\u8bc4\u5206\u6216\u4e8c\u5143\u901a\u8fc7\u7387\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u5e76\u4f7f\u7528AUC-E\u6307\u6807\u8fdb\u884c\u8de8\u6a21\u578b\u6bd4\u8f83", "result": "\u572814\u4e2a\u6a21\u578b\uff08Llama\u3001Qwen\u3001DeepSeek\uff09\u4e0a\u7684\u7814\u7a76\u8868\u660e\uff0c\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u662f\u89e3\u8026\u7684\u4f18\u5316\u76ee\u6807\uff0c\u63ed\u793a\u4e86\u67b6\u6784\u548c\u89c4\u6a21\u76f8\u5173\u7684\u6a21\u5f0f\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5e38\u89c1\u5047\u8bbe", "conclusion": "PromptSE\u80fd\u591f\u91cf\u5316\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u7684\u6743\u8861\uff0c\u652f\u6301\u90e8\u7f72\u548c\u6a21\u578b\u9009\u62e9\uff0c\u5c06\u63d0\u793a\u7a33\u5b9a\u6027\u5b9a\u4f4d\u4e3a\u4e0e\u6027\u80fd\u548c\u516c\u5e73\u6027\u4e92\u8865\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u4fe1\u7684AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177"}}
{"id": "2509.14090", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2509.14090", "abs": "https://arxiv.org/abs/2509.14090", "authors": ["Massimo Benerecetti", "Dario Della Monica", "Angelo Matteo", "Fabio Mogavero", "Gabriele Puppis"], "title": "An Automaton-based Characterisation of First-Order Logic over Infinite Trees", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "In this paper, we study First Order Logic (FO) over (unordered) infinite\ntrees and its connection with branching-time temporal logics. More\nspecifically, we provide an automata-theoretic characterisation of FO\ninterpreted over infinite trees. To this end, two different classes of hesitant\ntree automata are introduced and proved to capture precisely the expressive\npower of two branching time temporal logics, denoted polcCTLp and cCTL*[f],\nwhich are, respectively, a restricted version of counting CTL with past and\ncounting CTL* over finite paths, both of which have been previously shown\nequivalent to FO over infinite trees. The two automata characterisations\nnaturally lead to normal forms for the two temporal logics, and highlight the\nfact that FO can only express properties of the tree branches which are either\nsafety or co-safety in nature.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u4e24\u7c7b\u72b9\u8c6b\u6811\u81ea\u52a8\u673a\uff0c\u4e3a\u65e0\u9650\u6811\u4e0a\u7684FO\u903b\u8f91\u63d0\u4f9b\u4e86\u81ea\u52a8\u673a\u7406\u8bba\u7279\u5f81\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u5206\u652f\u65f6\u5e8f\u903b\u8f91polcCTLp\u548ccCTL*[f]\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u65e0\u9650\u6811\u4e0a\u7684\u4e00\u9636\u903b\u8f91(FO)\u53ca\u5176\u4e0e\u5206\u652f\u65f6\u5e8f\u903b\u8f91\u7684\u5173\u7cfb\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u673a\u7406\u8bba\u6765\u523b\u753bFO\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e24\u7c7b\u72b9\u8c6b\u6811\u81ea\u52a8\u673a\uff0c\u8bc1\u660e\u5b83\u4eec\u80fd\u7cbe\u786e\u6355\u6349\u4e24\u4e2a\u5206\u652f\u65f6\u5e8f\u903b\u8f91polcCTLp\u548ccCTL*[f]\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8fd9\u4e24\u4e2a\u903b\u8f91\u5df2\u88ab\u8bc1\u660e\u4e0e\u65e0\u9650\u6811\u4e0a\u7684FO\u7b49\u4ef7\u3002", "result": "\u83b7\u5f97\u4e86FO\u5728\u65e0\u9650\u6811\u4e0a\u7684\u81ea\u52a8\u673a\u7279\u5f81\uff0c\u4e3a\u4e24\u4e2a\u65f6\u5e8f\u903b\u8f91\u63d0\u4f9b\u4e86\u6b63\u89c4\u5f62\u5f0f\uff0c\u5e76\u63ed\u793aFO\u53ea\u80fd\u8868\u8fbe\u6811\u5206\u652f\u4e0a\u7684\u5b89\u5168\u6027\u6216\u5171\u5b89\u5168\u6027\u6027\u8d28\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u673a\u7406\u8bba\u6210\u529f\u523b\u753b\u4e86FO\u5728\u65e0\u9650\u6811\u4e0a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5efa\u7acb\u4e86\u4e0e\u5206\u652f\u65f6\u5e8f\u903b\u8f91\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u5e76\u63ed\u793a\u4e86FO\u8868\u8fbe\u80fd\u529b\u7684\u672c\u8d28\u9650\u5236\u3002"}}
{"id": "2509.13755", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13755", "abs": "https://arxiv.org/abs/2509.13755", "authors": ["Zhaoyang Chu", "Yao Wan", "Zhikun Zhang", "Di Wang", "Zhou Yang", "Hongyu Zhang", "Pan Zhou", "Xuanhua Shi", "Hai Jin", "David Lo"], "title": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "While Code Language Models (CLMs) have demonstrated superior performance in\nsoftware engineering tasks such as code generation and summarization, recent\nempirical studies reveal a critical privacy vulnerability: these models exhibit\nunintended memorization of sensitive training data, enabling verbatim\nreproduction of confidential information when specifically prompted. To address\nthis issue, several approaches, including training data de-duplication and\ndifferential privacy augmentation, have been proposed. However, these methods\nrequire full-model retraining for deployed CLMs, which incurs substantial\ncomputational costs. In this paper, we aim to answer the following research\nquestion: Can sensitive information memorized by CLMs be erased effectively and\nefficiently?\n  We conduct a pioneering investigation into erasing sensitive memorization in\nCLMs through machine unlearning - a post-hoc modification method that removes\nspecific information from trained models without requiring full retraining.\nSpecifically, we first quantify the memorization risks of sensitive data within\nCLM training datasets and curate a high-risk dataset of 50,000 sensitive\nmemorized samples as unlearning targets. We study two widely used gradient\nascent-based unlearning approaches: the vanilla and constraint-based methods,\nand introduce CodeEraser, an advanced variant that selectively unlearns\nsensitive memorized segments in code while preserving the structural integrity\nand functional correctness of the surrounding code. Extensive experiments on\nthree families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,\nvalidate the effectiveness and efficiency of CodeEraser in erasing targeted\nsensitive memorization while maintaining model utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCodeEraser\u65b9\u6cd5\uff0c\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u6280\u672f\u6709\u6548\u64e6\u9664\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e2d\u654f\u611f\u4fe1\u606f\u7684\u8bb0\u5fc6\uff0c\u65e0\u9700\u5b8c\u6574\u91cd\u65b0\u8bad\u7ec3\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u529f\u80fd\u6027\u7684\u540c\u65f6\u89e3\u51b3\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u654f\u611f\u8bad\u7ec3\u6570\u636e\u8bb0\u5fc6\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u673a\u5bc6\u4fe1\u606f\u6cc4\u9732\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5b8c\u6574\u91cd\u65b0\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u654f\u611f\u4fe1\u606f\u64e6\u9664\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u673a\u5668\u9057\u5fd8\u6280\u672f\uff0c\u9996\u5148\u91cf\u5316CLM\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8bb0\u5fc6\u98ce\u9669\u5e76\u6784\u5efa5\u4e07\u4e2a\u9ad8\u98ce\u9669\u6837\u672c\u6570\u636e\u96c6\uff0c\u7814\u7a76\u57fa\u4e8e\u68af\u5ea6\u4e0a\u5347\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u5f00\u53d1CodeEraser\u9009\u62e9\u6027\u64e6\u9664\u4ee3\u7801\u4e2d\u654f\u611f\u8bb0\u5fc6\u7247\u6bb5\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u529f\u80fd\u6b63\u786e\u6027\u3002", "result": "\u5728CodeParrot\u3001CodeGen-Mono\u548cQwen2.5-Coder\u4e09\u4e2aCLM\u5bb6\u65cf\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86CodeEraser\u5728\u64e6\u9664\u76ee\u6807\u654f\u611f\u8bb0\u5fc6\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u5b9e\u7528\u6027\u3002", "conclusion": "CodeEraser\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u6f0f\u6d1e\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14094", "categories": ["cs.LO", "F.4.1;I.2.3"], "pdf": "https://arxiv.org/pdf/2509.14094", "abs": "https://arxiv.org/abs/2509.14094", "authors": ["Radu Mardare", "Neil Ghani", "Eigil Rischel"], "title": "Metric Equational Theories", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "This paper proposes appropriate sound and complete proof systems for\nalgebraic structures over metric spaces by combining the development of\nQuantitative Equational Theories (QET) with the Enriched Lawvere Theories. We\nextend QETs to Metric Equational Theories (METs) where operations no longer\nhave finite sets as arities (as in QETs and the general theory of universal\nalgebras), but arities are now drawn from countable metric spaces. This\nextension is inspired by the theory of Enriched Lawvere Theories, which\nsuggests that the arities of operations should be the lambda-presentable\nobjects of the underlying lambda-accessible category. In this setting, the\nvalidity of terms in METs can no longer be guaranteed independently of the\nvalidity of equations, as is the case with QET. We solve this problem, and\nadapt the sound and complete proof system for QETs to these more general METs,\ntaking advantage of the specific structure of metric spaces.", "AI": {"tldr": "\u5c06\u5b9a\u91cf\u7b49\u5f0f\u7406\u8bba(QET)\u6269\u5c55\u5230\u5ea6\u91cf\u7b49\u5f0f\u7406\u8bba(MET)\uff0c\u5176\u4e2d\u64cd\u4f5c\u7684\u5143\u6570\u6765\u81ea\u53ef\u6570\u5ea6\u91cf\u7a7a\u95f4\u800c\u975e\u6709\u9650\u96c6\uff0c\u5e76\u4e3a\u6b64\u7c7b\u4ee3\u6570\u7ed3\u6784\u6784\u5efa\u4e86\u5b8c\u5907\u7684\u8bc1\u660e\u7cfb\u7edf", "motivation": "\u53d7\u4e30\u5bccLawvere\u7406\u8bba\u542f\u53d1\uff0c\u9700\u8981\u5c06QET\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u5ea6\u91cf\u7a7a\u95f4\u4ee3\u6570\u7ed3\u6784\uff0c\u5176\u4e2d\u64cd\u4f5c\u5143\u6570\u6765\u81ea\u53ef\u6570\u5ea6\u91cf\u7a7a\u95f4\uff0c\u8fd9\u5bfc\u81f4\u9879\u7684\u6709\u6548\u6027\u4e0d\u518d\u72ec\u7acb\u4e8e\u7b49\u5f0f\u7684\u6709\u6548\u6027", "method": "\u7ed3\u5408\u5b9a\u91cf\u7b49\u5f0f\u7406\u8bba\u548c\u4e30\u5bccLawvere\u7406\u8bba\uff0c\u5229\u7528\u5ea6\u91cf\u7a7a\u95f4\u7684\u7279\u5b9a\u7ed3\u6784\uff0c\u5c06QET\u7684\u5b8c\u5907\u8bc1\u660e\u7cfb\u7edf\u9002\u914d\u5230\u66f4\u4e00\u822c\u7684MET\u4e2d", "result": "\u6210\u529f\u89e3\u51b3\u4e86MET\u4e2d\u9879\u6709\u6548\u6027\u4f9d\u8d56\u7b49\u5f0f\u6709\u6548\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u5ea6\u91cf\u7a7a\u95f4\u4ee3\u6570\u7ed3\u6784\u6784\u5efa\u4e86\u9002\u5f53\u7684\u5b8c\u5907\u8bc1\u660e\u7cfb\u7edf", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u4e86QET\u5230\u66f4\u4e00\u822c\u7684\u5ea6\u91cf\u7a7a\u95f4\u4ee3\u6570\u7ed3\u6784\uff0c\u4e3a\u8fd9\u7c7b\u7ed3\u6784\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177"}}
{"id": "2509.13758", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13758", "abs": "https://arxiv.org/abs/2509.13758", "authors": ["Kevin Halim", "Sin G. Teo", "Ruitao Feng", "Zhenpeng Chen", "Yang Gu", "Chong Wang", "Yang Liu"], "title": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "comment": null, "summary": "Currently, many large language models (LLMs) are utilized for software\nengineering tasks such as code generation. The emergence of more advanced\nmodels known as large reasoning models (LRMs), such as OpenAI's o3, DeepSeek\nR1, and Qwen3. They have demonstrated the capability of performing multi-step\nreasoning. Despite the advancement in LRMs, little attention has been paid to\nsystematically analyzing the reasoning patterns these models exhibit and how\nsuch patterns influence the generated code. This paper presents a comprehensive\nstudy aimed at investigating and uncovering the reasoning behavior of LRMs\nduring code generation. We prompted several state-of-the-art LRMs of varying\nsizes with code generation tasks and applied open coding to manually annotate\nthe reasoning traces. From this analysis, we derive a taxonomy of LRM reasoning\nbehaviors, encompassing 15 reasoning actions across four phases.\n  Our empirical study based on the taxonomy reveals a series of findings.\nFirst, we identify common reasoning patterns, showing that LRMs generally\nfollow a human-like coding workflow, with more complex tasks eliciting\nadditional actions such as scaffolding, flaw detection, and style checks.\nSecond, we compare reasoning across models, finding that Qwen3 exhibits\niterative reasoning while DeepSeek-R1-7B follows a more linear, waterfall-like\napproach. Third, we analyze the relationship between reasoning and code\ncorrectness, showing that actions such as unit test creation and scaffold\ngeneration strongly support functional outcomes, with LRMs adapting strategies\nbased on task context. Finally, we evaluate lightweight prompting strategies\ninformed by these findings, demonstrating the potential of context- and\nreasoning-oriented prompts to improve LRM-generated code. Our results offer\ninsights and practical implications for advancing automatic code generation.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\uff0c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\u5efa\u7acb\u4e86\u5305\u542b15\u79cd\u63a8\u7406\u884c\u4e3a\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u63a8\u7406\u7279\u70b9\u53ca\u5176\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u63a8\u7406\u7684\u63d0\u793a\u7b56\u7565\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6a21\u578b\u63a8\u7406\u6a21\u5f0f\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6a21\u5f0f\u5982\u4f55\u5f71\u54cd\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u5148\u8fdbLRM\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u91c7\u7528\u5f00\u653e\u5f0f\u7f16\u7801\u65b9\u6cd5\u624b\u52a8\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\uff0c\u4ece\u4e2d\u63a8\u5bfc\u51fa\u5305\u542b15\u79cd\u63a8\u7406\u884c\u4e3a\u7684\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u56db\u4e2a\u63a8\u7406\u9636\u6bb5\u3002", "result": "\u53d1\u73b0LRMs\u9075\u5faa\u7c7b\u4eba\u7f16\u7801\u5de5\u4f5c\u6d41\uff0c\u590d\u6742\u4efb\u52a1\u5f15\u53d1\u989d\u5916\u63a8\u7406\u884c\u4e3a\uff1b\u4e0d\u540c\u6a21\u578b\u63a8\u7406\u6a21\u5f0f\u5dee\u5f02\u663e\u8457(Qwen3\u8fed\u4ee3\u5f0f\uff0cDeepSeek-R1-7B\u7011\u5e03\u5f0f)\uff1b\u5355\u5143\u6d4b\u8bd5\u521b\u5efa\u548c\u811a\u624b\u67b6\u751f\u6210\u7b49\u884c\u4e3a\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u5f3a\u76f8\u5173\uff1b\u57fa\u4e8e\u63a8\u7406\u7684\u63d0\u793a\u7b56\u7565\u80fd\u6709\u6548\u6539\u8fdb\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LRMs\u7684\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\u53ca\u5176\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u5f71\u54cd\uff0c\u4e3a\u6539\u8fdb\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u548c\u63a8\u7406\u5bfc\u5411\u7684\u63d0\u793a\u7b56\u7565\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.14095", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2509.14095", "abs": "https://arxiv.org/abs/2509.14095", "authors": ["Ga\u00ebtan Regaud", "Martin Zimmermann"], "title": "The Complexity of Generalized HyperLTL with Stuttering and Contexts", "comment": "In Proceedings GandALF 2025, arXiv:2509.13258", "summary": "We settle the complexity of satisfiability and model-checking for generalized\nHyperLTL with stuttering and contexts, an expressive logic for the\nspecification of asynchronous hyperproperties. Such properties cannot be\nspecified in HyperLTL, as it is restricted to synchronous hyperproperties.\nNevertheless, we prove that satisfiability is $\\Sigma_1^1$-complete and thus\nnot harder than for HyperLTL. On the other hand, we prove that model-checking\nis equivalent to truth in second-order arithmetic, and thus much harder than\nthe decidable HyperLTL model-checking problem. The lower bounds for the\nmodel-checking problem hold even when only allowing stuttering or only allowing\ncontexts.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e7f\u4e49HyperLTL\uff08\u5305\u542b\u505c\u987f\u548c\u4e0a\u4e0b\u6587\uff09\u7684\u6ee1\u8db3\u6027\u548c\u6a21\u578b\u68c0\u6d4b\u590d\u6742\u5ea6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8868\u8fbe\u5f02\u6b65\u8d85\u5c5e\u6027\u7684\u5f3a\u5927\u903b\u8f91\u3002", "motivation": "HyperLTL\u53ea\u80fd\u8868\u8fbe\u540c\u6b65\u8d85\u5c5e\u6027\uff0c\u65e0\u6cd5\u5904\u7406\u5f02\u6b65\u8d85\u5c5e\u6027\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u8005\u5f15\u5165\u4e86\u5305\u542b\u505c\u987f\u548c\u4e0a\u4e0b\u6587\u7684\u5e7f\u4e49HyperLTL\u6765\u652f\u6301\u5f02\u6b65\u8d85\u5c5e\u6027\u7684\u89c4\u8303\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u590d\u6742\u5ea6\u8bc1\u660e\uff0c\u7814\u7a76\u4e86\u5e7f\u4e49HyperLTL\u7684\u6ee1\u8db3\u6027\u95ee\u9898\u548c\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u6ee1\u8db3\u6027\u95ee\u9898\u4e3a\u03a3\u2081\u00b9-\u5b8c\u5168\uff0c\u4e0eHyperLTL\u590d\u6742\u5ea6\u76f8\u540c\uff1b\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u7b49\u4ef7\u4e8e\u4e8c\u9636\u7b97\u672f\u7684\u771f\u503c\u95ee\u9898\uff0c\u6bd4HyperLTL\u7684\u6a21\u578b\u68c0\u6d4b\u95ee\u9898\u56f0\u96be\u5f97\u591a\u3002", "conclusion": "\u5e7f\u4e49HyperLTL\u867d\u7136\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\uff0c\u4f46\u6a21\u578b\u68c0\u6d4b\u590d\u6742\u5ea6\u663e\u8457\u589e\u52a0\uff0c\u5373\u4f7f\u53ea\u5141\u8bb8\u505c\u987f\u6216\u53ea\u5141\u8bb8\u4e0a\u4e0b\u6587\uff0c\u4e0b\u754c\u4ecd\u7136\u6210\u7acb\u3002"}}
{"id": "2509.13782", "categories": ["cs.SE", "cs.AI", "cs.MA", "D.2.2; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.13782", "abs": "https://arxiv.org/abs/2509.13782", "authors": ["Yu Ge", "Linna Xie", "Zhong Li", "Yu Pei", "Tian Zhang"], "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "comment": "20 pages, 6 figures", "summary": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly\nemployed to automate complex real-world problems, such as programming and\nscientific discovery. Despite their promising, MASs are not without their\nflaws. However, failure attribution in MASs - pinpointing the specific agent\nactions responsible for failures - remains underexplored and labor-intensive,\nposing significant challenges for debugging and system improvement. To bridge\nthis gap, we propose FAMAS, the first spectrum-based failure attribution\napproach for MASs, which operates through systematic trajectory replay and\nabstraction, followed by spectrum analysis.The core idea of FAMAS is to\nestimate, from variations across repeated MAS executions, the likelihood that\neach agent action is responsible for the failure. In particular, we propose a\nnovel suspiciousness formula tailored to MASs, which integrates two key factor\ngroups, namely the agent behavior group and the action behavior group, to\naccount for the agent activation patterns and the action activation patterns\nwithin the execution trajectories of MASs. Through expensive evaluations\nagainst 12 baselines on the Who and When benchmark, FAMAS demonstrates superior\nperformance by outperforming all the methods in comparison.", "AI": {"tldr": "FAMAS\u662f\u9996\u4e2a\u57fa\u4e8e\u9891\u8c31\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u91cd\u653e\u548c\u9891\u8c31\u5206\u6790\u6765\u8bc6\u522b\u5bfc\u81f4\u6545\u969c\u7684\u5177\u4f53\u667a\u80fd\u4f53\u884c\u4e3a", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u6545\u969c\uff0c\u4f46\u6545\u969c\u5f52\u56e0\u56f0\u96be\u4e14\u4eba\u5de5\u5bc6\u96c6\uff0c\u963b\u788d\u4e86\u7cfb\u7edf\u8c03\u8bd5\u548c\u6539\u8fdb", "method": "\u63d0\u51faFAMAS\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u8f68\u8ff9\u91cd\u653e\u548c\u62bd\u8c61\uff0c\u7136\u540e\u8fdb\u884c\u9891\u8c31\u5206\u6790\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u667a\u80fd\u4f53\u884c\u4e3a\u5bfc\u81f4\u6545\u969c\u7684\u53ef\u80fd\u6027\u3002\u8bbe\u8ba1\u4e86\u4e13\u95e8\u9488\u5bf9MAS\u7684\u6000\u7591\u5ea6\u516c\u5f0f\uff0c\u6574\u5408\u667a\u80fd\u4f53\u884c\u4e3a\u7ec4\u548c\u52a8\u4f5c\u884c\u4e3a\u7ec4\u4e24\u4e2a\u5173\u952e\u56e0\u7d20", "result": "\u5728Who and When\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e12\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0cFAMAS\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4f18\u4e8e\u6240\u6709\u5bf9\u6bd4\u65b9\u6cd5", "conclusion": "FAMAS\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u5316\u6545\u969c\u5f52\u56e0\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u7cfb\u7edf\u8c03\u8bd5\u548c\u6539\u8fdb"}}
{"id": "2509.13852", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13852", "abs": "https://arxiv.org/abs/2509.13852", "authors": ["Yulun Wu", "Guangba Yu", "Zhihan Jiang", "Yichen Li", "Michael R. Lyu"], "title": "Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing", "comment": null, "summary": "Distributed tracing is an essential diagnostic tool in microservice systems,\nbut the sheer volume of traces places a significant burden on backend storage.\nA common approach to mitigating this issue is trace sampling, which selectively\nretains traces based on specific criteria, often preserving only anomalous\nones. However, this method frequently discards valuable information, including\nnormal traces that are essential for comparative analysis. To address this\nlimitation, we introduce Trace Sampling 2.0, which operates at the span level\nwhile maintaining trace structure consistency. This approach allows for the\nretention of all traces while significantly reducing storage overhead. Based on\nthis concept, we design and implement Autoscope, a span-level sampling method\nthat leverages static analysis to extract execution logic, ensuring that\ncritical spans are preserved without compromising structural integrity. We\nevaluated Autoscope on two open-source microservices. Our results show that it\nreduces trace size by 81.2% while maintaining 98.1% faulty span coverage,\noutperforming existing trace-level sampling methods. Furthermore, we\ndemonstrate its effectiveness in root cause analysis, achieving an average\nimprovement of 8.3%. These findings indicate that Autoscope can significantly\nenhance observability and storage efficiency in microservices, offering a\nrobust solution for performance monitoring.", "AI": {"tldr": "Trace Sampling 2.0\u901a\u8fc7\u5728span\u7ea7\u522b\u8fdb\u884c\u91c7\u6837\uff0c\u5728\u4fdd\u6301trace\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\uff0cAutoscope\u5b9e\u73b0\u4e8681.2%\u7684trace\u5927\u5c0f\u51cf\u5c11\u548c98.1%\u7684\u6545\u969cspan\u8986\u76d6\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u8ffd\u8e2a\u5728\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u662f\u91cd\u8981\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4f46\u6d77\u91cftrace\u6570\u636e\u7ed9\u540e\u7aef\u5b58\u50a8\u5e26\u6765\u5de8\u5927\u8d1f\u62c5\u3002\u4f20\u7edftrace\u91c7\u6837\u65b9\u6cd5\u901a\u5e38\u4f1a\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u6b63\u5e38trace\u4fe1\u606f\uff0c\u5f71\u54cd\u5bf9\u6bd4\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86Trace Sampling 2.0\u6982\u5ff5\uff0c\u5728span\u7ea7\u522b\u8fdb\u884c\u91c7\u6837\u540c\u65f6\u4fdd\u6301trace\u7ed3\u6784\u4e00\u81f4\u6027\u3002\u8bbe\u8ba1\u5b9e\u73b0\u4e86Autoscope\u7cfb\u7edf\uff0c\u5229\u7528\u9759\u6001\u5206\u6790\u63d0\u53d6\u6267\u884c\u903b\u8f91\uff0c\u786e\u4fdd\u5173\u952espan\u88ab\u4fdd\u7559\u800c\u4e0d\u7834\u574f\u7ed3\u6784\u5b8c\u6574\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e90\u5fae\u670d\u52a1\u4e0a\u8bc4\u4f30\u663e\u793a\uff1atrace\u5927\u5c0f\u51cf\u5c1181.2%\uff0c\u6545\u969cspan\u8986\u76d6\u7387\u8fbe\u523098.1%\uff0c\u4f18\u4e8e\u73b0\u6709trace\u7ea7\u522b\u91c7\u6837\u65b9\u6cd5\u3002\u5728\u6839\u56e0\u5206\u6790\u4e2d\u5e73\u5747\u63d0\u53478.3%\u7684\u6548\u679c\u3002", "conclusion": "Autoscope\u80fd\u591f\u663e\u8457\u63d0\u5347\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u53ef\u89c2\u6d4b\u6027\u548c\u5b58\u50a8\u6548\u7387\uff0c\u4e3a\u6027\u80fd\u76d1\u63a7\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13868", "abs": "https://arxiv.org/abs/2509.13868", "authors": ["Manal Binkhonain", "Reem Alfayaz"], "title": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "comment": "33 pages, 12 figures", "summary": "Requirements classification assigns natural language requirements to\npredefined classes, such as functional and non functional. Accurate\nclassification reduces risk and improves software quality. Most existing models\nrely on supervised learning, which needs large labeled data that are costly,\nslow to create, and domain dependent; they also generalize poorly and often\nrequire retraining for each task. This study tests whether prompt based large\nlanguage models can reduce data needs. We benchmark several models and\nprompting styles (zero shot, few shot, persona, and chain of thought) across\nmultiple tasks on two English datasets, PROMISE and SecReq. For each task we\ncompare model prompt configurations and then compare the best LLM setups with a\nstrong fine tuned transformer baseline. Results show that prompt based LLMs,\nespecially with few shot prompts, can match or exceed the baseline. Adding a\npersona, or persona plus chain of thought, can yield further gains. We conclude\nthat prompt based LLMs are a practical and scalable option that reduces\ndependence on large annotations and can improve generalizability across tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u6d4b\u8bd5\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u51cf\u5c11\u9700\u6c42\u5206\u7c7b\u4e2d\u7684\u6570\u636e\u9700\u6c42\uff0c\u901a\u8fc7\u591a\u79cd\u63d0\u793a\u65b9\u5f0f\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0c\u53d1\u73b0few shot\u63d0\u793a\u7684LLM\u53ef\u4ee5\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edf\u5fae\u8c03\u6a21\u578b\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u5206\u7c7b\u6a21\u578b\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u6210\u672c\u9ad8\u3001\u521b\u5efa\u6162\u3001\u9886\u57df\u4f9d\u8d56\u6027\u5f3a\uff0c\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u51cf\u5c11\u6570\u636e\u9700\u6c42\u5e76\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5728PROMISE\u548cSecReq\u4e24\u4e2a\u82f1\u6587\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u63d0\u793a\u98ce\u683c\uff08zero shot\u3001few shot\u3001persona\u3001chain of thought\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u5f3a\u5fae\u8c03transformer\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u663e\u793a\u57fa\u4e8e\u63d0\u793a\u7684LLM\uff0c\u7279\u522b\u662ffew shot\u63d0\u793a\uff0c\u53ef\u4ee5\u5339\u914d\u6216\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002\u6dfb\u52a0persona\u6216persona\u52a0chain of thought\u53ef\u4ee5\u5e26\u6765\u8fdb\u4e00\u6b65\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u9009\u62e9\uff0c\u51cf\u5c11\u4e86\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5e76\u80fd\u63d0\u9ad8\u8de8\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.13896", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13896", "abs": "https://arxiv.org/abs/2509.13896", "authors": ["Shalini Chakraborty", "Lola Burgue\u00f1o", "Nathalie Moreno", "Javier Troya", "Paula Mu\u00f1oz"], "title": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "comment": "8 pages, Educators Symposium at MODELS 2025", "summary": "Generative Artificial Intelligence (GenAI) is rapidly gaining momentum in\nsoftware modeling education, embraced by both students and educators. As GenAI\nassists with interpreting requirements, formalizing models, and translating\nstudents' mental models into structured notations, it increasingly shapes core\nlearning outcomes such as domain comprehension, diagrammatic thinking, and\nmodeling fluency without clear ethical oversight or pedagogical guidelines.\nYet, the ethical implications of this integration remain underexplored.\n  In this paper, we conduct a systematic literature review across six major\ndigital libraries in computer science (ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, SpringerLink, and Web of Science). Our aim is to\nidentify studies discussing the ethical aspects of GenAI in software modeling\neducation, including responsibility, fairness, transparency, diversity, and\ninclusion among others.\n  Out of 1,386 unique papers initially retrieved, only three explicitly\naddressed ethical considerations. This scarcity highlights the critical absence\nof ethical discourse surrounding GenAI in modeling education and raises urgent\nquestions about the responsible integration of AI in modeling curricula, as\nwell as it evinces the pressing need for structured ethical frameworks in this\nemerging educational landscape. We examine these three studies and explore the\nemerging research opportunities as well as the challenges that have arisen in\nthis field.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u53d1\u73b0\uff0c\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u7684\u4f26\u7406\u8003\u91cf\u4e25\u91cd\u7f3a\u5931\uff0c\u57281386\u7bc7\u76f8\u5173\u8bba\u6587\u4e2d\u4ec5\u67093\u7bc7\u660e\u786e\u8ba8\u8bba\u4f26\u7406\u95ee\u9898", "motivation": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u8fc5\u901f\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u4f26\u7406\u76d1\u7763\u548c\u6559\u5b66\u6307\u5bfc\uff0c\u5176\u4f26\u7406\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22", "method": "\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u516d\u5927\u6570\u5b57\u56fe\u4e66\u9986\uff08ACM\u3001IEEE\u3001Scopus\u7b49\uff09\u8fdb\u884c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u8bc6\u522b\u8ba8\u8bbaGenAI\u5728\u8f6f\u4ef6\u5efa\u6a21\u6559\u80b2\u4e2d\u4f26\u7406\u65b9\u9762\u7684\u7814\u7a76", "result": "\u4ece1386\u7bc7\u8bba\u6587\u4e2d\u4ec5\u53d1\u73b03\u7bc7\u660e\u786e\u8ba8\u8bba\u4f26\u7406\u8003\u91cf\uff0c\u7a81\u663e\u4e86\u8be5\u9886\u57df\u4f26\u7406\u8ba8\u8bba\u7684\u4e25\u91cd\u7f3a\u5931", "conclusion": "\u8feb\u5207\u9700\u8981\u5efa\u7acb\u7ed3\u6784\u5316\u4f26\u7406\u6846\u67b6\uff0c\u8d1f\u8d23\u4efb\u5730\u5c06AI\u6574\u5408\u5230\u5efa\u6a21\u8bfe\u7a0b\u4e2d\uff0c\u5e76\u9700\u8981\u66f4\u591a\u7814\u7a76\u6765\u5e94\u5bf9\u8fd9\u4e00\u65b0\u5174\u6559\u80b2\u9886\u57df\u7684\u4f26\u7406\u6311\u6218"}}
{"id": "2509.13941", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13941", "abs": "https://arxiv.org/abs/2509.13941", "authors": ["Simiao Liu", "Fang Liu", "Liehao Li", "Xin Tan", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "title": "An Empirical Study on Failures in Automated Issue Solving", "comment": null, "summary": "Automated issue solving seeks to autonomously identify and repair defective\ncode snippets across an entire codebase. SWE-Bench has emerged as the most\nwidely adopted benchmark for evaluating progress in this area. While LLM-based\nagentic tools show great promise, they still fail on a substantial portion of\ntasks. Moreover, current evaluations primarily report aggregate issue-solving\nrates, which obscure the underlying causes of success and failure, making it\nchallenging to diagnose model weaknesses or guide targeted improvements. To\nbridge this gap, we first analyze the performance and efficiency of three SOTA\ntools, spanning both pipeline-based and agentic architectures, in automated\nissue solving tasks of SWE-Bench-Verified under varying task characteristics.\nFurthermore, to move from high-level performance metrics to underlying cause\nanalysis, we conducted a systematic manual analysis of 150 failed instances.\nFrom this analysis, we developed a comprehensive taxonomy of failure modes\ncomprising 3 primary phases, 9 main categories, and 25 fine-grained\nsubcategories. Then we systematically analyze the distribution of the\nidentified failure modes, the results reveal distinct failure fingerprints\nbetween the two architectural paradigms, with the majority of agentic failures\nstemming from flawed reasoning and cognitive deadlocks. Motivated by these\ninsights, we propose a collaborative Expert-Executor framework. It introduces a\nsupervisory Expert agent tasked with providing strategic oversight and\ncourse-correction for a primary Executor agent. This architecture is designed\nto correct flawed reasoning and break the cognitive deadlocks that frequently\nlead to failure. Experiments show that our framework solves 22.2% of previously\nintractable issues for a leading single agent. These findings pave the way for\nbuilding more robust agents through diagnostic evaluation and collaborative\ndesign.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u4e2dLLM\u4ee3\u7406\u5de5\u5177\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b3\u4e2a\u9636\u6bb5\u30019\u4e2a\u7c7b\u522b\u548c25\u4e2a\u5b50\u7c7b\u522b\u7684\u5931\u8d25\u5206\u7c7b\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e13\u5bb6-\u6267\u884c\u8005\u534f\u4f5c\u6846\u67b6\u6765\u89e3\u51b3\u63a8\u7406\u7f3a\u9677\u548c\u8ba4\u77e5\u6b7b\u9501\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u8bc4\u4f30\u4e3b\u8981\u62a5\u544a\u805a\u5408\u6210\u529f\u7387\uff0c\u96be\u4ee5\u8bca\u65ad\u6a21\u578b\u5f31\u70b9\u6216\u6307\u5bfc\u9488\u5bf9\u6027\u6539\u8fdb\u3002\u9700\u8981\u6df1\u5165\u5206\u6790\u5931\u8d25\u539f\u56e0\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u4ee3\u7406\u63d0\u4f9b\u8bca\u65ad\u6027\u8bc4\u4f30\u548c\u534f\u4f5c\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u5206\u6790\u4e09\u79cdSOTA\u5de5\u5177\u5728SWE-Bench-Verified\u4e0a\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u7136\u540e\u5bf9150\u4e2a\u5931\u8d25\u5b9e\u4f8b\u8fdb\u884c\u7cfb\u7edf\u624b\u52a8\u5206\u6790\uff0c\u5efa\u7acb\u5931\u8d25\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u6700\u540e\u63d0\u51fa\u4e13\u5bb6-\u6267\u884c\u8005\u534f\u4f5c\u6846\u67b6\u6765\u7ea0\u6b63\u63a8\u7406\u7f3a\u9677\u548c\u8ba4\u77e5\u6b7b\u9501\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e24\u79cd\u67b6\u6784\u8303\u5f0f\u5177\u6709\u4e0d\u540c\u7684\u5931\u8d25\u7279\u5f81\uff0c\u591a\u6570\u4ee3\u7406\u5931\u8d25\u6e90\u4e8e\u63a8\u7406\u7f3a\u9677\u548c\u8ba4\u77e5\u6b7b\u9501\u3002\u63d0\u51fa\u7684\u534f\u4f5c\u6846\u67b6\u89e3\u51b3\u4e86\u9886\u5148\u5355\u4ee3\u740622.2%\u7684\u5148\u524d\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u8bca\u65ad\u6027\u8bc4\u4f30\u548c\u534f\u4f5c\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u4ee3\u7406\uff0c\u4e13\u5bb6-\u6267\u884c\u8005\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5355\u4ee3\u7406\u7684\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\u3002"}}
{"id": "2509.13942", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13942", "abs": "https://arxiv.org/abs/2509.13942", "authors": ["Duc Minh Ha", "Phu Trac Kien", "Tho Quan", "Anh Nguyen-Duc"], "title": "Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation", "comment": null, "summary": "[Background] Large Language Model (LLM)-based multi-agent systems (MAS) are\ntransforming software development by enabling autonomous collaboration.\nClassical software processes such asWaterfall, V-Model, and Agile offer\nstructured coordination patterns that can be repurposed to guide these agent\ninteractions. [Aims] This study explores how traditional software development\nprocesses can be adapted as coordination scaffolds for LLM based MAS and\nexamines their impact on code quality, cost, and productivity. [Method] We\nexecuted 11 diverse software projects under three process models and four GPT\nvariants, totaling 132 runs. Each output was evaluated using standardized\nmetrics for size (files, LOC), cost (execution time, token usage), and quality\n(code smells, AI- and human detected bugs). [Results] Both process model and\nLLM choice significantly affected system performance. Waterfall was most\nefficient, V-Model produced the most verbose code, and Agile achieved the\nhighest code quality, albeit at higher computational cost. [Conclusions]\nClassical software processes can be effectively instantiated in LLM-based MAS,\nbut each entails trade-offs across quality, cost, and adaptability. Process\nselection should reflect project goals, whether prioritizing efficiency,\nrobustness, or structured validation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5c06\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff08\u7011\u5e03\u6a21\u578b\u3001V\u6a21\u578b\u3001\u654f\u6377\uff09\u4f5c\u4e3a\u534f\u8c03\u6846\u67b6\u5e94\u7528\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5206\u6790\u4e0d\u540c\u6d41\u7a0b\u5bf9\u4ee3\u7801\u8d28\u91cf\u3001\u6210\u672c\u548c\u751f\u4ea7\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6b63\u5728\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\u65b9\u5f0f\uff0c\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u534f\u8c03\u6a21\u5f0f\uff0c\u53ef\u4ee5\u91cd\u65b0\u7528\u4e8e\u6307\u5bfc\u8fd9\u4e9b\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002", "method": "\u5728\u4e09\u79cd\u6d41\u7a0b\u6a21\u578b\u548c\u56db\u79cdGPT\u53d8\u4f53\u4e0b\u6267\u884c\u4e8611\u4e2a\u4e0d\u540c\u7684\u8f6f\u4ef6\u9879\u76ee\uff0c\u5171132\u6b21\u8fd0\u884c\u3002\u4f7f\u7528\u6807\u51c6\u5316\u6307\u6807\u8bc4\u4f30\u8f93\u51fa\u7ed3\u679c\uff0c\u5305\u62ec\u89c4\u6a21\uff08\u6587\u4ef6\u6570\u3001\u4ee3\u7801\u884c\u6570\uff09\u3001\u6210\u672c\uff08\u6267\u884c\u65f6\u95f4\u3001token\u4f7f\u7528\u91cf\uff09\u548c\u8d28\u91cf\uff08\u4ee3\u7801\u5f02\u5473\u3001AI\u548c\u4eba\u5de5\u68c0\u6d4b\u7684bug\uff09\u3002", "result": "\u6d41\u7a0b\u6a21\u578b\u548cLLM\u9009\u62e9\u90fd\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002\u7011\u5e03\u6a21\u578b\u6700\u6709\u6548\u7387\uff0cV\u6a21\u578b\u4ea7\u751f\u6700\u5197\u957f\u7684\u4ee3\u7801\uff0c\u654f\u6377\u65b9\u6cd5\u5b9e\u73b0\u6700\u9ad8\u4ee3\u7801\u8d28\u91cf\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8\u3002", "conclusion": "\u4f20\u7edf\u8f6f\u4ef6\u6d41\u7a0b\u53ef\u4ee5\u6709\u6548\u5730\u5728\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b9e\u4f8b\u5316\uff0c\u4f46\u6bcf\u79cd\u6d41\u7a0b\u5728\u8d28\u91cf\u3001\u6210\u672c\u548c\u9002\u5e94\u6027\u65b9\u9762\u90fd\u5b58\u5728\u6743\u8861\u3002\u6d41\u7a0b\u9009\u62e9\u5e94\u53cd\u6620\u9879\u76ee\u76ee\u6807\uff0c\u65e0\u8bba\u662f\u4f18\u5148\u8003\u8651\u6548\u7387\u3001\u5065\u58ee\u6027\u8fd8\u662f\u7ed3\u6784\u5316\u9a8c\u8bc1\u3002"}}
{"id": "2509.14093", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14093", "abs": "https://arxiv.org/abs/2509.14093", "authors": ["Kerui Huang", "Shuhan Liu", "Xing Hu", "Tongtong Xu", "Lingfeng Bao", "Xin Xia"], "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "comment": null, "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.", "AI": {"tldr": "Chain-of-Thought\u63a8\u7406\u867d\u7136\u63d0\u5347LLM\u6027\u80fd\u4f46\u5e26\u6765\u9ad8\u6602\u8ba1\u7b97\u6210\u672c\uff0c\u7814\u7a76\u53d1\u73b0\u8fc7\u957f\u63a8\u7406\u53cd\u800c\u6709\u5bb3\u3002\u63d0\u51faSEER\u6846\u67b6\u81ea\u9002\u5e94\u538b\u7f29CoT\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c1142.1%\u63a8\u7406\u957f\u5ea6\u5e76\u6d88\u9664\u65e0\u9650\u5faa\u73af\u3002", "motivation": "CoT\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8LLM\u5728\u7b97\u672f\u3001\u903b\u8f91\u548c\u5e38\u8bc6\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u6fc0\u589e\uff08\u5ef6\u8fdf\u589e\u52a0\u3001\u5185\u5b58\u4f7f\u7528\u4e0a\u5347\u3001KV\u7f13\u5b58\u9700\u6c42\u589e\u5927\uff09\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7b80\u6d01\u786e\u5b9a\u6027\u8f93\u51fa\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u3002\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u6743\u8861\u5173\u7cfb\u5e76\u627e\u5230\u4f18\u5316\u65b9\u6848\u3002", "method": "\u63d0\u51faSEER\uff08Self-Enhancing Efficient Reasoning\uff09\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7ed3\u5408Best-of-N\u91c7\u6837\u548c\u4efb\u52a1\u611f\u77e5\u81ea\u9002\u5e94\u8fc7\u6ee4\uff0c\u901a\u8fc7\u9884\u63a8\u7406\u8f93\u51fa\u52a8\u6001\u8c03\u6574\u9608\u503c\u6765\u538b\u7f29CoT\u63a8\u7406\u8fc7\u7a0b\uff0c\u51cf\u5c11\u5197\u4f59\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u4e09\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u548c\u4e00\u4e2a\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1aSEER\u5e73\u5747\u7f29\u77edCoT\u63a8\u740642.1%\uff0c\u901a\u8fc7\u51cf\u5c11\u622a\u65ad\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u6d88\u9664\u4e86\u5927\u591a\u6570\u65e0\u9650\u5faa\u73af\u95ee\u9898\u3002", "conclusion": "SEER\u662f\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u80fd\u4f7fCoT\u589e\u5f3a\u7684LLM\u66f4\u52a0\u9ad8\u6548\u548c\u9c81\u68d2\uff0c\u5373\u4f7f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4e5f\u80fd\u4fdd\u6301\u6027\u80fd\uff0c\u6311\u6218\u4e86\"\u63a8\u7406\u8d8a\u957f\u8d8a\u597d\"\u7684\u5047\u8bbe\u3002"}}
