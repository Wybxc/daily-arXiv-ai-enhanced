{"id": "2509.02860", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.02860", "abs": "https://arxiv.org/abs/2509.02860", "authors": ["Connor Wojtak", "Darek Gajewski", "Tomas Cerny"], "title": "Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems", "comment": "Accepted at MODELS 2025", "summary": "Microservice systems are becoming increasingly adopted due to their\nscalability, decentralized development, and support for continuous integration\nand delivery (CI/CD). However, this decentralized development by separate teams\nand continuous evolution can introduce miscommunication and incompatible\nimplementations, undermining system maintainability and reliability across\naspects from security policy to system architecture. We propose a novel\nmethodology that statically reconstructs microservice source code into a formal\nsystem model. From this model, a Satisfiability Modulo Theories (SMT)\nconstraint set can be derived, enabling formal verification. Our methodology is\nextensible, supporting software verification across multiple cross-cutting\nconcerns. We focus on applying the methodology to verify the system\narchitecture concern, presenting formal reasoning to validate the methodology's\ncorrectness and applicability for this concern. Additional concerns such as\nsecurity policy implementation are considered. Future directions are\nestablished to extend and evaluate the methodology.", "AI": {"tldr": "\u901a\u8fc7\u9759\u6001\u91cd\u6784\u5fae\u670d\u52a1\u6e90\u7801\u4e3a\u5f62\u5f0f\u7cfb\u7edf\u6a21\u578b\uff0c\u5229\u7528SMT\u7ea6\u675f\u6ee1\u8db3\u6c42\u89e3\u5668\u8fdb\u884c\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u89e3\u51b3\u5fae\u670d\u52a1\u7cfb\u7edf\u5728\u5206\u5e03\u5f0f\u5f00\u53d1\u4e2d\u7684\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898", "motivation": "\u5fae\u670d\u52a1\u7cfb\u7edf\u5728\u5206\u5e03\u5f0f\u5f00\u53d1\u548c\u6301\u7eed\u96c6\u6210\u4e2d\u5bb9\u6613\u51fa\u73b0\u6c9f\u901a\u4e0d\u826f\u548c\u5b9e\u73b0\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u5f71\u54cd\u7cfb\u7edf\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027", "method": "\u9759\u6001\u91cd\u6784\u5fae\u670d\u52a1\u6e90\u7801\u4e3a\u5f62\u5f0f\u7cfb\u7edf\u6a21\u578b\uff0c\u751f\u6210SMT\u7ea6\u675f\u96c6\u5408\u8fdb\u884c\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u652f\u6301\u591a\u79cd\u8de8\u5207\u5173\u6ce8\u70b9", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u8bba\uff0c\u80fd\u591f\u9a8c\u8bc1\u7cfb\u7edf\u67b6\u6784\u5173\u6ce8\u70b9\uff0c\u5e76\u8003\u8651\u5b89\u5168\u7b56\u7565\u7b49\u5176\u4ed6\u5173\u6ce8\u70b9", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6709\u6548\u89e3\u51b3\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\uff0c\u4e3a\u672a\u6765\u6269\u5c55\u548c\u8bc4\u4f30\u57fa\u7840\u4e86\u65b9\u5411"}}
{"id": "2509.03318", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.03318", "abs": "https://arxiv.org/abs/2509.03318", "authors": ["Eduard Kamburjan", "Vidar Norstein Klungre", "Yuanwei Qu", "Rudolf Schlatte", "Egor V. Kostylev", "Martin Giese", "Einar Broch Johnsen"], "title": "Semantically Reflected Programs", "comment": null, "summary": "This paper addresses the dichotomy between the formalization of structural\nand the formalization of behavioral knowledge by means of semantically lifted\nprograms, which explore an intuitive connection between programs and knowledge\ngraphs. While knowledge graphs and ontologies are eminently useful to represent\nformal knowledge about a system's individuals and universals, programming\nlanguages are designed to describe the system's evolution. To address this\ndichotomy, we introduce a semantic lifting of the program states of an\nexecuting program into a knowledge graph, for an object-oriented programming\nlanguage. The resulting graph is exposed as a semantic reflection layer within\nthe programming language, allowing programmers to leverage knowledge of the\napplication domain in their programs. In this paper, we formalize semantic\nlifting and semantic reflection for a small programming language, SMOL, explain\nthe operational aspects of the language, and consider type correctness and\nvirtualisation for runtime program queries through the semantic reflection\nlayer. We illustrate semantic lifting and semantic reflection through a case\nstudy of geological modelling and discuss different applications of the\ntechnique. The language implementation is open source and available online.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8bed\u4e49\u63d0\u5347\u7a0b\u5e8f\u6765\u89e3\u51b3\u7ed3\u6784\u77e5\u8bc6\u548c\u884c\u4e3a\u77e5\u8bc6\u5f62\u5f0f\u5316\u4e4b\u95f4\u7684\u4e8c\u5206\u6cd5\uff0c\u5efa\u7acb\u7a0b\u5e8f\u4e0e\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u7684\u76f4\u89c2\u8fde\u63a5\uff0c\u5c06\u7a0b\u5e8f\u72b6\u6001\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\u5e76\u5728\u7f16\u7a0b\u8bed\u8a00\u4e2d\u63d0\u4f9b\u8bed\u4e49\u53cd\u5c04\u5c42\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u548c\u672c\u4f53\u8bba\u80fd\u6709\u6548\u8868\u793a\u7cfb\u7edf\u7684\u4e2a\u4f53\u548c\u901a\u7528\u77e5\u8bc6\uff0c\u800c\u7f16\u7a0b\u8bed\u8a00\u4e13\u6ce8\u4e8e\u63cf\u8ff0\u7cfb\u7edf\u6f14\u5316\uff0c\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u4e8c\u5206\u6cd5\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u8bed\u4e49\u63d0\u5347\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5f15\u5165\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\u7684\u8bed\u4e49\u63d0\u5347\u6280\u672f\uff0c\u5c06\u6267\u884c\u7a0b\u5e8f\u7684\u72b6\u6001\u8f6c\u6362\u4e3a\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u5728\u7f16\u7a0b\u8bed\u8a00\u5185\u90e8\u63d0\u4f9b\u8bed\u4e49\u53cd\u5c04\u5c42\u3002\u57fa\u4e8e\u5c0f\u578b\u7f16\u7a0b\u8bed\u8a00SMOL\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u5305\u62ec\u64cd\u4f5c\u8bed\u4e49\u3001\u7c7b\u578b\u6b63\u786e\u6027\u548c\u8fd0\u884c\u65f6\u7a0b\u5e8f\u67e5\u8be2\u7684\u865a\u62df\u5316\u3002", "result": "\u5f00\u53d1\u4e86\u8bed\u4e49\u63d0\u5347\u548c\u8bed\u4e49\u53cd\u5c04\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5730\u8d28\u5efa\u6a21\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6280\u672f\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u7684\u8bed\u8a00\u5b9e\u73b0\u3002", "conclusion": "\u8bed\u4e49\u63d0\u5347\u548c\u8bed\u4e49\u53cd\u5c04\u6280\u672f\u6210\u529f\u8fde\u63a5\u4e86\u7a0b\u5e8f\u6267\u884c\u548c\u77e5\u8bc6\u8868\u793a\uff0c\u4f7f\u7a0b\u5e8f\u5458\u80fd\u591f\u5728\u7a0b\u5e8f\u4e2d\u5229\u7528\u5e94\u7528\u9886\u57df\u7684\u77e5\u8bc6\uff0c\u4e3a\u89e3\u51b3\u7ed3\u6784-\u884c\u4e3a\u77e5\u8bc6\u4e8c\u5206\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.03093", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03093", "abs": "https://arxiv.org/abs/2509.03093", "authors": ["Fatih Pehlivan", "Ar\u00e7in \u00dclk\u00fc Erg\u00fczen", "Sahand Moslemi Yengejeh", "Mayasah Lami", "Anil Koyuncu"], "title": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations", "comment": "Accepted to ASE2025", "summary": "Traditional static analysis methods struggle to detect semantic design flaws,\nsuch as violations of the SOLID principles, which require a strong\nunderstanding of object-oriented design patterns and principles. Existing\nsolutions typically focus on individual SOLID principles or specific\nprogramming languages, leaving a gap in the ability to detect violations across\nall five principles in multi-language codebases. This paper presents a new\napproach: a methodology that leverages tailored prompt engineering to assess\nLLMs on their ability to detect SOLID violations across multiple languages. We\npresent a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,\nand GPT-4o Mini-on their ability to detect violations of all five SOLID\nprinciples. For this evaluation, we construct a new benchmark dataset of 240\nmanually validated code examples. Using this dataset, we test four distinct\nprompt strategies inspired by established zero-shot, few-shot, and\nchain-of-thought techniques to systematically measure their impact on detection\naccuracy. Our emerging results reveal a stark hierarchy among models, with\nGPT-4o Mini decisively outperforming others, yet even struggles with\nchallenging principles like DIP. Crucially, we show that prompt strategy has a\ndramatic impact, but no single strategy is universally best; for instance, a\ndeliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE\nprompt is superior for DIP violations. Across all experiments, detection\naccuracy is heavily influenced by language characteristics and degrades sharply\nwith increasing code complexity. These initial findings demonstrate that\neffective, AI-driven design analysis requires not a single best model, but a\ntailored approach that matches the right model and prompt to the specific\ndesign context, highlighting the potential of LLMs to support maintainability\nthrough AI-assisted code analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u591a\u8bed\u8a00\u4ee3\u7801\u5e93\u4e2d\u7684SOLID\u539f\u5219\u8fdd\u53cd\u60c5\u51b5\uff0c\u53d1\u73b0GPT-4o Mini\u8868\u73b0\u6700\u4f73\u4f46\u4ecd\u6709\u6311\u6218\uff0c\u63d0\u793a\u7b56\u7565\u5bf9\u68c0\u6d4b\u51c6\u786e\u7387\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u8bed\u4e49\u8bbe\u8ba1\u7f3a\u9677\uff08\u5982SOLID\u539f\u5219\u8fdd\u53cd\uff09\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e2a\u539f\u5219\u6216\u7279\u5b9a\u8bed\u8a00\uff0c\u7f3a\u4e4f\u8de8\u6240\u6709\u4e94\u4e2a\u539f\u5219\u548c\u591a\u8bed\u8a00\u4ee3\u7801\u5e93\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b240\u4e2a\u624b\u52a8\u9a8c\u8bc1\u4ee3\u7801\u793a\u4f8b\u7684\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff08\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u601d\u7ef4\u94fe\u7b49\uff09\uff0c\u8bc4\u4f30\u56db\u79cd\u9886\u5148LLM\u6a21\u578b\u5728\u68c0\u6d4b\u4e94\u4e2aSOLID\u539f\u5219\u8fdd\u53cd\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "GPT-4o Mini\u660e\u663e\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4f46\u5728DIP\u7b49\u6311\u6218\u6027\u539f\u5219\u65b9\u9762\u4ecd\u6709\u56f0\u96be\uff1b\u63d0\u793a\u7b56\u7565\u5bf9\u51c6\u786e\u7387\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u6ca1\u6709\u5355\u4e00\u6700\u4f73\u7b56\u7565\uff1b\u68c0\u6d4b\u51c6\u786e\u7387\u53d7\u8bed\u8a00\u7279\u6027\u548c\u4ee3\u7801\u590d\u6742\u5ea6\u5f71\u54cd\u8f83\u5927\u3002", "conclusion": "\u6709\u6548\u7684AI\u9a71\u52a8\u8bbe\u8ba1\u5206\u6790\u9700\u8981\u6839\u636e\u5177\u4f53\u8bbe\u8ba1\u4e0a\u4e0b\u6587\u5339\u914d\u5408\u9002\u7684\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\uff0c\u800c\u975e\u5355\u4e00\u6700\u4f73\u6a21\u578b\uff0c\u5c55\u793a\u4e86LLM\u901a\u8fc7AI\u8f85\u52a9\u4ee3\u7801\u5206\u6790\u652f\u6301\u53ef\u7ef4\u62a4\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.02958", "categories": ["cs.LO", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.02958", "abs": "https://arxiv.org/abs/2509.02958", "authors": ["Kaustuv Mukherji", "Jaikrishna Manojkumar Patil", "Dyuman Aditya", "Paulo Shakarian", "Devendra Parkar", "Lahari Pokala", "Clark Dorman", "Gerardo I. Simari"], "title": "Lattice Annotated Temporal (LAT) Logic for Non-Markovian Reasoning", "comment": null, "summary": "We introduce Lattice Annotated Temporal (LAT) Logic, an extension of\nGeneralized Annotated Logic Programs (GAPs) that incorporates temporal\nreasoning and supports open-world semantics through the use of a lower lattice\nstructure. This logic combines an efficient deduction process with temporal\nlogic programming to support non-Markovian relationships and open-world\nreasoning capabilities. The open-world aspect, a by-product of the use of the\nlower-lattice annotation structure, allows for efficient grounding through a\nSkolemization process, even in domains with infinite or highly diverse\nconstants.\n  We provide a suite of theoretical results that bound the computational\ncomplexity of the grounding process, in addition to showing that many of the\nresults on GAPs (using an upper lattice) still hold with the lower lattice and\ntemporal extensions (though different proof techniques are required). Our\nopen-source implementation, PyReason, features modular design, machine-level\noptimizations, and direct integration with reinforcement learning environments.\nEmpirical evaluations across multi-agent simulations and knowledge graph tasks\ndemonstrate up to three orders of magnitude speedup and up to five orders of\nmagnitude memory reduction while maintaining or improving task performance.\nAdditionally, we evaluate LAT Logic's value in reinforcement learning\nenvironments as a non-Markovian simulator, achieving up to three orders of\nmagnitude faster simulation with improved agent performance, including a 26%\nincrease in win rate due to capturing richer temporal dependencies. These\nresults highlight LAT Logic's potential as a unified, extensible framework for\nopen-world temporal reasoning in dynamic and uncertain environments. Our\nimplementation is available at: pyreason.syracuse.edu.", "AI": {"tldr": "LAT Logic\u662fGAPs\u7684\u6269\u5c55\uff0c\u7ed3\u5408\u65f6\u95f4\u63a8\u7406\u548c\u5f00\u653e\u4e16\u754c\u8bed\u4e49\uff0c\u901a\u8fc7\u4e0b\u683c\u7ed3\u6784\u652f\u6301\u975e\u9a6c\u5c14\u53ef\u592b\u5173\u7cfb\u548c\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5f00\u653e\u4e16\u754c\u65f6\u95f4\u63a8\u7406\u7684\u9700\u6c42\uff0c\u7ed3\u5408\u9ad8\u6548\u6f14\u7ece\u8fc7\u7a0b\u548c\u65f6\u95f4\u903b\u8f91\u7f16\u7a0b\u3002", "method": "\u6269\u5c55GAPs\uff0c\u5f15\u5165\u65f6\u95f4\u63a8\u7406\u548c\u4e0b\u683c\u6ce8\u91ca\u7ed3\u6784\uff0c\u652f\u6301Skolem\u5316\u8fc7\u7a0b\u5b9e\u73b0\u9ad8\u6548\u63a5\u5730\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u673a\u5668\u7ea7\u4f18\u5316\u3002", "result": "\u5728\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u77e5\u8bc6\u56fe\u8c31\u4efb\u52a1\u4e2d\u5b9e\u73b03\u4e2a\u6570\u91cf\u7ea7\u52a0\u901f\u548c5\u4e2a\u6570\u91cf\u7ea7\u5185\u5b58\u51cf\u5c11\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u5b9e\u73b03\u4e2a\u6570\u91cf\u7ea7\u66f4\u5feb\u6a21\u62df\u548c26%\u80dc\u7387\u63d0\u5347\u3002", "conclusion": "LAT Logic\u4f5c\u4e3a\u7edf\u4e00\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5177\u6709\u5f3a\u5927\u7684\u5f00\u653e\u4e16\u754c\u65f6\u95f4\u63a8\u7406\u6f5c\u529b\u3002"}}
{"id": "2509.03270", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.03270", "abs": "https://arxiv.org/abs/2509.03270", "authors": ["Martin Skoglund", "Fredrik Warg", "Aria Mirzai", "Anders Thorsen", "Karl Lundgren", "Peter Folkesson", "Bastian Havers-zulka"], "title": "AI Safety Assurance in Electric Vehicles: A Case Study on AI-Driven SOC Estimation", "comment": "12 pages, 9 figures, EVS38,\n  https://evs38-program.org/en/evs-38-proceedings/all", "summary": "Integrating Artificial Intelligence (AI) technology in electric vehicles (EV)\nintroduces unique challenges for safety assurance, particularly within the\nframework of ISO 26262, which governs functional safety in the automotive\ndomain. Traditional assessment methodologies are not geared toward evaluating\nAI-based functions and require evolving standards and practices. This paper\nexplores how an independent assessment of an AI component in an EV can be\nachieved when combining ISO 26262 with the recently released ISO/PAS 8800,\nwhose scope is AI safety for road vehicles. The AI-driven State of Charge (SOC)\nbattery estimation exemplifies the process. Key features relevant to the\nindependent assessment of this extended evaluation approach are identified. As\npart of the evaluation, robustness testing of the AI component is conducted\nusing fault injection experiments, wherein perturbed sensor inputs are\nsystematically introduced to assess the component's resilience to input\nvariance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u7ed3\u5408ISO 26262\u548cISO/PAS 8800\u6807\u51c6\u5bf9\u7535\u52a8\u6c7d\u8f66\u4e2dAI\u7ec4\u4ef6\u8fdb\u884c\u72ec\u7acb\u5b89\u5168\u8bc4\u4f30\uff0c\u4ee5AI\u9a71\u52a8\u7684\u7535\u6c60SOC\u4f30\u8ba1\u4e3a\u4f8b\uff0c\u901a\u8fc7\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\u6d4b\u8bd5\u9c81\u68d2\u6027\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u4e2dAI\u6280\u672f\u7684\u5e94\u7528\u7ed9\u529f\u80fd\u5b89\u5168\u4fdd\u8bc1\u5e26\u6765\u65b0\u6311\u6218\uff0c\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30AI\u529f\u80fd\uff0c\u9700\u8981\u53d1\u5c55\u65b0\u7684\u6807\u51c6\u548c\u5b9e\u8df5\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408ISO 26262\u548cISO/PAS 8800\u6807\u51c6\uff0c\u91c7\u7528\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u5f15\u5165\u6270\u52a8\u4f20\u611f\u5668\u8f93\u5165\u6765\u8bc4\u4f30AI\u7ec4\u4ef6\u7684\u9c81\u68d2\u6027\u3002", "result": "\u8bc6\u522b\u4e86\u6269\u5c55\u8bc4\u4f30\u65b9\u6cd5\u4e2d\u72ec\u7acb\u8bc4\u4f30\u7684\u5173\u952e\u7279\u5f81\uff0c\u6210\u529f\u5bf9AI\u9a71\u52a8\u7684\u7535\u6c60SOC\u4f30\u8ba1\u7ec4\u4ef6\u8fdb\u884c\u4e86\u9c81\u68d2\u6027\u6d4b\u8bd5\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u73b0\u6709\u529f\u80fd\u5b89\u5168\u6807\u51c6\u548c\u65b0\u53d1\u5e03\u7684AI\u5b89\u5168\u6807\u51c6\uff0c\u53ef\u4ee5\u5efa\u7acb\u6709\u6548\u7684AI\u7ec4\u4ef6\u72ec\u7acb\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u7535\u52a8\u6c7d\u8f66AI\u529f\u80fd\u7684\u5b89\u5168\u4fdd\u8bc1\u63d0\u4f9b\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.03331", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03331", "abs": "https://arxiv.org/abs/2509.03331", "authors": ["Weizhe Wang", "Wei Ma", "Qiang Hu", "Yao Zhang", "Jianfei Sun", "Bin Wu", "Yang Liu", "Guangquan Xu", "Lingxiao Jiang"], "title": "VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities", "comment": null, "summary": "The adoption of Large Language Models (LLMs) for automated software\nvulnerability patching has shown promising outcomes on carefully curated\nevaluation sets. Nevertheless, existing datasets predominantly rely on\nsuperficial validation methods rather than exploit-based verification, leading\nto overestimated performance in security-sensitive applications. This paper\nintroduces VulnRepairEval, an evaluation framework anchored in functional\nProof-of-Concept (PoC) exploits. Our framework delivers a comprehensive,\ncontainerized evaluation pipeline that enables reproducible differential\nassessment, where repair success requires the original exploit to fail\nexecution against the modified code. The benchmark construction involved\nextensive data curation: we processed over 400 CVEs and approximately 2,500\npotential sources to extract a collection of authentic vulnerability instances\n(23 Python CVEs) amenable to automated testing with working PoCs. Through\nVulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and\nobserve a significant performance deficit: even the top-performing model\nsuccessfully addresses merely 5/23 instances (about 21.7%), exposing critical\nweaknesses in security-focused applications. Our failure analysis reveals that\nmost unsuccessful attempts stem from imprecise vulnerability identification and\npatches containing syntactic or semantic errors. Enhanced prompting strategies\nand multi-agent approaches yield minimal improvements, with overall\neffectiveness remaining largely unaffected. This work contributes a stringent,\npractical evaluation framework for LLM-driven vulnerability remediation and\nunderscores the necessity for assessment protocols that authentically reflect\nreal-world exploitation scenarios.", "AI": {"tldr": "VulnRepairEval\u662f\u4e00\u4e2a\u57fa\u4e8ePoC\u6f0f\u6d1e\u5229\u7528\u7684LLM\u6f0f\u6d1e\u4fee\u590d\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u73b0\u6709LLM\u5728\u771f\u5b9e\u6f0f\u6d1e\u4fee\u590d\u4e2d\u8868\u73b0\u4e0d\u4f73\uff08\u6700\u4f73\u6a21\u578b\u4ec5\u4fee\u590d21.7%\u7684\u6f0f\u6d1e\uff09\uff0c\u66b4\u9732\u4e86\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u4fee\u590d\u6570\u636e\u96c6\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u9a8c\u8bc1\u800c\u975e\u57fa\u4e8e\u6f0f\u6d1e\u5229\u7528\u7684\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u5728\u5b89\u5168\u654f\u611f\u5e94\u7528\u4e2d\u9ad8\u4f30\u4e86LLM\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b23\u4e2aPython CVE\u771f\u5b9e\u6f0f\u6d1e\u5b9e\u4f8b\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u4f7f\u7528\u5bb9\u5668\u5316\u8bc4\u4f30\u7ba1\u9053\u8fdb\u884c\u53ef\u91cd\u73b0\u7684\u5dee\u5206\u8bc4\u4f30\uff0c\u8981\u6c42\u4fee\u590d\u6210\u529f\u540e\u539f\u59cb\u6f0f\u6d1e\u5229\u7528\u5fc5\u987b\u5931\u6548\u3002", "result": "\u8bc4\u4f3012\u4e2a\u6d41\u884cLLM\u53d1\u73b0\u6027\u80fd\u663e\u8457\u4e0d\u8db3\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u6210\u529f\u4fee\u590d5/23\u4e2a\u5b9e\u4f8b\uff0821.7%\uff09\u3002\u5931\u8d25\u5206\u6790\u663e\u793a\u4e3b\u8981\u95ee\u9898\u662f\u4e0d\u7cbe\u786e\u7684\u6f0f\u6d1e\u8bc6\u522b\u548c\u5305\u542b\u8bed\u6cd5/\u8bed\u4e49\u9519\u8bef\u7684\u8865\u4e01\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e25\u683c\u7684\u5b9e\u7528\u8bc4\u4f30\u6846\u67b6\uff0c\u5f3a\u8c03\u9700\u8981\u771f\u5b9e\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u6f0f\u6d1e\u5229\u7528\u573a\u666f\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u73b0\u6709LLM\u5728\u6f0f\u6d1e\u4fee\u590d\u65b9\u9762\u4ecd\u6709\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2509.02828", "categories": ["cs.FL", "F.4.3"], "pdf": "https://arxiv.org/pdf/2509.02828", "abs": "https://arxiv.org/abs/2509.02828", "authors": ["Noah Friesen", "Oscar H. Ibarra", "Jozef Jir\u00e1sek", "Ian McQuillan"], "title": "Store Languages of Turing Machines and Counter Machines", "comment": "22 pages, 1 figure", "summary": "The store language of an automaton is the set of store configurations (state\nand store contents, but not the input) that can appear as an intermediate step\nin an accepting computation. A one-way nondeterministic finite-visit Turing\nmachine (fvNTM) is a Turing machine with a one-way read-only input tape, and a\nsingle worktape, where there is some number $k$ such that in every accepting\ncomputation, each worktape cell is visited at most $k$ times. We show that the\nstore language of every fvNTM is a regular language. Furthermore, we show that\nthe store language of every fvNTM augmented by reversal-bounded counters can be\naccepted by a machine with only reversal-bounded counters and no worktape.\nSeveral applications are given to problems in the areas of verification and\nfault tolerance, and to the study of right quotients. We also continue the\ninvestigation of the store languages of one-way and two-way machine models\nwhere we present some conditions under which their store languages are\nrecursive or non-recursive.", "AI": {"tldr": "\u6709\u9650\u8bbf\u95ee\u975e\u786e\u5b9a\u6027\u56fe\u7075\u673a\u7684\u5b58\u50a8\u8bed\u8a00\u662f\u6b63\u5219\u8bed\u8a00\uff0c\u589e\u5f3a\u7248\u672c\u53ef\u7531\u53cd\u8f6c\u6709\u754c\u8ba1\u6570\u5668\u63a5\u53d7\uff0c\u5728\u9a8c\u8bc1\u548c\u5bb9\u9519\u9886\u57df\u6709\u5e94\u7528", "motivation": "\u7814\u7a76\u6709\u9650\u8bbf\u95ee\u56fe\u7075\u673a\u53ca\u5176\u6269\u5c55\u6a21\u578b\u7684\u5b58\u50a8\u8bed\u8a00\u6027\u8d28\uff0c\u63a2\u7d22\u5176\u5728\u5f62\u5f0f\u9a8c\u8bc1\u3001\u5bb9\u9519\u7cfb\u7edf\u548c\u8bed\u8a00\u7406\u8bba\u4e2d\u7684\u5e94\u7528\u4ef7\u503c", "method": "\u5206\u6790\u4e00\u7c7b\u7279\u6b8a\u7684\u56fe\u7075\u673a\u6a21\u578b\u2014\u2014\u5355\u5411\u975e\u786e\u5b9a\u6027\u6709\u9650\u8bbf\u95ee\u56fe\u7075\u673a(fvNTM)\uff0c\u8bc1\u660e\u5176\u5b58\u50a8\u8bed\u8a00\u7684\u6b63\u5219\u6027\uff0c\u5e76\u6269\u5c55\u5230\u5e26\u53cd\u8f6c\u6709\u754c\u8ba1\u6570\u5668\u7684\u589e\u5f3a\u7248\u672c", "result": "\u8bc1\u660e\u4e86\u6240\u6709fvNTM\u7684\u5b58\u50a8\u8bed\u8a00\u90fd\u662f\u6b63\u5219\u8bed\u8a00\uff1b\u589e\u5f3a\u7248fvNTM\u7684\u5b58\u50a8\u8bed\u8a00\u53ef\u7531\u4ec5\u542b\u53cd\u8f6c\u6709\u754c\u8ba1\u6570\u5668\u7684\u673a\u5668\u63a5\u53d7\uff1b\u7ed9\u51fa\u4e86\u5728\u9a8c\u8bc1\u3001\u5bb9\u9519\u548c\u53f3\u5546\u95ee\u9898\u4e2d\u7684\u5e94\u7528", "conclusion": "\u6709\u9650\u8bbf\u95ee\u6761\u4ef6\u4fdd\u8bc1\u4e86\u5b58\u50a8\u8bed\u8a00\u7684\u6b63\u5219\u6027\uff0c\u8fd9\u4e00\u7ed3\u679c\u4e3a\u590d\u6742\u7cfb\u7edf\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\uff0c\u5e76\u63ed\u793a\u4e86\u5b58\u50a8\u8bed\u8a00\u4e0e\u673a\u5668\u8ba1\u7b97\u80fd\u529b\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb"}}
{"id": "2509.03463", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.03463", "abs": "https://arxiv.org/abs/2509.03463", "authors": ["Parham Khamsepour", "Mark Cole", "Ish Ashraf", "Sandeep Puri", "Mehrdad Sabetzadeh", "Shiva Nejati"], "title": "The Impact of Critique on LLM-Based Model Generation from Natural Language: The Case of Activity Diagrams", "comment": null, "summary": "Large Language Models (LLMs) show strong potential for automating the\ngeneration of models from natural-language descriptions. A common approach is\nan iterative generate-critique-refine loop, where candidate models are\nproduced, evaluated, and updated based on detected issues. This process needs\nto address: (1) structural correctness - compliance with well-formedness rules\n- and (2) semantic alignment - accurate reflection of the intended meaning in\nthe source text. We present LADEX (LLM-based Activity Diagram Extractor), a\npipeline for deriving activity diagrams from natural-language process\ndescriptions using an LLM-driven critique-refine process. Structural checks in\nLADEX can be performed either algorithmically or by an LLM, while alignment\nchecks are always performed by an LLM. We design five ablated variants of LADEX\nto study: (i) the impact of the critique-refine loop itself, (ii) the role of\nLLM-based semantic checks, and (iii) the comparative effectiveness of\nalgorithmic versus LLM-based structural checks.\n  To evaluate LADEX, we compare the generated activity diagrams with\nexpert-created ground truths using trace-based operational semantics. This\nenables automated measurement of correctness and completeness. Experiments on\ntwo datasets indicate that: (1) the critique-refine loop improves structural\nvalidity, correctness, and completeness compared to single-pass generation; (2)\nalgorithmic structural checks eliminate inconsistencies that LLM-based checks\nfail to detect, improving correctness by an average of 17.81% and completeness\nby 13.24% over LLM-only checks; and (3) combining algorithmic structural checks\nwith LLM-based semantic checks, implemented using the reasoning-focused O4\nMini, achieves the best overall performance - yielding average correctness of\nup to 86.37% and average completeness of up to 88.56% - while requiring fewer\nthan five LLM calls on average.", "AI": {"tldr": "LADEX\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u8fed\u4ee3\u5f0f\u751f\u6210-\u8bc4\u4ef7-\u4f18\u5316\u6d41\u7a0b\uff0c\u7528\u4e8e\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e2d\u63d0\u53d6\u6d3b\u52a8\u56fe\u3002\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408\u7b97\u6cd5\u7ed3\u6784\u68c0\u67e5\u548cLLM\u8bed\u4e49\u68c0\u67e5\u7684\u65b9\u6cd5\u6548\u679c\u6700\u4f73\uff0c\u5e73\u5747\u6b63\u786e\u7387\u8fbe\u523086.37%\uff0c\u5b8c\u6574\u6027\u8fbe\u523088.56%\u3002", "motivation": "\u89e3\u51b3\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u6a21\u578b\u65f6\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u7ed3\u6784\u6b63\u786e\u6027\uff08\u7b26\u5408\u683c\u5f0f\u89c4\u5219\uff09\u548c\u8bed\u4e49\u5bf9\u9f50\u6027\uff08\u51c6\u786e\u53cd\u6620\u6e90\u6587\u672c\u610f\u56fe\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u6539\u8fdb\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51faLADEX\u7ba1\u9053\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684critique-refine\u5faa\u73af\u3002\u7ed3\u6784\u68c0\u67e5\u53ef\u901a\u8fc7\u7b97\u6cd5\u6216LLM\u6267\u884c\uff0c\u8bed\u4e49\u5bf9\u9f50\u68c0\u67e5\u59cb\u7ec8\u7531LLM\u6267\u884c\u3002\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u6d88\u878d\u53d8\u4f53\u6765\u7814\u7a76\u4e0d\u540c\u7ec4\u4ef6\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09critique-refine\u5faa\u73af\u76f8\u6bd4\u5355\u6b21\u751f\u6210\u663e\u8457\u6539\u5584\u8d28\u91cf\uff1b2\uff09\u7b97\u6cd5\u7ed3\u6784\u68c0\u67e5\u6bd4\u7eafLLM\u68c0\u67e5\u5e73\u5747\u63d0\u9ad8\u6b63\u786e\u738717.81%\u548c\u5b8c\u6574\u602713.24%\uff1b3\uff09\u7ed3\u5408\u7b97\u6cd5\u7ed3\u6784\u68c0\u67e5\u548cLLM\u8bed\u4e49\u68c0\u67e5\u7684\u65b9\u6cd5\u6548\u679c\u6700\u4f73\u3002", "conclusion": "LADEX\u8bc1\u660e\u4e86\u8fed\u4ee3\u4f18\u5316\u6d41\u7a0b\u7684\u6709\u6548\u6027\uff0c\u7b97\u6cd5\u548cLLM\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\u5728\u6d3b\u52a8\u56fe\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5e73\u5747\u53ea\u9700\u4e0d\u52305\u6b21LLM\u8c03\u7528\u5373\u53ef\u83b7\u5f97\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002"}}
