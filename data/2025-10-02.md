<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 28]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [PBFD and PDFD: Formally Defined and Verified Methodologies and Empirical Evaluation for Scalable Full-Stack Software Engineering](https://arxiv.org/abs/2510.00002)
*Dong Liu*

Main category: cs.SE

TL;DR: 提出了PBFD和PDFD两种形式化验证的软件开发方法，通过图论建模确保结构正确性，并引入TLE编码方案实现恒定时间更新，在8年企业部署中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 弥合形式化方法与实际软件开发之间的鸿沟，为工业级全栈软件工程提供可扩展且经过验证的方法论。

Method: 基于分层有向图的图论建模，使用统一状态机和CSP进行形式化定义，提出TLE三层封装编码方案实现恒定时间更新。

Result: 8年企业部署验证：开发速度比Salesforce OmniScript快20倍以上，查询性能比传统关系模型快7-8倍。

Conclusion: PBFD和PDFD建立了可重现的透明框架，将形式化验证融入实际软件开发，所有规范、实现和数据集均已开源。

Abstract: This paper introduces Primary Breadth-First Development (PBFD) and Primary
Depth-First Development (PDFD), two formally defined and verified methodologies
for scalable, industrial-grade full-stack software engineering. These
approaches bridge a longstanding gap between formal methods and real-world
development practice by enforcing structural correctness through
graph-theoretic modeling. Unlike prior graph-based approaches, PBFD and PDFD
operate over layered directed graphs and are formalized using unified state
machines and Communicating Sequential Processes (CSP) to ensure critical
properties, including bounded-refinement termination and structural
completeness. To coordinate hierarchical data at scale, we propose Three-Level
Encapsulation (TLE) - a novel, bitmask-based encoding scheme that delivers
provably constant-time updates. TLE's formal guarantees underpin PBFD's
industrial-scale performance and scalability. PBFD was empirically validated
through an eight-year enterprise deployment, demonstrating over 20x faster
development than Salesforce OmniScript and 7-8x faster query performance
compared to conventional relational models. Additionally, both methodologies
are supported by open-source MVPs, with PDFD's implementation conclusively
demonstrating its correctness-first design principles. Together, PBFD and PDFD
establish a reproducible, transparent framework that integrates formal
verification into practical software development. All formal specifications,
MVPs, and datasets are publicly available to foster academic research and
industrial-grade adoption.

</details>


### [2] [Semantic Zoom and Mini-Maps for Software Cities](https://arxiv.org/abs/2510.00003)
*Malte Hansen,Jens Bamberg,Noe Baumann,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: 本文提出了两种解决3D软件城市可视化可扩展性挑战的方法：语义缩放和迷你地图，并在ExplorViz工具中实现。用户研究表明这两种方法对大型软件景观特别有用。


<details>
  <summary>Details</summary>
Motivation: 随着可视化中显示数据量的增加，可视化本身可能变得难以理解。软件可视化工具需要解决视觉可扩展性挑战，使开发者能够有效理解大型软件系统。

Method: 1. 语义缩放：根据虚拟相机与视觉对象的距离改变软件景观的图形表示
2. 迷你地图：在可视化中添加二维顶视图投影
在ExplorViz工具中实现，这是一个基于Web的3D城市隐喻软件可视化工具

Result: 两个独立的用户研究表明，语义缩放和迷你地图都是有用的补充。用户反馈表明这些功能对大型软件景观和协作软件探索特别有用。实现方法具有良好的可用性。

Conclusion: 语义缩放和迷你地图有效解决了3D软件城市中的视觉可扩展性问题。虽然实现中存在一些需要改进的缺点，但这些方法为大型软件系统的可视化理解提供了实用解决方案。

Abstract: Software visualization tools can facilitate program comprehension by
providing visual metaphors, or abstractions that reduce the amount of textual
data that needs to be processed mentally. One way they do this is by enabling
developers to build an internal representation of the visualized software and
its architecture. However, as the amount of displayed data in the visualization
increases, the visualization itself can become more difficult to comprehend.
The ability to display small and large amounts of data in visualizations is
called visual scalability.
  In this paper, we present two approaches to address the challenge of visual
scalability in 3D software cities. First, we present an approach to semantic
zoom, in which the graphical representation of the software landscape changes
based on the virtual camera's distance from visual objects. Second, we augment
the visualization with a miniature two-dimensional top-view projection called
mini-map. We demonstrate our approach using an open-source implementation in
our software visualization tool ExplorViz. ExplorViz is web-based and uses the
3D city metaphor, focusing on live trace visualization.
  We evaluated our approaches in two separate user studies. The results
indicate that semantic zoom and the mini-map are both useful additions. User
feedback indicates that semantic zoom and mini-maps are especially useful for
large software landscapes and collaborative software exploration. The studies
indicate a good usability of our implemented approaches. However, some
shortcomings in our implementations have also been discovered, to be addressed
in future work.
  Video URL: https://youtu.be/LYtUeWvizjU

</details>


### [3] [HTML Structure Exploration in 3D Software Cities](https://arxiv.org/abs/2510.00004)
*Malte Hansen,David Moreno-Lumbreras,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: 本文为ExplorViz软件可视化工具添加了嵌入式Web视图功能，可在3D可视化中直接与应用程序交互，并可视化HTML的DOM结构。


<details>
  <summary>Details</summary>
Motivation: 大型软件系统通常提供Web界面，但现有软件可视化工具往往忽略这些界面。本文旨在通过可视化Web界面来增强软件行为理解。

Method: 在ExplorViz工具中嵌入Web视图，通过3D表示可视化HTML的DOM结构，支持同源上下文下的交互探索。

Result: 初步用户研究显示该方法具有潜在应用价值，但也揭示了实现的优缺点。

Conclusion: 研究结果为Web界面可视化探索提供了方向，建议进一步研究软件城市与HTML结构结合的可视化用例。

Abstract: Software visualization, which uses data from dynamic program analysis, can
help to explore and understand the behavior of software systems. It is common
that large software systems offer a web interface for user interaction.
Usually, available web interfaces are not regarded in software visualization
tools. This paper introduces additions to the web-based live tracing software
visualization tool ExplorViz: We add an embedded web view for instrumented
applications in the 3D visualization to ease interaction with the given
applications and enable the exploration of the thereby displayed HTML content.
Namely, the Document Object Model (DOM) is visualized via a three-dimensional
representation of the HTML structure in same-origin contexts.
  Our visualization approach is evaluated in a preliminary user study. The
study results give insights into the potential use cases, benefits, and
shortcomings of our implemented approach. Based on our study results, we
propose directions for further research to support the visual exploration of
web interfaces and explore use cases for the combined visualization of software
cities and HTML structure.
  Video URL: https://youtu.be/wBWKlbvzOOE

</details>


### [4] [VibeCodeHPC: An Agent-Based Iterative Prompting Auto-Tuner for HPC Code Generation Using LLMs](https://arxiv.org/abs/2510.00031)
*Shun-ichiro Hayashi,Koki Morita,Daichi Mukunoki,Tetsuya Hoshino,Takahiro Katagiri*

Main category: cs.SE

TL;DR: VibeCodeHPC是一个基于多智能体LLM的HPC程序自动调优系统，通过角色分配和迭代提示优化来调优程序。


<details>
  <summary>Details</summary>
Motivation: 为了解决HPC程序调优的复杂性，提高代码生成质量和效率。

Method: 采用四角色多智能体配置（项目经理、系统工程师、程序员、持续交付），结合动态智能体部署和活动监控功能。

Result: 在CPU到GPU代码转换案例中，多智能体配置相比单智能体在单位时间内生成更高质量的代码，并能更有效地识别需求违规等问题。

Conclusion: 多智能体LLM系统在HPC程序调优中具有优势，能够通过角色分工和协作提高代码生成质量和效率。

Abstract: We propose VibeCodeHPC, an automatic tuning system for HPC programs based on
multi-agent LLMs for code generation. VibeCodeHPC tunes programs through
multi-agent role allocation and iterative prompt refinement. We describe the
system configuration with four roles: Project Manager (PM), System Engineer
(SE), Programmer (PG), and Continuous Delivery (CD). We introduce dynamic agent
deployment and activity monitoring functions to facilitate effective
multi-agent collaboration. In our case study, we convert and optimize CPU-based
matrix-matrix multiplication code written in C to GPU code using CUDA. The
multi-agent configuration of VibeCodeHPC achieved higher-quality code
generation per unit time compared to a solo-agent configuration. Additionally,
the dynamic agent deployment and activity monitoring capabilities facilitated
more effective identification of requirement violations and other issues.

</details>


### [5] [A Scalable Framework for Safety Assurance of Self-Driving Vehicles based on Assurance 2.0](https://arxiv.org/abs/2510.00092)
*Shufeng Chen,Mariat James Elizebeth,Robab Aghazadeh Chakherlou,Xingyu Zhao,Eric Barbier,Siddartha Khastgir,Paul Jennings*

Main category: cs.SE

TL;DR: 本文提出了基于Assurance 2.0框架的分解方法，用于识别完整的安全论证集并测量相应证据，通过三层次分解策略和5M1E模型在自动驾驶车辆开发中进行案例研究。


<details>
  <summary>Details</summary>
Motivation: 解决Assurance 2.0在置信度测量、残余怀疑管理、自动化支持以及实际处理反驳和确认偏见方面的局限性。

Method: 采用结构化模板和三层次分解策略，将自动驾驶车辆开发分为需求工程、验证与确认、部署后三个阶段，并使用适配的5M1E模型进行多维分解。

Result: 开发了一个支持细粒度可追溯性的分解框架，能够全面覆盖安全声明、证据和潜在反驳。

Conclusion: 该分解框架增强了Assurance 2.0的实用性和完整性，为复杂自适应系统的安全保障提供了更系统的方法。

Abstract: Assurance 2.0 is a modern framework developed to address the assurance
challenges of increasingly complex, adaptive, and autonomous systems. Building
on the traditional Claims-Argument-Evidence (CAE) model, it introduces reusable
assurance theories and explicit counterarguments (defeaters) to enhance rigor,
transparency, and adaptability. It supports continuous, incremental assurance,
enabling innovation without compromising safety. However, limitations persist
in confidence measurement, residual doubt management, automation support, and
the practical handling of defeaters and confirmation bias. This paper presents
\textcolor{black}{a set of decomposition frameworks to identify a complete set
of safety arguments and measure their corresponding evidence.} Grounded in the
Assurance 2.0 paradigm, the framework is instantiated through a structured
template and employs a three-tiered decomposition strategy. \textcolor{black}{A
case study regarding the application of the decomposition framework in the
end-to-end (E2E) AI-based Self-Driving Vehicle (SDV) development is also
presented in this paper.} At the top level, the SDV development is divided into
three critical phases: Requirements Engineering (RE), Verification and
Validation (VnV), and Post-Deployment (PD). Each phase is further decomposed
according to its Product Development Lifecycle (PDLC). To ensure comprehensive
coverage, each PDLC is analyzed using an adapted 5M1E model (Man, Machine,
Method, Material, Measurement, and Environment). Originally developed for
manufacturing quality control, the 5M1E model is reinterpreted and contextually
mapped to the assurance domain. This enables a multi-dimensional decomposition
that supports fine-grained traceability of safety claims, evidence, and
potential defeaters.

</details>


### [6] [Container Orchestration Patterns for Optimizing Resource Use](https://arxiv.org/abs/2510.00197)
*Diogo Maia,Filipe Correia,André Restivo,Paulo Queiroz*

Main category: cs.SE

TL;DR: 本文提出了三种服务编排资源优化模式：抢占式调度、服务平衡和垃圾回收，旨在解决服务编排中的挑战并促进其在服务架构中的更广泛采用。


<details>
  <summary>Details</summary>
Motivation: 服务编排在服务架构中具有重要价值，但现有资源缺乏清晰度和标准化，使得最佳实践难以实施，限制了在软件行业中的采用。

Method: 通过分析现有文献和工具，识别出常见的编排实践，并定义了三种关键编排资源优化模式。

Result: 提出了三种核心模式：抢占式调度（为高优先级服务分配足够资源）、服务平衡（重构节点以优化资源使用）和垃圾回收（创建清理机制以理解系统资源使用）。

Conclusion: 这些模式作为改进编排实践的基础要素，有助于促进服务架构中编排技术的更广泛采用。

Abstract: Service-based architectures provide substantial benefits, yet service
orchestration remains a challenge, particularly for newcomers. While various
resources on orchestration techniques exist, they often lack clarity and
standardization, making best practices difficult to implement and limiting
their adoption within the software industry.
  To address this gap, we analyzed existing literature and tools to identify
common orchestration practices. Based on our findings, we define three key
orchestration resource optimization patterns: {\sc Preemptive Scheduling}, {\sc
Service Balancing}, and {\sc Garbage Collection}. {\sc Preemptive Scheduling}
allows the allocation of sufficient resources for services of higher priority
in stressful situations, while {\sc Service Balancing} enables a restructuring
of the nodes to allow better resource usage. To end, {\sc Garbage Collection}
creates cleanup mechanisms to better understand the system's resource usage and
optimize it. These patterns serve as foundational elements for improving
orchestration practices and fostering broader adoption in service-based
architectures.

</details>


### [7] [Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?](https://arxiv.org/abs/2510.00324)
*Lucas Roberts,Denisa Roberts*

Main category: cs.SE

TL;DR: 该论文研究使用大型语言模型进行代码搜索，比较不同检索器表示、编程语言和LLM对代码搜索结果的影响，发现检索器和编程语言之间存在亲和性，并提出使用转译器来扩展代码搜索基准数据集。


<details>
  <summary>Details</summary>
Motivation: 代码搜索在信息检索中很重要，但缺乏高质量标注数据，因为代码标注需要编程语言和软件工程专业知识。该工作旨在利用LLM来检索代码并为搜索结果生成标注。

Method: 比较稀疏表示和语义表示检索器，在多种编程语言（C、Java、Javascript、Go、Python）上评估，使用LLM作为评判者来评估编程语言亲和性，并研究人类与AI相关性判断的一致性。

Result: 发现所选检索器和编程语言存在亲和性，可以改善人类和AI相关性判断的一致性；不同编程语言在表示方法上存在差异；使用转译器构建的基准数据集能达到与人类间一致性相当的效果。

Conclusion: LLM可以有效地用于代码搜索和标注，检索器与编程语言的亲和性对性能有重要影响，转译器是扩展代码搜索基准数据集的有效方法。

Abstract: Code search is an important information retrieval application. Benefits of
better code search include faster new developer on-boarding, reduced software
maintenance, and ease of understanding for large repositories. Despite
improvements in search algorithms and search benchmarks, the domain of code
search has lagged behind. One reason is the high cost of human annotation for
code queries and answers. While humans may annotate search results in general
text QA systems, code annotations require specialized knowledge of a
programming language (PL), as well as domain specific software engineering
knowledge. In this work we study the use of Large Language Models (LLMs) to
retrieve code at the level of functions and to generate annotations for code
search results. We compare the impact of the retriever representation (sparse
vs. semantic), programming language, and LLM by comparing human annotations
across several popular languages (C, Java, Javascript, Go, and Python). We
focus on repositories that implement common data structures likely to be
implemented in any PLs. For the same human annotations, we compare several
LLM-as-a-Judge models to evaluate programming language and other affinities
between LLMs. We find that the chosen retriever and PL exhibit affinities that
can be leveraged to improve alignment of human and AI relevance determinations,
with significant performance implications. We also find differences in
representation (sparse vs. semantic) across PLs that impact alignment of human
and AI relevance determinations. We propose using transpilers to bootstrap
scalable code search benchmark datasets in other PLs and in a case study
demonstrate that human-AI relevance agreement rates largely match the (worst
case) human-human agreement under study. The application code used in this work
is available at \href{https://github.com/rlucas7/code-searcher/}{this github
repo}.

</details>


### [8] [Vibe Coding in Practice: Motivations, Challenges, and a Future Outlook -- a Grey Literature Review](https://arxiv.org/abs/2510.00328)
*Ahmed Fawzy,Amjed Tahir,Kelly Blincoe*

Main category: cs.SE

TL;DR: AI代码生成工具通过直觉和试错的方式让用户进行"氛围编码"，虽然加速了原型开发，但导致了速度与质量的权衡悖论，多数用户跳过质量保证环节，产生了无法调试代码的脆弱开发者群体。


<details>
  <summary>Details</summary>
Motivation: 研究AI代码生成工具广泛使用下的"氛围编码"现象，系统调查用户为何采用这种编码方式、在过程中的体验以及如何进行质量保证。

Method: 对101个从业者来源进行系统性灰色文献综述，提取了518个关于氛围编码实践、挑战和限制的第一手行为描述。

Result: 揭示了速度-质量权衡悖论：用户追求速度和可访问性，体验到"即时成功和心流"，但大多认为生成的代码快速但有缺陷；质量保证实践常被忽视，许多用户跳过测试、直接使用模型输出或将检查委托回AI工具。

Conclusion: 氛围编码降低了门槛并加速了原型开发，但以可靠性和可维护性为代价，产生了无法调试代码的脆弱开发者群体，这对工具设计者和开发团队具有重要启示。

Abstract: AI code generation tools are transforming software development, especially
for novice and non-software developers, by enabling them to write code and
build applications faster and with little to no human intervention. Vibe coding
is the practice where users rely on AI code generation tools through intuition
and trial-and-error without necessarily understanding the underlying code.
Despite widespread adoption, no research has systematically investigated why
users engage in vibe coding, what they experience while doing so, and how they
approach quality assurance (QA) and perceive the quality of the AI-generated
code. To this end, we conduct a systematic grey literature review of 101
practitioner sources, extracting 518 firsthand behavioral accounts about vibe
coding practices, challenges, and limitations. Our analysis reveals a
speed-quality trade-off paradox, where vibe coders are motivated by speed and
accessibility, often experiencing rapid ``instant success and flow'', yet most
perceive the resulting code as fast but flawed. QA practices are frequently
overlooked, with many skipping testing, relying on the models' or tools'
outputs without modification, or delegating checks back to the AI code
generation tools. This creates a new class of vulnerable software developers,
particularly those who build a product but are unable to debug it when issues
arise. We argue that vibe coding lowers barriers and accelerates prototyping,
but at the cost of reliability and maintainability. These insights carry
implications for tool designers and software development teams. Understanding
how vibe coding is practiced today is crucial for guiding its responsible use
and preventing a broader QA crisis in AI-assisted development.

</details>


### [9] [Beyond Pass/Fail: The Story of Learning-Based Testing](https://arxiv.org/abs/2510.00450)
*Sheikh Md. Mushfiqur Rahman,Nasir Eisty*

Main category: cs.SE

TL;DR: 基于学习的测试(LBT)通过结合学习和测试过程，实现测试和行为充分性。该方法使用主动学习推断被测系统模型，仅需少量初始测试用例即可扩展至大型复杂程序。


<details>
  <summary>Details</summary>
Motivation: LBT处于早期阶段但已有坚实的理论研究基础，本文旨在通过系统文献综述展示LBT在不同程序类型中的应用现状，揭示其未充分利用的潜力。

Method: 对LBT领域进行系统性文献综述，分析不同理论框架、现有工具和库，并考察工业环境中LBT工具的应用案例研究。

Result: LBT已被证明在过程式和反应式程序测试中有效，展示了在商业软件测试中的潜力和有效性。

Conclusion: LBT是一种有前景的软件测试技术，本文为研究人员提供了LBT起源和发展的全面视角，对实践者和研究社区具有重要价值。

Abstract: Learning-Based Testing (LBT) merges learning and testing processes to achieve
both testing and behavioral adequacy. LBT utilizes active learning to infer the
model of the System Under Test (SUT), enabling scalability for large and
complex programs by requiring only a minimal set of initial test cases. The
core principle of LBT is that the SUT's behavior can be thoroughly inferred by
progressively generating test cases and subjecting the SUT to testing, thereby
ensuring comprehensive testing. Despite being in its early stages, LBT has a
solid foundation of theoretical research demonstrating its efficacy in testing
both procedural and reactive programs. This paper provides a systematic
literature review of various LBT implementations across different program types
and evaluates the current state of research in this field. We explore diverse
theoretical frameworks, existing tools, and libraries within the LBT domain to
illustrate the concept's evolution and current research status. Additionally,
we examine case studies involving the application of LBT tools in industrial
settings, highlighting their potential and effectiveness in commercial software
testing. This systematic literature review aims to offer researchers a
comprehensive perspective on the inception and development of LBT, presenting
it as a promising technique in software testing. By unveiling LBT's
underutilized potential, this paper seeks to significantly benefit the
practitioners and research community.

</details>


### [10] [Analyzing Latent Concepts in Code Language Models](https://arxiv.org/abs/2510.00476)
*Arushi Sharma,Vedant Pungliya,Christopher J. Quinn,Ali Jannesari*

Main category: cs.SE

TL;DR: 提出了Code Concept Analysis (CoCoA)框架，通过聚类上下文标记嵌入来揭示代码语言模型中的词汇、句法和语义结构，并开发了混合标注流程来标记潜在概念。


<details>
  <summary>Details</summary>
Motivation: 解释代码语言模型的内部行为对于需要信任、透明度和语义鲁棒性的应用至关重要，但目前仍是一个挑战。

Method: 使用CoCoA框架聚类上下文标记嵌入，结合静态分析工具和提示工程LLMs的混合标注流程，并与局部归因方法集成生成概念基础的解释。

Result: CoCoA发现的概念在语义保持扰动下保持稳定(CSI=0.288)，在微调中可预测地演化。在用户研究中，概念增强解释在编程语言分类任务中比基于标记的归因方法提高了37个百分点的可解释性。

Conclusion: CoCoA框架能够有效揭示代码语言模型中的潜在概念结构，提高模型解释的连贯性和可解释性，特别是在代码理解和分析任务中。

Abstract: Interpreting the internal behavior of large language models trained on code
remains a critical challenge, particularly for applications demanding trust,
transparency, and semantic robustness. We propose Code Concept Analysis
(CoCoA): a global post-hoc interpretability framework that uncovers emergent
lexical, syntactic, and semantic structures in a code language model's
representation space by clustering contextualized token embeddings into
human-interpretable concept groups. We propose a hybrid annotation pipeline
that combines static analysis tool-based syntactic alignment with
prompt-engineered large language models (LLMs), enabling scalable labeling of
latent concepts across abstraction levels. We analyse the distribution of
concepts across layers and across three finetuning tasks. Emergent concept
clusters can help identify unexpected latent interactions and be used to
identify trends and biases within the model's learned representations. We
further integrate LCA with local attribution methods to produce
concept-grounded explanations, improving the coherence and interpretability of
token-level saliency. Empirical evaluations across multiple models and tasks
show that LCA discovers concepts that remain stable under semantic-preserving
perturbations (average Cluster Sensitivity Index, CSI = 0.288) and evolve
predictably with fine-tuning. In a user study, concept-augmented explanations
disambiguate token roles. In a user study on the programming-language
classification task, concept-augmented explanations disambiguated token roles
and improved human-centric explainability by 37 percentage points compared with
token-level attributions using Integrated Gradients.

</details>


### [11] [CodeChemist: Functional Knowledge Transfer for Low-Resource Code Generation via Test-Time Scaling](https://arxiv.org/abs/2510.00501)
*Kaixin Wang,Tianlin Li,Xiaoyu Zhang,Aishan Liu,Xianglong Liu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,and Bin Shi*

Main category: cs.SE

TL;DR: CodeChemist是一个无需重新训练模型的高效测试时扩展框架，通过生成测试用例实现从高资源编程语言到低资源编程语言的功能知识迁移，提升低资源语言的代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 代码大语言模型在不同编程语言上的性能不一致，低资源语言由于训练数据有限表现较差，需要一种方法能够在不重新训练模型的情况下提升低资源语言的代码生成能力。

Method: 首先生成并执行高资源语言的代码来创建包含功能知识的测试用例，然后使用多温度对冲采样生成低资源语言的代码片段，最后根据测试用例的通过率选择最佳代码。

Result: 广泛的实验表明，CodeChemist优于现有的测试时扩展方法，显著提升了低资源编程语言的代码生成性能。

Conclusion: CodeChemist提供了一种有效的测试时扩展解决方案，能够在不重新训练模型的情况下，通过功能知识迁移显著改善低资源编程语言的代码生成质量。

Abstract: Code Large Language Models (CodeLLMs) are increasingly used in code
generation tasks across a wide range of applications. However, their
performance is often inconsistent across different programming languages (PLs),
with low-resource PLs suffering the most due to limited training data. In this
paper, we present CodeChemist, a novel and efficient framework for test-time
scaling that enables functional knowledge transfer from high-resource to
low-resource PLs using generated test cases. CodeChemist first generates and
executes code in high-resource PLs to create test cases that encapsulate
functional knowledge. It then uses multi-temperature hedged sampling to
generate code snippets in the low-resource PL and selects the best one based on
the pass rate of the test cases. Our extensive experiments show that
CodeChemist outperforms existing test-time scaling approaches, boosting the
performance of code generation for low-resource PLs without requiring any model
retraining.

</details>


### [12] [Architectural Transformations and Emerging Verification Demands in AI-Enabled Cyber-Physical Systems](https://arxiv.org/abs/2510.00519)
*Hadiza Umar Yusuf,Khouloud Gaaloul*

Main category: cs.SE

TL;DR: 本文研究了AI驱动的CPS与传统控制模型在架构和验证实践上的差异。


<details>
  <summary>Details</summary>
Motivation: 尽管AI显著提升了CPS的适应性，但其集成也带来了复杂性，影响控制优化和可靠性。目前尚不清楚这种转变如何影响CPS架构、操作复杂性和验证实践。

Method: 通过调查在Simulink中设计的AI驱动与传统控制模型之间的架构差异。

Result: 揭示了AI驱动与传统控制模型在架构上的区别及其对系统验证的影响。

Conclusion: AI集成改变了CPS架构，需要重新思考验证实践以应对增加的复杂性。

Abstract: In the world of Cyber-Physical Systems (CPS), a captivating real-time fusion
occurs where digital technology meets the physical world. This synergy has been
significantly transformed by the integration of artificial intelligence (AI), a
move that dramatically enhances system adaptability and introduces a layer of
complexity that impacts CPS control optimization and reliability. Despite
advancements in AI integration, a significant gap remains in understanding how
this shift affects CPS architecture, operational complexity, and verification
practices. The extended abstract addresses this gap by investigating
architectural distinctions between AI-driven and traditional control models
designed in Simulink and their respective implications for system verification.

</details>


### [13] [LSPFuzz: Hunting Bugs in Language Servers](https://arxiv.org/abs/2510.00532)
*Hengcheng Zhu,Songqiang Chen,Valerio Terragni,Lili Wei,Jiarong Wu,Yepang Liu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: LSPFuzz是一个针对语言服务器协议(LSP)服务器的灰盒混合模糊测试工具，通过两阶段变异策略有效发现LSP服务器中的未知漏洞。


<details>
  <summary>Details</summary>
Motivation: LSP协议已广泛集成到现代软件开发中，但LSP服务器的可靠性问题日益突出，崩溃会禁用所有代码智能功能，漏洞可能让开发者面临风险。目前缺乏专门针对LSP服务器测试的技术。

Method: 采用灰盒混合模糊测试方法，关键洞察是有效的LSP服务器测试需要对源代码和编辑器操作进行整体变异。使用两阶段变异管道：语法感知的源代码变异，然后上下文感知的编辑器操作分发。

Result: 在四个广泛使用的LSP服务器上评估，LSPFuzz表现优于基线模糊器，发现了真实LSP服务器中先前未知的漏洞。报告的51个漏洞中，42个被确认，26个被修复，2个被分配了CVE编号。

Conclusion: LSPFuzz推进了LSP服务器的质量保证，为该领域的未来研究提供了实用工具和基础见解。

Abstract: The Language Server Protocol (LSP) has revolutionized the integration of code
intelligence in modern software development. There are approximately 300 LSP
server implementations for various languages and 50 editors offering LSP
integration. However, the reliability of LSP servers is a growing concern, as
crashes can disable all code intelligence features and significantly impact
productivity, while vulnerabilities can put developers at risk even when
editing untrusted source code. Despite the widespread adoption of LSP, no
existing techniques specifically target LSP server testing. To bridge this gap,
we present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing.
Our key insight is that effective LSP server testing requires holistic mutation
of source code and editor operations, as bugs often manifest from their
combinations. To satisfy the sophisticated constraints of LSP and effectively
explore the input space, we employ a two-stage mutation pipeline: syntax-aware
mutations to source code, followed by context-aware dispatching of editor
operations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz
demonstrated superior performance compared to baseline fuzzers, and uncovered
previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported,
42 have been confirmed, 26 have been fixed by developers, and two have been
assigned CVE numbers. Our work advances the quality assurance of LSP servers,
providing both a practical tool and foundational insights for future research
in this domain.

</details>


### [14] [AI-Driven Self-Evolving Software: A Promising Path Toward Software Automation](https://arxiv.org/abs/2510.00591)
*Liyi Cai,Yijie Ren,Yitong Zhang,Jia Li*

Main category: cs.SE

TL;DR: 提出AI驱动的自进化软件概念，通过多智能体架构实现无需人工干预的持续软件演化


<details>
  <summary>Details</summary>
Motivation: 当前AI在软件开发中仅作为助手角色，仍需人工干预。探索AI能否成为软件核心组件，实现真正的软件自动化

Method: 基于多智能体架构构建轻量级原型，能够自主解释用户需求、生成验证代码并集成新功能

Result: 在多个代表性场景的案例研究表明，原型能可靠地构建和复用功能，为更复杂应用的扩展提供早期证据

Conclusion: 这种软件系统能够扩展到更复杂的应用，为实现真正自动化的软件开发铺平道路

Abstract: Software automation has long been a central goal of software engineering,
striving for software development that proceeds without human intervention.
Recent efforts have leveraged Artificial Intelligence (AI) to advance software
automation with notable progress. However, current AI functions primarily as
assistants to human developers, leaving software development still dependent on
explicit human intervention. This raises a fundamental question: Can AI move
beyond its role as an assistant to become a core component of software, thereby
enabling genuine software automation? To investigate this vision, we introduce
AI-Driven Self-Evolving Software, a new form of software that evolves
continuously through direct interaction with users. We demonstrate the
feasibility of this idea with a lightweight prototype built on a multi-agent
architecture that autonomously interprets user requirements, generates and
validates code, and integrates new functionalities. Case studies across
multiple representative scenarios show that the prototype can reliably
construct and reuse functionality, providing early evidence that such software
systems can scale to more sophisticated applications and pave the way toward
truly automated software development. We make code and cases in this work
publicly available at https://anonymous.4open.science/r/live-software.

</details>


### [15] [PyTrim: A Practical Tool for Reducing Python Dependency Bloat](https://arxiv.org/abs/2510.00674)
*Konstantinos Karakatsanis,Georgios Alexopoulos,Ioannis Karyotakis,Foivos Timotheos Proestakis,Evangelos Talos,Panos Louridas,Dimitris Mitropoulos*

Main category: cs.SE

TL;DR: PYTRIM是一个端到端的Python依赖修剪系统，能够自动检测并移除项目中未使用的依赖项，包括源代码和配置文件中的导入声明和包声明。


<details>
  <summary>Details</summary>
Motivation: Python项目中的依赖膨胀问题增加了维护成本和安全隐患，现有工具只能检测未使用的依赖，但需要手动移除这些依赖。

Method: PYTRIM采用模块化设计，可与任何依赖检测工具集成，并包含新颖的动态分析组件来提高依赖检测的召回率。系统能够自动移除Python源代码和配置文件中的未使用导入和包声明。

Result: 在37个真实合并请求的数据集上，PYTRIM实现了98.3%的准确率。在971个开源包中，成功识别并修剪了39个包的膨胀依赖，其中6个修剪请求已被接受合并。

Conclusion: PYTRIM是一个有效的自动化依赖修剪工具，能够显著减少Python项目的依赖膨胀问题，并已作为开源项目发布以促进社区贡献。

Abstract: Dependency bloat is a persistent challenge in Python projects, which
increases maintenance costs and security risks. While numerous tools exist for
detecting unused dependencies in Python, removing these dependencies across the
source code and configuration files of a project requires manual effort and
expertise.
  To tackle this challenge we introduce PYTRIM, an end-to-end system to
automate this process. PYTRIM eliminates unused imports and package
declarations across a variety of file types, including Python source and
configuration files such as requirements.txt and setup.py. PYTRIM's modular
design makes it agnostic to the source of dependency bloat information,
enabling integration with any detection tool. Beyond its contribution when it
comes to automation, PYTRIM also incorporates a novel dynamic analysis
component that improves dependency detection recall.
  Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset
of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3%
accuracy in replicating human-made changes. To show its practical impact, we
run PYTRIM on 971 open-source packages, identifying and trimming bloated
dependencies in 39 of them. For each case, we submit a corresponding pull
request, 6 of which have already been accepted and merged. PYTRIM is available
as an open-source project, encouraging community contributions and further
development.
  Video demonstration: https://youtu.be/LqTEdOUbJRI
  Code repository: https://github.com/TrimTeam/PyTrim

</details>


### [16] [TShape: Rescuing Machine Learning Models from Complex Shapelet Anomalies](https://arxiv.org/abs/2510.00680)
*Hang Cui,Jingjing Li,Haotian Si,Quan Zhou,Changhua Pei,Gaogang Xie,Dan Pei*

Main category: cs.SE

TL;DR: TShape是一个用于工业时间序列异常检测的新框架，通过补丁式双重注意力机制和多尺度卷积来检测复杂的形状异常，在五个基准测试中平均F1分数提升了10%。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以检测表现为复杂形状偏差的形状异常，这些异常对人类专家来说很明显，但对机器学习算法具有挑战性。

Method: 引入补丁式双重注意力机制与多尺度卷积，通过平衡局部细粒度形状特征与全局上下文依赖来建模复杂子序列变化。

Result: 在五个不同基准测试中，TShape优于现有最先进模型，异常检测平均F1分数提高了10%。消融研究和注意力可视化证实了各组件的重要贡献。

Conclusion: TShape对时间序列数据中复杂形状异常具有鲁棒性和适应性，各组件都发挥了重要作用。

Abstract: Time series anomaly detection (TSAD) is critical for maintaining the
reliability of modern IT infrastructures, where complex anomalies frequently
arise in highly dynamic environments. In this paper, we present TShape, a novel
framework designed to address the challenges in industrial time series anomaly
detection. Existing methods often struggle to detect shapelet anomalies that
manifest as complex shape deviations, which appear obvious to human experts but
prove challenging for machine learning algorithms. TShape introduces a
patch-wise dual attention mechanism with multi-scale convolution to model
intricate sub-sequence variations by balancing local, fine-grained shape
features with global contextual dependencies. Our extensive evaluation on five
diverse benchmarks demonstrates that TShape outperforms existing
state-of-the-art models, achieving an average 10\% F1 score improvement in
anomaly detection. Additionally, ablation studies and attention visualizations
confirm the essential contributions of each component, highlighting the
robustness and adaptability of TShape to complex shapelet shapes in time series
data.

</details>


### [17] [Maven-Lockfile: High Integrity Rebuild of Past Java Releases](https://arxiv.org/abs/2510.00730)
*Larissa Schmid,Elias Lundell,Yogya Gamage,Benoit Baudry,Martin Monperrus*

Main category: cs.SE

TL;DR: Maven-Lockfile为Java生态系统中的Maven包管理器提供了锁文件支持，解决了依赖版本冻结和构建完整性验证的问题。


<details>
  <summary>Details</summary>
Motivation: 现代软件项目依赖大量第三方库，使得可重现和安全构建变得复杂。Maven作为Java生态系统最重要的包管理器之一，缺乏原生锁文件支持，无法确保依赖版本的固定性和构建完整性。

Method: 开发了Maven-Lockfile工具来生成和更新锁文件，支持从历史版本重建项目。锁文件捕获所有直接和传递依赖及其校验和，实现高完整性构建。

Result: 评估显示Maven-Lockfile能够重现历史提交的构建，并能检测被篡改的构件。通过最小配置，为Java项目提供了现代构建完整性和可重现性。

Conclusion: Maven-Lockfile为Java项目配备了现代构建完整性和可重现性能力，并为Java软件供应链安全的未来研究奠定了基础。

Abstract: Modern software projects depend on many third-party libraries, complicating
reproducible and secure builds. Several package managers address this with the
generation of a lockfile that freezes dependency versions and can be used to
verify the integrity of dependencies. Yet, Maven, one of the most important
package managers in the Java ecosystem, lacks native support for a lockfile. We
present Maven-Lockfile to generate and update lockfiles, with support for
rebuilding projects from past versions. Our lockfiles capture all direct and
transitive dependencies with their checksums, enabling high integrity builds.
Our evaluation shows that Maven-Lockfile can reproduce builds from historical
commits and is able to detect tampered artifacts. With minimal configuration,
Maven-Lockfile equips Java projects with modern build integrity and build
reproducibility, and fosters future research on software supply chain security
in Java.

</details>


### [18] [AI Where It Matters: Where, Why, and How Developers Want AI Support in Daily Work](https://arxiv.org/abs/2510.00762)
*Rudrajit Choudhuri,Carmen Badea,Christian Bird,Jenna Butler,Rob DeLine,Brian Houck*

Main category: cs.SE

TL;DR: 该研究通过对860名开发者的大规模混合方法研究，揭示了开发者对AI支持的接受度和需求模式，发现任务评估能预测AI使用意愿，并识别了不同工作场景下的负责任AI优先级。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑软件开发工作，但目前缺乏关于开发者最需要AI支持的领域、如何负责任设计AI支持的明确指导。

Method: 采用大规模混合方法研究，基于认知评估理论分析860名开发者的任务评估与AI采用模式的关系。

Result: 研究发现：核心工作（编码、测试）有强烈使用需求；减少繁琐工作（文档、运维）需求高；身份和关系相关工作（指导）有明显限制。负责任AI优先级因场景而异：系统任务关注可靠性和安全性；控制任务需要透明度、对齐性和可操控性；面向人的工作关注公平性和包容性。

Conclusion: 研究结果为在开发者真正关心的领域提供AI支持提供了具体、情境化的指导，帮助设计更符合开发者需求的负责任AI工具。

Abstract: Generative AI is reshaping software work, yet we lack clear guidance on where
developers most need and want support, and how to design it responsibly. We
report a large-scale, mixed-methods study of N=860 developers that examines
where, why, and how they seek or limit AI help, providing the first task-aware,
empirically validated mapping from developers' perceptions of their tasks to AI
adoption patterns and responsible AI priorities. Using cognitive appraisal
theory, we show that task evaluations predict openness to and use of AI,
revealing distinct patterns: strong current use and a desire for improvement in
core work (e.g., coding, testing); high demand to reduce toil (e.g.,
documentation, operations); and clear limits for identity- and
relationship-centric work (e.g., mentoring). Priorities for responsible AI
support vary by context: reliability and security for systems-facing tasks;
transparency, alignment, and steerability to maintain control; and fairness and
inclusiveness for human-facing work. Our results offer concrete, contextual
guidance for delivering AI where it matters to developers and their work.

</details>


### [19] [Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning](https://arxiv.org/abs/2510.00881)
*Patrizio Migliarini,Mashal Afzal Memon,Marco Autili,Paola Inverardi*

Main category: cs.SE

TL;DR: 开发了一个自动化框架来评估16个LLM在零样本设置下的伦理推理能力，使用30个真实世界伦理场景。结果显示LLM在理论一致性方面达到73.3%，道德可接受性方面达到86.7%的一致率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地集成到软件工程工具中，需要评估它们在伦理推理方面的能力，特别是在涉及不确定性和伦理重要情境下的判断能力。

Method: 使用30个真实世界伦理场景，让16个LLM在零样本设置下识别最适用的伦理理论、评估道德可接受性并解释推理过程，然后与专家伦理学家的选择进行比较。

Result: LLM平均理论一致性率为73.3%，道德可接受性二元一致率为86.7%，在伦理模糊案例中存在可解释的分歧。定性分析显示模型间存在强概念收敛。

Conclusion: LLM作为软件工程流程中的伦理推理引擎具有潜在可行性，能够实现可扩展、可审计和自适应的用户对齐伦理推理集成。

Abstract: Large Language Models (LLMs) are increasingly integrated into software
engineering (SE) tools for tasks that extend beyond code synthesis, including
judgment under uncertainty and reasoning in ethically significant contexts. We
present a fully automated framework for assessing ethical reasoning
capabilities across 16 LLMs in a zero-shot setting, using 30 real-world
ethically charged scenarios. Each model is prompted to identify the most
applicable ethical theory to an action, assess its moral acceptability, and
explain the reasoning behind their choice. Responses are compared against
expert ethicists' choices using inter-model agreement metrics. Our results show
that LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary
Agreement Rate (BAR) on moral acceptability of 86.7%, with interpretable
divergences concentrated in ethically ambiguous cases. A qualitative analysis
of free-text explanations reveals strong conceptual convergence across models
despite surface-level lexical diversity. These findings support the potential
viability of LLMs as ethical inference engines within SE pipelines, enabling
scalable, auditable, and adaptive integration of user-aligned ethical
reasoning. Our focus is the Ethical Interpreter component of a broader
profiling pipeline: we evaluate whether current LLMs exhibit sufficient
interpretive stability and theory-consistent reasoning to support automated
profiling.

</details>


### [20] [On Effective Semantic Translation for Code: A Study Based on Pseudocode](https://arxiv.org/abs/2510.00920)
*Songqiang Chen,Congying Xu,Jingyi Chen,Jialun Cao,Jiarong Wu,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: 本文研究了基于伪代码的代码翻译方法，发现它能有效补充直接翻译方法，特别是在从灵活编程语言翻译到严格编程语言或处理低资源Rust时效果显著。


<details>
  <summary>Details</summary>
Motivation: 直接代码翻译方法在处理复杂程序时存在挑战，受人类语义翻译过程的启发，探索通过伪代码作为中间步骤来提升代码翻译的准确性。

Method: 采用伪代码作为中间表示，先将程序意图和逻辑转换为伪代码，再实现为目标编程语言。在9,690个翻译任务上比较了直接翻译和伪代码翻译方法，涉及6种编程语言和5个主流大语言模型。

Result: 伪代码翻译能有效补充直接翻译，特别是在从灵活语言到严格语言的翻译以及处理低资源Rust时表现突出。伪代码翻译有助于解耦复杂程序的翻译过程，减少原程序实现细节的干扰。

Conclusion: 建议结合两种方法的互补优势来提升代码翻译准确性。同时揭示了伪代码翻译的局限性，包括伪代码本身可能不正确、不完整或存在歧义。

Abstract: Large language models (LLMs) show great potential in code translation.
However, accurate translation remains challenging when using the commonly
adopted direct code-to-code translation approach, which converts a program into
the target programming language (PL) in a single step. Inspired by the success
of incorporating intermediate steps to guide LLMs in resolving challenging
tasks, we explore pseudocode-based code translation, which emulates the human
semantic translation by first interpreting the program's intent and logic into
pseudocode and then implementing it in the target PL. We find that
pseudocode-based translation helps translate programs that direct translation
struggles to handle. Nonetheless, the effectiveness, advantages, and
limitations of this approach remain underexplored. To bridge this gap, we
present an empirical study on pseudocode-based code translation, aiming to
investigate its effectiveness in enhancing the direct translation approach,
illuminate its effective usage, and identify limitations hindering its
potential benefits. By comparing direct and pseudocode-based translation
approaches on 9,690 translation tasks across six PLs with five popular LLMs, we
demonstrate that pseudocode-based translation can effectively complement direct
translation, particularly when translating from flexible to rigid PLs or
dealing with low-resource Rust. Based on these findings, we suggest adopting
strategies that combine the complementary strengths of both approaches to
enhance code translation accuracy. We also reveal the advantages of
pseudocode-based translation in disentangling translations of complicated
programs and mitigating distractions from detailed implementations in original
programs, as well as its limitations due to incorrect, incomplete, or ambiguous
pseudocode.

</details>


### [21] [ChatGPT in Introductory Programming: Counterbalanced Evaluation of Code Quality, Conceptual Learning, and Student Perceptions](https://arxiv.org/abs/2510.00946)
*Shiza Andleeb,Brandon Kantorski,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: ChatGPT能提高CS1课程学生的代码质量和效率，但对概念理解的影响不一致，需要结构化整合来培养独立解决问题的能力。


<details>
  <summary>Details</summary>
Motivation: 研究ChatGPT在编程入门课程中对代码质量、概念理解、任务完成时间和学生感知的影响，以了解AI工具在编程教育中的利弊。

Method: 采用平衡设计的准实验研究，学生在两个C语言编程作业（函数和结构体）中交替使用ChatGPT和非ChatGPT条件，通过多维评分标准、概念后测调查和任务完成时间进行评估。

Result: 使用ChatGPT的学生代码质量评分显著更高，任务完成时间更短；概念理解方面，函数主题较低但结构体主题较高；学生对ChatGPT体验积极，认为对调试和练习有价值，但担心准确性和长期技能发展。

Conclusion: ChatGPT能提升新手程序员的代码质量和效率，但未必能一致改善概念理解，建议采用结构化整合和补充教学策略来培养独立解决问题的能力。

Abstract: Background: Large language models (LLMs) such as ChatGPT are increasingly
used in introductory programming courses to provide real-time code generation,
debugging, and explanations. While these tools can boost productivity and code
quality, concerns remain about over-reliance and potential impacts on
conceptual learning. Objective: To investigate how ChatGPT access affects code
quality, conceptual understanding, task completion times, and student
perceptions in a CS1 course. Methods: We conducted a counterbalanced,
quasi-experimental study in which students alternated between ChatGPT and
non-ChatGPT conditions across two programming assignments in C (functions and
structures). We evaluated their code submissions using multidimensional
rubrics, conceptual post-surveys, and task completion time. Results: Students
who had access to ChatGPT produced significantly higher rubric scores for code
quality and completed tasks in less time compared to those without access.
However, gains in conceptual understanding were mixed, lower for the functions
topic but higher for the structures topic. Students reported positive
experiences with ChatGPT, citing its value for debugging and practice, while
expressing concerns about accuracy and long-term skill development.
Conclusions: ChatGPT can enhance code quality and efficiency for novice
programmers, but may not uniformly improve conceptual understanding. Structured
integration and complementary instructional strategies are recommended to
foster independent problem-solving skills.

</details>


### [22] [Enhancing Software Testing Education: Understanding Where Students Struggle](https://arxiv.org/abs/2510.00957)
*Shiza Andleeb,Teo Mendoza,Lucas Cordova,Gursimran Walia,Jeffrey C. Carver*

Main category: cs.SE

TL;DR: 研究分析学生在软件测试课程中常见的概念误解，特别是导致测试覆盖率无法提升的无效修改模式，发现决策覆盖和异常处理是最具挑战性的概念


<details>
  <summary>Details</summary>
Motivation: 许多计算机科学学生在掌握构建全面测试套件所需的基础概念方面存在困难，但尚不清楚哪些测试概念最常被误解以及这些误解如何反映在学生的测试套件修订中

Method: 利用自动化反馈工具分析高年级软件测试课程中两个作业的学生提交，识别普遍存在的概念差距和无成效修改模式

Result: 决策覆盖和异常处理是持续存在的挑战，学生最常进行表面或方法级别的修改，这些修改无法提升代码覆盖率

Conclusion: 研究结果为教育工作者、研究人员和工具设计者提供了可操作的见解，通过精确定位最常导致测试结果不佳的概念，可以改进反馈系统、针对性教学，更有效地支持学生开发健壮、可维护的测试套件

Abstract: Effective software testing is critical for producing reliable and secure
software, yet many computer science students struggle to master the
foundational concepts required to construct comprehensive test suites. While
automated feedback tools are widely used to support student learning, it
remains unclear which testing concepts are most frequently misunderstood and
how these misunderstandings are reflected in students' test suite revisions.
This study examines the specific testing concepts that lead students to make
ineffective changes, those that fail to improve code coverage, during test
suite development. Leveraging an automated feedback tool in a senior-level
software testing course, we analyzed student submissions from two assignments
to identify prevalent conceptual gaps and patterns of unproductive
modification. Our results reveal that decision coverage and exception handling
are persistent challenges, and that students most often make superficial or
method-level changes that do not enhance coverage. These findings provide
actionable insights for educators, researchers, and tool designers. By
pinpointing the concepts that most often contribute to poor testing outcomes,
we can refine feedback systems, target instruction to address persistent
misconceptions, and more effectively support students in developing robust,
maintainable test suites.

</details>


### [23] [Semantics-Aligned, Curriculum-Driven, and Reasoning-Enhanced Vulnerability Repair Framework](https://arxiv.org/abs/2510.01002)
*Chengran Yang,Ting Zhang,Jinfeng Jiang,Xin Zhou,Haoye Tian,Jieke Shi,Junkai Chen,Yikun Li,Eng Lieh Ouh,Lwin Khin Shar,David Lo*

Main category: cs.SE

TL;DR: SeCuRepair是一个基于语义对齐、课程驱动和推理增强的漏洞修复框架，通过"先推理后编辑"范式显著提升了自动化漏洞修复的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的自动化漏洞修复方法在真实场景中泛化能力不足，存在跨仓库泛化有限、无法捕获长距离依赖、过度依赖表面词汇模式三大弱点。

Method: 采用"先推理后编辑"范式，要求模型在生成补丁前明确说明修复原因和方法；使用语义感知的强化学习，奖励与oracle补丁在语法和语义上对齐的补丁；实施难度感知的课程学习，从简单修复逐步过渡到复杂的多hunk协调编辑。

Result: 在BigVul和PrimeVul_AVR数据集的严格仓库级划分上，SeCuRepair显著优于所有基线方法，在CodeBLEU指标上分别比最佳基线高出34.52%和31.52%。

Conclusion: SeCuRepair通过语义对齐、课程驱动和推理增强的方法有效解决了现有AVR方法的局限性，显著提升了漏洞修复的泛化性能。

Abstract: Current learning-based Automated Vulnerability Repair (AVR) approaches, while
promising, often fail to generalize effectively in real-world scenarios. Our
diagnostic analysis reveals three fundamental weaknesses in state-of-the-art
AVR approaches: (1) limited cross-repository generalization, with performance
drops on unseen codebases; (2) inability to capture long-range dependencies,
causing a performance degradation on complex, multi-hunk repairs; and (3)
over-reliance on superficial lexical patterns, leading to significant
performance drops on vulnerabilities with minor syntactic variations like
variable renaming.
  To address these limitations, we propose SeCuRepair, a semantics-aligned,
curriculum-driven, and reasoning-enhanced framework for vulnerability repair.
At its core, SeCuRepair adopts a reason-then-edit paradigm, requiring the model
to articulate why and how a vulnerability should be fixed before generating the
patch. This explicit reasoning enforces a genuine understanding of repair logic
rather than superficial memorization of lexical patterns. SeCuRepair also moves
beyond traditional supervised fine-tuning and employs semantics-aware
reinforcement learning, rewarding patches for their syntactic and semantic
alignment with the oracle patch rather than mere token overlap. Complementing
this, a difficulty-aware curriculum progressively trains the model, starting
with simple fixes and advancing to complex, multi-hunk coordinated edits.
  We evaluate SeCuRepair on strict, repository-level splits of BigVul and newly
crafted PrimeVul_AVR datasets. SeCuRepair significantly outperforms all
baselines, surpassing the best-performing baselines by 34.52% on BigVul and
31.52% on PrimeVul\textsubscript{AVR} in terms of CodeBLEU, respectively.
Comprehensive ablation studies further confirm that each component of our
framework contributes to its final performance.

</details>


### [24] [Improving Code Localization with Repository Memory](https://arxiv.org/abs/2510.01003)
*Boshi Wang,Weijian Xu,Yunsheng Li,Mei Gao,Yujia Xie,Huan Sun,Dongdong Chen*

Main category: cs.SE

TL;DR: 该研究提出通过利用仓库的提交历史来增强语言代理的代码定位能力，让代理能够访问历史提交、相关问题和功能摘要等非参数化记忆，从而更好地模拟人类开发者的长期仓库知识。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理代码仓库任务时通常从零开始，忽略了人类开发者会积累长期仓库记忆（如关键模块功能和bug类型与修复位置的关联）这一关键方面。

Method: 通过引入工具让代理能够从非参数化记忆中检索信息，包括近期历史提交和关联问题，以及通过提交模式识别的活跃代码部分的功能摘要。

Result: 实验表明，这种记忆增强方法显著提升了最先进的定位框架LocAgent在SWE-bench-verified和SWE-bench-live基准测试上的性能。

Conclusion: 该研究为开发能够积累和利用过去经验处理长期任务的代理做出了贡献，更接近模拟人类开发者的专业知识。

Abstract: Code localization is a fundamental challenge in repository-level software
engineering tasks such as bug fixing. While existing methods equip language
agents with comprehensive tools/interfaces to fetch information from the
repository, they overlook the critical aspect of memory, where each instance is
typically handled from scratch assuming no prior repository knowledge. In
contrast, human developers naturally build long-term repository memory, such as
the functionality of key modules and associations between various bug types and
their likely fix locations. In this work, we augment language agents with such
memory by leveraging a repository's commit history - a rich yet underutilized
resource that chronicles the codebase's evolution. We introduce tools that
allow the agent to retrieve from a non-parametric memory encompassing recent
historical commits and linked issues, as well as functionality summaries of
actively evolving parts of the codebase identified via commit patterns. We
demonstrate that augmenting such a memory can significantly improve LocAgent, a
state-of-the-art localization framework, on both SWE-bench-verified and the
more recent SWE-bench-live benchmarks. Our research contributes towards
developing agents that can accumulate and leverage past experience for
long-horizon tasks, more closely emulating the expertise of human developers.

</details>


### [25] [GenIA-E2ETest: A Generative AI-Based Approach for End-to-End Test Automation](https://arxiv.org/abs/2510.01024)
*Elvis Júnior,Alan Valejo,Jorge Valverde-Rebaza,Vânia de Oliveira Neves*

Main category: cs.SE

TL;DR: GenIA-E2ETest利用生成式AI从自然语言描述自动生成可执行的端到端测试脚本，在Web应用中实现了77%的元素指标、82%的执行精度和85%的执行召回率，只需10%的手动调整。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的测试生成方案主要关注单元测试，无法解决端到端测试的挑战，而手动端到端测试耗时且容易出错。

Method: 提出GenIA-E2ETest方法，利用生成式AI从自然语言描述自动生成可执行的端到端测试脚本。

Result: 在两个Web应用上的评估显示：元素指标平均77%，执行精度82%，执行召回率85%，手动修改率仅10%，在典型Web场景中表现一致。

Conclusion: GenIA-E2ETest是从自然语言加速端到端测试自动化的实用有效解决方案，能减少人工工作量并扩大自动化测试的覆盖范围。

Abstract: Software testing is essential to ensure system quality, but it remains
time-consuming and error-prone when performed manually. Although recent
advances in Large Language Models (LLMs) have enabled automated test
generation, most existing solutions focus on unit testing and do not address
the challenges of end-to-end (E2E) testing, which validates complete
application workflows from user input to final system response. This paper
introduces GenIA-E2ETest, which leverages generative AI to generate executable
E2E test scripts from natural language descriptions automatically. We evaluated
the approach on two web applications, assessing completeness, correctness,
adaptation effort, and robustness. Results were encouraging: the scripts
achieved an average of 77% for both element metrics, 82% for precision of
execution, 85% for execution recall, required minimal manual adjustments
(average manual modification rate of 10%), and showed consistent performance in
typical web scenarios. Although some sensitivity to context-dependent
navigation and dynamic content was observed, the findings suggest that
GenIA-E2ETest is a practical and effective solution to accelerate E2E test
automation from natural language, reducing manual effort and broadening access
to automated testing.

</details>


### [26] [CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code](https://arxiv.org/abs/2510.01077)
*Daniele Bifolco,Guido Annicchiarico,Pierluigi Barbiero,Massimiliano Di Penta,Fiorella Zampetti*

Main category: cs.SE

TL;DR: CodeGenLink是一个GitHub CoPilot扩展工具，通过结合LLM和网络搜索功能，为AI生成的代码提供相似代码链接和许可证信息，解决代码可信度和版权问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏代码来源信息，开发者对LLM生成代码的可信度和可能的版权/许可证违规存在担忧。

Method: 结合LLM的网络搜索功能检索候选链接，然后对生成代码和检索代码进行相似性分析。

Result: 初步结果显示CodeGenLink能有效通过相似性分析过滤无关链接，并在可用时提供许可证信息。

Conclusion: CodeGenLink为LLM生成的代码提供了来源追溯和许可证检查的能力，增强了代码的可信度。

Abstract: Large Language Models (LLMs) are widely used in software development tasks
nowadays. Unlike reusing code taken from the Web, for LLMs' generated code,
developers are concerned about its lack of trustworthiness and possible
copyright or licensing violations, due to the lack of code provenance
information. This paper proposes CodeGenLink, a GitHub CoPilot extension for
Visual Studio Code aimed at (i) suggesting links containing code very similar
to automatically generated code, and (ii) whenever possible, indicating the
license of the likely origin of the code. CodeGenLink retrieves candidate links
by combining LLMs with their web search features and then performs similarity
analysis between the generated and retrieved code. Preliminary results show
that CodeGenLink effectively filters unrelated links via similarity analysis
and provides licensing information when available. Tool URL:
https://github.com/danielebifolco/CodeGenLink Tool Video:
https://youtu.be/M6nqjBf9_pw

</details>


### [27] [Developers' Perspectives on Software Licensing: Current Practices, Challenges, and Tools](https://arxiv.org/abs/2510.01096)
*Nathan Wintersgill,Trevor Stalnaker,Daniel Otten,Laura A. Heymann,Oscar Chaparro,Massimiliano Di Penta,Daniel M. German,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 该研究调查了开发者在开源软件许可证合规方面的实践、挑战和工具使用情况，通过58名开发者的调查和7次访谈，提出了15个关键发现和建议。


<details>
  <summary>Details</summary>
Motivation: 随着现代软件产品广泛使用开源组件，许可证合规性变得至关重要。非合规可能导致严重的财务、法律和声誉后果。虽然组织可能寻求法律专业人士的帮助，但开发者在合规过程中仍扮演关键角色，因此需要了解他们的实践方法和面临的挑战。

Method: 研究由软件工程和法律研究人员组成的联合团队进行，包括对58名软件开发者的调查和7次后续访谈，采用混合研究方法。

Result: 研究得出了15个关于当前实践状态的关键发现，涵盖了开发者在许可证合规方面的具体做法、遇到的困难以及使用的工具情况。

Conclusion: 研究讨论了发现的启示，为未来研究提供了方向，并为许可证工具提出了可行的改进建议，旨在提升开源软件许可证合规的实践水平。

Abstract: Most modern software products incorporate open-source components, requiring
development teams to maintain compliance with each component's licenses.
Noncompliance can lead to significant financial, legal, and reputational
repercussions. While some organizations may seek advice from legal
practitioners to assist with licensing tasks, developers still play a key role
in such a process. To this end, it is essential to understand how developers
approach license compliance tasks, the challenges they encounter, and the tools
that they use. This work studies these aspects of software licensing practices
through a study - conducted by a joint team of software engineering and legal
researchers - consisting of a survey with 58 software developers and seven
follow-up interviews. The study resulted in 15 key findings regarding the
current state of practice. We discuss the implications of our findings and
offer directions for future research as well as actionable recommendations for
licensing tools.

</details>


### [28] [When Shared Worlds Break: Demystifying Defects in Multi-User Extended Reality Software Systems](https://arxiv.org/abs/2510.01182)
*Shuqing Li,Chenran Zhang,Binchang Li,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: 对2649个多用户XR系统缺陷报告进行首次大规模实证研究，开发了包含症状表现、根源原因和后果严重性三个维度的综合分类法，揭示了同步不一致和化身相关异常是最常见症状，网络/同步逻辑缺陷和会话管理问题为主要根源，超过34%的缺陷会导致严重破坏共享体验的后果。


<details>
  <summary>Details</summary>
Motivation: 多用户XR系统引入了独特的软件缺陷，影响用户体验，但目前对此类缺陷的理解仍不足。为了填补这一空白，需要进行大规模实证研究来深入了解多用户XR系统中的软件缺陷特征。

Method: 通过定性分析使用迭代开放编码方法，分析了来自开发者论坛、GitHub仓库和主流XR应用商店应用评论的2649个真实世界错误报告，开发了综合分类法。

Result: 研究发现同步不一致和化身相关异常是最普遍的症状，网络/同步逻辑缺陷和会话管理缺陷是主要根源原因。超过34%的缺陷会导致系统崩溃、持续断开连接和完全交互中断等严重后果，还发现了多用户XR特有的隐私和健康影响问题。

Conclusion: 多用户XR系统在分布式系统、实时3D交互和沉浸式体验的交汇处面临独特挑战，需要专门的测试、调试和质量保证方法。基于研究发现为开发者、平台供应商和研究人员提供了可操作的建议。

Abstract: Multi-user Extended Reality (XR) systems enable transformative shared
experiences but introduce unique software defects that compromise user
experience. Understanding software defects in multi-user XR systems is crucial
for enhancing system reliability, yet remains underexplored. To fill the gap,
this paper presents the first large-scale empirical study of multi-user XR
defects, analyzing 2,649 real-world bug reports from diverse sources, including
developer forums, GitHub repositories, and app reviews on mainstream XR app
stores. Through rigorous qualitative analysis using iterative open coding, we
develop a comprehensive taxonomy that classifies multi-user XR bugs along three
dimensions: Symptom Manifestation, Root Cause Origin, and Consequence Severity.
Our findings reveal that synchronization inconsistencies and avatar-related
anomalies are the most prevalent symptoms, while network/synchronization logic
defects and session management flaws emerge as dominant root causes.
Critically, over 34% of analyzed bugs lead to severe consequences that
fundamentally break the shared experience, including system crashes, persistent
disconnections, and complete interaction breakdowns, etc. We also identify
concerning privacy and health implications unique to multi-user XR contexts.
Based on our findings of defect analysis, we provide actionable recommendations
for developers, platform vendors, and researchers. Our results demonstrate that
multi-user XR systems face distinct challenges at the intersection of
distributed systems, real-time 3D interaction, and immersive experiences,
necessitating specialized approaches to testing, debugging, and quality
assurance.

</details>
