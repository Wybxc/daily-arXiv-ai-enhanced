<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 1]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 17]
- [cs.LO](#cs.LO) [Total: 11]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Parsing Hypergraphs using Context-Free Positional Grammars](https://arxiv.org/abs/2601.03896)
*Gennaro Costagliola,Federico Vastarini*

Main category: cs.FL

TL;DR: 提出一种基于LR解析技术和位置语法的新方法，用于解析由上下文无关超边替换文法生成的超图，通过将超边替换约简为带结构约束的位置语法来实现。


<details>
  <summary>Details</summary>
Motivation: 图解析在众多领域具有广泛相关性，当前需要推进对图解析问题的理论和实践理解，特别是针对超边替换文法生成的超图。

Method: 基于新的LR解析技术，将超边替换约简为带结构约束的位置语法，使用基于排列的操作来确定产生式右侧超边的正确顺序。

Result: 初步结果显示图生成歧义与图识别歧义之间的区别，该方法为未来扩展到更具表达力的文法形式提供了有前景的基础。

Conclusion: 该方法为超图解析提供了新的理论基础，虽然可解析的超边替换语言类别仍在研究中，但为未来扩展到更复杂文法形式奠定了基础。

Abstract: We present a novel work-in-progress approach to the parsing of hypergraphs generated by context-free hyperedge replacement grammars. This method is based on a new LR parsing technique for positional grammars, which is also under active development. Central to our approach is a reduction from hyperedge replacement to positional grammars with additional structural constraints, enabling the use of permutation-based operations to determine the correct ordering of hyperedges on the right-hand side of productions. Preliminary results also reveal a distinction between ambiguity in graph generation and ambiguity in graph recognition. While the exact class of hyperedge replacement languages parsable under this method remains under investigation, the approach provides a promising foundation for future generalisations to more expressive grammar formalisms. Graph parsing remains a broadly relevant problem across numerous domains, and our contribution aims to advance both the theoretical and practical understanding of this challenge.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark](https://arxiv.org/abs/2601.03708)
*Qingyun Zou,Jiahao Cui,Nuo Chen,Bingsheng He,Weng-Fai Wong*

Main category: cs.PL

TL;DR: 提出了首个面向多语言硬件代码的仓库级代码补全基准MHRC-Bench，包含训练集和评估集，覆盖三种主要硬件设计编码风格，并通过综合评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有仓库级代码补全基准主要关注软件代码，而忽视了硬件描述语言。LLMs在通用编程语言的代码补全任务上表现良好，但在硬件代码领域缺乏专门的评估基准。

Method: 构建了MHRC-Bench基准，包含MHRC-Bench-Train和MHRC-Bench-Eval两部分。基准针对代码补全任务，覆盖三种主要硬件设计编码风格。每个补全目标都通过具体语法树分析获得代码结构级和硬件导向的语义标签。

Result: 在MHRC-Bench-Eval上对模型进行了全面评估，评估结果和分析表明MHRC-Bench基准的有效性。

Conclusion: MHRC-Bench是首个专门针对多语言硬件代码的仓库级代码补全基准，填补了硬件描述语言评估的空白，为硬件代码补全研究提供了重要工具。

Abstract: Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \textbf{MHRC-Bench}, consisting of \textbf{MHRC-Bench-Train} and \textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.

</details>


### [3] [Agentic Proof Automation: A Case Study](https://arxiv.org/abs/2601.03768)
*Yichen Xu,Martin Odersky*

Main category: cs.PL

TL;DR: LLM代理可自动化定理证明工程，在Lean 4中成功完成189个证明任务，成功率87%，仅16%需要人工干预，显著提升证明工程效率。


<details>
  <summary>Details</summary>
Motivation: 传统定理证明工程劳动密集，而现代大语言模型具备生成证明脚本和代理行为的能力，为自动化证明工程提供了新机会。

Method: 提出"代理式证明自动化"方案：人类提供数学洞察（定义、定理、证明策略），LLM代理处理证明开发的机械工作。通过System Capless语义类型安全性的案例研究，在Lean 4中使用现成的LLM代理和轻量级证明检查工具。

Result: 代理完成了189个证明工程任务，成功率87%，仅16%需要人工干预。生成了超过14,000行代码的System Capless形式化系统机械化证明。

Conclusion: LLM代理是能力强大的证明工程师，能显著提升生产力，但在创造性推理方面仍有不足，某些情况下仍需人类指导。研究提供了交互式探索器和开源机械化代码。

Abstract: Proof engineering is notoriously labor-intensive: proofs that are straightforward on paper often require lengthy scripts in theorem provers. Recent advances in large language models (LLMs) create new opportunities for proof automation: modern LLMs not only generate proof scripts, but also support agentic behavior, exploring codebases and iteratively refining their outputs against prover feedback. These advances enable an emerging scheme where LLM-based agents undertake most proof engineering under human guidance. Humans provide mathematical insight (definitions, theorems, proof strategies); agents handle the mechanical work of proof development. We call this scheme agentic proof automation. We present this scheme through a case study: mechanizing the semantic type soundness of a sophisticated formal system, System Capless, in Lean 4, comprising over 14,000 lines of code. Using off-the-shelf LLM agents with a single lightweight proof-checking tool, the agents completed 189 proof engineering tasks with an 87% success rate, only 16% requiring human intervention. The case study demonstrates that agents are capable proof engineers that substantially boost productivity, though they fall short in creative reasoning and still require human guidance in certain cases. We release an interactive explorer where readers can examine all agent interactions; the mechanization is open-sourced for experiments and extensions.

</details>


### [4] [Logic Programming with Extensible Types](https://arxiv.org/abs/2601.03836)
*Ivan Perez,Angel Herranz*

Main category: cs.PL

TL;DR: 在类型化函数式语言中集成逻辑编程的新方法，通过可扩展类型、通用统一算法和领域特定语言实现


<details>
  <summary>Details</summary>
Motivation: 逻辑编程语言在声明性和简洁性方面具有优势，但其思想在其他编程社区中遇到阻力，未被其他范式和语言广泛采用。本文旨在找到一种将逻辑编程集成到现有类型化函数式编程代码库中的方法。

Method: 结合三个核心思想：1) 使用可扩展类型技术，允许宿主语言值包含逻辑变量；2) 实现适用于任何支持特定操作的数据结构的通用统一算法；3) 引入领域特定语言来定义和查询谓词。

Result: 通过一系列示例展示了该方法的可行性，提供了使表示法对用户更方便的辅助工具，表明该方法不仅在技术上可行，而且实用。已在Haskell语言中实现并取得良好效果。

Conclusion: 提出了一种在类型化函数式编程语言中集成逻辑编程的新方法，该方法不牺牲静态类型，并利用类型化函数式编程的优势（如多态性和高阶函数），实现了技术可行性和实用性的平衡。

Abstract: Logic programming languages present clear advantages in terms of declarativeness and conciseness. However, the ideas of logic programming have been met with resistance in other programming communities, and have not generally been adopted by other paradigms and languages. This paper proposes a novel way to incorporate logic programming in an existing codebase in a typed functional programming language. Our approach integrates with the host language without sacrificing static typing, and leverages strengths of typed functional programming such as polymorphism and higher-order. We do so by combining three ideas. First, we use the extensible types technique to allow values of the host language to contain logic variables. Second, we implement a unification algorithm that works for any data structure that supports certain operations.Third, we introduce a domain-specific language to define and query predicates. We demonstrate our proposal via a series of examples, and provide aids to make the notation convenient for users, showing that the proposed approach is not just technically possible but also practical. Our ideas have been implemented in the language Haskell with very good results.

</details>


### [5] [Inductive First-Order Formula Synthesis by ASP: A Case Study in Invariant Inference](https://arxiv.org/abs/2601.03854)
*Ziyi Yang,George Pîrlea,Ilya Sergey*

Main category: cs.PL

TL;DR: 提出基于ASP的FOL公式合成框架，通过正交切片技术加速分布式系统不变式推理


<details>
  <summary>Details</summary>
Motivation: 统一和推进现有的一阶逻辑公式合成方法，特别是用于推理转换系统不变式的技术，解决搜索空间管理问题

Method: 研究现有方法并分类，提出正交切片技术将搜索空间分区，结合ASP实现公式合成，开发FORCE框架

Result: 显著加速最先进的分布式系统不变式推理算法，支持不同不变式推理框架的组合，实现新颖优化

Conclusion: 提出的框架统一了现有方法，正交切片技术有效管理搜索空间，为不变式推理提供加速和组合能力

Abstract: We present a framework for synthesising formulas in first-order logic (FOL) from examples, which unifies and advances state-of-the-art approaches for inference of transition system invariants. To do so, we study and categorise the existing methodologies, encoding techniques in their formula synthesis via answer set programming (ASP). Based on the derived categorisation, we propose orthogonal slices, a new technique for formula enumeration that partitions the search space into manageable chunks, enabling two approaches for incremental candidate pruning. Using a combination of existing techniques for first-order (FO) invariant synthesis and the orthogonal slices implemented in our framework FORCE, we significantly accelerate a state-of-the-art algorithm for distributed system invariant inference. We also show that our approach facilitates composition of different invariant inference frameworks, allowing for novel optimisations.

</details>


### [6] [Implementing Binary Search Trees in GP 2 (Extended Abstract)](https://arxiv.org/abs/2601.03897)
*Ziad Ismaili Alaoui,Detlef Plump*

Main category: cs.PL

TL;DR: 在GP 2图编程语言中实现二叉搜索树，支持插入、删除和查询操作，最坏情况O(n)，平均O(log n)


<details>
  <summary>Details</summary>
Motivation: 探索在规则基础的图编程语言GP 2中实现经典数据结构，验证其能否达到与命令式语言相似的性能

Method: 使用GP 2的根图转换规则实现二叉搜索树，通过规则匹配和转换来执行插入、删除和查询操作

Result: 实现了二叉搜索树的基本操作，最坏情况时间复杂度为O(n)，平均情况为O(log n)

Conclusion: 在GP 2中实现的二叉搜索树能达到与命令式语言实现相似的时间复杂度，证明了图编程语言在数据结构实现方面的可行性

Abstract: We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.

</details>


### [7] [CSSG: Measuring Code Similarity with Semantic Graphs](https://arxiv.org/abs/2601.04085)
*Jingwen Xu,Yiyang Lu,Changze Lv,Zisu Huang,Zhengkang Guo,Zhengyuan Wang,Muzhao Tian,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.PL

TL;DR: 提出CSSG代码相似度度量方法，利用程序依赖图建模控制依赖和变量交互，相比传统基于字符串重叠或语法树的方法能更好捕获代码语义相似性。


<details>
  <summary>Details</summary>
Motivation: 现有代码相似度度量（如BLEU、CodeBLEU、TSED）主要依赖表层字符串重叠或抽象语法树结构，难以捕获程序间更深层的语义关系。

Method: 提出CSSG（基于语义图的代码相似度）度量方法，利用程序依赖图显式建模控制依赖和变量交互，提供语义感知的代码表示。

Result: 在CodeContests+数据集上的实验表明，CSSG在单语言和跨语言设置下均优于现有度量方法，能更好区分相似与不相似的代码。

Conclusion: 依赖感知的图表示比表层或基于语法的相似度度量更有效，为代码相似度评估提供了更好的替代方案。

Abstract: Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [8] [The Anatomy of a Successful Student Scrum Team: Motivation, Personalities, and Academic Adaptation](https://arxiv.org/abs/2601.03364)
*Nadia Damianova,Santiago Berrezueta-Guzman*

Main category: cs.SE

TL;DR: 研究分析学生团队在混合工作环境下如何调整Scrum实践以适应学术约束，发现轻量级工具协调、灵活冲刺周期和团队动力对项目成功至关重要。


<details>
  <summary>Details</summary>
Motivation: 敏捷方法（特别是Scrum）在软件工程教育中广泛教授，但缺乏关于这些实践在长期运行、学生主导的项目中如何适应学术和混合工作约束的实证证据。

Method: 对8人学生开发团队进行为期一年的案例研究，分析团队如何调整Scrum实践以适应学期节奏、考试、旅行和兼职可用性。使用Discord、Notion和GitHub的定性观察和工件，以及贡献指标和自定义沟通有效性指数（得分：0.76/1.00）来评估三个维度。

Result: 研究发现：(1) 轻量级工具协调即使在远程期间也能实现稳定进展；(2) 一周冲刺和灵活仪式有助于Scrum与学术义务的协调；(3) 共享动机、角色清晰度和兼容的工作风格与流程机制同等重要。

Conclusion: 为在混合、项目式学习环境中采用敏捷方法的教师和学生团队提出了实用建议，强调工具协调、灵活流程和团队动力对成功实施Scrum的重要性。

Abstract: Agile methods, and Scrum in particular, are widely taught in software engineering education; however, there is limited empirical evidence on how these practices function in long-running, student-led projects under academic and hybrid work constraints. This paper presents a year-long case study of an eight-person student development team tasked with designing and implementing a virtual reality game that simulates a university campus and provides program-related educational content. We analyze how the team adapted Scrum practices (sprint structure, roles, backlog management) to fit semester rhythms, exams, travel, and part-time availability, and how communication and coordination were maintained in a hybrid on-site/remote environment. Using qualitative observations and artifacts from Discord, Notion, and GitHub, as well as contribution metrics and a custom communication effectiveness index (score: 0.76/1.00), we evaluate three dimensions: (1) the effectiveness of collaboration tools, (2) the impact of hybrid work on communication and productivity, and (3) the feasibility of aligning Scrum with academic timelines. Our findings show that (i) lightweight, tool-mediated coordination enabled stable progress even during remote periods; (ii) one-week sprints and flexible ceremonies helped reconcile Scrum with academic obligations; and (iii) shared motivation, role clarity, and compatible working styles were as critical as process mechanics. We propose practical recommendations for instructors and student teams adopting agile methods in hybrid, project-based learning settings.

</details>


### [9] [RepoShapley: Shapley-Enhanced Context Filtering for Repository-Level Code Completion](https://arxiv.org/abs/2601.03378)
*Yu Huo,Siyu Zhang,Kun Zeng,Yuquan Lu,Cheng Yang,Yifu Guo,Xiaoying Tang*

Main category: cs.SE

TL;DR: RepoShapley：基于Shapley边际贡献的仓库级代码补全上下文过滤框架，通过联盟感知的块选择机制提升补全质量，减少有害上下文和不必要检索。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在仓库级代码补全中难以控制跨文件证据，因为块的效用具有交互依赖性：某些代码片段仅在与其他互补上下文配对时才有帮助，而冲突的片段则会损害解码过程。

Method: 提出RepoShapley框架，包含ChunkShapley模块：通过(i)单块探测估计带符号加权效应，(ii)捕捉饱和与干扰的代理游戏，(iii)小检索集的精确Shapley计算，(iv)使用冻结生成器的解码最优联盟选择。通过离散控制令牌将验证的KEEP/DROP决策和检索触发蒸馏到单一模型中。

Result: 在多个基准测试和骨干模型上的实验表明，RepoShapley提高了代码补全质量，同时减少了有害上下文和不必要的检索。

Conclusion: RepoShapley通过联盟感知的上下文过滤机制有效解决了仓库级代码补全中的上下文控制问题，为检索增强生成提供了更精细的上下文管理方案。

Abstract: Repository-level code completion benefits from retrieval-augmented generation (RAG). However, controlling cross-file evidence is difficult because chunk utility is often interaction-dependent: some snippets help only when paired with complementary context, while others harm decoding when they conflict. We propose RepoShapley, a coalition-aware context filtering framework supervised by Shapley-style marginal contributions. Our module ChunkShapley constructs offline labels by (i) single-chunk probing with teacher-forced likelihood to estimate signed, weighted effects, (ii) a surrogate game that captures saturation and interference, (iii) exact Shapley computation for small retrieval sets, and (iv) bounded post-verification that selects a decoding-optimal coalition using the frozen generator. We distill verified $KEEP$ or $DROP$ decisions and retrieval triggering into a single model via discrete control tokens. Experiments across benchmarks and backbones show that RepoShapley improves completion quality while reducing harmful context and unnecessary retrieval. Code: https://anonymous.4open.science/r/a7f3c9.

</details>


### [10] [An Empirical Analysis of Community and Coding Patterns in OSS4SG vs. Conventional OSS](https://arxiv.org/abs/2601.03430)
*Mohamed Ouf,Shayan Noei,Zeph Van Iterson,Mariam Guizani,Ying Zou*

Main category: cs.SE

TL;DR: 对比OSS4SG与传统OSS项目：OSS4SG社区更稳定粘性高，传统OSS更吸引新人但流动大；OSS4SG全年参与稳定，传统OSS有季节性波动；OSS4SG核心贡献者负责代码质量和问题解决，传统OSS则分工更明确。


<details>
  <summary>Details</summary>
Motivation: 开源软件对社会公益项目（OSS4SG）旨在解决医疗、社区安全等社会挑战，但现有研究主要关注传统OSS，缺乏对OSS4SG使命驱动特性的了解，需要研究其社区动态和贡献者模式以确保项目可持续性。

Method: 对1039个GitHub仓库进行大规模实证研究，包括422个OSS4SG项目和617个传统OSS项目，比较社区结构、贡献者参与度和编码实践。

Result: OSS4SG项目社区更稳定粘性（63.4%），传统OSS项目更吸引新人但流动大（75.4%）；OSS4SG全年参与稳定，传统OSS有季节性波动；OSS4SG核心贡献者负责代码质量和问题解决，传统OSS则分工更明确。

Conclusion: OSS4SG项目的使命驱动特性塑造了独特的社区动态：更稳定粘性的社区结构、全年一致的参与模式，以及核心贡献者在质量和问题解决中的核心作用，这对项目可持续性和社会影响有重要意义。

Abstract: Open Source Software for Social Good (OSS4SG) projects aim to address critical societal challenges, such as healthcare access and community safety. Understanding the community dynamics and contributor patterns in these projects is essential for ensuring their sustainability and long-term impact. However, while extensive research has focused on conventional Open Source Software (OSS), little is known about how the mission-driven nature of OSS4SG influences its development practices. To address this gap, we conduct a large-scale empirical study of 1,039 GitHub repositories, comprising 422 OSS4SG and 617 conventional OSS projects, to compare community structure, contributor engagement, and coding practices. Our findings reveal that OSS4SG projects foster significantly more stable and "sticky" (63.4%) communities, whereas conventional OSS projects are more "magnetic" (75.4%), attracting a high turnover of contributors. OSS4SG projects also demonstrate consistent engagement throughout the year, while conventional OSS communities exhibit seasonal fluctuations. Additionally, OSS4SG projects rely heavily on core contributors for both code quality and issue resolution, while conventional OSS projects leverage casual contributors for issue resolution, with core contributors focusing primarily on code quality.

</details>


### [11] [CodeEval: A pedagogical approach for targeted evaluation of code-trained Large Language Models](https://arxiv.org/abs/2601.03432)
*Danny Brahman,Mohammad Mahoor*

Main category: cs.SE

TL;DR: 论文提出CodeEval基准数据集和RunCodeEval执行框架，用于多维度评估LLM的Python代码生成能力，覆盖24个编程方面和3个熟练度级别。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集无法准确评估LLM的代码生成能力，难以识别具体优缺点，阻碍了针对性的模型改进。需要一种更精细的评估方法来指导LLM编程能力的提升。

Method: 提出CodeEval多维度基准数据集，模拟学术编程课程评估过程，覆盖24个Python编程方面、3个熟练度级别（初级、中级、高级），包含类和函数两种问题类型。同时开发RunCodeEval开源执行框架，提供完整的评估管道。

Result: 创建了全面的CodeEval基准数据集和RunCodeEval执行框架，能够详细评估LLM在不同复杂度、问题类型和编程类别上的表现，为研究者提供深入的模型能力分析。

Conclusion: CodeEval和RunCodeEval的组合实现了有针对性的LLM编程能力评估，能够指导模型改进，填补了现有代码生成评估的空白，促进了LLM编程能力的系统提升。

Abstract: Large Language Models (LLMs) are predominantly assessed based on their common sense reasoning, language comprehension, and logical reasoning abilities. While models trained in specialized domains like mathematics or coding have demonstrated remarkable advancements in logical reasoning, there remains a significant gap in evaluating their code generation capabilities. Existing benchmark datasets fall short in pinpointing specific strengths and weaknesses, impeding targeted enhancements in models' reasoning abilities to synthesize code. To bridge this gap, our paper introduces an innovative, pedagogical benchmarking method that mirrors the evaluation processes encountered in academic programming courses. We introduce CodeEval, a multi-dimensional benchmark dataset designed to rigorously evaluate LLMs across 24 distinct aspects of Python programming. The dataset covers three proficiency levels - beginner, intermediate, and advanced - and includes both class-based and function-based problem types with detailed problem specifications and comprehensive test suites. To facilitate widespread adoption, we also developed RunCodeEval, an open-source execution framework that provides researchers with a ready-to-use evaluation pipeline for CodeEval. RunCodeEval handles test execution, context setup, and metrics generation, enabling researchers to quickly obtain detailed insights into model strengths and weaknesses across complexity levels, problem types, and programming categories. This combination enables targeted evaluation and guides improvements in LLMs' programming proficiencies.

</details>


### [12] [Bootstrapping Code Translation with Weighted Multilanguage Exploration](https://arxiv.org/abs/2601.03512)
*Yuhan Wu,Huan Zhang,Wei Cheng,Chen Shen,Jingyue Yang,Wei Hu*

Main category: cs.SE

TL;DR: BootTrans：利用测试套件的功能不变性和跨语言可移植性，通过引导方法解决多语言代码翻译中并行数据稀缺和优化不平衡问题


<details>
  <summary>Details</summary>
Motivation: 多语言代码翻译面临两个关键挑战：1）缺乏带有可执行测试用例的并行数据；2）处理不同语言对时的优化不平衡问题

Method: 提出BootTrans引导方法：利用测试套件的功能不变性，将丰富的枢纽语言单元测试适配为多语言强化学习的通用验证机制；采用双池架构（种子池和探索池）通过执行引导的经验收集逐步扩展训练数据；设计语言感知加权机制，根据兄弟语言间的相对性能动态优先处理更难的翻译方向

Result: 在HumanEval-X和TransCoder-Test基准测试中，相比基线LLM在所有翻译方向上都取得了显著改进，消融实验验证了引导和加权组件的有效性

Conclusion: BootTrans通过利用测试套件的跨语言可移植性和动态加权机制，有效解决了多语言代码翻译中的数据稀缺和优化不平衡问题，为跨语言代码翻译提供了有效的解决方案

Abstract: Code translation across multiple programming languages is essential yet challenging due to two vital obstacles: scarcity of parallel data paired with executable test oracles, and optimization imbalance when handling diverse language pairs. We propose BootTrans, a bootstrapping method that resolves both obstacles. Its key idea is to leverage the functional invariance and cross-lingual portability of test suites, adapting abundant pivot-language unit tests to serve as universal verification oracles for multilingual RL training. Our method introduces a dual-pool architecture with seed and exploration pools to progressively expand training data via execution-guided experience collection. Furthermore, we design a language-aware weighting mechanism that dynamically prioritizes harder translation directions based on relative performance across sibling languages, mitigating optimization imbalance. Extensive experiments on the HumanEval-X and TransCoder-Test benchmarks demonstrate substantial improvements over baseline LLMs across all translation directions, with ablations validating the effectiveness of both bootstrapping and weighting components.

</details>


### [13] [Deploy-Master: Automating the Deployment of 50,000+ Agent-Ready Scientific Tools in One Day](https://arxiv.org/abs/2601.03513)
*Yi Wang,Zhenting Huang,Zhaohan Ding,Ruoxue Liao,Yuan Huang,Xinzijian Liu,Jiajun Xie,Siheng Chen,Linfeng Zhang*

Main category: cs.SE

TL;DR: Deploy-Master是一个自动化工作流，用于大规模发现、构建、验证和发布开源科学软件，成功将50,112个科学工具容器化，解决了科学软件部署难题。


<details>
  <summary>Details</summary>
Motivation: 开源科学软件虽然丰富，但大多数工具难以编译、配置和重用，这限制了可重复性、大规模评估以及科学工具在现代AI-for-Science和智能体工作流中的集成。这种部署瓶颈维持了科学计算的"小作坊"模式。

Method: Deploy-Master采用一站式智能体工作流，包括：1) 基于90+科学工程领域分类的大规模工具发现；2) 从50万个公共仓库中筛选出52,550个候选工具；3) 构建规范推断；4) 基于执行的验证；5) 容器化发布。系统在一天内完成了52,550次构建尝试，成功创建了50,112个可重现的运行时环境。

Result: 成功构建了50,112个可执行的科学工具，每个工具都经过最小可执行命令验证，并注册到SciencePedia供搜索和重用。研究还提供了5万工具规模的部署追踪，揭示了吞吐量、成本分布、失败模式和规范不确定性等大规模才可见的问题。

Conclusion: 科学软件难以操作化的原因在于大规模部署的复杂性，需要共享、可观察的执行基础作为可扩展AI-for-Science和智能体科学的基础。Deploy-Master展示了自动化部署工作流如何突破科学计算的"小作坊"模式。

Abstract: Open-source scientific software is abundant, yet most tools remain difficult to compile, configure, and reuse, sustaining a small-workshop mode of scientific computing. This deployment bottleneck limits reproducibility, large-scale evaluation, and the practical integration of scientific tools into modern AI-for-Science (AI4S) and agentic workflows.
  We present Deploy-Master, a one-stop agentic workflow for large-scale tool discovery, build specification inference, execution-based validation, and publication. Guided by a taxonomy spanning 90+ scientific and engineering domains, our discovery stage starts from a recall-oriented pool of over 500,000 public repositories and progressively filters it to 52,550 executable tool candidates under license- and quality-aware criteria. Deploy-Master transforms heterogeneous open-source repositories into runnable, containerized capabilities grounded in execution rather than documentation claims. In a single day, we performed 52,550 build attempts and constructed reproducible runtime environments for 50,112 scientific tools. Each successful tool is validated by a minimal executable command and registered in SciencePedia for search and reuse, enabling direct human use and optional agent-based invocation.
  Beyond delivering runnable tools, we report a deployment trace at the scale of 50,000 tools, characterizing throughput, cost profiles, failure surfaces, and specification uncertainty that become visible only at scale. These results explain why scientific software remains difficult to operationalize and motivate shared, observable execution substrates as a foundation for scalable AI4S and agentic science.

</details>


### [14] [Do Autonomous Agents Contribute Test Code? A Study of Tests in Agentic Pull Requests](https://arxiv.org/abs/2601.03556)
*Sabrina Haque,Sarvesh Ingale,Christoph Csallner*

Main category: cs.SE

TL;DR: 对AI驱动的代码提交中测试行为的实证研究：分析测试包含率、PR生命周期、规模差异及合并结果


<details>
  <summary>Details</summary>
Motivation: 随着AI编码工具越来越多地提交代码拉取请求，了解测试在这些AI驱动工作流中的表现变得至关重要。需要实证研究AI提交中测试的包含情况，为自主软件开发提供基础。

Method: 使用AIDev数据集，对AI驱动的拉取请求进行实证研究。分析测试包含频率、测试在PR生命周期中的引入时机，以及包含测试的PR与不包含测试的PR在规模、周转时间和合并结果上的差异。

Result: 随时间推移，包含测试的PR越来越普遍，且规模更大、完成时间更长，但合并率基本相似。不同AI代理在测试采用率和测试代码与生产代码的平衡上存在差异。

Conclusion: 研究提供了AI驱动拉取请求中测试行为的描述性视图，为未来自主软件开发研究提供了实证基础。测试包含的PR具有不同特征，但合并成功率保持稳定。

Abstract: Testing is a critical practice for ensuring software correctness and long-term maintainability. As agentic coding tools increasingly submit pull requests (PRs), it becomes essential to understand how testing appears in these agent-driven workflows. Using the AIDev dataset, we present an empirical study of test inclusion in agentic pull requests. We examine how often tests are included, when they are introduced during the PR lifecycle and how test-containing PRs differ from non-test PRs in terms of size, turnaround time, and merge outcomes. Across agents, test-containing PRs are more common over time and tend to be larger and take longer to complete, while merge rates remain largely similar. We also observe variation across agents in both test adoption and the balance between test and production code within test PRs. Our findings provide a descriptive view of testing behavior in agentic pull requests and offer empirical grounding for future studies of autonomous software development.

</details>


### [15] [Auditable DevOps Automation via VSM and GQM](https://arxiv.org/abs/2601.03574)
*Mamdouh Alenezi*

Main category: cs.SE

TL;DR: 提出VSM-GQM-DevOps框架，将价值流映射、目标-问题-指标范式和DevOps自动化结合，帮助组织基于数据驱动决策来优先自动化投资，改善交付性能和项目管理成果。


<details>
  <summary>Details</summary>
Motivation: 虽然DevOps自动化能加速软件交付，但许多组织难以从战略项目管理成果（如减少浪费、提高交付可预测性、跨团队协调和面向客户的质量）的角度来论证和优先自动化工作。需要一种可追溯的框架来连接自动化投资与业务价值。

Method: 提出VSM-GQM-DevOps统一框架：1) 价值流映射(VSM)可视化端到端交付系统并量化延迟、返工和交接；2) 目标-问题-指标(GQM)范式将利益相关者目标转化为最小化、决策相关的测量模型；3) 成熟度对齐的DevOps自动化通过小型可逆干预修复经验观察到的瓶颈。框架还包含多站点纵向混合方法验证协议。

Result: 该框架提供了从观察到浪费到目标对齐问题、指标和自动化候选的可追溯性，以及平衡预期影响、置信度和成本的防御性优先级排序方法。验证协议结合了遥测准实验分析和定性三角验证。

Conclusion: 预期贡献是经过验证的路径和一套实用工具，使组织能够选择那些能显著改善交付性能和项目管理成果的自动化投资，实现数据驱动的DevOps自动化决策。

Abstract: DevOps automation can accelerate software delivery, yet many organizations still struggle to justify and prioritize automation work in terms of strategic project-management outcomes such as waste reduction, delivery predictability, cross-team coordination, and customer-facing quality. This paper presents \textit{VSM--GQM--DevOps}, a unified, traceable framework that integrates (i) Value Stream Mapping (VSM) to visualize the end-to-end delivery system and quantify delays, rework, and handoffs, (ii) the Goal--Question--Metric (GQM) paradigm to translate stakeholder objectives into a minimal, decision-relevant measurement model (combining DORA with project and team outcomes), and (iii) maturity-aligned DevOps automation to remediate empirically observed bottlenecks through small, reversible interventions. The framework operationalizes traceability from observed waste to goal-aligned questions, metrics, and automation candidates, and provides a defensible prioritization approach that balances expected impact, confidence, and cost. We also define a multi-site, longitudinal mixed-method validation protocol that combines telemetry-based quasi-experimental analysis (interrupted time series and, where feasible, controlled rollouts) with qualitative triangulation from interviews and retrospectives. The expected contribution is a validated pathway and a set of practical instruments that enables organizations to select automation investments that demonstrably improve both delivery performance and project-management outcomes.

</details>


### [16] [On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation](https://arxiv.org/abs/2601.03621)
*Verya Monjezi,Ashish Kumar,Ashutosh Trivedi,Gang Tan,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文探讨机器学习公平性实践在现实数据问题（如错误标签、缺失数据、分布偏移）下的可靠性问题


<details>
  <summary>Details</summary>
Motivation: 机器学习在关键社会应用中可能产生不公平决策，虽然已有公平性干预措施，但缺乏对这些措施在现实数据质量问题下的可靠性评估

Method: 通过分析现有公平性实践（包括敏感特征处理、属性选择、偏置缓解技术）在数据质量问题下的表现，评估其可靠性

Result: 研究发现现有公平性实践在面临错误标签、缺失数据和分布偏移时可能不可靠，需要更稳健的解决方案

Conclusion: 需要重新评估当前机器学习公平性实践在现实世界数据问题下的有效性，并开发更可靠的公平性保障方法

Abstract: Machine learning (ML) algorithms are increasingly deployed to make critical decisions in socioeconomic applications such as finance, criminal justice, and autonomous driving. However, due to their data-driven and pattern-seeking nature, ML algorithms may develop decision logic that disproportionately distributes opportunities, benefits, resources, or information among different population groups, potentially harming marginalized communities. In response to such fairness concerns, the software engineering and ML communities have made significant efforts to establish the best practices for creating fair ML software. These include fairness interventions for training ML models, such as including sensitive features, selecting non-sensitive attributes, and applying bias mitigators. But how reliably can software professionals tasked with developing data-driven systems depend on these recommendations? And how well do these practices generalize in the presence of faulty labels, missing data, or distribution shifts? These questions form the core theme of this paper.

</details>


### [17] [Verbatim Data Transcription Failures in LLM Code Generation: A State-Tracking Stress Test](https://arxiv.org/abs/2601.03640)
*Mohd Ariful Haque,Kishor Datta Gupta,Mohammad Ashiqur Rahman,Roy George*

Main category: cs.SE

TL;DR: 提出了一个专门测试LLM代码生成中精确转录能力的基准测试，要求模型将高精度十进制常数原样嵌入Python代码并执行简单聚合计算


<details>
  <summary>Details</summary>
Motivation: 现实软件任务中经常需要将数据精确转录到代码中（如加密常数、协议测试向量等），这些操作对微小错误敏感但可能产生语法有效的程序，现有代码生成评估缺乏对此类数据完整性的关注

Method: 设计了一个最小化的转录到代码基准测试：给定高精度十进制常数列表，模型必须生成嵌入这些常数的Python代码并进行简单聚合计算；采用基于精确字符串包含的评估协议，分析状态跟踪和长时程生成失败

Result: 该基准测试作为紧凑的压力测试，能够补充现有代码生成评估，专注于数据完整性而非算法推理能力

Conclusion: 提出了一个专门针对LLM代码生成中精确转录可靠性的基准测试，填补了现有评估在数据完整性方面的空白，有助于识别状态跟踪和长时程生成中的失败模式

Abstract: Many real-world software tasks require exact transcription of provided data into code, such as cryptographic constants, protocol test vectors, allowlists, and calibration tables. These tasks are operationally sensitive because small omissions or alterations can remain silent while producing syntactically valid programs. This paper introduces a deliberately minimal transcription-to-code benchmark to isolate this reliability concern in LLM-based code generation. Given a list of high-precision decimal constants, a model must generate Python code that embeds the constants verbatim and performs a simple aggregate computation. We describe the prompting variants, evaluation protocol based on exact-string inclusion, and analysis framework used to characterize state-tracking and long-horizon generation failures. The benchmark is intended as a compact stress test that complements existing code-generation evaluations by focusing on data integrity rather than algorithmic reasoning.

</details>


### [18] [From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level](https://arxiv.org/abs/2601.03731)
*Jia Li,Yuxin Su,Michael R. Lyu*

Main category: cs.SE

TL;DR: RepoReason：一个基于溯因断言验证的白盒诊断基准，用于评估LLM在仓库级代码推理中的逻辑一致性能力，通过执行驱动的变异框架消除记忆化问题，并提供细粒度的三维度量系统。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型发展为自主代理，评估其在真实、大规模、相互依赖的文件系统中保持逻辑一致性的仓库级推理能力变得至关重要。当前基准测试通常在孤立代码片段和黑盒评估之间波动，缺乏对复杂代码库中逻辑一致性的深入诊断。

Method: 1. 提出RepoReason基准，围绕溯因断言验证构建白盒诊断框架；2. 采用执行驱动的变异框架，利用环境作为语义预言机重新生成真实状态，消除记忆化同时保持真实逻辑深度；3. 建立基于动态程序切片的细粒度诊断系统，使用三个正交指标：ESV（读取负载）、MCL（模拟深度）和DFI（集成宽度）。

Result: 对前沿模型（如Claude-4.5-Sonnet、DeepSeek-v3.1-Terminus）的全面评估揭示了一个普遍的聚合缺陷：集成宽度（DFI）成为主要的认知瓶颈。模型在处理跨多个文件的复杂依赖关系时表现不佳，而读取负载（ESV）和模拟深度（MCL）方面的表现相对较好。

Conclusion: RepoReason提供了细粒度的白盒洞察，可用于优化下一代代理式软件工程。研究结果表明，当前LLM在仓库级推理中的主要瓶颈在于跨文件集成能力，这为未来模型改进指明了方向。

Abstract: As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.

</details>


### [19] [Assessing and Improving the Representativeness of Code Generation Benchmarks Using Knowledge Units (KUs) of Programming Languages -- An Empirical Study](https://arxiv.org/abs/2601.03780)
*Md Ahasanuzzaman,Bram Adams,Emad Fallahzadeh,Gustavo A. Oliva,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 该研究首次系统分析了代码生成基准测试中编程概念的代表性，发现HumanEval和MBPP等基准测试仅覆盖一半的知识单元，且分布严重偏斜，而真实项目则全面覆盖且分布均衡。作者提出了基于提示的LLM框架来合成新任务以重新平衡基准测试，评估显示现有基准测试高估了LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准测试（如HumanEval）可能无法全面反映真实世界项目中使用的编程概念。如果基准测试中涵盖的概念不具有代表性，评估结果可能不完整。然而，基准测试中代码概念的代表性尚未得到系统研究。

Method: 通过知识单元（KUs）的视角分析代码生成基准测试的代表性。分析两个广泛使用的Python基准测试（HumanEval和MBPP）的KU覆盖情况，并与30个真实世界Python项目进行比较。提出基于提示的LLM框架来合成KU-based任务，以重新平衡基准测试的KU分布。

Result: 每个基准测试仅覆盖20个已识别KUs的一半，而真实项目则全面覆盖所有KUs且分布相对均衡。基准测试任务呈现高度偏斜的KU分布。使用提出的框架生成了440个新任务并增强现有基准测试，使分布对齐度提高了60%以上。在增强基准测试上评估最先进的LLMs显示性能一致且显著下降（12.54-44.82%）。

Conclusion: 现有基准测试由于有限的KU覆盖而高估了LLM性能。研究结果为构建更现实的LLM代码生成能力评估提供了可操作的指导。

Abstract: Large Language Models (LLMs) such as GPT-4, Claude and LLaMA have shown impressive performance in code generation, typically evaluated using benchmarks (e.g., HumanEval). However, effective code generation requires models to understand and apply a wide range of language concepts. If the concepts exercised in benchmarks are not representative of those used in real-world projects, evaluations may yield incomplete. Despite this concern, the representativeness of code concepts in benchmarks has not been systematically examined.
  To address this gap, we present the first empirical study that analyzes the representativeness of code generation benchmarks through the lens of Knowledge Units (KUs) - cohesive sets of programming language capabilities provided by language constructs and APIs. We analyze KU coverage in two widely used Python benchmarks, HumanEval and MBPP, and compare them with 30 real-world Python projects. Our results show that each benchmark covers only half of the identified 20 KUs, whereas projects exercise all KUs with relatively balanced distributions. In contrast, benchmark tasks exhibit highly skewed KU distributions.
  To mitigate this misalignment, we propose a prompt-based LLM framework that synthesizes KU-based tasks to rebalance benchmark KU distributions and better align them with real-world usage. Using this framework, we generate 440 new tasks and augment existing benchmarks. The augmented benchmarks substantially improve KU coverage and achieve over a 60% improvement in distributional alignment. Evaluations of state-of-the-art LLMs on these augmented benchmarks reveal consistent and statistically significant performance drops (12.54-44.82%), indicating that existing benchmarks overestimate LLM performance due to their limited KU coverage. Our findings provide actionable guidance for building more realistic evaluations of LLM code-generation capabilities.

</details>


### [20] [Once Upon a Team: Investigating Bias in LLM-Driven Software Team Composition and Task Allocation](https://arxiv.org/abs/2601.03857)
*Alessandra Parziale,Gianmario Voria,Valeria Pontillo,Amleto Di Salle,Patrizio Pelliccione,Gemma Catolino,Fabio Palomba*

Main category: cs.SE

TL;DR: LLMs在软件工程团队组建和任务分配中存在系统性偏见，基于候选人的国家和代词等人口属性产生不公平决策，加剧了人口不平等问题。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地用于提高生产力和支持软件工程任务，但当应用于团队组建和任务分配等社会敏感决策时，引发了公平性担忧。先前研究显示LLMs可能再现刻板印象，但这些分析仍是探索性的，且孤立地考察敏感属性。

Method: 研究通过分析候选人国家和代词的组合效应，调查LLMs在团队组建和任务分配中是否存在偏见。使用三个LLM模型和3000个模拟决策进行分析。

Result: 发现系统性差异：人口属性显著影响选择可能性和任务分配，即使考虑了专业知识相关因素。任务分布进一步反映了刻板印象，技术和领导角色在不同群体间分配不均。

Conclusion: LLMs在软件工程环境中加剧了人口不平等，强调了需要公平意识评估的重要性。

Abstract: LLMs are increasingly used to boost productivity and support software engineering tasks. However, when applied to socially sensitive decisions such as team composition and task allocation, they raise concerns of fairness. Prior studies have revealed that LLMs may reproduce stereotypes; however, these analyses remain exploratory and examine sensitive attributes in isolation. This study investigates whether LLMs exhibit bias in team composition and task assignment by analyzing the combined effects of candidates' country and pronouns. Using three LLMs and 3,000 simulated decisions, we find systematic disparities: demographic attributes significantly shaped both selection likelihood and task allocation, even when accounting for expertise-related factors. Task distributions further reflected stereotypes, with technical and leadership roles unevenly assigned across groups. Our findings indicate that LLMs exacerbate demographic inequities in software engineering contexts, underscoring the need for fairness-aware assessment.

</details>


### [21] [Understanding Specification-Driven Code Generation with LLMs: An Empirical Study Design](https://arxiv.org/abs/2601.03878)
*Giovanni Rosa,David Moreno-Lumbreras,Gregorio Robles,Jesús M. González-Barahona*

Main category: cs.SE

TL;DR: 该论文通过CURRANTE工具研究人类在规格说明和测试细化中的干预如何影响LLM生成代码的质量和动态过程。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM越来越多地集成到软件开发工作流中，但它们在结构化、规格驱动的过程中的行为仍然缺乏深入理解。需要研究人类干预如何影响LLM辅助代码生成的质量和动态。

Method: 使用CURRANTE（Visual Studio Code扩展）进行实证研究设计，该工具支持人机协同工作流，引导开发者通过规格说明、测试和函数三个顺序阶段。参与者解决LiveCodeBench数据集中的中等难度问题，工具记录细粒度交互日志、有效性指标（通过率、全通过完成率）、效率指标（通过时间）和迭代行为。

Result: 研究将分析人类在规格说明和测试细化中的干预如何影响LLM生成代码的质量和动态过程，但目前论文尚未提供具体实验结果。

Conclusion: 研究结果将为设计下一代开发环境提供实证见解，使人类推理与模型驱动的代码生成更好地对齐。

Abstract: Large Language Models (LLMs) are increasingly integrated into software development workflows, yet their behavior in structured, specification-driven processes remains poorly understood. This paper presents an empirical study design using CURRANTE, a Visual Studio Code extension that enables a human-in-the-loop workflow for LLM-assisted code generation. The tool guides developers through three sequential stages--Specification, Tests, and Function--allowing them to define requirements, generate and refine test suites, and produce functions that satisfy those tests. Participants will solve medium-difficulty problems from the LiveCodeBench dataset, while the tool records fine-grained interaction logs, effectiveness metrics (e.g., pass rate, all-pass completion), efficiency indicators (e.g., time-to-pass), and iteration behaviors. The study aims to analyze how human intervention in specification and test refinement influences the quality and dynamics of LLM-generated code. The results will provide empirical insights into the design of next-generation development environments that align human reasoning with model-driven code generation.

</details>


### [22] [Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures](https://arxiv.org/abs/2601.03988)
*Nicolas Lacroix,Mireille Blay-Fornarino,Sébastien Mosser,Frederic Precioso*

Main category: cs.SE

TL;DR: 本文评估小型语言模型(SLMs)在提取机器学习管道阶段方面的能力，以解决现有方法在可扩展性和领域多样性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 从源代码中提取机器学习管道阶段对于深入理解数据科学实践至关重要，但现有方法存在局限性：要么依赖不可扩展的人工标注，要么使用无法充分支持领域多样性的机器学习分类器。这些限制凸显了对更灵活可靠解决方案的需求。

Method: 采用验证性研究方法，基于两个相关参考工作。首先使用Cochran's Q检验比较多个SLM模型，然后通过两个独立的McNemar's检验将最佳模型与参考研究对比。通过额外的Cochran's Q检验分析分类定义变化对性能的影响，最后使用Pearson卡方检验进行拟合优度分析，比较与先前研究的数据科学实践见解。

Result: 未在摘要中明确说明具体结果，但研究方法表明将评估SLM在代码理解和分类能力方面的表现，并分析其对数据科学实践理解的推进作用。

Conclusion: 研究旨在确定小型语言模型是否能够利用其代码理解和分类能力解决现有方法的局限性，从而推进对数据科学实践的理解。

Abstract: Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.
  Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.
  Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.

</details>


### [23] [An Ontology-Based Approach to Security Risk Identification of Container Deployments in OT Contexts](https://arxiv.org/abs/2601.04010)
*Yannick Landeck,Dian Balta,Martin Wimmer,Christian Knierim*

Main category: cs.SE

TL;DR: 提出基于本体的容器安全风险模型(CSRO)，用于OT环境中特权容器的自动化、可重复风险识别


<details>
  <summary>Details</summary>
Motivation: OT环境中容器化应用常需要特权访问网络接口或执行监控任务，这降低了容器默认隔离性并带来安全风险。现有方法缺乏可重复性、跨上下文可解释性以及与部署工件的技术集成

Method: 提出基于模型的方法，实现为容器安全风险本体(CSRO)，集成五个关键领域：对抗行为、上下文假设、攻击场景、风险评估规则和容器安全工件

Result: 案例研究表明，CSRO实现了从工件到风险级别的端到端形式化风险计算，支持自动化和可重复的风险识别

Conclusion: CSRO目前专注于技术层面的容器级处理措施，但其模块化和灵活设计为扩展到主机级和组织风险因素提供了坚实基础

Abstract: In operational technology (OT) contexts, containerised applications often require elevated privileges to access low-level network interfaces or perform administrative tasks such as application monitoring. These privileges reduce the default isolation provided by containers and introduce significant security risks. Security risk identification for OT container deployments is challenged by hybrid IT/OT architectures, fragmented stakeholder knowledge, and continuous system changes. Existing approaches lack reproducibility, interpretability across contexts, and technical integration with deployment artefacts. We propose a model-based approach, implemented as the Container Security Risk Ontology (CSRO), which integrates five key domains: adversarial behaviour, contextual assumptions, attack scenarios, risk assessment rules, and container security artefacts. Our evaluation of CSRO in a case study demonstrates that the end-to-end formalisation of risk calculation, from artefact to risk level, enables automated and reproducible risk identification. While CSRO currently focuses on technical, container-level treatment measures, its modular and flexible design provides a solid foundation for extending the approach to host-level and organisational risk factors.

</details>


### [24] [Smells Depend on the Context: An Interview Study of Issue Tracking Problems and Smells in Practice](https://arxiv.org/abs/2601.04124)
*Lloyd Montgomery,Clara Lüders,Christian Rahe,Walid Maalej*

Main category: cs.SE

TL;DR: 研究人员通过访谈26名软件工程从业者，发现ITS（问题跟踪系统）存在14个常见问题，包括问题可发现性、僵尸问题、工作流膨胀等，并指出文献中的31种ITS异味大多不常见或不构成问题，强调ITS问题高度依赖上下文因素。


<details>
  <summary>Details</summary>
Motivation: 尽管研究人员广泛分析ITS数据以自动化或辅助特定活动（如问题分配、重复检测、优先级预测），但对ITS的开发人员研究仍然很少。特别是，对软件工程团队在ITS中遇到的挑战以及某些实践和变通方法（如将"优先级"等字段留空）何时被视为问题知之甚少。

Method: 通过深度访谈研究，采访了来自不同组织和行业的26名经验丰富的软件工程从业者，询问他们遇到的一般问题以及文献中讨论的31种ITS异味（即潜在问题实践）的相关性。应用主题分析法对访谈记录进行分析。

Result: 识别出14个常见问题，包括问题可发现性、僵尸问题、工作流膨胀、缺乏工作流执行等。参与者还指出，许多ITS异味并不发生或不构成问题。结果表明ITS问题和异味高度依赖于上下文因素，如ITS配置、工作流阶段和团队规模。

Conclusion: ITS问题和异味具有高度上下文依赖性，需要根据具体环境进行评估。研究讨论了潜在的工具体解决方案，以配置、监控和可视化ITS异味来应对这些挑战。

Abstract: Issue Tracking Systems (ITSs) enable software developers and managers to collect and resolve issues collaboratively. While researchers have extensively analysed ITS data to automate or assist specific activities such as issue assignments, duplicate detection, or priority prediction, developer studies on ITSs remain rare. Particularly, little is known about the challenges Software Engineering (SE) teams encounter in ITSs and when certain practices and workarounds (such as leaving issue fields like "priority" empty) are considered problematic. To fill this gap, we conducted an in-depth interview study with 26 experienced SE practitioners from different organisations and industries. We asked them about general problems encountered, as well as the relevance of 31 ITS smells (aka potentially problematic practices) discussed in the literature. By applying Thematic Analysis to the interview notes, we identified 14 common problems including issue findability, zombie issues, workflow bloat, and lack of workflow enforcement. Participants also stated that many of the ITS smells do not occur or are not problematic. Our results suggest that ITS problems and smells are highly dependent on context factors such as ITS configuration, workflow stage, and team size. We also discuss potential tooling solutions to configure, monitor, and visualise ITS smells to cope with these challenges.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [25] [130k Lines of Formal Topology in Two Weeks: Simple and Cheap Autoformalization for Everyone?](https://arxiv.org/abs/2601.03298)
*Josef Urban*

Main category: cs.LO

TL;DR: 该项目使用LLM与证明检查器Megalodon的反馈循环，在6周内以约100美元成本自动形式化了Munkres拓扑学教材的大部分内容（160k行代码），包括Urysohn引理、度量化定理等复杂证明。


<details>
  <summary>Details</summary>
Motivation: 展示自动形式化在2026年可能变得简单普及，通过低成本、快速的方法实现大规模数学教材的形式化验证。

Method: 建立LLM（ChatGPT 5.2/Claude Sonnet 4.5）与高阶集合论证明检查器Megalodon之间的长期反馈循环，结合提示工程和技术选择，实现自动形式化。

Result: 在6周内形式化了Munkres拓扑学教材的160k行代码（其中130k行在2周内完成），包含1500多个引理/定理，包括Urysohn引理（3k行）、Urysohn度量化定理（2k行）、Tietze延拓定理（10k+行）等重要结果。

Conclusion: 基于快速进展、低成本、简单设置和相对不知名的证明系统，自动形式化可能在2026年变得容易普及，无论使用哪种证明助手。

Abstract: This is a brief description of a project that has already autoformalized a large portion of the general topology from the Munkres textbook (which has in total 241 pages in 7 chapters and 39 sections). The project has been running since November 21, 2025 and has as of January 4, 2026, produced 160k lines of formalized topology. Most of it (about 130k lines) have been done in two weeks,from December 22 to January 4, for an LLM subscription cost of about \$100. This includes a 3k-line proof of Urysohn's lemma, a 2k-line proof of Urysohn's Metrization theorem, over 10k-line proof of the Tietze extension theorem, and many more (in total over 1.5k lemmas/theorems). The approach is quite simple and cheap: build a long-running feedback loop between an LLM and a reasonably fast proof checker equipped with a core foundational library. The LLM is now instantiated as ChatGPT (mostly 5.2) or Claude Sonnet (4.5) run through the respective Codex or Claude Code command line interfaces. The proof checker is Chad Brown's higher-order set theory system Megalodon, and the core library is Brown's formalization of basic set theory and surreal numbers (including reals, etc). The rest is some prompt engineering and technical choices which we describe here. Based on the fast progress, low cost, virtually unknown ITP/library, and the simple setup available to everyone, we believe that (auto)formalization may become quite easy and ubiquitous in 2026, regardless of which proof assistant is used.

</details>


### [26] [Chronology as a Consistency Invariant in Composable Information Systems](https://arxiv.org/abs/2601.03330)
*Anherutowa Calvo,Dante K. Calvo*

Main category: cs.LO

TL;DR: 在分布式信息系统中，通过局部可组合性的一致性要求，从事件间的操作影响关系推导出内在的时间序，无需预设原始时间概念。


<details>
  <summary>Details</summary>
Motivation: 研究在没有预设时间概念的情况下，如何从分布式系统的操作约束中自然地推导出时间序。传统方法通常假设原始的时间结构，而本文试图从信息约束和局部可组合性的一致性要求中推导出时间序。

Method: 形式化一个最小设置：系统维护分布式记录作为全局可能性空间的约束，事件通过单调收紧记录局部作用，独立事件可交换。定义操作影响（弱影响和强影响），假设全局可满足性、菱形属性、单调信息写入和分支确定性公理，证明强影响是无环的，从而诱导出内在时间序。

Result: 证明了在给定假设下，强影响关系是无环的，因此可以诱导出内在的时间序。同时展示了轨迹不变性和导出序的最小性，引入了基于-log μ(可行集)的单调信息时钟，并给出了避免不一致性的逃逸分类法。

Conclusion: 在分布式信息系统中，通过局部可组合性的一致性要求，可以从事件间的操作影响关系自然地推导出时间序。任何允许强影响环而不导致不一致性的模型，必然违反了全局一致性、局部可组合性、单调写入或分支确定性中的至少一个条件。

Abstract: We formalize a minimal setting in which a chronology (a strict partial order on events) is forced by consistency of distributed information under local composability. The system maintains distributed records interpreted as constraints over a global possibility space (Omega, Sigma), optionally with a measure mu. Events act locally by monotonically tightening records, and independent events commute (diamond/trace semantics), yielding schedule invariance. We define operational influence without assuming primitive time: e influences f if executing e can change what constraint f writes on a shared site. Influence cycles alone need not imply inconsistency, so we distinguish weak influence (dependence) from strong influence (exclusive branching on an observable predicate). Assuming global satisfiability of all reachable record states, the diamond property, monotone information writing, and a mild branch-determinacy axiom for witnessed exclusivity, we prove that strong influence is acyclic and therefore induces an intrinsic chronology. We also show trace invariance and minimality of the derived order, introduce a monotone information clock based on -log mu(feasible set), and give an escape taxonomy: any model that admits strong-influence cycles without inconsistency must violate global consistency, local composability, monotone writing, or branch determinacy.

</details>


### [27] [Extracting Policies from Quantified Answer Set Programs](https://arxiv.org/abs/2601.03835)
*Martín Diéguez,Igor Stéphan*

Main category: cs.LO

TL;DR: 本文提出了一种基于策略的QASP模型解释方法，并设计了相应的策略提取算法


<details>
  <summary>Details</summary>
Motivation: 量化答案集编程（QASP）扩展了ASP，允许命题变量的量化，类似于量化布尔公式（QBF）。需要为QASP公式提供合适的模型解释和计算方法。

Method: 将QASP公式的模型解释为策略，这些策略代表决策制定策略，确定在给定全称量化变量设定的条件下如何分配存在量化变量。提出了一种基于均衡逻辑语义的策略提取算法。

Result: 提出了QASP的策略语义解释框架，并设计了相应的策略提取算法，为QASP计算提供了理论基础。

Conclusion: 通过将QASP模型解释为策略，并基于均衡逻辑语义设计算法，为QASP提供了新的语义解释和计算方法，扩展了ASP在量化推理方面的应用。

Abstract: Quantified Answer Set Programming (QASP) extends Answer Set Programming (ASP) by allowing quantification over propositional variables, similar to Quantified Boolean Formulas (QBF). In this paper, we interpret models of QASP formulas in terms of policies, which represent decision-making strategies that determine how existentially quantified variables should be assigned, given the conditions set by universally quantified variables. As a main contribution, we present an algorithm for policy extraction under QASP semantics, inspired by the Equilibrium Logic semantics for general ASP theories.

</details>


### [28] [Fixpoint Semantics for DatalogMTL with Negation](https://arxiv.org/abs/2601.03841)
*Samuele Pollaci*

Main category: cs.LO

TL;DR: 本文为带否定的DatalogMTL定义了多种语义（稳定、良基、Kripke-Kleene、支持），使用近似不动点理论（AFT）提供简洁形式化，并证明AFT导出的稳定模型语义与之前基于here-and-there逻辑的方法一致。


<details>
  <summary>Details</summary>
Motivation: DatalogMTL是带度量时间算子的Datalog扩展，加入否定后需要明确定义其语义。先前工作已通过here-and-there逻辑对定义了稳定模型语义，但缺乏统一的理论框架。本文旨在使用AFT为带否定的DatalogMTL提供系统化的语义定义，并验证与现有定义的一致性。

Method: 采用近似不动点理论（AFT）这一数学形式化框架，为DatalogMTL with negation定义稳定模型、良基模型、Kripke-Kleene模型和支持模型语义。AFT提供统一的方法处理非分层否定，通过近似算子构建语义。

Result: 成功使用AFT为DatalogMTL with negation定义了四种语义：稳定、良基、Kripke-Kleene和支持模型。关键结果是证明了通过AFT获得的稳定模型语义与先前基于here-and-there逻辑对方法定义的语义完全一致。

Conclusion: AFT为DatalogMTL with negation提供了简洁统一的语义定义框架，涵盖多种语义变体。与先前工作的等价性证明增强了AFT方法的可信度，为带时间逻辑程序的分析和推理提供了坚实的理论基础。

Abstract: DatalogMTL with negation is an extension of Datalog with metric temporal operators enriched with unstratifiable negation. In this paper, we define the stable, well-founded, Kripke-Kleene, and supported model semantics for DatalogMTL with negation in a very simple and straightforward way, by using the solid mathematical formalism of Approximation Fixpoint Theory (AFT). Moreover, we prove that the stable model semantics obtained via AFT coincides with  the one defined in previous work, through the employment of pairs of interpretations stemming from the logic of here-and-there.

</details>


### [29] [On the Trap Space Semantics of Normal Logic Programs](https://arxiv.org/abs/2601.03842)
*Van-Giang Trinh,Sylvain Soliman,François Fages,Belaid Benhamou*

Main category: cs.LO

TL;DR: 本文提出将陷阱空间概念从Datalog^\neg程序推广到任意正规逻辑程序，引入陷阱空间语义作为程序解释的新方法，建立了模型论和动力学特征，并系统关联了现有各种语义。


<details>
  <summary>Details</summary>
Motivation: 传统正规逻辑程序语义基于Clark完备化和各种规范模型（支持、稳定、正则、良基等），但缺乏统一的动力学视角。虽然Datalog^\neg程序与布尔网络的联系已建立，但需要将陷阱空间概念推广到任意正规逻辑程序，以提供更全面的程序行为理解框架。

Method: 将陷阱空间概念从Datalog^\neg程序推广到任意正规逻辑程序，引入陷阱空间语义作为新的程序解释方法。该方法同时具备模型论特征和动力学特征，通过状态空间轨迹来刻画程序含义。

Result: 建立了陷阱空间语义的基础性质，并系统关联了现有模型论语义（稳定模型、稳定偏模型、正则模型、L-稳定模型）和动力学稳定类语义。证明陷阱空间语义能够统一证明支持类、严格稳定类和正则模型的存在性，并揭示现有语义间更深层关系。

Conclusion: 陷阱空间语义为正规逻辑程序提供了一个统一而精确的框架，不仅能够证明各种模型的存在性，还能形式化现有语义间的深层关系，为程序行为理解提供了更全面的方法。

Abstract: The logical semantics of normal logic programs has traditionally been based on the notions of Clark's completion and two-valued or three-valued canonical models, including supported, stable, regular, and well-founded models. Two-valued interpretations can also be seen as states evolving under a program's update operator, producing a transition graph whose fixed points and cycles capture stable and oscillatory behaviors, respectively. We refer to this view as dynamical semantics since it characterizes the program's meaning in terms of state-space trajectories, as first introduced in the stable (supported) class semantics. Recently, we have established a formal connection between Datalog^\neg programs (i.e., normal logic programs without function symbols) and Boolean networks, leading to the introduction of the trap space concept for Datalog^\neg programs. In this paper, we generalize the trap space concept to arbitrary normal logic programs, introducing trap space semantics as a new approach to their interpretation. This new semantics admits both model-theoretic and dynamical characterizations, providing a comprehensive approach to understanding program behavior. We establish the foundational properties of the trap space semantics and systematically relate it to the established model-theoretic semantics, including the stable (supported), stable (supported) partial, regular, and L-stable model semantics, as well as to the dynamical stable (supported) class semantics. Our results demonstrate that the trap space semantics offers a unified and precise framework for proving the existence of supported classes, strict stable (supported) classes, and regular models, in addition to uncovering and formalizing deeper relationships among the existing semantics of normal logic programs.

</details>


### [30] [Implementing the First-Order Logic of Here and There](https://arxiv.org/abs/2601.03848)
*Jens Otten,Torsten Schaub*

Main category: cs.LO

TL;DR: 开发了基于原生序列演算和嵌入直觉逻辑的一阶HT逻辑自动定理证明器，通过自由变量和Skolem化优化，并在大规模基准集上评估。


<details>
  <summary>Details</summary>
Motivation: 为"here and there"（HT）逻辑开发高效的自动定理证明器，该逻辑在非单调推理和回答集编程中具有重要应用，但缺乏专门的证明工具。

Method: 1) 基于HT逻辑的原生序列演算，使用自由变量和Skolem化优化分析证明搜索；2) 将HT逻辑公理化嵌入到直觉逻辑中，结合直觉逻辑的序列、表格和连接演算。

Result: 开发了多个HT逻辑定理证明器，并在大规模一阶公式基准集上进行了评估，为开发更高效的HT证明器奠定了基础。

Conclusion: 成功实现了HT逻辑的自动定理证明，原生序列演算和嵌入直觉逻辑两种方法都有效，评估结果为未来优化提供了基准。

Abstract: We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic. All provers are evaluated on a large benchmark set of first-order formulas, providing a foundation for the development of more efficient HT provers.

</details>


### [31] [Automated Theorem Proving for Prolog Verification](https://arxiv.org/abs/2601.03849)
*Fred Mesnard,Thierry Marianne,Étienne Payet*

Main category: cs.LO

TL;DR: LPTP是用于Prolog程序验证的交互式定理证明器，本文提出将其公理转换为FOF格式，利用自动定理证明器进行验证，并在约400个属性上进行了评估。


<details>
  <summary>Details</summary>
Motivation: LPTP虽然能验证Prolog程序的终止性和部分正确性，但它是交互式的，需要人工参与。本文希望通过将LPTP的公理转换为FOF格式，利用自动定理证明器实现自动化验证，提高验证效率。

Method: 将LPTP的公理（包括Clark等式理论、成功/失败/终止定义、关系公理和归纳公理模式）转换为FOF格式，然后应用自动定理证明器进行验证。开发了编译器将Prolog程序及其属性转换为FOF文件。

Result: 在LPTP库中约400个Prolog程序属性上进行了评估，验证了该方法的可行性。编译器和基准测试集已公开可用。

Conclusion: 通过将LPTP公理转换为FOF格式并利用自动定理证明器，可以实现Prolog程序验证的自动化，该方法在现有基准测试上表现良好。

Abstract: LPTP (Logic Program Theorem Prover) is an interactive natural-deduction-based theorem  prover for pure Prolog programs with negation as failure, unification with the occurs check, and a restricted but extensible set of built-in predicates. With LPTP, one can formally prove termination  and partial correctness of such Prolog programs. LPTP was designed in the mid-1990's by Robert F. Staerk.  It is written in ISO-Prolog and comes with an Emacs user-interface. 
  From a theoretical point of view, in his publications about LPTP, Staerk associates a set of first-order axioms IND(P) to the considered Prolog program P.  IND(P) contains the Clark's equality theory for P,  definitions of success, failure and termination for each user-defined logic procedure in P,  axioms relating these three points of view, and an axiom schema for  proving inductive properties. LPTP is thus a dedicated proof editor where these axioms are hard-wired. 
  We propose to translate these axioms as first-order formulas (FOFs), and apply automated theorem provers to  check the property of interest. Using  FOF  as an intermediary language, we experiment the use of automated theorem  provers for Prolog program verification. We evaluate the approach over  a benchmark of about 400 properties of Prolog  programs from the library available with LPTP. Both the  compiler which generates a set of FOF files from a given input  Prolog program together with its properties and the benchmark are publicly available.

</details>


### [32] [On Zeno-like Behaviors in the Event Calculus with Goal-directed Answer Set Programming](https://arxiv.org/abs/2601.03852)
*Ondřej Vašíček,Joaquin Arias,Jan Fiedor,Gopal Gupta,Brendan Hall,Bohuslav Křena,Brian Larson,Tomáš Vojnar*

Main category: cs.LO

TL;DR: 本文研究事件演算（EC）建模中的芝诺式行为问题，提出检测和处理方法


<details>
  <summary>Details</summary>
Motivation: 事件演算适合建模安全关键信息物理系统，但精确的连续时间表示会导致芝诺式行为和非终止问题

Method: 通过文献中的经典案例系统研究EC建模模式，分析芝诺式行为产生原因，提出处理方法和自动检测技术

Result: 识别了导致芝诺式行为的自然EC建模模式，提出了相应的解决方案和自动检测技术

Conclusion: 解决了EC建模中的芝诺式行为问题，增强了事件演算在安全关键系统建模中的实用性

Abstract: It has been argued that Event Calculus (EC) is suitable for modeling high-level specifications of safety-critical cyber-physical systems. The primary advantage lies in the rather small semantic gap between EC models and requirements expressed in a semi-formal natural language. Moreover, its use of continuous time and variables avoids imprecision that stems from discretization. In the past, we have shown that a goal-directed ASP system can be used for implementing these EC models. However, precise representation of time as an infinitesimally divisible continuous quantity leads to Zeno-like behaviors and to non-termination in such a system. In this work, we model a number of well-known example problems from the literature to systematically study various natural EC modeling patterns that yield these Zeno-like behaviors, and propose ways to deal with them. Moreover, we also propose a technique to automatically detect all such cases.

</details>


### [33] [Introducing The Maximum Common Bigraph Problem](https://arxiv.org/abs/2601.03898)
*Kyle Burns,Michele Sevegnani,Ciaran McCreesh,James Trimble*

Main category: cs.LO

TL;DR: 提出最大公共双图问题定义，并基于McSplit算法开发计算两个双图状态间最大公共双图的算法，为双图工具的互模拟检查铺平道路


<details>
  <summary>Details</summary>
Motivation: 双图反应系统是建模智能技术、网络、传感器系统和生物学等领域中空间与非空间关系的强大数学框架。虽然理论上支持通过模拟和比较最小上下文转移系统来识别互模拟代理，但缺乏计算两个双图间最大共享结构的算法，这是确定给定代理状态可能转移集合的关键前提。

Method: 定义最大公共双图问题，并基于McSplit最大公共诱导子图算法进行适配，开发计算两个双图状态间最大公共双图的算法。

Result: 成功开发了计算最大公共双图的算法，为双图工具的互模拟检查提供了技术基础。

Conclusion: 该工作为双图建模范式中的简化、优化和模型验证工具支持互模拟检查开辟了路径，填补了双图理论中算法实现的空白。

Abstract: Bigraph reactive systems offer a powerful and flexible mathematical framework for modelling both spatial and non-spatial relationships between agents, with practical applications in domains such as smart technologies, networks, sensor systems, and biology. While bigraphs theoretically support the identification of bisimilar agents, by simulating and comparing their corresponding minimal contextual transition systems, no known algorithm exists for computing the maximum shared structure between two bigraphs, an essential prerequisite for determining the set of possible transitions for a given agent state. In this work, we provide a definition of the maximum common bigraph problem, and present an adaptation of the McSplit maximum common induced subgraph algorithm to compute the maximum common bigraph between two bigraph states. Our approach opens a path toward supporting bisimulation checking in bigraph-based tools, which have been leveraged in other modelling paradigms for simplification, optimisation, and verification of models.

</details>


### [34] [Recursive Program Synthesis from Sketches and Mixed-Quantifier Properties](https://arxiv.org/abs/2601.04045)
*Derek Egolf,Stavros Tripakis*

Main category: cs.LO

TL;DR: 提出一种从混合量词一阶逻辑属性自动合成递归程序的新方法，通过Skolem化将混合量词合成问题转化为∀*合成问题，结合草图枚举和反例引导学习来提升性能。


<details>
  <summary>Details</summary>
Motivation: 自动程序合成是形式化方法的重要方向，但现有方法在处理混合量词（∃∀）逻辑属性时面临挑战。需要开发能够有效处理混合量词约束的程序合成技术。

Method: 1. 使用Skolem化将混合量词合成问题转化为∀*合成问题；2. 为引入的Skolem符号合成见证生成函数；3. 采用基于草图的枚举式反例引导方法；4. 从反例中学习语法约束来剪枝候选空间；5. 使用预防性剪枝技术避免枚举无效候选。

Result: 在42个基准测试上进行评估，结果显示反例泛化和预防性剪枝都能显著提升性能，证明了方法的有效性。

Conclusion: 该方法成功解决了混合量词逻辑属性的程序合成问题，通过Skolem化转换和创新的剪枝技术实现了高效合成，为复杂逻辑约束的程序合成提供了新思路。

Abstract: We present a novel approach to the automatic synthesis of recursive programs from mixed-quantifier first-order logic properties. Our approach uses Skolemization to reduce the mixed-quantifier synthesis problem to a $\forall^*$-synthesis problem, synthesizing witness-generating functions for introduced Skolem symbols alongside the target program. We tackle $\forall^*$-synthesis using a sketching-based, enumerative, counterexample-guided approach. Our algorithm learns syntactic constraints from counterexamples to prune the candidate space and employs a prophylactic pruning technique to avoid enumerating invalid candidates altogether. We evaluate our technique on 42 benchmarks, demonstrating that both counterexample generalization and prophylactic pruning significantly improve performance.

</details>


### [35] [Craig Interpolation for HT with a Variation of Mints' Sequent System](https://arxiv.org/abs/2601.04080)
*Christoph Wernhard*

Main category: cs.LO

TL;DR: 本文提出了一种为三值命题逻辑HT构造Craig插值的方法，通过Maehara风格构造，将经典编码插值技术适配到HT的序列演算中。


<details>
  <summary>Details</summary>
Motivation: 为三值命题逻辑HT（也称为Gödel的G_3）开发有效的Craig插值构造方法，这是逻辑推理和程序验证中的重要工具。

Method: 采用两阶段方法：首先基于Mints的HT序列演算构造初步插值（在某种意义上是插值但不是真正的HT公式），然后从初步插值中提取实际的HT插值。将经典编码插值技术适配到直接操作HT公式的序列系统中。

Result: 成功开发了HT逻辑的Craig插值构造方法，通过将经典编码技术适配到非经典逻辑的序列演算中实现。

Conclusion: 该方法为三值命题逻辑HT提供了有效的插值构造技术，扩展了插值理论在非经典逻辑中的应用。

Abstract: We present a Maehara-style construction of Craig interpolants for the three-valued propositional logic of here and there (HT), also known as Gödel's $G_3$. The method adapts a recent interpolation technique that operates on classically encoded logic programs to a variation of a sequent calculus for HT by Mints. The approach is characterized by two stages: First, a preliminary interpolant is constructed, a formula that is an interpolant in some sense, but not yet the desired HT formula. In the second stage, an actual HT interpolant is obtained from this preliminary interpolant. With the classical encoding, the preliminary interpolant is a classical Craig interpolant for classical encodings of the two input HT formulas. In the presented adaptation, the sequent system operates directly on HT formulas, and the preliminary interpolant is in a nonclassical logic that generalizes HT by an additional logic operator.

</details>
