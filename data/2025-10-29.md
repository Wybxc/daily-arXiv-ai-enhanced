<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 16]
- [cs.LO](#cs.LO) [Total: 7]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [AI-Driven Development of a Publishing Imprint: Xynapse Traces](https://arxiv.org/abs/2510.23627)
*Fred Zimmerman*

Main category: cs.SE

TL;DR: Xynapse Traces是一个实验性出版品牌，通过人机融合方法实现了90%的时间缩短和80%的成本降低，第一年出版了52本书，质量指标优异。


<details>
  <summary>Details</summary>
Motivation: 探索人机协作的新出版模式，解决传统出版周期长、成本高的问题，使小众市场变得可行。

Method: 采用配置驱动架构和多模型AI集成框架，包括连续创意管道、代码设计、全面自动化流程和出版者角色定义。

Result: 出版周期从6-12个月缩短至2-4周，成本降低80%，第一年出版52本书，引用准确率99%，验证成功率100%。

Conclusion: 该系统为图书出版业开辟了新范式，展示了人机协作如何民主化高端出版能力，使小众市场变得可行。

Abstract: Xynapse Traces is an experimental publishing imprint created via a fusion of
human and algorithmic methods using a configuration-driven architecture and a
multi-model AI integration framework. The system achieved a remarkable 90%
reduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),
with 80% cost reduction compared to traditional imprint development, while
publishing 52 books in its first year and maintaining exceptional quality
metrics, including 99% citation accuracy and 100% validation success after
initial corrections. Key technical innovations include a continuous ideation
pipeline with tournament-style evaluation, a novel codex design for
transcriptive meditation practice, comprehensive automation spanning from
ideation through production and distribution, and publisher personas that
define and guide the imprint's mission. The system also integrates automated
verification with human oversight, ensuring that gains in speed do not
compromise publishing standards. This effort has significant implications for
the future of book publishing, suggesting new paradigms for human-AI
collaboration that democratize access to sophisticated publishing capabilities
and make previously unviable niche markets accessible.

</details>


### [2] [VisCoder2: Building Multi-Language Visualization Coding Agents](https://arxiv.org/abs/2510.23642)
*Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: 提出了VisCode-Multi-679K数据集、VisPlotBench基准和VisCoder2模型，显著提升了多语言可视化代码生成和调试能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在可视化代码生成中存在语言覆盖有限、执行不可靠、缺乏迭代修正机制等问题，且受限于窄数据集和基准测试。

Method: 构建了包含679K验证样本的多语言数据集VisCode-Multi-679K、系统评估基准VisPlotBench，并训练了多语言可视化模型VisCoder2。

Result: VisCoder2显著超越开源基线模型，接近GPT-4.1性能，在32B规模下达到82.4%执行通过率，特别在符号或编译器依赖语言中表现优异。

Conclusion: 提出的资源组合有效推进了可视化编码代理的发展，通过多语言数据集、系统基准和专用模型解决了现有挑战。

Abstract: Large language models (LLMs) have recently enabled coding agents capable of
generating, executing, and revising visualization code. However, existing
models often fail in practical workflows due to limited language coverage,
unreliable execution, and lack of iterative correction mechanisms. Progress has
been constrained by narrow datasets and benchmarks that emphasize single-round
generation and single-language tasks. To address these challenges, we introduce
three complementary resources for advancing visualization coding agents.
VisCode-Multi-679K is a large-scale, supervised dataset containing 679K
validated and executable visualization samples with multi-turn correction
dialogues across 12 programming languages. VisPlotBench is a benchmark for
systematic evaluation, featuring executable tasks, rendered outputs, and
protocols for both initial generation and multi-round self-debug. Finally, we
present VisCoder2, a family of multi-language visualization models trained on
VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms
strong open-source baselines and approaches the performance of proprietary
models like GPT-4.1, with further gains from iterative self-debug, reaching
82.4% overall execution pass rate at the 32B scale, particularly in symbolic or
compiler-dependent languages.

</details>


### [3] [Agentsway -- Software Development Methodology for AI Agents-based Teams](https://arxiv.org/abs/2510.23664)
*Eranga Bandara,Ross Gore,Xueping Liang,Sachini Rajapakse,Isurunima Kularathne,Pramoda Karunarathna,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Amin Hass,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.SE

TL;DR: 提出了Agentsway框架，这是首个专门为AI代理协作软件工程团队设计的方法论，通过定义规划、提示、编码、测试和微调等不同角色的AI代理，实现人类编排和隐私保护的协作开发。


<details>
  <summary>Details</summary>
Motivation: 传统软件开发方法如Agile、Kanban等是为人类团队设计的，在自主AI代理参与规划、编码、测试和持续学习的环境中越来越不适用，需要专门的方法论来解决这一差距。

Method: Agentsway框架围绕人类编排和隐私保护协作构建结构化生命周期，定义不同角色的专门AI代理，通过集成微调LLM利用开发周期中各代理的输出和反馈进行回顾性学习。

Result: 该框架增强了领域特定推理和可解释决策，通过协调使用多个微调LLM和先进推理模型嵌入负责任的AI原则，确保平衡、透明和负责任的决策制定。

Conclusion: Agentsway通过形式化代理中心协作、集成隐私设计原则和定义可衡量的生产力和信任指标，推进了软件工程发展，代表了迈向下一代AI原生、自我改进软件开发方法论的基础性步骤。

Abstract: The emergence of Agentic AI is fundamentally transforming how software is
designed, developed, and maintained. Traditional software development
methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for
human-centric teams and are increasingly inadequate in environments where
autonomous AI agents contribute to planning, coding, testing, and continuous
learning. To address this methodological gap, we present "Agentsway" a novel
software development framework designed for ecosystems where AI agents operate
as first-class collaborators. Agentsway introduces a structured lifecycle
centered on human orchestration, and privacy-preserving collaboration among
specialized AI agents. The framework defines distinct roles for planning,
prompting, coding, testing, and fine-tuning agents, each contributing to
iterative improvement and adaptive learning throughout the development process.
By integrating fine-tuned LLMs that leverage outputs and feedback from
different agents throughout the development cycle as part of a retrospective
learning process, Agentsway enhances domain-specific reasoning, and explainable
decision-making across the entire software development lifecycle. Responsible
AI principles are further embedded across the agents through the coordinated
use of multiple fine-tuned LLMs and advanced reasoning models, ensuring
balanced, transparent, and accountable decision-making. This work advances
software engineering by formalizing agent-centric collaboration, integrating
privacy-by-design principles, and defining measurable metrics for productivity
and trust. Agentsway represents a foundational step toward the next generation
of AI-native, self-improving software development methodologies. To the best of
our knowledge, this is the first research effort to introduce a dedicated
methodology explicitly designed for AI agent-based software engineering teams.

</details>


### [4] [RefleXGen:The unexamined code is not worth using](https://arxiv.org/abs/2510.23674)
*Bin Wang,Hui Li,AoFan Liu,BoTao Yang,Ao Yang,YiLu Zhong,Weixiang Huang,Yanping Zhang,Runhuai Huang,Weimin Zeng*

Main category: cs.SE

TL;DR: RefleXGen通过结合检索增强生成和引导式自反思机制，显著提升LLM生成代码的安全性，无需大量资源即可实现持续改进。


<details>
  <summary>Details</summary>
Motivation: 代码生成中的安全性是应用大语言模型的关键挑战，传统方法需要大量资源进行微调或构建专用安全数据集，成本高昂。

Method: 结合检索增强生成技术和LLM的引导式自反思机制，通过自我评估和反思迭代优化代码生成过程，持续积累和精炼知识库。

Result: 在多个模型上显著提升代码安全性：GPT-3.5 Turbo提升13.6%，GPT-4o提升6.7%，CodeQwen提升4.5%，Gemini提升5.8%。

Conclusion: 提高模型自反思质量是增强AI生成代码安全性的有效且实用的策略。

Abstract: Security in code generation remains a pivotal challenge when applying large
language models (LLMs). This paper introduces RefleXGen, an innovative method
that significantly enhances code security by integrating Retrieval-Augmented
Generation (RAG) techniques with guided self-reflection mechanisms inherent in
LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing
specialized secure code datasets - processes that can be resource-intensive -
RefleXGen iteratively optimizes the code generation process through
self-assessment and reflection without the need for extensive resources. Within
this framework, the model continuously accumulates and refines its knowledge
base, thereby progressively improving the security of the generated code.
Experimental results demonstrate that RefleXGen substantially enhances code
security across multiple models, achieving a 13.6% improvement with GPT-3.5
Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a
5.8% improvement with Gemini. Our findings highlight that improving the quality
of model self-reflection constitutes an effective and practical strategy for
strengthening the security of AI-generated code.

</details>


### [5] [TDFlow: Agentic Workflows for Test Driven Software Engineering](https://arxiv.org/abs/2510.23761)
*Kevin Han,Siddharth Maddikayala,Tim Knappe,Om Patel,Austen Liao,Amir Barati Farimani*

Main category: cs.SE

TL;DR: TDFlow是一个新颖的测试驱动代理工作流，将仓库级软件工程构建为测试解决任务，通过专门的子代理和受限工具来修复人类编写的测试，在SWE-Bench基准上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决仓库级软件工程中的程序修复问题，通过测试驱动的方法来提升大型语言模型在复杂软件工程任务中的表现。

Method: 将软件工程程序修复分解为四个组件：补丁提议、调试、补丁修订和可选测试生成，每个组件由专门的子代理负责，减少单个代理的长上下文负担。

Result: 在SWE-Bench Lite上达到88.8%的通过率（比次优系统提升27.8%），在SWE-Bench Verified上达到94.3%，仅发现7个测试黑客实例。

Conclusion: 现代LLM在精心设计的测试驱动工作流中已能达到人类水平的测试解决能力，完全自主仓库修复的最终挑战在于生成有效的重现测试。

Abstract: We introduce TDFlow, a novel test-driven agentic workflow that frames
repository-scale software engineering as a test-resolution task, specifically
designed to solve human-written tests. Given a set of tests, TDFlow repeatedly
proposes, revises, and debugs repository-scale patches using precisely
engineered sub-agents and tightly constrained tools. The workflow decomposes
software engineering program repair into four components governed by respective
sub-agents. This simple, forced decoupling of patch proposing, debugging, patch
revision, and optional test generation (1) reduces long-context burden on any
individual sub-agent, (2) focuses each sub-agent on specific, pre-defined
sub-tasks, and (3) allows for specialized performance improvement on specific
sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on
SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and
94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within
SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which
were subsequently counted as failures. Furthermore, we show that the primary
obstacle to human-level software engineering performance lies within writing
successful reproduction tests. We envision a human-LLM interactive system
powered by TDFlow where human developers write tests solved by LLM systems.
Together, these results indicate that modern LLMs, when embedded in a narrowly
engineered, test-driven workflow, already achieve human-level test resolution
-- with the final frontier for fully autonomous repository repair being the
accurate generation of valid reproduction tests.

</details>


### [6] [Evaluating the effectiveness of LLM-based interoperability](https://arxiv.org/abs/2510.23893)
*Rodrigo Falcão,Stefan Schweitzer,Julien Siebert,Emily Calvet,Frank Elberzhager*

Main category: cs.SE

TL;DR: 该研究评估了13个开源大语言模型在农业互操作性用例中的表现，发现qwen2.5-coder:32b模型在两种策略下都能有效实现系统间的自主互操作。


<details>
  <summary>Details</summary>
Motivation: 随着系统变得越来越动态和异构，互操作性挑战日益严峻。研究旨在利用大语言模型的最新进展，分析其在无需人工干预的情况下实现系统运行时自主互操作的有效性。

Method: 选取13个开源LLM，在农业互操作性用例中构建四个版本的数据集，使用DIRECT和CODEGEN两种策略，对每个模型和数据集版本进行三次运行，比较模型效果和结果一致性。

Result: qwen2.5-coder:32b在两种策略下表现最佳，DIRECT策略平均pass@1≥0.99，CODEGEN策略平均pass@1≥0.89。在包含单位转换的数据集版本中，所有模型使用DIRECT策略都失败，而CODEGEN策略下qwen2.5-coder:32b仍能达到平均pass@1=0.75。

Conclusion: 某些LLM能够实现系统的自主互操作，建议在不同领域进一步评估，并开展可靠性策略的深入研究。

Abstract: Background: Systems of systems are becoming increasingly dynamic and
heterogeneous, and this adds pressure on the long-standing challenge of
interoperability. Besides its technical aspect, interoperability has also an
economic side, as development time efforts are required to build the
interoperability artifacts. Objectives: With the recent advances in the field
of large language models (LLMs), we aim at analyzing the effectiveness of
LLM-based strategies to make systems interoperate autonomously, at runtime,
without human intervention. Method: We selected 13 open source LLMs and curated
four versions of a dataset in the agricultural interoperability use case. We
performed three runs of each model with each version of the dataset, using two
different strategies. Then we compared the effectiveness of the models and the
consistency of their results across multiple runs. Results: qwen2.5-coder:32b
was the most effective model using both strategies DIRECT (average pass@1 >=
0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset
versions. In the fourth dataset version, which included an unit conversion, all
models using the strategy DIRECT failed, whereas using CODEGEN
qwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some
LLMs can make systems interoperate autonomously. Further evaluation in
different domains is recommended, and further research on reliability
strategies should be conducted.

</details>


### [7] [Validating Alerts in Cloud-Native Observability](https://arxiv.org/abs/2510.23970)
*Maria C. Borges,Julian Legler,Lucca Di Benedetto*

Main category: cs.SE

TL;DR: 本文介绍了OXN观测实验工具的新告警扩展，让工程师能在开发早期实验告警规则，在设计时调整规则并常规验证告警触发行为，避免运行时问题。


<details>
  <summary>Details</summary>
Motivation: 现代可靠性工程中，告警设计面临挑战：需要在及早发现问题与最小化误报之间取得平衡，且告警代码很少执行和检查。缺乏支持系统化设计和验证告警的工具。

Method: 为OXN观测实验工具开发告警扩展，使工程师能够在开发阶段实验告警，在设计时调整规则并常规验证告警触发行为。

Result: 工程师现在可以在设计时调整告警规则，并常规验证告警的触发行为，从而避免未来在运行时出现问题。

Conclusion: OXN的告警扩展提供了一种系统化的方法来设计和验证告警，解决了告警代码难以测试和验证的挑战。

Abstract: Observability and alerting form the backbone of modern reliability
engineering. Alerts help teams catch faults early before they turn into
production outages and serve as first clues for troubleshooting. However,
designing effective alerts is challenging. They need to strike a fine balance
between catching issues early and minimizing false alarms. On top of this,
alerts often cover uncommon faults, so the code is rarely executed and
therefore rarely checked. To address these challenges, several industry
practitioners advocate for testing alerting code with the same rigor as
application code. Still, there's a lack of tools that support such systematic
design and validation of alerts.
  This paper introduces a new alerting extension for the observability
experimentation tool OXN. It lets engineers experiment with alerts early during
development. With OXN, engineers can now tune rules at design time and
routinely validate the firing behavior of their alerts, avoiding future
problems at runtime.

</details>


### [8] [Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs](https://arxiv.org/abs/2510.24019)
*Xing Xing,Wei Wang,Lipeng Ma,Weidong Yang,Junjie Zheng*

Main category: cs.SE

TL;DR: 提出了一种生命周期感知的代码生成框架，通过引入需求分析、状态机建模和伪代码等中间产物，在训练和推理阶段系统性地结合软件工程实践，显著提升代码正确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型代码生成方法主要依赖从问题描述到代码的单步翻译，忽略了结构化的软件工程实践，需要更系统的方法来提升代码质量。

Method: 设计生命周期感知框架，在训练和推理阶段引入需求分析、状态机建模和伪代码等中间产物，与标准软件开发阶段对齐，支持结构化推理。

Result: 生命周期级微调使代码正确性提升高达75%，多步推理始终优于单步生成。微调后的开源LLM性能达到或略超代码预训练模型，在DeepSeek-Coder-1.3B上相对CodeBLEU提升显著。

Conclusion: 中间产物对最终代码质量有独特贡献，状态机建模影响最大。框架在训练数据减少80%时仍保持稳健，证明了其韧性。

Abstract: Recent progress in large language models (LLMs) has advanced automatic code
generation, yet most approaches rely on direct, single-step translation from
problem descriptions to code, disregarding structured software engineering
practices. We introduce a lifecycle-aware framework that systematically
incorporates intermediate artifacts such as requirements analysis, state
machine modeling, and pseudocode into both the training and inference stages.
This design aligns code generation with standard software development phases
and enables more structured reasoning. Experiments show that lifecycle-level
fine-tuning improves code correctness by up to 75% over the same model before
fine-tuning, with performance gains compounding across intermediate stages.
Multi-step inference consistently surpasses single-step generation,
demonstrating the effectiveness of intermediate scaffolding. Notably,
open-source LLMs, once fine-tuned under our framework, match or slightly
outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our
framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and
22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,
respectively. Our pipeline also proves robust with up to 80\% less training
data, confirming its resilience. Ablation studies further reveal that each
intermediate artifact contributes distinctly to final code quality, with state
machine modeling yielding the most substantial impact. Our source code and
detailed experimental data are available at
https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.

</details>


### [9] [Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps](https://arxiv.org/abs/2510.24142)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 该研究通过焦点小组会议实证分析了机器学习系统在实际应用中的可观测性现状，发现ML系统通常以错误决策而非崩溃的方式失败，并识别了当前实践中的工具和研究空白。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在运行中会静默失败（通过错误决策而非系统崩溃），虽然可观测性被认为是ML运维的关键，但缺乏关于实践者实际捕获内容的实证证据。

Method: 通过在多个领域进行七个焦点小组会议，收集和分析实践者系统性地捕获的ML系统及其环境信息。

Result: 研究人员编目了实践者捕获的信息类型，并绘制了他们如何使用这些信息来验证模型、检测和诊断故障以及解释观察到的性能下降。

Conclusion: 研究识别了当前实践中的空白，并为建立ML可观测性实践的工具设计和研究提出了建议方向。

Abstract: Production machine learning (ML) systems fail silently -- not with crashes,
but through wrong decisions. While observability is recognized as critical for
ML operations, there is a lack empirical evidence of what practitioners
actually capture. This study presents empirical results on ML observability in
practice through seven focus group sessions in several domains. We catalog the
information practitioners systematically capture across ML systems and their
environment and map how they use it to validate models, detect and diagnose
faults, and explain observed degradations. Finally, we identify gaps in current
practice and outline implications for tooling design and research to establish
ML observability practices.

</details>


### [10] [Investigating Software Aging in LLM-Generated Software Systems](https://arxiv.org/abs/2510.24188)
*César Santos,Ermeson Andrade,Roberto Natella*

Main category: cs.SE

TL;DR: 该论文通过实验研究了LLM生成软件中的软件老化现象，发现这些应用在持续运行50小时后会出现显著的内存增长、响应时间增加和性能不稳定等问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM自动生成软件的广泛应用，了解其在持续执行下的长期可靠性变得至关重要，但目前对这类系统在长期运行中的老化现象知之甚少。

Method: 使用Bolt平台和Baxbench标准化提示生成四个面向服务的应用，进行50小时负载测试，持续监控资源使用、响应时间和吞吐量以检测退化模式。

Result: 结果显示所有应用都存在显著的软件老化证据，包括渐进式内存增长、响应时间增加和性能不稳定，统计分析确认了这些趋势并显示不同应用类型的老化严重程度存在差异。

Conclusion: 研究发现需要在自动生成软件中考虑老化问题，为未来研究缓解策略和长期可靠性评估提供了基础。

Abstract: Automatically generated software, especially code produced by Large Language
Models (LLMs), is increasingly adopted to accelerate development and reduce
manual effort. However, little is known about the long-term reliability of such
systems under sustained execution. In this paper, we experimentally investigate
the phenomenon of software aging in applications generated by LLM-based tools.
Using the Bolt platform and standardized prompts from Baxbench, we generated
four service-oriented applications and subjected them to 50-hour load tests.
Resource usage, response time, and throughput were continuously monitored to
detect degradation patterns. The results reveal significant evidence of
software aging, including progressive memory growth, increased response time,
and performance instability across all applications. Statistical analyzes
confirm these trends and highlight variability in the severity of aging
according to the type of application. Our findings show the need to consider
aging in automatically generated software and provide a foundation for future
studies on mitigation strategies and long-term reliability evaluation.

</details>


### [11] [MAGNET: A Multi-Graph Attentional Network for Code Clone Detection](https://arxiv.org/abs/2510.24241)
*Zixian Zhang,Takfarinas Saber*

Main category: cs.SE

TL;DR: MAGNET是一个多图注意力框架，通过联合利用AST、CFG和DFG表示来检测代码克隆，在BigCloneBench和Google Code Jam数据集上分别达到96.5%和99.2%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有代码克隆检测方法通常依赖单一表示（如AST、CFG、DFG），只能捕捉代码语义的部分方面。混合方法虽然出现，但其融合策略通常是手工设计且效果不佳。

Method: MAGNET集成残差图神经网络与节点级自注意力来学习局部和长程依赖，引入门控交叉注意力机制进行细粒度图间交互，并使用Set2Set池化将多图嵌入融合为统一的程序级表示。

Result: 在BigCloneBench和Google Code Jam数据集上的广泛实验表明，MAGNET实现了最先进的性能，整体F1分数分别为96.5%和99.2%。消融研究证实了多图融合和每个注意力组件的重要贡献。

Conclusion: MAGNET通过多图注意力框架有效捕捉代码的语法和语义特征，在代码克隆检测任务上取得了优异的性能。

Abstract: Code clone detection is a fundamental task in software engineering that
underpins refactoring, debugging, plagiarism detection, and vulnerability
analysis. Existing methods often rely on singular representations such as
abstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs
(DFGs), which capture only partial aspects of code semantics. Hybrid approaches
have emerged, but their fusion strategies are typically handcrafted and
ineffective. In this study, we propose MAGNET, a multi-graph attentional
framework that jointly leverages AST, CFG, and DFG representations to capture
syntactic and semantic features of source code. MAGNET integrates residual
graph neural networks with node-level self-attention to learn both local and
long-range dependencies, introduces a gated cross-attention mechanism for
fine-grained inter-graph interactions, and employs Set2Set pooling to fuse
multi-graph embeddings into unified program-level representations. Extensive
experiments on BigCloneBench and Google Code Jam demonstrate that MAGNET
achieves state-of-the-art performance with an overall F1 score of 96.5\% and
99.2\% on the two datasets, respectively. Ablation studies confirm the critical
contributions of multi-graph fusion and each attentional component. Our code is
available at https://github.com/ZixianReid/Multigraph_match

</details>


### [12] [Developer Productivity with GenAI](https://arxiv.org/abs/2510.24265)
*Sadia Afroz,Zixuan Feng,Katie Kimura,Bianca Trinkenreich,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 调查生成式AI工具对开发者生产力的影响，基于415名软件从业者的调查，发现整体生产力改善有限，存在生产力悖论


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具在软件开发中日益普及，但关于这些工具何时何地真正提升生产力的证据尚不明确

Method: 使用SPACE框架（满意度与幸福感、绩效、活动、沟通与协作、效率与流程）调查415名软件从业者，按AI使用频率进行分层分析

Result: 整体生产力变化有限，揭示了生产力悖论：开发者速度变快但未必创造更好的软件或感到更满足

Conclusion: 生成式AI工具在软件开发中的生产力提升效果有限，存在生产力悖论现象

Abstract: Generative AI (GenAI) tools are increasingly being adopted in software
development as productivity aids. However, evidence regarding where and when
these tools actually enhance productivity is unclear. In this paper, we
investigate how GenAI adoption affects different dimensions of developer
productivity. We surveyed 415 software practitioners to capture their
perceptions of productivity changes associated with AI-assisted development
using the SPACE framework - Satisfaction and well-being, Performance, Activity,
Communication and collaboration, and Efficiency and flow. Our results,
disaggregated by frequency of AI usage, reveal limited overall productivity
change, highlighting the productivity paradox in which developers become faster
but do not necessarily create better software or feel more fulfilled.

</details>


### [13] [Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation](https://arxiv.org/abs/2510.24358)
*Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu*

Main category: cs.SE

TL;DR: 提出了PRDBench基准测试，通过智能体驱动的管道构建包含50个真实Python项目的基准，解决现有代码智能体评估的高标注成本和刚性指标问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码智能体评估基准存在两大限制：高标注成本和专业知识要求，以及主要依赖单元测试的刚性评估指标。

Method: 采用智能体驱动的基准构建管道，结合人工监督生成多样化的项目级任务；引入Agent-as-a-Judge范式来评分智能体输出。

Result: 构建了PRDBench基准，包含50个真实Python项目，涵盖20个领域，每个项目都有结构化PRD需求、全面评估标准和参考实现。

Conclusion: PRDBench在评估代码智能体和评估智能体能力方面表现出有效性，为标注和评估提供了可扩展且稳健的框架。

Abstract: Recent advances in code agents have enabled automated software development at
the project level, supported by large language models (LLMs) and widely adopted
tools. However, existing benchmarks for code agent evaluation face two major
limitations: high annotation cost and expertise requirements, and rigid
evaluation metrics that rely primarily on unit tests. To address these
challenges, we propose an agent-driven benchmark construction pipeline that
leverages human supervision to efficiently generate diverse and challenging
project-level tasks. Based on this approach, we introduce PRDBench, a novel
benchmark comprising 50 real-world Python projects across 20 domains, each with
structured Product Requirement Document (PRD) requirements, comprehensive
evaluation criteria, and reference implementations. PRDBench features rich data
sources, high task complexity, and flexible metrics. We further employ an
Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of
various test types beyond unit tests. Extensive experiments on PRDBench
demonstrate its effectiveness in assessing the capabilities of both code agents
and evaluation agents, providing a scalable and robust framework for annotation
and evaluation.

</details>


### [14] [LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead](https://arxiv.org/abs/2510.24367)
*Junda He,Jieke Shi,Terry Yue Zhuo,Christoph Treude,Jiamou Sun,Zhenchang Xing,Xiaoning Du,David Lo*

Main category: cs.SE

TL;DR: 本文提出了LLM-as-a-Judge框架，旨在解决LLM生成软件工件的自动化评估瓶颈，通过文献综述、局限性分析和研究路线图，推动该范式在软件工程中的发展。


<details>
  <summary>Details</summary>
Motivation: LLM在软件工程中的广泛应用产生了大量软件工件，但缺乏可扩展、可靠的评估方法。人工评估成本高，传统自动指标无法捕捉质量细节，需要开发更智能的评估方案。

Method: 采用文献综述方法，分析现有SE研究中LLM-as-a-Judge的应用，识别研究空白，并提出详细的发展路线图。

Result: 发现LLM-as-a-Judge在SE领域仍处于早期阶段，现有研究存在局限性，需要进一步发展和完善评估框架。

Conclusion: 到2030年，LLM-as-a-Judge框架应成为可靠、鲁棒、可扩展的人类评估替代方案，能够进行一致、多方面的软件工件评估，从而提升评估的可扩展性。

Abstract: The rapid integration of Large Language Models (LLMs) into software
engineering (SE) has revolutionized tasks like code generation, producing a
massive volume of software artifacts. This surge has exposed a critical
bottleneck: the lack of scalable, reliable methods to evaluate these outputs.
Human evaluation is costly and time-consuming, while traditional automated
metrics like BLEU fail to capture nuanced quality aspects. In response, the
LLM-as-a-Judge paradigm - using LLMs for automated evaluation - has emerged.
This approach leverages the advanced reasoning of LLMs, offering a path toward
human-like nuance at automated scale. However, LLM-as-a-Judge research in SE is
still in its early stages. This forward-looking SE 2030 paper aims to steer the
community toward advancing LLM-as-a-Judge for evaluating LLM-generated software
artifacts. We provide a literature review of existing SE studies, analyze their
limitations, identify key research gaps, and outline a detailed roadmap. We
envision these frameworks as reliable, robust, and scalable human surrogates
capable of consistent, multi-faceted artifact evaluation by 2030. Our work aims
to foster research and adoption of LLM-as-a-Judge frameworks, ultimately
improving the scalability of software artifact evaluation.

</details>


### [15] [CodeWiki: Automated Repository-Level Documentation at Scale](https://arxiv.org/abs/2510.24428)
*Nguyen Hoang Anh,Minh Le-Anh,Bach Le,Nghi D. Q. Bui*

Main category: cs.SE

TL;DR: CodeWiki是首个开源的全仓库级文档生成框架，通过分层分解、递归代理处理和综合文本视觉工件的创新方法，在7种编程语言上实现了高质量的仓库级文档生成。


<details>
  <summary>Details</summary>
Motivation: 开发者58%的时间用于理解代码库，但现有LLM只能在函数级别生成文档，无法处理仓库级别的架构模式和跨模块交互，导致文档维护困难。

Method: 采用三个创新方法：(i) 保持架构上下文的分层分解，(ii) 动态委派的递归代理处理，(iii) 综合文本和视觉工件（架构图和数据流图）。

Result: 在CodeWikiBench基准测试中，CodeWiki使用专有模型获得68.79%质量分数，开源模型获得64.80%质量分数，优于现有闭源系统。

Conclusion: CodeWiki证明了在真实世界仓库中实现可扩展、准确文档生成的可行性，填补了仓库级文档自动生成的空白。

Abstract: Developers spend nearly 58% of their time understanding codebases, yet
maintaining comprehensive documentation remains challenging due to complexity
and manual effort. While recent Large Language Models (LLMs) show promise for
function-level documentation, they fail at the repository level, where
capturing architectural patterns and cross-module interactions is essential. We
introduce CodeWiki, the first open-source framework for holistic
repository-level documentation across seven programming languages. CodeWiki
employs three innovations: (i) hierarchical decomposition that preserves
architectural context, (ii) recursive agentic processing with dynamic
delegation, and (iii) synthesis of textual and visual artifacts including
architecture diagrams and data flows. We also present CodeWikiBench, the first
repository-level documentation benchmark with multi-level rubrics and agentic
assessment. CodeWiki achieves 68.79% quality score with proprietary models and
64.80% with open-source alternatives, outperforming existing closed-source
systems and demonstrating scalable, accurate documentation for real-world
repositories.

</details>


### [16] [The Divine Software Engineering Comedy -- Inferno: The Okinawa Files](https://arxiv.org/abs/2510.24483)
*Michele Lanza*

Main category: cs.SE

TL;DR: 本文是对2024年6月在日本冲绳举行的软件工程未来研讨会的反思，作者以略带黑暗和讽刺的视角分析了软件工程领域面临的三个噩梦：不懂技术的软件开发者、快速发展的领域遗忘自身教训、以及技术爆炸式增长。


<details>
  <summary>Details</summary>
Motivation: 作者希望通过分享在FUSE研讨会上的观察和讨论，揭示软件工程领域面临的严峻挑战和潜在危机，引发对该领域未来发展的深度思考。

Method: 基于研讨会上的讨论内容，结合个人观察和反思，采用讽刺和批判性的写作风格，提炼出三个核心问题。

Result: 识别出软件工程领域面临的三个主要噩梦：1) 不懂技术的开发者却能完成任务；2) 领域发展过快导致遗忘历史教训；3) 技术呈指数级增长带来的管理挑战。

Conclusion: 作者认为软件工程的未来如同慢动作的车祸，虽然能看到问题来临却无法避免，表达了对该领域发展方向的悲观看法。

Abstract: In June 2024 I co-organized the FUture of Software Engineering symposium in
Okinawa, Japan. Me, Andrian Marcus, Takashi Kobayashi and Shinpei Hayashi were
general chairs, Nicole Novielli, Kevin Moran, Yutaro Kashiwa and Masanari Kondo
were program chairs, some members of my group, Carmen Armenti, Stefano
Campanella, Roberto Minelli, were the tables, can't have a room with only
chairs, after all. We invited a crowd of people to discuss what future software
engineering has. FUSE became a 3-day marathon on whether there is actually a
future at all for SE. This essay is a slightly dark take about what I saw at
that event, very loosely based on the discussions that took place, adding some
healthy sarcasm and cynicism, the intellectual salt and pepper I never seem to
run out of. I listened to the brilliant people who gathered to talk about where
we're headed, and distilled three nightmares headed in our direction: software
makers who don't know what they're doing, but get the job done anyway, a field
moving so fast it can't remember its own lessons, and technologies multiplying
like rabbits in Spring. So, let's start. The future, eh? The future of software
engineering looks like a car crash in slow motion: you can see it coming but
you can't look away. The thing is...

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Formalizing Schwartz functions and tempered distributions](https://arxiv.org/abs/2510.24060)
*Moritz Doll*

Main category: cs.LO

TL;DR: 在Lean证明助手中形式化缓分布理论的进展，这是任何证明助手中的首次形式化。应用包括证明傅里叶变换在L^2空间上扩展为线性等距，以及通过傅里叶变换定义Sobolev空间。


<details>
  <summary>Details</summary>
Motivation: 分布理论是偏微分方程理论的基石，但在证明助手中尚未被形式化。本文旨在填补这一空白，为数学定理的机器验证提供基础。

Method: 在Lean证明助手中形式化缓分布理论，采用与经典表述不同的关键方面。通过傅里叶变换扩展和Sobolev空间定义展示应用。

Result: 成功在Lean中实现了缓分布理论的首次形式化，证明了傅里叶变换在L^2空间上的线性等距性质，并定义了基于傅里叶变换的Sobolev空间。

Conclusion: 这项工作为分布理论的机器验证奠定了基础，展示了证明助手在高级数学理论形式化方面的能力，为后续相关研究提供了工具和框架。

Abstract: Distribution theory is a cornerstone of the theory of partial differential
equations. We report on the progress of formalizing the theory of tempered
distributions in the interactive proof assistant Lean, which is the first
formalization in any proof assistant. We give an overview of the mathematical
theory and highlight key aspects of the formalization that differ from the
classical presentation. As an application, we prove that the Fourier transform
extends to a linear isometry on $L^2$ and we define Sobolev spaces via the
Fourier transform on tempered distributions.

</details>


### [18] [Dynamic Hypersequents for Public Announcement Logic](https://arxiv.org/abs/2510.24165)
*Clara Lerouvillois,Francesca Poggiolesi*

Main category: cs.LO

TL;DR: 本文提出了一个基于超序列演算的动态超序列演算，用于公知逻辑（PAL），解决了现有证明理论无法在纯句法层面表示知识动态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 动态认知逻辑虽然能够建模知识的信息更新，但其证明理论在纯句法层面无法表示这种动态性。本文旨在弥补这一缺陷。

Method: 基于S5的超序列演算，扩展了建模公知引发的认知模型转换机制，构建了动态超序列演算。

Result: 构建的PAL演算具有良好的性质：所有结构规则（包括收缩）的可接纳性、逻辑规则的可逆性，以及句法切割消除。

Conclusion: 动态超序列演算成功地在纯句法层面表示了PAL的动态语义，为动态认知逻辑提供了更完整的证明理论框架。

Abstract: Dynamic Epistemic Logic extends classical epistemic logic by modeling not
only static knowledge but also its evolution through information updates. Among
its various systems, Public Announcement Logic (PAL) provides one of the
simplest and most studied frameworks for representing epistemic change. While
the semantics of PAL is well understood as transformation of Kripke models, the
proof theory so far developed fails to represent this dynamism in purely
syntactical terms. The aim of this paper is to repair this lack. In particular,
building on a hypersequent calculus for S5, we extend it with a mechanism that
models the transition between epistemic models induced by public announcements.
We call these structures dynamic hypersequents. Using dynamic hypersequents, we
construct a calculus for PAL and we show that it enjoys several desirable
properties: admissibility of all structural rules (including contraction),
invertibility of logical rules, as well as syntactic cut-elimination.

</details>


### [19] [Fault-Tolerant Multiparty Session Types with Global Escape Loops](https://arxiv.org/abs/2510.24203)
*Lukas Bartl,Julian Linne,Kirstin Peters*

Main category: cs.LO

TL;DR: 本文扩展了容错多会话类型(FTMPST)，引入了具有全局逃逸机制的容错循环构造，无需全局协调即可实现分布式算法的终止验证。


<details>
  <summary>Details</summary>
Motivation: 分布式算法通常类似于多方通信协议，但证明其性质（特别是与进展密切相关的终止性）可能很复杂。由于分布式算法通常设计用于应对故障，使用会话类型验证分布式算法的第一步是集成容错性。

Method: 扩展FTMPST，引入新颖的容错循环构造，每个进程运行自己的本地循环版本。当进程找到问题解决方案时，不仅终止自身循环，还通过退出消息通知其他参与者。这些消息是非阻塞的，进程可以继续运行直到收到可能延迟的退出消息。

Result: 提出的方法能够验证分布式算法的终止性，特别是通过分析Chandra和Toueg的著名旋转协调器算法的变体来展示方法的有效性。

Conclusion: 该扩展为使用会话类型验证容错分布式算法提供了重要基础，通过非阻塞的退出消息机制实现了高效的全局终止协调。

Abstract: Multiparty session types are designed to abstractly capture the structure of
communication protocols and verify behavioural properties. One important such
property is progress, i.e., the absence of deadlock. Distributed algorithms
often resemble multiparty communication protocols. But proving their
properties, in particular termination that is closely related to progress, can
be elaborate. Since distributed algorithms are often designed to cope with
faults, a first step towards using session types to verify distributed
algorithms is to integrate fault-tolerance.
  We extend FTMPST (a version of fault-tolerant multiparty session types with
failure patterns to represent system requirements for system failures such as
unreliable communication and process crashes) by a novel, fault-tolerant loop
construct with global escapes that does not require global coordination. Each
process runs its own local version of the loop. If a process finds a solution
to the considered problem, it does not only terminate its own loop but also
informs the other participants via exit-messages. Upon receiving an
exit-message, a process immediately terminates its algorithm. To increase
efficiency and model standard fault-tolerant algorithms, these messages are
non-blocking, i.e., a process may continue until a possibly delayed
exit-message is received. To illustrate our approach, we analyse a variant of
the well-known rotating coordinator algorithm by Chandra and Toueg.

</details>


### [20] [An Adequacy Theorem Between Mixed Powerdomains and Probabilistic Concurrency](https://arxiv.org/abs/2510.24204)
*Renato Neves*

Main category: cs.LO

TL;DR: 提出了并发概率GCL的充分性定理，基于混合幂域语义，通过拓扑方法处理可观测属性，并应用了概率编程中的拓扑版König引理。


<details>
  <summary>Details</summary>
Motivation: 研究并发概率程序的充分性，探索可观测属性的拓扑处理方法，验证Escardo关于概率测试半可判定性的猜想。

Method: 使用混合幂域作为指称语义基础，通过拓扑空间中的开集表示可观测属性，并证明概率编程中的拓扑版König引理。

Result: 建立了并发概率程序的充分性定理，证明了程序满足特定形式可观测属性的半可判定性。

Conclusion: 该定理支持了Escardo关于概率测试半可判定性的猜想，为并发概率程序的验证提供了理论基础。

Abstract: We present an adequacy theorem for a concurrent extension of probabilistic
GCL. The underlying denotational semantics is based on the so-called mixed
powerdomains, which combine non-determinism with probabilistic behaviour. The
theorem itself is formulated via M. Smyth's idea of treating observable
properties as open sets of a topological space. The proof hinges on a
'topological generalisation' of K\"onig's lemma in the setting of probabilistic
programming (a result that is proved in the paper as well). One application of
the theorem is that it entails semi-decidability w.r.t. whether a concurrent
program satisfies an observable property (written in a certain form). This is
related to M. Escardo's conjecture about semi-decidability w.r.t. may and must
probabilistic testing.

</details>


### [21] [Unique Solutions of Guarded Recursive Equations](https://arxiv.org/abs/2510.24206)
*Rob van Glabbeek*

Main category: cs.LO

TL;DR: 该论文证明了在就绪模拟格式的结构化操作语义下，受保护的递归方程系统在强互模拟等价性方面具有唯一解，并推导出相应的公理化系统。


<details>
  <summary>Details</summary>
Motivation: 研究递归方程在进程代数中的解的唯一性问题，为进程代数中递归构造的语义基础提供理论支持。

Method: 基于结构化操作语义的就绪模拟格式，分析受保护的递归方程系统的解的性质。

Result: 证明了受保护的递归方程系统在强互模拟、模拟等价、就绪模拟等价及其预序下具有唯一解，并推导出相应的公理系统。

Conclusion: 这些等价关系和预序关系对于受保护的递归是完整的（预）同余关系，且唯一解结果为有限GSOS语言提供了健全且基础完备的强互模拟公理化。

Abstract: This paper shows that guarded systems of recursive equations have unique
solutions up to strong bisimilarity for any process algebra with a structural
operation semantics in the ready simulation format. A similar result holds for
simulation equivalence, for ready simulation equivalence and for the (ready)
simulation preorder. As a consequence, these equivalences and preorders are
full (pre)congruences for guarded recursion. Moreover, the unique-solutions
result yields a sound and ground-complete axiomatisation of strong bisimilarity
for any finitary GSOS language.

</details>


### [22] [Traces via Strategies in Two-Player Games](https://arxiv.org/abs/2510.24252)
*Benjamin Plummer,Corina Cirstea*

Main category: cs.LO

TL;DR: 该论文将有限余代数迹语义框架应用于控制器与环境博弈，涵盖非确定性和概率性环境，证明迹映射中的每个元素对应控制器可以强制执行的游戏玩法集合或分布。


<details>
  <summary>Details</summary>
Motivation: 研究控制器与环境博弈中的迹语义，旨在建立粗粒度的语义等价概念，并恢复熟悉的博弈论概念。

Method: 实例化Hasuo等人的有限余代数迹语义框架，使用由弱分配律参数化的单子来处理控制器与环境博弈。

Result: 证明在控制器与环境博弈中，迹映射的每个元素对应控制器可以强制执行的玩法集合（子集或分布），且每个元素可视为遵循控制器策略的结果。

Conclusion: 通过弱分配律参数化的方法，成功将有限余代数迹语义框架应用于博弈场景，建立了迹语义与控制器强制玩法之间的对应关系。

Abstract: Traces form a coarse notion of semantic equivalence between states of a
process, and have been studied coalgebraically for various types of system. We
instantiate the finitary coalgebraic trace semantics framework of Hasuo et al.
for controller-versus-environment games, encompassing both nondeterministic and
probabilistic environments. Although our choice of monads is guided by the
constraints of this abstract framework, they enable us to recover familiar
game-theoretic concepts. Concretely, we show that in these games, each element
in the trace map corresponds to a collection (a subset or distribution) of
plays the controller can force. Furthermore, each element can be seen as the
outcome of following a controller strategy. Our results are parametrised by a
weak distributive law, which computes what the controller can force in a single
step.

</details>


### [23] [Graded Monads in the Semantics of Nominal Automata](https://arxiv.org/abs/2510.24353)
*Hannes Schulze,Lutz Schröder,Üsame Cengiz*

Main category: cs.LO

TL;DR: 本文扩展了分级代数理论到名义设置，提出了分级名义代数框架，为RNNA的局部新鲜性语义提供了代数理论。


<details>
  <summary>Details</summary>
Motivation: 名义自动机模型作为数据语言的形式化工具，与经典寄存器模型密切相关。名义自动机中的名称分配范式有助于缓解寄存器模型普遍存在的计算困难，在表达能力和计算可处理性之间进行权衡。

Method: 将分级代数理论扩展到名义设置，建立分级名义代数框架，为RNNA的局部新鲜性语义提供代数理论。

Result: 开发了一个代数理论来捕捉RNNA的局部新鲜性语义。

Conclusion: 分级名义代数框架为名义自动机的行为等价性提供了统一的代数处理方法，扩展了分级单子的语义框架。

Abstract: Nominal automata models serve as a formalism for data languages, and in fact
often relate closely to classical register models. The paradigm of name
allocation in nominal automata helps alleviate the pervasive computational
hardness of register models in a tradeoff between expressiveness and
computational tractability. For instance, regular nondeterministic nominal
automata (RNNAs) correspond, under their local freshness semantics, to a form
of lossy register automata, and unlike the full register automaton model allow
for inclusion checking in elementary complexity. The semantic framework of
graded monads provides a unified algebraic treatment of spectra of behavioural
equivalences in the setting of universal coalgebra. In the present work, we
extend the associated notion of graded algebraic theory to the nominal setting.
In the arising framework of graded nominal algebra, we give an algebraic theory
capturing the local freshness semantics of RNNAs.

</details>
