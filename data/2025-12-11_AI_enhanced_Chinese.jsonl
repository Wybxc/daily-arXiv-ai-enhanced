{"id": "2512.09006", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09006", "abs": "https://arxiv.org/abs/2512.09006", "authors": ["Dyna Soumhane Ouchebara", "St\u00e9phane Dupont"], "title": "Llama-based source code vulnerability detection: Prompt engineering vs Fine tuning", "comment": "20 pages, Accepted at ESORICS 2025", "summary": "The significant increase in software production, driven by the acceleration of development cycles over the past two decades, has led to a steady rise in software vulnerabilities, as shown by statistics published yearly by the CVE program. The automation of the source code vulnerability detection (CVD) process has thus become essential, and several methods have been proposed ranging from the well established program analysis techniques to the more recent AI-based methods. Our research investigates Large Language Models (LLMs), which are considered among the most performant AI models to date, for the CVD task. The objective is to study their performance and apply different state-of-the-art techniques to enhance their effectiveness for this task. We explore various fine-tuning and prompt engineering settings. We particularly suggest one novel approach for fine-tuning LLMs which we call Double Fine-tuning, and also test the understudied Test-Time fine-tuning approach. We leverage the recent open-source Llama-3.1 8B, with source code samples extracted from BigVul and PrimeVul datasets. Our conclusions highlight the importance of fine-tuning to resolve the task, the performance of Double tuning, as well as the potential of Llama models for CVD. Though prompting proved ineffective, Retrieval augmented generation (RAG) performed relatively well as an example selection technique. Overall, some of our research questions have been answered, and many are still on hold, which leaves us many future work perspectives. Code repository is available here: https://github.com/DynaSoumhaneOuchebara/Llama-based-vulnerability-detection.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4f7f\u7528Llama-3.1 8B\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u53d1\u73b0\u5fae\u8c03\u5bf9\u4efb\u52a1\u89e3\u51b3\u81f3\u5173\u91cd\u8981\uff0c\u53cc\u5fae\u8c03\u8868\u73b0\u826f\u597d\uff0c\u4f46\u63d0\u793a\u5de5\u7a0b\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5f00\u53d1\u5468\u671f\u52a0\u901f\uff0c\u8f6f\u4ef6\u6f0f\u6d1e\u6570\u91cf\u6301\u7eed\u589e\u52a0\uff0c\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f53\u524d\u6027\u80fd\u6700\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5e94\u7528\u6700\u5148\u8fdb\u6280\u672f\u63d0\u5347\u5176\u6548\u679c\u3002", "method": "\u4f7f\u7528Llama-3.1 8B\u5f00\u6e90\u6a21\u578b\uff0c\u4eceBigVul\u548cPrimeVul\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6e90\u4ee3\u7801\u6837\u672c\u3002\u63a2\u7d22\u4e86\u591a\u79cd\u5fae\u8c03\u8bbe\u7f6e\uff08\u5305\u62ec\u63d0\u51fa\u7684\u53cc\u5fae\u8c03\u65b9\u6cd5\uff09\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u8fd8\u6d4b\u8bd5\u4e86\u8f83\u5c11\u7814\u7a76\u7684\u6d4b\u8bd5\u65f6\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u53ca\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4f5c\u4e3a\u793a\u4f8b\u9009\u62e9\u6280\u672f\u3002", "result": "\u5fae\u8c03\u5bf9\u89e3\u51b3\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff1b\u63d0\u51fa\u7684\u53cc\u5fae\u8c03\u65b9\u6cd5\u8868\u73b0\u826f\u597d\uff1bLlama\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff1b\u63d0\u793a\u5de5\u7a0b\u6548\u679c\u4e0d\u4f73\uff1b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4f5c\u4e3a\u793a\u4f8b\u9009\u62e9\u6280\u672f\u8868\u73b0\u76f8\u5bf9\u8f83\u597d\u3002", "conclusion": "\u7814\u7a76\u90e8\u5206\u56de\u7b54\u4e86\u7814\u7a76\u95ee\u9898\uff0c\u4f46\u4ecd\u6709\u8bb8\u591a\u95ee\u9898\u5f85\u89e3\u51b3\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u591a\u4e2a\u65b9\u5411\u3002\u5f3a\u8c03\u4e86\u5fae\u8c03\u7684\u91cd\u8981\u6027\uff0c\u5c55\u793a\u4e86\u53cc\u5fae\u8c03\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53caLlama\u6a21\u578b\u5728\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.09108", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09108", "abs": "https://arxiv.org/abs/2512.09108", "authors": ["Paul Brookes", "Vardan Voskanyan", "Rafail Giavrimis", "Matthew Truscott", "Mina Ilieva", "Chrystalla Pavlou", "Alexandru Staicu", "Manal Adham", "Will Evers- Hood", "Jingzhi Gong", "Kejia Zhang", "Matvey Fedoseev", "Vishal Sharma", "Roman Bauer", "Zheng Wang", "Hema Nair", "Wei Jie", "Tianhua Xu", "Aurora Constantin", "Leslie Kanthan", "Michail Basios"], "title": "Evolving Excellence: Automated Optimization of LLM-based Agents", "comment": null, "summary": "Agentic AI systems built on large language models (LLMs) offer significant potential for automating complex workflows, from software development to customer support. However, LLM agents often underperform due to suboptimal configurations; poorly tuned prompts, tool descriptions, and parameters that typically require weeks of manual refinement. Existing optimization methods either are too complex for general use or treat components in isolation, missing critical interdependencies.\n  We present ARTEMIS, a no-code evolutionary optimization platform that jointly optimizes agent configurations through semantically-aware genetic operators. Given only a benchmark script and natural language goals, ARTEMIS automatically discovers configurable components, extracts performance signals from execution logs, and evolves configurations without requiring architectural modifications.\n  We evaluate ARTEMIS on four representative agent systems: the \\emph{ALE Agent} for competitive programming on AtCoder Heuristic Contest, achieving a \\textbf{$13.6\\%$ improvement} in acceptance rate; the \\emph{Mini-SWE Agent} for code optimization on SWE-Perf, with a statistically significant \\textbf{10.1\\% performance gain}; and the \\emph{CrewAI Agent} for cost and mathematical reasoning on Math Odyssey, achieving a statistically significant \\textbf{$36.9\\%$ reduction} in the number of tokens required for evaluation. We also evaluate the \\emph{MathTales-Teacher Agent} powered by a smaller open-source model (Qwen2.5-7B) on GSM8K primary-level mathematics problems, achieving a \\textbf{22\\% accuracy improvement} and demonstrating that ARTEMIS can optimize agents based on both commercial and local models.", "AI": {"tldr": "ARTEMIS\u662f\u4e00\u4e2a\u65e0\u9700\u4ee3\u7801\u7684\u8fdb\u5316\u4f18\u5316\u5e73\u53f0\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u9057\u4f20\u7b97\u5b50\u8054\u5408\u4f18\u5316AI\u4ee3\u7406\u914d\u7f6e\uff0c\u5728\u591a\u4e2a\u4ee3\u7406\u7cfb\u7edf\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u4ee3\u7406\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u901a\u5e38\u7531\u4e8e\u6b21\u4f18\u914d\u7f6e\uff08\u5982\u63d0\u793a\u8bcd\u3001\u5de5\u5177\u63cf\u8ff0\u3001\u53c2\u6570\u7b49\u9700\u8981\u6570\u5468\u624b\u52a8\u8c03\u4f18\uff09\u800c\u8868\u73b0\u4e0d\u4f73\u3002\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u8981\u4e48\u8fc7\u4e8e\u590d\u6742\uff0c\u8981\u4e48\u5b64\u7acb\u5904\u7406\u7ec4\u4ef6\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "ARTEMIS\u662f\u4e00\u4e2a\u65e0\u9700\u4ee3\u7801\u7684\u8fdb\u5316\u4f18\u5316\u5e73\u53f0\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u9057\u4f20\u7b97\u5b50\u8054\u5408\u4f18\u5316\u4ee3\u7406\u914d\u7f6e\u3002\u7ed9\u5b9a\u57fa\u51c6\u811a\u672c\u548c\u81ea\u7136\u8bed\u8a00\u76ee\u6807\uff0c\u5b83\u80fd\u81ea\u52a8\u53d1\u73b0\u53ef\u914d\u7f6e\u7ec4\u4ef6\uff0c\u4ece\u6267\u884c\u65e5\u5fd7\u4e2d\u63d0\u53d6\u6027\u80fd\u4fe1\u53f7\uff0c\u5e76\u5728\u65e0\u9700\u67b6\u6784\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u8fdb\u5316\u914d\u7f6e\u3002", "result": "\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u4ee3\u7406\u7cfb\u7edf\u4e0a\u8bc4\u4f30\uff1a1) ALE Agent\u5728AtCoder Heuristic Contest\u4e0a\u63a5\u53d7\u7387\u63d0\u534713.6%\uff1b2) Mini-SWE Agent\u5728SWE-Perf\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u534710.1%\uff1b3) CrewAI Agent\u5728Math Odyssey\u4e0a\u8bc4\u4f30\u6240\u9700token\u6570\u663e\u8457\u51cf\u5c1136.9%\uff1b4) \u57fa\u4e8e\u8f83\u5c0f\u5f00\u6e90\u6a21\u578b(Qwen2.5-7B)\u7684MathTales-Teacher Agent\u5728GSM8K\u4e0a\u51c6\u786e\u7387\u63d0\u534722%\uff0c\u8bc1\u660eARTEMIS\u80fd\u4f18\u5316\u5546\u4e1a\u548c\u672c\u5730\u6a21\u578b\u4ee3\u7406\u3002", "conclusion": "ARTEMIS\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4ee3\u7801\u7684\u8fdb\u5316\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u8054\u5408\u4f18\u5316AI\u4ee3\u7406\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5546\u4e1a\u548c\u5f00\u6e90\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u7684\u590d\u6742\u6027\u548c\u5b64\u7acb\u6027\u95ee\u9898\u3002"}}
{"id": "2512.09196", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09196", "abs": "https://arxiv.org/abs/2512.09196", "authors": ["Haonan Li", "Keyu Man", "Partha Kanuparthy", "Hanning Chen", "Wei Sun", "Sreen Tallam", "Chenguang Zhu", "Kevin Zhu", "Zhiyun Qian"], "title": "TritonForge: Profiling-Guided Framework for Automated Triton Kernel Optimization", "comment": null, "summary": "High-performance GPU kernel optimization remains a critical yet labor-intensive task in modern machine learning workloads. Although Triton, a domain-specific language for GPU programming, enables developers to write efficient kernels with concise code, achieving expert-level performance still requires deep understanding of GPU architectures and low-level performance trade-offs. We present TritonForge, a profiling-guided framework for automated Triton kernel optimization. TritonForge integrates kernel analysis, runtime profiling, and iterative code transformation to streamline the optimization process. By incorporating data-driven feedback from profiling results, the system identifies performance bottlenecks, proposes targeted code modifications, and evaluates their impact automatically. While our prototype leverages large language models (LLMs) to assist in code reasoning and transformation, the framework remains modular and model-agnostic. Across diverse kernel types and GPU architectures, TritonForge achieves up to 5x performance improvement over baseline implementations and on average 1.76x of the cases are successful, providing a foundation for future research in automated GPU performance optimization.", "AI": {"tldr": "TritonForge\u662f\u4e00\u4e2a\u57fa\u4e8e\u6027\u80fd\u5256\u6790\u7684\u81ea\u52a8\u5316Triton GPU\u5185\u6838\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5185\u6838\u5206\u6790\u3001\u8fd0\u884c\u65f6\u5256\u6790\u548c\u8fed\u4ee3\u4ee3\u7801\u8f6c\u6362\uff0c\u5b9e\u73b0GPU\u5185\u6838\u7684\u81ea\u52a8\u5316\u6027\u80fd\u4f18\u5316\uff0c\u6700\u9ad8\u53ef\u83b7\u5f975\u500d\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1Triton DSL\u7b80\u5316\u4e86GPU\u5185\u6838\u5f00\u53d1\uff0c\u4f46\u8981\u8fbe\u5230\u4e13\u5bb6\u7ea7\u6027\u80fd\u4ecd\u9700\u6df1\u539a\u7684GPU\u67b6\u6784\u77e5\u8bc6\u548c\u4f4e\u5c42\u6027\u80fd\u6743\u8861\u7406\u89e3\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u4ecd\u7136\u52b3\u52a8\u5bc6\u96c6\u4e14\u56f0\u96be\u3002", "method": "TritonForge\u91c7\u7528\u5256\u6790\u5f15\u5bfc\u7684\u6846\u67b6\uff0c\u96c6\u6210\u5185\u6838\u5206\u6790\u3001\u8fd0\u884c\u65f6\u5256\u6790\u548c\u8fed\u4ee3\u4ee3\u7801\u8f6c\u6362\u3002\u7cfb\u7edf\u5229\u7528LLM\u8f85\u52a9\u4ee3\u7801\u63a8\u7406\u548c\u8f6c\u6362\uff0c\u4f46\u4fdd\u6301\u6a21\u5757\u5316\u548c\u6a21\u578b\u65e0\u5173\u6027\u3002\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u5256\u6790\u53cd\u9988\u8bc6\u522b\u6027\u80fd\u74f6\u9888\uff0c\u63d0\u51fa\u9488\u5bf9\u6027\u4ee3\u7801\u4fee\u6539\u5e76\u81ea\u52a8\u8bc4\u4f30\u5176\u5f71\u54cd\u3002", "result": "\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5185\u6838\u548cGPU\u67b6\u6784\u4e0a\uff0cTritonForge\u76f8\u6bd4\u57fa\u7ebf\u5b9e\u73b0\u6700\u9ad8\u53ef\u83b7\u5f975\u500d\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u5747\u6210\u529f\u7387\u4e3a1.76\u500d\uff08\u537376%\u7684\u6027\u80fd\u63d0\u5347\uff09\u3002", "conclusion": "TritonForge\u4e3a\u81ea\u52a8\u5316GPU\u6027\u80fd\u4f18\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u5256\u6790\u5f15\u5bfc\u4f18\u5316\u6d41\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9ad8\u6027\u80fdGPU\u5185\u6838\u4f18\u5316\u7684\u95e8\u69db\u3002"}}
{"id": "2512.09216", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09216", "abs": "https://arxiv.org/abs/2512.09216", "authors": ["Guangzong Cai", "Zengyang Li", "Peng Liang", "Ran Mo", "Hui Liu", "Yutao Ma"], "title": "Bug Priority Change Prediction: An Exploratory Study on Apache Software", "comment": "Preprint accepted for publication in ACM Transactions on Software Engineering and Methodology (TOSEM), 2025", "summary": "Bug fixing is a critical activity in the software development process. In issue tracking systems such as JIRA, each bug report is assigned a priority level to indicate the urgency and importance level of the bug. The priority may change during the bug fixing process, indicating that the urgency and importance level of the bug will change with the bug fixing. However, manually evaluating priority changes for bugs is a tedious process that heavily relies on the subjective judgment of developers and project managers, leading to incorrect priority changes and thus hindering timely bug fixes. Given the lack of research on bug priority change prediction, we propose a novel two-phase bug report priority change prediction method based on bug fixing evolution features and class imbalance handling strategy. Specifically, we divided the bug lifecycle into two phases: bug reporting and bug fixing, and constructed bug priority change prediction models for each phase. To evaluate the performance of our method, we conducted experiments on a bug dataset constructed from 32 non-trivial Apache projects. The experimental results show that our proposed bug fixing evolution features and the adopted class imbalance handling strategy can effectively improve the performance of prediction models. The F1-score of the prediction model constructed for the bug reporting phase reached 0.798, while the F1-weighted and F1-macro of the prediction model constructed for the bug fixing phase were 0.712 and 0.613, respectively. Furthermore, we explored the cross-project applicability of our prediction models and their performance at different priority levels. The findings indicate large variations in model performance across different projects, although the overall scores remain decent. Meanwhile, the predictive performance across various priority levels remained relatively consistently high.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7f3a\u9677\u4fee\u590d\u6f14\u5316\u7279\u5f81\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406\u7b56\u7565\u7684\u4e24\u9636\u6bb5\u7f3a\u9677\u4f18\u5148\u7ea7\u53d8\u66f4\u9884\u6d4b\u65b9\u6cd5\uff0c\u572832\u4e2aApache\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u7f3a\u9677\u4f18\u5148\u7ea7\u5728\u4fee\u590d\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u53d1\u751f\u53d8\u5316\uff0c\u4f46\u624b\u52a8\u8bc4\u4f30\u4f9d\u8d56\u4e3b\u89c2\u5224\u65ad\u4e14\u7e41\u7410\uff0c\u5bb9\u6613\u5bfc\u81f4\u9519\u8bef\u53d8\u66f4\uff0c\u5f71\u54cd\u53ca\u65f6\u4fee\u590d\u3002\u76ee\u524d\u7f3a\u4e4f\u7f3a\u9677\u4f18\u5148\u7ea7\u53d8\u66f4\u9884\u6d4b\u7684\u7814\u7a76\u3002", "method": "\u5c06\u7f3a\u9677\u751f\u547d\u5468\u671f\u5206\u4e3a\u62a5\u544a\u9636\u6bb5\u548c\u4fee\u590d\u9636\u6bb5\uff0c\u4e3a\u6bcf\u4e2a\u9636\u6bb5\u6784\u5efa\u4f18\u5148\u7ea7\u53d8\u66f4\u9884\u6d4b\u6a21\u578b\u3002\u91c7\u7528\u7f3a\u9677\u4fee\u590d\u6f14\u5316\u7279\u5f81\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406\u7b56\u7565\u6765\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u62a5\u544a\u9636\u6bb5\u6a21\u578b\u7684F1-score\u8fbe\u52300.798\uff0c\u4fee\u590d\u9636\u6bb5\u6a21\u578b\u7684F1-weighted\u548cF1-macro\u5206\u522b\u4e3a0.712\u548c0.613\u3002\u4e0d\u540c\u9879\u76ee\u95f4\u6027\u80fd\u5dee\u5f02\u8f83\u5927\u4f46\u6574\u4f53\u8868\u73b0\u826f\u597d\uff0c\u5404\u4f18\u5148\u7ea7\u7ea7\u522b\u7684\u9884\u6d4b\u6027\u80fd\u76f8\u5bf9\u4e00\u81f4\u4e14\u8f83\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u7f3a\u9677\u4fee\u590d\u6f14\u5316\u7279\u5f81\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u4f18\u5148\u7ea7\u53d8\u66f4\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u65b9\u6cd5\u5728\u4e0d\u540c\u9879\u76ee\u4e2d\u5177\u6709\u9002\u7528\u6027\uff0c\u4e14\u80fd\u7a33\u5b9a\u9884\u6d4b\u5404\u4f18\u5148\u7ea7\u7ea7\u522b\u7684\u53d8\u66f4\u3002"}}
{"id": "2512.09412", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.09412", "abs": "https://arxiv.org/abs/2512.09412", "authors": ["Patrick Bahr"], "title": "Simple Modal Types for Functional Reactive Programming", "comment": null, "summary": "Functional reactive programming (FRP) is a declarative programming paradigm for implementing reactive programs at a high level of abstraction. It applies functional programming principles to construct and manipulate time-varying values, also known as signals. However, for this programming paradigm to work in practice, an FRP language must ensure that programs are causal, productive, and free from space leaks. Over the past fifteen years, several modal type systems to enforce these operational properties have been developed.\n  We present a new FRP language with a significantly simplified modal type system that imposes fewer restrictions than previous modal FRP languages while still guaranteeing the central operational properties of causality, productivity, and absence of space leaks. The key enabling idea is to alter the semantics of signals so that the type system can safely allow more programs to type-check, which also makes the language more expressive. With this new semantics, signals are modelled as mutable references whose mutability is tightly controlled by the 'later' type modality. This disciplined form of mutability also enables more efficient in-place updates of signals, all while preserving a functional programming style.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u51fd\u6570\u54cd\u5e94\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff0c\u91c7\u7528\u7b80\u5316\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\uff0c\u5728\u4fdd\u8bc1\u56e0\u679c\u6027\u3001\u751f\u4ea7\u6027\u548c\u65e0\u7a7a\u95f4\u6cc4\u6f0f\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u5bf9\u7a0b\u5e8f\u7684\u9650\u5236\uff0c\u63d0\u9ad8\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684FRP\u8bed\u8a00\u867d\u7136\u901a\u8fc7\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u4fdd\u8bc1\u4e86\u7a0b\u5e8f\u7684\u56e0\u679c\u6027\u3001\u751f\u4ea7\u6027\u548c\u65e0\u7a7a\u95f4\u6cc4\u6f0f\uff0c\u4f46\u5f80\u5f80\u5bf9\u7a0b\u5e8f\u65bd\u52a0\u8fc7\u591a\u9650\u5236\uff0c\u964d\u4f4e\u4e86\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u5173\u952e\u64cd\u4f5c\u5c5e\u6027\uff0c\u53c8\u80fd\u5141\u8bb8\u66f4\u591a\u7a0b\u5e8f\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6539\u53d8\u4fe1\u53f7\u7684\u8bed\u4e49\uff0c\u5c06\u4fe1\u53f7\u5efa\u6a21\u4e3a\u53d7\"later\"\u7c7b\u578b\u6a21\u6001\u4e25\u683c\u63a7\u5236\u7684\u53ef\u53d8\u5f15\u7528\u3002\u8fd9\u79cd\u53d7\u63a7\u7684\u53ef\u53d8\u6027\u4f7f\u5f97\u7c7b\u578b\u7cfb\u7edf\u80fd\u591f\u5b89\u5168\u5730\u5141\u8bb8\u66f4\u591a\u7a0b\u5e8f\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\uff0c\u540c\u65f6\u652f\u6301\u66f4\u9ad8\u6548\u7684\u539f\u4f4d\u66f4\u65b0\u3002", "result": "\u5f00\u53d1\u51fa\u65b0\u7684FRP\u8bed\u8a00\uff0c\u5176\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u6bd4\u4e4b\u524d\u7684\u7cfb\u7edf\u66f4\u7b80\u5316\uff0c\u9650\u5236\u66f4\u5c11\uff0c\u4f46\u4ecd\u80fd\u4fdd\u8bc1\u56e0\u679c\u6027\u3001\u751f\u4ea7\u6027\u548c\u65e0\u7a7a\u95f4\u6cc4\u6f0f\u3002\u65b0\u8bed\u4e49\u4f7f\u8bed\u8a00\u66f4\u5177\u8868\u8fbe\u529b\uff0c\u540c\u65f6\u652f\u6301\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\u4e0b\u7684\u9ad8\u6548\u66f4\u65b0\u3002", "conclusion": "\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u4fe1\u53f7\u7684\u8bed\u4e49\uff0c\u5b9e\u73b0\u4e86\u7b80\u5316\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\uff0c\u5728\u4fdd\u6301FRP\u5173\u952e\u64cd\u4f5c\u5c5e\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6548\u7387\uff0c\u4e3a\u51fd\u6570\u54cd\u5e94\u5f0f\u7f16\u7a0b\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09280", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.09280", "abs": "https://arxiv.org/abs/2512.09280", "authors": ["Arthur Ramos", "Anjolina Oliveira", "Ruy de Queiroz", "Tiago de Veras"], "title": "A Modular Lean 4 Framework for Confluence and Strong Normalization of Lambda Calculi with Products and Sums", "comment": "15 pages, 2 figures, 1 table. Complete Lean 4 formalization with 10,367 lines of code and 497 fully mechanized theorems", "summary": "We present Metatheory, a comprehensive library for programming language foundations in Lean 4. The library features a modular framework for proving confluence of abstract rewriting systems using three classical proof techniques: the diamond property, Newmans lemma, and the Hindley-Rosen lemma. These are instantiated across six case studies including untyped lambda calculus, combinatory logic, term rewriting, simply typed lambda calculus, and STLC with products and sums. All theorems are fully mechanized with zero axioms or sorry statements. We provide complete proofs of de Bruijn substitution infrastructure and demonstrate strong normalization via logical relations. To our knowledge, this is the first comprehensive confluence and normalization framework for Lean 4.", "AI": {"tldr": "Metatheory \u662f\u4e00\u4e2a\u7528\u4e8e Lean 4 \u7684\u7f16\u7a0b\u8bed\u8a00\u57fa\u7840\u5e93\uff0c\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u7684\u6846\u67b6\u6765\u8bc1\u660e\u62bd\u8c61\u91cd\u5199\u7cfb\u7edf\u7684\u5408\u6d41\u6027\uff0c\u5305\u542b\u4e09\u79cd\u7ecf\u5178\u8bc1\u660e\u6280\u672f\uff0c\u5e76\u5728\u516d\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u5b9e\u4f8b\u5316\u3002", "motivation": "\u4e3a Lean 4 \u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u5408\u6d41\u6027\u548c\u5f52\u4e00\u5316\u6846\u67b6\uff0c\u586b\u8865\u5f53\u524d\u5728\u5f62\u5f0f\u5316\u7f16\u7a0b\u8bed\u8a00\u57fa\u7840\u65b9\u9762\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u79cd\u7ecf\u5178\u8bc1\u660e\u6280\u672f\uff08\u83f1\u5f62\u6027\u8d28\u3001Newman \u5f15\u7406\u3001Hindley-Rosen \u5f15\u7406\uff09\uff0c\u5728\u516d\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u5b9e\u4f8b\u5316\uff0c\u5305\u62ec\u65e0\u7c7b\u578b lambda \u6f14\u7b97\u3001\u7ec4\u5408\u903b\u8f91\u3001\u9879\u91cd\u5199\u7cfb\u7edf\u7b49\u3002", "result": "\u5b9e\u73b0\u4e86\u5b8c\u5168\u673a\u68b0\u5316\u7684\u5b9a\u7406\u8bc1\u660e\uff08\u96f6\u516c\u7406\u6216 sorry \u8bed\u53e5\uff09\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684 de Bruijn \u66ff\u6362\u57fa\u7840\u8bbe\u65bd\u8bc1\u660e\uff0c\u5e76\u901a\u8fc7\u903b\u8f91\u5173\u7cfb\u5c55\u793a\u4e86\u5f3a\u5f52\u4e00\u5316\u3002", "conclusion": "\u8fd9\u662f Lean 4 \u4e2d\u7b2c\u4e00\u4e2a\u5168\u9762\u7684\u5408\u6d41\u6027\u548c\u5f52\u4e00\u5316\u6846\u67b6\uff0c\u4e3a\u7f16\u7a0b\u8bed\u8a00\u57fa\u7840\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.09543", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09543", "abs": "https://arxiv.org/abs/2512.09543", "authors": ["Arihant Tripathy", "Ch Pavan Harshit", "Karthik Vaidhyanathan"], "title": "SWEnergy: An Empirical Study on Energy Efficiency in Agentic Issue Resolution Frameworks with SLMs", "comment": "8 pages, 5 figures, 1 table. Accepted to AGENT 2026 (ICSE 2026 workshop)", "summary": "Context. LLM-based autonomous agents in software engineering rely on large, proprietary models, limiting local deployment. This has spurred interest in Small Language Models (SLMs), but their practical effectiveness and efficiency within complex agentic frameworks for automated issue resolution remain poorly understood.\n  Goal. We investigate the performance, energy efficiency, and resource consumption of four leading agentic issue resolution frameworks when deliberately constrained to using SLMs. We aim to assess the viability of these systems for this task in resource-limited settings and characterize the resulting trade-offs.\n  Method. We conduct a controlled evaluation of four leading agentic frameworks (SWE-Agent, OpenHands, Mini SWE Agent, AutoCodeRover) using two SLMs (Gemma-3 4B, Qwen-3 1.7B) on the SWE-bench Verified Mini benchmark. On fixed hardware, we measure energy, duration, token usage, and memory over 150 runs per configuration.\n  Results. We find that framework architecture is the primary driver of energy consumption. The most energy-intensive framework, AutoCodeRover (Gemma), consumed 9.4x more energy on average than the least energy-intensive, OpenHands (Gemma). However, this energy is largely wasted. Task resolution rates were near-zero, demonstrating that current frameworks, when paired with SLMs, consume significant energy on unproductive reasoning loops. The SLM's limited reasoning was the bottleneck for success, but the framework's design was the bottleneck for efficiency.\n  Conclusions. Current agentic frameworks, designed for powerful LLMs, fail to operate efficiently with SLMs. We find that framework architecture is the primary driver of energy consumption, but this energy is largely wasted due to the SLMs' limited reasoning. Viable low-energy solutions require shifting from passive orchestration to architectures that actively manage SLM weaknesses.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u57fa\u4e8e\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u6846\u67b6\u7684\u6027\u80fd\u548c\u80fd\u6548\uff0c\u53d1\u73b0\u5f53\u524d\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u7531\u4e8eSLM\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u5927\u90e8\u5206\u80fd\u8017\u88ab\u6d6a\u8d39\u5728\u65e0\u6210\u6548\u7684\u63a8\u7406\u5faa\u73af\u4e2d\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u4f9d\u8d56\u5927\u578b\u4e13\u6709\u6a21\u578b\uff0c\u96be\u4ee5\u672c\u5730\u90e8\u7f72\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8da3\u3002\u4f46SLM\u5728\u590d\u6742\u4ee3\u7406\u6846\u67b6\u4e2d\u7528\u4e8e\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u7684\u5b9e\u9645\u6548\u679c\u548c\u6548\u7387\u4ecd\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u8bc4\u4f30\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u53ef\u884c\u6027\u3002", "method": "\u5728\u56fa\u5b9a\u786c\u4ef6\u4e0a\u5bf9\u56db\u79cd\u9886\u5148\u7684\u4ee3\u7406\u6846\u67b6\uff08SWE-Agent\u3001OpenHands\u3001Mini SWE Agent\u3001AutoCodeRover\uff09\u4f7f\u7528\u4e24\u79cdSLM\uff08Gemma-3 4B\u3001Qwen-3 1.7B\uff09\u8fdb\u884c\u63a7\u5236\u6027\u8bc4\u4f30\u3002\u5728SWE-bench Verified Mini\u57fa\u51c6\u4e0a\u6d4b\u91cf150\u6b21\u8fd0\u884c\u7684\u80fd\u91cf\u6d88\u8017\u3001\u6301\u7eed\u65f6\u95f4\u3001\u4ee4\u724c\u4f7f\u7528\u548c\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff1a\u80fd\u8017\u6700\u9ad8\u7684AutoCodeRover\uff08Gemma\uff09\u6bd4\u6700\u4f4e\u7684OpenHands\uff08Gemma\uff09\u5e73\u5747\u591a\u6d88\u80179.4\u500d\u80fd\u91cf\u3002\u4f46\u4efb\u52a1\u89e3\u51b3\u7387\u63a5\u8fd1\u96f6\uff0c\u8868\u660e\u5f53\u524d\u6846\u67b6\u4e0eSLM\u914d\u5bf9\u65f6\uff0c\u5927\u91cf\u80fd\u91cf\u88ab\u6d6a\u8d39\u5728\u65e0\u6210\u6548\u7684\u63a8\u7406\u5faa\u73af\u4e2d\u3002SLM\u7684\u6709\u9650\u63a8\u7406\u80fd\u529b\u662f\u6210\u529f\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u800c\u6846\u67b6\u8bbe\u8ba1\u662f\u6548\u7387\u7684\u4e3b\u8981\u74f6\u9888\u3002", "conclusion": "\u5f53\u524d\u4e3a\u5f3a\u5927LLM\u8bbe\u8ba1\u7684\u4ee3\u7406\u6846\u67b6\u65e0\u6cd5\u4e0eSLM\u9ad8\u6548\u534f\u4f5c\u3002\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u7531\u4e8eSLM\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u8fd9\u4e9b\u80fd\u91cf\u5927\u90e8\u5206\u88ab\u6d6a\u8d39\u3002\u53ef\u884c\u7684\u4f4e\u80fd\u8017\u89e3\u51b3\u65b9\u6848\u9700\u8981\u4ece\u88ab\u52a8\u7f16\u6392\u8f6c\u5411\u80fd\u591f\u4e3b\u52a8\u7ba1\u7406SLM\u5f31\u70b9\u7684\u67b6\u6784\u8bbe\u8ba1\u3002"}}
{"id": "2512.09464", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.09464", "abs": "https://arxiv.org/abs/2512.09464", "authors": ["Antoine Van Muylder", "Andreas Nuyts", "Dominique Devriese"], "title": "Nominal Type Theory by Nullary Internal Parametricity", "comment": null, "summary": "There are many ways to represent the syntax of a language with binders. In particular, nominal frameworks are metalanguages that feature (among others) name abstraction types, which can be used to specify the type of binders. The resulting syntax representation (nominal data types) makes alpha-equivalent terms equal, and features a name-invariant induction principle. It is known that name abstraction types can be presented either as existential or universal quantification on names. On the one hand, nominal frameworks use the existential presentation for practical reasoning since the user is allowed to match on a name-term pattern where the name is bound in the term. However inference rules for existential name abstraction are cumbersome to specify/implement because they must keep track of information about free and bound names at the type level. On the other hand, universal name abstractions are easier to specify since they are treated not as pairs, but as functions consuming fresh names. Yet the ability to pattern match on such functions is seemingly lost. In this work we show that this ability and others are recovered in a type theory consisting of (1) nullary ($0$-ary) internally parametric type theory (nullary PTT) (2) a type of names and a novel name induction principle (3) nominal data types. This extension of nullary PTT can act as a legitimate nominal framework. Indeed it has universal name abstractions, nominal pattern matching, a freshness type former, name swapping and local-scope operations and (non primitive) existential name abstractions. We illustrate how term-relevant nullary parametricity is used to recover nominal pattern matching. Our main example involves synthetic Kripke parametricity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f6\u5143\u5185\u90e8\u53c2\u6570\u5316\u7c7b\u578b\u7406\u8bba\u7684\u65b0\u578b\u540d\u4e49\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u540d\u79f0\u7c7b\u578b\u548c\u540d\u79f0\u5f52\u7eb3\u539f\u7406\uff0c\u5b9e\u73b0\u4e86\u901a\u7528\u540d\u79f0\u62bd\u8c61\u3001\u540d\u4e49\u6a21\u5f0f\u5339\u914d\u7b49\u529f\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u540d\u4e49\u6846\u67b6\u4e2d\u5b58\u5728\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u540d\u4e49\u6846\u67b6\u4e2d\uff0c\u5b58\u5728\u540d\u79f0\u62bd\u8c61\u7c7b\u578b\u7684\u4e24\u79cd\u8868\u793a\u65b9\u5f0f\uff1a\u5b58\u5728\u91cf\u5316\u548c\u5168\u79f0\u91cf\u5316\u3002\u5b58\u5728\u91cf\u5316\u8868\u793a\u5141\u8bb8\u6a21\u5f0f\u5339\u914d\u4f46\u7c7b\u578b\u89c4\u5219\u590d\u6742\uff0c\u5168\u79f0\u91cf\u5316\u8868\u793a\u7c7b\u578b\u89c4\u5219\u7b80\u5355\u4f46\u5931\u53bb\u6a21\u5f0f\u5339\u914d\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u5168\u79f0\u91cf\u5316\u7684\u7b80\u6d01\u6027\uff0c\u53c8\u80fd\u6062\u590d\u6a21\u5f0f\u5339\u914d\u80fd\u529b\u7684\u540d\u4e49\u6846\u67b6\u3002", "method": "\u6269\u5c55\u96f6\u5143\u5185\u90e8\u53c2\u6570\u5316\u7c7b\u578b\u7406\u8bba\uff0c\u6dfb\u52a0\u540d\u79f0\u7c7b\u578b\u548c\u65b0\u7684\u540d\u79f0\u5f52\u7eb3\u539f\u7406\uff0c\u6784\u5efa\u540d\u4e49\u6570\u636e\u7c7b\u578b\u3002\u5229\u7528\u96f6\u5143\u53c2\u6570\u5316\u7279\u6027\u6062\u590d\u540d\u4e49\u6a21\u5f0f\u5339\u914d\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5408\u6210Kripke\u53c2\u6570\u5316\u4f5c\u4e3a\u4e3b\u8981\u793a\u4f8b\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u5408\u6cd5\u7684\u540d\u4e49\u6846\u67b6\uff0c\u5305\u542b\uff1a\u901a\u7528\u540d\u79f0\u62bd\u8c61\u3001\u540d\u4e49\u6a21\u5f0f\u5339\u914d\u3001\u65b0\u9c9c\u5ea6\u7c7b\u578b\u6784\u9020\u5b50\u3001\u540d\u79f0\u4ea4\u6362\u548c\u5c40\u90e8\u4f5c\u7528\u57df\u64cd\u4f5c\uff0c\u4ee5\u53ca\uff08\u975e\u539f\u59cb\u7684\uff09\u5b58\u5728\u540d\u79f0\u62bd\u8c61\u3002\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u96f6\u5143\u53c2\u6570\u5316\u6062\u590d\u540d\u4e49\u6a21\u5f0f\u5339\u914d\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55\u96f6\u5143\u5185\u90e8\u53c2\u6570\u5316\u7c7b\u578b\u7406\u8bba\uff0c\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u529f\u80fd\u5b8c\u6574\u7684\u540d\u4e49\u6846\u67b6\uff0c\u65e2\u4fdd\u6301\u4e86\u5168\u79f0\u540d\u79f0\u62bd\u8c61\u7684\u7b80\u6d01\u6027\uff0c\u53c8\u6062\u590d\u4e86\u6a21\u5f0f\u5339\u914d\u80fd\u529b\uff0c\u4e3a\u8bed\u8a00\u8bed\u6cd5\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2512.09562", "categories": ["cs.SE", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.09562", "abs": "https://arxiv.org/abs/2512.09562", "authors": ["Radoslaw Klimek", "Jakub Blazowski"], "title": "Explainable Verification of Hierarchical Workflows Mined from Event Logs with Shapley Values", "comment": "This manuscript has been submitted to Rank A/A* conference", "summary": "Workflow mining discovers hierarchical process trees from event logs, but it remains unclear why such models satisfy or violate logical properties, or how individual elements contribute to overall behavior. We propose to translate mined workflows into logical specifications and analyze properties such as satisfiability, liveness, and safety with automated theorem provers. On this basis, we adapt Shapley values from cooperative game theory to attribute outcomes to workflow elements and quantify their contributions. Experiments on benchmark datasets show that this combination identifies critical nodes, reveals redundancies, and exposes harmful structures. This outlines a novel direction for explainable workflow analysis with direct relevance to software engineering practice, supporting compliance checks, process optimization, redundancy reduction, and the design of next-generation process mining tools.", "AI": {"tldr": "\u5c06\u5de5\u4f5c\u6d41\u6316\u6398\u8f6c\u6362\u4e3a\u903b\u8f91\u89c4\u8303\uff0c\u4f7f\u7528\u5b9a\u7406\u8bc1\u660e\u5668\u5206\u6790\u5c5e\u6027\uff0c\u5e76\u5e94\u7528Shapley\u503c\u91cf\u5316\u5de5\u4f5c\u6d41\u5143\u7d20\u7684\u8d21\u732e\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u5de5\u4f5c\u6d41\u5206\u6790", "motivation": "\u5de5\u4f5c\u6d41\u6316\u6398\u80fd\u4ece\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u53d1\u73b0\u5206\u5c42\u8fc7\u7a0b\u6811\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u6a21\u578b\u6ee1\u8db3\u6216\u8fdd\u53cd\u903b\u8f91\u5c5e\u6027\uff0c\u4ee5\u53ca\u5404\u4e2a\u5143\u7d20\u5982\u4f55\u5f71\u54cd\u6574\u4f53\u884c\u4e3a", "method": "1) \u5c06\u6316\u6398\u7684\u5de5\u4f5c\u6d41\u8f6c\u6362\u4e3a\u903b\u8f91\u89c4\u8303\uff1b2) \u4f7f\u7528\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u5206\u6790\u53ef\u6ee1\u8db3\u6027\u3001\u6d3b\u6027\u548c\u5b89\u5168\u6027\u7b49\u5c5e\u6027\uff1b3) \u5e94\u7528\u5408\u4f5c\u535a\u5f08\u8bba\u4e2d\u7684Shapley\u503c\u6765\u5f52\u56e0\u5de5\u4f5c\u6d41\u5143\u7d20\u5e76\u91cf\u5316\u5176\u8d21\u732e", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u8bc6\u522b\u5173\u952e\u8282\u70b9\u3001\u63ed\u793a\u5197\u4f59\u7ed3\u6784\u3001\u66b4\u9732\u6709\u5bb3\u6a21\u5f0f\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u5de5\u4f5c\u6d41\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u63d0\u4f9b\u4e86\u76f4\u63a5\u652f\u6301\uff0c\u53ef\u7528\u4e8e\u5408\u89c4\u68c0\u67e5\u3001\u6d41\u7a0b\u4f18\u5316\u3001\u5197\u4f59\u51cf\u5c11\uff0c\u5e76\u4e3a\u4e0b\u4e00\u4ee3\u8fc7\u7a0b\u6316\u6398\u5de5\u5177\u7684\u8bbe\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2512.09508", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.09508", "abs": "https://arxiv.org/abs/2512.09508", "authors": ["Oskar Fiuk", "Emanuel Kieronski", "Vincent Michielini"], "title": "Two-Variable Logic for Hierarchically Partitioned and Ordered Data", "comment": "This is an extended version of the paper presented at KR 2025", "summary": "We study Two-Variable First-Order Logic, FO2, under semantic constraints that model hierarchically structured data. Our first logic extends FO2 with a linear order < and a chain of increasingly coarser equivalence relations E_1, E_2, ... . We show that its finite satisfiability problem is NExpTime-complete. We also demonstrate that a weaker variant of this logic without the linear order enjoys the exponential model property. Our second logic extends FO2 with a chain of nested total preorders. We prove that its finite satisfiability problem is also NExpTime-complete.However, we show that the complexity increases to ExpSpace-complete once access to the successor relations of the preorders is allowed. Our last result is the undecidability of FO2 with two independent chains of nested equivalence relations.", "AI": {"tldr": "FO2\u903b\u8f91\u5728\u4e0d\u540c\u5c42\u6b21\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff1a\u5e26\u7ebf\u6027\u5e8f\u548c\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684FO2\u662fNExpTime\u5b8c\u5168\u7684\uff1b\u65e0\u7ebf\u6027\u5e8f\u7248\u672c\u5177\u6709\u6307\u6570\u6a21\u578b\u6027\u8d28\uff1b\u5e26\u5d4c\u5957\u5168\u9884\u5e8f\u94fe\u7684FO2\u4e5f\u662fNExpTime\u5b8c\u5168\u7684\uff0c\u4f46\u52a0\u5165\u540e\u7ee7\u5173\u7cfb\u540e\u590d\u6742\u5ea6\u5347\u81f3ExpSpace\u5b8c\u5168\uff1b\u5e26\u4e24\u4e2a\u72ec\u7acb\u5d4c\u5957\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684FO2\u4e0d\u53ef\u5224\u5b9a\u3002", "motivation": "\u7814\u7a76\u5c42\u6b21\u5316\u7ed3\u6784\u5316\u6570\u636e\u5efa\u6a21\u4e0b\u7684\u4e24\u53d8\u91cf\u4e00\u9636\u903b\u8f91\uff08FO2\uff09\uff0c\u63a2\u7d22\u5728\u4e0d\u540c\u8bed\u4e49\u7ea6\u675f\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u4e3a\u6570\u636e\u5e93\u7406\u8bba\u3001\u5f62\u5f0f\u9a8c\u8bc1\u7b49\u9886\u57df\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "1. \u6269\u5c55FO2\u4e3a\u5e26\u7ebf\u6027\u5e8f\u548c\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684\u903b\u8f91\uff0c\u5206\u6790\u5176\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\n2. \u7814\u7a76\u65e0\u7ebf\u6027\u5e8f\u7684\u5f31\u5316\u7248\u672c\uff0c\u8bc1\u660e\u5176\u6307\u6570\u6a21\u578b\u6027\u8d28\n3. \u6269\u5c55FO2\u4e3a\u5e26\u5d4c\u5957\u5168\u9884\u5e8f\u94fe\u7684\u903b\u8f91\uff0c\u5206\u6790\u5176\u590d\u6742\u6027\n4. \u7814\u7a76\u52a0\u5165\u9884\u5e8f\u540e\u7ee7\u5173\u7cfb\u540e\u7684\u590d\u6742\u5ea6\u53d8\u5316\n5. \u7814\u7a76\u5e26\u4e24\u4e2a\u72ec\u7acb\u5d4c\u5957\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684FO2\u7684\u53ef\u5224\u5b9a\u6027", "result": "1. FO2+\u7ebf\u6027\u5e8f+\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u662fNExpTime\u5b8c\u5168\u7684\n2. \u65e0\u7ebf\u6027\u5e8f\u7248\u672c\u5177\u6709\u6307\u6570\u6a21\u578b\u6027\u8d28\n3. FO2+\u5d4c\u5957\u5168\u9884\u5e8f\u94fe\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u4e5f\u662fNExpTime\u5b8c\u5168\u7684\n4. \u52a0\u5165\u9884\u5e8f\u540e\u7ee7\u5173\u7cfb\u540e\u590d\u6742\u5ea6\u5347\u81f3ExpSpace\u5b8c\u5168\n5. FO2+\u4e24\u4e2a\u72ec\u7acb\u5d4c\u5957\u7b49\u4ef7\u5173\u7cfb\u94fe\u662f\u4e0d\u53ef\u5224\u5b9a\u7684", "conclusion": "\u5c42\u6b21\u7ed3\u6784\u7ea6\u675f\u5bf9FO2\u7684\u8ba1\u7b97\u590d\u6742\u6027\u6709\u663e\u8457\u5f71\u54cd\uff1a\u7ebf\u6027\u5e8f\u548c\u7b49\u4ef7\u5173\u7cfb\u94fe\u7684\u52a0\u5165\u4fdd\u6301NExpTime\u5b8c\u5168\u6027\uff0c\u4f46\u9884\u5e8f\u540e\u7ee7\u5173\u7cfb\u4f7f\u590d\u6742\u5ea6\u5347\u81f3ExpSpace\u5b8c\u5168\uff0c\u800c\u4e24\u4e2a\u72ec\u7acb\u5d4c\u5957\u7b49\u4ef7\u5173\u7cfb\u94fe\u5219\u5bfc\u81f4\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u63ed\u793a\u4e86\u5c42\u6b21\u5316\u6570\u636e\u5efa\u6a21\u4e2d\u4e0d\u540c\u7ea6\u675f\u7684\u590d\u6742\u6027\u8fb9\u754c\u3002"}}
{"id": "2512.09596", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09596", "abs": "https://arxiv.org/abs/2512.09596", "authors": ["Arkadiusz Ry\u015b", "Lucas Lima", "Joeri Exelmans", "Dennis Janssens", "Hans Vangheluwe"], "title": "Model management to support systems engineering workflows using ontology-based knowledge graphs", "comment": null, "summary": "System engineering has been shifting from document-centric to model-based approaches, where assets are becoming more and more digital. Although digitisation conveys several benefits, it also brings several concerns (e.g., storage and access) and opportunities. In the context of Cyber- Physical Systems (CPS), we have experts from various domains executing complex workflows and manipulating models in a plethora of different formalisms, each with their own methods, techniques and tools. Storing knowledge on these workflows can reduce considerable effort during system development not only to allow their repeatability and replicability but also to access and reason on data generated by their execution. In this work, we propose a framework to manage modelling artefacts generated from workflow executions. The basic workflow concepts, related formalisms and artefacts are formally defined in an ontology specified in OML (Ontology Modelling Language). This ontology enables the construction of a knowledge graph that contains system engineering data to which we can apply reasoning. We also developed several tools to support system engineering during the design of workflows, their enactment, and artefact storage, considering versioning, querying and reasoning on the stored data. These tools also hide the complexity of manipulating the knowledge graph directly. Finally, we have applied our proposed framework in a real-world system development scenario of a drivetrain smart sensor system. Results show that our proposal not only helped the system engineer with fundamental difficulties like storage and versioning but also reduced the time needed to access relevant information and new knowledge that can be inferred from the knowledge graph.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u7684\u6846\u67b6\u6765\u7ba1\u7406CPS\u5de5\u4f5c\u6d41\u6267\u884c\u4ea7\u751f\u7684\u5efa\u6a21\u5de5\u4ef6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u7cfb\u7edf\u5de5\u7a0b\u7684\u5b58\u50a8\u3001\u7248\u672c\u63a7\u5236\u3001\u67e5\u8be2\u548c\u63a8\u7406\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u5de5\u7a0b\u4ece\u6587\u6863\u4e2d\u5fc3\u8f6c\u5411\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u6570\u5b57\u8d44\u4ea7\u589e\u591a\u5e26\u6765\u5b58\u50a8\u548c\u8bbf\u95ee\u7b49\u95ee\u9898\u3002CPS\u6d89\u53ca\u591a\u9886\u57df\u4e13\u5bb6\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u5316\u65b9\u6cd5\u6267\u884c\u590d\u6742\u5de5\u4f5c\u6d41\uff0c\u5b58\u50a8\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u77e5\u8bc6\u53ef\u4ee5\u51cf\u5c11\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u652f\u6301\u53ef\u91cd\u590d\u6027\u548c\u6570\u636e\u63a8\u7406\u3002", "method": "\u4f7f\u7528OML\uff08\u672c\u4f53\u5efa\u6a21\u8bed\u8a00\uff09\u5f62\u5f0f\u5316\u5b9a\u4e49\u5de5\u4f5c\u6d41\u6982\u5ff5\u3001\u76f8\u5173\u5f62\u5f0f\u5316\u548c\u5de5\u4ef6\uff0c\u6784\u5efa\u5305\u542b\u7cfb\u7edf\u5de5\u7a0b\u6570\u636e\u7684\u77e5\u8bc6\u56fe\u8c31\u3002\u5f00\u53d1\u5de5\u5177\u652f\u6301\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u3001\u6267\u884c\u3001\u5de5\u4ef6\u5b58\u50a8\uff0c\u5305\u62ec\u7248\u672c\u63a7\u5236\u3001\u67e5\u8be2\u548c\u63a8\u7406\u529f\u80fd\uff0c\u9690\u85cf\u76f4\u63a5\u64cd\u4f5c\u77e5\u8bc6\u56fe\u8c31\u7684\u590d\u6742\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u4f20\u52a8\u7cfb\u7edf\u667a\u80fd\u4f20\u611f\u5668\u7cfb\u7edf\u5f00\u53d1\u573a\u666f\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6848\u4e0d\u4ec5\u5e2e\u52a9\u7cfb\u7edf\u5de5\u7a0b\u5e08\u89e3\u51b3\u4e86\u5b58\u50a8\u548c\u7248\u672c\u63a7\u5236\u7b49\u57fa\u672c\u56f0\u96be\uff0c\u8fd8\u51cf\u5c11\u4e86\u8bbf\u95ee\u76f8\u5173\u4fe1\u606f\u7684\u65f6\u95f4\uff0c\u5e76\u80fd\u4ece\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63a8\u7406\u51fa\u65b0\u77e5\u8bc6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u672c\u4f53\u7684\u6846\u67b6\u6709\u6548\u7ba1\u7406\u4e86CPS\u5de5\u4f5c\u6d41\u6267\u884c\u4ea7\u751f\u7684\u5efa\u6a21\u5de5\u4ef6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u7cfb\u7edf\u5de5\u7a0b\u7684\u6570\u636e\u7ba1\u7406\u3001\u67e5\u8be2\u548c\u63a8\u7406\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4ef7\u503c\u3002"}}
{"id": "2512.09758", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2512.09758", "abs": "https://arxiv.org/abs/2512.09758", "authors": ["Yuhao Zhou", "Stavros Tripakis"], "title": "Towards Language Model Guided TLA+ Proof Automation", "comment": null, "summary": "Formal theorem proving with TLA+ provides rigorous guarantees for system specifications, but constructing proofs requires substantial expertise and effort. While large language models have shown promise in automating proofs for tactic-based theorem provers like Lean, applying these approaches directly to TLA+ faces significant challenges due to the unique hierarchical proof structure of the TLA+ proof system. We present a prompt-based approach that leverages LLMs to guide hierarchical decomposition of complex proof obligations into simpler sub-claims, while relying on symbolic provers for verification. Our key insight is to constrain LLMs to generate normalized claim decompositions rather than complete proofs, significantly reducing syntax errors. We also introduce a benchmark suite of 119 theorems adapted from (1) established mathematical collections and (2) inductive proofs of distributed protocols. Our approach consistently outperforms baseline methods across the benchmark suite.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u7684LLM\u65b9\u6cd5\uff0c\u7528\u4e8eTLA+\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u5c42\u6b21\u5206\u89e3\uff0c\u901a\u8fc7\u751f\u6210\u89c4\u8303\u5316\u58f0\u660e\u5206\u89e3\u800c\u975e\u5b8c\u6574\u8bc1\u660e\u6765\u51cf\u5c11\u8bed\u6cd5\u9519\u8bef\uff0c\u5e76\u5728119\u4e2a\u5b9a\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "TLA+\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u867d\u7136\u80fd\u63d0\u4f9b\u4e25\u683c\u7684\u7cfb\u7edf\u89c4\u8303\u4fdd\u8bc1\uff0c\u4f46\u6784\u5efa\u8bc1\u660e\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u52aa\u529b\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u57fa\u4e8e\u7b56\u7565\u7684\u5b9a\u7406\u8bc1\u660e\u5668\uff08\u5982Lean\uff09\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u7531\u4e8eTLA+\u8bc1\u660e\u7cfb\u7edf\u72ec\u7279\u7684\u5c42\u6b21\u5316\u8bc1\u660e\u7ed3\u6784\uff0c\u76f4\u63a5\u5e94\u7528\u8fd9\u4e9b\u65b9\u6cd5\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u5229\u7528LLM\u6307\u5bfc\u590d\u6742\u8bc1\u660e\u4e49\u52a1\u7684\u5c42\u6b21\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u5b50\u58f0\u660e\uff0c\u540c\u65f6\u4f9d\u8d56\u7b26\u53f7\u8bc1\u660e\u5668\u8fdb\u884c\u9a8c\u8bc1\u3002\u5173\u952e\u89c1\u89e3\u662f\u7ea6\u675fLLM\u751f\u6210\u89c4\u8303\u5316\u7684\u58f0\u660e\u5206\u89e3\u800c\u975e\u5b8c\u6574\u8bc1\u660e\uff0c\u4ece\u800c\u663e\u8457\u51cf\u5c11\u8bed\u6cd5\u9519\u8bef\u3002", "result": "\u5728\u5305\u542b119\u4e2a\u5b9a\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\uff08\u6539\u7f16\u81ea\uff081\uff09\u5df2\u5efa\u7acb\u7684\u6570\u5b66\u96c6\u5408\u548c\uff082\uff09\u5206\u5e03\u5f0f\u534f\u8bae\u7684\u5f52\u7eb3\u8bc1\u660e\uff09\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408LLM\u7684\u5c42\u6b21\u5206\u89e3\u80fd\u529b\u548c\u7b26\u53f7\u8bc1\u660e\u5668\u7684\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86TLA+\u5b9a\u7406\u8bc1\u660e\u81ea\u52a8\u5316\u7684\u6311\u6218\uff0c\u4e3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u52a8\u5316\u9014\u5f84\u3002"}}
{"id": "2512.09627", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09627", "abs": "https://arxiv.org/abs/2512.09627", "authors": ["Jingwei Ye", "Zhi Wang", "Chenbin Su", "Jieshuai Yang", "Jiayi Ding", "Chunbo Liu", "Ge Chu"], "title": "LogICL: Distilling LLM Reasoning to Bridge the Semantic Gap in Cross-Domain Log Anomaly Detection", "comment": null, "summary": "Effective log anomaly detection is critical to sustaining reliability in large-scale IT infrastructures. Transformer-based models require substantial resources and labeled data, exacerbating the cold-start problem in target domains where logs are scarce. Existing cross-domain methods leverage source logs but struggle with generalization due to reliance on surface lexical similarity, failing to capture latent semantic equivalence amid structural divergences. To address this, we propose LogICL, a framework distilling Large Language Model (LLM) reasoning into a lightweight encoder for cross-domain anomaly detection. During training, LogICL constructs a delta matrix measuring the utility of demonstrations selected via Maximal Marginal Relevance relative to zero-shot inference. The encoder is optimized via a multi-objective loss comprising an ICL-Guided term that aligns representations based on reasoning assistance utility, maximum mean discrepancy for domain alignment, and supervised contrastive loss. At inference, the optimized encoder retrieves reasoning-aware demonstrations using semantic similarity and delta scores, enabling frozen-LLM in-context learning with Chain-of-Thought for accurate and interpretable detection. Experiments on few-shot and zero-shot cross-domain benchmarks confirm LogICL achieves state-of-the-art performance across heterogeneous systems. Further analysis via visualizations and case studies confirms LogICL bridges the semantic gap beyond surface lexical similarity, effectively capturing latent semantic equivalence for rapid deployment.", "AI": {"tldr": "LogICL\uff1a\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u57df\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\u5e76\u8d85\u8d8a\u8868\u9762\u8bcd\u6c47\u76f8\u4f3c\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u9700\u8981\u5927\u91cf\u8d44\u6e90\u548c\u6807\u6ce8\u6570\u636e\uff0c\u5728\u76ee\u6807\u57df\u65e5\u5fd7\u7a00\u7f3a\u65f6\u5b58\u5728\u51b7\u542f\u52a8\u95ee\u9898\u3002\u73b0\u6709\u8de8\u57df\u65b9\u6cd5\u4f9d\u8d56\u8868\u9762\u8bcd\u6c47\u76f8\u4f3c\u6027\uff0c\u96be\u4ee5\u6355\u6349\u7ed3\u6784\u5dee\u5f02\u4e0b\u7684\u6f5c\u5728\u8bed\u4e49\u7b49\u4ef7\u6027\u3002", "method": "\u63d0\u51faLogICL\u6846\u67b6\uff1a1\uff09\u8bad\u7ec3\u65f6\u6784\u5efadelta\u77e9\u9635\u8861\u91cf\u57fa\u4e8e\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u7684\u6f14\u793a\u6837\u672c\u76f8\u5bf9\u4e8e\u96f6\u6837\u672c\u63a8\u7406\u7684\u6548\u7528\uff1b2\uff09\u7f16\u7801\u5668\u901a\u8fc7\u591a\u76ee\u6807\u635f\u5931\u4f18\u5316\uff1aICL\u5f15\u5bfc\u9879\u3001\u6700\u5927\u5747\u503c\u5dee\u5f02\u57df\u5bf9\u9f50\u3001\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\uff1b3\uff09\u63a8\u7406\u65f6\u7f16\u7801\u5668\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u548cdelta\u5206\u6570\u68c0\u7d22\u63a8\u7406\u611f\u77e5\u6f14\u793a\uff0c\u4f7f\u7528\u51bb\u7ed3LLM\u8fdb\u884c\u601d\u7ef4\u94fe\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002", "result": "\u5728\u5c11\u6837\u672c\u548c\u96f6\u6837\u672c\u8de8\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u548c\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u80fd\u8d85\u8d8a\u8868\u9762\u8bcd\u6c47\u76f8\u4f3c\u6027\uff0c\u6709\u6548\u6355\u6349\u6f5c\u5728\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5b9e\u73b0\u5feb\u901f\u90e8\u7f72\u3002", "conclusion": "LogICL\u901a\u8fc7\u5c06LLM\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668\uff0c\u89e3\u51b3\u4e86\u8de8\u57df\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u80fd\u591f\u6355\u6349\u6f5c\u5728\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5728\u5f02\u6784\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u3002"}}
{"id": "2512.09679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09679", "abs": "https://arxiv.org/abs/2512.09679", "authors": ["Naizhu Jin", "Zhong Li", "Guang Yang", "Tian Zhang", "Qingkai Zeng"], "title": "Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis", "comment": null, "summary": "Large language models (LLMs) achieve strong performance on code generation, but the mechanisms by which Chain-of-Thought (CoT) prompting helps remain unclear. We present a systematic empirical and information-theoretic study of CoT effectiveness in neural code generation, evaluating five paradigms (Zero-Shot, Zero-Shot CoT, Self-Planning, Structured CoT, Reasoning-CoT) across six Python benchmarks, a multilingual benchmark with 12 programming languages, and six models from 7B to 480B parameters, using conditional mutual information $I(Y;C|X)$ as a conceptual lens. Our results show that externally guided CoT consistently outperforms direct generation, with structured methods improving Pass@1 by 5--12\\% on average while using substantially fewer tokens than reflective reasoning, and that CoT benefits depend on language type systems and model capacity. We further find that reasoning \\emph{quality} is critical: high-quality structured CoT from strong generators yields significantly higher accuracy than lightweight alternatives with the same template, whereas naive Zero-Shot CoT can even degrade performance. These findings provide practical guidance for choosing CoT strategies based on model capacity, language characteristics, and task complexity.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u89c6\u89d2\u7cfb\u7edf\u7814\u7a76CoT\u63d0\u793a\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u7ed3\u6784\u5316CoT\u65b9\u6cd5\u5728\u51cf\u5c11token\u4f7f\u7528\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u6548\u679c\u53d7\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u6a21\u578b\u5bb9\u91cf\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46Chain-of-Thought\u63d0\u793a\u673a\u5236\u7684\u6709\u6548\u6027\u4ecd\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5b9e\u8bc1\u548c\u4fe1\u606f\u8bba\u7814\u7a76\uff0c\u63ed\u793aCoT\u5728\u795e\u7ecf\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u673a\u5236\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u4e92\u4fe1\u606fI(Y;C|X)\u4f5c\u4e3a\u6982\u5ff5\u6846\u67b6\uff0c\u8bc4\u4f30\u4e94\u79cdCoT\u8303\u5f0f\uff08Zero-Shot\u3001Zero-Shot CoT\u3001Self-Planning\u3001Structured CoT\u3001Reasoning-CoT\uff09\uff0c\u5728\u516d\u4e2aPython\u57fa\u51c6\u3001\u4e00\u4e2a\u5305\u542b12\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u4ee5\u53ca\u516d\u4e2a7B\u5230480B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5916\u90e8\u5f15\u5bfc\u7684CoT\u6301\u7eed\u4f18\u4e8e\u76f4\u63a5\u751f\u6210\uff0c\u7ed3\u6784\u5316\u65b9\u6cd5\u5e73\u5747\u63d0\u5347Pass@1 5-12%\uff0c\u540c\u65f6\u6bd4\u53cd\u601d\u63a8\u7406\u4f7f\u7528\u66f4\u5c11token\u3002CoT\u6548\u679c\u53d6\u51b3\u4e8e\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u6a21\u578b\u5bb9\u91cf\uff0c\u63a8\u7406\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff1a\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316CoT\u6bd4\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u51c6\u786e\u7387\u663e\u8457\u66f4\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8e\u6a21\u578b\u5bb9\u91cf\u3001\u8bed\u8a00\u7279\u6027\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u9009\u62e9CoT\u7b56\u7565\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u5f3a\u8c03\u7ed3\u6784\u5316CoT\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4f18\u52bf\u53ca\u5176\u5bf9\u63a8\u7406\u8d28\u91cf\u7684\u4f9d\u8d56\u6027\u3002"}}
{"id": "2512.09775", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09775", "abs": "https://arxiv.org/abs/2512.09775", "authors": ["Vladimir Balditsyn", "Philippe Lalanda", "German Vega", "St\u00e9phanie Chollet"], "title": "Quantifying Uncertainty in Machine Learning-Based Pervasive Systems: Application to Human Activity Recognition", "comment": null, "summary": "The recent convergence of pervasive computing and machine learning has given rise to numerous services, impacting almost all areas of economic and social activity. However, the use of AI techniques precludes certain standard software development practices, which emphasize rigorous testing to ensure the elimination of all bugs and adherence to well-defined specifications. ML models are trained on numerous high-dimensional examples rather than being manually coded. Consequently, the boundaries of their operating range are uncertain, and they cannot guarantee absolute error-free performance. In this paper, we propose to quantify uncertainty in ML-based systems. To achieve this, we propose to adapt and jointly utilize a set of selected techniques to evaluate the relevance of model predictions at runtime. We apply and evaluate these proposals in the highly heterogeneous and evolving domain of Human Activity Recognition (HAR). The results presented demonstrate the relevance of the approach, and we discuss in detail the assistance provided to domain experts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u6280\u672f\u6765\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u5728\u8fd0\u884c\u65f6\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u4e0d\u540c\uff0c\u5b83\u4eec\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u800c\u975e\u624b\u52a8\u7f16\u7801\u5f00\u53d1\uff0c\u5bfc\u81f4\u5176\u64cd\u4f5c\u8fb9\u754c\u4e0d\u786e\u5b9a\u4e14\u65e0\u6cd5\u4fdd\u8bc1\u5b8c\u5168\u65e0\u9519\u8bef\u3002\u5f53\u524d\u7f3a\u4e4f\u6709\u6548\u91cf\u5316ML\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u5c06\u4e00\u7ec4\u9009\u5b9a\u7684\u6280\u672f\u8fdb\u884c\u9002\u914d\u548c\u8054\u5408\u4f7f\u7528\uff0c\u4ee5\u5728\u8fd0\u884c\u65f6\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u7684\u76f8\u5173\u6027\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u7528\u4e8e\u9ad8\u5ea6\u5f02\u6784\u548c\u52a8\u6001\u53d8\u5316\u7684\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u76f8\u5173\u6027\uff0c\u80fd\u591f\u6709\u6548\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002\u8be6\u7ec6\u8ba8\u8bba\u4e86\u8be5\u65b9\u6cd5\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u7684\u8f85\u52a9\u4f5c\u7528\u3002", "conclusion": "\u91cf\u5316\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u662f\u5fc5\u8981\u7684\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u51b3\u7b56\u652f\u6301\u3002"}}
