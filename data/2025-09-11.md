<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 5]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Decidability in First-Order Modal Logic with Non-Rigid Constants and Definite Descriptions](https://arxiv.org/abs/2509.08165)
*Alessandro Artale,Christopher Hampson,Roman Kontchakov,Andrea Mazzullo,Frank Wolter*

Main category: cs.LO

TL;DR: 本文系统研究了单子模态逻辑片段的可判定性，发现在允许非刚性常量、确定描述和非平凡计数的情况下，某些单子片段仍然可判定，并建立了紧复杂度界限。


<details>
  <summary>Details</summary>
Motivation: 虽然模态扩展的一阶逻辑可判定片段通常不可判定，但其单子对应片段（模态算子范围内的公式最多有一个自由变量）通常是可判定的。然而，这只有在不允许非刚性常量、确定描述和非平凡计数的情况下才成立。本文旨在系统研究这些特征对可判定性的影响。

Method: 系统分析具有非刚性常量、确定描述和非平凡计数等特征的单子模态逻辑片段，研究其在标准一阶模态逻辑K_n和S5_n中的可判定性。

Result: 证明了具有计数功能的二变量片段和标准一阶模态逻辑的守卫片段是可判定的，并建立了紧复杂度界限。在扩展域语义下，证明了在有限无环框架上扩展传递闭包算子的基本模态逻辑的可判定性，但该逻辑是Ackermann难的。

Conclusion: 尽管某些特征通常导致不可判定性，但本文发现并证明了多个重要的单子模态逻辑片段在特定条件下仍然是可判定的，为模态逻辑的可判定性研究提供了新的理论结果。

Abstract: While modal extensions of decidable fragments of first-order logic are
usually undecidable, their monodic counterparts, in which formulas in the scope
of modal operators have at most one free variable, are typically decidable.
This only holds, however, under the provision that non-rigid constants,
definite descriptions and non-trivial counting are not admitted. Indeed,
several monodic fragments having at least one of these features are known to be
undecidable. We investigate these features systematically and show that
fundamental monodic fragments such as the two-variable fragment with counting
and the guarded fragment of standard first-order modal logics $\mathbf{K}_{n}$
and $\mathbf{S5}_{n}$ are decidable. Tight complexity bounds are established as
well. Under the expanding-domain semantics, we show decidability of the basic
modal logic extended with the transitive closure operator on finite acyclic
frames; this logic, however, is Ackermann-hard.

</details>


### [2] [Hammering Higher Order Set Theory](https://arxiv.org/abs/2509.08264)
*Chad E. Brown,Cezary Kaliszyk,Martin Suda,Josef Urban*

Main category: cs.LO

TL;DR: 使用自动定理证明器显著缩短高阶集合论的形式化开发，包括算术基本定理和√2无理数等标准定理的证明


<details>
  <summary>Details</summary>
Motivation: 高阶集合论框架与高阶自动定理证明器的经典外延高阶逻辑相吻合，无需重大翻译或编码工作，且许多子目标是一阶的，可用一阶证明器处理

Method: 利用高阶自动定理证明器处理形式化开发中的子目标，比较不同证明器在生成子目标上的性能，并探讨证明重构的可能性

Result: 成功缩短了高阶集合论的形式化开发过程，验证了自动定理证明器在此类数学定理证明中的有效性

Conclusion: 高阶自动定理证明器特别适合高阶集合论的形式化开发，既能处理高阶逻辑又能利用一阶证明器处理一阶子目标，证明重构是未来重要研究方向

Abstract: We use automated theorem provers to significantly shorten a formal
development in higher order set theory. The development includes many standard
theorems such as the fundamental theorem of arithmetic and irrationality of
square root of two. Higher order automated theorem provers are particularly
useful here, since the underlying framework of higher order set theory
coincides with the classical extensional higher order logic of (most) higher
order automated theorem provers, so no significant translation or encoding is
required. Additionally, many subgoals are first order and so first order
automated provers often suffice. We compare the performance of different
provers on the subgoals generated from the development. We also discuss
possibilities for proof reconstruction, i.e., obtaining formal proof terms when
an automated theorem prover claims to have proven the subgoal.

</details>


### [3] [Exploring Formal Math on the Blockchain: An Explorer for Proofgold](https://arxiv.org/abs/2509.08267)
*Chad E. Brown,Cezary Kaliszyk,Josef Urban*

Main category: cs.LO

TL;DR: Proofgold是一个支持形式化数学的区块链系统，本文介绍了其基于Web的区块链浏览器，能够展示数学理论和证明等正式内容。


<details>
  <summary>Details</summary>
Motivation: 为Proofgold区块链开发一个专门的浏览器，不仅要展示常规交易数据，还要支持形式化数学内容的展示和交互，促进去中心化数学知识管理。

Method: 设计并实现基于Web的区块链浏览器系统，与Proofgold Lava软件集成，支持区块、交易、地址的查看，以及理论、定义、定理和证明等数学对象的展示和交互。

Result: 成功开发了功能完整的区块链浏览器，支持数学内容的导航和交易提交，并在范畴论等领域进行了形式化验证。

Conclusion: 该浏览器有效支持了Proofgold区块链中形式化数学内容的展示和管理，为去中心化数学知识库的发展提供了重要工具。

Abstract: Proofgold is a blockchain that supports formalized mathematics alongside
standard cryptocurrency functionality. It incorporates logical constructs into
the blockchain, including declarations of formal theories, definitions,
propositions and proofs. It also supports placing and collecting bounties on
proving these propositions, incentivizing the development of the formal
libraries contained in Proofgold. In this paper, we present a web-based
blockchain explorer for Proofgold. The system exposes not only the usual
transactional data but also the formal mathematical components embedded in the
chain and allows some interaction with them. The explorer allows users to
inspect blocks, transactions, and addresses, as well as formal objects:
theories, definitions, theorems and their proofs. We also support the
submission of transactions to the blockchain using our interface. We describe
the system architecture and its integration with the Proofgold Lava software,
highlighting how the explorer supports navigation of formal content and
facilitates mathematical knowledge management in a decentralized setting, as
well as a number of formalizations in category theory done in the system.

</details>


### [4] [Payment Channels with Proofs](https://arxiv.org/abs/2509.08268)
*Chad E. Brown,Cezary Kaliszyk,Josef Urban*

Main category: cs.LO

TL;DR: 扩展比特币闪电网络的双向支付通道，在Proofgold网络中实现支持命题证明的支付通道，为构建Proofgold闪电网络奠定基础，支持证明请求和奖励机制


<details>
  <summary>Details</summary>
Motivation: 为Proofgold网络构建类似比特币闪电网络的支付通道系统，支持用户对命题可证明性进行投注，建立去中心化快速协作形式化项目的基础设施

Method: 扩展双向支付通道功能，使其支持对命题在特定时间内是否可被证明进行投注，实现Proofgold网络中的证明支持支付通道

Result: 提出了支持证明的支付通道实现方案，为构建Proofgold闪电网络提供了技术基础，能够实现证明请求和奖励机制

Conclusion: 这种扩展的支付通道技术为构建Proofgold闪电网络奠定了基础，可用于创建大规模去中心化协作形式化项目基础设施，同时通过投注机制近似估算命题可证明概率

Abstract: The fundamental building blocks of the Bitcoin lightning network are
bidirectional payment channels. We describe an extension of payment channels in
the Proofgold network which allow the two parties to bet on whether a
proposition will be proven by a certain time. These provide the foundation for
a Proofgold lightning network that would allow parties to request proofs (by
betting there will be no proof by a certain time) and other parties to provide
proofs (and be rewarded by betting there will be a proof). The bets may also
provide a way to approximate the probability that a certain proposition is
provable (in the given amount of time). We describe the implementation of
payment channels supporting proofs in Proofgold and discuss a potential
lightning network that could be built as a result. One application of such
lightning network would be a large decentralized infrastructure for fast
collaborative formalization projects.

</details>


### [5] [Trace Repair for Temporal Behavior Trees](https://arxiv.org/abs/2509.08610)
*Sebastian Schirmer,Philipp Schitz,Johann C. Dauer,Bernd Finkbeiner,Sriram Sankaranarayanan*

Main category: cs.LO

TL;DR: 提出两种实用的追踪修复策略：增量式修复和重要里程碑修复，用于在时序行为树规范下修复追踪，解决MILP方法计算费用高的问题


<details>
  <summary>Details</summary>
Motivation: 追踪修复对于失败解释和避免问题的训练示例很有用，但传统的混合整数线性规划(MILP)方法计算费用太高，不适合实际应用

Method: 1、增量式修复：通过将追踪分割成段落来减少MILP问题规模
2、重要里程碑修复：使用TBT的稳健语义作为哈希函数，通过迭代方式使用更高效的线性规划近似MILP

Result: 在实验中，能够在10分钟内修复超过25,000个进入项的追踪，而MILP方法会流出内存

Conclusion: 所提出的两种实用修复策略能够有效解决MILP方法计算费用过高的问题，为机器人学和载具系统提供高效的追踪修复方案

Abstract: We present methods for repairing traces against specifications given as
temporal behavior trees (TBT). TBT are a specification formalism for action
sequences in robotics and cyber-physical systems, where specifications of
sub-behaviors, given in signal temporal logic, are composed using operators for
sequential and parallel composition, fallbacks, and repetition. Trace repairs
are useful to explain failures and as training examples that avoid the observed
problems. In principle, repairs can be obtained via mixed-integer linear
programming (MILP), but this is far too expensive for practical applications.
We present two practical repair strategies: (1) incremental repair, which
reduces the MILP by splitting the trace into segments, and (2) landmark-based
repair, which solves the repair problem iteratively using TBT's robust
semantics as a heuristic that approximates MILP with more efficient linear
programming. In our experiments, we were able to repair traces with more than
25,000 entries in under ten minutes, while MILP runs out of memory.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [ChatGPT for Code Refactoring: Analyzing Topics, Interaction, and Effective Prompts](https://arxiv.org/abs/2509.08090)
*Eman Abdullah AlOmar,Luo Xu,Sofia Martinez,Anthony Peruma,Mohamed Wiem Mkaouer,Christian D. Newman,Ali Ouni*

Main category: cs.SE

TL;DR: 这篇论文通过分析开发者与ChatGPT在重构相关交互中的主动式需求表达方式，探索开发者如何识别代码改进点以及ChatGPT如何响应这些需求。


<details>
  <summary>Details</summary>
Motivation: 虽然最近的研究已经检验了LLMs在推荐和建议重构方面的效果，但对开发者在与ChatGPT交互时如何表达重构需求的理解仍然有限。

Method: 采用文本挖掘方法，从29,778个ChatGPT提示和响应中提取715个重构相关交互，并分析开发者的显式重构意图。

Result: 本文提供了开发者与ChatGPT在重构交互中的具体数据分析结果，但摘要未呈现具体的数据结果和发现。

Conclusion: 这项研究有助于更好地理解开发者如何通过与LLMs交互来识别和表达代码重构需求，为改进这种人机协作模式提供基础。

Abstract: Large Language Models (LLMs), such as ChatGPT, have become widely popular and
widely used in various software engineering tasks such as refactoring, testing,
code review, and program comprehension. Although recent studies have examined
the effectiveness of LLMs in recommending and suggesting refactoring, there is
a limited understanding of how developers express their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore interactions
related to refactoring between developers and ChatGPT to better understand how
developers identify areas for improvement in code, and how ChatGPT addresses
developers' needs. Our approach involves text mining 715 refactoring-related
interactions from 29,778 ChatGPT prompts and responses, as well as the analysis
of developers' explicit refactoring intentions.

</details>


### [7] [Safety Factories -- a Manifesto](https://arxiv.org/abs/2509.08285)
*Carmen Cârlan,Daniel Ratiu,Michael Wagner*

Main category: cs.SE

TL;DR: 软件工厂模式应用于安全弘程，通过形式化模型和自动化检查来缩小软件开发与安全工程间的差距


<details>
  <summary>Details</summary>
Motivation: 现代软件速度开发与安全关键功能的需求存在脱节，需要将软件开发的最佳实践转移到安全工程中

Method: 提出安全工厂概念，将安全工具和方法集成到软件开发流水线中，使用可机器处理的语义丰富模型，定义自动一致性检查，自动生成文档

Result: 建立了一种新的安全工程方法论，通过前期投资形式化来获得后期效益

Conclusion: 建立安全工厂是缩小软件开发与安全工程间差距的有效途径，软件工厂模式在安全领域的转移价值突出

Abstract: Modern cyber-physical systems are operated by complex software that
increasingly takes over safety-critical functions. Software enables rapid
iterations and continuous delivery of new functionality that meets the
ever-changing expectations of users. As high-speed development requires
discipline, rigor, and automation, software factories are used. These entail
methods and tools used for software development, such as build systems and
pipelines. To keep up with the rapid evolution of software, we need to bridge
the disconnect in methods and tools between software development and safety
engineering today. We need to invest more in formality upfront - capturing
safety work products in semantically rich models that are machine-processable,
defining automatic consistency checks, and automating the generation of
documentation - to benefit later. Transferring best practices from software to
safety engineering is worth exploring. We advocate for safety factories, which
integrate safety tooling and methods into software development pipelines.

</details>


### [8] [The Impact of Team Diversity in Agile Development Education](https://arxiv.org/abs/2509.08389)
*Marco Torchiano,Riccardo Coppola,Antonio Vetro',Xhoi Musaj*

Main category: cs.SE

TL;DR: 这篇论文研究软件工程团队多样性对项目质量的影响，重点分析了性别和国籍多样性在敏捷软件开发课程中的作用。


<details>
  <summary>Details</summary>
Motivation: 软件工程领域以男性为主，研究多样性对平等机会、生产力和创新的影响。国籍和种族等其他多样性维度被过很少研究。

Method: 分析了3个学术年度的51个团队，采用三种不同的多样性指数（性别、国籍和其共同存在）来评估多样性对团队项目成果质量的影响。

Result: 性别多样性与项目成功呈现中等程度的显著正相关关系；国籍多样性对项目结果有较弱的负面影响；性别和国籍多样性共同存在时产生负面影响，可能因沟通障碍和文化差异导致。

Conclusion: 教育环境中需要考虑多重多样性维度及其交互作用。总体而言，推动团队多样性不会对学生表现和教育目标完成产生负面影响。

Abstract: Software Engineering is mostly a male-dominated sector, where gender
diversity is a key feature for improving equality of opportunities,
productivity, and innovation. Other diversity aspects, including but not
limited to nationality and ethnicity, are often understudied.In this work we
aim to assess the impact of team diversity, focusing mainly on gender and
nationality, in the context of an agile software development project-based
course. We analyzed 51 teams over three academic years, measuring three
different Diversity indexes - regarding Gender, Nationality and their
co-presence - to examine how different aspects of diversity impact the quality
of team project outcomes.Statistical analysis revealed a moderate,
statistically significant correlation between gender diversity and project
success, aligning with existing literature. Diversity in nationality showed a
negative but negligible effect on project results, indicating that promoting
these aspects does not harm students' performance. Analyzing their co-presence
within a team, gender and nationality combined had a negative impact, likely
due to increased communication barriers and differing cultural norms.This study
underscores the importance of considering multiple diversity dimensions and
their interactions in educational settings. Our findings, overall, show that
promoting diversity in teams does not negatively impact their performance and
achievement of educational goals.

</details>


### [9] [AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution](https://arxiv.org/abs/2509.08524)
*Felix Mächtle,Nils Loose,Jan-Niclas Serr,Jonas Sander,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: AutoStub使用遗传编程自动为符号执行中的外部函数生成符号存根，无需人工干预即可近似函数行为，准确率超过90%


<details>
  <summary>Details</summary>
Motivation: 符号执行在遇到外部函数（如原生方法或第三方库）时存在局限性，现有解决方案需要额外上下文、昂贵的SMT求解器或手动干预

Method: 当符号执行器遇到外部函数时，AutoStub通过随机生成输入执行函数并收集输出来生成训练数据，然后使用遗传编程推导近似函数行为的表达式作为符号存根

Result: AutoStub能自动近似55%评估的外部函数，准确率超过90%，并能推断出语言特定行为，揭示对软件测试至关重要的边缘情况

Conclusion: 该方法使符号执行器能够继续分析而无需手动干预，实现了以前难以处理的程序路径探索

Abstract: Symbolic execution is a powerful technique for software testing, but suffers
from limitations when encountering external functions, such as native methods
or third-party libraries. Existing solutions often require additional context,
expensive SMT solvers, or manual intervention to approximate these functions
through symbolic stubs. In this work, we propose a novel approach to
automatically generate symbolic stubs for external functions during symbolic
execution that leverages Genetic Programming. When the symbolic executor
encounters an external function, AutoStub generates training data by executing
the function on randomly generated inputs and collecting the outputs. Genetic
Programming then derives expressions that approximate the behavior of the
function, serving as symbolic stubs. These automatically generated stubs allow
the symbolic executor to continue the analysis without manual intervention,
enabling the exploration of program paths that were previously intractable. We
demonstrate that AutoStub can automatically approximate external functions with
over 90% accuracy for 55% of the functions evaluated, and can infer
language-specific behaviors that reveal edge cases crucial for software
testing.

</details>


### [10] [Beyond the Binary: The System of All-round Evaluation of Research and Its Practices in China](https://arxiv.org/abs/2509.08546)
*Yu Zhu,Jiyuan Ye*

Main category: cs.SE

TL;DR: 这篇论文提出了全面科研评价体系（SAER），通过形式、内容和效用三维度与六大要素的结合，解决了定性与定量评价方法的二元对立问题，为全球科研评价改革提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前全球科研评价系统改革缺乏宏观层面的系统化评价理论指导，定性与定量评价方法存在二元对立问题，需要突破性理论来解决这一瓶颈。

Method: 通过回顾科研评价历史发展，提出全面科研评价体系（SAER）框架，整合了形式评价、内容评价和效用评价三个维度，结合六大关键要素，超越了传统的二元评价方法。

Result: SAER体系为学术评价者和研究人员提供了协调评价方法二元对立的综合框架，展现了中国科研评价理论中的辨证智慧和经验。

Conclusion: 该系统为全球科研评价系统的改革和发展提供了重要的理论基础和参考价值，有助于推动科研评价方法的综合化发展。

Abstract: The lack of a macro-level, systematic evaluation theory to guide the
implementation of evaluation practices has become a key bottleneck in the
reform of global research evaluation systems. By reviewing the historical
development of research evaluation, this paper highlights the current binary
opposition between qualitative and quantitative methods in evaluation
practices. This paper introduces the System of All-round Evaluation of Research
(SAER), a framework that integrates form, content, and utility evaluations with
six key elements. SAER offers a theoretical breakthrough by transcending the
binary, providing a comprehensive foundation for global evaluation reforms. The
comprehensive system proposes a trinity of three evaluation dimensions,
combined with six evaluation elements, which would help academic evaluators and
researchers reconcile binary oppositions in evaluation methods. The system
highlights the dialectical wisdom and experience embedded in Chinese research
evaluation theory, offering valuable insights and references for the reform and
advancement of global research evaluation systems.

</details>


### [11] [Minimal Data, Maximum Clarity: A Heuristic for Explaining Optimization](https://arxiv.org/abs/2509.08667)
*Amirali Rayegan,Tim Menzies*

Main category: cs.SE

TL;DR: EZR是一个新颖的模块化多目标优化框架，通过主动学习和决策树解释，用更少但更信息丰富的样本实现高效可解释的软件配置优化


<details>
  <summary>Details</summary>
Motivation: 解决软件工程中配置空间巨大、标注成本高且易出错的问题，提供高效且可解释的优化方法

Method: 基于朴素贝叶斯采样的主动学习策略，结合最大清晰度启发式方法，使用决策树提供全局和局部决策的透明解释

Result: 在60个真实数据集上，EZR在大多数情况下达到超过90%的最佳优化性能，解释清晰度和实用性优于LIME、SHAP等标准XAI方法

Conclusion: 证明了'少而精'的可行性，使用更少但更信息丰富的样本可以产生标签高效的优化和解释，优于完全监督方法

Abstract: Efficient, interpretable optimization is a critical but underexplored
challenge in software engineering, where practitioners routinely face vast
configuration spaces and costly, error-prone labeling processes. This paper
introduces EZR, a novel and modular framework for multi-objective optimization
that unifies active sampling, learning, and explanation within a single,
lightweight pipeline. Departing from conventional wisdom, our Maximum Clarity
Heuristic demonstrates that using less (but more informative) data can yield
optimization models that are both effective and deeply understandable. EZR
employs an active learning strategy based on Naive Bayes sampling to
efficiently identify high-quality configurations with a fraction of the labels
required by fully supervised approaches. It then distills optimization logic
into concise decision trees, offering transparent, actionable explanations for
both global and local decision-making. Extensive experiments across 60
real-world datasets establish that EZR reliably achieves over 90% of the
best-known optimization performance in most cases, while providing clear,
cohort-based rationales that surpass standard attribution-based explainable AI
(XAI) methods (LIME, SHAP, BreakDown) in clarity and utility. These results
endorse "less but better"; it is both possible and often preferable to use
fewer (but more informative) examples to generate label-efficient optimization
and explanations in software systems. To support transparency and
reproducibility, all code and experimental materials are publicly available at
https://github.com/amiiralii/Minimal-Data-Maximum-Clarity.

</details>


### [12] [SWE-Mirror: Scaling Issue-Resolving Datasets by Mirroring Issues Across Repositories](https://arxiv.org/abs/2509.08724)
*Junhao Wang,Daoguang Zan,Shulin Xin,Siyao Liu,Yurong Wu,Kai Shen*

Main category: cs.SE

TL;DR: SWE-Mirror是一个从GitHub真实问题中创建可验证训练数据集的管道，通过重用现有Gym环境和问题解决历史，构建了60,671个任务的大规模数据集，显著提升了代码代理的问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化Gym环境设置过程中成功率低、开销大，而合成新任务又无法利用大量真实的人类报告问题。需要最大化利用现有Gym环境和GitHub上的问题解决历史数据。

Method: 引入SWE-Mirror管道：提取真实问题的语义本质，将其镜像到配置了Gym环境的另一个仓库中，并重新激活为可验证的问题解决任务。

Result: 在4种语言的40个仓库中创建了60,671个问题解决任务的数据集。使用该数据集训练的模型在问题解决能力上表现出改进，在OpenHands框架上建立了新的SOTA，7B模型和32B模型的解决率分别提升了21.8%和46.0%。

Conclusion: SWE-Mirror有效利用了现有Gym环境和GitHub问题历史，构建了大规模可验证数据集，显著提升了代码代理的性能，验证了该方法的有效性。

Abstract: Creating large-scale verifiable training datasets for issue-resolving tasks
is a critical yet notoriously difficult challenge. Existing methods on
automating the Gym environment setup process for real-world issues suffer from
low success rates and high overhead. Meanwhile, synthesizing new tasks within
existing Gym environments leaves the vast pool of authentic, human-reported
problems untapped. To maximize the utilization of existing Gym environments and
also the rich data of issue-resolving history on GitHub, we introduce
SWE-Mirror, a pipeline that distills a real-world issue's semantic essence,
mirrors it into another repository with a configured Gym environment, and
re-animates it as a verifiable issue-resolving task. SWE-Mirror reuses existing
Gym environments along with the vast pool of issue-resolving history hosted on
GitHub to construct a large-scale dataset of mirrored authentic and verifiable
tasks. Applying SWE-Mirror to 40 repositories across 4 languages, we have
curated a dataset with 60,671 issue-resolving tasks and demonstrated the value
of our dataset by training and evaluating coding agents at various scale.
Post-training experiments show that models trained with the dataset exhibit
improvements in issue-resolving capabilities. Furthermore, by extending the
dataset size to over 12,000 high-quality trajectories, we established a new
state-of-the-art (SOTA) among Qwen2.5-Coder-Instruct based LLMs on the
OpenHands agent framework, which increases the resolve rate on
SWE-Bench-Verified by +21.8% for the 7B model and +46.0% for the 32B model and
validates the effectiveness of our approach.

</details>


### [13] [Handling Open-Vocabulary Constructs in Formalizing Specifications: Retrieval-Augmented Parsing with Expert Knowledge](https://arxiv.org/abs/2509.08808)
*Mohammad Saqib Hasan,Sayontan Ghosh,Dhruv Verma,Geoff Kuenning,Erez Zadok,Scott A. Smolka,Niranjan Balasubramanian*

Main category: cs.SE

TL;DR: 这篇论文提出了动态知识增强解析方法DKAP和ROLex方案，通过在推理时动态利用专家提供的知识词典来处理开放词汇构造，提高了自然语言到形式语言转换的性能。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇构造(OVCs)在自然语言到形式语言转换中的挑战，因为模型缺乏对未知构造的先验知识，而专家可以在推理时提供这些知识。

Method: 提出DKAP方法，使用动态增长的专家知识词典（NL短语到正确OVC构造的键值对）。设计ROLex检索增强解析方案，包含检索器和生成器，使用合成数据生成和数据增布技术进行训练。

Result: 在三个形式化任务（NL2LTL、NL2Code、NL2CMD）上评估，显示DKAP是一个具有挑战性的问题，ROLex能够通过有效利用动态专家知识来提高基线模型的性能。

Conclusion: DKAP方法能够有效处理开放词汇构造问题，ROLex方案通过动态知识利用明显提升了解析性能，为自然语言形式化转换提供了新的解决方案。

Abstract: We study the problem of Open-Vocabulary Constructs(OVCs) -- ones not known
beforehand -- in the context of converting natural language (NL) specifications
into formal languages (e.g., temporal logic or code). Models fare poorly on
OVCs due to a lack of necessary knowledge a priori. In such situations, a
domain expert can provide correct constructs at inference time based on their
preferences or domain knowledge. Our goal is to effectively reuse this
inference-time, expert-provided knowledge for future parses without retraining
the model. We present dynamic knowledge-augmented parsing(DKAP), where in
addition to the input sentence, the model receives (dynamically growing) expert
knowledge as a key-value lexicon that associates NL phrases with correct OVC
constructs. We propose ROLex, a retrieval-augmented parsing approach that uses
this lexicon. A retriever and a generator are trained to find and use the
key-value store to produce the correct parse. A key challenge lies in curating
data for this retrieval-augmented parser. We utilize synthetic data generation
and the data augmentation techniques on annotated (NL sentence, FL statement)
pairs to train the augmented parser. To improve training effectiveness, we
propose multiple strategies to teach models to focus on the relevant subset of
retrieved knowledge. Finally, we introduce a new evaluation paradigm modeled
after the DKAP problem and simulate the scenario across three formalization
tasks (NL2LTL, NL2Code, and NL2CMD). Our evaluations show that DKAP is a
difficult challenge, and ROLex helps improve the performance of baseline models
by using dynamic expert knowledge effectively.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [14] [XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols](https://arxiv.org/abs/2509.08182)
*Faruk Alpay,Taylan Alpay*

Main category: cs.PL

TL;DR: 本文提出了一种基于XML标签的结构化提示方法，通过逻辑优先的处理方式统一了语法约束解码、分层提示的固定点语义以及人机交互循环，并提供了数学证明和实际应用模式。


<details>
  <summary>Details</summary>
Motivation: 结构化提示已成为引导大型语言模型生成可解析、符合模式输出的有效方法，但缺乏统一的理论框架来整合语法约束、语义固定点和人机交互。

Method: 建立了XML树的完全格结构，证明了单调提示操作符存在最小固定点（Knaster-Tarski定理），在任务感知收缩度量下证明了迭代指导的收敛性（Banach风格），并使用上下文无关文法实例化。

Result: 开发了数学完整的理论框架，证明了约束解码既能保证格式良好性又能保持任务性能，并展示了多层人机交互的实际部署模式。

Conclusion: 该研究为结构化提示提供了坚实的理论基础，将语法对齐解码、验证链和程序化提示等最新进展统一在一个框架内，具有重要的理论和实践价值。

Abstract: Structured prompting with XML tags has emerged as an effective way to steer
large language models (LLMs) toward parseable, schema-adherent outputs in
real-world systems. We develop a logic-first treatment of XML prompting that
unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over
lattices of hierarchical prompts, and (iii) convergent human-AI interaction
loops. We formalize a complete lattice of XML trees under a refinement order
and prove that monotone prompt-to-prompt operators admit least fixed points
(Knaster-Tarski) that characterize steady-state protocols; under a task-aware
contraction metric on trees, we further prove Banach-style convergence of
iterative guidance. We instantiate these results with context-free grammars
(CFGs) for XML schemas and show how constrained decoding guarantees
well-formedness while preserving task performance. A set of multi-layer
human-AI interaction recipes demonstrates practical deployment patterns,
including multi-pass "plan $\to$ verify $\to$ revise" routines and agentic tool
use. We provide mathematically complete proofs and tie our framework to recent
advances in grammar-aligned decoding, chain-of-verification, and programmatic
prompting.

</details>
