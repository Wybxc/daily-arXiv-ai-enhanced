<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.SE](#cs.SE) [Total: 17]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts](https://arxiv.org/abs/2512.04755)
*Stian Lybech,Daniele Gorla,Luca Aceto*

Main category: cs.PL

TL;DR: 该论文提出在智能合约环境中使用语义类型来确保使用静态不可类型化语言构造（如fallback函数）的代码类型安全，采用证明携带代码方法，用户只需验证提供的类型安全证明证书。


<details>
  <summary>Details</summary>
Motivation: 智能合约中某些语言构造（如fallback函数）无法静态类型检查，需要在区块链环境中确保类型安全，特别是信息流控制和非干扰性安全属性。

Method: 采用证明携带代码方法：合约创建者为包含不可类型化构造的代码提供形式化类型安全证明；基于TINYSOL语言的类型化操作语义定义类型语义；使用共归纳定义的类型解释和up-to技术紧凑表示安全证明。

Result: 建立了在区块链/智能合约环境中实现语义类型检查的理论框架；能够为基于fallback函数的典型指针到实现模式提供类型安全证明；确保信息流控制和非干扰性安全。

Conclusion: 该研究的主要贡献不是安全定理本身，而是展示了在区块链/智能合约环境中实现语义类型检查所需的理论发展框架，可扩展到非干扰性之外的其他安全属性。

Abstract: This paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate' of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment.
  As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.

</details>


### [2] [Optimizations and extensions for fair join pattern matching](https://arxiv.org/abs/2512.04876)
*Ioannis Karras*

Main category: cs.PL

TL;DR: 该论文优化了Haller等人的状态树匹配算法，在公平连接模式匹配中实现了高达10倍的性能提升，接近Rete算法在常规基准测试中的表现，同时保持了处理复杂条件守卫的优势。


<details>
  <summary>Details</summary>
Motivation: 连接模式在并发和分布式系统编程中尚未充分探索。虽然Haller等人提出了公平连接模式匹配算法，但其时间效率问题仍未得到充分研究。现有状态树算法在常规基准测试中表现不如Rete算法，而Rete算法需要大量手动适配才能应用于连接模式匹配。

Method: 1. 增强和优化Haller等人的状态树匹配算法；2. 改进基准测试套件，增加新功能并提升可扩展性和用户友好性；3. 扩展连接模式实现，提供更少歧义的语法和动态模式切换；4. 提出新的复杂模型用例，展示连接模式在微服务Web架构中的应用。

Result: 1. 在某些基准测试中实现了高达10倍的性能提升；2. 在常规基准测试中接近Rete算法的性能；3. 保持了在处理复杂条件守卫时的优势；4. 提供了更完善的基准测试套件和更清晰的语法支持。

Conclusion: 通过优化状态树匹配算法，论文显著提升了公平连接模式匹配的时间效率，同时保持了算法的通用性和处理复杂条件的能力。扩展的实现和新的用例展示了连接模式在实际分布式系统中的实用价值。

Abstract: Join patterns are an underexplored approach for the programming of concurrent and distributed systems. When applied to the actor model, join patterns offer the novel capability of matching combinations of messages in the mailbox of an actor. Previous work by Philipp Haller et al. in the paper "Fair Join Pattern Matching for Actors" (ECOOP 2024) explored join patterns with conditional guards in an actor-based setting with a specification of fair and deterministic matching semantics. Nevertheless, the question of time efficiency in fair join pattern matching has remained underexplored. The stateful tree-based matching algorithm of Haller et al. performs worse than an implementation that adapts the Rete algorithm to the regular version of a join pattern matching benchmark, while outperforming on a variant with heavy conditional guards, which take longer to evaluate. Nevertheless, conforming Rete to the problem of join pattern matching requires heavy manual adaptation.
  In this thesis, we enhance and optimize the stateful tree-based matching algorithm of Haller et al. to achieve up to tenfold performance improvements on certain benchmarks, approaching the performance of Rete on regular benchmarks while maintaining the advantages of versatility and performance with heavy guards. We also enhance the benchmark suite, adding new features and enhancing its extensibility and user-friendliness. We extend the join pattern implementation with a less ambiguous syntax as well as dynamic pattern switching. Finally, we present a new complex model use case for join patterns, showing their applicability in a microservice web architecture.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [3] [A Rocq Formalization of Monomial and Graded Orders](https://arxiv.org/abs/2512.04573)
*Sylvie Boldo,François Clément,Vincent Martin,Micaela Mayero*

Main category: cs.LO

TL;DR: 本文在Rocq中形式化了关系和序的理论，特别关注单项式序和分级序，为有限元方法的形式化提供了基础库，包含700多个引理。


<details>
  <summary>Details</summary>
Motivation: 在Rocq中形式化有限元方法时，需要形式化特定的序（单项式序和分级序）。虽然二元关系和序是常见的形式化主题，但需要为有限元方法的形式化过程提供专门的序理论支持。

Method: 在Rocq中定义关系和序的相关概念、操作符和性质证明。特别关注单项式序（与幺半群运算兼容的全序），定义了多种单项式序（如字典序和grevlex序）。为了通用性，形式化了序的分级操作，这是一个将二元关系转换为另一个关系的高级操作符，并证明分级操作保持许多性质（如单项式序性质）。

Result: 建立了一个全面且用户友好的Rocq库，包含关系和序的理论，特别是单项式序和分级序，定义了四种不同的分级序，证明过程高度因子化，包含700多个引理。

Conclusion: 本文提供了一个全面的Rocq库，形式化了关系和序的理论，特别关注单项式序和分级序，为有限元方法的形式化提供了必要的基础设施，证明过程高度因子化，库设计用户友好。

Abstract: Even if binary relations and orders are a common formalization topic, we need to formalize specific orders (namely monomial and graded) in the process of formalizing in Rocq the finite element method. This article is therefore definitions, operators, and proofs of properties about relations and orders, thus providing a comprehensive Rocq library. We especially focus on monomial orders, that are total orders compatible with the monoid operation. More than its definition and proved properties, we define several of them, among them the lexicographic and grevlex orders. For the sake of genericity, we formalize the grading of an order, a high-level operator that transforms a binary relation into another one, and we prove that grading an order preserves many of its properties, such as the monomial order property. This leads us to the definition and properties of four different graded orders, with very factorized proofs. We therefore provide a comprehensive and user-friendly library in Rocq about orders, including monomial and graded orders, that contains more than 700 lemmas.

</details>


### [4] [Intuitionistic modal logic LIK4 is decidable](https://arxiv.org/abs/2512.04687)
*Philippe Balbiani,Çigdem Gencer,Tinko Tinchev*

Main category: cs.LO

TL;DR: 直觉主义模态逻辑LIK4是可判定的


<details>
  <summary>Details</summary>
Motivation: 研究直觉主义模态逻辑LIK4的可判定性问题，这类逻辑在哲学和计算机科学中都有重要应用

Method: 通过形式化证明的方法，建立LIK4逻辑系统的可判定性

Result: 成功证明了直觉主义模态逻辑LIK4是可判定的

Conclusion: 该研究为直觉主义模态逻辑的可判定性理论提供了重要结果，对相关领域有理论意义

Abstract: In this note, we prove that intuitionistic modal logic LIK4 is decidable.

</details>


### [5] [Parametric disjunctive timed networks](https://arxiv.org/abs/2512.04991)
*Étienne André,Swen Jacobs,Engel Lefaucheux*

Main category: cs.LO

TL;DR: 研究了带参数化定时网络的可达性问题，证明了单时钟无不变式系统的局部可达性可判定，但全局可达性不可判定，揭示了不变式的强大表达能力。


<details>
  <summary>Details</summary>
Motivation: 研究分布式系统中带参数化定时自动机的可达性问题，探索在位置守卫通信机制下，参数化定时网络的可判定性边界，特别是理解不变式对系统表达能力和可判定性的影响。

Method: 引入参数化析取定时网络模型，其中每个定时自动机包含未知的时间参数。研究两种可达性问题：局部可达性（至少一个进程到达给定位置）和全局可达性（所有进程同时到达给定位置）。分析不同约束条件下的可判定性。

Result: 主要正面结果：对于单时钟且无不变式的网络，局部可达性问题可判定，即使有任意多个时间参数。负面结果：当允许不变式或考虑全局性质时，即使只有一个参数，问题也变得不可判定。还展示了通过限制守卫和不变式语法得到的其他可判定子类。

Conclusion: 不变式在参数化析取定时网络中具有显著的表达能力，是导致不可判定性的关键因素。单时钟无不变式系统的局部可达性可判定，这为参数化定时网络分析提供了重要的可判定性边界。

Abstract: We consider distributed systems with an arbitrary number of processes, modelled by timed automata that communicate through location guards: a process can take a guarded transition if at least one other process is in a given location. In this work, we introduce parametric disjunctive timed networks, where each timed automaton may contain timing parameters, i.e. unknown constants. We investigate two problems: deciding the emptiness of the set of parameter valuations for which
  1) a given location is reachable for at least one process (local property), and
  2) a global state is reachable where all processes are in a given location (global property).
  Our main positive result is that the first problem is decidable for networks of processes with a single clock and without invariants; this result holds for arbitrarily many timing parameters -- a setting with few known decidability results. However, it becomes undecidable when invariants are allowed, or when considering global properties, even for systems with a single parameter. This highlights the significant expressive power of invariants in these networks. Additionally, we exhibit further decidable subclasses by restraining the syntax of guards and invariants.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection](https://arxiv.org/abs/2512.04106)
*Fouad Trad,Ali Chehab*

Main category: cs.SE

TL;DR: 检索增强提示在代码漏洞检测任务中显著优于标准少样本提示和微调模型，在20个样本下达到74.05%的F1分数，且无需训练成本。


<details>
  <summary>Details</summary>
Motivation: 少样本提示虽然实用，但其效果严重依赖于上下文示例的选择和质量，特别是在复杂领域如代码漏洞检测中。需要探索更有效的提示策略来提升性能。

Method: 系统评估了三种方法：1) 标准少样本提示（随机选择示例）；2) 检索增强提示（使用语义相似示例）；3) 检索标注（基于检索示例直接标注）。使用Gemini-1.5-Flash模型在代码漏洞检测任务上进行对比。

Result: 检索增强提示在20个样本下达到74.05%的F1分数和83.90%的部分匹配准确率，显著优于标准少样本提示。同时优于零样本提示（F1: 36.35%）和微调的Gemini模型（F1: 59.31%），但低于微调的CodeBERT（F1: 91.22%）。

Conclusion: 检索增强提示在代码漏洞检测中提供了性能与成本的良好平衡，避免了微调的时间和资源消耗，是实际应用中的有效选择。虽然微调CodeBERT性能更高，但需要额外的训练和维护成本。

Abstract: Few-shot prompting has emerged as a practical alternative to fine-tuning for leveraging the capabilities of large language models (LLMs) in specialized tasks. However, its effectiveness depends heavily on the selection and quality of in-context examples, particularly in complex domains. In this work, we examine retrieval-augmented prompting as a strategy to improve few-shot performance in code vulnerability detection, where the goal is to identify one or more security-relevant weaknesses present in a given code snippet from a predefined set of vulnerability categories. We perform a systematic evaluation using the Gemini-1.5-Flash model across three approaches: (1) standard few-shot prompting with randomly selected examples, (2) retrieval-augmented prompting using semantically similar examples, and (3) retrieval-based labeling, which assigns labels based on retrieved examples without model inference. Our results show that retrieval-augmented prompting consistently outperforms the other prompting strategies. At 20 shots, it achieves an F1 score of 74.05% and a partial match accuracy of 83.90%. We further compare this approach against zero-shot prompting and several fine-tuned models, including Gemini-1.5-Flash and smaller open-source models such as DistilBERT, DistilGPT2, and CodeBERT. Retrieval-augmented prompting outperforms both zero-shot (F1 score: 36.35%, partial match accuracy: 20.30%) and fine-tuned Gemini (F1 score: 59.31%, partial match accuracy: 53.10%), while avoiding the training time and cost associated with model fine-tuning. On the other hand, fine-tuning CodeBERT yields higher performance (F1 score: 91.22%, partial match accuracy: 91.30%) but requires additional training, maintenance effort, and resources.

</details>


### [7] [HAI-Eval: Measuring Human-AI Synergy in Collaborative Coding](https://arxiv.org/abs/2512.04111)
*Hanjun Luo,Chiming Ni,Jiaheng Wen,Zhimu Huang,Yiran Wang,Bingduo Liao,Sylvia Chung,Yingbin Jin,Xinfeng Li,Wenyuan Xu,XiaoFeng Wang,Hanan Salam*

Main category: cs.SE

TL;DR: HAI-Eval是一个评估人-AI协作编程能力的基准测试，通过45个模板动态生成任务，显示人-AI协作（31.11%通过率）显著优于单独LLM（0.67%）或单独人类（18.89%）的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估系统（无论是针对人类的传统测试还是针对LLM的基准测试）都未能捕捉到人-AI协作编程的范式转变，它们仍然专注于明确定义的算法问题，而排除了需要人-AI协作才能成功的问题。

Method: 引入HAI-Eval基准测试，核心创新是"协作必要"问题模板（45个），这些任务对单独的LLM和单独的人类都难以解决，但通过有效协作可以解决。提供标准化IDE供人类参与者使用，以及包含450个任务实例的可复现工具包供LLM测试。进行了45名参与者的组内研究，比较了5个最先进LLM在4种不同人类干预水平下的表现。

Result: 单独LLM和单独人类参与者通过率都很低（分别为0.67%和18.89%），而人-AI协作显著提高性能至31.11%。分析揭示了新兴的共同推理伙伴关系，挑战了传统的人-工具层级观念，表明战略突破可以来自人类或AI。

Conclusion: HAI-Eval不仅为下一代编码代理建立了具有挑战性的基准测试，还为AI时代评估核心开发者能力提供了一个基础、可扩展的框架。基准测试和交互演示将公开可用。

Abstract: LLM-powered coding agents are reshaping the development paradigm. However, existing evaluation systems, neither traditional tests for humans nor benchmarks for LLMs, fail to capture this shift. They remain focused on well-defined algorithmic problems, which excludes problems where success depends on human-AI collaboration. Such collaborative problems not only require human reasoning to interpret complex contexts and guide solution strategies, but also demand AI efficiency for implementation. To bridge this gap, we introduce HAI-Eval, a unified benchmark designed to measure the synergy of human-AI partnership in coding. HAI-Eval's core innovation is its "Collaboration-Necessary" problem templates, which are intractable for both standalone LLMs and unaided humans, but solvable through effective collaboration. Specifically, HAI-Eval uses 45 templates to dynamically create tasks. It also provides a standardized IDE for human participants and a reproducible toolkit with 450 task instances for LLMs, ensuring an ecologically valid evaluation. We conduct a within-subject study with 45 participants and benchmark their performance against 5 state-of-the-art LLMs under 4 different levels of human intervention. Results show that standalone LLMs and unaided participants achieve poor pass rates (0.67% and 18.89%), human-AI collaboration significantly improves performance to 31.11%. Our analysis reveals an emerging co-reasoning partnership. This finding challenges the traditional human-tool hierarchy by showing that strategic breakthroughs can originate from either humans or AI. HAI-Eval establishes not only a challenging benchmark for next-generation coding agents but also a grounded, scalable framework for assessing core developer competencies in the AI era. Our benchmark and interactive demo will be openly accessible.

</details>


### [8] [Reusing Model Validation Methods for the Continuous Validation of Digital Twins of Cyber-Physical Systems](https://arxiv.org/abs/2512.04117)
*Joost Mertens,Joachim Denil*

Main category: cs.SE

TL;DR: 提出一种基于模型验证技术的数字孪生系统异常检测方法，通过验证指标检测物理系统变化，并使用参数估计校正数字孪生模型


<details>
  <summary>Details</summary>
Motivation: 数字孪生系统面临的主要挑战是保持数字孪生与物理系统的有效对应关系。对于仿真模型类数字孪生，物理系统会因维护、磨损、用户错误等过程不断演化，需要检测物理系统变化并及时更新数字孪生模型。

Method: 采用基于模型设计的验证技术，提出通用方法：1) 使用验证指标检测孪生系统中的异常；2) 通过历史数据进行参数估计来校正数字孪生模型中的错误。以港口龙门起重机为案例进行验证。

Result: 开发了能够检测数字孪生系统异常的通用方法，并在工业相关案例（龙门起重机）中成功演示了该技术，实现了通过参数估计校正数字孪生模型。

Conclusion: 基于模型验证技术的方法能够有效检测数字孪生系统中的异常，并通过参数估计校正数字孪生模型，确保数字孪生与物理系统保持同步演化。

Abstract: One of the challenges in twinned systems is ensuring the digital twin remains a valid representation of the system it twins. Depending on the type of twinning occurring, it is either trivial, such as in dashboarding/visualizations that mirror the system with real-time data, or challenging, in case the digital twin is a simulation model that reflects the behavior of a physical twinned system. The challenge in this latter case comes from the fact that in contrast to software systems, physical systems are not immutable once deployed, but instead they evolve through processes like maintenance, wear and tear or user error. It is therefore important to detect when changes occur in the physical system to evolve the twin alongside it. We employ and reuse validation techniques from model-based design for this goal. Model validation is one of the steps used to gain trust in the representativeness of a simulation model. In this work, we provide two contributions: (i) we provide a generic approach that, through the use of validation metrics, is able to detect anomalies in twinned systems, and (ii) we demonstrate these techniques with the help of an academic yet industrially relevant case study of a gantry crane such as found in ports. Treating anomalies also means correcting the error in the digital twin, which we do with a parameter estimation based on the historical data.

</details>


### [9] [DrP: Meta's Efficient Investigations Platform at Scale](https://arxiv.org/abs/2512.04250)
*Shubham Somani,Vanish Talwar,Madhura Parikh,Eduardo Hernandez,Jimmy Wang,Shreya Shah,Chinmay Gandhi,Sanjay Sundarajan,Neeru Sharma,Srikanth Kamath,Nitin Gupta,Benjamin Renard,Ohad Yahalom,Chris Davis*

Main category: cs.SE

TL;DR: DrP是一个端到端的自动化调查框架，通过编写代码化的调查剧本（分析器）来减少事故平均解决时间（MTTR）和值班工程师的工作负担。


<details>
  <summary>Details</summary>
Motivation: 大规模系统（如服务、数据、AI/ML、移动等领域）的调查流程通常依赖手动或临时脚本，导致调查效率低下、事故解决时间延长、值班工程师工作负担重且生产力低下。

Method: DrP包含：1）用于编写代码化调查剧本（分析器）的灵活SDK；2）执行这些自动化剧本的可扩展后端系统；3）将剧本集成到警报和事故管理等主流工作流的插件；4）基于调查结果采取行动（包括缓解步骤）的后处理系统。

Result: 在Meta大规模部署5年，覆盖300+团队、2000+分析器，每天执行5万次自动化分析。平均MTTR减少20%（某些团队超过80%），显著提高了值班工程师的生产力。

Conclusion: DrP是一个成功的大规模自动化调查系统，能有效减少事故解决时间并提升值班工程师效率，已在多个领域证明其价值。

Abstract: Investigations are a significant step in the operational workflows for large scale systems across multiple domains such as services, data, AI/ML, mobile. Investigation processes followed by on-call engineers are often manual or rely on ad-hoc scripts. This leads to inefficient investigations resulting in increased time to mitigate and isolate failures/SLO violations. It also contributes to on-call toil and poor productivity leading to multiple hours/days spent in triaging/debugging incidents. In this paper, we present DrP, an end-to-end framework and system to automate investigations that reduces the mean time to resolve incidents (MTTR) and reduces on-call toil. DrP consists of an expressive and flexible SDK to author investigation playbooks in code (called analyzers), a scalable backend system to execute these automated playbooks, plug-ins to integrate playbooks into mainstream workflows such as alerts and incident management tools, and a post-processing system to take actions on investigations including mitigation steps.
  We have implemented and deployed DrP at large scale at Meta covering 300+ teams, 2000+ analyzers, across a large set of use cases across domains such as services, core infrastructure, AI/ML, hardware, mobile. DrP has been running in production for the past 5 years and executes 50K automated analyses per day. Overall, our results and experience show that DrP has been able to reduce average MTTR by 20 percent at large scale (with over 80 percent for some teams) and has significantly improved on-call productivity.

</details>


### [10] [On the Role and Impact of GenAI Tools in Software Engineering Education](https://arxiv.org/abs/2512.04256)
*Qiaolin Qin,Ronnie de Souza Santos,Rodrigo Spinola*

Main category: cs.SE

TL;DR: 软件工程学生使用生成式AI工具进行学习和编程，面临机遇与挑战并存的情况，需要教学指导和伦理规范


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT、GitHub Copilot等生成式AI工具在软件工程领域的普及，研究这些工具如何影响本科生的学习体验、使用模式、面临的挑战以及伦理问题，为教育实践提供指导

Method: 对两所大学的130名本科生进行问卷调查，结合结构化李克特量表和开放式问题，从五个维度（使用情境、感知益处、挑战、伦理和教学认知）进行调查

Result: 学生最常将GenAI用于渐进式学习和高级实现，获得头脑风暴支持和信心建立等益处，同时面临输出逻辑不清晰、难以适应等挑战，关注公平性和学术不端等伦理问题，呼吁更清晰的教学指导

Conclusion: 生成式AI正在以微妙方式重塑软件工程教育，研究发现需要提供教学支架、伦理政策和适应性教学策略，以确保GenAI支持公平有效的学习

Abstract: Context. The rise of generative AI (GenAI) tools like ChatGPT and GitHub Copilot has transformed how software is learned and written. In software engineering (SE) education, these tools offer new opportunities for support, but also raise concerns about over-reliance, ethical use, and impacts on learning. Objective. This study investigates how undergraduate SE students use GenAI tools, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. Method. We conducted a survey with 130 undergraduate students from two universities. The survey combined structured Likert-scale items and open-ended questions to investigate five dimensions: usage context, perceived benefits, challenges, ethical and instructional perceptions. Results. Students most often use GenAI for incremental learning and advanced implementation, reporting benefits such as brainstorming support and confidence-building. At the same time, they face challenges including unclear rationales and difficulty adapting outputs. Students highlight ethical concerns around fairness and misconduct, and call for clearer instructional guidance. Conclusion. GenAI is reshaping SE education in nuanced ways. Our findings underscore the need for scaffolding, ethical policies, and adaptive instructional strategies to ensure that GenAI supports equitable and effective learning.

</details>


### [11] [Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage](https://arxiv.org/abs/2512.04262)
*Nolan Platt,Ethan Luchs,Sehrish Nizamani*

Main category: cs.SE

TL;DR: 研究评估GPT-4o在早期开发阶段进行自动化可用性启发式评估的可靠性和一致性，发现模型在问题检测上表现中等一致性，但在严重性判断上存在较大变异性。


<details>
  <summary>Details</summary>
Motivation: 传统的人工专家启发式评估耗时且主观，特别是在开发早期阶段。本研究旨在探索大型语言模型（LLMs）是否能在开发阶段提供可靠一致的启发式评估，实现自动化可用性测试。

Method: 使用OpenAI的GPT-4o构建评估管道，将Jakob Nielsen的十个可用性启发式原则应用于30个开源网站，每个网站进行三次独立评估，共生成超过850个启发式评估。采用Cohen's Kappa、精确一致性和Krippendorff's Alpha等统计方法分析模型一致性。

Result: 问题检测方面：平均配对Cohen's Kappa为0.50（中等一致性），精确一致性为84%。严重性判断方面：加权Cohen's Kappa平均为0.63，但精确一致性仅为56%，Krippendorff's Alpha接近零。表明GPT-4o在识别可用性问题存在上具有内部一致性，但在严重性判断上变异性较大。

Conclusion: GPT-4o能够产生内部一致的评估，特别是在识别可用性问题存在方面，但其严重性判断能力存在变异性，需要人工监督。研究为早期自动化可用性测试提供了可行性基础和局限性分析，是首批自动化启发式评估的定量评估者间可靠性分析之一。

Abstract: Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen's ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI's GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen's Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen's Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff's Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.

</details>


### [12] [Polynomiogram: An Integrated Framework for Root Visualization and Generative Art](https://arxiv.org/abs/2512.04263)
*Hoang Duc Nguyen,Anh Van Pham,Hien D. Nguyen*

Main category: cs.SE

TL;DR: Polynomiogram框架：一个集成的计算平台，通过灵活采样参数映射到多项式系数，支持多项式根系统的科学研究和生成艺术创作。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的平台，既能支持多项式根系统的科学研究，又能用于生成算法艺术，填补科学探索与艺术创作之间的桥梁。

Method: 采用灵活采样方案，从用户定义域中抽取两个独立参数，通过生成函数映射到多项式系数；集成NumPy伴侣矩阵求解器进行大规模快速计算，以及MPSolve进行高精度验证的双引擎架构。

Result: 验证了数值精度（使用Kac和Lucas多项式），分析了三次多项式系统的分岔结构，展示了作为科学工具和教育辅助的价值，并生成了类似芙蓉花的自然形态和向AI/LLM致敬的个性化艺术作品。

Conclusion: Polynomiogram框架成功地将数学基础与计算工具相结合，既可作为探索根现象的科学工具和代数/动力系统可视化教育辅助，又可作为个性化生成艺术平台，展示了数学与艺术的融合潜力。

Abstract: This work presents the Polynomiogram framework, an integrated computational platform for exploring, visualizing, and generating art from polynomial root systems. The main innovation is a flexible sampling scheme in which two independent parameters are drawn from user defined domains and mapped to the polynomial coefficients through a generating function. This design allows the same mathematical foundation to support both scientific investigation and generative algorithmic art. The framework integrates two complementary numerical engines: NumPy companion matrix solver for fast, large scale computation and MPSolve for high precision, scientifically rigorous validation. This dual architecture enables efficient visualization for creative use and accurate computation for research and education. Numerical accuracy was verified using classical ensembles, including the Kac and Lucas polynomials. The method was applied to the cubic polynomial system to analyze its bifurcation structure, demonstrating its value as both a scientific tool for exploring root phenomena and an educational aid for visualizing fundamental concepts in algebra and dynamical systems. Beyond analysis, the Polynomiogram also demonstrated its potential as a tool for personalized generative art. Examples include the use of the platform to generate a natural form resembling a hibiscus flower and to create personalized artwork expressing gratitude toward advances in artificial intelligence and large language models through a tribute composition.

</details>


### [13] [Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures](https://arxiv.org/abs/2512.04273)
*Tyler Slater*

Main category: cs.SE

TL;DR: 该研究首次提出量化AI生成微服务架构侵蚀和技术债务积累的框架，发现开源模型在架构一致性上表现较差，存在实现懒惰现象，可能加速技术债务积累。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从代码补全工具转变为自主系统架构师，它们对软件长期可维护性的影响尚未量化。现有研究主要关注功能正确性（pass@k），但缺乏对AI合成微服务中"架构侵蚀"和技术债务积累的测量框架。

Method: 采用比较性试点研究，使用三种最先进模型（GPT-5.1、Claude 4.5 Sonnet和Llama 3 8B），在严格的六边形架构约束下实现标准化的图书借阅微服务。利用抽象语法树（AST）解析分析架构一致性。

Result: 专有模型实现高架构一致性（GPT-5.1违规率为0%），而开源模型表现出严重分歧。Llama 3的架构违规率达80%，经常绕过接口适配器创建领域层和基础设施层之间的非法循环依赖。还发现"实现懒惰"现象，开源模型生成的逻辑代码行数比专有模型少60%，省略复杂业务逻辑以满足令牌约束。

Conclusion: 如果没有自动化的架构检查，使用较小的开源模型进行系统脚手架会加速结构性技术债务的积累。研究强调了在AI辅助软件开发中实施架构质量保证的重要性。

Abstract: As Large Language Models (LLMs) transition from code completion tools to autonomous system architects, their impact on long-term software maintainability remains unquantified. While existing research benchmarks functional correctness (pass@k), this study presents the first empirical framework to measure "Architectural Erosion" and the accumulation of Technical Debt in AI-synthesized microservices. We conducted a comparative pilot study of three state-of-the-art models (GPT-5.1, Claude 4.5 Sonnet, and Llama 3 8B) by prompting them to implement a standardized Book Lending Microservice under strict Hexagonal Architecture constraints. Utilizing Abstract Syntax Tree (AST) parsing, we find that while proprietary models achieve high architectural conformance (0% violation rate for GPT-5.1), open-weights models exhibit critical divergence. Specifically, Llama 3 demonstrated an 80% Architectural Violation Rate, frequently bypassing interface adapters to create illegal circular dependencies between Domain and Infrastructure layers. Furthermore, we identified a phenomenon of "Implementation Laziness," where open-weights models generated 60% fewer Logical Lines of Code (LLOC) than their proprietary counterparts, effectively omitting complex business logic to satisfy token constraints. These findings suggest that without automated architectural linting, utilizing smaller open-weights models for system scaffolding accelerates the accumulation of structural technical debt.

</details>


### [14] [MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training](https://arxiv.org/abs/2512.04319)
*Zixiao Zhao,Fatemeh H. Fard,Jie JW Wu*

Main category: cs.SE

TL;DR: MANTRA框架通过多阶段自适应噪声处理，在代码预训练模型和代码LLMs微调过程中嵌入噪声诊断和缓解机制，提升软件工程任务中模型对噪声数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 软件工程任务中深度学习模型的可靠应用依赖于高质量训练数据，但大规模代码库不可避免地包含噪声或错误标签，这会降低模型的准确性和鲁棒性。虽然噪声标签学习在其他领域已有广泛研究，但在软件工程和LLMs应用于SE任务方面的研究较少。

Method: 提出MANTRA多阶段自适应噪声处理框架：1) 研究不同噪声水平对模型收敛和损失轨迹的影响；2) 应用基于样本损失动态和高斯混合模型聚类的自适应dropout策略，排除持续噪声点同时保留干净数据。

Result: 实验应用于代码摘要和提交意图分类任务，发现某些LLMs对噪声更敏感。但使用MANTRA后，所有模型在两个任务中的性能都得到提升，能够减少数据集错误的影响，节省数据清洗时间，最大化微调效果。

Conclusion: MANTRA框架能够有效缓解软件工程任务中训练数据的噪声问题，提升代码预训练模型和LLMs的鲁棒性和性能，为研究者和实践者提供了实用的噪声处理解决方案。

Abstract: The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning.

</details>


### [15] [Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles](https://arxiv.org/abs/2512.04344)
*Zitong Zhou,Ben Limpanukorn,Hong Jin Kang,Jiyuan Wang,Yaoxuan Wu,Akos Kiss,Renata Hodovan,Miryung Kim*

Main category: cs.SE

TL;DR: TargetFuzz：一种针对单个编译器优化的定向模糊测试方法，通过挖掘和重建优化相关的程序结构关系来有效测试优化逻辑


<details>
  <summary>Details</summary>
Motivation: 现有模糊测试器难以有效测试编译器优化：1）使用优化流水线作为测试框架，存在阶段排序问题，会错过优化交互；2）许多优化未被调度；3）优化需要特定的程序结构关系，现有生成器和突变难以产生

Method: 提出针对单个优化的定向模糊测试方法：1）从优化相关语料库中挖掘组合样式（程序构造间的结构关系）；2）通过合成突变在不同上下文中重建这些组合样式；3）基于语法的通用模糊测试器，支持新编程语言的轻量级语法注释

Result: 在LLVM和MLIR上的评估显示：TargetFuzz比基线模糊测试器在定向模式下分别提高覆盖率8%和11%，触发优化次数增加2.8倍和2.6倍；能有效测试所有37个LLVM优化，而流水线模糊测试错过了12个

Conclusion: 定向模糊测试是对流水线测试的有效补充，能更全面地测试编译器优化，特别适用于MLIR等模块化框架的快速演进生态系统

Abstract: Ensuring the correctness of compiler optimizations is critical, but existing fuzzers struggle to test optimizations effectively. First, most fuzzers use optimization pipelines (heuristics-based, fixed sequences of passes) as their harness. The phase-ordering problem can enable or preempt transformations, so pipelines inevitably miss optimization interactions; moreover, many optimizations are not scheduled, even at aggressive levels. Second, optimizations typically fire only when inputs satisfy specific structural relationships, which existing generators and mutations struggle to produce. We propose targeted fuzzing of individual optimizations to complement pipeline-based testing. Our key idea is to exploit composition styles - structural relations over program constructs (adjacency, nesting, repetition, ordering) - that optimizations look for. We build a general-purpose, grammar-based mutational fuzzer, TargetFuzz, that (i) mines composition styles from an optimization-relevant corpus, then (ii) rebuilds them inside different contexts offered by a larger, generic corpus via synthesized mutations to test variations of optimization logic. TargetFuzz is adaptable to a new programming language by lightweight, grammar-based, construct annotations - and it automatically synthesizes mutators and crossovers to rebuild composition styles. No need for hand-coded generators or language-specific mutators, which is particularly useful for modular frameworks such as MLIR, whose dialect-based, rapidly evolving ecosystem makes optimizations difficult to fuzz. Our evaluation on LLVM and MLIR shows that TargetFuzz improves coverage by 8% and 11% and triggers optimizations 2.8$\times$ and 2.6$\times$, compared to baseline fuzzers under the targeted fuzzing mode. We show that targeted fuzzing is complementary: it effectively tests all 37 sampled LLVM optimizations, while pipeline-fuzzing missed 12.

</details>


### [16] [Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration](https://arxiv.org/abs/2512.04445)
*Yanbin Zhang,Hanhui Ye,Yue Bai,Qiming Zhang,Liao Xiang,Wu Mianzhi,Renjun Hu*

Main category: cs.SE

TL;DR: AutoDW是一个支持多步骤、可回滚的文档工作流自动化框架，通过增量规划和多级回滚机制，在复杂文档处理任务中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统只能执行孤立指令，难以自动化多步骤、会话级的工作流，因为缺乏对操作过程的控制能力。文档处理中的长时程工作流需要更强大的执行框架。

Method: AutoDW采用增量规划方法，基于用户指令、意图过滤的API候选和文档演化状态逐步规划API操作。同时设计了参数级和API级的回滚机制，支持动态纠错和容错。

Result: 在包含250个会话和1,708条人工标注指令的基准测试中，AutoDW在指令级和会话级任务上分别达到90%和62%的完成率，比强基线分别高出40%和76%。框架对骨干LLM的选择和任务难度变化都表现出鲁棒性。

Conclusion: AutoDW通过增量规划和多级回滚机制，能够有效处理复杂的长时程文档工作流，显著提升自动化系统的执行能力和容错性，为文档处理自动化提供了新的解决方案。

Abstract: Workflow automation promises substantial productivity gains in everyday document-related tasks. While prior agentic systems can execute isolated instructions, they struggle with automating multi-step, session-level workflows due to limited control over the operational process. To this end, we introduce AutoDW, a novel execution framework that enables stepwise, rollback-enabled operation orchestration. AutoDW incrementally plans API actions conditioned on user instructions, intent-filtered API candidates, and the evolving states of the document. It further employs robust rollback mechanisms at both the argument and API levels, enabling dynamic correction and fault tolerance. These designs together ensure that the execution trajectory of AutoDW remains aligned with user intent and document context across long-horizon workflows. To assess its effectiveness, we construct a comprehensive benchmark of 250 sessions and 1,708 human-annotated instructions, reflecting realistic document processing scenarios with interdependent instructions. AutoDW achieves 90% and 62% completion rates on instruction- and session-level tasks, respectively, outperforming strong baselines by 40% and 76%. Moreover, AutoDW also remains robust for the decision of backbone LLMs and on tasks with varying difficulty. Code and data will be open-sourced. Code: https://github.com/YJett/AutoDW

</details>


### [17] [LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models](https://arxiv.org/abs/2512.04474)
*Jiaqi Sun,Wei Li,Heng Zhang,Chutong Ding,Shiyou Qian,Jian Cao,Guangtao Xue*

Main category: cs.SE

TL;DR: LLM-SrcLog：一种主动统一的日志模板解析框架，结合源码分析和数据驱动方法，在准确性和速度上取得理想平衡


<details>
  <summary>Details</summary>
Motivation: 现有日志解析器大多是反应式和日志中心的，仅从日志推断模板，忽略了源代码，限制了理解动态日志结构或适应系统演进的能力。同时，基于每条日志的LLM推理成本过高，难以实际部署。

Method: 提出LLM-SrcLog框架：1）部署前直接从源代码提取模板；2）对无可用代码的日志补充数据驱动解析。具体包括：跨函数静态代码分析器重建有意义的日志上下文，基于LLM的白盒模板提取器区分常量与变量，黑盒模板提取器结合数据驱动聚类处理剩余未匹配日志。

Result: 在两个公共基准测试（Hadoop和Zookeeper）和一个大规模工业系统（Sunfire-Compute）上的实验表明：相比两个基于LLM的基线方法，LLM-SrcLog将平均F1分数提高了2-17%和8-35%。在线解析延迟与数据驱动方法相当，比每条日志的LLM解析快约1000倍。

Conclusion: LLM-SrcLog在速度和准确性之间实现了近乎理想的平衡，并通过实际生产环境案例研究进一步验证了其有效性。该框架为日志解析提供了主动、统一的解决方案。

Abstract: Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.

</details>


### [18] [Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding](https://arxiv.org/abs/2512.04538)
*Xinkui Zhao,Rongkai Liu,Yifan Zhang,Chen Zhi,Lufei Zhang,Guanjie Cheng,Yueshen Xu,Shuiguang Deng,Jianwei Yin*

Main category: cs.SE

TL;DR: CoCo是一个通过理解多粒度上下文进行代码补全的新框架，利用静态代码分析提取结构化上下文，采用基于图的多粒度上下文选择机制，并通过结构感知的代码重排器确保语义和结构对齐，在代码补全任务上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法通常将代码视为纯自然语言，主要依赖浅层语义匹配，忽视了结构语义和代码特定依赖关系，这限制了它们捕捉控制流和底层意图的能力，从而制约了生成代码的质量。

Method: CoCo采用静态代码分析提取函数、文件和项目级别的结构化上下文，捕捉执行逻辑和语义依赖；使用基于图的多粒度上下文选择机制过滤冗余信息和噪声；将信息一致地转换为自然语言作为显式上下文提示；采用结构感知的代码重排器确保语义和结构对齐。

Result: 在CrossCodeEval和RepoEval基准测试上的大量实验表明，CoCo始终超越最先进的基线方法，在EM指标上实现了高达20.2%的提升。该框架是模型无关的，可以无缝集成到现有方法中，带来显著的性能提升。

Conclusion: CoCo通过理解多粒度上下文有效提升了代码补全质量，其静态代码分析和基于图的选择机制能够更好地捕捉代码的结构语义和依赖关系，为从函数级到仓库级的代码补全任务提供了有效的解决方案。

Abstract: As code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.

</details>


### [19] [Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models](https://arxiv.org/abs/2512.04673)
*Gunjan Das,Paheli Bhattacharya,Rishabh Gupta*

Main category: cs.SE

TL;DR: 本文对通用和代码专用LLM进行了跨领域系统评估，发现代码优化模型在推理和句法精度方面表现优异，甚至在非编码任务中也能带来性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在通用NLP和领域特定应用（如代码合成、法律推理、金融）中取得了革命性进展，但先前研究主要关注单个模型能力，缺乏对语言、推理和代码理解能力的系统性跨领域比较。

Method: 对5个通用目的和3个代码专用最先进LLM进行全面评估，涵盖6个多样化基准测试（语言能力、数学推理、可信度），并分析模型在CoNaLa数据集上的代码解释行为，比较自然语言和代码专用LLM。

Result: 代码优化模型（如CodeLLaMA变体）展现出强大的推理能力和句法精度，即使在非编码任务中也能显示出可测量的性能提升，这与Mistral-7B和Llama-3-8B等通用模型形成对比。

Conclusion: 代码专用LLM在跨领域评估中表现出色，其推理和句法精度优势不仅限于代码任务，还能提升通用任务性能，这为模型选择和优化提供了重要见解。

Abstract: Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model capabilities, a systematic cross-domain comparison that unifies linguistic, reasoning, and code understanding abilities remains underexplored. In this work, we present a comprehensive evaluation of five general-purpose and three code-specific state-of-the-art LLMs across six diverse benchmarks encompassing linguistic competence, mathematical reasoning, and trustworthiness. Additionally, we analyze model behavior on the CoNaLa dataset for code explanation, comparing natural language and code-specialized LLMs. Our findings reveal that models optimized for code (e.g., CodeLLaMA variants) exhibit strong reasoning and syntactic precision, that even for non-coding tasks can show measurable performance gains, in contrast to general-purpose models like Mistral-7B and Llama-3-8B.

</details>


### [20] [Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap](https://arxiv.org/abs/2512.04680)
*Jialong Li,Mingyue Zhang,Nianyu Li,Danny Weyns,Zhi Jin,Kenji Tei*

Main category: cs.SE

TL;DR: 论文探讨了将生成式AI（特别是大语言模型）应用于自适应系统的潜在益处与挑战，分析了其对MAPE-K反馈循环功能和人机交互的增强作用，并提出了研究路线图。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在数据理解和逻辑推理方面表现出色，这些能力与自适应系统（SAS）所需的监控、分析、规划、执行功能高度契合。然而，将GenAI应用于SAS的具体益处和挑战尚不明确，且由于SAS领域出版物有限、技术应用多样性以及GenAI技术快速演进，全面理解这些问题变得复杂。

Method: 从四个不同研究领域收集、筛选和分析文献，将其组织为两个主要类别：1）围绕MAPE-K反馈循环特定功能的自适应系统自主性增强；2）人在回路设置中人与自适应系统交互的改进。

Result: 研究提出了一个整合GenAI到SAS的研究路线图，突出了需要解决的关键研究挑战，并阐述了当前GenAI的不足及可能的缓解策略。

Conclusion: 生成式AI有潜力显著增强自适应系统的自主性和人机交互能力，但需要解决特定的技术挑战和研究问题才能充分发挥其潜力。论文为研究者和实践者提供了全面的现状分析和未来研究方向。

Abstract: Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.

</details>


### [21] [POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?](https://arxiv.org/abs/2512.04702)
*Divyansh Pandey,Vyakhya Gupta,Prakhar Singhal,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: POLARIS是一个三层多智能体自适应框架，通过整合监控执行、透明推理和元学习层，超越传统反应式自适应，实现预测性和主动性的系统行为


<details>
  <summary>Details</summary>
Motivation: 现代软件生态系统的规模、复杂性、互连性和自主性不断增加，引入了前所未有的不确定性，挑战了传统自适应方法的基础。现有方法（通常是规则驱动的控制器或孤立的学习组件）难以泛化到新环境或协调分布式子系统的响应，无法应对"未知的未知"问题

Method: 提出POLARIS三层多智能体自适应框架：1) 低延迟适配层：用于监控和安全执行；2) 透明推理层：使用工具感知、可解释的智能体生成和验证计划；3) 元层：记录经验并随时间元学习改进的自适应策略。通过共享知识和预测模型处理不确定性

Result: 在SWIM和SWITCH两个自适应示例上的初步评估表明，POLARIS始终优于最先进的基线方法

Conclusion: POLARIS标志着向"自适应3.0"的转变，类似于"软件3.0"：系统不仅从环境中学习，还能推理和演化自身的自适应过程，持续改进以应对新挑战

Abstract: The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal partnership between AI and adaptive systems, merging learning-driven intelligence with adaptive control for predictive and proactive behavior. Building on this foundation, we introduce POLARIS, a three-layer multi-agentic self-adaptation framework that advances beyond reactive adaptation. POLARIS integrates: (1) a low-latency Adapter layer for monitoring and safe execution, (2) a transparent Reasoning layer that generates and verifies plans using tool-aware, explainable agents, and (3) a Meta layer that records experiences and meta-learns improved adaptation policies over time. Through shared knowledge and predictive models, POLARIS handles uncertainty, learns from past actions, and evolves its strategies, enabling systems that anticipate change and maintain resilient, goal-directed behavior. Preliminary evaluation on two self-adaptive exemplars, SWIM and SWITCH, shows that POLARIS consistently outperforms state-of-the-art baselines. We argue this marks a shift toward Self-Adaptation 3.0, akin to Software 3.0: a paradigm where systems not only learn from their environment but also reason about and evolve their own adaptation processes, continuously improving to meet novel challenges.

</details>


### [22] [Configuration Defects in Kubernetes](https://arxiv.org/abs/2512.05062)
*Yue Zhang,Uchswas Paul,Marcelo d'Amorim,Akond Rahman*

Main category: cs.SE

TL;DR: 对Kubernetes配置缺陷的实证研究，分析了719个缺陷，识别15个类别，评估现有静态分析工具，并开发了能检测严重缺陷的新linter工具。


<details>
  <summary>Details</summary>
Motivation: Kubernetes配置容易出错，配置缺陷可能导致严重后果，但目前缺乏对这些缺陷的系统性研究。本文旨在帮助从业者检测和预防Kubernetes配置缺陷。

Method: 从2,260个Kubernetes配置脚本中提取719个缺陷，通过定性分析识别15个缺陷类别，评估8个公开可用的静态分析工具，并开发新的linter工具来检测现有工具无法发现的严重缺陷。

Result: 发现现有工具只能检测15个缺陷类别中的8个，对数据字段相关缺陷的检测精度和召回率最高。新开发的linter发现了26个先前未知的缺陷，其中19个已被修复。

Conclusion: 提供了关于如何将缺陷检测和修复技术应用于Kubernetes配置脚本的建议，并公开了数据集和源代码供进一步研究使用。

Abstract: Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online.

</details>
