<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 19]
- [cs.LO](#cs.LO) [Total: 11]
- [cs.PL](#cs.PL) [Total: 6]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Git Context Controller: Manage the Context of LLM-based Agents like Git](https://arxiv.org/abs/2508.00031)
*Junde Wu*

Main category: cs.SE

TL;DR: GCC是一个基于Git启发的上下文管理框架，帮助LLM代理在长期任务中高效管理上下文，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM代理在长期任务中面临上下文管理的瓶颈，需要一种结构化方法来管理记忆和任务状态。

Method: GCC将代理记忆结构化为类似Git的版本控制系统，支持COMMIT、BRANCH、MERGE等操作，实现里程碑检查点和结构化反思。

Result: 在SWE-Bench-Lite基准测试中，GCC代理解决了48.00%的软件错误，优于26个竞争系统；在自复制案例中，任务解决率从11.7%提升至40.7%。

Conclusion: GCC显著提升了LLM代理在长期任务中的上下文管理能力，为复杂工作流提供了高效解决方案。

Abstract: Large language model (LLM) based agents have shown impressive capabilities by
interleaving internal reasoning with external tool use. However, as these
agents are deployed in long-horizon workflows, such as coding for a big,
long-term project, context management becomes a critical bottleneck. We
introduce Git-Context-Controller (GCC), a structured context management
framework inspired by software version control systems. GCC elevates context as
versioned memory hierarchy like Git. It structures agent memory as a persistent
file system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,
enabling milestone-based checkpointing, exploration of alternative plans, and
structured reflection. Our approach empowers agents to manage long-term goals,
isolate architectural experiments, and recover or hand off memory across
sessions and agents. Empirically, agents equipped with GCC achieve
state-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00
of software bugs, outperforming 26 competitive systems. In a self-replication
case study, a GCC-augmented agent builds a new CLI agent from scratch,
achieving 40.7 task resolution, compared to only 11.7 without GCC. The code is
released at: https://github.com/theworldofagents/GCC

</details>


### [2] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
*Nuno Fachada,Daniel Fernandes,Carlos M. Fernandes,Bruno D. Ferreira-Saraiva,João P. Matos-Carvalho*

Main category: cs.SE

TL;DR: 该研究系统评估了大型语言模型（LLMs）在生成复杂Python代码时的表现，发现仅有少数模型（如GPT-4.1）能稳定生成正确代码，同时揭示了第三方库文档和实现中的问题。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在科学计算中生成代码的能力，尤其是对不熟悉API的使用情况，以推动科学自动化的发展。

Method: 通过零样本提示，测试LLMs在两种复杂任务（数据分析和合成数据生成）中的表现，定量和定性分析生成代码的功能正确性和错误。

Result: 仅少数模型（如GPT-4.1）能稳定生成正确代码，同时发现第三方库文档和实现中的问题。

Conclusion: LLMs在科学自动化中仍有局限，需改进提示设计、库文档和模型能力。

Abstract: Large Language Models (LLMs) have advanced rapidly as tools for automating
code generation in scientific research, yet their ability to interpret and use
unfamiliar Python APIs for complex computational experiments remains poorly
characterized. This study systematically benchmarks a selection of
state-of-the-art LLMs in generating functional Python code for two increasingly
challenging scenarios: conversational data analysis with the \textit{ParShift}
library, and synthetic data generation and clustering using \textit{pyclugen}
and \textit{scikit-learn}. Both experiments use structured, zero-shot prompts
specifying detailed requirements but omitting in-context examples. Model
outputs are evaluated quantitatively for functional correctness and prompt
compliance over multiple runs, and qualitatively by analyzing the errors
produced when code execution fails. Results show that only a small subset of
models consistently generate correct, executable code, with GPT-4.1 standing
out as the only model to always succeed in both tasks. In addition to
benchmarking LLM performance, this approach helps identify shortcomings in
third-party libraries, such as unclear documentation or obscure implementation
bugs. Overall, these findings highlight current limitations of LLMs for
end-to-end scientific automation and emphasize the need for careful prompt
design, comprehensive library documentation, and continued advances in language
model capabilities.

</details>


### [3] [Machine Learning Pipeline for Software Engineering: A Systematic Literature Review](https://arxiv.org/abs/2508.00045)
*Samah Kansab*

Main category: cs.SE

TL;DR: 本文通过系统文献综述（SLR）探讨了机器学习（ML）在软件工程（SE）中的应用，总结了最佳实践、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂度的增加，传统方法难以满足质量和效率需求，ML成为解决SE问题的关键工具。

Method: 通过SLR分析ML在SE中的流程，包括数据预处理、特征工程、算法选择和验证。

Result: 研究发现，数据平衡（如SMOTE）、特征选择（如SZZ）和集成方法（如随机森林）显著提升模型性能。

Conclusion: 设计良好的ML流程对优化SE至关重要，本文为研究者和实践者提供了实用建议，并指出了未来研究方向。

Abstract: The rapid advancement of software development practices has introduced
challenges in ensuring quality and efficiency across the software engineering
(SE) lifecycle. As SE systems grow in complexity, traditional approaches often
fail to scale, resulting in longer debugging times, inefficient defect
detection, and resource-heavy development cycles. Machine Learning (ML) has
emerged as a key solution, enabling automation in tasks such as defect
prediction, code review, and release quality estimation. However, the
effectiveness of ML in SE depends on the robustness of its pipeline, including
data collection, preprocessing, feature engineering, algorithm selection,
validation, and evaluation.
  This systematic literature review (SLR) examines state-of-the-art ML
pipelines designed for SE, consolidating best practices, challenges, and gaps.
Our findings show that robust preprocessing, such as SMOTE for data balancing
and SZZ-based algorithms for feature selection, improves model reliability.
Ensemble methods like Random Forest and Gradient Boosting dominate performance
across tasks, while simpler models such as Naive Bayes remain valuable for
efficiency and interpretability. Evaluation metrics including AUC, F1-score,
and precision are most common, with new metrics like Best Arithmetic Mean (BAM)
emerging in niche applications. Validation techniques such as bootstrapping are
widely used to ensure model stability and generalizability.
  This SLR highlights the importance of well-designed ML pipelines for
addressing SE challenges and provides actionable insights for researchers and
practitioners seeking to optimize software quality and efficiency. By
identifying gaps and trends, this study sets a foundation for advancing ML
adoption and fostering innovation in increasingly complex development
environments.

</details>


### [4] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
*Yihong Dong,Xue Jiang,Jiaru Qian,Tian Wang,Kechi Zhang,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: 本文系统综述了基于大语言模型（LLM）的代码生成代理，总结了其核心特征、技术分类、应用场景、评估工具及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨代码生成代理如何通过自主性、任务范围扩展和工程实用性提升，革新软件开发范式。

Method: 通过系统性调查，分类单代理和多代理架构，并分析其在软件开发生命周期中的应用。

Result: 总结了主流评估基准和工具，展示了该领域的快速发展和应用潜力。

Conclusion: 提出了该领域的基础性、长期研究方向，以应对当前挑战。

Abstract: Code generation agents powered by large language models (LLMs) are
revolutionizing the software development paradigm. Distinct from previous code
generation techniques, code generation agents are characterized by three core
features. 1) Autonomy: the ability to independently manage the entire workflow,
from task decomposition to coding and debugging. 2) Expanded task scope:
capabilities that extend beyond generating code snippets to encompass the full
software development lifecycle (SDLC). 3) Enhancement of engineering
practicality: a shift in research emphasis from algorithmic innovation toward
practical engineering challenges, such as system reliability, process
management, and tool integration. This domain has recently witnessed rapid
development and an explosion in research, demonstrating significant application
potential. This paper presents a systematic survey of the field of LLM-based
code generation agents. We trace the technology's developmental trajectory from
its inception and systematically categorize its core techniques, including both
single-agent and multi-agent architectures. Furthermore, this survey details
the applications of LLM-based agents across the full SDLC, summarizes
mainstream evaluation benchmarks and metrics, and catalogs representative
tools. Finally, by analyzing the primary challenges, we identify and propose
several foundational, long-term research directions for the future work of the
field.

</details>


### [5] [Tool-Assisted Conformance Checking to Reference Process Models](https://arxiv.org/abs/2508.00738)
*Bernhard Rumpe,Max Stachon,Sebastian Stüber,Valdes Voufo*

Main category: cs.SE

TL;DR: 本文提出了一种基于因果依赖分析的自动化一致性检查方法，用于验证具体流程模型与参考模型的一致性，填补了语义模型比较的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性检查方法缺乏语义模型比较的表达能力和自动化能力，无法满足需求。

Method: 采用因果依赖分析任务和事件，提出算法并集成到语义框架中。

Result: 通过案例研究验证了方法的有效性，提高了准确性和灵活性。

Conclusion: 研究提供了一种工具辅助解决方案，增强了流程模型一致性验证的能力。

Abstract: Reference models convey best practices and standards. The reference
frameworks necessitate conformance checks to ensure adherence to established
guidelines and principles, which is crucial for maintaining quality and
consistency in various processes. This paper explores automated conformance
checks for concrete process models against reference models using causal
dependency analysis of tasks and events. Existing notions of conformance
checking for process models focus on verifying process execution traces and
lack the expressiveness and automation needed for semantic model comparison,
leaving this question unresolved. We integrate our approach into a broader
semantic framework for defining reference model conformance. We outline an
algorithm for reference process model conformance checking, evaluate it through
a case study, and discuss its strengths and limitations. Our research provides
a tool-assisted solution enhancing accuracy and flexibility in process model
conformance verification.

</details>


### [6] [How Quantization Impacts Privacy Risk on LLMs for Code?](https://arxiv.org/abs/2508.00128)
*Md Nazmul Haque,Hua Yang,Zhou Yang,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术显著降低代码大语言模型的隐私风险，同时揭示了任务性能与隐私风险之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 研究量化技术对代码大语言模型（LLMs4Code）任务性能和隐私风险的影响，以指导实际部署中的隐私保护。

Method: 对Pythia、CodeGen和GPTNeo三种模型家族应用静态和动态量化技术，分析量化对隐私风险和任务性能的影响。

Result: 量化显著降低隐私风险，并发现任务性能与隐私风险正相关；量化大模型可能比小模型更优。

Conclusion: 量化是降低LLMs4Code隐私风险的有效方法，研究结果为部署压缩模型提供了实用指导。

Abstract: Large language models for code (LLMs4Code) rely heavily on massive training
data, including sensitive data, such as cloud service credentials of the
projects and personal identifiable information of the developers, raising
serious privacy concerns. Membership inference (MI) has recently emerged as an
effective tool for assessing privacy risk by identifying whether specific data
belong to a model's training set. In parallel, model compression techniques,
especially quantization, have gained traction for reducing computational costs
and enabling the deployment of large models. However, while quantized models
still retain knowledge learned from the original training data, it remains
unclear whether quantization affects their ability to retain and expose privacy
information. Answering this question is of great importance to understanding
privacy risks in real-world deployments. In this work, we conduct the first
empirical study on how quantization influences task performance and privacy
risk simultaneously in LLMs4Code. To do this, we implement widely used
quantization techniques (static and dynamic) to three representative model
families, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that
quantization has a significant impact on reducing the privacy risk relative to
the original model. We also uncover a positive correlation between task
performance and privacy risk, indicating an underlying tradeoff. Moreover, we
reveal the possibility that quantizing larger models could yield better balance
than using full-precision small models. Finally, we demonstrate that these
findings generalize across different architectures, model sizes and MI methods,
offering practical guidance for safeguarding privacy when deploying compressed
LLMs4Code.

</details>


### [7] [Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures](https://arxiv.org/abs/2508.00749)
*Johanna Grahl,Bernhard Rumpe,Max Stachon,Sebastian Stüber*

Main category: cs.SE

TL;DR: 本文研究了动态符号执行（DSE）在组件-连接器架构语义差异分析中的应用，通过增强MontiArc模型生成器，收集运行时数据以识别关键执行轨迹。评估了不同执行策略，发现DSE潜力显著但可扩展性受限。


<details>
  <summary>Details</summary>
Motivation: 在模型驱动开发中，确保模型正确性和一致性至关重要，因此需要探索有效的语义差异分析方法。

Method: 增强MontiArc-to-Java生成器，收集符号和具体执行数据，分析执行轨迹，评估不同执行策略的效率、最小性和完整性。

Result: DSE在组件-连接器架构分析中表现出潜力，但可扩展性是其主要限制。

Conclusion: DSE在语义差异分析中具有应用前景，但需进一步研究以提升其在大规模系统中的实用性。

Abstract: In the context of model-driven development, ensuring the correctness and
consistency of evolving models is paramount. This paper investigates the
application of Dynamic Symbolic Execution (DSE) for semantic difference
analysis of component-and-connector architectures, specifically utilizing
MontiArc models. We have enhanced the existing MontiArc-to-Java generator to
gather both symbolic and concrete execution data at runtime, encompassing
transition conditions, visited states, and internal variables of automata. This
data facilitates the identification of significant execution traces that
provide critical insights into system behavior. We evaluate various execution
strategies based on the criteria of runtime efficiency, minimality, and
completeness, establishing a framework for assessing the applicability of DSE
in semantic difference analysis. Our findings indicate that while DSE shows
promise for analyzing component and connector architectures, scalability
remains a primary limitation, suggesting further research is needed to enhance
its practical utility in larger systems.

</details>


### [8] [Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems](https://arxiv.org/abs/2508.00198)
*Cleyton Magalhaes,Italo Santos,Brody Stuart-Verner,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 论文探讨了在现实应用开发中如何测试基于大语言模型（LLM）的系统，发现测试策略结合了手动和自动方法，并面临集成失败、输出不可预测等挑战。


<details>
  <summary>Details</summary>
Motivation: 研究背景是LLM系统在日常技术中广泛应用，但对其测试方法的关注有限。目标是探索实际开发中LLM系统的测试实践。

Method: 通过分析99份学生报告，采用主题分析和结构化编码进行探索性案例研究。

Result: 测试策略结合手动与自动方法，常见实践包括探索性测试、单元测试和提示迭代。挑战包括集成失败、输出不可预测等。

Conclusion: 测试LLM系统需调整传统验证方法，结合源代码推理和行为感知评估，为生成组件测试提供实践参考。

Abstract: Background: Software systems powered by large language models are becoming a
routine part of everyday technologies, supporting applications across a wide
range of domains. In software engineering, many studies have focused on how
LLMs support tasks such as code generation, debugging, and documentation.
However, there has been limited focus on how full systems that integrate LLMs
are tested during development. Aims: This study explores how LLM-powered
systems are tested in the context of real-world application development.
Method: We conducted an exploratory case study using 99 individual reports
written by students who built and deployed LLM-powered applications as part of
a university course. Each report was independently analyzed using thematic
analysis, supported by a structured coding process. Results: Testing strategies
combined manual and automated methods to evaluate both system logic and model
behavior. Common practices included exploratory testing, unit testing, and
prompt iteration. Reported challenges included integration failures,
unpredictable outputs, prompt sensitivity, hallucinations, and uncertainty
about correctness. Conclusions: Testing LLM-powered systems required
adaptations to traditional verification methods, blending source-level
reasoning with behavior-aware evaluations. These findings provide evidence on
the practical context of testing generative components in software systems.

</details>


### [9] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
*Briza Mel Dias de Sousa,Renato Cordeiro Ferreira,Alfredo Goldman*

Main category: cs.SE

TL;DR: 比较面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响，通过Kotlin（OOP）和Scala（FP）实现数字钱包系统，结合定性和定量分析。


<details>
  <summary>Details</summary>
Motivation: 研究OOP和FP在软件架构中的实际影响，帮助开发者和组织选择更适合的编程范式。

Method: 通过Kotlin和Scala实现数字钱包系统，进行定性（自民族志）和定量（开发者调查）分析。

Result: 定性分析揭示了编写代码的视角，定量分析展示了开发者对代码的阅读体验。

Conclusion: 研究结果为开发者和组织在选择编程范式时提供了参考依据。

Abstract: After decades of dominance by object-oriented programming (OOP), functional
programming (FP) is gaining increasing attention in the software industry. This
study compares the impact of OOP and FP on the architectural characteristics of
software systems. For that, it examines the design and implementation of a
Digital Wallet system, developed in Kotlin (representing OOP) and Scala
(representing FP). The comparison is made through both qualitative and
quantitative analyses to explore how each paradigm influences the system's
architectural characteristics. The self-ethnographic qualitative analysis
provides a side-by-side comparison of both implementations, revealing the
perspective of those writing such code. The survey-based quantitative analysis
gathers feedback from developers with diverse backgrounds, showing their
impressions of those reading this code. Hopefully, these results may be useful
for developers or organizations seeking to make more informed decisions about
which paradigm is best suited for their next project.

</details>


### [10] [Leveraging Large Language Model for Information Retrieval-based Bug Localization](https://arxiv.org/abs/2508.00253)
*Moumita Asad,Rafed Muhammad Yasir,Armin Geramirad,Sam Malek*

Main category: cs.SE

TL;DR: GenLoc是一种基于大型语言模型（LLM）的缺陷定位方法，通过代码探索功能迭代分析代码库，有效解决了缺陷报告与源代码之间的词汇不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有缺陷定位方法（从向量空间模型到深度学习模型）的有效性受限于缺陷报告与源代码之间的词汇不匹配问题。

Method: GenLoc利用配备代码探索功能的LLM，迭代分析代码库并识别潜在缺陷文件，还可通过向量嵌入检索语义相关文件以获取更好的上下文。

Result: 在6个大型Java项目的9,000多个真实缺陷报告上测试，GenLoc在多项指标上优于5种最先进的缺陷定位技术，Accuracy@1平均提升超过60%。

Conclusion: GenLoc通过LLM和代码探索功能显著提升了缺陷定位的准确性和效率。

Abstract: Information Retrieval-based Bug Localization aims to identify buggy source
files for a given bug report. While existing approaches -- ranging from vector
space models to deep learning models -- have shown potential in this domain,
their effectiveness is often limited by the vocabulary mismatch between bug
reports and source code. To address this issue, we propose a novel Large
Language Model (LLM) based bug localization approach, called GenLoc. Given a
bug report, GenLoc leverages an LLM equipped with code-exploration functions to
iteratively analyze the code base and identify potential buggy files. To gather
better context, GenLoc may optionally retrieve semantically relevant files
using vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug
reports from six large-scale Java projects. Experimental results show that
GenLoc outperforms five state-of-the-art bug localization techniques across
multiple metrics, achieving an average improvement of more than 60\% in
Accuracy@1.

</details>


### [11] [Accurate and Consistent Graph Model Generation from Text with Large Language Models](https://arxiv.org/abs/2508.00255)
*Boqi Chen,Ou Wei,Bingzhou Zheng,Gunter Mussbacher*

Main category: cs.SE

TL;DR: 提出了一种基于抽象-具体化框架的方法，通过聚合多个LLM输出生成更一致和高质量的图模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成图模型时的语法违规、约束不一致和准确性不足问题。

Method: 采用抽象-具体化框架，聚合多个LLM输出并优化为满足约束的具体模型。

Result: 实验表明，该方法显著提升了生成图模型的一致性和质量。

Conclusion: 提出的框架有效解决了LLM生成图模型的三大问题，提升了实用性。

Abstract: Graph model generation from natural language description is an important task
with many applications in software engineering. With the rise of large language
models (LLMs), there is a growing interest in using LLMs for graph model
generation. Nevertheless, LLM-based graph model generation typically produces
partially correct models that suffer from three main issues: (1) syntax
violations: the generated model may not adhere to the syntax defined by its
metamodel, (2) constraint inconsistencies: the structure of the model might not
conform to some domain-specific constraints, and (3) inaccuracy: due to the
inherent uncertainty in LLMs, the models can include inaccurate, hallucinated
elements. While the first issue is often addressed through techniques such as
constraint decoding or filtering, the latter two remain largely unaddressed.
Motivated by recent self-consistency approaches in LLMs, we propose a novel
abstraction-concretization framework that enhances the consistency and quality
of generated graph models by considering multiple outputs from an LLM. Our
approach first constructs a probabilistic partial model that aggregates all
candidate outputs and then refines this partial model into the most appropriate
concrete model that satisfies all constraints. We evaluate our framework on
several popular open-source and closed-source LLMs using diverse datasets for
model generation tasks. The results demonstrate that our approach significantly
improves both the consistency and quality of the generated graph models.

</details>


### [12] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
*Panagiotis Diamantakis,Thanassis Avgerinos,Yannis Smaragdakis*

Main category: cs.SE

TL;DR: Desyan平台无缝整合了值流分析和符号推理，提供高效的程序分析工具。


<details>
  <summary>Details</summary>
Motivation: 解决值流分析和符号分析长期分离的问题，提供统一的平台。

Method: 扩展Soufflé Datalog引擎，集成SMT求解器，支持多种推理模式。

Result: Desyan在值流分析中表现卓越，符号推理时速度显著提升。

Conclusion: Desyan为程序分析提供了灵活高效的统一平台。

Abstract: Over the past two decades, two different types of static analyses have
emerged as dominant paradigms both in academia and industry: value-flow
analysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis
(e.g., symbolic execution). Despite their individual successes in numerous
application fields, the two approaches have remained largely separate; an
artifact of the simple reality that there is no broadly adopted unifying
platform for effortless and efficient integration of symbolic techniques with
high-performance data-flow reasoning.
  To bridge this gap, we introduce Desyan: a platform for writing program
analyses with seamless integration of value-flow and symbolic reasoning. Desyan
expands a production-ready Datalog fixpoint engine (Souffl\'e) with
full-fledged SMT solving invoking industry-leading SMT engines. Desyan provides
constructs for automatically (and efficiently!) handling typical patterns that
come up in program analysis. At the same time, the integration is agnostic with
respect to the solving technology, and supports Datalog-native symbolic
reasoning, via a bottom-up algebraic reasoning module.
  The result is an engine that allows blending different kinds of reasoning, as
needed for the underlying analysis. For value-flow analysis, the engine is the
best-in-class Datalog evaluator (often by a factor of over 20x in execution
time); for applications that require full SMT (e.g., a concolic execution
engine or other symbolic evaluator that needs to solve arbitrarily complex
conditions), the engine is leveraging the leading SMT solvers; for lightweight
symbolic evaluation (e.g., solving simple conditionals in the context of a
path-sensitive analysis), the engine can use Datalog-native symbolic reasoning,
achieving large speedups (often of over 2x) compared to eagerly appealing to an
SMT solver.

</details>


### [13] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
*Dong Huang,Jie M. Zhang,Mark Harman,Qianru Zhang,Mingzhe Du,See-Kiong Ng*

Main category: cs.SE

TL;DR: 论文提出了ULT（UnLeakedTestbench）基准，用于更真实地评估大语言模型（LLM）在单元测试生成中的能力，解决了现有基准的数据污染和结构简单性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成基准存在数据污染和结构过于简单的问题，导致科学结论的可靠性不足。

Method: 通过多阶段筛选过程构建ULT基准，包含3,909个高复杂度的真实Python函数任务，并引入PLT基准进行对比分析。

Result: ULT基准显著更具挑战性，LLM生成的测试用例在准确率、语句覆盖率、分支覆盖率和变异分数上表现明显低于其他基准。

Conclusion: ULT提供了一个更真实和严格的评估框架，有助于更准确地衡量LLM在测试生成中的能力。

Abstract: Recently, large language models (LLMs) have shown great promise in automating
unit test generation, significantly reducing the manual effort required by
developers. To effectively evaluate the capabilities of LLMs in this domain, it
is crucial to have a well-designed benchmark that accurately reflects
real-world scenarios and mitigates common pitfalls. Existing LLM test
generation benchmarks are limited by two critical drawbacks: data contamination
and structurally simple function code. As a result, we often cannot rely on the
validity of scientific conclusions drawn from empirical studies using these
limited benchmarks. The empirical evidence presented may be biased due to
contamination and may fail to generalize beyond toy programs due to structural
simplicity.
  To address these problems, we introduce ULT (UnLeakedTestbench), a new
benchmark specifically designed for function-level unit test generation from
real-world Python functions. ULT is constructed through a multi-stage curation
process that ensures high cyclomatic complexity and mitigates test case
contamination. With 3,909 carefully selected function-level tasks, ULT provides
a more realistic and challenging evaluation of LLMs' test generation
capabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT
with leaked tests designed to enable a controlled analysis of memorization
versus reasoning in test generation. Our evaluation results demonstrate that
ULT is significantly more challenging. For example, test cases generated by
LLMs only achieve 41.32\%, 45.10\%, 30.22\%, and 40.21\% for accuracy,
statement coverage, branch coverage, and mutation score on average for all
LLMs, respectively. These results are substantially lower than the
corresponding metrics on TestEval (91.79\%, 92.18\%, 82.04\%, and 49.69\%) and
PLT (47.07\%, 55.13\%, 40.07\%, and 50.80\%).

</details>


### [14] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
*Md Imranur Rahman Akib,Fathima Binthe Muhammed,Umit Saha,Md Fazlul Karim Patwary,Mehrin Anannya,Md Alomgeer Hussein,Md Biplob Hosen*

Main category: cs.SE

TL;DR: 研究通过分析Codeforces用户的编程竞赛表现，预测其在不同级别软件工程职位中的就业潜力，并构建了一个基于随机森林的分类模型。


<details>
  <summary>Details</summary>
Motivation: 快速发展的科技行业需要评估程序员就业潜力的工具，研究旨在探索编程竞赛表现与就业机会之间的关联。

Method: 使用Codeforces API收集用户数据，处理关键性能指标，并利用随机森林分类器构建预测模型，将用户分为四个就业能力等级。

Result: 模型能有效区分不同技能水平，系统通过Flask实现并部署在Render上，支持实时预测。

Conclusion: 该研究为机器学习在职业评估中的应用奠定了基础，未来可扩展至更广泛的技术领域。

Abstract: In today's fast-paced tech industry, there is a growing need for tools that
evaluate a programmer's job readiness based on their coding performance. This
study focuses on predicting the potential of Codeforces users to secure various
levels of software engineering jobs. The primary objective is to analyze how a
user's competitive programming activity correlates with their chances of
obtaining positions, ranging from entry-level roles to jobs at major tech
companies. We collect user data using the Codeforces API, process key
performance metrics, and build a prediction model using a Random Forest
classifier. The model categorizes users into four levels of employability,
ranging from those needing further development to those ready for top-tier tech
jobs. The system is implemented using Flask and deployed on Render for
real-time predictions. Our evaluation demonstrates that the approach
effectively distinguishes between different skill levels based on coding
proficiency and participation. This work lays a foundation for the use of
machine learning in career assessment and could be extended to predict job
readiness in broader technical fields.

</details>


### [15] [Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory](https://arxiv.org/abs/2508.00462)
*Linus Ververs,Lutz Prechelt*

Main category: cs.SE

TL;DR: 论文研究了工业中结对编程中的权力差距现象，提出了避免权力差距的建议。


<details>
  <summary>Details</summary>
Motivation: 理解工业中结对编程中权力相关现象，并为从业者提供改进建议。

Method: 通过扎根理论分析22个工业结对编程会话，并调查292名参与者验证理论。

Result: 提出了权力差距理论，显示其普遍性及对知识传递、代码质量和效率的负面影响。

Conclusion: 避免权力差距是结对编程的重要技能，需减少等级行为，增加平等行为。

Abstract: Context: Pair Programming as a work mode is used (occasionally or frequently)
throughout professional software development. Objective: Understand what
power-related phenomena occur in pair programming as it is used in industry;
give advice to practitioners on how to do better pair programming. Method:
Analyze 22 industrial pair programming sessions using Grounded Theory
Methodology. Formulate a Grounded Theory on power-related behaviors. Run a
survey with 292 participants about that theory. Use it to demonstrate that the
phenomena are common. Results: Our theory describes the phenomenon of Power
Gap: a perceived difference in participation opportunities. The theory shows
the behaviors that create a Power Gap or result from it. Power Gaps tend to
damage knowledge transfer, code quality, and process effi ciency. The survey
results show that all concepts from our theory are frequent in practice. They
also provide more grounding for concepts that are observable only indirectly.
Conclusions: It is a valuable component of pair programming skill to be able to
avoid Power Gaps. Specifically, pair partners need to avoid Hierarchical
Behavior (which tends to create or increase a Power Gap) and should perform
enough Equalizing Behavior (which prevents or reduces a Power Gap).

</details>


### [16] [SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval](https://arxiv.org/abs/2508.00546)
*Wenchao Gu,Zongyi Lyu,Yanlin Wang,Hongyu Zhang,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文提出了一种名为SPENCER的框架，结合双编码器和交叉编码器以提高代码检索的效率和准确性，并通过模型蒸馏技术减少推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有双编码器模型在代码检索任务中缺乏底层交互，限制了性能。

Method: SPENCER框架先使用双编码器缩小搜索空间，再用交叉编码器提升准确性，并引入自适应模型蒸馏技术优化效率。

Result: 实验表明，双编码器与交叉编码器的组合提升了性能，模型蒸馏技术减少70%推理时间的同时保持了98%的性能。

Conclusion: SPENCER框架在代码检索任务中实现了高效与高准确性的平衡。

Abstract: Code retrieval aims to provide users with desired code snippets based on
users' natural language queries. With the development of deep learning
technologies, adopting pre-trained models for this task has become mainstream.
Considering the retrieval efficiency, most of the previous approaches adopt a
dual-encoder for this task, which encodes the description and code snippet into
representation vectors, respectively. However, the model structure of the
dual-encoder tends to limit the model's performance, since it lacks the
interaction between the code snippet and description at the bottom layer of the
model during training. To improve the model's effectiveness while preserving
its efficiency, we propose a framework, which adopts Self-AdaPtive Model
Distillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts
the dual-encoder to narrow the search space and then adopts the cross-encoder
to improve accuracy. To improve the efficiency of SPENCER, we propose a novel
model distillation technique, which can greatly reduce the inference time of
the dual-encoder while maintaining the overall performance. We also propose a
teaching assistant selection strategy for our model distillation, which can
adaptively select the suitable teaching assistant models for different
pre-trained models during the model distillation to ensure the model
performance. Extensive experiments demonstrate that the combination of
dual-encoder and cross-encoder improves overall performance compared to solely
dual-encoder-based models for code retrieval. Besides, our model distillation
technique retains over 98% of the overall performance while reducing the
inference time of the dual-encoder by 70%.

</details>


### [17] [Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System](https://arxiv.org/abs/2508.00593)
*Shuyao Jiang,Jiazhen Gu,Wujie Zheng,Yangfan Zhou,Michael R. Lyu*

Main category: cs.SE

TL;DR: 研究通过分析大规模用户反馈数据，发现过滤无关信息对问题检测至关重要，并验证了机器学习方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 理解用户反馈在大型在线服务系统中的特性，以改进基于反馈的问题检测方法。

Method: 对来自6个实际服务的50,378,766条用户反馈进行实证研究，分析内容、特征与问题关联性。

Result: 大部分反馈与系统问题无关，某些问题难以通过反馈特征直接检测，反馈主题分布稳定。

Conclusion: 研究结果为大规模服务系统中基于反馈的问题检测提供了实证基础，支持机器学习方法的实际应用。

Abstract: Background: It has long been suggested that user feedback, typically written
in natural language by end-users, can help issue detection. However, for
large-scale online service systems that receive a tremendous amount of
feedback, it remains a challenging task to identify severe issues from user
feedback. Aims: To develop a better feedback-based issue detection approach, it
is crucial first to gain a comprehensive understanding of the characteristics
of user feedback in real production systems. Method: In this paper, we conduct
an empirical study on 50,378,766 user feedback items from six real-world
services in a one-billion-user online service system. We first study what users
provide in their feedback. We then examine whether certain features of feedback
items can be good indicators of severe issues. Finally, we investigate whether
adopting machine learning techniques to analyze user feedback is reasonable.
Results: Our results show that a large proportion of user feedback provides
irrelevant information about system issues. As a result, it is crucial to
filter out issue-irrelevant information when processing user feedback.
Moreover, we find severe issues that cannot be easily detected based solely on
user feedback characteristics. Finally, we find that the distributions of the
feedback topics in different time intervals are similar. This confirms that
designing machine learning-based approaches is a viable direction for better
analyzing user feedback. Conclusions: We consider that our findings can serve
as an empirical foundation for feedback-based issue detection in large-scale
service systems, which sheds light on the design and implementation of
practical issue detection approaches.

</details>


### [18] [MCeT: Behavioral Model Correctness Evaluation using Large Language Models](https://arxiv.org/abs/2508.00630)
*Khaled Ahmed,Jialing Song,Boqi Chen,Ou Wei,Bingzhou Zheng*

Main category: cs.SE

TL;DR: 本文提出了一种名为MCeT的工具，用于自动评估行为模型（如顺序图）的正确性，并生成问题列表。通过结合细粒度多视角方法和自一致性检查，显著提高了问题检测的准确性和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在AI建模辅助中的应用增加，需要自动化的模型正确性评估工具来支持工程师和AI助手。

Method: MCeT将图表和需求文本分解为原子级元素，采用多视角比较和自一致性检查，结合LLM的自然语言理解能力。

Result: 该方法将直接检查的精度从0.58提升至0.81，并检测到比直接方法多90%的问题，平均每个图表报告6个新问题。

Conclusion: MCeT通过细粒度分析和自一致性检查，显著提升了行为模型正确性评估的效果，为工程师和AI助手提供了高效的工具。

Abstract: Behavioral model diagrams, e.g., sequence diagrams, are an essential form of
documentation that are typically designed by system engineers from requirements
documentation, either fully manually or assisted by design tools. With the
growing use of Large Language Models (LLM) as AI modeling assistants, more
automation will be involved in generating diagrams. This necessitates the
advancement of automatic model correctness evaluation tools. Such a tool can be
used to evaluate both manually and AI automatically generated models; to
provide feedback to system engineers, and enable AI assistants to self-evaluate
and self-enhance their generated models.
  In this paper, we propose MCeT, the first fully automated tool to evaluate
the correctness of a behavioral model, sequence diagrams in particular, against
its corresponding requirements text and produce a list of issues that the model
has. We utilize LLMs for the correctness evaluation tasks as they have shown
outstanding natural language understanding ability. However, we show that
directly asking an LLM to compare a diagram to requirements finds less than 35%
of issues that experienced engineers can find. We propose to supplement the
direct check with a fine-grained, multi-perspective approach; we split the
diagram into atomic, non-divisible interactions, and split the requirements
text into atomic, self-contained items. We compare the diagram with atomic
requirements and each diagram-atom with the requirements. We also propose a
self-consistency checking approach that combines perspectives to mitigate LLM
hallucinated issues. Our combined approach improves upon the precision of the
direct approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,
the approach finds 90% more issues that the experienced engineers found than
the direct approach, and reports an average of 6 new issues per diagram.

</details>


### [19] [Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?](https://arxiv.org/abs/2508.00700)
*Alfred Santa Molison,Marcia Moraes,Glaucia Melo,Fabio Santos,Wesley K. G. Assuncao*

Main category: cs.SE

TL;DR: 研究比较了LLM生成代码与人工编写代码的内部质量属性，发现LLM生成的代码整体上缺陷更少且修复成本更低，但在复杂场景下可能引入关键问题。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在代码生成中的软件质量表现，并与人工编写代码进行对比。

Method: 整合编码任务数据集、三种LLM配置（零样本、少样本和微调）及SonarQube工具，分析Python代码质量指标。

Result: LLM生成的代码缺陷较少且修复成本低，但微调模型可能降低性能并在复杂场景中引入结构性问题。

Conclusion: LLM生成代码具有优势，但在复杂场景需系统评估和验证，以充分发挥其潜力。

Abstract: Background: The rise of Large Language Models (LLMs) in software development
has opened new possibilities for code generation. Despite the widespread use of
this technology, it remains unclear how well LLMs generate code solutions in
terms of software quality and how they compare to human-written code. Aims:
This study compares the internal quality attributes of LLM-generated and
human-written code. Method: Our empirical study integrates datasets of coding
tasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and
SonarQube to assess software quality. The dataset comprises Python code
solutions across three difficulty levels: introductory, interview, and
competition. We analyzed key code quality metrics, including maintainability
and reliability, and the estimated effort required to resolve code issues.
Results: Our analysis shows that LLM-generated code has fewer bugs and requires
less effort to fix them overall. Interestingly, fine-tuned models reduced the
prevalence of high-severity issues, such as blocker and critical bugs, and
shifted them to lower-severity categories, but decreased the model's
performance. In competition-level problems, the LLM solutions sometimes
introduce structural issues that are not present in human-written code.
Conclusion: Our findings provide valuable insights into the quality of
LLM-generated code; however, the introduction of critical issues in more
complex scenarios highlights the need for a systematic evaluation and
validation of LLM solutions. Our work deepens the understanding of the
strengths and limitations of LLMs for code generation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [20] [Building Bigraphs of the real world](https://arxiv.org/abs/2508.00003)
*Kang Rong Roy Ang*

Main category: cs.LO

TL;DR: 提出了一种基于OpenStreetMap数据的全球建筑、街道和行政区域的层次化空间分区树规范，并将其编码为大图（bigraph），作为世界的数字孪生。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个能够完整捕捉街道连通性的全球数字孪生模型。

Method: 使用OCaml实现工具，从OpenStreetMap数据构建大图，并改进开源工具以高效处理大规模数据。

Result: 实现了高达97倍的加速，并能高效构建和转换极大尺寸的大图。

Conclusion: 该方法为全球空间数据的层次化建模提供了高效工具，并显著提升了处理能力。

Abstract: This report proposes a formal specification for organising all buildings,
streets and administrative areas in the world into a hierarchical
space-partitioning tree using data from OpenStreetMap. This hierarchical
structure is encoded into a bigraph, serving as a digital twin of the world and
capturing complete street connectivity. It presents a tool implemented in OCaml
(source code at https://github.com/royangkr/bigraph-of-the-world ) that
constructs bigraphs for regions from any part of the world. In addition, it
contributes algorithmic improvements to open-source bigraph-building tools that
enable them to efficiently construct and transform extremely large bigraphs,
achieving up to a 97x speedup among other gains.

</details>


### [21] [Reasoning under uncertainty in the game of Cops and Robbers](https://arxiv.org/abs/2508.00004)
*Dazhu Li,Sujata Ghosh,Fenrong Liu*

Main category: cs.LO

TL;DR: 本文提出了一种新的形式化框架ELCR，用于研究具有不完全信息的Cops and Robbers游戏，通过模态逻辑和动态操作符分析玩家互动和信息更新。


<details>
  <summary>Details</summary>
Motivation: 研究在不完全信息环境下Cops and Robbers游戏的计算查询和玩家互动。

Method: 提出Epistemic Logic of Cops and Robbers (ELCR)框架，结合模态逻辑和动态操作符分析游戏中的信息更新。

Result: 实现了玩家互动的自动化跟踪和信息更新机制，研究了ELCR的公理化和可判定性。

Conclusion: ELCR为不完全信息下的Cops and Robbers游戏提供了首个形式化分析框架，具有理论和应用价值。

Abstract: The game of Cops and Robbers is an important model for studying computational
queries in pursuit-evasion environments, among others. As recent logical
explorations have shown, its structure exhibits appealing analogies with modal
logic. In this paper, we enrich the game with a setting in which players may
have imperfect information. We propose a new formal framework, Epistemic Logic
of Cops and Robbers (ELCR), to make the core notions of the game precise, for
instance, players' positions, observational power and inference. Applying ELCR
to analyze the game, we obtain an automated way to track interactions between
players and characterize their information updates during the game. The update
mechanism is defined by a novel dynamic operator, and we compare it with some
relevant paradigms from the game and logic perspectives. We study various
properties of ELCR including axiomatization and decidability. To our knowledge,
this is the first attempt to explore these games from a formal point of view
where (partial) information available to players is taken into account.

</details>


### [22] [Deciding the Value of Two-Clock Almost Non-Zeno Weighted Timed Games](https://arxiv.org/abs/2508.00014)
*Isa Vialard*

Main category: cs.LO

TL;DR: 本文探讨了加权定时游戏（wtgs）的值问题，特别关注两时钟几乎非Zeno wtgs的可判定性。


<details>
  <summary>Details</summary>
Motivation: 研究加权定时游戏的值问题，尤其是两时钟非负wtgs的未解问题，填补了该领域的空白。

Method: 分析两时钟几乎非Zeno wtgs的特性，并证明其值问题的可判定性。

Result: 证明了两时钟几乎非Zeno wtgs的值问题是可判定的。

Conclusion: 为加权定时游戏的值问题提供了新的理论结果，扩展了可判定性的范围。

Abstract: The Value Problem for weighted timed games (wtgs) consists in determining,
given a two-player weighted timed game with a reachability objective and a
rational threshold, whether or not the value of the game exceeds the threshold.
When restrained to wtgs with non-negative weight, this problem is known to be
undecidable for weighted timed games with three or more clocks, and decidable
for one-clock wtgs. The Value Problem for two-clock non-negative wtgs, which
remained stubbornly open for a decade, was recently shown to be undecidable. In
this article, we show that the Value Problem is decidable when considering
two-clock almost non-Zeno wtgs.

</details>


### [23] [Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2](https://arxiv.org/abs/2508.00015)
*Matt Kaufmann,J Strother Moore*

Main category: cs.LO

TL;DR: 展示了partial-encapsulate在ACL2中实现浮点运算的强大功能。


<details>
  <summary>Details</summary>
Motivation: 探讨partial-encapsulate在ACL2中的应用，以验证其在实现复杂运算（如浮点运算）中的有效性。

Method: 使用partial-encapsulate技术，在ACL2中实现浮点运算。

Result: 成功展示了partial-encapsulate在浮点运算实现中的实用性。

Conclusion: partial-encapsulate是ACL2中实现复杂运算的有效工具。

Abstract: We illustrate the power of partial-encapsulate, showing how it is used in the
implementation of floating-point operations in ACL2.

</details>


### [24] [Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers](https://arxiv.org/abs/2508.00419)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.LO

TL;DR: 论文探讨了利用大型语言模型（LLM）结合Z3求解器自动合成循环不变式的方法，在Code2Inv基准测试中实现了100%的覆盖率，优于之前的最佳结果。


<details>
  <summary>Details</summary>
Motivation: 循环不变式对程序验证至关重要，但自动合成具有挑战性。现有方法仅适用于部分标准基准测试，因此研究现代LLM是否能改进这一过程。

Method: 将OpenAI的O1、O1-mini和O3-mini模型与Z3求解器结合，通过生成-检查迭代优化不变式。

Result: 在133个任务中实现100%覆盖率，优于之前的107/133，且每次仅需1-2次模型提议和14-55秒时间。

Conclusion: LLM具有潜在逻辑推理能力，可自动化循环不变式合成，且方法可推广到其他命令式语言。

Abstract: Loop invariants are essential for proving the correctness of programs with
loops. Developing loop invariants is challenging, and fully automatic synthesis
cannot be guaranteed for arbitrary programs. Some approaches have been proposed
to synthesize loop invariants using symbolic techniques and more recently using
neural approaches. These approaches are able to correctly synthesize loop
invariants only for subsets of standard benchmarks. In this work, we
investigate whether modern, reasoning-optimized large language models can do
better. We integrate OpenAI's O1, O1-mini, and O3-mini into a tightly coupled
generate-and-check pipeline with the Z3 SMT solver, using solver
counterexamples to iteratively guide invariant refinement. We use Code2Inv
benchmark, which provides C programs along with their formal preconditions and
postconditions. On this benchmark of 133 tasks, our framework achieves 100%
coverage (133 out of 133), outperforming the previous best of 107 out of 133,
while requiring only 1-2 model proposals per instance and 14-55 seconds of
wall-clock time. These results demonstrate that LLMs possess latent logical
reasoning capabilities which can help automate loop invariant synthesis. While
our experiments target C-specific programs, this approach should be
generalizable to other imperative languages.

</details>


### [25] [Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation](https://arxiv.org/abs/2508.00017)
*Nikolai Sergeev*

Main category: cs.LO

TL;DR: Generative Logic (GL) 是一种确定性架构，通过用户提供的公理化定义，系统地探索其演绎邻域，生成可重放、可审计的证明图。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自动化方式从公理出发，重建算术定律的机器可检查证明，并探索与概率模型（如大语言模型）的潜在集成。

Method: 将定义编译为分布式逻辑块网格，通过消息交换和统一规则生成新事实，并导出为可导航的HTML证明图。

Result: 成功从Peano公理出发，自动重建了加法、乘法的结合律、交换律及分配律的证明。

Conclusion: GL展示了自动化证明生成的潜力，并提出了硬件-软件协同设计的未来方向，鼓励社区反馈与合作。

Abstract: We present Generative Logic (GL), a deterministic architecture that begins
from user-supplied axiomatic definitions -- written in a minimalist
Mathematical Programming Language (MPL) -- and systematically explores their
deductive neighborhood. Definitions are compiled into a distributed grid of
simple Logic Blocks (LBs) that exchange messages; any time several expressions
unify under an inference rule, a new fact is emitted with full provenance to
its sources, yielding replayable, auditable proof graphs.
  A prototype software implementation instantiates the workflow on first-order
Peano arithmetic. Starting only from the Peano axioms, GL enumerates candidate
implications, applies normalization and type filters, and automatically
reconstructs machine-checkable proofs of foundational arithmetic laws including
associativity and commutativity of addition, associativity and commutativity of
multiplication, and distributivity. Generated proofs export to navigable HTML
so that every inference step can be inspected independently.
  We outline a hardware-software co-design path toward massively parallel
realizations and describe prospective integration with probabilistic models
(e.g., Large Language Models (LLMs)) for autoformalization and conjecture
seeding. The Python and MPL code to reproduce the Peano experiments, along with
the full HTML proof graphs, are available in the project's GitHub repository at
https://github.com/Generative-Logic/GL/tree/35a111ea9ba53afe051703d6050be0c3923e9724
and are permanently archived at https://doi.org/10.5281/zenodo.16408441. We
invite community feedback and collaboration.

</details>


### [26] [Alignment Monitoring](https://arxiv.org/abs/2508.00021)
*Thomas A. Henzinger,Konstantin Kueffner,Vasu Singh,I Sun*

Main category: cs.LO

TL;DR: 提出了一种对齐监控方法，用于验证概率模型是否与实际情况一致，通过预测与实际行为的相似性评分来评估模型对齐性。


<details>
  <summary>Details</summary>
Motivation: 确保概率模型与实际情况一致，以提供可靠的验证结果。

Method: 利用顺序预测工具构建对齐监控器，包括预期对齐评分、差异对齐监控和加权对齐监控。

Result: 实验表明监控器快速、内存高效，并能早期检测到不一致。

Conclusion: 对齐监控器有效验证模型与实际行为的一致性，适用于多种任务场景。

Abstract: Formal verification provides assurances that a probabilistic system satisfies
its specification--conditioned on the system model being aligned with reality.
We propose alignment monitoring to watch that this assumption is justified. We
consider a probabilistic model well aligned if it accurately predicts the
behaviour of an uncertain system in advance. An alignment score measures this
by quantifying the similarity between the model's predicted and the system's
(unknown) actual distributions. An alignment monitor observes the system at
runtime; at each point in time it uses the current state and the model to
predict the next state. After the next state is observed, the monitor updates
the verdict, which is a high-probability interval estimate for the true
alignment score. We utilize tools from sequential forecasting to construct our
alignment monitors. Besides a monitor for measuring the expected alignment
score, we introduce a differential alignment monitor, designed for comparing
two models, and a weighted alignment monitor, which permits task-specific
alignment monitoring. We evaluate our monitors experimentally on the PRISM
benchmark suite. They are fast, memory-efficient, and detect misalignment
early.

</details>


### [27] [Ordinal Folding Index: A Computable Metric for Self-Referential Semantics](https://arxiv.org/abs/2508.00151)
*Faruk Alpay,Hamdi Al Alakkad*

Main category: cs.LO

TL;DR: OFI是一种新的可计算度量，用于衡量语句、协议或立场在自引用展开后其真值或结果稳定的轮数，将抽象的“折叠”深度转化为序数。它连接了固定点逻辑、无限奇偶博弈和形式理论的序数强度校准，并证明OFI细化经典度量且可算法枚举。


<details>
  <summary>Details</summary>
Motivation: 研究自引用展开的深度如何影响逻辑、博弈论和形式理论的稳定性，以提供统一的度量工具。

Method: 提出Ordinal Folding Index（OFI），将其与固定点逻辑、无限奇偶博弈和形式理论的序数强度校准联系起来，并证明其算法可枚举性和多项式时间近似性。

Result: OFI细化经典度量，算法可枚举，且在有限竞技场上有多项式时间近似方案，与评估博弈的最短获胜策略长度一致。

Conclusion: OFI为无限博弈、超限归纳和自反推理提供了统一视角，并提出了五个开放问题，为计算机辅助逻辑、算法博弈论和序数分析的交叉研究开辟了新方向。

Abstract: The Ordinal Folding Index (OFI) is a new, fully computable yard-stick that
measures how many rounds of self-reference a statement, protocol or position
must unfold before its truth or outcome stabilises. By turning this abstract
'fold-back' depth into a single ordinal number, OFI forges a direct link
between areas that are usually studied in isolation: the closure stages of
fixed-point logics, the time-to-win values of infinite parity games, and the
ordinal progressions that calibrate the strength of formal theories. We prove
that OFI refines all classical game-theoretic and logical metrics while
remaining algorithmically enumerable, supply a polynomial-time approximation
scheme on finite arenas, and show how the index coincides exactly with the
length of the shortest winning strategy in the associated evaluation game.
Alongside the theory we outline five open problems from the completeness of the
computable-ordinal spectrum to the possibility of 'compressing' deep
self-reference that chart a research programme at the intersection of
computer-aided logic, algorithmic game theory and ordinal analysis. OFI thus
invites game theorists and logicians alike to view infinite play, transfinite
induction and reflective reasoning through a single, intuitive lens, opening
common ground for techniques.

</details>


### [28] [Analysing Temporal Reasoning in Description Logics Using Formal Grammars](https://arxiv.org/abs/2508.00575)
*Camille Bourgaux,Anton Gnatenko,Michaël Thomazo*

Main category: cs.LO

TL;DR: 论文建立了$\mathcal{TEL}^\bigcirc$（一种带有LTL操作符$\bigcirc^k$的$\mathcal{EL}$描述逻辑的时间扩展）与某些形式文法（如合取文法）的对应关系，揭示了其模型不具备最终周期性，并证明了查询回答的不可判定性。同时，该研究也为$\mathcal{TEL}^\bigcirc$的某些片段提供了查询回答的可判定性，并利用合取文法的工具和算法。


<details>
  <summary>Details</summary>
Motivation: 研究$\mathcal{TEL}^\bigcirc$的性质，特别是其模型的周期性和查询回答的可判定性，填补了自$\mathcal{TEL}^\bigcirc$提出以来的开放性问题。

Method: 通过建立$\mathcal{TEL}^\bigcirc$与合取文法等特定形式文法的对应关系，分析其模型性质和查询回答的可判定性。

Result: 证明了$\mathcal{TEL}^\bigcirc$模型不具备最终周期性，查询回答在该逻辑中不可判定，但某些片段具有可判定性。

Conclusion: 研究不仅解决了$\mathcal{TEL}^\bigcirc$的开放性问题，还为其片段的可判定性提供了新工具和算法。

Abstract: We establish a correspondence between (fragments of)
$\mathcal{TEL}^\bigcirc$, a temporal extension of the $\mathcal{EL}$
description logic with the LTL operator $\bigcirc^k$, and some specific kinds
of formal grammars, in particular, conjunctive grammars (context-free grammars
equipped with the operation of intersection). This connection implies that
$\mathcal{TEL}^\bigcirc$ does not possess the property of ultimate periodicity
of models, and further leads to undecidability of query answering in
$\mathcal{TEL}^\bigcirc$, closing a question left open since the introduction
of $\mathcal{TEL}^\bigcirc$. Moreover, it also allows to establish decidability
of query answering for some new interesting fragments of
$\mathcal{TEL}^\bigcirc$, and to reuse for this purpose existing tools and
algorithms for conjunctive grammars.

</details>


### [29] [Parameterized Infinite-State Reactive Synthesis](https://arxiv.org/abs/2508.00613)
*Benedikt Maderbacher,Roderick Bloem*

Main category: cs.LO

TL;DR: 提出了一种合成参数化无限状态系统的方法，通过反例引导循环验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决参数化系统的合成问题，使其能适应不同参数值，并验证其正确性。

Method: 采用反例引导循环，包括具体系统合成、参数化程序泛化、证明候选生成及验证四个步骤。

Result: 方法在文献案例和新问题上进行了验证，证明其有效性。

Conclusion: 该方法能成功合成并验证参数化系统，适用于多种场景。

Abstract: We propose a method to synthesize a parameterized infinite-state systems that
can be instantiated for different parameter values. The specification is given
in a parameterized temporal logic that allows for data variables as well as
parameter variables that encode properties of the environment. Our synthesis
method runs in a counterexample-guided loop consisting of four main steps:
First, we use existing techniques to synthesize concrete systems for some small
parameter instantiations. Second, we generalize the concrete systems into a
parameterized program. Third, we create a proof candidate consisting of an
invariant and a ranking function. Fourth, we check the proof candidate for
consistency with the program. If the proof succeeds, the parameterized program
is valid. Otherwise, we identify a parameter value for which the proof fails
and add a new concrete instance to step one. To generalize programs and create
proof candidates, we use a combination of anti-unification and syntax-guided
synthesis to express syntactic differences between programs as functions of the
parameters. We evaluate our approach on examples from the literature that have
been extended with parameters as well as new problems.

</details>


### [30] [Putting Perspective into OWL [sic]: Complexity-Neutral Standpoint Reasoning for Ontology Languages via Monodic S5 over Counting Two-Variable First-Order Logic (Extended Version with Appendix)](https://arxiv.org/abs/2508.00653)
*Lucía Gómez Álvarez,Sebastian Rudolph*

Main category: cs.LO

TL;DR: 论文探讨了知识表示形式的多视角扩展，特别是单子视角扩展在C2逻辑中的应用，证明了其可满足性问题复杂度不变，并揭示了在某些条件下问题会变得不可判定。


<details>
  <summary>Details</summary>
Motivation: 研究多视角建模和推理的需求，通过模态算子将知识归因于特定实体或代理，以增强知识表示的灵活性和表达能力。

Method: 通过多项式时间翻译将单子视角扩展的C2逻辑公式转换为标准C2逻辑，利用模型论论证保持复杂度不变。

Result: 扩展后的逻辑可满足性问题复杂度仍为NExpTime完全，且适用于高表达描述逻辑如SHOIQBs和SROIQBs。

Conclusion: 单子视角扩展在保持推理复杂度的同时增强了表达能力，但放松单子性限制会导致问题不可判定。

Abstract: Standpoint extensions of knowledge representation formalisms have been
recently introduced as a means to incorporate multi-perspective modelling and
reasoning through modal operators that attribute pieces of knowledge to
specific entities or agents. In these extensions, the integration between
conceptual modelling and perspective annotations can vary in strength, with
monodic standpoint extensions offering a well-balanced approach. They allow for
advanced modelling features, such as the expression of rigid concepts, while
maintaining desirable reasoning complexity.
  We consider the extension of C2--the counting two-variable fragment of
first-order logic--by monodic standpoints. At the heart of our work is a
polynomial-time translation of formulas in this extended formalism into
standard, standpoint-free C2, a result that relies on intricate model-theoretic
arguments. Thanks to this translation, the satisfiability problem remains at
the same complexity level: NExpTime-complete, as in plain C2. Since our
formalism subsumes monodic S5 over C2, this result also marks a substantial
advancement in the study of first-order modal logics.
  From a practical standpoint, this means that highly expressive description
logics such as SHOIQBs and SROIQBs--which underpin the widely adopted OWL 1 and
OWL 2 ontology languages standardised by the W3C--can be extended with monodic
standpoints without increasing the standard reasoning complexity.
  We further prove that NExpTime-hardness arises even in significantly less
expressive description logics, as long as they include both nominals and
monodic standpoints. Moreover, we show that if the monodicity restriction is
relaxed even slightly in the presence of inverse roles, functionality, and
nominals, the satisfiability problem becomes undecidable.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [31] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
*Tilman Hinnerichs,Bart Swinkels,Jaap de Jong,Reuben Gardos Reid,Tudor Magirescu,Neil Yorke-Smith,Sebastijan Dumancic*

Main category: cs.PL

TL;DR: 论文提出了一种利用语法约束来优化程序合成的方法，通过BART求解器高效传播和解决这些约束，显著减少了程序空间的枚举时间和规模。


<details>
  <summary>Details</summary>
Motivation: 程序合成的核心挑战在于处理庞大的可能程序空间，传统方法主要依赖组合约束求解器表达程序语义，但未充分利用约束去除无用程序。

Method: 引入语法约束来建模程序空间，定义可行且可能有用的解，开发BART求解器高效传播和解决这些约束。

Result: 实验表明，语法约束能消除高达99%的程序空间，显著减少枚举时间。

Conclusion: 语法约束是优化程序合成的有效工具，BART求解器展示了其高效性和实用性。

Abstract: A core challenge in program synthesis is taming the large space of possible
programs. Since program synthesis is essentially a combinatorial search, the
community has sought to leverage powerful combinatorial constraint solvers.
Here, constraints are used to express the program semantics, but not as a
potentially potent tool to remove unwanted programs. Recent inductive logic
programming approaches introduce constraints on the program's syntax to be
synthesized. These syntactic constraints allow for checking and propagating a
constraint without executing the program, and thus for arbitrary operators. In
this work, we leverage syntactic constraints to model program spaces, defining
not just solutions that are feasible, but also ones that are likely useful. To
demonstrate this idea, we introduce BART, a solver that efficiently propagates
and solves these constraints. We evaluate BART on program space enumeration
tasks, finding that the constraints eliminate up to 99 percent of the program
space, and that modeling program spaces significantly reduces enumeration time.

</details>


### [32] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
*Zurabi Kobaladze,Anna Arnania,Tamar Sanikidze*

Main category: cs.PL

TL;DR: 该论文综述了程序合成的五种主要方法，从逻辑基础到神经符号混合方法，分析了其发展历程、优缺点及未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨程序合成领域的发展历程，比较不同方法的优缺点，为未来研究提供方向。

Method: 通过文献综述，分析五种程序合成方法：逻辑基础、归纳基础、草图/模式基础、大语言模型基础和神经符号混合方法。

Result: 总结了每种方法的原理、系统、应用及权衡，突出了从符号方法到神经符号混合的转变。

Conclusion: 未来程序合成需结合神经符号方法，以实现可靠和可扩展的合成技术。

Abstract: Program synthesis--the automated generation of executable code from
high-level specifications--has been a central goal of computer science for over
fifty years. This thesis provides a comparative literature review of the main
paradigms that have shaped the field, tracing its evolution from formal logic
based methods to recent advances using large scale neural models. We examine
five key approaches: logic based (deductive) synthesis, inductive (example
based) synthesis, sketch/schema based synthesis, large language model based
synthesis, and neuro-symbolic hybrids. For each, we analyze foundational
principles, notable systems, and practical applications, highlighting trade
offs between correctness guarantees, specification requirements, search
complexity, and expressive power. By reviewing developments from formally
verified synthesis tools such as KIDS and Coq to data driven models generating
probabilistic code from natural language like Codex, we present a comprehensive
narrative of progress and ongoing challenges. This work emphasizes the
transition from symbolic to hybrid neuro-symbolic methods and outlines future
directions for reliable and scalable program synthesis.

</details>


### [33] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
*Matt Kaufmann,Yahya Sohail,Warren A. Hunt Jr*

Main category: cs.PL

TL;DR: ACL2的attach-stobj功能支持对抽象stobj的不同可执行操作，无需重新认证相关书籍或定理。


<details>
  <summary>Details</summary>
Motivation: 提供一种灵活的方式，允许用户在不重新认证书籍或定理的情况下，为抽象stobj定义不同的可执行操作。

Method: 介绍了attach-stobj功能，包括背景、用户级概述和实现细节。

Result: 成功实现了对抽象stobj的多操作支持，提升了ACL2的灵活性和实用性。

Conclusion: attach-stobj功能为ACL2用户提供了更高效和灵活的工具，简化了开发流程。

Abstract: This extended abstract outlines an ACL2 feature, attach-stobj, that first
appeared in ACL2 Version 8.6 (October, 2024). This feature supports different
executable operations for a given abstract stobj, without requiring
recertification of the book that introduces that stobj or theorems about it.
The paper provides background as well as a user-level overview and some
implementation notes.

</details>


### [34] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.PL

TL;DR: 该论文探索了使用LLMs（如GPT 4oMini、GPT 4.1mini等）自动生成Python类型注释的方法，通过生成-检查-修复流程，验证了其在一致性和准确性上的表现。


<details>
  <summary>Details</summary>
Motivation: 手动生成Python类型注释容易出错且耗时，传统自动化方法（如静态分析、机器学习）存在类型词汇有限、行为过度近似等问题。

Method: 采用生成-检查-修复流程：LLM基于语法树生成注释，静态检查器验证，错误反馈迭代优化。

Result: GPT 4.1mini和O3Mini表现最佳，一致性达88.6%，准确率最高70.5%（精确匹配）和79.1%（基础类型匹配）。

Conclusion: 通用和推理优化的LLMs无需额外训练即可有效生成类型注释，性能与传统深度学习相当，适用于其他可选类型语言。

Abstract: Type annotations in Python enhance maintainability and error detection.
However, generating these annotations manually is error prone and requires
extra effort. Traditional automation approaches like static analysis, machine
learning, and deep learning struggle with limited type vocabularies, behavioral
over approximation, and reliance on large labeled datasets. In this work, we
explore the use of LLMs for generating type annotations in Python. We develop a
generate check repair pipeline: the LLM proposes annotations guided by a
Concrete Syntax Tree representation, a static type checker (Mypy) verifies
them, and any errors are fed back for iterative refinement. We evaluate four
LLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini
(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.
We first measure the proportion of code snippets annotated by LLMs for which
MyPy reported no errors (i.e., consistent results): GPT 4oMini achieved
consistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,
and O4Mini each reached approximately 88.6% consistency (around 11.4%
failures). To measure annotation quality, we then compute exact-match and
base-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini
perform the best, achieving up to 70.5% exact match and 79.1% base type
accuracy, requiring under one repair iteration on average. Our results
demonstrate that general-purpose and reasoning optimized LLMs, without any task
specific fine tuning or additional training can be effective in generating
consistent type annotations.They perform competitively with traditional deep
learning techniques which require large labeled dataset for training. While our
work focuses on Python, the pipeline can be extended to other optionally typed
imperative languages like Ruby

</details>


### [35] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
*Erdem Yildirim,Albert Schimpf,Stefan Wehr,Annette Bieniusa*

Main category: cs.PL

TL;DR: 构建了一个包含类型变量、基础类型、集合类型和映射类型的集合论模型，定义了基于集合包含的语义子类型关系，重点研究了参数化映射类型的子类型。


<details>
  <summary>Details</summary>
Motivation: 研究类型系统中的子类型关系，特别是针对Erlang中的映射类型，填补参数化映射类型子类型定义的空白。

Method: 构建集合论模型，涵盖多种类型，并基于集合包含定义语义子类型关系。

Result: 成功定义了参数化映射类型的子类型关系，扩展了类型系统的表达能力。

Conclusion: 该模型为类型系统提供了新的理论基础，尤其在处理复杂映射类型时具有实际意义。

Abstract: In this paper we will construct a set-theoretic model of types featuring type
variables, base types, set-theoretic types and map types. Syntax of map types
spans all the map types available in Erlang. The model of types is used to
define a semantic subtyping relation based on set containment. The novelty of
this work is the definition of subtyping over parameteric map types.

</details>


### [36] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 本文通过系统文献综述，探讨了多范式语言的分类问题，提出了一种基于原子原语和数学框架的重构方法。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起挑战了传统分类方法，导致互操作性缺陷等问题，需要更强大的理论基础。

Method: 基于74项主要研究的系统文献综述，分析了现有分类方法的局限性，并提出了基于类型理论、范畴理论和统一编程理论的重构方法。

Result: 研究发现现有分类方法缺乏概念粒度，而重构方法通过正交原子原语和数学框架解决了这一问题。

Conclusion: 文献表明，研究趋势正从分类转向重构框架，本文提出了统一这些框架的研究议程。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>
