<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.SE](#cs.SE) [Total: 15]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Numbers Reverse AD for Functional Array Languages](https://arxiv.org/abs/2507.12640)
*Tom Smeding,Mikołaj Konarski,Simon Peyton Jones,Andrew Fitzgibbon*

Main category: cs.PL

TL;DR: 本文提出了一种针对多维数组的对偶数反向模式自动微分方法，通过批量操作变换(BOT)、对偶数算法提升和符号解释三个组件，在保持性能的同时实现了对数组程序的有效支持，但牺牲了对高阶代码的通用支持。


<details>
  <summary>Details</summary>
Motivation: 标准的对偶数构造在前向模式自动微分中表现良好且简单，虽然已被适配到反向模式AD，但在数组程序上的实际性能表现不佳。需要为多维数组提供一流的支持，同时保持低性能开销。

Method: 提出三个松耦合组件的算法：(1)语义保持的向量化代码变换(批量操作变换BOT)；(2)将基本对偶数反向AD算法提升到主要为一阶的数组语言；(3)符号解释实现端到端编译流水线。支持精心选择的高阶数组组合子：build、gather和scatter。

Result: BOT能够消除输入程序中对AD至关重要的高阶性，使AD实质上面对一阶程序。这使得将对偶数提升为"对偶数组"的朴素技巧能够在几乎无需修改的情况下工作，实现了对多维数组的高效支持。

Conclusion: 成功实现了多维数组的对偶数反向模式AD，性能开销很小，但代价是失去了对偶数AD的一些良好的泛化特性，特别是对高阶代码的支持。通过限制支持的高阶组合子集合，换取了实际的性能改进。

Abstract: The standard dual-numbers construction works well for forward-mode automatic
differentiation (AD) and is attractive due to its simplicity; recently, it also
has been adapted to reverse-mode AD, but practical performance, especially on
array programs, leaves a lot to be desired. In this paper we introduce
first-class support for multidimensional arrays in dual-numbers reverse-mode AD
with little to no performance overhead. The algorithm consists of three
loosely-coupled components: a semantics-preserving vectorisation code
transformation (the bulk-operation transform or BOT), a fairly straightforward
lifting of the basic dual-numbers reverse AD algorithm to a mostly first-order
array language, and symbolic interpretation to achieve an end-to-end
compilation pipeline. Unfortunately, we lose some of the nice generalisable
aspects of dual-numbers AD in the process, most importantly support for
higher-order code.
  We do support some higher-order array combinators, but only a
carefully-chosen set: 'build' (elementwise array construction), 'gather' and
'scatter'. In return, the BOT can eliminate the essential (for AD)
higher-orderness of the input program, meaning that AD gets essentially
presented with a first-order program. This allows the naive trick of lifting
dual numbers to "dual arrays" to work without much modification.

</details>


### [2] [Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications](https://arxiv.org/abs/2507.13091)
*Aurèle Barrière,Victor Deng,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 本文提出了一种机械化、简洁、实用、完整且经过验证的现代正则表达式语义，支持回溯语义，并通过实际应用展示了其实用性。


<details>
  <summary>Details</summary>
Motivation: 为现代正则表达式语言提供一种可靠的语义定义，填补现有规范和其他形式化工作的不足。

Method: 通过证明其与ECMAScript官方规范的等价性确保语义的忠实性，并展示了两种实际应用：上下文等价性验证和PikeVM算法的形式化证明。

Result: 成功定义了一种完整且忠实于规范的正则表达式语义，并实现了两种实际应用。

Conclusion: 该语义不仅捕获了最高优先级匹配，还记录了完整的回溯树，所有定义和结果均在Rocq证明助手中实现。

Abstract: We present the first mechanized, succinct, practical, complete, and
proven-faithful semantics for a modern regular expression language with
backtracking semantics. We ensure its faithfulness by proving it equivalent to
a preexisting line-by-line embedding of the official ECMAScript specification
of JavaScript regular expressions. We demonstrate its practicality by
presenting two real-world applications. First, a new notion of contextual
equivalence for modern regular expressions, which we use to prove or disprove
rewrites drawn from previous work. Second, the first formal proof of the PikeVM
algorithm used in many real-world engines. In contrast with the specification
and other formalization work, our semantics captures not only the top-priority
match, but a full backtracking tree recording all possible matches and their
respective priority. All our definitions and results have been mechanized in
the Rocq proof assistant.

</details>


### [3] [Towards Formal Verification of LLM-Generated Code from Natural Language Prompts](https://arxiv.org/abs/2507.13290)
*Aaron Councilman,David Fu,Aryan Gupta,Chengxiao Wang,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.PL

TL;DR: 论文提出了一种方法，通过结合形式化查询语言和验证技术，为LLM生成的代码提供正确性保证，以提升AI代码助手的用户体验。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码常存在错误且用户难以检测，因此需要一种方法提供形式化正确性保证，以支持自然语言编程。

Method: 提出使用形式化查询语言表达用户意图，并通过符号解释器验证LLM生成的代码是否符合意图。系统名为Astrogator，针对Ansible语言实现。

Result: 在21个代码生成任务中，验证器能正确验证83%的正确代码，并识别92%的错误代码。

Conclusion: 该方法有效提升了LLM生成代码的可靠性，为自然语言编程提供了潜在支持。

Abstract: In the past few years LLMs have emerged as a tool that can aid programmers by
taking natural language descriptions and generating code based on it. However,
LLMs often generate incorrect code that users need to fix and the literature
suggests users often struggle to detect these errors. In this work we seek to
offer formal guarantees of correctness to LLM generated code; such guarantees
could improve the experience of using AI Code Assistants and potentially enable
natural language programming for users with little or no programming knowledge.
To address this challenge we propose to incorporate a formal query language
that can represent a user's intent in a formally defined but natural
language-like manner that a user can confirm matches their intent. Then, using
such a query we propose to verify LLM generated code to ensure it matches the
user's intent. We implement these ideas in our system, Astrogator, for the
Ansible programming language which includes such a formal query language, a
calculus for representing the behavior of Ansible programs, and a symbolic
interpreter which is used for the verification. On a benchmark suite of 21
code-generation tasks, our verifier is able to verify correct code in 83% of
cases and identify incorrect code in 92%.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [Dependency Pairs for Expected Innermost Runtime Complexity and Strong Almost-Sure Termination of Probabilistic Term Rewriting](https://arxiv.org/abs/2507.12918)
*Jan-Christoph Kassing,Leon Spitzer,Jürgen Giesl*

Main category: cs.LO

TL;DR: 本文提出了一种新的依赖对（DP）框架，用于分析概率项重写系统（PTRSs）的预期复杂性和证明其强几乎必然终止（SAST）。


<details>
  <summary>Details</summary>
Motivation: 尽管依赖对（DP）框架在自动终止和复杂性分析中表现强大，但在概率项重写系统（PTRSs）的复杂性分析方面仍未被充分探索。

Method: 作者扩展了DP框架，用于分析PTRSs的预期复杂性和证明SAST，并实现了工具AProVE。

Result: 实验表明，该框架在证明SAST方面优于现有技术。

Conclusion: 该研究填补了PTRSs复杂性分析的空白，并展示了其实际应用潜力。

Abstract: The dependency pair (DP) framework is one of the most powerful techniques for
automatic termination and complexity analysis of term rewrite systems. While
DPs were extended to prove almost-sure termination of probabilistic term
rewrite systems (PTRSs), automatic complexity analysis for PTRSs is largely
unexplored. We introduce the first DP framework for analyzing expected
complexity and for proving positive or strong almost-sure termination (SAST) of
innermost rewriting with PTRSs, i.e., finite expected runtime. We implemented
our framework in the tool AProVE and demonstrate its power compared to existing
techniques for proving SAST.

</details>


### [5] [Cyclic proof theory of positive inductive definitions](https://arxiv.org/abs/2507.13057)
*Gianluca Curzi,Lukas Melgaard*

Main category: cs.LO

TL;DR: 本文研究了μPA的循环证明系统，证明其与归纳μPA具有相同的证明论强度，并通过翻译和形式化方法验证了这一点。


<details>
  <summary>Details</summary>
Motivation: 探索循环证明系统在μPA中的表现，以及其与归纳证明系统的等价性，进一步推动非良基证明论在算术理论中的应用。

Method: 将循环证明翻译为基于Sprenger和Dam系统的注释变体，利用更强的有效性条件简化了完备性证明，并在Π²₁-CA₀中形式化这一论证。

Result: 证明了循环μPA和归纳μPA的证明论强度相同，同时表明注释和普通循环证明在μPA中证明相同的定理。

Conclusion: 本研究为非良基证明论在算术理论中的应用提供了新视角，延续了Simpson等人的工作。

Abstract: We study cyclic proof systems for $\mu\mathsf{PA}$, an extension of Peano
arithmetic by positive inductive definitions that is arithmetically equivalent
to the (impredicative) subsystem of second-order arithmetic
$\Pi^1_2$-$\mathsf{CA}_0$ by M\"{o}llefeld. The main result of this paper is
that cyclic and inductive $\mu\mathsf{PA}$ have the same proof-theoretic
strength. First, we translate cyclic proofs into an annotated variant based on
Sprenger and Dam's systems for first-order $\mu$-calculus, whose stronger
validity condition allows for a simpler proof of soundness. We then formalise
this argument within $\Pi^1_2$-$\mathsf{CA}_0$, leveraging M\"{o}llerfeld's
conservativity properties. To this end, we build on prior work by Curzi and Das
on the reverse mathematics of the Knaster-Tarski theorem. As a byproduct of our
proof methods we show that, despite the stronger validity condition, annotated
and "plain" cyclic proofs for $\mu\mathsf{PA}$ prove the same theorems. This
work represents a further step in the non-wellfounded proof-theoretic analysis
of theories of arithmetic via impredicative fragments of second-order
arithmetic, an approach initiated by Simpson's Cyclic Arithmetic, and continued
by Das and Melgaard in the context of arithmetical inductive definitions.

</details>


### [6] [Monotone weak distributive laws over the lifted powerset monad in categories of algebras](https://arxiv.org/abs/2507.13058)
*Quentin Aristote*

Main category: cs.LO

TL;DR: 研究了单调弱分配律在集合和紧致Hausdorff空间中的相似性，探讨了后者能否通过前者的弱提升自动获得。部分成立，但不适用于其他代数范畴，进一步刻画了幂集幺半群上单调弱分配律的存在条件。


<details>
  <summary>Details</summary>
Motivation: 探索单调弱分配律在不同代数范畴中的普适性，特别是在紧致Hausdorff空间中的应用。

Method: 通过比较集合和紧致Hausdorff空间中的弱分配律，研究其自动提升的可能性，并分析其他代数范畴中的存在条件。

Result: 部分情况下成立，但在其他代数范畴中不存在单调弱分配律。

Conclusion: 单调弱分配律在紧致Hausdorff空间中部分适用，但在其他代数范畴中普遍不存在。

Abstract: Noticing the similarity between the monotone weak distributive laws combining
two layers of nondeterminism in sets and in compact Hausdorff spaces, we study
whether the latter law can be obtained automatically as a weak lifting of the
former. This holds partially, but does not generalize to other categories of
algebras: we then characterize when exactly monotone weak distributive laws
over powerset monads in categories of algebras exist, exhibiting a law
combining probabilities and non-determinism in compact Hausdorff spaces and
showing on the other hand that such laws do not exist in a lot of other cases.

</details>


### [7] [Impact and Performance of Randomized Test-Generation using Prolog](https://arxiv.org/abs/2507.13178)
*Marcus Gelderie,Maximilian Luff,Maximilian Peltzer*

Main category: cs.LO

TL;DR: 研究使用Prolog随机生成测试序列的方法，分析随机化与SLD解析对测试性能的影响，并提出两种随机化策略。


<details>
  <summary>Details</summary>
Motivation: Prolog适合生成具有复杂逻辑依赖结构的测试序列，但面对大量或无限测试集时，随机化是自然选择。

Method: 提出两种随机化策略：一种基于标准Prolog语义，另一种修改SLD选择函数，并通过马尔可夫链分析性能。

Result: 分析了两种策略的平均测试用例生成时间和数量，并进行了实证评估与比较。

Conclusion: 研究为Prolog测试生成提供了有效的随机化方法，并通过理论分析和实证验证了其性能。

Abstract: We study randomized generation of sequences of test-inputs to a system using
Prolog. Prolog is a natural fit to generate test-sequences that have complex
logical inter-dependent structure. To counter the problems posed by a large (or
infinite) set of possible tests, randomization is a natural choice. We study
the impact that randomization in conjunction with SLD resolution have on the
test performance. To this end, this paper proposes two strategies to add
randomization to a test-generating program. One strategy works on top of
standard Prolog semantics, whereas the other alters the SLD selection function.
We analyze the mean time to reach a test-case, and the mean number of generated
test-cases in the framework of Markov chains. Finally, we provide an additional
empirical evaluation and comparison between both approaches. Under
consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [8] [Just Verification of Mutual Exclusion Algorithms](https://arxiv.org/abs/2507.13198)
*Rob van Glabbeek,Bas Luttik,Myrthe Spronck*

Main category: cs.LO

TL;DR: 通过模型检验验证多种互斥算法的正确性，关注共享读/写寄存器的原子性与非原子性，并使用公正性作为完整性标准。


<details>
  <summary>Details</summary>
Motivation: 验证互斥算法的正确性，特别是针对共享寄存器的不同工作假设。

Method: 采用模型检验方法，结合公正性作为完整性标准，分析多种并发关系。

Result: 展示了多个算法违反正确性属性的执行案例，并提出改进建议。

Conclusion: 公正性作为完整性标准能有效消除虚假反例，验证互斥算法的正确性。

Abstract: We verify the correctness of a variety of mutual exclusion algorithms through
model checking. We look at algorithms where communication is via shared
read/write registers, where those registers can be atomic or non-atomic. For
the verification of liveness properties, it is necessary to assume a
completeness criterion to eliminate spurious counterexamples. We use justness
as completeness criterion. Justness depends on a concurrency relation; we
consider several such relations, modelling different assumptions on the working
of the shared registers. We present executions demonstrating the violation of
correctness properties by several algorithms, and in some cases suggest
improvements.

</details>


### [9] [Solving SAT By Computing A Stable Set Of Points In Clusters](https://arxiv.org/abs/2507.13282)
*Eugene Goldberg*

Main category: cs.LO

TL;DR: 本文提出了一种通过集群计算稳定点集（SSP）的方法，以解决传统逐点计算不可行的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，计算CNF公式的SSP需要逐点处理，而实际应用中SSP规模庞大，导致计算不可行。

Method: 提出了一种集群计算SSP的方法，每个集群同时处理大量点。

Result: 该方法能够更好地利用公式结构，设计更高效的SAT算法，并支持并行计算。

Conclusion: 集群计算SSP为SAT求解提供了更高效和并行的解决方案。

Abstract: Earlier we introduced the notion of a stable set of points (SSP). We proved
that a CNF formula is unsatisfiable iff there is a set of points (i.e. complete
assignments) that is stable with respect to this formula. Experiments showed
that SSPs for CNF formulas of practical interest are very large. So computing
an SSP for a CNF formula point by point is, in general, infeasible. In this
report, we show how an SSP can be computed in clusters, each cluster being a
large set of points that are processed simultaneously. The appeal of computing
SSPs is twofold. First, it allows one to better take into account formula
structure and hence, arguably, design more efficient SAT algorithms. Second,
SAT solving by SSPs facilitates parallel computing.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [10] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 该论文调查了大型语言模型（LLMs）在AIOps中的应用，分析了183篇研究论文，探讨了数据来源、任务演变、方法应用和评估方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的普及，其在AIOps中的应用潜力与局限性尚未被充分理解，因此需要系统性的调查与分析。

Method: 通过分析2020年至2024年的183篇论文，回答了四个关键研究问题（RQs），涵盖数据来源、任务演变、方法应用和评估方法。

Result: 总结了LLMs在AIOps中的最新进展和趋势，并指出了现有研究的不足。

Conclusion: 论文为LLMs在AIOps领域的未来研究提供了方向，强调了进一步探索的必要性。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [11] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 使用大型语言模型（LLMs）作为量子SDK间的自动转译工具，解决跨平台开发的互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 量子SDK多样性导致互操作性和跨平台开发困难，传统规则转译方法耗时且维护成本高。

Method: 利用LLMs的预训练知识和上下文推理能力，实现量子程序在不同QSDK间的自动转译。

Result: 提出了一种无需手动定义规则的可扩展量子软件移植方案。

Conclusion: LLMs为量子计算生态中的智能通用转译提供了新方向。

Abstract: There exist various Software Development Kits (SDKs) tailored to different
quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples
include but are not limited to Qiskit, Cirq, and PennyLane. However, this
diversity presents significant challenges for interoperability and
cross-platform development of hybrid quantum-classical software systems.
Traditional rule-based transpilers for translating code between QSDKs are
time-consuming to design and maintain, requiring deep expertise and rigid
mappings in the source and destination code. In this study, we explore the use
of Large Language Models (LLMs) as a flexible and automated solution.
Leveraging their pretrained knowledge and contextual reasoning capabilities, we
position LLMs as programming language-agnostic transpilers capable of
converting quantum programs from one QSDK to another while preserving
functional equivalence. Our approach eliminates the need for manually defined
transformation rules and offers a scalable solution to quantum software
portability. This work represents a step toward enabling intelligent,
general-purpose transpilation in the quantum computing ecosystem.

</details>


### [12] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
*Ishraq Khan,Assad Chowdary,Sharoz Haseeb,Urvish Patel*

Main category: cs.SE

TL;DR: Kodezi Chronos是一种新型架构，用于自主代码理解、调试和维护，支持超长上下文，性能优于现有LLMs和代码模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLMs在代码生成和软件自动化中因上下文限制和缺乏显式代码结构推理而受限的问题。

Method: 采用多级嵌入内存引擎，结合向量和图索引，实现高效代码检索和推理。

Result: 在真实世界错误检测中提升23%，调试周期减少40%。

Conclusion: Kodezi Chronos为自主软件维护和优化生态系统提供了重要进展。

Abstract: Large Language Models (LLMs) have advanced code generation and software
automation, but are fundamentally constrained by limited inference-time context
and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a
next-generation architecture for autonomous code understanding, debugging, and
maintenance, designed to operate across ultra-long contexts comprising entire
codebases, histories, and documentation, all without fixed window limits.
Kodezi Chronos leverages a multi-level embedding memory engine, combining
vector and graph-based indexing with continuous code-aware retrieval. This
enables efficient and accurate reasoning over millions of lines of code,
supporting repository-scale comprehension, multi-file refactoring, and
real-time self-healing actions. Our evaluation introduces a novel Multi Random
Retrieval benchmark, specifically tailored to the software engineering domain.
Unlike classical retrieval benchmarks, this method requires the model to
resolve arbitrarily distant and obfuscated associations across code artifacts,
simulating realistic tasks such as variable tracing, dependency migration, and
semantic bug localization. Chronos outperforms prior LLMs and code models,
demonstrating a 23% improvement in real-world bug detection and reducing
debugging cycles by up to 40% compared to traditional sequence-based
approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos
enables seamless, autonomous software maintenance, elevating code reliability
and productivity while reducing manual effort. These results mark a critical
advance toward self-sustaining, continuously optimized software ecosystems.

</details>


### [13] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
*Dong Wang,Hanmo You,Lingwei Zhu,Kaiwei Lin,Zheng Chen,Chen Yang,Junji Yu,Zan Wang,Junjie Chen*

Main category: cs.SE

TL;DR: 该论文对强化学习（RL）在软件工程（SE）中的应用进行了首次系统性综述，分析了115篇研究，总结了趋势、分类和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着RL和大型语言模型（LLM）的发展，软件工程领域对自动化需求增加，但缺乏对RL应用的全面调查。

Method: 综述了115篇同行评审研究，分析了发表趋势、SE主题和RL算法分类，以及数据集、模型设计和评估实践。

Result: 提供了RL在SE中的系统性映射，总结了当前应用、挑战和未来研究方向。

Conclusion: 该调查为研究者和从业者提供了RL在SE领域的现状和未来方向，推动了该领域的发展。

Abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential
decision-making and has attracted growing interest across various domains,
particularly following the advent of Deep Reinforcement Learning (DRL) in 2015.
Simultaneously, the rapid advancement of Large Language Models (LLMs) has
further fueled interest in integrating RL with LLMs to enable more adaptive and
intelligent systems. In the field of software engineering (SE), the increasing
complexity of systems and the rising demand for automation have motivated
researchers to apply RL to a broad range of tasks, from software design and
development to quality assurance and maintenance. Despite growing research in
RL-for-SE, there remains a lack of a comprehensive and systematic survey of
this evolving field. To address this gap, we reviewed 115 peer-reviewed studies
published across 22 premier SE venues since the introduction of DRL. We
conducted a comprehensive analysis of publication trends, categorized SE topics
and RL algorithms, and examined key factors such as dataset usage, model design
and optimization, and evaluation practices. Furthermore, we identified open
challenges and proposed future research directions to guide and inspire ongoing
work in this evolving area. To summarize, this survey offers the first
systematic mapping of RL applications in software engineering, aiming to
support both researchers and practitioners in navigating the current landscape
and advancing the field. Our artifacts are publicly available:
https://github.com/KaiWei-Lin-lanina/RL4SE.

</details>


### [14] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
*Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen*

Main category: cs.SE

TL;DR: 论文提出了一种名为RAGSum的新方法，通过结合检索和生成技术，自动为源代码生成简洁且信息丰富的注释，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 自动生成源代码注释可以减轻文档编写负担并加速程序理解，但现有检索增强方法中检索和生成通常独立优化，导致噪声传播。

Method: RAGSum基于CodeT5框架，通过对比预训练阶段优化代码嵌入，并结合检索和生成的复合损失函数进行端到端训练，同时采用轻量级自优化循环优化输出。

Result: 在Java、Python和C三种语言的基准测试中，RAGSum在BLEU、METEOR和ROUGE-L指标上显著优于三种基线方法。

Conclusion: 紧密耦合检索和生成可以提高注释自动化的效果，为未来研究和开发者研究提供了方向。

Abstract: Automatically generating concise, informative comments for source code can
lighten documentation effort and accelerate program comprehension.
Retrieval-augmented approaches first fetch code snippets with existing comments
and then synthesize a new comment, yet retrieval and generation are typically
optimized in isolation, allowing irrelevant neighbors topropagate noise
downstream. To tackle the issue, we propose a novel approach named RAGSum with
the aim of both effectiveness and efficiency in recommendations. RAGSum is
built on top offuse retrieval and generation using a single CodeT5 backbone. We
report preliminary results on a unified retrieval-generation framework built on
CodeT5. A contrastive pre-training phase shapes code embeddings for
nearest-neighbor search; these weights then seed end-to-end training with a
composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes
comment-generation error. More importantly, a lightweight self-refinement loop
is deployed to polish the final output. We evaluated theframework on three
cross-language benchmarks (Java, Python, C), and compared it with three
well-established baselines. The results show that our approach substantially
outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These
findings indicate that tightly coupling retrieval and generationcan raise the
ceiling for comment automation and motivateforthcoming replications and
qualitative developer studies.

</details>


### [15] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
*Samal Nursapa,Anastassiya Samuilova,Alessio Bucaioni. Phuong T. Nguyen*

Main category: cs.SE

TL;DR: 论文探讨了使用预训练Transformer模型（CodeBERT和CodeT5）为检测到的架构异味推荐重构方法，CodeT5表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有工具能检测架构异味但缺乏修复建议，研究旨在填补这一空白。

Method: 将任务定义为三分类问题，并在大量开源Java项目数据上微调模型。

Result: CodeT5达到96.9%准确率和95.2% F1分数，优于其他方法。

Conclusion: Transformer模型能有效连接异味检测与修复，为未来重构推荐系统奠定基础。

Abstract: Architectural smells such as God Class, Cyclic Dependency, and Hub-like
Dependency degrade software quality and maintainability. Existing tools detect
such smells but rarely suggest how to fix them. This paper explores the use of
pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable
refactorings based on detected smells. We frame the task as a three-class
classification problem and fine-tune both models on over 2 million refactoring
instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%
accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our
results show that transformer-based models can effectively bridge the gap
between smell detection and actionable repair, laying the foundation for future
refactoring recommendation systems. We release all code, models, and data under
an open license to support reproducibility and further research.

</details>


### [16] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
*Kiana Kheiri,Aamna Aamir,Andriy Miranskyy,Chen Ding*

Main category: cs.SE

TL;DR: 论文通过GRPO和ORPO两种强化学习方法微调32B模型，显著提升了量子编程代码生成的准确性，但仍存在高级任务未解决的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决量子电路中代码生成错误率高的问题，提升AI辅助量子编程的可靠性。

Method: 使用GRPO和ORPO两种强化学习方法对32B模型进行微调，并利用合成数据集进行训练。

Result: 在Qiskit HumanEval基准测试中，ORPO达到56.29% Pass@1，GRPO为49%，均优于通用基线；在原始HumanEval中分别为65.90%和63.00%。

Conclusion: GRPO和ORPO在基础和中級任务中表现优异，但高级任务仍有改进空间，显示了AI辅助量子编程的潜力与挑战。

Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and
StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two
RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference
Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit
HumanEval benchmark, ORPO reaches 56.29\% Pass@1 ($\approx+10$ pp over
Granite-8B-QK) and GRPO hits 49\%, both beating all general-purpose baselines;
on the original HumanEval they score 65.90\% and 63.00\%. GRPO excels on basic
tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five
advanced tasks, highlighting clear gains yet room for progress in AI-assisted
quantum programming.

</details>


### [17] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
*Christine van Stiphoudt,Sergio Potenciano Menci,Gilbert Fridgen*

Main category: cs.SE

TL;DR: 本文提出了一种结合显式和隐式评估方法的三阶段评估方法，用于智能电网中新设计的信息和数据模型。


<details>
  <summary>Details</summary>
Motivation: 智能电网数字化导致信息交换增加，现有模型不足，需在设计阶段评估新模型以避免潜在问题。

Method: 采用设计科学研究方法，设计三阶段评估方法，结合显式和隐式评估，并以工业灵活性描述的信息和数据模型为例进行验证。

Result: 提出了一种适用于新模型开发的评估方法，并通过案例研究验证其有效性。

Conclusion: 该方法填补了智能电网领域新模型评估的空白，并提供了实践经验。

Abstract: The ongoing digitalisation of the smart grid is resulting in an increase in
automated information exchanges across distributed energy systems. This process
has led to the development of new information and data models when the existing
ones fall short. To prevent potential disruptions caused by flaws in the newly
designed information and data models, it is essential to evaluate them during
the design process before they are implemented in operation.
  Currently, general explicit evaluation approaches outside the smart grid
domain stay at a high level without defining clear steps. Meanwhile, implicit
evaluation approaches in the smart grid domain focus on testing systems that
utilise information and data models already in use for functionality in terms
of conformance and interoperability. Notably, no combination of explicit and
implicit evaluation approaches for newly designed information and data models
offers a clearly defined set of steps during their design process in the smart
grid context.
  Consequently, we design a three-phase evaluation approach using design
science research to address this gap. Our evaluation approach combines explicit
and implicit evaluation methods and is applicable when developing new
information and data models. We use the development of an information model and
data model focused on industrial flexibility descriptions to refine our
evaluation approach. Additionally, we provide lessons learned from our
experience.

</details>


### [18] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 论文提出了一种结合模糊逻辑的新方法，用于更准确地评估项目成功，强调对终端用户的持续积极影响。


<details>
  <summary>Details</summary>
Motivation: 传统Likert量表方法忽视了项目成功的多面性和情境依赖性，需要更动态的评估方式。

Method: 采用分层Type-1 Mamdani模糊系统，减少对次要结果（如利益相关者满意度）的依赖。

Result: 该方法可能提供更准确的项目成功衡量，并适用于复杂评估。

Conclusion: 未来研究将聚焦于实证测试和模糊逻辑在社会科学中的广泛应用。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


### [19] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
*Salvador D. Escobedo*

Main category: cs.SE

TL;DR: 提出了一种名为SCM的新方法，通过单一持续对话结构利用LLMs进行软件开发，强调开发者的主动角色。


<details>
  <summary>Details</summary>
Motivation: 当前对LLMs的被动依赖需要纠正，SCM旨在重新确立开发者作为架构和监督者的角色。

Method: SCM基于认知清晰性、可追溯性、模块化和文档化原则，定义开发阶段和最佳实践。

Result: SCM提供了一种结构化方法，替代了当前与生成式AI的临时交互模式。

Conclusion: SCM为LLMs在软件开发中的应用提供了更主动和结构化的方法论。

Abstract: We propose the Single Conversation Methodology (SCM), a novel and pragmatic
approach to software development using large language models (LLMs). In
contrast to ad hoc interactions with generative AI, SCM emphasizes a structured
and persistent development dialogue, where all stages of a project - from
requirements to architecture and implementation - unfold within a single,
long-context conversation. The methodology is grounded on principles of
cognitive clarity, traceability, modularity, and documentation. We define its
phases, best practices, and philosophical stance, while arguing that SCM offers
a necessary correction to the passive reliance on LLMs prevalent in current
practices. We aim to reassert the active role of the developer as architect and
supervisor of the intelligent tool.

</details>


### [20] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
*Keila Lucas,Rohit Gheyi,Márcio Ribeiro,Fabio Palomba,Luana Martins,Elvys Soares*

Main category: cs.SE

TL;DR: 研究探讨了小型语言模型（SLMs）在自动检测测试异味（test smells）中的潜力，评估了Gemma3、Llama3.2和Phi-4在真实测试案例中的表现，Phi-4表现最佳。


<details>
  <summary>Details</summary>
Motivation: 手动测试中的测试异味（如模糊性、冗余或缺失检查）降低了测试的可靠性和可维护性，现有检测工具需手动定义规则且缺乏扩展性。

Method: 评估了Gemma3、Llama3.2和Phi-4在143个真实Ubuntu测试案例中检测七种测试异味的能力。

Result: Phi-4表现最佳，检测成功率达97%，Gemma3和Llama3.2约为91%。SLMs还能自主解释问题并提出改进建议。

Conclusion: SLMs可作为高效工具，无需依赖大量规则定义或语法分析，提升测试质量并保护数据隐私。

Abstract: Manual testing, in which testers follow natural language instructions to
validate system behavior, remains crucial for uncovering issues not easily
captured by automation. However, these test cases often suffer from test
smells, quality issues such as ambiguity, redundancy, or missing checks that
reduce test reliability and maintainability. While detection tools exist, they
typically require manual rule definition and lack scalability. This study
investigates the potential of Small Language Models (SLMs) for automatically
detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143
real-world Ubuntu test cases, covering seven types of test smells. Phi-4
achieved the best results, reaching a pass@2 of 97% in detecting sentences with
test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond
detection, SLMs autonomously explained issues and suggested improvements, even
without explicit prompt instructions. They enabled low-cost, concept-driven
identification of diverse test smells without relying on extensive rule
definitions or syntactic analysis. These findings highlight the potential of
SLMs as efficient tools that preserve data privacy and can improve test quality
in real-world scenarios.

</details>


### [21] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
*Dongming Jin,Weisong Sun,Jiangping Huang,Peng Liang,Jifeng Xuan,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: iReDev是一个知识驱动的多智能体框架，用于智能需求开发，通过整合人类知识和事件驱动机制，提升需求开发的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 需求开发是软件工程中的关键阶段，但传统方法耗时耗力，且现有研究对多智能体系统的支持有限，缺乏人类知识与智能体的整合。

Method: iReDev框架包含六个知识驱动的智能体，通过事件驱动的通信机制和人工介入机制，协作完成需求开发任务。

Result: 评估表明，iReDev在多个方面优于现有基线方法。

Conclusion: iReDev为智能需求开发提供了新方向，未来可进一步探索其潜力。

Abstract: Requirements development is a critical phase as it is responsible for
providing a clear understanding of what stakeholders need. It involves
collaboration among stakeholders to extract explicit requirements and address
potential conflicts, which is time-consuming and labor-intensive. Recently,
multi-agent systems for software development have attracted much attention.
However, existing research provides limited support for requirements
development and overlooks the injection of human knowledge into agents and the
human-agent collaboration. % To address these issues, this paper proposes a
knowledge-driven multi-agent framework for intelligent requirement development,
named iReDev. iReDev features: iReDev consists of six knowledge-driven agents
to support the entire requirements development. They collaboratively perform
various tasks to produce a software requirements specification. iReDev focuses
on integrating human knowledge for agents, enabling them to simulate real-world
stakeholders. iReDev uses an event-driven communication mechanism based on an
artifact pool. Agents continuously monitor the pool and autonomously trigger
the next action based on its changes, enabling iReDev to handle new
requirements quickly. iReDev introduces a human-in-the-loop mechanism to
support human-agent collaboration, ensuring that the generated artifacts align
with the expectations of stakeholders. We evaluated the generated artifacts and
results show that iReDev outperforms existing baselines in multiple aspects. We
further envision three key directions and hope this work can facilitate the
development of intelligent requirements development.

</details>


### [22] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
*Dongming Jin,Zhi Jin,Linyu Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: 论文探讨了预训练模型在现代软件系统中的集成及其对需求工程的挑战，提出了一个针对此类系统的概念框架和研究方向。


<details>
  <summary>Details</summary>
Motivation: 预训练模型的广泛应用对传统需求工程的确定性假设提出了挑战，需要重新思考方法论。

Method: 提出了一个针对预训练模型软件系统的概念框架，并概述了相关研究方向。

Result: 框架为研究人员和实践者提供了应对预训练模型系统需求工程挑战的指导。

Conclusion: 论文呼吁重新思考需求工程方法，以适应预训练模型带来的新特性，并提出了未来研究方向。

Abstract: Recent advances in large pretrained models have led to their widespread
integration as core components in modern software systems. The trend is
expected to continue in the foreseeable future. Unlike traditional software
systems governed by deterministic logic, systems powered by pretrained models
exhibit distinctive and emergent characteristics, such as ambiguous capability
boundaries, context-dependent behavior, and continuous evolution. These
properties fundamentally challenge long-standing assumptions in requirements
engineering, including functional decomposability and behavioral
predictability. This paper investigates this problem and advocates for a
rethinking of existing requirements engineering methodologies. We propose a
conceptual framework tailored to requirements engineering of
pretrained-model-enabled software systems and outline several promising
research directions within this framework. This vision helps provide a guide
for researchers and practitioners to tackle the emerging challenges in
requirements engineering of pretrained-model-enabled systems.

</details>


### [23] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.SE

TL;DR: 提出了一种从递归下降解析器实现中推断属性文法的新方法，以恢复输入处理的语义规范。


<details>
  <summary>Details</summary>
Motivation: 现有语法挖掘技术主要关注语法结构恢复，而输入处理的语义规范仍未被充分探索。

Method: 通过动态分析递归下降解析器的实现，将运行时行为映射到文法中，提取并嵌入语义动作。

Result: 实验表明，该方法能准确通过生成的属性文法重现程序行为。

Conclusion: 该方法为输入处理的语义规范恢复提供了可行途径。

Abstract: Software systems that process structured inputs often lack complete and
up-to-date specifications, which specify the input syntax and the semantics of
input processing. While grammar mining techniques have focused on recovering
syntactic structures, the semantics of input processing remains largely
unexplored. In this work, we introduce a novel approach for inferring
attributed grammars from parser implementations. Given an input grammar, our
technique dynamically analyzes the implementation of recursive descent parsers
to reconstruct the semantic aspects of input handling, resulting in
specifications in the form of attributed grammars. By observing program
executions and mapping the program's runtime behavior to the grammar, we
systematically extract and embed semantic actions into the grammar rules. This
enables comprehensive specification recovery. We demonstrate the feasibility of
our approach using an initial set of programs, showing that it can accurately
reproduce program behavior through the generated attributed grammars.

</details>


### [24] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
*Xin Yin,Xinrui Li,Chao Ni,Xiaodan Xu,Xiaohu Yang*

Main category: cs.SE

TL;DR: 论文提出CodeGPTSensor+，通过对抗训练增强对修改后LLM生成代码的检测鲁棒性，解决了现有方法在代码修改后检测效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成代码的广泛应用，代码来源监管、版权争议和质量问题日益突出，但现有检测方法对修改后的代码鲁棒性不足。

Method: 提出CodeGPTSensor+，集成对抗样本生成模块MIST，通过多目标标识符和结构转换生成高质量对抗样本，提升模型鲁棒性。

Result: 在HMCorp数据集上，CodeGPTSensor+显著提升对抗测试集的检测准确率，同时保持原始测试集的高准确率。

Conclusion: CodeGPTSensor+在检测修改后的LLM生成代码方面表现出优越的鲁棒性，为实际应用提供了有效解决方案。

Abstract: With the rapid development of Large Language Models (LLMs), their powerful
code-generation capabilities have been widely applied in tasks like code
completion and automated development, demonstrating the value of improving
coding efficiency. However, the extensive use of LLM-generated code also raises
several new challenges. On the one hand, issues such as the regulation of code
provenance, copyright disputes, and code quality have become increasingly
concerning. How to effectively detect LLM-generated code and ensure its
compliant and responsible use has become a critical and urgent issue. On the
other hand, in practical applications, LLM-generated code is often subject to
manual modifications, such as variable renaming or structural adjustments.
Although some recent studies have proposed training-based and zero-shot methods
for detecting LLM-generated code, these approaches show insufficient robustness
when facing modified LLM-generated code, and there is a lack of an effective
solution. To address the real-world scenario where LLM-generated code may
undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of
CodeGPTSensor, which employs adversarial training to improve robustness against
input perturbations. CodeGPTSensor+ integrates an adversarial sample generation
module, Multi-objective Identifier and Structure Transformation (MIST), which
systematically generates both high-quality and representative adversarial
samples. This module effectively enhances the model's resistance against
diverse adversarial attacks. Experimental results on the HMCorp dataset
demonstrate that CodeGPTSensor+ significantly improves detection accuracy on
the adversarial test set while maintaining high accuracy on the original test
set, showcasing superior robustness compared to CodeGPTSensor.

</details>
