<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 15]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: Survey on LLMs in AIOps, analyzing 183 papers to explore data sources, task evolution, methods, and evaluation, with future research directions.


<details>
  <summary>Details</summary>
Motivation: Understand impact, potential, and limitations of LLMs in AIOps due to lack of comprehensive research.

Method: Survey of 183 papers (2020-2024) addressing four research questions on data, tasks, methods, and evaluation.

Result: Identified advancements, trends, and gaps in LLM4AIOps, highlighting novel tasks and evaluation needs.

Conclusion: Proposes future research directions to address gaps and leverage LLMs for AIOps optimization.

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [2] [LLM-Powered Quantum Code Transpilation](https://arxiv.org/abs/2507.12480)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: LLMs are proposed as a flexible, automated solution for translating quantum programs between QSDKs, eliminating manual rule-based transpilers.


<details>
  <summary>Details</summary>
Motivation: Diverse QSDKs create interoperability challenges; traditional transpilers are rigid and labor-intensive.

Method: Uses LLMs for language-agnostic transpilation of quantum programs, preserving functional equivalence.

Result: LLMs enable scalable, automated quantum software portability without manual rules.

Conclusion: LLMs offer a step toward intelligent, general-purpose transpilation in quantum computing.

Abstract: There exist various Software Development Kits (SDKs) tailored to different
quantum computing platforms. These are known as Quantum SDKs (QSDKs). Examples
include but are not limited to Qiskit, Cirq, and PennyLane. However, this
diversity presents significant challenges for interoperability and
cross-platform development of hybrid quantum-classical software systems.
Traditional rule-based transpilers for translating code between QSDKs are
time-consuming to design and maintain, requiring deep expertise and rigid
mappings in the source and destination code. In this study, we explore the use
of Large Language Models (LLMs) as a flexible and automated solution.
Leveraging their pretrained knowledge and contextual reasoning capabilities, we
position LLMs as programming language-agnostic transpilers capable of
converting quantum programs from one QSDK to another while preserving
functional equivalence. Our approach eliminates the need for manually defined
transformation rules and offers a scalable solution to quantum software
portability. This work represents a step toward enabling intelligent,
general-purpose transpilation in the quantum computing ecosystem.

</details>


### [3] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding](https://arxiv.org/abs/2507.12482)
*Ishraq Khan,Assad Chowdary,Sharoz Haseeb,Urvish Patel*

Main category: cs.SE

TL;DR: Kodezi Chronos enhances code generation and maintenance by overcoming LLM limitations with a multi-level embedding memory engine, improving bug detection by 23% and reducing debugging cycles by 40%.


<details>
  <summary>Details</summary>
Motivation: LLMs are limited by context constraints and lack of code structure reasoning, hindering large-scale code understanding and maintenance.

Method: Kodezi Chronos uses a multi-level embedding memory engine for efficient reasoning over entire codebases, supporting tasks like refactoring and bug detection.

Result: Outperforms prior models with 23% better bug detection and 40% faster debugging, integrating seamlessly with IDEs and CI/CD workflows.

Conclusion: Chronos advances autonomous software maintenance, improving reliability and productivity while reducing manual effort.

Abstract: Large Language Models (LLMs) have advanced code generation and software
automation, but are fundamentally constrained by limited inference-time context
and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a
next-generation architecture for autonomous code understanding, debugging, and
maintenance, designed to operate across ultra-long contexts comprising entire
codebases, histories, and documentation, all without fixed window limits.
Kodezi Chronos leverages a multi-level embedding memory engine, combining
vector and graph-based indexing with continuous code-aware retrieval. This
enables efficient and accurate reasoning over millions of lines of code,
supporting repository-scale comprehension, multi-file refactoring, and
real-time self-healing actions. Our evaluation introduces a novel Multi Random
Retrieval benchmark, specifically tailored to the software engineering domain.
Unlike classical retrieval benchmarks, this method requires the model to
resolve arbitrarily distant and obfuscated associations across code artifacts,
simulating realistic tasks such as variable tracing, dependency migration, and
semantic bug localization. Chronos outperforms prior LLMs and code models,
demonstrating a 23% improvement in real-world bug detection and reducing
debugging cycles by up to 40% compared to traditional sequence-based
approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos
enables seamless, autonomous software maintenance, elevating code reliability
and productivity while reducing manual effort. These results mark a critical
advance toward self-sustaining, continuously optimized software ecosystems.

</details>


### [4] [A Survey of Reinforcement Learning for Software Engineering](https://arxiv.org/abs/2507.12483)
*Dong Wang,Hanmo You,Lingwei Zhu,Kaiwei Lin,Zheng Chen,Chen Yang,Junji Yu,Zan Wang,Junjie Chen*

Main category: cs.SE

TL;DR: This survey systematically maps RL applications in SE, analyzing 115 studies to identify trends, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of SE tasks and demand for automation motivate integrating RL with SE, yet no comprehensive survey exists.

Method: Reviewed 115 peer-reviewed studies from 22 SE venues, analyzing trends, algorithms, datasets, and evaluation practices.

Result: Identified key RL applications in SE, categorized topics/algorithms, and highlighted open challenges.

Conclusion: Provides the first systematic survey of RL-for-SE, offering guidance for researchers and practitioners to advance the field.

Abstract: Reinforcement Learning (RL) has emerged as a powerful paradigm for sequential
decision-making and has attracted growing interest across various domains,
particularly following the advent of Deep Reinforcement Learning (DRL) in 2015.
Simultaneously, the rapid advancement of Large Language Models (LLMs) has
further fueled interest in integrating RL with LLMs to enable more adaptive and
intelligent systems. In the field of software engineering (SE), the increasing
complexity of systems and the rising demand for automation have motivated
researchers to apply RL to a broad range of tasks, from software design and
development to quality assurance and maintenance. Despite growing research in
RL-for-SE, there remains a lack of a comprehensive and systematic survey of
this evolving field. To address this gap, we reviewed 115 peer-reviewed studies
published across 22 premier SE venues since the introduction of DRL. We
conducted a comprehensive analysis of publication trends, categorized SE topics
and RL algorithms, and examined key factors such as dataset usage, model design
and optimization, and evaluation practices. Furthermore, we identified open
challenges and proposed future research directions to guide and inspire ongoing
work in this evolving area. To summarize, this survey offers the first
systematic mapping of RL applications in software engineering, aiming to
support both researchers and practitioners in navigating the current landscape
and advancing the field. Our artifacts are publicly available:
https://github.com/KaiWei-Lin-lanina/RL4SE.

</details>


### [5] [When Retriever Meets Generator: A Joint Model for Code Comment Generation](https://arxiv.org/abs/2507.12558)
*Tien P. T. Le,Anh M. T. Bui,Huy N. D. Pham,Alessio Bucaioni,Phuong T. Nguyen*

Main category: cs.SE

TL;DR: RAGSum, a novel approach combining retrieval and generation for code comments, outperforms baselines by tightly coupling these tasks.


<details>
  <summary>Details</summary>
Motivation: To improve comment automation by addressing noise propagation in retrieval-augmented methods.

Method: Uses CodeT5 backbone with contrastive pre-training, composite loss, and self-refinement.

Result: Outperforms baselines on BLEU, METEOR, and ROUTE-L metrics across Java, Python, and C.

Conclusion: Tight coupling of retrieval and generation enhances comment automation, warranting further study.

Abstract: Automatically generating concise, informative comments for source code can
lighten documentation effort and accelerate program comprehension.
Retrieval-augmented approaches first fetch code snippets with existing comments
and then synthesize a new comment, yet retrieval and generation are typically
optimized in isolation, allowing irrelevant neighbors topropagate noise
downstream. To tackle the issue, we propose a novel approach named RAGSum with
the aim of both effectiveness and efficiency in recommendations. RAGSum is
built on top offuse retrieval and generation using a single CodeT5 backbone. We
report preliminary results on a unified retrieval-generation framework built on
CodeT5. A contrastive pre-training phase shapes code embeddings for
nearest-neighbor search; these weights then seed end-to-end training with a
composite loss that (i) rewards accurate top-k retrieval; and (ii) minimizes
comment-generation error. More importantly, a lightweight self-refinement loop
is deployed to polish the final output. We evaluated theframework on three
cross-language benchmarks (Java, Python, C), and compared it with three
well-established baselines. The results show that our approach substantially
outperforms thebaselines with respect to BLEU, METEOR, and ROUTE-L. These
findings indicate that tightly coupling retrieval and generationcan raise the
ceiling for comment automation and motivateforthcoming replications and
qualitative developer studies.

</details>


### [6] [ROSE: Transformer-Based Refactoring Recommendation for Architectural Smells](https://arxiv.org/abs/2507.12561)
*Samal Nursapa,Anastassiya Samuilova,Alessio Bucaioni. Phuong T. Nguyen*

Main category: cs.SE

TL;DR: Transformer models (CodeBERT, CodeT5) are fine-tuned to recommend refactorings for architectural smells, with CodeT5 outperforming others at 96.9% accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing tools detect architectural smells but lack actionable fixes, prompting the use of AI for refactoring recommendations.

Method: Fine-tuned CodeBERT and CodeT5 on 2M+ refactoring instances from 11,149 Java projects, framing it as a three-class classification task.

Result: CodeT5 achieved 96.9% accuracy and 95.2% F1, surpassing CodeBERT and traditional methods.

Conclusion: Transformer models effectively link smell detection to actionable fixes, paving the way for advanced refactoring recommendation systems.

Abstract: Architectural smells such as God Class, Cyclic Dependency, and Hub-like
Dependency degrade software quality and maintainability. Existing tools detect
such smells but rarely suggest how to fix them. This paper explores the use of
pre-trained transformer models--CodeBERT and CodeT5--for recommending suitable
refactorings based on detected smells. We frame the task as a three-class
classification problem and fine-tune both models on over 2 million refactoring
instances mined from 11,149 open-source Java projects. CodeT5 achieves 96.9%
accuracy and 95.2% F1, outperforming CodeBERT and traditional baselines. Our
results show that transformer-based models can effectively bridge the gap
between smell detection and actionable repair, laying the foundation for future
refactoring recommendation systems. We release all code, models, and data under
an open license to support reproducibility and further research.

</details>


### [7] [QSpark: Towards Reliable Qiskit Code Generation](https://arxiv.org/abs/2507.12642)
*Kiana Kheiri,Aamna Aamir,Andriy Miranskyy,Chen Ding*

Main category: cs.SE

TL;DR: Fine-tuned 32B model with GRPO and ORPO outperforms baselines in Qiskit HumanEval, but struggles with advanced tasks.


<details>
  <summary>Details</summary>
Motivation: Address error resilience in quantum circuits by improving AI-generated Qiskit code.

Method: Fine-tuned 32B model using GRPO and ORPO on synthetic dataset.

Result: ORPO: 56.29% Pass@1, GRPO: 49% on Qiskit HumanEval; both beat baselines.

Conclusion: Clear progress in AI-assisted quantum programming, but advanced tasks remain unsolved.

Abstract: Quantum circuits must be error-resilient, yet LLMs like Granite-20B-Code and
StarCoder often output flawed Qiskit code. We fine-tuned a 32 B model with two
RL methods, Group Relative Policy Optimization (GRPO) and Odds-Ratio Preference
Optimization (ORPO), using a richly annotated synthetic dataset. On the Qiskit
HumanEval benchmark, ORPO reaches 56.29\% Pass@1 ($\approx+10$ pp over
Granite-8B-QK) and GRPO hits 49\%, both beating all general-purpose baselines;
on the original HumanEval they score 65.90\% and 63.00\%. GRPO excels on basic
tasks (42/54), ORPO on intermediate ones (41/68), and neither solves the five
advanced tasks, highlighting clear gains yet room for progress in AI-assisted
quantum programming.

</details>


### [8] [A Three-Phase Evaluation Approach for new Information and Data Models in the Smart Grid Domain](https://arxiv.org/abs/2507.12649)
*Christine van Stiphoudt,Sergio Potenciano Menci,Gilbert Fridgen*

Main category: cs.SE

TL;DR: The paper proposes a three-phase evaluation approach combining explicit and implicit methods to assess newly designed information and data models in smart grids, addressing gaps in current evaluation practices.


<details>
  <summary>Details</summary>
Motivation: Existing evaluation approaches for smart grid information and data models are either too high-level (explicit) or limited to testing operational systems (implicit), lacking a combined method for design-phase evaluation.

Method: A three-phase evaluation approach using design science research, combining explicit and implicit methods, is developed and refined through the creation of industrial flexibility description models.

Result: The proposed approach successfully integrates explicit and implicit evaluation methods, providing a structured process for assessing new models during their design phase.

Conclusion: The study fills a critical gap in smart grid model evaluation, offering practical insights and lessons learned for future implementations.

Abstract: The ongoing digitalisation of the smart grid is resulting in an increase in
automated information exchanges across distributed energy systems. This process
has led to the development of new information and data models when the existing
ones fall short. To prevent potential disruptions caused by flaws in the newly
designed information and data models, it is essential to evaluate them during
the design process before they are implemented in operation.
  Currently, general explicit evaluation approaches outside the smart grid
domain stay at a high level without defining clear steps. Meanwhile, implicit
evaluation approaches in the smart grid domain focus on testing systems that
utilise information and data models already in use for functionality in terms
of conformance and interoperability. Notably, no combination of explicit and
implicit evaluation approaches for newly designed information and data models
offers a clearly defined set of steps during their design process in the smart
grid context.
  Consequently, we design a three-phase evaluation approach using design
science research to address this gap. Our evaluation approach combines explicit
and implicit evaluation methods and is applicable when developing new
information and data models. We use the development of an information model and
data model focused on industrial flexibility descriptions to refine our
evaluation approach. Additionally, we provide lessons learned from our
experience.

</details>


### [9] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: A novel fuzzy logic approach enhances project success evaluation by prioritizing end-user impact over traditional Likert-scale measures.


<details>
  <summary>Details</summary>
Motivation: Traditional methods overlook context-dependent and multifaceted aspects of project success.

Method: Hierarchical Type-1 Mamdani fuzzy system prioritizes sustained positive impact for end-users.

Result: More accurate project success measurement, adaptable to complex evaluations.

Conclusion: Future research will test empirically and explore broader fuzzy logic applications in social science.

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>


### [10] [Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development](https://arxiv.org/abs/2507.12665)
*Salvador D. Escobedo*

Main category: cs.SE

TL;DR: SCM is a structured methodology for software development using LLMs, emphasizing persistent dialogue and developer control.


<details>
  <summary>Details</summary>
Motivation: Addresses the ad hoc use of LLMs by promoting structured, traceable development.

Method: Uses a single, long-context conversation for all project stages, grounded in clarity and modularity.

Result: Proposes a corrective to passive LLM reliance, reasserting developer agency.

Conclusion: SCM offers a pragmatic, developer-centric approach to leveraging LLMs in software development.

Abstract: We propose the Single Conversation Methodology (SCM), a novel and pragmatic
approach to software development using large language models (LLMs). In
contrast to ad hoc interactions with generative AI, SCM emphasizes a structured
and persistent development dialogue, where all stages of a project - from
requirements to architecture and implementation - unfold within a single,
long-context conversation. The methodology is grounded on principles of
cognitive clarity, traceability, modularity, and documentation. We define its
phases, best practices, and philosophical stance, while arguing that SCM offers
a necessary correction to the passive reliance on LLMs prevalent in current
practices. We aim to reassert the active role of the developer as architect and
supervisor of the intelligent tool.

</details>


### [11] [Investigating the Performance of Small Language Models in Detecting Test Smells in Manual Test Cases](https://arxiv.org/abs/2507.13035)
*Keila Lucas,Rohit Gheyi,Márcio Ribeiro,Fabio Palomba,Luana Martins,Elvys Soares*

Main category: cs.SE

TL;DR: SLMs like Phi-4, Gemma3, and Llama3.2 effectively detect test smells in manual testing, with Phi-4 achieving 97% accuracy, outperforming others. They also autonomously explain issues and suggest improvements.


<details>
  <summary>Details</summary>
Motivation: Manual testing suffers from test smells (ambiguity, redundancy, etc.), reducing reliability. Existing tools lack scalability and require manual rules.

Method: Evaluated SLMs (Gemma3, Llama3.2, Phi-4) on 143 Ubuntu test cases for seven test smell types.

Result: Phi-4 achieved 97% pass@2 accuracy, outperforming Gemma3 (91%) and Llama3.2 (91%). SLMs also autonomously explained and suggested fixes.

Conclusion: SLMs offer scalable, low-cost test smell detection without extensive rules, improving test quality while preserving privacy.

Abstract: Manual testing, in which testers follow natural language instructions to
validate system behavior, remains crucial for uncovering issues not easily
captured by automation. However, these test cases often suffer from test
smells, quality issues such as ambiguity, redundancy, or missing checks that
reduce test reliability and maintainability. While detection tools exist, they
typically require manual rule definition and lack scalability. This study
investigates the potential of Small Language Models (SLMs) for automatically
detecting test smells. We evaluate Gemma3, Llama3.2, and Phi-4 on 143
real-world Ubuntu test cases, covering seven types of test smells. Phi-4
achieved the best results, reaching a pass@2 of 97% in detecting sentences with
test smells, while Gemma3 and Llama3.2 reached approximately 91%. Beyond
detection, SLMs autonomously explained issues and suggested improvements, even
without explicit prompt instructions. They enabled low-cost, concept-driven
identification of diverse test smells without relying on extensive rule
definitions or syntactic analysis. These findings highlight the potential of
SLMs as efficient tools that preserve data privacy and can improve test quality
in real-world scenarios.

</details>


### [12] [iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development](https://arxiv.org/abs/2507.13081)
*Dongming Jin,Weisong Sun,Jiangping Huang,Peng Liang,Jifeng Xuan,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: iReDev is a knowledge-driven multi-agent framework for intelligent requirements development, integrating human knowledge and enabling human-agent collaboration to outperform existing baselines.


<details>
  <summary>Details</summary>
Motivation: Existing multi-agent systems lack support for requirements development and human-agent collaboration, prompting the need for iReDev.

Method: iReDev uses six knowledge-driven agents, an event-driven communication mechanism, and a human-in-the-loop approach to collaboratively develop software requirements.

Result: iReDev outperforms existing baselines in generating software requirements specifications.

Conclusion: iReDev advances intelligent requirements development and suggests future directions for further research.

Abstract: Requirements development is a critical phase as it is responsible for
providing a clear understanding of what stakeholders need. It involves
collaboration among stakeholders to extract explicit requirements and address
potential conflicts, which is time-consuming and labor-intensive. Recently,
multi-agent systems for software development have attracted much attention.
However, existing research provides limited support for requirements
development and overlooks the injection of human knowledge into agents and the
human-agent collaboration. % To address these issues, this paper proposes a
knowledge-driven multi-agent framework for intelligent requirement development,
named iReDev. iReDev features: iReDev consists of six knowledge-driven agents
to support the entire requirements development. They collaboratively perform
various tasks to produce a software requirements specification. iReDev focuses
on integrating human knowledge for agents, enabling them to simulate real-world
stakeholders. iReDev uses an event-driven communication mechanism based on an
artifact pool. Agents continuously monitor the pool and autonomously trigger
the next action based on its changes, enabling iReDev to handle new
requirements quickly. iReDev introduces a human-in-the-loop mechanism to
support human-agent collaboration, ensuring that the generated artifacts align
with the expectations of stakeholders. We evaluated the generated artifacts and
results show that iReDev outperforms existing baselines in multiple aspects. We
further envision three key directions and hope this work can facilitate the
development of intelligent requirements development.

</details>


### [13] [A Conceptual Framework for Requirements Engineering of Pretrained-Model-Enabled Systems](https://arxiv.org/abs/2507.13095)
*Dongming Jin,Zhi Jin,Linyu Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: The paper discusses the challenges of integrating large pretrained models into software systems and proposes a new framework for requirements engineering to address these issues.


<details>
  <summary>Details</summary>
Motivation: The integration of pretrained models into software systems challenges traditional requirements engineering assumptions due to their emergent, context-dependent, and evolving nature.

Method: The paper proposes a conceptual framework tailored for requirements engineering of pretrained-model-enabled systems and outlines research directions.

Result: The framework aims to guide researchers and practitioners in addressing the unique challenges posed by pretrained models in software systems.

Conclusion: The paper advocates for rethinking requirements engineering methodologies to better accommodate the distinctive properties of pretrained-model-enabled systems.

Abstract: Recent advances in large pretrained models have led to their widespread
integration as core components in modern software systems. The trend is
expected to continue in the foreseeable future. Unlike traditional software
systems governed by deterministic logic, systems powered by pretrained models
exhibit distinctive and emergent characteristics, such as ambiguous capability
boundaries, context-dependent behavior, and continuous evolution. These
properties fundamentally challenge long-standing assumptions in requirements
engineering, including functional decomposability and behavioral
predictability. This paper investigates this problem and advocates for a
rethinking of existing requirements engineering methodologies. We propose a
conceptual framework tailored to requirements engineering of
pretrained-model-enabled software systems and outline several promising
research directions within this framework. This vision helps provide a guide
for researchers and practitioners to tackle the emerging challenges in
requirements engineering of pretrained-model-enabled systems.

</details>


### [14] [Inferring Attributed Grammars from Parser Implementations](https://arxiv.org/abs/2507.13117)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.SE

TL;DR: A novel approach infers attributed grammars from parser implementations to recover semantic aspects of input handling, enabling comprehensive specification recovery.


<details>
  <summary>Details</summary>
Motivation: Software systems often lack complete specifications for structured input processing, especially regarding semantics.

Method: Dynamic analysis of recursive descent parsers, mapping runtime behavior to grammar rules to embed semantic actions.

Result: Accurate reproduction of program behavior through generated attributed grammars.

Conclusion: The approach is feasible and effective for recovering input processing specifications.

Abstract: Software systems that process structured inputs often lack complete and
up-to-date specifications, which specify the input syntax and the semantics of
input processing. While grammar mining techniques have focused on recovering
syntactic structures, the semantics of input processing remains largely
unexplored. In this work, we introduce a novel approach for inferring
attributed grammars from parser implementations. Given an input grammar, our
technique dynamically analyzes the implementation of recursive descent parsers
to reconstruct the semantic aspects of input handling, resulting in
specifications in the form of attributed grammars. By observing program
executions and mapping the program's runtime behavior to the grammar, we
systematically extract and embed semantic actions into the grammar rules. This
enables comprehensive specification recovery. We demonstrate the feasibility of
our approach using an initial set of programs, showing that it can accurately
reproduce program behavior through the generated attributed grammars.

</details>


### [15] [Detecting LLM-generated Code with Subtle Modification by Adversarial Training](https://arxiv.org/abs/2507.13123)
*Xin Yin,Xinrui Li,Chao Ni,Xiaodan Xu,Xiaohu Yang*

Main category: cs.SE

TL;DR: CodeGPTSensor+ is an enhanced tool for detecting LLM-generated code, even after modifications, using adversarial training and MIST for robustness.


<details>
  <summary>Details</summary>
Motivation: Address challenges like code provenance, copyright, and quality in LLM-generated code, especially after manual modifications.

Method: Proposes CodeGPTSensor+ with adversarial training and MIST module for generating adversarial samples to improve robustness.

Result: Shows higher detection accuracy on adversarial and original test sets compared to CodeGPTSensor.

Conclusion: CodeGPTSensor+ effectively detects modified LLM-generated code, offering a robust solution for real-world applications.

Abstract: With the rapid development of Large Language Models (LLMs), their powerful
code-generation capabilities have been widely applied in tasks like code
completion and automated development, demonstrating the value of improving
coding efficiency. However, the extensive use of LLM-generated code also raises
several new challenges. On the one hand, issues such as the regulation of code
provenance, copyright disputes, and code quality have become increasingly
concerning. How to effectively detect LLM-generated code and ensure its
compliant and responsible use has become a critical and urgent issue. On the
other hand, in practical applications, LLM-generated code is often subject to
manual modifications, such as variable renaming or structural adjustments.
Although some recent studies have proposed training-based and zero-shot methods
for detecting LLM-generated code, these approaches show insufficient robustness
when facing modified LLM-generated code, and there is a lack of an effective
solution. To address the real-world scenario where LLM-generated code may
undergo minor modifications, we propose CodeGPTSensor+, an enhanced version of
CodeGPTSensor, which employs adversarial training to improve robustness against
input perturbations. CodeGPTSensor+ integrates an adversarial sample generation
module, Multi-objective Identifier and Structure Transformation (MIST), which
systematically generates both high-quality and representative adversarial
samples. This module effectively enhances the model's resistance against
diverse adversarial attacks. Experimental results on the HMCorp dataset
demonstrate that CodeGPTSensor+ significantly improves detection accuracy on
the adversarial test set while maintaining high accuracy on the original test
set, showcasing superior robustness compared to CodeGPTSensor.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [16] [Dependency Pairs for Expected Innermost Runtime Complexity and Strong Almost-Sure Termination of Probabilistic Term Rewriting](https://arxiv.org/abs/2507.12918)
*Jan-Christoph Kassing,Leon Spitzer,Jürgen Giesl*

Main category: cs.LO

TL;DR: The paper introduces a DP framework for analyzing expected complexity and proving termination in probabilistic term rewrite systems (PTRSs), implemented in AProVE.


<details>
  <summary>Details</summary>
Motivation: Automatic complexity analysis for PTRSs is largely unexplored, despite the success of DP frameworks in termination analysis.

Method: The authors extend the DP framework to analyze expected complexity and prove SAST for PTRSs, focusing on innermost rewriting.

Result: The framework is implemented in AProVE and outperforms existing techniques for proving SAST.

Conclusion: The work fills a gap in PTRS analysis and demonstrates practical effectiveness through AProVE.

Abstract: The dependency pair (DP) framework is one of the most powerful techniques for
automatic termination and complexity analysis of term rewrite systems. While
DPs were extended to prove almost-sure termination of probabilistic term
rewrite systems (PTRSs), automatic complexity analysis for PTRSs is largely
unexplored. We introduce the first DP framework for analyzing expected
complexity and for proving positive or strong almost-sure termination (SAST) of
innermost rewriting with PTRSs, i.e., finite expected runtime. We implemented
our framework in the tool AProVE and demonstrate its power compared to existing
techniques for proving SAST.

</details>


### [17] [Cyclic proof theory of positive inductive definitions](https://arxiv.org/abs/2507.13057)
*Gianluca Curzi,Lukas Melgaard*

Main category: cs.LO

TL;DR: Cyclic and inductive $\mu\mathsf{PA}$ have the same proof-theoretic strength, shown via translation into annotated cyclic proofs and formalization in $\Pi^1_2$-$\mathsf{CA}_0$.


<details>
  <summary>Details</summary>
Motivation: To analyze cyclic proof systems for $\mu\mathsf{PA}$ and compare their strength with inductive proofs, leveraging impredicative second-order arithmetic.

Method: Translate cyclic proofs into annotated variants, formalize in $\Pi^1_2$-$\mathsf{CA}_0$, and use conservativity properties.

Result: Cyclic and inductive $\mu\mathsf{PA}$ are equally strong; annotated and plain cyclic proofs prove the same theorems.

Conclusion: Advances non-wellfounded proof theory for arithmetic, connecting cyclic proofs to impredicative second-order arithmetic.

Abstract: We study cyclic proof systems for $\mu\mathsf{PA}$, an extension of Peano
arithmetic by positive inductive definitions that is arithmetically equivalent
to the (impredicative) subsystem of second-order arithmetic
$\Pi^1_2$-$\mathsf{CA}_0$ by M\"{o}llefeld. The main result of this paper is
that cyclic and inductive $\mu\mathsf{PA}$ have the same proof-theoretic
strength. First, we translate cyclic proofs into an annotated variant based on
Sprenger and Dam's systems for first-order $\mu$-calculus, whose stronger
validity condition allows for a simpler proof of soundness. We then formalise
this argument within $\Pi^1_2$-$\mathsf{CA}_0$, leveraging M\"{o}llerfeld's
conservativity properties. To this end, we build on prior work by Curzi and Das
on the reverse mathematics of the Knaster-Tarski theorem. As a byproduct of our
proof methods we show that, despite the stronger validity condition, annotated
and "plain" cyclic proofs for $\mu\mathsf{PA}$ prove the same theorems. This
work represents a further step in the non-wellfounded proof-theoretic analysis
of theories of arithmetic via impredicative fragments of second-order
arithmetic, an approach initiated by Simpson's Cyclic Arithmetic, and continued
by Das and Melgaard in the context of arithmetical inductive definitions.

</details>


### [18] [Monotone weak distributive laws over the lifted powerset monad in categories of algebras](https://arxiv.org/abs/2507.13058)
*Quentin Aristote*

Main category: cs.LO

TL;DR: The paper explores whether monotone weak distributive laws in compact Hausdorff spaces can generalize from sets, finding partial success and characterizing their existence in algebra categories.


<details>
  <summary>Details</summary>
Motivation: To investigate the generalization of monotone weak distributive laws from sets to compact Hausdorff spaces and other algebraic categories.

Method: Study the weak lifting of laws, characterize conditions for existence, and test applicability in various categories.

Result: Partial generalization to compact Hausdorff spaces; laws exist for probabilities and non-determinism there but fail in many other cases.

Conclusion: Monotone weak distributive laws are context-dependent, with limited generalizability beyond specific algebraic structures.

Abstract: Noticing the similarity between the monotone weak distributive laws combining
two layers of nondeterminism in sets and in compact Hausdorff spaces, we study
whether the latter law can be obtained automatically as a weak lifting of the
former. This holds partially, but does not generalize to other categories of
algebras: we then characterize when exactly monotone weak distributive laws
over powerset monads in categories of algebras exist, exhibiting a law
combining probabilities and non-determinism in compact Hausdorff spaces and
showing on the other hand that such laws do not exist in a lot of other cases.

</details>


### [19] [Impact and Performance of Randomized Test-Generation using Prolog](https://arxiv.org/abs/2507.13178)
*Marcus Gelderie,Maximilian Luff,Maximilian Peltzer*

Main category: cs.LO

TL;DR: Randomized test-input generation in Prolog using two strategies: one preserves standard Prolog semantics, the other alters SLD resolution. Analyzed via Markov chains and empirical evaluation.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of generating test-sequences with complex logical interdependencies efficiently, especially for large or infinite test sets.

Method: Two randomization strategies: one modifies standard Prolog semantics, the other changes the SLD selection function. Analyzed using Markov chains for performance metrics.

Result: Evaluation shows impact of randomization on test performance, comparing mean time to reach test-cases and number of generated cases.

Conclusion: Proposes effective randomization methods for Prolog-based test generation, with empirical validation.

Abstract: We study randomized generation of sequences of test-inputs to a system using
Prolog. Prolog is a natural fit to generate test-sequences that have complex
logical inter-dependent structure. To counter the problems posed by a large (or
infinite) set of possible tests, randomization is a natural choice. We study
the impact that randomization in conjunction with SLD resolution have on the
test performance. To this end, this paper proposes two strategies to add
randomization to a test-generating program. One strategy works on top of
standard Prolog semantics, whereas the other alters the SLD selection function.
We analyze the mean time to reach a test-case, and the mean number of generated
test-cases in the framework of Markov chains. Finally, we provide an additional
empirical evaluation and comparison between both approaches. Under
consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [20] [Just Verification of Mutual Exclusion Algorithms](https://arxiv.org/abs/2507.13198)
*Rob van Glabbeek,Bas Luttik,Myrthe Spronck*

Main category: cs.LO

TL;DR: Model checking verifies mutual exclusion algorithms using shared registers, with justness as a completeness criterion for liveness.


<details>
  <summary>Details</summary>
Motivation: To ensure correctness of mutual exclusion algorithms under various register assumptions.

Method: Model checking with atomic/non-atomic shared registers and justness for liveness.

Result: Identified violations in algorithms and suggested improvements.

Conclusion: Justness effectively eliminates spurious counterexamples, aiding in algorithm verification and refinement.

Abstract: We verify the correctness of a variety of mutual exclusion algorithms through
model checking. We look at algorithms where communication is via shared
read/write registers, where those registers can be atomic or non-atomic. For
the verification of liveness properties, it is necessary to assume a
completeness criterion to eliminate spurious counterexamples. We use justness
as completeness criterion. Justness depends on a concurrency relation; we
consider several such relations, modelling different assumptions on the working
of the shared registers. We present executions demonstrating the violation of
correctness properties by several algorithms, and in some cases suggest
improvements.

</details>


### [21] [Solving SAT By Computing A Stable Set Of Points In Clusters](https://arxiv.org/abs/2507.13282)
*Eugene Goldberg*

Main category: cs.LO

TL;DR: SSPs (stable sets of points) for CNF formulas are large, making point-by-point computation infeasible. This paper proposes computing SSPs in clusters for efficiency and parallelization.


<details>
  <summary>Details</summary>
Motivation: SSPs are useful for determining CNF formula unsatisfiability, but their large size makes computation impractical. Clustering offers a scalable solution.

Method: Proposes computing SSPs in clusters (large sets of points processed simultaneously) to leverage formula structure and enable parallel computing.

Result: Enables more efficient SAT algorithms and facilitates parallel processing of SSPs.

Conclusion: Clustering SSPs improves scalability and efficiency, benefiting SAT solving and parallel computing.

Abstract: Earlier we introduced the notion of a stable set of points (SSP). We proved
that a CNF formula is unsatisfiable iff there is a set of points (i.e. complete
assignments) that is stable with respect to this formula. Experiments showed
that SSPs for CNF formulas of practical interest are very large. So computing
an SSP for a CNF formula point by point is, in general, infeasible. In this
report, we show how an SSP can be computed in clusters, each cluster being a
large set of points that are processed simultaneously. The appeal of computing
SSPs is twofold. First, it allows one to better take into account formula
structure and hence, arguably, design more efficient SAT algorithms. Second,
SAT solving by SSPs facilitates parallel computing.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [22] [Dual-Numbers Reverse AD for Functional Array Languages](https://arxiv.org/abs/2507.12640)
*Tom Smeding,Mikołaj Konarski,Simon Peyton Jones,Andrew Fitzgibbon*

Main category: cs.PL

TL;DR: The paper introduces a method for efficient reverse-mode automatic differentiation (AD) on multidimensional arrays using dual numbers, addressing performance issues in existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing dual-numbers reverse-mode AD methods perform poorly on array programs, prompting the need for a more efficient solution.

Method: The approach combines vectorisation (BOT), lifting dual-numbers AD to an array language, and symbolic interpretation for compilation.

Result: The method achieves efficient AD on arrays with minimal overhead but sacrifices support for higher-order code.

Conclusion: The trade-off between efficiency and generality is justified by the practical performance gains for array programs.

Abstract: The standard dual-numbers construction works well for forward-mode automatic
differentiation (AD) and is attractive due to its simplicity; recently, it also
has been adapted to reverse-mode AD, but practical performance, especially on
array programs, leaves a lot to be desired. In this paper we introduce
first-class support for multidimensional arrays in dual-numbers reverse-mode AD
with little to no performance overhead. The algorithm consists of three
loosely-coupled components: a semantics-preserving vectorisation code
transformation (the bulk-operation transform or BOT), a fairly straightforward
lifting of the basic dual-numbers reverse AD algorithm to a mostly first-order
array language, and symbolic interpretation to achieve an end-to-end
compilation pipeline. Unfortunately, we lose some of the nice generalisable
aspects of dual-numbers AD in the process, most importantly support for
higher-order code.
  We do support some higher-order array combinators, but only a
carefully-chosen set: 'build' (elementwise array construction), 'gather' and
'scatter'. In return, the BOT can eliminate the essential (for AD)
higher-orderness of the input program, meaning that AD gets essentially
presented with a first-order program. This allows the naive trick of lifting
dual numbers to "dual arrays" to work without much modification.

</details>


### [23] [Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications](https://arxiv.org/abs/2507.13091)
*Aurèle Barrière,Victor Deng,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: Mechanized, succinct, and practical semantics for modern regex with backtracking, proven faithful to ECMAScript, with real-world applications and mechanized proofs.


<details>
  <summary>Details</summary>
Motivation: To provide a faithful and practical semantics for modern regex with backtracking, addressing gaps in existing formalizations.

Method: Prove equivalence to ECMAScript's line-by-line embedding, apply to contextual equivalence and PikeVM algorithm, and mechanize in Rocq.

Result: Faithful semantics capturing full backtracking tree, enabling proofs of regex rewrites and PikeVM correctness.

Conclusion: Successful mechanization and practical applications demonstrate the semantics' utility and faithfulness.

Abstract: We present the first mechanized, succinct, practical, complete, and
proven-faithful semantics for a modern regular expression language with
backtracking semantics. We ensure its faithfulness by proving it equivalent to
a preexisting line-by-line embedding of the official ECMAScript specification
of JavaScript regular expressions. We demonstrate its practicality by
presenting two real-world applications. First, a new notion of contextual
equivalence for modern regular expressions, which we use to prove or disprove
rewrites drawn from previous work. Second, the first formal proof of the PikeVM
algorithm used in many real-world engines. In contrast with the specification
and other formalization work, our semantics captures not only the top-priority
match, but a full backtracking tree recording all possible matches and their
respective priority. All our definitions and results have been mechanized in
the Rocq proof assistant.

</details>


### [24] [Towards Formal Verification of LLM-Generated Code from Natural Language Prompts](https://arxiv.org/abs/2507.13290)
*Aaron Councilman,David Fu,Aryan Gupta,Chengxiao Wang,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.PL

TL;DR: The paper proposes a method to provide formal correctness guarantees for LLM-generated code using a formal query language and verification system, achieving high accuracy in verification.


<details>
  <summary>Details</summary>
Motivation: LLMs often generate incorrect code, and users struggle to detect errors, hindering the reliability of AI Code Assistants. Formal guarantees could enhance usability, especially for non-programmers.

Method: Incorporates a formal query language to represent user intent and verifies LLM-generated code against it. Implemented in Astrogator for Ansible, using a calculus and symbolic interpreter.

Result: On 21 tasks, the verifier confirmed correct code in 83% of cases and detected incorrect code in 92%.

Conclusion: The approach improves reliability of AI-generated code, supporting natural language programming for non-experts.

Abstract: In the past few years LLMs have emerged as a tool that can aid programmers by
taking natural language descriptions and generating code based on it. However,
LLMs often generate incorrect code that users need to fix and the literature
suggests users often struggle to detect these errors. In this work we seek to
offer formal guarantees of correctness to LLM generated code; such guarantees
could improve the experience of using AI Code Assistants and potentially enable
natural language programming for users with little or no programming knowledge.
To address this challenge we propose to incorporate a formal query language
that can represent a user's intent in a formally defined but natural
language-like manner that a user can confirm matches their intent. Then, using
such a query we propose to verify LLM generated code to ensure it matches the
user's intent. We implement these ideas in our system, Astrogator, for the
Ansible programming language which includes such a formal query language, a
calculus for representing the behavior of Ansible programs, and a symbolic
interpreter which is used for the verification. On a benchmark suite of 21
code-generation tasks, our verifier is able to verify correct code in 83% of
cases and identify incorrect code in 92%.

</details>
