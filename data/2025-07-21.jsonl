{"id": "2507.13481", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.13481", "abs": "https://arxiv.org/abs/2507.13481", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Font√£o"], "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts."}
{"id": "2507.13499", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale."}
{"id": "2507.13553", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13553", "abs": "https://arxiv.org/abs/2507.13553", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively."}
{"id": "2507.13555", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13555", "abs": "https://arxiv.org/abs/2507.13555", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks."}
{"id": "2507.13494", "categories": ["cs.PL", "stat.CO"], "pdf": "https://arxiv.org/pdf/2507.13494", "abs": "https://arxiv.org/abs/2507.13494", "authors": ["Feras A. Saad", "Wonyeol Lee"], "title": "Random Variate Generation with Formal Guarantees", "comment": null, "summary": "This article introduces a new approach to principled and practical random\nvariate generation with formal guarantees. The key idea is to first specify the\ndesired probability distribution in terms of a finite-precision numerical\nprogram that defines its cumulative distribution function (CDF), and then\ngenerate exact random variates according to this CDF. We present a universal\nand fully automated method to synthesize exact random variate generators given\nany numerical CDF implemented in any binary number format, such as\nfloating-point, fixed-point, and posits. The method is guaranteed to operate\nwith the same precision used to specify the CDF, does not overflow, avoids\nexpensive arbitrary-precision arithmetic, and exposes a consistent API. The\nmethod rests on a novel space-time optimal implementation for the class of\ngenerators that attain the information-theoretically optimal Knuth and Yao\nentropy rate, consuming the least possible number of input random bits per\noutput variate. We develop a random variate generation library using our method\nin C and evaluate it on a diverse set of ``continuous'' and ``discrete''\ndistributions, showing competitive runtime with the state-of-the-art GNU\nScientific Library while delivering higher accuracy, entropy efficiency, and\nautomation."}
{"id": "2507.14082", "categories": ["cs.FL", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.14082", "abs": "https://arxiv.org/abs/2507.14082", "authors": ["Nelma Moreira", "Luca Prigioniero"], "title": "Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications", "comment": null, "summary": "The Fifteenth International Workshop on Non-Classical Models of Automata and\nApplications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,\norganized by the Department of Computer Science at Loughborough University and\nco-located with the 26th International Conference on Descriptional Complexity\nof Formal Systems (DCFS 2025, 22-24 July).\n  The NCMA workshop series was established in 2009 as an annual event for\nresearchers working on non-classical and classical models of automata, grammars\nor related devices. Such models are investigated both as theoretical models and\nas formal models for applications from various points of view. The goal of the\nNCMA workshop series is to exchange and develop novel ideas in order to gain\ndeeper and interdisciplinary coverage of this particular area that may foster\nnew insights and substantial progress."}
{"id": "2507.13847", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.13847", "abs": "https://arxiv.org/abs/2507.13847", "authors": ["Katsumi Inoue", "Daniil Kozhemiachenko"], "title": "Complexity of Abduction in ≈Åukasiewicz Logic", "comment": null, "summary": "We explore the problem of explaining observations in contexts involving\nstatements with truth degrees such as `the lift is loaded', `the symptoms are\nsevere', etc. To formalise these contexts, we consider infinitely-valued\n{\\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction\nproblems and explanations in the language of {\\L}ukasiewicz logic expanded with\n`interval literals' of the form $p\\geq\\mathbf{c}$, $p\\leq\\mathbf{c}$, and their\nnegations that express the set of values a variable can have. We analyse the\ncomplexity of standard abductive reasoning tasks (solution recognition,\nsolution existence, and relevance / necessity of hypotheses) in {\\L}ukasiewicz\nlogic for the case of the full language and for the case of theories containing\nonly disjunctive clauses and show that in contrast to classical propositional\nlogic, the abduction in the clausal fragment has lower complexity than in the\ngeneral case."}
{"id": "2507.13661", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.13661", "abs": "https://arxiv.org/abs/2507.13661", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "comment": null, "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy."}
{"id": "2507.13533", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.13533", "abs": "https://arxiv.org/abs/2507.13533", "authors": ["Priyam Gupta"], "title": "Increasing the Expressiveness of a Gradual Verifier", "comment": "Presented at the 52nd ACM SIGPLAN Symposium on Principles of\n  Programming Languages (POPL 2025) Student Research Competition", "summary": "Static verification provides strong correctness guarantees for code; however,\nfully specifying programs for static verification is a complex, burdensome\nprocess for users. Gradual verification was introduced to make this process\neasier by supporting the verification of partially specified programs. The only\ncurrently working gradual verifier, Gradual C0, successfully verifies heap\nmanipulating programs, but lacks expressiveness in its specification language.\nThis paper describes the design and implementation of an extension to Gradual\nC0 that supports unfolding expressions, which allow more intuitive\nspecifications of recursive heap data structures."}
{"id": "2507.13895", "categories": ["cs.LO", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.13895", "abs": "https://arxiv.org/abs/2507.13895", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "title": "Application Placement with Constraint Relaxation", "comment": null, "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications."}
{"id": "2507.13774", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2; F.4.1"], "pdf": "https://arxiv.org/pdf/2507.13774", "abs": "https://arxiv.org/abs/2507.13774", "authors": ["Arthur Adjedj", "Meven Lennon-Bertrand", "Thibaut Benjamin", "Kenji Maillard"], "title": "AdapTT: Functoriality for Dependent Type Casts", "comment": null, "summary": "The ability to cast values between related types is a leitmotiv of many\nflavors of dependent type theory, such as observational type theories,\nsubtyping, or cast calculi for gradual typing. These casts all exhibit a common\nstructural behavior that boils down to the pervasive functoriality of type\nformers. We propose and extensively study a type theory, called AdapTT, which\nmakes systematic and precise this idea of functorial type formers, with respect\nto an abstract notion of adapters relating types. Leveraging descriptions for\nfunctorial inductive types in AdapTT, we derive structural laws for type casts\non general inductive type formers."}
{"id": "2507.13946", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.13946", "abs": "https://arxiv.org/abs/2507.13946", "authors": ["Tadeusz Litak", "Katsuhiko Sano"], "title": "Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity", "comment": "This is a modified and expanded version of a paper accepted for\n  TABLEAUX 2025. In particular, readers should note that the numeration of\n  environments is different in the conference version", "summary": "Propositional inquisitive logic is the limit of its $n$-bounded\napproximations. In the predicate setting, however, this does not hold anymore,\nas discovered by Ciardelli and Grilletti, who also found complete\naxiomatizations of $n$-bounded inquisitive logics $\\mathsf{InqBQ}_{n}$, for\nevery fixed $n$. We introduce cut-free labelled sequent calculi for these\nlogics. We illustrate the intricacies of \\textit{schematic validity} in such\nsystems by showing that the well-known Casari formula is \\textit{atomically}\nvalid in (a weak sublogic of) predicate inquisitive logic $\\mathsf{InqBQ}$,\nfails to be schematically valid in it, and yet is schematically valid under the\nfinite boundedness assumption. The derivations in our calculi, however, are\nguaranteed to be schematically valid whenever a single specific rule is not\nused."}
{"id": "2507.13792", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.13792", "abs": "https://arxiv.org/abs/2507.13792", "authors": ["Riccardo Bianchini", "Francesco Dagnino", "Paola Giannini", "Elena Zucca"], "title": "Don't exhaust, don't waste", "comment": "Submitted to JFP (Journal of Functional Programming)", "summary": "We extend the semantics and type system of a lambda calculus equipped with\ncommon constructs to be resource-aware. That is, the semantics keep tracks of\nthe usage of resources, and is stuck, besides in case of type errors, if either\na needed resource is exhausted, or a provided resource would be wasted. In such\nway, the type system guarantees, besides standard soundness, that for\nwell-typed programs there is a computation where no resource gets either\nexhausted or wasted.\n  The no-waste extension is parametric on an arbitrary grade algebra, modeling\nan arbitrary assortment of possible usages, and does not require ad-hoc changes\nto the underlying language. To this end, the semantics needs to be formalized\nin big-step style; as a consequence, expressing and proving (resource-aware)\nsoundness is challenging, and is achieved by applying recent techniques based\non coinductive reasoning."}
{"id": "2507.13987", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.13987", "abs": "https://arxiv.org/abs/2507.13987", "authors": ["Simon Fl√ºgel", "Martin Glauer", "Till Mossakowski", "Fabian Neuhaus"], "title": "ChemLog: Making MSOL Viable for Ontological Classification and Learning", "comment": null, "summary": "Despite its prevalence, in many domains, OWL is not expressive enough to\ndefine ontology classes. In this paper, we present an approach that allows to\nuse monadic second-order formalisations for ontology classification. As a case\nstudy, we have applied our approach to 14 peptide-related classes from the\nchemistry ontology ChEBI. For these classes, a monadic second-order logic\nformalisation has been developed and applied both to ChEBI as well as to 119\nmillion molecules from the chemistry database PubChem. While this logical\napproach alone is limited to classification for the specified classes (in our\ncase, (sub)classes of peptides), transformer deep learning models scale\nclassification to the whole of the ChEBI ontology. We show that when using the\nclassifications obtained by the logical approach as training data, the\nperformance of the deep learning models can be significantly enhanced."}
{"id": "2507.13499", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale."}
{"id": "2507.13774", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2; F.4.1"], "pdf": "https://arxiv.org/pdf/2507.13774", "abs": "https://arxiv.org/abs/2507.13774", "authors": ["Arthur Adjedj", "Meven Lennon-Bertrand", "Thibaut Benjamin", "Kenji Maillard"], "title": "AdapTT: Functoriality for Dependent Type Casts", "comment": null, "summary": "The ability to cast values between related types is a leitmotiv of many\nflavors of dependent type theory, such as observational type theories,\nsubtyping, or cast calculi for gradual typing. These casts all exhibit a common\nstructural behavior that boils down to the pervasive functoriality of type\nformers. We propose and extensively study a type theory, called AdapTT, which\nmakes systematic and precise this idea of functorial type formers, with respect\nto an abstract notion of adapters relating types. Leveraging descriptions for\nfunctorial inductive types in AdapTT, we derive structural laws for type casts\non general inductive type formers."}
