<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 2]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [Axiomatisation for an asynchronous epistemic logic with sending and receiving messages](https://arxiv.org/abs/2510.02890)
*Philippe Balbiani,Hans van Ditmarsch,Clara Lerouvillois*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate a public announcement logic for asynchronous public
announcements wherein the sending of the announcements by the environment is
separated from the reception of the announcements by the individual agents.
Both come with different modalities. In the logical semantics, formulas are
interpreted in a world of a Kripke model but given a history of prior
announcements and receptions of announcements that already happened. An
axiomatisation AA for such a logic has been given in prior work, for the
formulas that are valid when interpreted in the Kripke model before any such
announcements have taken place. This axiomatisation is a reduction system
wherein one can show that every formula is equivalent to a purely epistemic
formula without dynamic modalities for announcements and receptions. We propose
a generalisation AA* of this axiomatisation, for the formulas that are valid
when interpreted in the Kripke model given any history of prior announcements
and receptions of announcements. It does not extend the axiomatisation AA, for
example it is no longer valid that nobody has received any announcement. Unlike
AA, this axiomatisation AA* is infinitary and it is not a reduction system.

</details>


### [2] [A Graded Modal Type Theory for Pulse Schedules](https://arxiv.org/abs/2510.03130)
*Robin Adams*

Main category: cs.LO

TL;DR: 提出了一种用于表示超导量子计算机脉冲调度输入的语言PSTT，这是一种分级模态类型理论，使用分级来编码时序信息。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够精确表示量子计算机脉冲调度的语言，传统方法难以处理时序约束和资源管理。

Method: 开发了名为PSTT的分级模态类型理论，其中变量用参数或分级进行注释，用于表示时序信息。提供了范畴语义并证明了系统的完备性和可靠性。

Result: 成功构建了PSTT语言，能够有效表示量子脉冲调度，并通过数学形式化验证了系统的正确性。

Conclusion: PSTT为量子计算中的脉冲调度提供了一种形式化、类型安全且具有时序保证的表示方法。

Abstract: We propose a language for representing the pulse schedules that a
superconducting quantum computer accepts as input. The language is a graded
modal type theory named PSTT (Pulse Schedule Type Theory). Graded modals type
theories are type systems where each variable is annotated with a parameter or
grade. These can be used to represent, for example, resource usage, where the
grade denotes how many times a given resource may be used; or privacy levels,
whether a resource is private or public. In this system, we use the grades to
represent timing information. We give categorical semantics to the system and
prove soundness and completeness.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [CWM: An Open-Weights LLM for Research on Code Generation with World Models](https://arxiv.org/abs/2510.02387)
*FAIR CodeGen team,Quentin Carbonneaux,Gal Cohen,Jonas Gehring,Jacob Kahn,Jannik Kossen,Felix Kreuk,Emily McMilin,Michel Meyer,Yuxiang Wei,David Zhang,Kunhao Zheng,Jordi Armengol-Estapé,Pedram Bashiri,Maximilian Beck,Pierre Chambon,Abhishek Charnalia,Chris Cummins,Juliette Decugis,Zacharias V. Fisches,François Fleuret,Fabian Gloeckle,Alex Gu,Michael Hassid,Daniel Haziza,Badr Youbi Idrissi,Christian Keller,Rahul Kindi,Hugh Leather,Gallil Maimon,Aram Markosyan,Francisco Massa,Pierre-Emmanuel Mazaré,Vegard Mella,Naila Murray,Keyur Muzumdar,Peter O'Hearn,Matteo Pagliardini,Dmitrii Pedchenko,Tal Remez,Volker Seeker,Marco Selvi,Oren Sultan,Sida Wang,Luca Wehrstedt,Ori Yoran,Lingming Zhang,Taco Cohen,Yossi Adi,Gabriel Synnaeve*

Main category: cs.SE

TL;DR: 发布了Code World Model (CWM)，一个320亿参数的开源LLM，通过世界模型训练提升代码生成能力，在多种编程和数学任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了超越仅从静态代码训练获得的代码理解能力，探索世界模型如何通过环境交互轨迹提升代码生成中的推理和规划能力。

Method: 在Python解释器和Docker环境中进行大规模观察-行动轨迹的中期训练，并在可验证编码、数学和多轮软件工程环境中进行多任务推理强化学习。

Result: CWM在多个基准测试中表现强劲：SWE-bench Verified 65.8%、LiveCodeBench 68.6%、Math-500 96.6%、AIME 2024 76.0%。

Conclusion: CWM为研究代码世界建模提供了强大平台，展示了世界模型如何通过逐步模拟代码执行来增强智能编码能力。

Abstract: We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,
to advance research on code generation with world models. To improve code
understanding beyond what can be learned from training on static code alone, we
mid-train CWM on a large amount of observation-action trajectories from Python
interpreter and agentic Docker environments, and perform extensive multi-task
reasoning RL in verifiable coding, math, and multi-turn software engineering
environments. With CWM, we provide a strong testbed for researchers to explore
the opportunities world modeling affords for improving code generation with
reasoning and planning in computational environments. We present first steps of
how world models can benefit agentic coding, enable step-by-step simulation of
Python code execution, and show early results of how reasoning can benefit from
the latter. CWM is a dense, decoder-only LLM trained with a context size of up
to 131k tokens. Independent of its world modeling capabilities, CWM offers
strong performance on general coding and math tasks: it reaches pass@1 scores
of 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on
LiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further
research on code world modeling, we release model checkpoints after
mid-training, SFT, and RL.

</details>


### [4] [From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization](https://arxiv.org/abs/2510.02389)
*Haoran Xi,Minghao Shao,Brendan Dolan-Gavitt,Muhammad Shafique,Ramesh Karri*

Main category: cs.SE

TL;DR: T2L-Agent是一个项目级的端到端框架，通过从模块逐步缩小范围到具体漏洞行，结合运行时证据和AST代码分块，实现精确的漏洞定位和修复指导。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞检测方法孤立分析代码、难以处理长上下文、仅提供粗粒度的函数或文件级检测，无法为工程师提供精确的行级定位和针对性修复指导。

Method: T2L-Agent采用多轮反馈机制，结合Agentic Trace Analyzer(ATA)融合运行时证据（崩溃点、堆栈跟踪、覆盖率差异）和基于AST的代码分块，实现迭代精炼。

Result: 在T2L-ARVO基准测试中，T2L-Agent达到58.0%的检测率和54.8%的行级定位率，显著优于基线方法。

Conclusion: 该框架和基准测试将基于LLM的漏洞检测从粗粒度识别推向可部署、鲁棒、精确的诊断，减少噪声并加速开源软件工作流中的修复过程。

Abstract: Large language models show promise for vulnerability discovery, yet
prevailing methods inspect code in isolation, struggle with long contexts, and
focus on coarse function- or file-level detections - offering limited
actionable guidance to engineers who need precise line-level localization and
targeted patches in real-world software development. We present T2L-Agent
(Trace-to-Line Agent), a project-level, end-to-end framework that plans its own
analysis and progressively narrows scope from modules to exact vulnerable
lines. T2L-Agent couples multi-round feedback with an Agentic Trace Analyzer
(ATA) that fuses runtime evidence - crash points, stack traces, and coverage
deltas - with AST-based code chunking, enabling iterative refinement beyond
single pass predictions and translating symptoms into actionable, line-level
diagnoses. To benchmark line-level vulnerability discovery, we introduce
T2L-ARVO, a diverse, expert-verified 50-case benchmark spanning five crash
families and real-world projects. T2L-ARVO is specifically designed to support
both coarse-grained detection and fine-grained localization, enabling rigorous
evaluation of systems that aim to move beyond file-level predictions. On
T2L-ARVO, T2L-Agent achieves up to 58.0% detection and 54.8% line-level
localization, substantially outperforming baselines. Together, the framework
and benchmark push LLM-based vulnerability detection from coarse identification
toward deployable, robust, precision diagnostics that reduce noise and
accelerate patching in open-source software workflows.

</details>


### [5] [AP2O: Correcting LLM-Generated Code Errors Type by Type Like Humans via Adaptive Progressive Preference Optimization](https://arxiv.org/abs/2510.02393)
*Jianqing Zhang,Wei Xia,Hande Dong,Qiang Lin,Jian Cao*

Main category: cs.SE

TL;DR: AP2O-Coder是一种自适应渐进偏好优化方法，通过分析失败代码的错误类型，逐步优化LLM以减少代码生成错误，在减少偏好数据使用的同时提升代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有离线偏好优化方法主要关注通过成功/失败信号提升LLM编码能力，但忽略了失败代码中的深层错误类型信息。

Method: 构建错误笔记本记录失败代码，按错误类型逐步优化LLM，并在训练过程中自适应重放错误类型以适应LLM不断变化的弱点。

Result: 在0.5B到34B参数的代码和通用LLM上实验，AP2O-Coder将代码生成性能提升高达3%（pass@k指标），同时使用更少的偏好数据。

Conclusion: AP2O-Coder通过关注错误类型而非简单成功/失败信号，有效提升了LLM的代码生成能力，证明了渐进式错误类型优化的有效性。

Abstract: LLMs' code generation capabilities have yielded substantial improvements in
the effectiveness of programming tasks. However, LLM-generated code still
suffers from compilation and runtime errors. Existing offline preference
optimization methods primarily focus on enhancing LLMs' coding abilities using
pass/fail signals in the preference data, overlooking the deep-level error
types in the failed codes. To address this, we propose Adaptively Progressive
Preference Optimization (AP2O) for coding (i.e., AP2O-Coder), a method that
guides LLMs adaptively and methodically to reduce code errors for code
generation. Specifically, we construct an error notebook from failed codes and
progressively optimize the LLM to correct errors type by type. Furthermore, we
adaptively replay error types to tailor to the LLM's changing weaknesses
throughout the training process. Through extensive experiments on both code and
general LLMs (Llama, Qwen, and DeepSeek series) with parameters ranging from
0.5B to 34B, our AP2O-Coder improves code generation performance by up to 3% in
pass@k while using less preference data. Code: https://github.com/TsingZ0/AP2O

</details>


### [6] [Dynamic Function Configuration and its Management in Serverless Computing: A Taxonomy and Future Directions](https://arxiv.org/abs/2510.02404)
*Siddharth Agarwal,Maria A. Rodriguez,Rajkumar Buyya*

Main category: cs.SE

TL;DR: 本文分析了无服务器计算中函数资源配置的挑战，提出了影响函数设计、配置、成本和性能的因素分类法，并对现有资源配置研究进行了全面综述。


<details>
  <summary>Details</summary>
Motivation: 无服务器平台缺乏透明度，开发者难以优化资源配置，这影响了运营成本和性能质量。开源框架允许独立配置资源，增加了优化复杂性。

Method: 识别了FaaS环境中资源配置技术的不同方面，提出了影响函数设计、配置、运行成本和性能保证的因素分类法，并对现有文献进行了分析。

Result: 建立了资源配置因素的综合分类法，对当前函数配置研究进行了系统综述，识别了现有研究空白。

Conclusion: 需要进一步研究来增强函数配置能力，强化无服务器计算环境的功能，推动其更广泛采用。

Abstract: The serverless cloud computing model offers a framework where the service
provider abstracts the underlying infrastructure management from developers. In
this serverless model, FaaS provides an event-driven, function-oriented
computing service characterised by fine-grained, usage-based pricing that
eliminates cost for idle resources. Platforms like AWS Lambda, Azure Functions,
and Cloud Run Functions require developers to configure their function(s) with
minimum operational resources for its successful execution. This resource
allocation influences both the operational expense and the performance quality
of these functions. However, a noticeable lack of platform transparency forces
developers to rely on expert knowledge or experience-based ad-hoc decisions to
request desired function resources. This makes optimal resource configuration a
non-trivial task while adhering to performance constraints. Furthermore, while
commercial platforms often scale resources like CPU and network bandwidth
proportional to memory, open-source frameworks permit independent configuration
of function resources, introducing additional complexity for developers aiming
to optimise their functions. These complexities have directed researchers to
resolve developer challenges and advance towards an efficient server-less
execution model. In this article, we identify different aspects of resource
configuration techniques in FaaS settings and propose a taxonomy of factors
that influence function design, configuration, run-time cost, and performance
guarantees. We conduct an analysis of existing literature on resource
configuration to present a comprehensive review of current studies on function
configuration. We also identify existing research gaps and suggest future
research directions to enhance function configuration and strengthen the
capabilities of serverless computing environments to drive its broader
adoption.

</details>


### [7] [Product Manager Practices for Delegating Work to Generative AI: "Accountability must not be delegated to non-human actors"](https://arxiv.org/abs/2510.02504)
*Mara Ulloa,Jenna L. Butler,Sankeerti Haniyur,Courtney Miller,Barrett Amos,Advait Sarkar,Margaret-Anne Storey*

Main category: cs.SE

TL;DR: 研究微软产品经理对生成式AI的采用情况、使用案例、感知效益与障碍，以及任务委托框架和角色适应实践。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在改变知识工作的性质，但现有研究主要关注开发者与GenAI的互动，对产品经理工作如何因GenAI而演变的理解较少。

Method: 在微软进行混合方法研究：调查885名产品经理，分析731名产品经理的遥测数据，访谈15名产品经理。

Result: 提供了产品经理当前的GenAI采用率、使用案例、感知效益和障碍；提出了产品经理评估哪些任务委托给GenAI的框架；描述了产品经理整合GenAI到其角色的适应实践。

Conclusion: 讨论了GenAI工作流采用过程和软件开发角色的更广泛影响。

Abstract: Generative AI (GenAI) is changing the nature of knowledge work, particularly
for Product Managers (PMs) in software development teams. While much software
engineering research has focused on developers' interactions with GenAI, there
is less understanding of how the work of PMs is evolving due to GenAI. To
address this gap, we conducted a mixed-methods study at Microsoft, a large,
multinational software company: surveying 885 PMs, analyzing telemetry data for
a subset of PMs (N=731), and interviewing a subset of 15 PMs. We contribute:
(1) PMs' current GenAI adoption rates, uses cases, and perceived benefits and
barriers and; (2) a framework capturing how PMs assess which tasks to delegate
to GenAI; (3) PMs adaptation practices for integrating GenAI into their roles
and perceptions of how their role is evolving. We end by discussing
implications on the broader GenAI workflow adoption process and software
development roles.

</details>


### [8] [ZeroFalse: Improving Precision in Static Analysis with LLMs](https://arxiv.org/abs/2510.02534)
*Mohsen Iranmanesh,Sina Moradi Sabet,Sina Marefat,Ali Javidi Ghasr,Allison Wilson,Iman Sharafaldin,Mohammad A. Tayebi*

Main category: cs.SE

TL;DR: ZeroFalse框架结合静态分析和大型语言模型，通过将静态分析器输出作为结构化合约处理，并添加流敏感追踪、上下文证据和CWE特定知识，显著减少SAST工具的误报率，同时保持覆盖率。


<details>
  <summary>Details</summary>
Motivation: SAST工具在现代软件开发中至关重要，但过高的误报率削弱了开发者的信任并需要昂贵的人工排查，因此需要一种方法来减少误报同时保持覆盖范围。

Method: 将静态分析器输出视为结构化合约，通过添加流敏感追踪、上下文证据和CWE特定知识来丰富分析结果，然后由LLM进行裁决，结合静态分析的系统性覆盖和LLM的推理能力。

Result: 在OWASP Java Benchmark上F1分数达到0.912，在OpenVuln数据集上达到0.955，召回率和精确率均保持在90%以上，CWE专用提示优于通用提示，推理导向的LLM提供最可靠的精确率-召回率平衡。

Conclusion: ZeroFalse是一个实用且可扩展的方法，可增强SAST的可靠性并支持其集成到真实的CI/CD流水线中。

Abstract: Static Application Security Testing (SAST) tools are integral to modern
software development, yet their adoption is undermined by excessive false
positives that weaken developer trust and demand costly manual triage. We
present ZeroFalse, a framework that integrates static analysis with large
language models (LLMs) to reduce false positives while preserving coverage.
ZeroFalse treats static analyzer outputs as structured contracts, enriching
them with flow-sensitive traces, contextual evidence, and CWE-specific
knowledge before adjudication by an LLM. This design preserves the systematic
reach of static analysis while leveraging the reasoning capabilities of LLMs.
We evaluate ZeroFalse across both benchmarks and real-world projects using ten
state-of-the-art LLMs. Our best-performing models achieve F1-scores of 0.912 on
the OWASP Java Benchmark and 0.955 on the OpenVuln dataset, maintaining recall
and precision above 90%. Results further show that CWE-specialized prompting
consistently outperforms generic prompts, and reasoning-oriented LLMs provide
the most reliable precision-recall balance. These findings position ZeroFalse
as a practical and scalable approach for enhancing the reliability of SAST and
supporting its integration into real-world CI/CD pipelines.

</details>


### [9] [Key Considerations for Auto-Scaling: Lessons from Benchmark Microservices](https://arxiv.org/abs/2510.02585)
*Majid Dashtbani,Ladan Tahvildari*

Main category: cs.SE

TL;DR: 本文通过将多种先进的自动扩缩方法应用于微服务基准测试，识别了微服务自动扩缩的实际考虑因素，并基于软件生命周期（架构、实现、部署）对这些因素进行分类，强调了生命周期感知工程对实现有效自动扩缩的重要性。


<details>
  <summary>Details</summary>
Motivation: 微服务已成为构建可扩展云原生系统的主流架构范式，但实现有效的自动扩缩仍面临挑战。现有基准测试往往忽视设计、实现和部署等基础方面，难以在真实条件下评估自动扩缩方法。

Method: 将多种先进的自动扩缩方法应用于广泛使用的微服务基准测试，识别实际考虑因素，并基于软件生命周期（架构、实现、部署）进行分类。使用Sock-Shop基准验证这些考虑因素，评估包括基于阈值、控制理论、学习型、黑盒优化和依赖感知等多样化自动扩缩策略。

Result: 研究结果表明，忽视关键生命周期问题会降低自动扩缩器性能，而解决这些问题可实现更稳定和高效的扩缩。

Conclusion: 这些结果强调了生命周期感知工程对于释放微服务系统中自动扩缩全部潜力的重要性。

Abstract: Microservices have become the dominant architectural paradigm for building
scalable and modular cloud-native systems. However, achieving effective
auto-scaling in such systems remains a non-trivial challenge, as it depends not
only on advanced scaling techniques but also on sound design, implementation,
and deployment practices. Yet, these foundational aspects are often overlooked
in existing benchmarks, making it difficult to evaluate autoscaling methods
under realistic conditions. In this paper, we identify a set of practical
auto-scaling considerations by applying several state-of-the-art autoscaling
methods to widely used microservice benchmarks. To structure these findings, we
classify the issues based on when they arise during the software lifecycle:
Architecture, Implementation, and Deployment. The Architecture phase covers
high-level decisions such as service decomposition and inter-service
dependencies. The Implementation phase includes aspects like initialization
overhead, metrics instrumentation, and error propagation. The Deployment phase
focuses on runtime configurations such as resource limits and health checks. We
validate these considerations using the Sock-Shop benchmark and evaluate
diverse auto-scaling strategies, including threshold-based, control-theoretic,
learning-based, black-box optimization, and dependency-aware approaches. Our
findings show that overlooking key lifecycle concerns can degrade autoscaler
performance, while addressing them leads to more stable and efficient scaling.
These results underscore the importance of lifecycle-aware engineering for
unlocking the full potential of auto-scaling in microservice-based systems.

</details>


### [10] [RedCodeAgent: Automatic Red-teaming Agent against Diverse Code Agents](https://arxiv.org/abs/2510.02609)
*Chengquan Guo,Chulin Xie,Yu Yang,Zhaorun Chen,Zinan Lin,Xander Davies,Yarin Gal,Dawn Song,Bo Li*

Main category: cs.SE

TL;DR: 提出了RedCodeAgent，首个自动化红队代理，用于系统性地发现代码代理中的漏洞。通过自适应记忆模块和定制工具箱，能够动态选择最有效的红队工具组合，在模拟沙盒环境中评估执行结果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 代码代理的广泛应用带来了严重的安全风险，现有的静态安全基准和红队工具无法覆盖新兴的真实风险场景，特别是不同越狱工具组合的边界条件。

Method: 开发了RedCodeAgent，包含自适应记忆模块来利用现有越狱知识，动态选择最有效的红队工具和工具组合，并在模拟沙盒环境中评估代码代理的执行结果。

Result: 在多个最先进代码代理、多样化风险场景和各种编程语言的广泛评估中，RedCodeAgent始终优于现有红队方法，实现了更高的攻击成功率、更低的拒绝率和高效率。在真实世界代码助手（如Cursor和Codeium）上也暴露了先前未识别的安全风险。

Conclusion: 通过自动化和优化红队流程，RedCodeAgent实现了对代码代理的可扩展、自适应和有效的安全评估。

Abstract: Code agents have gained widespread adoption due to their strong code
generation capabilities and integration with code interpreters, enabling
dynamic execution, debugging, and interactive programming capabilities. While
these advancements have streamlined complex workflows, they have also
introduced critical safety and security risks. Current static safety benchmarks
and red-teaming tools are inadequate for identifying emerging real-world risky
scenarios, as they fail to cover certain boundary conditions, such as the
combined effects of different jailbreak tools. In this work, we propose
RedCodeAgent, the first automated red-teaming agent designed to systematically
uncover vulnerabilities in diverse code agents. With an adaptive memory module,
RedCodeAgent can leverage existing jailbreak knowledge, dynamically select the
most effective red-teaming tools and tool combinations in a tailored toolbox
for a given input query, thus identifying vulnerabilities that might otherwise
be overlooked. For reliable evaluation, we develop simulated sandbox
environments to additionally evaluate the execution results of code agents,
mitigating potential biases of LLM-based judges that only rely on static code.
Through extensive evaluations across multiple state-of-the-art code agents,
diverse risky scenarios, and various programming languages, RedCodeAgent
consistently outperforms existing red-teaming methods, achieving higher attack
success rates and lower rejection rates with high efficiency. We further
validate RedCodeAgent on real-world code assistants, e.g., Cursor and Codeium,
exposing previously unidentified security risks. By automating and optimizing
red-teaming processes, RedCodeAgent enables scalable, adaptive, and effective
safety assessments of code agents.

</details>


### [11] [Automatic Building Code Review: A Case Study](https://arxiv.org/abs/2510.02634)
*Hanlong Wan,Weili Xu,Michael Rosenberg,Jian Zhang,Aysha Siddika*

Main category: cs.SE

TL;DR: 提出了一种基于BIM和LLM的自动化建筑规范审查框架，结合RAG和MCP代理管道，实现几何属性提取和规范验证。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限地区建筑官员面临的设计文档人工审查劳动密集、易出错且成本高的问题，利用BIM和LLM技术实现自动化规范审查。

Method: 开发代理驱动框架，集成BIM数据提取与自动化验证，使用RAG和MCP代理管道，通过COMcheck API和基于规则的推理进行建筑规范检查。

Result: GPT-4o在效率和稳定性方面表现最佳，MCP代理管道在严谨性和可靠性上优于RAG推理管道，成功实现几何属性提取和照明规范验证。

Conclusion: 该研究展示了可扩展、可互操作且生产就绪的自动化规范审查方法，将BIM与权威规范审查工具有效结合。

Abstract: Building officials, particularly those in resource-constrained or rural
jurisdictions, face labor-intensive, error-prone, and costly manual reviews of
design documents as projects increase in size and complexity. The growing
adoption of Building Information Modeling (BIM) and Large Language Models
(LLMs) presents opportunities for automated code review (ACR) solutions. This
study introduces a novel agent-driven framework that integrates BIM-based data
extraction with automated verification using both retrieval-augmented
generation (RAG) and Model Context Protocol (MCP) agent pipelines. The
framework employs LLM-enabled agents to extract geometry, schedules, and system
attributes from heterogeneous file types, which are then processed for building
code checking through two complementary mechanisms: (1) direct API calls to the
US Department of Energy COMcheck engine, providing deterministic and
audit-ready outputs, and (2) RAG-based reasoning over rule provisions, enabling
flexible interpretation where coverage is incomplete or ambiguous.
  The framework was evaluated through case demonstrations, including automated
extraction of geometric attributes (such as surface area, tilt, and insulation
values), parsing of operational schedules, and validation of lighting
allowances under ASHRAE Standard 90.1-2022. Comparative performance tests
across multiple LLMs showed that GPT-4o achieved the best balance of efficiency
and stability, while smaller models exhibited inconsistencies or failures.
Results confirm that MCP agent pipelines outperform RAG reasoning pipelines in
rigor and reliability. This work advances ACR research by demonstrating a
scalable, interoperable, and production-ready approach that bridges BIM with
authoritative code review tools.

</details>


### [12] [Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing](https://arxiv.org/abs/2510.02718)
*Ali Ghanbari,Sasan Tavakkol*

Main category: cs.SE

TL;DR: DM#是一种基于傅里叶分析的深度神经网络突变测试加速技术，通过量化突变体行为进行聚类，仅测试代表性突变体，显著减少测试成本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络突变分析成本高昂，因为需要测试大量生成的突变体和大规模数据集。

Method: 利用傅里叶分析量化突变体行为，进行聚类分组，每组仅测试一个代表性突变体，结果复用给同组其他突变体。

Result: 在14个不同规模的DNN模型上评估，平均加速28.38%，突变分数误差仅0.72%，相比其他方法误差显著降低。

Conclusion: DM#能有效加速DNN突变测试，在保持准确性的同时大幅减少计算成本。

Abstract: Deep neural network (DNN) mutation analysis is a promising approach to
evaluating test set adequacy. Due to the large number of generated mutants that
must be tested on large datasets, mutation analysis is costly. In this paper,
we present a technique, named DM#, for accelerating DNN mutation testing using
Fourier analysis. The key insight is that DNN outputs are real-valued functions
suitable for Fourier analysis that can be leveraged to quantify mutant behavior
using only a few data points. DM# uses the quantified mutant behavior to
cluster the mutants so that the ones with similar behavior fall into the same
group. A representative from each group is then selected for testing, and the
result of the test, e.g., whether the mutant is killed or survived, is reused
for all other mutants represented by the selected mutant, obviating the need
for testing other mutants. 14 DNN models of sizes ranging from thousands to
millions of parameters, trained on different datasets, are used to evaluate DM#
and compare it to several baseline techniques. Our results provide empirical
evidence on the effectiveness of DM# in accelerating mutation testing by
28.38%, on average, at the average cost of only 0.72% error in mutation score.
Moreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation
score error compared to random mutant selection, boundary sample selection, and
random sample selection techniques, respectively, while generally offering
comparable speed-up.

</details>


### [13] [Automated Repair of OpenID Connect Programs (Extended Version)](https://arxiv.org/abs/2510.02773)
*Tamjid Al Rahat,Yanju Chen,Yu Feng,Yuan Tian*

Main category: cs.SE

TL;DR: AuthFix是一个基于LLM的OpenID连接漏洞自动修复引擎，通过反例引导的修复方法，成功修复了74%的OpenID漏洞。


<details>
  <summary>Details</summary>
Motivation: OpenID Connect虽然广泛采用，但存在严重安全漏洞导致重大经济损失，需要强大的自动化修复策略。

Method: AuthFix集成三个关键组件：故障定位、补丁合成和补丁验证，采用新颖的Petri网模型检查器确保补丁正确性。

Result: 在23个OpenID漏洞数据集上，AuthFix成功为17个漏洞（74%）生成了正确补丁，其中大部分补丁与开发者编写的修复在语义上等价。

Conclusion: AuthFix证明了基于LLM的自动化程序修复在OpenID安全漏洞修复中的有效性，为复杂领域特定系统的安全修复提供了可行方案。

Abstract: OpenID Connect has revolutionized online authentication based on single
sign-on (SSO) by providing a secure and convenient method for accessing
multiple services with a single set of credentials. Despite its widespread
adoption, critical security bugs in OpenID Connect have resulted in significant
financial losses and security breaches, highlighting the need for robust
mitigation strategies. Automated program repair presents a promising solution
for generating candidate patches for OpenID implementations. However,
challenges such as domain-specific complexities and the necessity for precise
fault localization and patch verification must be addressed. We propose
AuthFix, a counterexample-guided repair engine leveraging LLMs for automated
OpenID bug fixing. AuthFix integrates three key components: fault localization,
patch synthesis, and patch verification. By employing a novel Petri-net-based
model checker, AuthFix ensures the correctness of patches by effectively
modeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates
that AuthFix successfully generated correct patches for 17 out of 23 bugs
(74%), with a high proportion of patches semantically equivalent to
developer-written fixes.

</details>


### [14] [C2|Q>: A Robust Framework for Bridging Classical and Quantum Software Development](https://arxiv.org/abs/2510.02854)
*Boshuai Ye,Arif Ali Khan,Teemu Pihkakoski,Peng Liang,Muhammad Azeem Akbar,Matti Silveri,Lauri Malmi*

Main category: cs.SE

TL;DR: C2|Q>是一个硬件无关的量子软件开发框架，通过将经典代码规范转换为量子可执行程序，使经典软件工程师能够更容易地进行量子计算开发。


<details>
  <summary>Details</summary>
Motivation: 当前量子开发环境要求开发者处理软件栈的低层细节，包括问题编码、电路构建、算法配置、硬件选择和结果解释等，这使得经典软件工程师难以使用量子计算。

Method: 框架采用模块化软件工程原则，将工作流分为三个核心模块：编码器（分类问题、生成量子兼容格式、构建量子电路）、部署模块（生成电路、基于保真度、运行时间和成本推荐硬件）、解码器（将量子输出解释为经典解决方案）。

Result: 编码器模块完成率达到93.8%，硬件推荐模块为最多56量子比特的工作负载正确选择量子设备，完整C2|Q>工作流处理了434个Python代码片段和100个JSON输入，完成率分别为93.8%和100%。在NISQ硬件上的案例研究中，相比使用低层量子SDK的手动实现，C2|Q>减少了近40倍的实施工作量。

Conclusion: C2|Q>框架成功地将量子软件开发抽象化，显著降低了经典软件工程师进入量子计算领域的门槛，同时保持了方法论的严谨性。

Abstract: Quantum Software Engineering (QSE) is emerging as a critical discipline to
make quantum computing accessible to a broader developer community; however,
most quantum development environments still require developers to engage with
low-level details across the software stack - including problem encoding,
circuit construction, algorithm configuration, hardware selection, and result
interpretation - making them difficult for classical software engineers to use.
To bridge this gap, we present C2|Q>: a hardware-agnostic quantum software
development framework that translates classical specifications (code) into
quantum-executable programs while preserving methodological rigor. The
framework applies modular software engineering principles by classifying the
workflow into three core modules: an encoder that classifies problems, produces
Quantum-Compatible Formats (QCFs), and constructs quantum circuits, a
deployment module that generates circuits and recommends hardware based on
fidelity, runtime, and cost, and a decoder that interprets quantum outputs into
classical solutions. In evaluation, the encoder module achieved a 93.8%
completion rate, the hardware recommendation module consistently selected the
appropriate quantum devices for workloads scaling up to 56 qubits, and the full
C2|Q>: workflow successfully processed classical specifications (434 Python
snippets and 100 JSON inputs) with completion rates of 93.8% and 100%,
respectively. For case study problems executed on publicly available NISQ
hardware, C2|Q>: reduced the required implementation effort by nearly 40X
compared to manual implementations using low-level quantum software development
kits (SDKs), with empirical runs limited to small- and medium-sized instances
consistent with current NISQ capabilities. The open-source implementation of
C2|Q>: is available at https://github.com/C2-Q/C2Q

</details>


### [15] [GramTrans: A Better Code Representation Approach in Code Generation](https://arxiv.org/abs/2510.02887)
*Zhao Zhang,Qingyuan Liang,Zeyu Sun,Yizhou Chen,Guoqing Wang,Yican Sun,Lu Zhang,Ge Li,Yingfei Xiong*

Main category: cs.SE

TL;DR: 论文提出一个猜想：代码表示越容易解析，模型性能越好。通过GramTrans方法将上下文无关语言转换为LL(1)类表示，实验证明解析难度与模型性能强相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用不同代码表示（纯文本、语法规则序列、语法树序列），但缺乏对解析难度与模型效果关系的系统性理解。

Method: 提出GramTrans方法，使用分层冲突消除算法将上下文无关语言转换为LL(1)类表示，平衡语法简单性和标记效率。

Result: 在Python和Java上使用三个代码生成模型评估，GramTrans在多个基准测试中显著优于基线表示。

Conclusion: 解析难度与模型性能强相关，GramTrans方法能有效提升代码生成模型性能。

Abstract: Code generation has shown great promise in assisting software development. A
fundamental yet underexplored question is how the choice of code representation
affects model performance. While existing studies employ various
representations, such as treating code as plain text, grammar rule sequences,
or syntax tree sequences, they lack a principled understanding of the
relationship between parsing difficulty and model effectiveness. This paper
proposes a conjecture: the easier a representation is to parse, the better
performance the model achieves. We formalize this idea using grammar classes,
where representations in simpler classes (e.g., LL(1)) are easier to parse.
Through a controlled experiment on a Python-based DSL, we show that parsing
difficulty strongly correlates with model performance. Motivated by this
finding, we present GramTrans, a general approach that automatically transforms
a context-free language into a representation within the LL(1) class. GramTrans
introduces a novel hierarchical conflict elimination algorithm, enabling a
flexible trade-off between syntactic simplicity and token efficiency. We
evaluate GramTrans on both Python and Java using three code generation models:
StarCoder 1B, DeepSeek-Coder 1.3B, and Qwen2.5 1.5B. Across multiple
benchmarks, GramTrans consistently delivers significant improvements over
baseline representations. Furthermore, our analysis of existing representations
reconfirms the strong alignment between parsing difficulty and model
performance, providing additional support for the conjecture.

</details>


### [16] [Mechanistic Interpretability of Code Correctness in LLMs via Sparse Autoencoders](https://arxiv.org/abs/2510.02917)
*Kriz Tahimic,Charibeth Cheng*

Main category: cs.SE

TL;DR: 该论文通过稀疏自编码器分析LLM内部表示，识别出与代码正确性相关的方向，并发现这些方向能可靠预测错误代码。研究揭示了代码生成机制依赖于关注测试用例而非问题描述，且基础模型中学到的代码正确性机制在指令微调后仍保持有效。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件开发中的广泛应用，理解其内部代码正确性机制对于安全部署至关重要。研究旨在揭示LLM如何内部表示和处理代码正确性。

Method: 使用稀疏自编码器分解LLM表示，通过t统计量选择预测方向，通过分离分数从基础模型表示中确定引导方向，然后通过引导、注意力分析和权重正交化分析其机制特性。

Result: 发现代码正确性方向能可靠预测错误代码，但纠错能力涉及修复错误与保留正确代码之间的权衡。成功的代码生成依赖于关注测试用例而非问题描述。基础模型中识别的方向在指令微调后仍保持有效性。

Conclusion: 研究提出了三个实际应用：提示策略应优先考虑测试示例而非详细问题描述，预测方向可作为开发者审查的错误警报，这些预测器可指导选择性引导，仅在预期错误时进行干预以避免代码损坏。

Abstract: As Large Language Models become integral to software development, with
substantial portions of AI-suggested code entering production, understanding
their internal correctness mechanisms becomes critical for safe deployment. We
apply sparse autoencoders to decompose LLM representations, identifying
directions that correspond to code correctness. We select predictor directions
using t-statistics and steering directions through separation scores from base
model representations, then analyze their mechanistic properties through
steering, attention analysis, and weight orthogonalization. We find that code
correctness directions in LLMs reliably predict incorrect code, while
correction capabilities, though statistically significant, involve tradeoffs
between fixing errors and preserving correct code. Mechanistically, successful
code generation depends on attending to test cases rather than problem
descriptions. Moreover, directions identified in base models retain their
effectiveness after instruction-tuning, suggesting code correctness mechanisms
learned during pre-training are repurposed during fine-tuning. Our mechanistic
insights suggest three practical applications: prompting strategies should
prioritize test examples over elaborate problem descriptions, predictor
directions can serve as error alarms for developer review, and these same
predictors can guide selective steering, intervening only when errors are
anticipated to prevent the code corruption from constant steering.

</details>


### [17] [Model-Agnostic Correctness Assessment for LLM-Generated Code via Dynamic Internal Representation Selection](https://arxiv.org/abs/2510.02934)
*Thanh Trong Vu,Tuan-Dung Bui,Thu-Trang Nguyen,Son Nguyen,Hieu Dinh Vo*

Main category: cs.SE

TL;DR: AUTOPROBE是一种模型无关的方法，通过动态选择LLM内部最有信息量的表示来评估代码正确性，在编译性、功能性和安全性评估方面均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预选层和标记位置的表示，限制了在不同模型架构和任务间的泛化能力，需要一种更通用的代码正确性评估方法。

Method: 使用基于注意力的机制学习隐藏状态的重要性分数，聚焦最相关特征，然后聚合加权表示并通过探测分类器预测代码正确性。

Result: 在多个基准测试和代码LLM上的实验表明，AUTOPROBE始终优于基线方法。安全性评估超越最先进白盒方法18%，编译性和功能性评估分别比其他方法高19%和111%。

Conclusion: 动态选择重要内部信号使AUTOPROBE成为评估各种LLM生成代码正确性的鲁棒且可泛化的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
code generation and are increasingly integrated into the software development
process. However, ensuring the correctness of LLM-generated code remains a
critical concern. Prior work has shown that the internal representations of
LLMs encode meaningful signals for assessing code correctness. Nevertheless,
the existing methods rely on representations from pre-selected/fixed layers and
token positions, which could limit its generalizability across diverse model
architectures and tasks. In this work, we introduce AUTOPROBE, a novel
model-agnostic approach that dynamically selects the most informative internal
representations for code correctness assessment. AUTOPROBE employs an
attention-based mechanism to learn importance scores for hidden states,
enabling it to focus on the most relevant features. These weighted
representations are then aggregated and passed to a probing classifier to
predict code correctness across multiple dimensions, including compilability,
functionality, and security. To evaluate the performance of AUTOPROBE, we
conduct extensive experiments across multiple benchmarks and code LLMs. Our
experimental results show that AUTOPROBE consistently outperforms the
baselines. For security assessment, AUTOPROBE surpasses the state-of-the-art
white-box approach by 18%. For compilability and functionality assessment,
AUTOPROBE demonstrates its highest robustness to code complexity, with the
performance higher than the other approaches by up to 19% and 111%,
respectively. These findings highlight that dynamically selecting important
internal signals enables AUTOPROBE to serve as a robust and generalizable
solution for assessing the correctness of code generated by various LLMs.

</details>


### [18] [Tracing and Metrics Design Patterns for Monitoring Cloud-native Applications](https://arxiv.org/abs/2510.02991)
*Carlos Albuquerque,Filipe F. Correia*

Main category: cs.SE

TL;DR: 本文提出了三种云原生应用监控设计模式：分布式追踪、应用指标和基础设施指标，以解决分布式系统中可观测性挑战。


<details>
  <summary>Details</summary>
Motivation: 随着软件架构日益分布式和易变，诊断系统问题变得更加困难，需要应对碎片化可观测性和更复杂的根因分析挑战。

Method: 基于先前工作，引入三种设计模式：分布式追踪改进跨服务请求流的可见性，应用指标提供结构化应用性能监控方法，基础设施指标监控系统运行环境。

Result: 这些模式源自行业实践和可观测性框架，为软件从业者提供指导，帮助改善系统可靠性、延迟分析和根因检测。

Conclusion: 三种设计模式共同构成了云原生应用可观测性的完整解决方案，有助于确保分布式系统的可靠性和可维护性。

Abstract: Observability helps ensure the reliability and maintainability of
cloud-native applications. As software architectures become increasingly
distributed and subject to change, it becomes a greater challenge to diagnose
system issues effectively, often having to deal with fragmented observability
and more difficult root cause analysis. This paper builds upon our previous
work and introduces three design patterns that address key challenges in
monitoring cloud-native applications. Distributed Tracing improves visibility
into request flows across services, aiding in latency analysis and root cause
detection, Application Metrics provides a structured approach to instrumenting
applications with meaningful performance indicators, enabling real-time
monitoring and anomaly detection, and Infrastructure Metrics focuses on
monitoring the environment in which the system is operated, helping teams
assess resource utilization, scalability, and operational health. These
patterns are derived from industry practices and observability frameworks and
aim to offer guidance for software practitioners.

</details>


### [19] [Patterns for Teaching Agile with Student Projects -- Team and Project Setup](https://arxiv.org/abs/2510.03005)
*Daniel Pinho,Petr Pícha,Filipe Correia,Přemek Brada*

Main category: cs.SE

TL;DR: 提出用于教授敏捷软件开发(ASD)的大学课程模式语言，重点关注团队和项目设置阶段的五个具体模式。


<details>
  <summary>Details</summary>
Motivation: 现有关于ASD教学方法的文献缺乏可操作建议，要么过于关注框架，要么偏离软件开发本身而转向敏捷教学方式。

Method: 基于高等教育背景下的教学经验，开发模式语言，提出五个团队和项目设置阶段的模式：限制团队规模、缩小项目范围、非关键业务项目、自组织团队、团队选择主题。

Result: 展示了模式语言的早期工作，提供了五个具体模式作为整体模式语言开发的起点。

Conclusion: 这些模式为教授ASD实践提供了具体的、可操作的教学指导，填补了现有文献的空白。

Abstract: Higher education courses teaching about agile software development (ASD) have
increased in commonality as the ideas behind the Agile Manifesto became more
commonplace in the industry. However, a lot of the literature on how ASD is
applied in the classroom does not provide much actionable advice, focusing on
frameworks or even moving beyond the software development area into teaching in
an agile way. We, therefore, showcase early work on a pattern language that
focuses on teaching ASD practices to university students, which stems from our
own experiences as educators in higher education contexts. We present five
patterns, specifically focused on team and project setup phase: Capping Team
Size, Smaller Project Scope, Business Non-Critical Project, Self-assembling
Teams, and Team Chooses Topic as a starting point for developing the overall
pattern language.

</details>


### [20] [Investigating The Smells of LLM Generated Code](https://arxiv.org/abs/2510.03029)
*Debalina Ghosh Paul,Hong Zhu,Ian Bayley*

Main category: cs.SE

TL;DR: 本文提出了一种基于场景的方法来评估LLM生成代码的质量，通过测量代码异味并与专业编写的参考解决方案进行比较，发现在代码质量方面LLM生成的代码明显差于人类编写的代码。


<details>
  <summary>Details</summary>
Motivation: 目前关于LLM生成代码的研究主要集中在功能正确性上，而对代码质量的研究较少。本文旨在评估LLM生成代码的质量，识别最需要改进的场景。

Method: 使用基于场景的方法，测量代码异味作为代码质量指标，并与专业编写的参考解决方案进行比较。将测试数据集按代码主题和任务复杂度划分为不同子集，测试了四种先进LLM：Gemini Pro、ChatGPT、Codex和Falcon。

Result: LLM生成的代码比参考解决方案有更高的代码异味发生率。Falcon表现最好（异味增加42.28%），其次是Gemini Pro（62.07%）、ChatGPT（65.05%）和Codex（84.97%）。平均异味增加63.34%，其中实现异味增加73.35%，设计异味增加21.42%。更复杂的编码任务和涉及面向对象概念的题目异味增加更明显。

Conclusion: 在代码异味方面，LLM在不同编码任务复杂度和主题上的表现与相应场景下人类编写代码的质量高度相关，但LLM生成代码的质量明显比人类编写的代码差。

Abstract: Context: Large Language Models (LLMs) are increasingly being used to generate
program code. Much research has been reported on the functional correctness of
generated code, but there is far less on code quality.
  Objectives: In this study, we propose a scenario-based method of evaluating
the quality of LLM-generated code to identify the weakest scenarios in which
the quality of LLM generated code should be improved.
  Methods: The method measures code smells, an important indicator of code
quality, and compares them with a baseline formed from reference solutions of
professionally written code. The test dataset is divided into various subsets
according to the topics of the code and complexity of the coding tasks to
represent different scenarios of using LLMs for code generation. We will also
present an automated test system for this purpose and report experiments with
the Java programs generated in response to prompts given to four
state-of-the-art LLMs: Gemini Pro, ChatGPT, Codex, and Falcon.
  Results: We find that LLM-generated code has a higher incidence of code
smells compared to reference solutions. Falcon performed the least badly, with
a smell increase of 42.28%, followed by Gemini Pro (62.07%), ChatGPT (65.05%)
and finally Codex (84.97%). The average smell increase across all LLMs was
63.34%, comprising 73.35% for implementation smells and 21.42% for design
smells. We also found that the increase in code smells is greater for more
complex coding tasks and for more advanced topics, such as those involving
object-orientated concepts.
  Conclusion: In terms of code smells, LLM's performances on various coding
task complexities and topics are highly correlated to the quality of human
written code in the corresponding scenarios. However, the quality of LLM
generated code is noticeably poorer than human written code.

</details>


### [21] [Refactoring Towards Microservices: Preparing the Ground for Service Extraction](https://arxiv.org/abs/2510.03050)
*Rita Peixoto,Filipe F. Correia,Thatiane Rosa,Eduardo Guerra,Alfredo Goldman*

Main category: cs.SE

TL;DR: 本文提出了一个包含7种重构方法的目录，专门用于支持向微服务架构的迁移，重点处理依赖关系问题。


<details>
  <summary>Details</summary>
Motivation: 随着组织从单体系统向微服务迁移，现有方法主要关注架构层面指导，忽略了代码层面的挑战和依赖关系，导致迁移过程仍然手动且劳动密集。

Method: 开发了一个重构目录，整合了文献中已识别的重构方法，提供结构化的逐步指导来处理代码级依赖。

Result: 提供了一个系统化的重构指南，简化了迁移过程，并为潜在自动化奠定了基础。

Conclusion: 该工作通过提供结构化方法，使开发者能够更高效地实施微服务迁移，填补了代码层面系统化处理的空白。

Abstract: As organizations increasingly transition from monolithic systems to
microservices, they aim to achieve higher availability, automatic scaling,
simplified infrastructure management, enhanced collaboration, and streamlined
deployments. However, this migration process remains largely manual and
labour-intensive. While existing literature offers various strategies for
decomposing monoliths, these approaches primarily focus on architecture-level
guidance, often overlooking the code-level challenges and dependencies that
developers must address during the migration. This article introduces a
catalogue of seven refactorings specifically designed to support the transition
to a microservices architecture with a focus on handling dependencies. The
catalogue provides developers with a systematic guide that consolidates
refactorings identified in the literature and addresses the critical gap in
systematizing the process at the code level. By offering a structured,
step-by-step approach, this work simplifies the migration process and lays the
groundwork for its potential automation, empowering developers to implement
these changes efficiently and effectively.

</details>


### [22] [State Field Coverage: A Metric for Oracle Quality](https://arxiv.org/abs/2510.03071)
*Facundo Molina,Nazareno Aguirre,Alessandra Gorla*

Main category: cs.SE

TL;DR: 提出了一种名为状态字段覆盖的新指标，用于评估测试预言的质量，该指标衡量预言在测试执行期间可能访问的对象状态字段的比例。


<details>
  <summary>Details</summary>
Motivation: 现有指标要么无法为预言改进提供全面基础，要么局限于特定类型的预言，限制了通用性。评估预言质量对于提高测试过程整体有效性至关重要。

Method: 实现了一种静态计算状态字段覆盖指标的机制，该指标高效且能通过识别未检查的状态字段直接指导测试预言改进。

Result: 通过对273个表示不变式和249,027个测试断言的实验评估，结果显示状态字段覆盖与预言故障检测能力（通过变异得分衡量）强相关。

Conclusion: 状态字段覆盖是评估预言质量的合适指标，因为它与预言检测软件故障的能力密切相关。

Abstract: The effectiveness of testing in uncovering software defects depends not only
on the characteristics of the test inputs and how thoroughly they exercise the
software, but also on the quality of the oracles used to determine whether the
software behaves as expected. Therefore, assessing the quality of oracles is
crucial to improve the overall effectiveness of the testing process. Existing
metrics have been used for this purpose, but they either fail to provide a
comprehensive basis for guiding oracle improvement, or they are tailored to
specific types of oracles, thus limiting their generality.
  In this paper, we introduce state field coverage, a novel metric for
assessing oracle quality. This metric measures the proportion of an object's
state, as statically defined by its class fields, that an oracle may access
during test execution. The main intuition of our metric is that oracles with a
higher state field coverage are more likely to detect faults in the software
under analysis, as they inspect a larger portion of the object states to
determine whether tests pass or not.
  We implement a mechanism to statically compute the state field coverage
metric. Being statically computed, the metric is efficient and provides direct
guidance for improving test oracles by identifying state fields that remain
unexamined. We evaluate state field coverage through experiments involving 273
representation invariants and 249,027 test assertions. The results show that
state field coverage is a well-suited metric for assessing oracle quality, as
it strongly correlates with the oracles' fault-detection ability, measured by
mutation score.

</details>


### [23] [When Names Disappear: Revealing What LLMs Actually Understand About Code](https://arxiv.org/abs/2510.03178)
*Cuong Chi Le,Minh V. T. Pham,Cuong Duc Van,Hoang N. Phan,Huy N. Phan,Tien N. Nguyen*

Main category: cs.SE

TL;DR: 论文研究了LLMs如何理解代码，发现代码通过结构语义和命名两个渠道传递信息。去除命名会严重影响意图级任务，并在执行任务中暴露命名模式记忆问题。作者引入语义保留混淆方法，并发布ClassEval-Obf基准来更可靠地评估LLMs的代码理解能力。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs如何从代码中获取程序含义，区分结构语义和人类可解释命名两个渠道的作用，揭示当前基准测试中存在的命名模式记忆问题。

Method: 引入语义保留混淆方法，通过去除命名信息来分离结构语义和命名的影响，并创建ClassEval-Obf混淆增强基准。

Result: 去除命名会严重降低意图级任务性能，在执行任务中也观察到一致性能下降，表明当前基准奖励命名模式记忆而非真正的语义推理。混淆方法暴露了标识符泄漏问题。

Conclusion: ClassEval-Obf基准通过抑制命名线索同时保留行为，减少了膨胀的性能差距，削弱了记忆捷径，为评估LLMs的代码理解和泛化能力提供了更可靠的基础。

Abstract: Large Language Models (LLMs) achieve strong results on code tasks, but how
they derive program meaning remains unclear. We argue that code communicates
through two channels: structural semantics, which define formal behavior, and
human-interpretable naming, which conveys intent. Removing the naming channel
severely degrades intent-level tasks such as summarization, where models
regress to line-by-line descriptions. Surprisingly, we also observe consistent
reductions on execution tasks that should depend only on structure, revealing
that current benchmarks reward memorization of naming patterns rather than
genuine semantic reasoning. To disentangle these effects, we introduce a suite
of semantics-preserving obfuscations and show that they expose identifier
leakage across both summarization and execution. Building on these insights, we
release ClassEval-Obf, an obfuscation-enhanced benchmark that systematically
suppresses naming cues while preserving behavior. Our results demonstrate that
ClassEval-Obf reduces inflated performance gaps, weakens memorization
shortcuts, and provides a more reliable basis for assessing LLMs' code
understanding and generalization.

</details>


### [24] [Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic Program Repair](https://arxiv.org/abs/2510.03217)
*José Cambronero,Michele Tufano,Sherry Shi,Renyao Wei,Grant Uy,Runxiang Cheng,Chin-Jung Liu,Shiying Pan,Satish Chandra,Pat Rondon*

Main category: cs.SE

TL;DR: 提出了两种LLM策略来减少自动化程序修复中的噪音：错误弃权和补丁验证，显著提高了修复成功率


<details>
  <summary>Details</summary>
Motivation: 自动化程序修复系统生成的补丁需要人工审查，但展示不太可能成功的补丁会浪费开发者时间并损害对自动化代码变更的信任

Method: 引入两种互补的LLM策略：错误弃权策略排除系统不太可能修复的错误，补丁验证策略拒绝不太可能是良好修复的补丁

Result: 在174个人工报告的错误上，应用策略可将成功率分别提高13和15个百分点，组合使用时提高39个百分点

Conclusion: 这种双策略方法为自动化程序修复系统的可靠工业规模部署提供了实用路径

Abstract: Agentic Automated Program Repair (APR) is increasingly tackling complex,
repository-level bugs in industry, but ultimately agent-generated patches still
need to be reviewed by a human before committing them to ensure they address
the bug. Showing unlikely patches to developers can lead to substantial noise,
wasting valuable developer time and eroding trust in automated code changes. We
introduce two complementary LLM-based policies to reduce such noise: bug
abstention and patch validation policies. Bug abstention excludes bugs that the
agentic APR system is unlikely to fix. Patch validation rejects patches that
are unlikely to be a good fix for the given bug. We evaluate both policies on
three sets of bugs from Google's codebase, and their candidate patches
generated by an internal agentic APR system. On a set of 174 human-reported
bugs, removing bugs and patch trajectories rejected by our policies can raise
success rates by up to 13 percentage points and 15 percentage points,
respectively, and by up to 39 percentage points in combination. On null pointer
exceptions and sanitizer-reported bugs with machine-generated bug reports,
patch validation also improves average single-sample success rates. This
two-policy approach provides a practical path to the reliable, industrial-scale
deployment of agentic APR systems.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [25] [Designing Walrus: Relational Programming with Rich Types, On-Demand Laziness, and Structured Traces](https://arxiv.org/abs/2510.02579)
*Santiago Cuéllar,Naomi Spargo,Jonathan Daugherty,David Darais*

Main category: cs.PL

TL;DR: Walrus是一个嵌入在Haskell中的函数式关系编程语言，扩展了miniKanren模型，增加了类型多态统一、按需惰性求值和实用开发功能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决实际开发中的可用性挑战，为双向编译器开发等应用提供更好的编程体验和工具支持。

Method: 通过Haskell泛型减少样板代码，提供结构化调试跟踪，改进乘积类型的支持，并在双向编译器开发实践中验证设计。

Result: 成功实现了类型多态统一、按需惰性求值等核心功能，并提供了实用的开发工具集。

Conclusion: Walrus通过扩展miniKanren模型并添加实用功能，为关系编程提供了更实用的开发环境，设计决策在实践应用中得到了验证。

Abstract: We present Walrus, a functional relational programming language embedded in
Haskell that extends the miniKanren model with type-polymorphic unification,
on-demand laziness, and a range of usability features aimed at practical
development. These include use of Haskell Generics for boilerplate reduction,
structured debugging traces, and ergonomic support for product types. We
describe the design and implementation of Walrus through the lens of our
experience developing bidirectional compilers, and reflect on key design
decisions and recurring usability challenges encountered in practice.

</details>


### [26] [Beyond Cons: Purely Relational Data Structures](https://arxiv.org/abs/2510.03170)
*Rafaello Sanna,William E. Byrd,Nada Amin*

Main category: cs.PL

TL;DR: Kanren是miniKanren的扩展，增加了集合和关联列表的约束推理功能，支持声明式编程和惰性求值。


<details>
  <summary>Details</summary>
Motivation: 为了改进抽象数据操作程序（特别是解释器）的表达能力和操作行为，避免依赖结构编码和表示空间的急切搜索。

Method: 在支持约束的miniKanren系统中设计实现Kanren，包括一阶集合对象、完整的集合论约束族（成员、并集、不相交性）以及关联列表的新约束。

Result: 提高了程序的表达能力，支持基于内容的集合相等性，实现有限失败机制。

Conclusion: Kanren扩展使程序员能够以声明式和惰性方式描述集合，改善了抽象数据操作程序的性能。

Abstract: We present {Kanren} (read: set-Kanren), an extension to miniKanren with
constraints for reasoning about sets and association lists. {Kanren} includes
first-class set objects, a functionally complete family of set-theoretic
constraints (including membership, union, and disjointedness), and new
constraints for reasoning about association lists with shadowing and scoped
lookup. These additions allow programmers to describe collections declaratively
and lazily, without relying on structural encodings and eager search over
representation spaces. The result is improved expressiveness and operational
behavior in programs that manipulate abstract data -- particularly interpreters
-- by supporting set equality based on contents, enabling finite failure. We
describe the design and implementation of {Kanren} in a constraint-enabled
miniKanren system and illustrate its use in representative examples.

</details>
