<div id=toc></div>

# Table of Contents

- [cs.FL](#cs.FL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [1] [Transformers are Inherently Succinct](https://arxiv.org/abs/2510.19315)
*Pascal Bergsträßer,Ryan Cotterell,Anthony W. Lin*

Main category: cs.FL

TL;DR: 本文提出用简洁性衡量transformer的表达能力，证明transformer在表示形式语言时比有限自动机和LTL公式更简洁，并由此得出验证transformer属性是EXPSPACE完全问题。


<details>
  <summary>Details</summary>
Motivation: 研究transformer的表达能力，特别是其在描述概念时的简洁性，并与传统形式语言表示方法进行比较。

Method: 提出简洁性作为衡量标准，通过理论证明比较transformer与有限自动机、LTL公式在表示形式语言时的表达能力。

Result: 证明transformer能够比有限自动机和LTL公式更简洁地表示形式语言，且验证transformer属性是EXPSPACE完全问题。

Conclusion: transformer具有强大的表达能力，能够简洁表示复杂形式语言，但这导致其验证问题在计算上非常困难。

Abstract: We propose succinctness as a measure of the expressive power of a transformer
in describing a concept. To this end, we prove that transformers are highly
expressive in that they can represent formal languages substantially more
succinctly than standard representations of formal languages like finite
automata and Linear Temporal Logic (LTL) formulas. As a by-product of this
expressivity, we show that verifying properties of transformers is provably
intractable (i.e. EXPSPACE-complete).

</details>


### [2] [Stochastic Languages at Sub-stochastic Cost](https://arxiv.org/abs/2510.19276)
*Smayan Agarwal,Aalok Thakkar*

Main category: cs.FL

TL;DR: 该论文解决了加权自动机和成本寄存器自动机(CRA)的随机性问题，证明了CRA的随机性检查是不可判定的，但在完全线性片段中是可判定的，并建立了完整的理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究确定性计算模型何时定义概率分布及其性质，为概率计算提供形式化理论基础。

Method: 使用谱方法分析完全线性CRA片段，建立局部语法特征，提供代数Kleene-Schutzenberger特征描述。

Result: 证明了线性CRA的随机性可在多项式时间内判定，每个随机线性CRA都有等价的局部子随机更新函数模型，并引入了随机正则表达式。

Conclusion: 该框架为概率计算的形式理论奠定了基础，对近似、采样和分布测试具有直接应用价值。

Abstract: When does a deterministic computational model define a probability
distribution? What are its properties? This work formalises and settles this
stochasticity problem for weighted automata, and its generalisation cost
register automata (CRA).
  We show that checking stochasticity is undecidable for CRAs in general. This
motivates the study of the fully linear fragment, where a complete and
tractable theory is established. For this class, stochasticity becomes
decidable in polynomial time via spectral methods, and every stochastic linear
CRA admits an equivalent model with locally sub-stochastic update functions.
This provides a local syntactic characterisation of the semantics of the
quantitative model.
  This local characterisation allows us to provide an algebraic
Kleene-Schutzenberger characterisation for stochastic languages. The class of
rational stochastic languages is the smallest class containing finite support
distributions, which is closed under convex combination, Cauchy product, and
discounted Kleene star. We also introduce Stochastic Regular Expressions as a
complete and composable grammar for this class.
  Our framework provides the foundations for a formal theory of probabilistic
computation, with immediate consequences for approximation, sampling, and
distribution testing.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [An Empirical Study of Bitwise Operators Intuitiveness through Performance Metrics](https://arxiv.org/abs/2510.19281)
*Shubham Joshi*

Main category: cs.SE

TL;DR: 研究探讨了不同编程背景人员对位运算符的理解差异，发现某些运算符(OR、NOT、左移)在任务完成时间上具有统计显著性差异。


<details>
  <summary>Details</summary>
Motivation: 调查位运算符在编程中的可读性和可理解性，检验不同编程背景人员在处理位运算符时的性能差异。

Method: 采用被试内实验设计，让23名不同编程背景的参与者完成JavaScript编程任务，记录任务完成时间和准确率。

Result: 运算符是预测响应时间的因素之一，具有小但显著的影响(R²=0.032)。OR、NOT和左移运算符在任务完成时间上显示出统计显著性。

Conclusion: 虽然位运算符的复杂性并未普遍导致更长的任务完成时间，但某些运算符被发现不够直观，需要进一步研究和可能的重新设计以提高可理解性。

Abstract: Objectives: This study aims to investigate the readability and
understandability of bitwise operators in programming, with the main hypothesis
that there will be a difference in the performance metrics (response time and
error rate) between participants exposed to various bitwise operators related
questions and those who are not.
  Participants: Participants in this human research study include people
without programming background, novice programmers, and university students
with varying programming experience (from freshmen to PhD level). There were 23
participants for this study.
  Study Methods: This study uses an Within-Subjects Experimental Design to
assess how people with diverse programming backgrounds understand and use
bitwise operators. Participants complete tasks in JavaScript program, and their
task completion time and accuracy of the tasks are recorded for analysis.
  Findings: The results indicate that operators can be one of the factors
predicting response time, with a small but significant effect, with R-squared
0.032, (1, 494) = 16.5, p < .001. Additionally, some operators like OR, NOT,
and Left Shift showed statistical significance in task completion times
compared to other operators.
  Conclusions: While the complexity of bitwise operators did not generally
result in longer task completion times, certain operators were found to be less
intuitive, suggesting the need for further investigation and potential redesign
for improved understandability.

</details>


### [4] [CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation](https://arxiv.org/abs/2510.18895)
*Santhosh Kumar Ravindran*

Main category: cs.SE

TL;DR: CosmoCore是一种受神经科学启发的强化学习架构，通过整合情感信号来增强大语言模型的代码生成能力，显著减少幻觉代码并加速自我修正。


<details>
  <summary>Details</summary>
Motivation: 受人类和动物学习的启发，特别是从错误中感到尴尬并快速纠正的行为，如训练小狗避免重复错误。

Method: 使用轻量级多层感知器为代码生成轨迹标记效价和惊喜值，将高负效价（尴尬）的代码片段优先在Dream Queue中进行五倍重放，同时修剪低惊喜的成功案例以防止过度自信。

Result: 在HumanEval和BigCodeBench等代码生成基准测试中，CosmoCore将幻觉代码（语法错误或逻辑错误）减少了48%，并将自我修正速度提高了45%。

Conclusion: 该框架扩展了基于人类反馈的强化学习，为代码助手提供了更情感感知的能力，适用于IDE和数据管道等场景。

Abstract: We introduce CosmoCore, a neuroscience-inspired reinforcement learning (RL)
architecture that integrates affective signals to enhance code generation in
large language models (LLMs). Motivated by human and animal learning where
embarrassment from mistakes drives rapid correction, as observed in training a
puppy to avoid repeating errors after a single scolding CosmoCore tags code
generation trajectories with valence and surprise using a lightweight
multi-layer perceptron (MLP). High-negative valence (cringe) episodes, such as
buggy code outputs, are prioritized in a Dream Queue for five-fold replay
during off-policy updates, while low-surprise successes are pruned to prevent
overconfidence and buffer bloat. Evaluated on code generation benchmarks like
HumanEval and BigCodeBench, alongside simulations with a custom data pipeline
environment, CosmoCore reduces hallucinated code (e.g., syntax errors or
logical bugs) by 48\% and accelerates self-correction by 45\%. Local
experiments using Hugging Face models in a PySpark environment validate these
gains, with code snippets provided for replication. Ablations confirm valence
tagging boosts curiosity in exploration, and pruning mitigates inefficiency.
This framework extends RL from human feedback (RLHF) for more emotionally aware
code assistants, with applications in IDEs and data pipelines. Code and the
custom mini-world simulation are released.

</details>


### [5] [A Survey on Feedback Types in Automated Programming Assessment Systems](https://arxiv.org/abs/2510.18923)
*Eduard Frankford,Tobias Antensteiner,Michael Vierhauser,Clemens Sauerwein,Vivien Wallner,Iris Groher,Reinhold Plösch,Ruth Breu*

Main category: cs.SE

TL;DR: 该研究比较了编程自动评估系统中不同反馈机制的效果，发现虽然学生认为单元测试反馈最有帮助，但AI生成的反馈能显著提高学生表现，建议结合两种方法优化编程教育。


<details>
  <summary>Details</summary>
Motivation: 随着编程课程需求的增加，需要可扩展的自动评估系统。传统基于单元测试的反馈存在局限性，而大型语言模型为提升反馈质量和个性化提供了新机会。

Method: 在两个大学对200多名学生进行大规模研究，比较编译器反馈、标准单元测试反馈和基于LLM的高级反馈在感知质量和学生表现方面的影响。

Result: 学生评价单元测试反馈最有帮助，但AI生成的反馈能带来显著更好的表现结果。

Conclusion: 建议结合单元测试和AI驱动的指导来优化自动反馈机制，改善编程教育的学习成果。

Abstract: With the recent rapid increase in digitization across all major industries,
acquiring programming skills has increased the demand for introductory
programming courses. This has further resulted in universities integrating
programming courses into a wide range of curricula, including not only
technical studies but also business and management fields of study.
  Consequently, additional resources are needed for teaching, grading, and
tutoring students with diverse educational backgrounds and skills. As part of
this, Automated Programming Assessment Systems (APASs) have emerged, providing
scalable and high-quality assessment systems with efficient evaluation and
instant feedback. Commonly, APASs heavily rely on predefined unit tests for
generating feedback, often limiting the scope and level of detail of feedback
that can be provided to students. With the rise of Large Language Models (LLMs)
in recent years, new opportunities have emerged as these technologies can
enhance feedback quality and personalization.
  To investigate how different feedback mechanisms in APASs are perceived by
students, and how effective they are in supporting problem-solving, we have
conducted a large-scale study with over 200 students from two different
universities. Specifically, we compare baseline Compiler Feedback, standard
Unit Test Feedback, and advanced LLM-based Feedback regarding perceived quality
and impact on student performance.
  Results indicate that while students rate unit test feedback as the most
helpful, AI-generated feedback leads to significantly better performances.
These findings suggest combining unit tests and AI-driven guidance to optimize
automated feedback mechanisms and improve learning outcomes in programming
education.

</details>


### [6] [Extending Resource Constrained Project Scheduling to Mega-Projects with Model-Based Systems Engineering & Hetero-functional Graph Theory](https://arxiv.org/abs/2510.19035)
*Amirreza Hosseini,Amro M. Farid*

Main category: cs.SE

TL;DR: 将资源受限项目调度问题与基于模型的系统工程相结合，构建从活动网络到SysML活动图再到操作数网络的转换管道，并证明RCPSP是更广泛模型的特殊情况。


<details>
  <summary>Details</summary>
Motivation: RCPSP作为项目管理核心问题，与基于模型的系统工程文献脱节，限制了其在复杂系统设计和管理中的集成应用。

Method: 构建从活动网络到SysML活动图再到操作数网络的转换管道，将异质功能网络最小成本流公式特化到RCPSP上下文。

Result: 在包含可再生和不可再生操作数的示例实例中，特化的HFNMCF产生相似调度，同时提供项目状态的显式解释，支持更丰富的监控和控制。

Conclusion: 该框架保留了经典RCPSP的优势，同时适应了大型复杂超大型项目中遇到的现实约束和企业级决策过程。

Abstract: Within the project management context, project scheduling serves as an
indispensable component, functioning as a fundamental tool for planning,
monitoring, controlling, and managing projects more broadly. Although the
resource-constrained project scheduling problem (RCPSP) lies at the core of
project management activities, it remains largely disconnected from the broader
literature on model-based systems engineering (MBSE), thereby limiting its
integration into the design and management of complex systems. The original
contribution of this paper is twofold. First, the paper seeks to reconcile the
RCPSP with the broader literature and vocabulary of model-based systems
engineering and hetero-functional graph theory (HFGT). A concrete translation
pipeline from an activity-on-node network to a SysML activity diagram, and then
to an operand net is constructed. Using this representation, it specializes the
hetero-functional network minimum-cost flow (HFNMCF) formulation to the RCPSP
context as a systematic means of HFGT for quantitative analysis and proves that
the RCPSP is recoverable as a special case of a broader model. Secondly, on an
illustrative instance with renewable and non-renewable operands, the
specialized HFNMCF, while producing similar schedules, yields explicit
explanations of the project states that enable richer monitoring and control.
Overall, the framework preserves the strengths of the classical RCPSP while
accommodating real-world constraints and enterprise-level decision processes
encountered in large, complex megaprojects.

</details>


### [7] [Docker-based CI/CD for Rocq/OCaml projects](https://arxiv.org/abs/2510.19089)
*Érik Martin-Dorel*

Main category: cs.SE

TL;DR: 本文介绍了三个密切相关的软件项目：docker-coq、docker-coq-action和docker-keeper，旨在促进基于Docker的Coq/OCaml项目CI/CD使用，并为未来维护者提供设计文档。


<details>
  <summary>Details</summary>
Motivation: 提供基于Docker的CI/CD解决方案，促进Coq（现名Rocq）和OCaml项目的开发效率，同时为工具的未来维护提供清晰的设计文档。

Method: 开发三个相互关联的DevOps工具：docker-coq（Docker镜像）、docker-coq-action（GitHub Action）和docker-keeper（自动化维护工具），采用Docker容器化技术实现CI/CD流程。

Result: 成功构建了一套完整的Docker-based CI/CD工具链，为Coq/OCaml项目提供了标准化的开发环境配置和自动化构建流程。

Conclusion: 这三个工具为Coq/OCaml社区提供了实用的DevOps解决方案，既满足了当前项目的CI/CD需求，也为未来的维护和扩展奠定了良好基础。

Abstract: This paper presents three closely-related software projects, namely:
docker-coq, docker-coq-action, and docker-keeper. It aims at two objectives:
provide a high-level description of the available features -- to foster the use
of a Docker-based CI/CD for Rocq (formerly known as Coq) or OCaml projects --
and document the underlying requirements and the main design choices of these
three DevOps tools -- to help their future maintainers.

</details>


### [8] [Automated Concern Extraction from Textual Requirements of Cyber-Physical Systems: A Multi-solution Study](https://arxiv.org/abs/2510.19237)
*Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Shengxin Zhao,Chuihui Wang,Hongbin Xiao*

Main category: cs.SE

TL;DR: 提出了ReqEBench基准测试，包含2,721个真实CPS需求，用于评估自动化需求关注点提取方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化需求关注点提取解决方案缺乏公平和全面的基准测试来评估其有效性。

Method: 构建包含12个真实世界CPS的2,721个需求的基准测试，经过严格标注过程，涵盖多个应用领域。

Result: 使用ReqEBench评估三种自动化解决方案，发现GPT-4在实体关注点提取中的最高F1分数仅为0.24。

Conclusion: ReqEBench将促进自动化需求关注点提取的评估和发展，分析失败案例为改进提供了思路。

Abstract: Cyber-physical systems (CPSs) are characterized by a deep integration of the
information space and the physical world, which makes the extraction of
requirements concerns more challenging. Some automated solutions for
requirements concern extraction have been proposed to alleviate the burden on
requirements engineers. However, evaluating the effectiveness of these
solutions, which relies on fair and comprehensive benchmarks, remains an open
question. To address this gap, we propose ReqEBench, a new CPSs requirements
concern extraction benchmark, which contains 2,721 requirements from 12
real-world CPSs. ReqEBench offers four advantages. It aligns with real-world
CPSs requirements in multiple dimensions, e.g., scale and complexity. It covers
comprehensive concerns related to CPSs requirements. It undergoes a rigorous
annotation process. It covers multiple application domains of CPSs, e.g.,
aerospace and healthcare. We conducted a comparative study on three types of
automated requirements concern extraction solutions and revealed their
performance in real-world CPSs using our ReqEBench. We found that the highest
F1 score of GPT-4 is only 0.24 in entity concern extraction. We further analyze
failure cases of popular LLM-based solutions, summarize their shortcomings, and
provide ideas for improving their capabilities. We believe ReqEBench will
facilitate the evaluation and development of automated requirements concern
extraction.

</details>


### [9] [A General Solution for the Implementation of CI/CD in Embedded Linux Development](https://arxiv.org/abs/2510.19240)
*Behnam Agahi,Hamed Farbeh*

Main category: cs.SE

TL;DR: 设计并实现了一个基于Yocto项目的集成式Linux操作系统开发基础设施，采用三层架构确保版本同步和可重现性，通过CI/CD流水线自动化构建测试流程，显著减少构建时间，验证了系统的功能稳定性。


<details>
  <summary>Details</summary>
Motivation: 随着嵌入式系统在各行业的广泛应用，需要自动化平台来开发和部署定制化的Linux操作系统，以提高开发效率和系统可靠性。

Method: 采用三层架构：Yocto主仓库、自定义层(meta-custom)和协调清单层；开发了三个示例项目并集成到构建流程；使用GitLab CI实现CI/CD流水线，结合Docker隔离环境；部署本地缓存服务器减少构建时间；通过QEMU模拟器进行六种启动测试场景验证。

Result: 提出的设计确保了可重现性，构建时间显著减少，系统功能稳定性得到验证，可扩展到实时Linux版本等高级应用的持续部署。

Conclusion: 该基础设施为嵌入式系统工业和研究项目提供了稳定、可扩展的模型，实现了快速可靠的开发周期，未来可扩展自动化测试、系统监控、分布式构建等优化功能。

Abstract: With the growing use of embedded systems in various industries, the need for
automated platforms for the development and deployment of customized
Linux-based operating systems has become more important. This research was
conducted with the aim of designing and implementing an integrated and
reproducible infrastructure for the development, building, and testing of a
Linux-based operating system using the Yocto Project. The proposed structure
was implemented based on a three-layer architecture consisting of the main
Yocto repositories, a custom layer (meta-custom), and a coordinating manifest
layer to ensure version synchronization, scalability, and reproducibility.
Three sample projects, including libhelloworld, helloworld, and the kernel
module hello mod, were developed and integrated into the build process.
Continuous Integration and Continuous Deployment pipelines were implemented
with GitLab CI and combined with an isolated Docker environment to automate and
streamline the build and testing workflows. Using a local cache server
containing hashserv, downloads and sstate cache significantly reduced the build
time. The functionality and stability of the system were verified through six
boot test scenarios in the QEMU simulator. The results show that the proposed
design not only ensures reproducibility but also can be extended to advanced
applications such as continuous deployment of real-time Linux versions. Future
recommendations include expanding automated tests, implementing system
monitoring with Prometheus and Grafana, using distributed builds, optimizing
with Docker multi-stage builds, and enabling continuous deployment of real-time
Linux changes to provide a stable and scalable model for industrial and
research projects in embedded systems with a rapid and reliable development
cycle.

</details>


### [10] [Trace: Securing Smart Contract Repository Against Access Control Vulnerability](https://arxiv.org/abs/2510.19254)
*Chong Chen,Jiachi Chen,Lingfeng Bao,David Lo,Yanlin Wang,Zhenyu Shan,Ting Chen,Guangqiang Yin,Jianxing Yu,Zibin Zheng*

Main category: cs.SE

TL;DR: TRACE是一个用于检测不可编译智能合约仓库中访问控制漏洞的工具，它使用LLM定位敏感函数并补全为可编译合约，然后通过分析函数调用图和控制流图来检测漏洞。


<details>
  <summary>Details</summary>
Motivation: 智能合约中的访问控制漏洞已造成数十亿美元损失，现有工具无法有效处理复杂的不可编译仓库，因为需要可编译的合约才能进行分析。

Method: 使用LLM定位敏感函数，补全函数片段为可编译合约，构建AST函数调用图和CFG控制流图，分析敏感函数节点检测访问控制漏洞。

Result: 在开源CVE数据集中检测出15个中的14个漏洞，在5000个链上合约中达到89.2%准确率，在83个真实仓库中达到87.0%准确率，远超现有最佳工具。

Conclusion: TRACE能有效检测不可编译智能合约仓库中的访问控制漏洞，性能显著优于现有工具，为智能合约安全提供了重要保障。

Abstract: Smart contract vulnerabilities, particularly improper Access Control that
allows unauthorized execution of restricted functions, have caused billions of
dollars in losses. GitHub hosts numerous smart contract repositories containing
source code, documentation, and configuration files-these serve as intermediate
development artifacts that must be compiled and packaged before deployment.
Third-party developers often reference, reuse, or fork code from these
repositories during custom development. However, if the referenced code
contains vulnerabilities, it can introduce significant security risks. Existing
tools for detecting smart contract vulnerabilities are limited in their ability
to handle complex repositories, as they typically require the target contract
to be compilable to generate an abstract representation for further analysis.
This paper presents TRACE, a tool designed to secure non-compilable smart
contract repositories against access control vulnerabilities. TRACE employs
LLMs to locate sensitive functions involving critical operations (e.g.,
transfer) within the contract and subsequently completes function snippets into
a fully compilable contract. TRACE constructs a function call graph from the
abstract syntax tree (AST) of the completed contract. It uses the control flow
graph (CFG) of each function as node information. The nodes of the sensitive
functions are then analyzed to detect Access Control vulnerabilities.
Experimental results demonstrate that TRACE outperforms state-of-the-art tools
on an open-sourced CVE dataset, detecting 14 out of 15 CVEs. In addition, it
achieves 89.2% precision on 5,000 recent on-chain contracts, far exceeding the
best existing tool at 76.9%. On 83 real-world repositories, TRACE achieves
87.0% precision, significantly surpassing DeepSeek-R1's 14.3%.

</details>


### [11] [From Specification to Service: Accelerating API-First Development Using Multi-Agent Systems](https://arxiv.org/abs/2510.19274)
*Saurabh Chauhan,Zeeshan Rasheed,Malik Abdul Sami,Kai-Kristian Kemell,Muhammad Waseem,Zheying Zhang,Jussi Rasku,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 使用基于LLM的代理系统自动化RESTful微服务的API优先开发，通过OpenAPI规范生成代码并利用日志分析反馈循环优化代码质量。


<details>
  <summary>Details</summary>
Motivation: 推进API优先开发的自动化，测试基于LLM的多代理系统在支持API优先开发方法中的能力。

Method: 利用LLM代理创建OpenAPI规范，从中生成服务器代码，并通过分析执行日志和错误消息的反馈循环来优化代码。

Result: 在PRAB基准测试中，当保持OpenAPI规范小而专注时，LLM能够生成符合规范的完整功能代码和业务逻辑。

Conclusion: 基于LLM的多代理系统可以有效支持API优先开发，通过集成日志分析能够高效检测和解决问题，减少迭代次数，生成功能强大且稳健的服务。

Abstract: This paper presents a system that uses Large Language Models (LLMs)-based
agents to automate the API-first development of RESTful microservices. This
system helps to create an OpenAPI specification, generate server code from it,
and refine the code through a feedback loop that analyzes execution logs and
error messages. The integration of log analysis enables the LLM to detect and
address issues efficiently, reducing the number of iterations required to
produce functional and robust services. This study's main goal is to advance
API-first development automation for RESTful web services and test the
capability of LLM-based multi-agent systems in supporting the API-first
development approach. To test the proposed system's potential, we utilized the
PRAB benchmark. The results indicate that if we keep the OpenAPI specification
small and focused, LLMs are capable of generating complete functional code with
business logic that aligns to the specification. The code for the system is
publicly available at https://github.com/sirbh/code-gen

</details>


### [12] [Bytecode-centric Detection of Known-to-be-vulnerable Dependencies in Java Projects](https://arxiv.org/abs/2510.19393)
*Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Jonas Klauke,Eric Bodden*

Main category: cs.SE

TL;DR: Jaralyzer是一个基于字节码分析的Java依赖扫描器，能够有效检测修改后的开源依赖中的安全漏洞，在检测性能上优于现有扫描器。


<details>
  <summary>Details</summary>
Motivation: 现代Java项目中71%的代码来自开源依赖，这带来了严重的安全风险。现有依赖扫描器在处理依赖修改（如重新编译、重新打包）时存在不足，无法有效检测漏洞。

Method: Jaralyzer不依赖元数据或源代码，直接分析依赖的字节码来检测已知安全漏洞。

Result: 在56个流行OSS组件的评估中，Jaralyzer在检测修改依赖中的漏洞方面优于其他扫描器，是唯一能识别所有类型修改依赖中漏洞的扫描器。即使对于未修改依赖，也比当前最先进的Eclipse Steady多检测28个真实漏洞，减少29个误报。

Conclusion: Jaralyzer通过字节码分析的方法，有效解决了现有依赖扫描器在处理修改依赖时的局限性，显著提升了漏洞检测能力。

Abstract: On average, 71% of the code in typical Java projects comes from open-source
software (OSS) dependencies, making OSS dependencies the dominant component of
modern software code bases. This high degree of OSS reliance comes with a
considerable security risk of adding known security vulnerabilities to a code
base. To remedy this risk, researchers and companies have developed various
dependency scanners, which try to identify inclusions of known-to-be-vulnerable
OSS dependencies. However, there are still challenges that modern dependency
scanners do not overcome, especially when it comes to dependency modifications,
such as re-compilations, re-bundlings or re-packagings, which are common in the
Java ecosystem. To overcome these challenges, we present Jaralyzer, a
bytecode-centric dependency scanner for Java. Jaralyzer does not rely on the
metadata or the source code of the included OSS dependencies being available
but directly analyzes a dependency's bytecode. Our evaluation across 56 popular
OSS components demonstrates that Jaralyzer outperforms other popular dependency
scanners in detecting vulnerabilities within modified dependencies. It is the
only scanner capable of identifying vulnerabilities across all the above
mentioned types of modifications. But even when applied to unmodified
dependencies, Jaralyzer outperforms the current state-of-the-art code-centric
scanner Eclipse Steady by detecting 28 more true vulnerabilities and yielding
29 fewer false warnings.

</details>


### [13] [AutoMT: A Multi-Agent LLM Framework for Automated Metamorphic Testing of Autonomous Driving Systems](https://arxiv.org/abs/2510.19438)
*Linfeng Liang,Chenkai Tan,Yao Deng,Yingfeng Cai,T. Y Chen,Xi Zheng*

Main category: cs.SE

TL;DR: AutoMT是一个基于大语言模型的多智能体蜕变测试框架，用于自动驾驶系统的自动化测试。它从交通规则中自动提取蜕变关系并生成有效的后续测试用例，相比手动方法实现了更高的测试多样性和错误检测率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统是安全关键系统，故障可能造成严重后果。现有的蜕变测试方法依赖大量人工工作且缺乏自动化，需要更高效的自动化测试解决方案。

Method: AutoMT使用LLM从Gherkin语法的交通规则中提取蜕变关系，通过视觉语言智能体分析场景，搜索智能体从RAG数据库中检索合适的蜕变关系，利用计算机视觉生成后续测试用例。

Result: 实验显示AutoMT在后续用例生成中达到比最佳基线（手动专家定义的蜕变关系）高5倍的测试多样性，检测到20.55%更多的行为违规。

Conclusion: AutoMT自动提取多样化的蜕变关系，补充真实世界数据集，发现现场测试和数据收集中常被遗漏的边界情况。其模块化架构支持工业流水线集成，可能实现基于仿真的测试来系统覆盖代表性不足或安全关键场景。

Abstract: Autonomous Driving Systems (ADS) are safety-critical, where failures can be
severe. While Metamorphic Testing (MT) is effective for fault detection in ADS,
existing methods rely heavily on manual effort and lack automation. We present
AutoMT, a multi-agent MT framework powered by Large Language Models (LLMs) that
automates the extraction of Metamorphic Relations (MRs) from local traffic
rules and the generation of valid follow-up test cases. AutoMT leverages LLMs
to extract MRs from traffic rules in Gherkin syntax using a predefined
ontology. A vision-language agent analyzes scenarios, and a search agent
retrieves suitable MRs from a RAG-based database to generate follow-up cases
via computer vision. Experiments show that AutoMT achieves up to 5 x higher
test diversity in follow-up case generation compared to the best baseline
(manual expert-defined MRs) in terms of validation rate, and detects up to
20.55% more behavioral violations. While manual MT relies on a fixed set of
predefined rules, AutoMT automatically extracts diverse metamorphic relations
that augment real-world datasets and help uncover corner cases often missed
during in-field testing and data collection. Its modular architecture
separating MR extraction, filtering, and test generation supports integration
into industrial pipelines and potentially enables simulation-based testing to
systematically cover underrepresented or safety-critical scenarios.

</details>


### [14] [Mapping and Evolving Interoperability Testing in European Energy Systems: The int:net Perspective](https://arxiv.org/abs/2510.19460)
*Thomas I. Strasser,Edmund Widl,Carlos Ayon Mac Gregor,Mirko Ginocchi,Rene Kuchenbuch*

Main category: cs.SE

TL;DR: 本文分析了欧洲30个互操作性测试设施，提供了测试基础设施、方法和参考测试案例的分类清单，并为未来测试环境开发提出了蓝图。


<details>
  <summary>Details</summary>
Motivation: 欧洲能源转型需要高度互操作性，但目前缺乏专门的互操作性测试基础设施和协调的测试能力概述。

Method: 通过对30个欧洲测试设施进行结构化调查，分析测试基础设施、应用方法和参考测试案例。

Result: 建立了欧洲互操作性测试设施的分类清单，识别了现有测试能力，并提出了未来测试环境开发的蓝图。

Conclusion: 这项工作有助于建立协调的欧洲互操作性测试生态系统，支持合作、创新和能源转型目标的实现。

Abstract: The ongoing transformation of the European energy landscape, driven by the
integration of renewable energy sources, digital technologies, and
decentralized systems, requires a high degree of interoperability across
diverse components and systems. Ensuring that these elements can exchange
information and operate together reliably is essential for achieving a secure,
flexible, and efficient energy supply infrastructure. While several initiatives
have contributed to the development of smart grid testing infrastructures, they
do not provide a dedicated or comprehensive focus on interoperability testing.
A structured and harmonized overview of interoperability testing capabilities
across Europe is therefore still missing. This work therefore presents a novel
contribution by analyzing the European interoperability testing facility
landscape through a structured survey of 30 facilities. It provides a
categorized inventory of testing infrastructures, applied methodologies, and
reference test cases, and introduces a blueprint for the development of future
testing environments. The findings contribute to the establishment of a
coordinated European ecosystem for interoperability testing, supporting
collaboration, innovation, and alignment with the goals of the energy
transition.

</details>


### [15] [A Goal-Driven Survey on Root Cause Analysis](https://arxiv.org/abs/2510.19593)
*Aoyang Fang,Haowen Yang,Haoze Dong,Qisheng Lu,Junjielong Xu,Pinjia He*

Main category: cs.SE

TL;DR: 本文提出了一个基于目标驱动的框架，对2014-2025年间云事故管理中的135篇根因分析论文进行分类和整合，强调按研究目标而非数据类型进行分类的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有根因分析调查通常按数据类型分类，忽略了不同研究目标的根本差异，导致目标不同的研究被混为一谈，难以反映领域真实进展和差距。

Method: 提出了一个目标驱动的框架，根据研究的不同目标对根因分析论文进行分类和整合，涵盖从故障服务定位到具体功能bug识别的不同任务目标。

Result: 成功整合了135篇根因分析论文，建立了基于目标分类的新框架，并讨论了根因分析的终极目标作为不同表述的统一覆盖。

Conclusion: 基于目标的分类方法能更清晰地展示根因分析领域的进展和挑战，为研究者和实践者提供了更有价值的指导框架。

Abstract: Root Cause Analysis (RCA) is a crucial aspect of incident management in
large-scale cloud services. While the term root cause analysis or RCA has been
widely used, different studies formulate the task differently. This is because
the term "RCA" implicitly covers tasks with distinct underlying goals. For
instance, the goal of localizing a faulty service for rapid triage is
fundamentally different from identifying a specific functional bug for a
definitive fix. However, previous surveys have largely overlooked these
goal-based distinctions, conventionally categorizing papers by input data types
(e.g., metric-based vs. trace-based methods). This leads to the grouping of
works with disparate objectives, thereby obscuring the true progress and gaps
in the field. Meanwhile, the typical audience of an RCA survey is either laymen
who want to know the goals and big picture of the task or RCA researchers who
want to figure out past research under the same task formulation. Thus, an RCA
survey that organizes the related papers according to their goals is in high
demand. To this end, this paper presents a goal-driven framework that
effectively categorizes and integrates 135 papers on RCA in the context of
cloud incident management based on their diverse goals, spanning the period
from 2014 to 2025. In addition to the goal-driven categorization, it discusses
the ultimate goal of all RCA papers as an umbrella covering different RCA
formulations. Moreover, the paper discusses open challenges and future
directions in RCA.

</details>


### [16] [Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1](https://arxiv.org/abs/2510.19600)
*Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang*

Main category: cs.SE

TL;DR: AutoPage是一个多智能体系统，能够自动将研究论文转化为交互式项目网页，通过分层协作流程在15分钟内以低于0.1美元的成本生成高质量页面。


<details>
  <summary>Details</summary>
Motivation: 研究人员在构建项目网页时面临手动、重复性的工作负担，而现有的自动化工具无法处理网页的动态交互特性。

Method: 采用多智能体系统，将论文到网页的创建过程分解为从叙事规划到多模态内容生成和交互式渲染的粗到细管道，并引入专门的"检查器"智能体来对抗AI幻觉。

Result: AutoPage不仅生成了高质量、视觉吸引力强的网页，而且效率极高，在15分钟内以低于0.1美元的成本完成。

Conclusion: AutoPage将系统从单纯工具转变为强大的协作助手，通过分层协作方法成功解决了论文到网页自动化的挑战。

Abstract: In the quest for scientific progress, communicating research is as vital as
the discovery itself. Yet, researchers are often sidetracked by the manual,
repetitive chore of building project webpages to make their dense papers
accessible. While automation has tackled static slides and posters, the
dynamic, interactive nature of webpages has remained an unaddressed challenge.
To bridge this gap, we reframe the problem, arguing that the solution lies not
in a single command, but in a collaborative, hierarchical process. We introduce
$\textbf{AutoPage}$, a novel multi-agent system that embodies this philosophy.
AutoPage deconstructs paper-to-page creation into a coarse-to-fine pipeline
from narrative planning to multimodal content generation and interactive
rendering. To combat AI hallucination, dedicated "Checker" agents verify each
step against the source paper, while optional human checkpoints ensure the
final product aligns perfectly with the author's vision, transforming the
system from a mere tool into a powerful collaborative assistant. To rigorously
validate our approach, we also construct $\textbf{PageBench}$, the first
benchmark for this new task. Experiments show AutoPage not only generates
high-quality, visually appealing pages but does so with remarkable efficiency
in under 15 minutes for less than \$0.1. Code and dataset will be released at
$\href{https://mqleet.github.io/AutoPage_ProjectPage/}{Webpage}$.

</details>


### [17] [FidelityGPT: Correcting Decompilation Distortions with Retrieval Augmented Generation](https://arxiv.org/abs/2510.19615)
*Zhiping Zhou,Xiaohong Li,Ruitao Feng,Yao Zhang,Yuekang Li,Wenbu Feng,Yunqian Wang,Yuqing Li*

Main category: cs.SE

TL;DR: FidelityGPT是一个提升反编译代码准确性和可读性的框架，通过系统检测和修正语义失真，在闭源二进制文件上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有反编译方法存在保真度问题，导致反编译输出的可读性和语义准确性下降，特别是在复杂闭源二进制文件上缺乏鲁棒的检测和修正机制。

Method: 引入失真感知提示模板，结合检索增强生成(RAG)和动态语义强度算法定位失真代码行，使用变量依赖算法分析冗余变量并集成依赖关系到提示上下文中。

Result: 在620个函数对上的评估显示，检测准确率89%，精确率83%。相比DeGPT(修复率83%，正确修复率37%)，FidelityGPT达到94%修复率和64%正确修复率。

Conclusion: FidelityGPT在准确性和可读性方面取得显著提升，展示了其在基于LLM的反编译和逆向工程中的潜力。

Abstract: Decompilation converts machine code into human-readable form, enabling
analysis and debugging without source code. However, fidelity issues often
degrade the readability and semantic accuracy of decompiled output. Existing
methods, such as variable renaming or structural simplification, provide
partial improvements but lack robust detection and correction, particularly for
complex closed-source binaries. We present FidelityGPT, a framework that
enhances decompiled code accuracy and readability by systematically detecting
and correcting semantic distortions. FidelityGPT introduces distortion-aware
prompt templates tailored to closed-source settings and integrates
Retrieval-Augmented Generation (RAG) with a dynamic semantic intensity
algorithm to locate distorted lines and retrieve semantically similar code from
a database. A variable dependency algorithm further mitigates long-context
limitations by analyzing redundant variables and integrating their dependencies
into the prompt context. Evaluated on 620 function pairs from a binary
similarity benchmark, FidelityGPT achieved an average detection accuracy of 89%
and a precision of 83%. Compared to the state-of-the-art DeGPT (Fix Rate 83%,
Corrected Fix Rate 37%), FidelityGPT attained 94% FR and 64% CFR, demonstrating
significant gains in accuracy and readability. These results highlight its
potential to advance LLM-based decompilation and reverse engineering.

</details>


### [18] [Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary](https://arxiv.org/abs/2510.19692)
*Rashina Hoda*

Main category: cs.SE

TL;DR: 本文提出了扩展智能体软件工程（agentic SE）研究范围的建议，从仅关注代码活动转向涵盖整个软件开发过程的愿景，并提出了指导原则和词汇设计指南。


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI在软件工程中引发范式转变，需要建立智能体软件工程作为研究领域，并考虑实际应用中的社会技术问题。

Method: 通过分析软件工程基础、演进和新兴的智能体SE框架，提出扩展研究范围的建议、初步的价值观和原则，以及词汇设计指南。

Result: 提出了'全过程'愿景，强调超越代码的智能体SE范围，建立了指导原则和词汇标准，为社区协作奠定基础。

Conclusion: 这些建议旨在引导软件工程社区为智能体SE建立坚实基础，使其不仅是必然趋势，而且是经过深思熟虑和长期可取的。

Abstract: Agentic AI is poised to usher in a seismic paradigm shift in Software
Engineering (SE). As technologists rush head-along to make agentic AI a
reality, SE researchers are driven to establish agentic SE as a research area.
While early visions of agentic SE are primarily focused on code-related
activities, early empirical evidence calls for a consideration of a range of
socio-technical concerns to make it work in practice. This paper contributes to
the emerging community vision by: (a) recommending an expansion of its scope
beyond code, toward a 'whole of process' vision, grounding it in SE foundations
and evolution and emerging agentic SE frameworks, (b) proposing a preliminary
set of values and principles to guide efforts, and (c) sharing guidance on
designing/using well-defined vocabulary for agentic SE. It is hoped that these
ideas will encourage community collaborations and steer the SE community
towards laying strong foundations of agentic SE so its not only inevitable but
also deliberate and desirable in the long run.

</details>


### [19] [Review of Tools for Zero-Code LLM Based Application Development](https://arxiv.org/abs/2510.19747)
*Priyaranjan Pattnayak,Hussain Bohra*

Main category: cs.SE

TL;DR: 本调查综述了基于大语言模型的零代码开发平台，分析了专用LLM应用构建器和集成LLM功能的通用无代码平台，提出了按界面风格、后端集成、输出类型和可扩展性等维度的分类法，并讨论了与传统的低代码开发方法的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型改变软件创建方式，零代码开发平台让用户无需编写代码即可构建应用程序。调查旨在系统分析这些平台如何利用LLM作为开发过程的核心，降低AI应用开发门槛。

Method: 采用广泛的调查方法，基于界面风格、后端集成、输出类型和可扩展性等关键维度对平台进行分类。分析了专用LLM应用构建器（如OpenAI的定制GPT、Bolt.new等）和集成LLM功能的通用无代码平台（如Bubble、Glide）。

Result: 提出了一个分类法，按界面（对话式、可视化等）、支持的LLM后端、输出类型（聊天机器人、完整应用、工作流）和可扩展性程度对平台进行分类。详细比较了各平台的优势和局限性，讨论了与传统和低代码开发方法在可定制性、可扩展性、供应商锁定等方面的权衡。

Conclusion: 基于LLM的零代码平台显著降低了创建AI驱动应用程序的门槛，但在灵活性和可靠性方面仍面临挑战。该领域正在快速发展，为非程序员创建复杂软件提供了令人兴奋的机会，未来方向包括多模态界面、设备端LLM和改进的编排技术。

Abstract: Large Language Models (LLMs) are transforming software creation by enabling
zero code development platforms. Our survey reviews recent platforms that let
users build applications without writing code, by leveraging LLMs as the brains
of the development process. We adopt a broad survey methodology, categorizing
platforms based on key dimensions such as interface style, backend integration,
output type, and extensibility. We analyze both dedicated LLM based app
builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and
general no code platforms (e.g., Bubble, Glide) that integrate LLM
capabilities. We present a taxonomy categorizing these platforms by their
interface (conversational, visual, etc.), supported LLM backends, output type
(chatbot, full application, workflow), and degree of extensibility. Core
features such as autonomous agents, memory management, workflow orchestration,
and API integrations are in scope of the survey. We provide a detailed
comparison, highlighting each platform's strengths and limitations. Trade offs
(customizability, scalability, vendor lock-in) are discussed in comparison with
traditional and low code development approaches. Finally, we outline future
directions, including multimodal interfaces, on device LLMs, and improved
orchestration for democratizing app creation with AI. Our findings indicate
that while zero code LLM platforms greatly reduce the barrier to creating AI
powered applications, they still face challenges in flexibility and
reliability. Overall, the landscape is rapidly evolving, offering exciting
opportunities to empower non programmers to create sophisticated software.

</details>


### [20] [BOSQTGEN: Breaking the Sound Barrier in Test Generation](https://arxiv.org/abs/2510.19777)
*S M Sadrul Islam Asif,James Chen,Earl T. Barr,Mark Marron*

Main category: cs.SE

TL;DR: BOSQTGEN是一个新颖的黑盒API测试生成方法，通过分解API规范为原语、使用LLM建议连贯分层、组合测试采样，显著提升代码覆盖率


<details>
  <summary>Details</summary>
Motivation: 现代软件越来越多地通过组合API构建，但API契约不足会导致期望不匹配和故障。现有测试生成技术面临多语言系统、源代码不可访问、成本可靠性权衡以及生成结构化输入困难等挑战

Method: 将API规范分解为原语，使用LLM建议连贯的分层，采用组合测试在这些值上进行高效采样，覆盖关键交互同时避免随机采样的冗余

Result: 在RESTful基准测试中平均达到82%的代码覆盖率，通常比先前最先进系统提高20%或更多，接近手工编写测试套件的水平

Conclusion: BOSQTGEN提供完全API驱动的测试生成方法，使开发人员能够自动创建高质量测试用例进行验证或测试驱动开发

Abstract: Modern software is increasingly built by composing APIs, elevating the API
contract to a critical role. Inadequate contracts, however, lead to mismatched
expectations and failures, creating a pressing need for robust conformance
testing. Current test generation techniques are hindered by key challenges:
polyglot systems, source code inaccessibility, a cost-reliability trade-off,
and, most critically, the difficulty of generating structured inputs.
  We introduce BOSQTGEN, a novel black-box methodology and tool for API test
generation. BOSQTGEN utilizes a novel approach for decomposing API
specifications into primitives, using LLMs to suggest coherent strata for them,
and employing combinatorial testing to efficiently sample over these values.
This approach ensures coverage of critical interactions while avoiding the
redundancy of random sampling.
  The resulting BOSQTGEN system achieves an average of 82% code coverage on
RESTful benchmarks, often a 20% or more increase over prior state-of-the-art
systems and nearing parity with hand-written test suites. Providing a fully
API-driven approach to test generation, enables developers to automatically
create high-quality test cases for validation or test-driven development.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [21] [Dependent Session Types for Verified Concurrent Programming](https://arxiv.org/abs/2510.19129)
*Qiancheng Fu,Hongwei Xi,Ankush Das*

Main category: cs.PL

TL;DR: TLLC扩展了TLL类型系统，添加了基于会话的并发支持，通过依赖会话类型实现并发程序的验证，能够将顺序程序的正确性证明提升到对应的并发实现。


<details>
  <summary>Details</summary>
Motivation: 将依赖类型与会话类型结合，使协议能够指定通信消息的属性，支持关系验证，将顺序程序的正确性证明扩展到并发实现。

Method: 开发了直觉主义会话类型的新表述，扩展TLL类型系统支持会话类型，实现原型编译器将TLLC程序翻译为并发C代码。

Result: 证明了语言的元理论，包括项演算和进程演算的可靠性，实现了队列和map-reduce等数据结构和并发算法的验证。

Conclusion: TLLC使会话类型成为验证数据结构和并发算法正确性的强大工具，其会话类型表述具有广泛适用性。

Abstract: We present TLLC which extends the Two-Level Linear dependent type theory
(TLL) with session-based concurrency. Equipped with Martin-L\"{o}f style
dependency, the session types of TLLC allow protocols to specify properties of
communicated messages. When used in conjunction with the dependent type
machinery already present in TLL, dependent session types facilitate a form of
relational verification by relating concurrent programs with their idealized
sequential counterparts. Correctness properties proven for sequential programs
can be easily lifted to their corresponding concurrent implementations. TLLC
makes session types a powerful tool for intrinsically verifying the correctness
of data structures such as queues and concurrent algorithms such as map-reduce.
To extend TLL with session types, we develop a novel formulation of
intuitionistic session type which we believe to be widely applicable for
integrating session types into other type systems beyond the context of TLLC.
We study the meta-theory of our language, proving its soundness as both a term
calculus and a process calculus. To demonstrate the practicality of TLLC, we
have implemented a prototype compiler that translates TLLC programs into
concurrent C code, which has been extensively evaluated.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [22] [Knowledge and Common Knowledge of Strategies](https://arxiv.org/abs/2510.19298)
*Borja Sierra Miranda,Thomas Studer*

Main category: cs.LO

TL;DR: 提出了一种细粒度的策略知识模型，区分一阶、高阶和共同知识，研究其对游戏Hanabi和共识问题的影响，并分析模型检测问题的可判定性。


<details>
  <summary>Details</summary>
Motivation: 现有战略推理工作通常采用知情或不知情语义，缺乏对策略知识的细粒度区分，需要更精确的模型来刻画不同层次的知识。

Method: 提出新的策略知识模型，能够区分一阶知识、高阶知识和共同知识，通过Hanabi游戏和共识问题来验证模型效果。

Result: 展示了高阶策略知识在Hanabi游戏中的影响，证明了共同知识对解决共识问题的必要性。

Conclusion: 细粒度的策略知识模型能够更精确地描述战略推理，共同知识在解决分布式问题中具有关键作用，模型检测问题具有可判定性。

Abstract: Most existing work on strategic reasoning simply adopts either an informed or
an uninformed semantics. We propose a model where knowledge of strategies can
be specified on a fine-grained level. In particular, it is possible to
distinguish first-order, higher-order, and common knowledge of strategies. We
illustrate the effect of higher-order knowledge of strategies by studying the
game Hanabi. Further, we show that common knowledge of strategies is necessary
to solve the consensus problem. Finally, we study the decidability of the model
checking problem.

</details>


### [23] [Universal Quantitative Abstraction: Categorical Duality and Logical Completeness for Probabilistic Systems](https://arxiv.org/abs/2510.19444)
*Nivar Anwer*

Main category: cs.LO

TL;DR: 提出了一个统一的概率系统定量抽象理论，连接了范畴论、最优传输和定量模态逻辑，建立了抽象与实现之间的范畴对偶关系。


<details>
  <summary>Details</summary>
Motivation: 为概率系统提供一个统一的定量抽象框架，将范畴论、最优传输和定量模态逻辑联系起来，解决状态聚合和表示学习中的价值函数近似问题。

Method: 构建了具有通用性质的ε-商结构，建立了抽象与实现函子之间的伴随关系，引入了定量模态μ-演算，并在余代数设置中证明了收缩性和Lipschitz性质。

Result: 行为伪度量被表征为Bellman风格算子的唯一不动点，定量模态μ-演算在逻辑可表示系统中具有表达完备性，行为距离与最大逻辑偏差一致。

Conclusion: 该框架为状态聚合和表示学习提供了原则性目标，在随机领域中为价值函数近似提供了数学精确的保证，具有鲁棒性和计算可行性。

Abstract: A unified theory of quantitative abstraction is presented for probabilistic
systems that links category theory, optimal transport, and quantitative modal
logic. At its core is a canonical $ \varepsilon $-quotient endowed with a
universal property: among all $ \varepsilon $-abstractions, it is the most
informative one that respects a prescribed bound on value loss. This
construction induces an adjunction between abstraction and realization functors
$ (Q_{\varepsilon} \dashv R_{\varepsilon}) $, established via the Special
Adjoint Functor Theorem, revealing a categorical duality between metric
structure and logical semantics. A behavioral pseudometric is characterized as
the unique fixed point of a Bellman-style operator, with contraction and
Lipschitz properties proved in a coalgebraic setting. A quantitative modal $
\mu $-calculus is introduced and shown to be expressively complete for
logically representable systems, so that behavioral distance coincides with
maximal logical deviation. Compositionality under interface refinement is
analyzed, clarifying how abstractions interact across system boundaries. An
exact validation suite on finite Markov decision processes corroborates the
contraction property, value-loss bounds, stability under perturbation,
adversarial distinguishability, and scalability, demonstrating both robustness
and computational feasibility. The resulting framework provides principled
targets for state aggregation and representation learning, with mathematically
precise guarantees for value-function approximation in stochastic domains.

</details>
