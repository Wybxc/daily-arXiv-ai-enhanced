<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.FL](#cs.FL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 21]
- [cs.LO](#cs.LO) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [DeliverC: Teaching Pointers through GenAI-Powered Game-Based Learning](https://arxiv.org/abs/2509.14496)
*Wyatt Petula,Anushcka Joshi,Peggy Tu,Amrutha Somasundar,Suman Saha*

Main category: cs.PL

TL;DR: DeliverC是一个集成GPT-4-mini的GenAI增强游戏，为C语言指针学习提供实时个性化提示和挑战生成。试点研究表明能提升学生自信和反思能力，但AI反馈质量仍需改进。


<details>
  <summary>Details</summary>
Motivation: 解决编程教育中复杂主题（如C指针）缺乏实时自适应支持工具的问题，探索GenAI与游戏化学习结合在传统挑战性编程领域的潜力。

Method: 开发DeliverC游戏系统，集成GPT-4-mini提供个性化提示和动态生成指针相关挑战。通过25名本科生的试点研究，收集游戏数据和15项问卷调查（涵盖动机、自我效能、元认知和反馈质量等维度）。

Result: 大多数学生使用后感到更自信和善于反思，错误率随着支架式关卡进展而下降。但参与度随任务难度增加而降低，部分学生反馈AI生成的提示不够清晰明确。

Conclusion: DeliverC能够增强系统编程学习的参与度和理解，但需要进一步改进AI生成反馈的质量。研究证明了GenAI与游戏化学习结合在支持个性化交互式编程实践方面的潜力。

Abstract: While game-based learning is widely used in programming education, few tools
offer adaptive, real-time support for complex topics, such as C pointers. We
present DeliverC, a GenAI-enhanced game that integrates GPT-4-mini to provide
personalized hints and generate pointer-related challenges on the fly. In a
pilot study involving 25 undergraduate students, we investigated the impact of
the system on learning through gameplay data and a 15-item survey that covered
constructs such as motivation, self-efficacy, metacognition, and feedback
quality. Results show that most students felt more confident and reflective
after using the tool, and error rates decreased as students progressed through
scaffolded levels. However, participation decreased with task difficulty, and
some students reported receiving unclear or vague feedback. These findings
suggest that DeliverC can enhance engagement and understanding in systems
programming, although refinement in AI-generated feedback is still needed. Our
study highlights the potential of combining GenAI with game-based learning to
support personalized and interactive practice in traditionally challenging
programming domains.

</details>


### [2] [Refinement-Types Driven Development: A study](https://arxiv.org/abs/2509.15005)
*Facundo Domínguez,Arnaud Spiwack*

Main category: cs.PL

TL;DR: 本文主张将SMT求解器更广泛地应用于日常编程，通过精化类型（如Liquid Haskell）将SMT求解器集成到编译器静态检查中，提升普通类型检查器的程序组合能力。


<details>
  <summary>Details</summary>
Motivation: 挑战SMT求解器仅用于形式化方法和验证的传统观念，探索其在日常编程任务中的应用潜力，使普通编程更简单、更愉快。

Method: 采用精化类型（Liquid Haskell体现），将SMT求解器无缝集成到编译器静态检查中，并通过处理编译器中的绑定器作用域案例研究进行验证。

Result: 展示了精化类型和SMT求解器在日常编程中的实际应用价值，并开发了Liquid Haskell求解器的有限映射理论原型实现来支持案例研究。

Conclusion: 精化类型和SMT求解器的结合为日常编程提供了新的可能性，有望改变编程实践，使普通编程任务更加简单和高效。

Abstract: This paper advocates for the broader application of SMT solvers in everyday
programming, challenging the conventional wisdom that these tools are solely
for formal methods and verification. We claim that SMT solvers, when seamlessly
integrated into a compiler's static checks, significantly enhance the
capabilities of ordinary type checkers in program composition. Specifically, we
argue that refinement types, as embodied by Liquid Haskell, enable the use of
SMT solvers in mundane programming tasks. Through a case study on handling
binder scopes in compilers, we envision a future where ordinary programming is
made simpler and more enjoyable with the aid of refinement types and SMT
solvers. As a secondary contribution, we present a prototype implementation of
a theory of finite maps for Liquid Haskell's solver, developed to support our
case study.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [3] [On the Complexity of the Secret Protection Problem for Discrete-Event Systems](https://arxiv.org/abs/2509.14372)
*Tomáš Masopust,Jakub Večeřa*

Main category: cs.FL

TL;DR: 本文证明了均匀秘密保护问题的NP难性，提出了基于整数线性规划的解决方案，并分析了变体问题的计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决先前工作中关于均匀秘密保护问题复杂性的开放性问题，并探索有效的解决方案。

Method: 通过理论证明NP难性，提出基于整数线性规划(ILP)的求解方法，并进行实证评估。

Result: 证明了均匀秘密保护问题即使在二元参数限制下也是NP难的，ILP方法在大规模系统上表现出良好的可扩展性和有效性。

Conclusion: 秘密保护问题在一般条件下具有较高的计算复杂性，但ILP方法提供了实用的解决方案，同时揭示了变体问题的更高复杂性等级。

Abstract: The secret protection problem (SPP) seeks to synthesize a minimum-cost policy
ensuring that every execution from an initial state to a secret state includes
a sufficient number of protected events. Previous work showed that the problem
is solvable in polynomial time under the assumptions that transitions are
uniquely labeled and that the clearance level for every event is uniformly set
to one. When these assumptions are relaxed, the problem was shown to be weakly
NP-hard, leaving the complexity of the uniform variant open. In this paper, we
close this gap by proving that the uniform secret protection problem is
NP-hard, even if all parameters are restricted to binary values. Moreover, we
strengthen the existing results by showing that the general problem becomes
NP-hard as soon as the uniqueness constraint on event labels is removed. We
further propose a formulation of SPP as an Integer Linear Programming (ILP)
problem. Our empirical evaluation demonstrates the scalability and
effectiveness of the ILP-based approach on relatively large systems. Finally,
we examine a variant of SPP in which only distinct protected events contribute
to clearance and show that its decision version is $\Sigma_{2}^{P}$-complete.

</details>


### [4] [Active Learning of Symbolic Mealy Automata](https://arxiv.org/abs/2509.14694)
*Kengo Irie,Masaki Waga,Kohei Suenaga*

Main category: cs.FL

TL;DR: 提出Λ*_M算法，一种学习支持无限输入字母表和多输出字符的符号Mealy自动机的主动学习方法，通过引入必要输入字符概念解决输出函数学习挑战


<details>
  <summary>Details</summary>
Motivation: 现有的研究工作分别解决了无限输入字母表和多输出字符的问题，但将这两个特征结合起来时，在状态级别学习输出函数面临挑战，需要新的方法来处理潜在的无限输入字符集

Method: 引入必要输入字符的概念，这是一个有限的输入字符集，足以学习符号Mealy自动机的输出函数。Λ*_M算法维护必要输入字符的下近似并在学习过程中不断优化这个集合

Result: 证明了Λ*_M在特定假设下会终止，提供了查询复杂度的上下界，其相似性表明界限的紧致性。实证研究表明该算法在实际基准测试中查询效率高，在随机生成基准测试中具有良好可扩展性

Conclusion: Λ*_M算法成功解决了学习支持无限输入字母表和多输出字符的符号Mealy自动机的挑战，通过必要输入字符的概念实现了高效和可扩展的学习

Abstract: We propose $\Lambda^*_M$-an active learning algorithm that learns symbolic
Mealy automata, which support infinite input alphabets and multiple output
characters. Each of these two features has been addressed separately in prior
work. Combining these two features poses a challenge in learning the outputs
corresponding to potentially infinite sets of input characters at each state.
To address this challenge, we introduce the notion of essential input
characters, a finite set of input characters that is sufficient for learning
the output function of a symbolic Mealy automaton. $\Lambda^*_M$ maintains an
underapproximation of the essential input characters and refines this set
during learning. We prove that $\Lambda^*_M$ terminates under certain
assumptions. Moreover, we provide upper and lower bounds for the query
complexity. Their similarity suggests the tightness of the bounds. We
empirically demonstrate that $\Lambda^*_M$ is i) efficient regarding the number
of queries on practical benchmarks and ii) scalable according to evaluations
with randomly generated benchmarks.

</details>


### [5] [Characterization of deterministically recognizable weighted tree languages over commutative semifields by finitely generated and cancellative scalar algebras](https://arxiv.org/abs/2509.14914)
*Zoltán Fülöp,Heiko Vogler*

Main category: cs.FL

TL;DR: 本文提出了在交换半域上可识别的加权树语言的表征定理，通过引入标量代数概念并证明m-句法标量代数的有限生成性，同时给出了自底向上确定性加权树自动机的最小化定理和最小自动机构造方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作已建立了在域上可识别加权树语言与句法向量空间有限维性之间的关系，但缺乏在交换半域上的相应理论。本文旨在填补这一空白，为更一般的代数结构提供理论框架。

Method: 引入标量代数概念（忽略向量加法的向量空间），证明自底向上确定性可识别加权树语言等价于相应m-句法标量代数的有限生成性，并建立最小化定理。

Result: 成功建立了交换半域上加权树语言的可识别性表征定理，证明了最小化定理的有效性，并给出了最小自动机的具体构造方法。

Conclusion: 本文扩展了加权树语言理论到交换半域情形，提出的标量代数概念和表征定理为相关领域提供了新的理论基础和实用工具。

Abstract: Due to the works of S. Bozapalidis and A. Alexandrakis, there is a well-known
characterization of recognizable weighted tree languages over fields in terms
of finite-dimensionality of syntactic vector spaces. Here we prove a
characterization of bottom-up deterministically recognizable weighted tree
languages over commutative semifields in terms of the requirement that the
respective m-syntactic scalar algebras are finitely generated. The concept of
scalar algebra is introduced in this paper; it is obtained from the concept of
vector space by disregarding the addition of vectors. Moreover, we prove a
minimization theorem for bottom-up-deterministic weighted tree automata and we
construct the minimal automaton.

</details>


### [6] [Weighted Automata for Exact Inference in Discrete Probabilistic Programs](https://arxiv.org/abs/2509.15074)
*Dominik Geißler,Tobias Winkler*

Main category: cs.FL

TL;DR: 本文提出了一种基于加权自动机的方法来处理概率编程中的精确推理问题，通过将分布编码为交换字母表上的自动机来实现从先验分布到后验分布的有效转换。


<details>
  <summary>Details</summary>
Motivation: 概率编程中的推理问题需要确定程序在给定观察指令下的后验分布，精确推理尤其具有挑战性。受概率生成函数工作的启发，需要一种有效的方法来处理这类问题。

Method: 将N^k上的分布编码为具有k个符号的交换字母表上的加权自动机，将各种命令式编程语句的语义映射到自动机理论构造，实现从先验到后验分布的有效转换。

Result: 开发了一种有效的翻译方法，能够处理丰富类别的程序，并将分布编码为自动机形式。

Conclusion: 该方法相对于标准操作程序语义是可靠的，为概率编程中的精确推理提供了一种自动机理论的新途径。

Abstract: In probabilistic programming, the inference problem asks to determine a
program's posterior distribution conditioned on its "observe" instructions.
Inference is challenging, especially when exact rather than approximate results
are required. Inspired by recent work on probability generating functions
(PGFs), we propose encoding distributions on $\mathbb{N}^k$ as weighted
automata over a commutative alphabet with $k$ symbols. Based on this, we map
the semantics of various imperative programming statements to
automata-theoretic constructions. For a rich class of programs, this results in
an effective translation from prior to posterior distribution, both encoded as
automata. We prove that our approach is sound with respect to a standard
operational program semantics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models](https://arxiv.org/abs/2509.14265)
*Siyuan Chen,Zhichao Lu,Qingfu Zhang*

Main category: cs.SE

TL;DR: EoK是一个基于LLM的进化程序搜索框架，通过从成熟内核库的开发历史中挖掘可重用优化思想，结合RISC-V特定上下文的RAG技术，在参考材料稀缺的RISC-V平台上实现了自动化内核设计，性能超越人类专家和现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决在参考材料稀缺的新兴硬件平台（如RISC-V）上自动化内核设计的挑战，传统LLM方法在CUDA等成熟领域有效，但在RISC-V等缺乏参考的领域效果未经验证。

Method: 提出EoK框架：1）从成熟内核库开发历史中挖掘可重用优化思想（通用设计原则+可操作思路）；2）使用RAG技术增强RISC-V特定上下文；3）基于历史有效技术指导并行LLM探索的进化程序搜索。

Result: 在80个内核设计任务评估中，EoK实现了中位数1.27倍加速，在所有任务上都超越了人类专家，比之前基于LLM的自动化内核设计方法提升了20%。

Conclusion: EoK证明了将人类经验融入新兴领域的可行性，凸显了基于LLM的自动化内核优化的巨大潜力，特别是在参考材料稀缺的硬件平台上。

Abstract: Automated kernel design is critical for overcoming software ecosystem
barriers in emerging hardware platforms like RISC-V. While large language
models (LLMs) have shown promise for automated kernel optimization,
demonstrating success in CUDA domains with comprehensive technical documents
and mature codebases, their effectiveness remains unproven for reference-scarce
domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based
evolutionary program search framework that automates kernel design for domains
with limited reference material. EoK mitigates reference scarcity by mining and
formalizing reusable optimization ideas (general design principles + actionable
thoughts) from established kernel libraries' development histories; it then
guides parallel LLM explorations using these ideas, enriched via
Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing
historically effective techniques. Empirically, EoK achieves a median 1.27x
speedup, surpassing human experts on all 80 evaluated kernel design tasks and
improving upon prior LLM-based automated kernel design methods by 20%. These
results underscore the viability of incorporating human experience into
emerging domains and highlight the immense potential of LLM-based automated
kernel optimization.

</details>


### [8] [Automated and Context-Aware Code Documentation Leveraging Advanced LLMs](https://arxiv.org/abs/2509.14273)
*Swapnil Sharma Sarker,Tanzina Taher Ifty*

Main category: cs.SE

TL;DR: 本研究开发了一个针对Javadoc生成的上下文感知数据集，并评估了五个开源大语言模型在零样本、少样本和微调设置下的性能，发现LLaMA 3.1在自动化Javadoc生成方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化文档生成方法主要关注代码摘要，缺乏针对模板化文档（如Javadoc）的研究，特别是使用公开可用的大语言模型。同时，缺乏包含现代语言特性、广泛框架/库覆盖和必要上下文信息的Javadoc专用数据集阻碍了该领域的进展。

Method: 开发了一个新颖的上下文感知Javadoc生成数据集，包含现代Java代码库的关键结构和语义信息。评估了五个开源LLM（LLaMA-3.1、Gemma-2、Phi-3、Mistral、Qwen-2.5）在零样本、少样本和微调设置下的性能。

Result: LLaMA 3.1在所有设置下表现一致良好，是实用自动化Javadoc生成的可靠候选模型，为专有系统提供了可行的替代方案。

Conclusion: 该研究填补了模板化文档生成领域的空白，证明了开源大语言模型在自动化Javadoc生成方面的有效性，特别是LLaMA 3.1模型的优异表现。

Abstract: Code documentation is essential to improve software maintainability and
comprehension. The tedious nature of manual code documentation has led to much
research on automated documentation generation. Existing automated approaches
primarily focused on code summarization, leaving a gap in template-based
documentation generation (e.g., Javadoc), particularly with publicly available
Large Language Models (LLMs). Furthermore, progress in this area has been
hindered by the lack of a Javadoc-specific dataset that incorporates modern
language features, provides broad framework/library coverage, and includes
necessary contextual information. This study aims to address these gaps by
developing a tailored dataset and assessing the capabilities of publicly
available LLMs for context-aware, template-based Javadoc generation. In this
work, we present a novel, context-aware dataset for Javadoc generation that
includes critical structural and semantic information from modern Java
codebases. We evaluate five open-source LLMs (including LLaMA-3.1, Gemma-2,
Phi-3, Mistral, Qwen-2.5) using zero-shot, few-shot, and fine-tuned setups and
provide a comparative analysis of their performance. Our results demonstrate
that LLaMA 3.1 performs consistently well and is a reliable candidate for
practical, automated Javadoc generation, offering a viable alternative to
proprietary systems.

</details>


### [9] [Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization](https://arxiv.org/abs/2509.14279)
*Robert Tjarko Lange,Qi Sun,Aaditya Prasad,Maxence Faldor,Yujin Tang,David Ha*

Main category: cs.SE

TL;DR: 提出了robust-kbench基准测试和自动化CUDA内核发现框架，通过LLM将PyTorch代码转换为CUDA内核并进行迭代优化，在性能和正确性方面超越torch实现


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法主要关注高层软件工程任务，对底层CUDA内核优化关注不足，且现有内核生成基准存在可被利用的漏洞和测试条件多样性不足的问题

Method: 开发robust-kbench基准测试，构建包含翻译、验证和优化的自动化代理框架，使用进化元生成过程优化CUDA内核运行时性能，基于LLM的验证器确保正确性

Result: 在robust-kbench上评估显示，该方法生成的CUDA内核在实用应用中超越torch实现，能够融合操作并部署多种运行时优化策略，验证器工作流能准确分类错误内核

Conclusion: 提出的框架能够有效自动化CUDA内核的发现和优化过程，在严格评估设置下实现性能提升和正确性保证，为LLM在底层硬件优化中的应用提供了新途径

Abstract: Recent advances in large language models (LLMs) demonstrate their
effectiveness in scaling test-time compute for software engineering tasks.
However, these approaches often focus on high-level solutions, with limited
attention to optimizing low-level CUDA kernel implementations. Additionally,
existing kernel generation benchmarks suffer from exploitable loopholes and
insufficient diversity in testing conditions, hindering true generalization
assessment. To address these limitations, we introduce robust-kbench, a new
benchmark for rigorous evaluation of kernel performance and correctness across
varied scenarios. Furthermore, we present a comprehensive agentic framework
that automates CUDA kernel discovery, verification, and optimization. This
pipeline enables frontier LLMs to translate torch code to CUDA kernels and
iteratively improve their runtime within our robust evaluation setting. Our
sequential workflow first translates PyTorch code into equivalent CUDA kernels.
It then optimizes their runtime using a novel evolutionary meta-generation
procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for
correctness and efficient filtering. Evaluated on robust-kbench, our approach
produces CUDA kernels outperforming torch implementations for practical
applications, including forward and backward passes. It can fuse operations and
deploy various runtime optimization strategies. The verifier workflow
accurately classifies incorrect kernels, enhancing hardware verification
efficiency.

</details>


### [10] [A Taxonomy of Prompt Defects in LLM Systems](https://arxiv.org/abs/2509.14404)
*Haoye Tian,Chong Wang,BoYang Yang,Lyuye Zhang,Yang Liu*

Main category: cs.SE

TL;DR: 本文首次系统性地调查和分类了提示缺陷，将提示设计中的常见问题归纳为六个维度的缺陷类型，并针对每种缺陷提供了具体的缓解策略和工程方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已成为现代软件的关键组件，但提示设计仍主要依赖经验，小的错误可能导致不可靠、不安全或低效的行为，需要系统化的工程方法来确保LLM驱动系统的可靠性。

Method: 通过系统调查和分类学方法，将提示缺陷组织为六个维度（规范与意图、输入与内容、结构与格式、上下文与记忆、性能与效率、可维护性与工程），每个维度细分为具体子类型，并提供实例分析和根本原因分析。

Result: 建立了完整的提示缺陷分类体系，为每种缺陷类型提炼了缓解策略，包括新兴的提示工程模式、自动化防护机制、测试框架和评估方法，并构建了连接缺陷、影响和补救措施的主分类法。

Conclusion: 提出了面向工程的严格方法学需求，以确保LLM驱动系统在设计上就是可靠的，并指出了开放的研究挑战。

Abstract: Large Language Models (LLMs) have become key components of modern software,
with prompts acting as their de-facto programming interface. However, prompt
design remains largely empirical and small mistakes can cascade into
unreliable, insecure, or inefficient behavior. This paper presents the first
systematic survey and taxonomy of prompt defects, recurring ways that prompts
fail to elicit their intended behavior from LLMs. We organize defects along six
dimensions: (1) Specification and Intent, (2) Input and Content, (3) Structure
and Formatting, (4) Context and Memory, (5) Performance and Efficiency, and (6)
Maintainability and Engineering. Each dimension is refined into fine-grained
subtypes, illustrated with concrete examples and root cause analysis. Grounded
in software engineering principles, we show how these defects surface in real
development workflows and examine their downstream effects. For every subtype,
we distill mitigation strategies that span emerging prompt engineering
patterns, automated guardrails, testing harnesses, and evaluation frameworks.
We then summarize these strategies in a master taxonomy that links defect,
impact, and remedy. We conclude with open research challenges and a call for
rigorous engineering-oriented methodologies to ensure that LLM-driven systems
are dependable by design.

</details>


### [11] [SCoGen: Scenario-Centric Graph-Based Synthesis of Real-World Code Problems](https://arxiv.org/abs/2509.14281)
*Xifeng Yao,Dongyu Lang,Wu Zhang,Xintong Guo,Huarui Xie,Yinhao Ni,Ping Liu,Guang Shen,Yi Bai,Dandan Tu,Changzheng Zhang*

Main category: cs.SE

TL;DR: 提出了一种从真实编程数据中合成代码问题的新框架，通过整合领域知识、领域技能和编码技能来模拟真实世界编程场景，在多个基准测试中优于现有开源大语言模型。


<details>
  <summary>Details</summary>
Motivation: 代码大语言模型的进一步发展受到真实世界编程问题稀缺性的限制，需要构建能够模拟真实场景的代码问题来促进模型进步。

Method: 从Stack Overflow和Kaggle等真实编程数据集中提取领域知识、领域技能和编码技能，构建场景中心图连接这些元素，并设计图采样策略来控制问题的复杂性和多样性。

Result: 实验结果表明，该方法在各种真实世界基准测试中 consistently 优于不同规模和功能的最先进开源大语言模型，包括代码专用模型和通用模型。

Conclusion: 提出的框架能够有效合成反映真实世界挑战的代码问题，为代码大语言模型的进一步发展提供了有价值的训练数据来源。

Abstract: Significant advancements have been made in the capabilities of code large
language models, leading to their rapid adoption and application across a wide
range of domains. However, their further advancements are often constrained by
the scarcity of real-world coding problems. To bridge this gap, we propose a
novel framework for synthesizing code problems that emulate authentic
real-world scenarios. This framework systematically integrates domain
knowledge, domain skills, and coding skills, all of which are meticulously
extracted from real-world programming-related datasets, including Stack
Overflow and Kaggle. The extracted elements serve as the foundational building
blocks for constructing code problems. To align the generated problems with
practical applications, application scenarios are also mined from the
aforementioned datasets. These scenarios are then utilized to construct a
scenario-centric graph that interconnects domain knowledge, domain skills, and
coding skills. Based on this structured representation, a sampling strategy on
the graph is designed, which effectively controls the generation of a code
problem with complexity and diversity, reflects real-world challenges.
Experimental results demonstrate that the proposed method consistently achieves
superior performance over state-of-the-art open-source large language models of
varying sizes and functionalities, including both coders and general-purpose
models, across a diverse set of real-world benchmarks.

</details>


### [12] [Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language](https://arxiv.org/abs/2509.14623)
*Hanlong Wan,Xing Lu,Yan Chen,Karthik Devaprasad,Laura Hinkle*

Main category: cs.SE

TL;DR: 本文研究使用大型语言模型(LLM)自动生成Modelica控制模块，通过结构化工作流程结合标准化提示、库感知接地和人工评估，在控制模块上达到83%的成功率，开发时间减少40-60%。


<details>
  <summary>Details</summary>
Motivation: Modelica是广泛使用的基于方程的语言，但开发控制模块劳动密集且需要专业知识，需要自动化解决方案来提高效率。

Method: 开发结构化工作流程，包括标准化提示支架、库感知接地、OpenModelica自动编译和人工循环评估，在基础逻辑任务和控制模块上进行实验。

Result: GPT 4o在零样本模式下无法生成可执行代码，Claude Sonnet 4在精心设计的提示下对基础逻辑块达到完全成功，控制模块成功率达83%，开发时间从10-20小时减少到4-6小时。

Conclusion: LLM辅助工作流程在Modelica生成方面显示出潜力但仍有局限，未来需要在预模拟验证、更强接地和闭环评估方面进一步研究。

Abstract: Dynamic energy systems and controls require advanced modeling frameworks to
design and test supervisory and fault tolerant strategies. Modelica is a widely
used equation based language, but developing control modules is labor intensive
and requires specialized expertise. This paper examines the use of large
language models (LLMs) to automate the generation of Control Description
Language modules in the Building Modelica Library as a case study. We developed
a structured workflow that combines standardized prompt scaffolds, library
aware grounding, automated compilation with OpenModelica, and human in the loop
evaluation. Experiments were carried out on four basic logic tasks (And, Or,
Not, and Switch) and five control modules (chiller enable/disable, bypass valve
control, cooling tower fan speed, plant requests, and relief damper control).
The results showed that GPT 4o failed to produce executable Modelica code in
zero shot mode, while Claude Sonnet 4 achieved up to full success for basic
logic blocks with carefully engineered prompts. For control modules, success
rates reached 83 percent, and failed outputs required medium level human repair
(estimated one to eight hours). Retrieval augmented generation often produced
mismatches in module selection (for example, And retrieved as Or), while a
deterministic hard rule search strategy avoided these errors. Human evaluation
also outperformed AI evaluation, since current LLMs cannot assess simulation
results or validate behavioral correctness. Despite these limitations, the LLM
assisted workflow reduced the average development time from 10 to 20 hours down
to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.
These results highlight both the potential and current limitations of LLM
assisted Modelica generation, and point to future research in pre simulation
validation, stronger grounding, and closed loop evaluation.

</details>


### [13] [Monitoring Machine Learning Systems: A Multivocal Literature Review](https://arxiv.org/abs/2509.14294)
*Hira Naveed,Scott Barnett,Chetan Arora,John Grundy,Hourieh Khalajzadeh,Omar Haggag*

Main category: cs.SE

TL;DR: 这篇论文通过多源文献综述(MLR)方法，对136篇文献进行了系统分析，提供了机器学习监控领域的全面概述，包括监控动机、方法、工具和当前局限性。


<details>
  <summary>Details</summary>
Motivation: 动态生产环境中机器学习系统面临运行时问题（如数据模式变化），需要监控来早期检测和缓解这些问题，维护用户信任并防止组织不良后果。

Method: 采用多源文献综述(MLR)方法，遵循Garousi的成熟指南，从四个关键维度分析136篇论文：动机目标背景、监控方面技术指标工具、贡献效益、当前局限性。

Result: 系统识别和总结了机器学习监控实践与空白，强调了正式文献与灰色文献之间的相似性和脱节，提供了监控解决方案选择指南。

Conclusion: 研究为学术界和实践者提供了价值，帮助选择合适的监控解决方案，突出当前方法的局限性，并为未来研究和工具开发提供了方向。

Abstract: Context: Dynamic production environments make it challenging to maintain
reliable machine learning (ML) systems. Runtime issues, such as changes in data
patterns or operating contexts, that degrade model performance are a common
occurrence in production settings. Monitoring enables early detection and
mitigation of these runtime issues, helping maintain users' trust and prevent
unwanted consequences for organizations. Aim: This study aims to provide a
comprehensive overview of the ML monitoring literature. Method: We conducted a
multivocal literature review (MLR) following the well established guidelines by
Garousi to investigate various aspects of ML monitoring approaches in 136
papers. Results: We analyzed selected studies based on four key areas: (1) the
motivations, goals, and context; (2) the monitored aspects, specific
techniques, metrics, and tools; (3) the contributions and benefits; and (4) the
current limitations. We also discuss several insights found in the studies,
their implications, and recommendations for future research and practice.
Conclusion: Our MLR identifies and summarizes ML monitoring practices and gaps,
emphasizing similarities and disconnects between formal and gray literature.
Our study is valuable for both academics and practitioners, as it helps select
appropriate solutions, highlights limitations in current approaches, and
provides future directions for research and tool development.

</details>


### [14] [SALT4Decompile: Inferring Source-level Abstract Logic Tree for LLM-Based Binary Decompilation](https://arxiv.org/abs/2509.14646)
*Yongpan Wang,Xin Xu,Xiaojie Zhu,Xiaodong Gu,Beijun Shen*

Main category: cs.SE

TL;DR: SALT提出了一个新颖的二进制反编译方法，通过构建源级抽象逻辑树(SALT)来抽象二进制和源代码之间的稳定逻辑特征，指导LLM进行语义恢复，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的反编译方法将汇编代码视为线性指令序列，忽略了二进制文件固有的任意跳转模式和孤立数据段，这严重阻碍了从汇编代码正确推断源代码语义的能力。

Method: SALT方法首先从汇编代码构建源级抽象逻辑树(SALT)来近似高级语言的逻辑结构，然后使用重构的SALT微调LLM生成反编译代码，最后通过错误纠正和符号恢复来改进输出的可读性和正确性。

Result: 在三个知名数据集上的实验表明，SALT在恢复源代码逻辑方面非常有效，显著优于最先进的方法（如在Decompile-Eval上达到70.4%的TCP率，提升10.6%），并且对四种常用混淆技术具有鲁棒性。

Conclusion: SALT通过抽象二进制级操作为高级逻辑框架，有效提升了LLM在二进制反编译中的语义恢复能力，为人类分析人员理解二进制函数提供了优越的帮助。

Abstract: Decompilation is widely used in reverse engineering to recover high-level
language code from binary executables. While recent approaches leveraging Large
Language Models (LLMs) have shown promising progress, they typically treat
assembly code as a linear sequence of instructions, overlooking arbitrary jump
patterns and isolated data segments inherent to binary files. This limitation
significantly hinders their ability to correctly infer source code semantics
from assembly code. To address this limitation, we propose \saltm, a novel
binary decompilation method that abstracts stable logical features shared
between binary and source code. The core idea of \saltm is to abstract selected
binary-level operations, such as specific jumps, into a high-level logic
framework that better guides LLMs in semantic recovery. Given a binary
function, \saltm constructs a Source-level Abstract Logic Tree (\salt) from
assembly code to approximate the logic structure of high-level language. It
then fine-tunes an LLM using the reconstructed \salt to generate decompiled
code. Finally, the output is refined through error correction and symbol
recovery to improve readability and correctness. We compare \saltm to three
categories of baselines (general-purpose LLMs, commercial decompilers, and
decompilation methods) using three well-known datasets (Decompile-Eval, MBPP,
Exebench). Our experimental results demonstrate that \saltm is highly effective
in recovering the logic of the source code, significantly outperforming
state-of-the-art methods (e.g., 70.4\% TCP rate on Decompile-Eval with a 10.6\%
improvement). The results further validate its robustness against four commonly
used obfuscation techniques. Additionally, analyses of real-world software and
a user study confirm that our decompiled output offers superior assistance to
human analysts in comprehending binary functions.

</details>


### [15] [On the Illusion of Success: An Empirical Study of Build Reruns and Silent Failures in Industrial CI](https://arxiv.org/abs/2509.14347)
*Henri Aïdasso,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: 本文首次对持续集成中的静默失败进行了实证研究，发现11%的成功作业会被重新运行，其中35%在24小时后重跑，识别出测试、静态分析、Shell脚本等关键因素，并揭示了11类静默失败模式。


<details>
  <summary>Details</summary>
Motivation: 持续集成的可靠性至关重要，但开发者经常面临非确定性问题和静默失败（作业标记为成功但未完成所有任务），这些问题会降低对构建结果的信任，增加成本并可能导致bug进入生产环境。

Method: 通过对81个工业项目的142,387个作业进行分析，使用混合效应模型对32个自变量（AUC为85%）进行研究，并进一步分析92个公开问题来识别静默失败模式。

Result: 研究发现11%的成功作业会被重新运行，35%的重跑发生在24小时后；识别出测试和静态分析任务、Shell等脚本语言、开发者重跑倾向等关键因素；揭示了11类静默失败，最常见的是工件操作错误、缓存错误和忽略退出码。

Conclusion: 研究提供了关于静默失败情况和原因的重要见解，有助于提高团队意识，并为改进CI可靠性提出了解决方案，强调了需要关注这些容易被忽视但具有破坏性的失败模式。

Abstract: Reliability of build outcomes is a cornerstone of effective Continuous
Integration (CI). Yet in practice, developers often struggle with
non-deterministic issues in the code or CI infrastructure, which undermine
trust in build results. When faced with such unexpected outcomes, developers
often repeatedly rerun jobs hoping for true success, but this practice is known
to increase CI costs and reduce productivity. While recent studies have focused
on intermittent job failures, no prior work has investigated silent failures,
where build jobs are marked as successful but fail to complete all or part of
their tasks. Such silent failures often go unnoticed, creating an illusion of
success with detrimental consequences such as bugs escaping into production.
This paper presents the first empirical study of silent failures through the
practice of rerunning successful jobs. An analysis of 142,387 jobs across 81
industrial projects shows that 11% of successful jobs are rerun, with 35% of
these reruns occurring after more than 24 hours. Using mixed-effects models on
32 independent variables (AUC of 85%), we identified key factors associated
with reruns of successful jobs, notably testing and static analysis tasks,
scripting languages like Shell, and developers prior rerun tendencies. A
further analysis of 92 public issues revealed 11 categories of silent failures
aligning with these factors, the most frequent being artifact operation errors,
caching errors, and ignored exit codes. Overall, our findings provide valuable
insights into the circumstances and causes of silent failures to raise
awareness among teams, and present solutions to improve CI reliability.

</details>


### [16] [CodeLSI: Leveraging Foundation Models for Automated Code Generation with Low-Rank Optimization and Domain-Specific Instruction Tuning](https://arxiv.org/abs/2509.14373)
*Huy Le,Phong Nguyen,Hao Do,Tuan Nguyen,Thien Pham,Anh Nguyen-Duc,Tho Quan*

Main category: cs.SE

TL;DR: CodeLSI是一个结合低秩优化和领域特定指令调优的框架，用于在内部基础设施上高效生成高质量、领域特定的代码，避免依赖第三方API。


<details>
  <summary>Details</summary>
Motivation: 解决自动化代码生成中领域特异性、成本效益和安全性问题，特别是在依赖第三方API时存在的挑战。

Method: 应用低秩适应技术降低模型预训练和微调的计算成本，采用领域特定指令调优使代码生成与组织需求对齐，在真实JavaScript编码任务上进行测试。

Result: CodeLSI生成高质量、上下文感知的代码，在相关性、准确性和领域适应性方面优于基线模型，低秩优化显著降低了资源需求。

Conclusion: 低秩优化与领域特定调优相结合可以提升基础模型在自动化代码生成中的实用性和性能，为商业API解决方案提供了安全、经济高效的替代方案。

Abstract: Context: Automated code generation using Foundation Models (FMs) offers
promising solutions for enhancing software development efficiency. However,
challenges remain in ensuring domain specificity, cost-effectiveness, and
security - especially when relying on third-party APIs. This paper introduces
CodeLSI, a framework that combines low-rank optimization and domain-specific
instruction tuning to address these challenges.
  Objectives: The aim of this study is to develop and evaluate CodeLSI, a novel
approach for generating high-quality code tailored to specific domains, using
FMs fine-tuned on company infrastructure without dependence on external APIs.
  Methods: CodeLSI applies low-rank adaptation techniques to reduce the
computational cost of model pre-training and fine-tuning. Domain-specific
instruction tuning is employed to align code generation with organizational
needs. We implemented and tested the framework on real-world JavaScript coding
tasks using datasets drawn from internal software projects.
  Results: Experimental evaluations show that CodeLSI produces high-quality,
context aware code. It outperforms baseline models in terms of relevance,
accuracy, and domain fit. The use of low-rank optimization significantly
reduced resource requirements, enabling scalable training on company-owned
infrastructure.
  Conclusion: CodeLSI demonstrates that combining low-rank optimization with
domain specific tuning can enhance the practicality and performance of FMs for
automated code generation. This approach provides a secure, cost-efficient
alternative to commercial API based solutions and supports faster, more
targeted innovation in software development.

</details>


### [17] [Code Less to Code More: Streamlining Language Server Protocol and Type System Development for Language Families](https://arxiv.org/abs/2509.15150)
*Federico Bruzzone,Walter Cazzola,Luca Favalli*

Main category: cs.SE

TL;DR: 提出了Typelang语言家族和模块化语言服务器生成方法，将语言编辑器组合从L×E减少到N×1，显著降低了语言编辑支持的开销


<details>
  <summary>Details</summary>
Motivation: 解决现有语言工作台在模块化、可重用性和利用类型系统生成语言服务器方面的不足，减少语言编辑器组合的复杂性

Method: 开发Typelang DSL家族用于模块化类型系统实现，建立模块化语言服务器生成流程，采用变体导向编程和跨工件协调层管理软件变体，自动化生成LSP插件

Result: 实现了93.48%的类型系统实现字符数减少，100%自动化LSP插件生成，显著降低了语言家族编辑支持的工作量

Conclusion: 该方法有效解决了语言编辑器组合的复杂性，通过模块化重用和自动化生成大幅降低了开发成本，特别在语言工件复用时效果更显著

Abstract: Developing editing support for $L$ languages in $E$ editors is complex and
time-consuming. Some languages do not provide dedicated editors, while others
offer a single native editor. The $\textit{language server protocol}$ (LSP)
reduces the language-editor combinations $L \times E$ to $L + E$, where a
single language server communicates with editors via LSP plugins. However,
overlapping implementations of linguistic components remain an issue. Existing
language workbenches struggle with modularity, reusability, and leveraging type
systems for language server generation. In this work, we propose: (i) Typelang,
a family of domain-specific languages for modular, composable, and reusable
type system implementation, (ii) a modular language server generation process,
producing servers for languages built in a modular workbench, (iii) the
variant-oriented programming paradigm and a cross-artifact coordination layer
to manage interdependent software variants, and (iv) an LSP plugin generator,
reducing $E$ to $1$ by automating plugin creation for multiple editors. To
simplify editing support for language families, each language artifact
integrates its own Typelang variant, used to generate language servers. This
reduces combinations to $T \times 1$, where $T = L$ represents the number of
type systems. Further reuse of language artifacts across languages lowers this
to $N \times 1$, where $N << T$, representing unique type systems. We implement
Typelang in Neverlang, generating language servers for each artifact and LSP
plugins for three editors. Empirical evaluation shows a 93.48% reduction in
characters needed for type system implementation and 100% automation of LSP
plugin generation, significantly lowering effort for editing support in
language families, especially when artifacts are reused.

</details>


### [18] [An LLM-based multi-agent framework for agile effort estimation](https://arxiv.org/abs/2509.14483)
*Thanh-Long Bui,Hoa Khanh Dam,Rashina Hoda*

Main category: cs.SE

TL;DR: 提出基于大语言模型的多智能体框架，用于敏捷软件开发中的工作量估算，能够与人类开发者协作讨论并达成共识，在准确性和用户体验方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前敏捷工作量估算主要依赖主观评估，导致估算不准确和不一致。虽然机器学习方法显示出良好准确性，但无法解释估算结果或与人类团队成员互动。

Method: 利用大语言模型构建多智能体框架，该框架不仅能生成估算，还能与人类开发者和其他智能体协调、沟通和讨论以达成共识。

Result: 在真实数据集上的评估显示，该方法在大多数情况下在所有评估指标上都优于最先进技术。与软件开发从业者的人类研究也显示出与智能体协作的极其积极体验。

Conclusion: 该LLM-based多智能体框架成功解决了传统敏捷估算方法的主观性和机器学习方法缺乏交互性的问题，为敏捷软件开发提供了更准确、可解释且协作性强的估算解决方案。

Abstract: Effort estimation is a crucial activity in agile software development, where
teams collaboratively review, discuss, and estimate the effort required to
complete user stories in a product backlog. Current practices in agile effort
estimation heavily rely on subjective assessments, leading to inaccuracies and
inconsistencies in the estimates. While recent machine learning-based methods
show promising accuracy, they cannot explain or justify their estimates and
lack the capability to interact with human team members. Our paper fills this
significant gap by leveraging the powerful capabilities of Large Language
Models (LLMs). We propose a novel LLM-based multi-agent framework for agile
estimation that not only can produce estimates, but also can coordinate,
communicate and discuss with human developers and other agents to reach a
consensus. Evaluation results on a real-life dataset show that our approach
outperforms state-of-the-art techniques across all evaluation metrics in the
majority of the cases. Our human study with software development practitioners
also demonstrates an overwhelmingly positive experience in collaborating with
our agents in agile effort estimation.

</details>


### [19] [Evaluating the Effectiveness of Coverage-Guided Fuzzing for Testing Deep Learning Library APIs](https://arxiv.org/abs/2509.14626)
*Feiran Qin,M. M. Abid Naziri,Hengyu Ai,Saikat Dutta,Marcelo d'Amorim*

Main category: cs.SE

TL;DR: FlashFuzz是首个将覆盖率引导模糊测试(CGF)应用于深度学习库的研究，通过LLM自动合成API级测试工具，显著提高了代码覆盖率、错误检测效率和输入有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习库模糊测试方法缺乏覆盖率引导，限制了测试效果和效率。研究旨在探索CGF在DL库中的应用价值，并解决API级测试工具自动生成的挑战。

Method: 提出FlashFuzz技术，利用大型语言模型(LLMs)结合模板、辅助函数和API文档自动合成API级测试工具，采用反馈驱动的迭代策略来合成和修复测试工具。

Result: 为1,151个PyTorch和662个TensorFlow API合成了测试工具，相比现有方法覆盖率提高101.13-212.88%，有效性提高1.0-5.4倍，输入生成速度提升1-1182倍，发现了42个未知错误。

Conclusion: 研究证实CGF可有效应用于DL库测试，FlashFuzz为未来测试方法提供了强基线，展示了LLM在自动化测试工具生成中的巨大潜力。

Abstract: Deep Learning (DL) libraries such as PyTorch provide the core components to
build major AI-enabled applications. Finding bugs in these libraries is
important and challenging. Prior approaches have tackled this by performing
either API-level fuzzing or model-level fuzzing, but they do not use coverage
guidance, which limits their effectiveness and efficiency. This raises an
intriguing question: can coverage guided fuzzing (CGF), in particular
frameworks like LibFuzzer, be effectively applied to DL libraries, and does it
offer meaningful improvements in code coverage, bug detection, and scalability
compared to prior methods?
  We present the first in-depth study to answer this question. A key challenge
in applying CGF to DL libraries is the need to create a test harness for each
API that can transform byte-level fuzzer inputs into valid API inputs. To
address this, we propose FlashFuzz, a technique that leverages Large Language
Models (LLMs) to automatically synthesize API-level harnesses by combining
templates, helper functions, and API documentation. FlashFuzz uses a feedback
driven strategy to iteratively synthesize and repair harnesses. With this
approach, FlashFuzz synthesizes harnesses for 1,151 PyTorch and 662 TensorFlow
APIs. Compared to state-of-the-art fuzzing methods (ACETest, PathFinder, and
TitanFuzz), FlashFuzz achieves up to 101.13 to 212.88 percent higher coverage
and 1.0x to 5.4x higher validity rate, while also delivering 1x to 1182x
speedups in input generation. FlashFuzz has discovered 42 previously unknown
bugs in PyTorch and TensorFlow, 8 of which are already fixed. Our study
confirms that CGF can be effectively applied to DL libraries and provides a
strong baseline for future testing approaches.

</details>


### [20] [Wireless Communication Performance Testing: From Laboratory Environment to Research Vessel](https://arxiv.org/abs/2509.14740)
*Andrei-Raoul Morariu,Andreas Strandberg,Bogdan Iancu,Jerker Bjorkqvist*

Main category: cs.SE

TL;DR: 研究通过实验室和室外环境测量，分析了共享频谱中信号传输特性，重点关注视线遮挡物、距离和位置对信号衰减的影响。


<details>
  <summary>Details</summary>
Motivation: 探究动态和遮挡环境中环境因素对无线通信的影响，特别是在共享频谱场景下信号传输的可靠性。

Method: 在实验室和室外环境中进行信号传输测量，分析视线遮挡物对Tx-Rx信号的衰减效应，并研究距离和电动研究船上不同位置对传输效率的影响。

Result: 实验室物体遮挡视线会导致信号衰减，距离和位置布置显著影响信号传输效率，环境因素在动态遮挡环境中对无线通信有重要影响。

Conclusion: 环境因素（包括遮挡物、距离和位置）在共享频谱的无线通信中起着关键作用，这些发现有助于理解动态遮挡环境中的通信可靠性。

Abstract: This study investigates signal transmission within a shared spectrum,
focusing on measurements conducted both in laboratory and outdoor environments.
The objective was to demonstrate how laboratory objects obstructing the line of
sight can attenuate the signal between a transmitter (Tx) and a receiver (Rx).
Additionally, we examined the impact of distance and placement in various
locations aboard an electric research boat on signal transmission efficiency.
These findings contribute to understanding whether the environmental factors
influence wireless communication in dynamic and obstructed environments.

</details>


### [21] [On the Use of Agentic Coding Manifests: An Empirical Study of Claude Code](https://arxiv.org/abs/2509.14744)
*Worawalan Chatlatanagulchai,Kundjanasith Thonglek,Brittany Reid,Yutaro Kashiwa,Pattara Leelaprute,Arnon Rungsawang,Bundit Manaskasemsak,Hajimu Iida*

Main category: cs.SE

TL;DR: 分析253个Claude.md文件，发现智能编码工具的manifest文件通常具有浅层次结构，主要包含操作命令、技术实现说明和高级架构内容


<details>
  <summary>Details</summary>
Motivation: 智能编码工具需要manifest文件提供项目上下文、身份和操作规则，但缺乏全面的文档指导开发者创建这些配置文件

Method: 分析了242个代码仓库中的253个Claude.md文件，识别结构模式和常见内容

Result: manifest文件通常具有浅层次结构（一个主标题和若干子章节），内容以操作命令、技术实现说明和高级架构为主

Conclusion: 研究为开发者创建有效的agent manifest提供了实证基础，揭示了当前实践中的常见模式和内容分布

Abstract: Agentic coding tools receive goals written in natural language as input,
break them down into specific tasks, and write/execute the actual code with
minimal human intervention. Key to this process are agent manifests,
configuration files (such as Claude.md) that provide agents with essential
project context, identity, and operational rules. However, the lack of
comprehensive and accessible documentation for creating these manifests
presents a significant challenge for developers. We analyzed 253 Claude.md
files from 242 repositories to identify structural patterns and common content.
Our findings show that manifests typically have shallow hierarchies with one
main heading and several subsections, with content dominated by operational
commands, technical implementation notes, and high-level architecture.

</details>


### [22] [On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub](https://arxiv.org/abs/2509.14745)
*Miku Watanabe,Hao Li,Yutaro Kashiwa,Brittany Reid,Hajimu Iida,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 对567个由Claude Code生成的GitHub PR进行实证研究，发现83.8%的AI辅助PR被接受合并，其中54.9%无需修改直接合并，45.1%需要人工修订


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地集成到软件开发过程中，需要了解AI生成的pull requests在实际项目中的实用性和接受程度

Method: 实证研究157个开源项目中的567个由Claude Code生成的GitHub pull requests，分析其任务类型、接受率和修改需求

Result: 83.8%的AI辅助PR被接受合并；54.9%的合并PR无需修改；45.1%需要人工修订，特别是在bug修复、文档和项目标准遵循方面

Conclusion: AI辅助的PR大部分可被接受，但仍需要人工监督和精炼，特别是在复杂任务和项目特定标准的遵循方面

Abstract: Large language models (LLMs) are increasingly being integrated into software
development processes. The ability to generate code and submit pull requests
with minimal human intervention, through the use of autonomous AI agents, is
poised to become a standard practice. However, little is known about the
practical usefulness of these pull requests and the extent to which their
contributions are accepted in real-world projects. In this paper, we
empirically study 567 GitHub pull requests (PRs) generated using Claude Code,
an agentic coding tool, across 157 diverse open-source projects. Our analysis
reveals that developers tend to rely on agents for tasks such as refactoring,
documentation, and testing. The results indicate that 83.8% of these
agent-assisted PRs are eventually accepted and merged by project maintainers,
with 54.9% of the merged PRs are integrated without further modification. The
remaining 45.1% require additional changes benefit from human revisions,
especially for bug fixes, documentation, and adherence to project-specific
standards. These findings suggest that while agent-assisted PRs are largely
acceptable, they still benefit from human oversight and refinement.

</details>


### [23] [RulER: Automated Rule-Based Semantic Error Localization and Repair for Code Translation](https://arxiv.org/abs/2509.14829)
*Shuo Jin,Songqiang Chen,Xiaoyuan Xie,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: RulER是一种基于规则的代码翻译调试方法，通过从LLM生成的正确定译中自动推导代码翻译规则，有效定位和修复翻译错误，在错误定位率和修复成功率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代码翻译自动调试方法缺乏可靠的参考来构建代码对齐和修复补丁模板，影响了定位准确性和修复效果。

Method: RulER从LLM生成的正确定译中自动推导代码翻译规则，并在可扩展节点上动态组合现有规则，建立源语言和目标语言之间的结构对应关系，作为代码对齐和修复模板设计的可靠参考。

Result: 在Java到C++和Python到C++翻译任务中，RulER在错误定位率和修复成功率上分别比最佳基线方法提高了20%和272%，且优于直接使用LLM生成补丁的方法。

Conclusion: RulER展示了从LLMs中提取和利用编码知识的有前景的方法论，能够有效提升代码翻译的可靠性。

Abstract: Automated code translation aims to convert programs between different
programming languages while maintaining their functionality. Due to the
imperfections of code translation models, the generated translations may
contain errors that compromise their reliability. Existing automated debugging
methods for code translation rely on code alignments and repair patch templates
to locate and fix erroneous translations. However, existing methods lack
reliable references to construct code alignments and design repair patch
templates, which significantly impacts their localization accuracy and repair
effectiveness. To address these limitations, we reintroduce code translation
rules and propose a rule-based debugging method for code translation, called
RulER. RulER automatically derives code translation rules from correct
translations generated by LLMs, enabling the efficient collection of diverse
translation rules. In addition, RulER dynamically combines the existing rules
on expandable nodes like expressions and tokens to further adaptively align
more statements. These rules capture clear and detailed structural
correspondences between source and target programming languages. Therefore,
they can serve as reliable and reusable references for code alignment and
repair template design, enabling RulER to locate and fix translation errors
effectively. Our evaluation of RulER on Java-to-C++ and Python-to-C++
translations produced by four code translation models demonstrates that RulER
outperforms state-of-the-art methods, BatFix and TransMap. Our experimental
results show that RulER outperformed the best baseline by 20% and 272% in terms
of error localization rates and repair success rates, respectively. RulER
exhibits superior repair performance compared to directly prompting LLMs for
patch generation, demonstrating a promising methodology for extracting and
leveraging coding knowledge from LLMs.

</details>


### [24] [CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects](https://arxiv.org/abs/2509.14856)
*Hanyang Guo,Xunjin Zheng,Zihan Liao,Hang Yu,Peng DI,Ziyin Zhang,Hong-Ning Dai*

Main category: cs.SE

TL;DR: 提出了CodeFuse-CR-Bench，首个面向代码审查的综合性基准测试，包含601个高质量实例，覆盖9个PR问题域，提供丰富的上下文信息，用于评估LLM在真实代码审查任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码审查基准测试存在"现实差距"，仅评估孤立子任务且使用简化数据，无法反映真实世界代码审查的完整上下文丰富特性。

Method: 构建包含601个实例的基准测试，来自70个Python项目，提供问题、PR详情和仓库状态等丰富上下文。提出结合基于规则的定位和语法检查与基于模型的审查质量评估的新框架。

Result: 进行了大规模评估发现：(1)没有单一LLM在所有CR方面都占优；(2)Gemini 2.5 Pro综合表现最佳；(3)不同LLM对冗余上下文的鲁棒性不同。

Conclusion: 研究强调了进行全面、多维度评估的必要性，为推进真正智能且实用的代码审查助手提供了可行见解。

Abstract: Automated code review (CR) is a key application for Large Language Models
(LLMs), but progress is hampered by a "reality gap": existing benchmarks
evaluate models on isolated sub-tasks using simplified, context-poor data. This
fails to reflect the holistic context-rich nature of real-world CR. To bridge
this gap, we introduce CodeFuse-CR-Bench, the first comprehensiveness-aware
benchmark for repository-level CR evaluation. CodeFuse-CR-Bench comprises 601
high-quality instances from 70 Python projects covering nine Pull-Request (PR)
problem domains, where each instance provides rich, multi-faceted context
including the associated issue, PR details, and repository state, enabling
end-to-end evaluation. Beyond superficial metrics, we also propose a novel
evaluation framework that combines rule-based checks for location and syntax
with model-based judgments of review quality. We present the first large-scale
assessment of state-of-the-art LLMs on this comprehensive CR task. Our results
establish crucial baselines and reveal that (1) no single LLM dominates all
aspects of CR; (2) Gemini 2.5 Pro achieves the highest comprehensive
performance; and (3) different LLMs exhibit varying robustness to redundant
context. These findings highlight the necessity of holistic, multi-dimensional
evaluation and provide actionable insights for advancing truly intelligent yet
practical CR assistants.

</details>


### [25] [CARGO: A Framework for Confidence-Aware Routing of Large Language Models](https://arxiv.org/abs/2509.14899)
*Amine Barrak,Yosr Fourati,Michael Olchawa,Emna Ksontini,Khalil Zoghlami*

Main category: cs.SE

TL;DR: CARGO是一个轻量级的LLM路由框架，通过嵌入回归器和可选分类器实现动态模型选择，无需人工标注，在四个主流LLM上达到76.4%的top-1路由准确率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在规模、专业化和延迟特性上的多样化，如何将用户提示路由到最合适的模型以平衡性能和成本变得至关重要。

Method: 使用基于嵌入的回归器训练LLM判断的成对比较来预测模型性能，不确定时调用二元分类器。支持五个任务类别（数学、编码、推理、摘要、创意写作）的特定领域回归器。

Result: 在GPT-4o、Claude 3.5 Sonnet、DeepSeek V3和Perplexity Sonar四个模型上，达到76.4%的top-1路由准确率，对抗单个专家的胜率为72%-89%。

Conclusion: 置信度引导的轻量级路由能够以最小开销实现专家级性能，为现实世界多模型LLM部署提供实用解决方案。

Abstract: As large language models (LLMs) proliferate in scale, specialization, and
latency profiles, the challenge of routing user prompts to the most appropriate
model has become increasingly critical for balancing performance and cost. We
introduce CARGO (Category-Aware Routing with Gap-based Optimization), a
lightweight, confidence-aware framework for dynamic LLM selection. CARGO
employs a single embedding-based regressor trained on LLM-judged pairwise
comparisons to predict model performance, with an optional binary classifier
invoked when predictions are uncertain. This two-stage design enables precise,
cost-aware routing without the need for human-annotated supervision. To capture
domain-specific behavior, CARGO also supports category-specific regressors
trained across five task groups: mathematics, coding, reasoning, summarization,
and creative writing. Evaluated on four competitive LLMs (GPT-4o, Claude 3.5
Sonnet, DeepSeek V3, and Perplexity Sonar), CARGO achieves a top-1 routing
accuracy of 76.4% and win rates ranging from 72% to 89% against individual
experts. These results demonstrate that confidence-guided, lightweight routing
can achieve expert-level performance with minimal overhead, offering a
practical solution for real-world, multi-model LLM deployments.

</details>


### [26] ["Let it be Chaos in the Plumbing!" Usage and Efficacy of Chaos Engineering in DevOps Pipelines](https://arxiv.org/abs/2509.14931)
*Stefano Fossati,Damian Andrew Tamburri,Massimiliano Di Penta,Marco Tonnarelli*

Main category: cs.SE

TL;DR: 本文通过系统性的灰色文献综述，分析了2019-2024年间50个来源，将混沌工程基础原则扩展为10个概念，揭示了行业实践中对受控实验、自动化和风险缓解策略的重视。


<details>
  <summary>Details</summary>
Motivation: 混沌工程已成为提高现代分布式系统弹性的主动方法，但需要了解行业实践者近年来如何采用和调整混沌工程原则。

Method: 采用系统性灰色文献综述方法，分析2019年至2024年初发布的50个来源，开发了全面的分类框架。

Result: 研究发现混沌工程核心原则仍然具有影响力，但实践者越来越强调受控实验、自动化和风险缓解策略，以适应敏捷和持续演进的DevOps流程需求。

Conclusion: 研究结果增强了人们对混沌工程在实践中如何设计和实施的理解，为未来研究和工业应用提供了指导，旨在提高动态生产环境中的系统鲁棒性。

Abstract: Chaos Engineering (CE) has emerged as a proactive method to improve the
resilience of modern distributed systems, particularly within DevOps
environments. Originally pioneered by Netflix, CE simulates real-world failures
to expose weaknesses before they impact production. In this paper, we present a
systematic gray literature review that investigates how industry practitioners
have adopted and adapted CE principles over recent years. Analyzing 50 sources
published between 2019 and early 2024, we developed a comprehensive
classification framework that extends the foundational CE principles into ten
distinct concepts. Our study reveals that while the core tenets of CE remain
influential, practitioners increasingly emphasize controlled experimentation,
automation, and risk mitigation strategies to align with the demands of agile
and continuously evolving DevOps pipelines. Our results enhance the
understanding of how CE is intended and implemented in practice, and offer
guidance for future research and industrial applications aimed at improving
system robustness in dynamic production environments.

</details>


### [27] [Orion: Fuzzing Workflow Automation](https://arxiv.org/abs/2509.15195)
*Max Bazalii,Marius Fleischer*

Main category: cs.SE

TL;DR: Orion是一个自动化模糊测试框架，通过整合LLM推理与传统工具，大幅减少人工工作量，在clib库中发现两个未知漏洞


<details>
  <summary>Details</summary>
Motivation: 现代模糊测试虽然能自动生成输入和监控执行，但从代码库分析、配置harness到结果分类的整个工作流程仍需大量人工操作，现有研究只关注单个阶段

Method: Orion框架将LLM用于代码推理和语义指导，同时依赖确定性工具进行验证、迭代优化和需要精确性的任务

Result: 在基准测试套件中，Orion将人工工作量减少了46-204倍（取决于工作流阶段），并在广泛使用的开源clib库中发现两个先前未知的漏洞

Conclusion: Orion通过整合LLM推理与传统工具，成功实现了模糊测试工作流程的自动化，显著降低了人工成本并提高了漏洞发现效率

Abstract: Fuzz testing is one of the most effective techniques for finding software
vulnerabilities. While modern fuzzers can generate inputs and monitor
executions automatically, the overall workflow, from analyzing a codebase, to
configuring harnesses, to triaging results, still requires substantial manual
effort. Prior attempts focused on single stages such as harness synthesis or
input minimization, leaving researchers to manually connect the pieces into a
complete fuzzing campaign.
  We introduce Orion, a framework that automates the the manual bottlenecks of
fuzzing by integrating LLM reasoning with traditional tools, allowing campaigns
to scale to settings where human effort alone was impractical. Orion uses LLMs
for code reasoning and semantic guidance, while relying on deterministic tools
for verification, iterative refinement, and tasks that require precision.
Across our benchmark suite, Orion reduces human effort by 46-204x depending on
the workflow stage, and we demonstrate its effectiveness through the discovery
of two previously unknown vulnerabilities in the widely used open-source clib
library.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [28] [The Groupoid-syntax of Type Theory is a Set](https://arxiv.org/abs/2509.14988)
*Thorsten Altenkirch,Ambrus Kaposi,Szumi Xie*

Main category: cs.LO

TL;DR: 提出了Groupoid Category with Families (GCwF)框架，通过在群胚层面截断类型并引入一致性方程，扩展了传统CwF框架，解决了HoTT中传统CwF需要集合截断的限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统CwF在Homotopy Type Theory中需要集合截断类型，这排除了基于单值范畴的模型（如标准集合模型）。为了克服这一限制，需要一个新的框架来支持更丰富和自然的语义模型。

Method: 引入Groupoid Category with Families (GCwF)概念，在群胚层面截断类型并包含一致性方程，作为从1-范畴出发时CwF框架的自然扩展。

Result: 证明了具有基础集合族和Pi类型的类型理论的初始GCwF是集合截断的，从而可以在保持传统内在语法的同时，支持更丰富语义模型的解释。

Conclusion: GCwF框架成功扩展了传统CwF，允许在更自然的模型中进行类型理论解释，所有构造都在Cubical Agda中形式化验证。

Abstract: Categories with families (CwFs) have been used to define the semantics of
type theory in type theory. In the setting of Homotopy Type Theory (HoTT), one
of the limitations of the traditional notion of CwFs is the requirement to
set-truncate types, which excludes models based on univalent categories, such
as the standard set model. To address this limitation, we introduce the concept
of a Groupoid Category with Families (GCwF). This framework truncates types at
the groupoid level and incorporates coherence equations, providing a natural
extension of the CwF framework when starting from a 1-category.
  We demonstrate that the initial GCwF for a type theory with a base family of
sets and Pi-types (groupoid-syntax) is set-truncated. Consequently, this allows
us to utilize the conventional intrinsic syntax of type theory while enabling
interpretations in semantically richer and more natural models. All
constructions in this paper were formalised in Cubical Agda.

</details>


### [29] [Theorem Provers: One Size Fits All?](https://arxiv.org/abs/2509.15015)
*Harrison Oates,Hyeonggeun Yun,Nikhila Gurusinghe*

Main category: cs.LO

TL;DR: 本文通过在实际案例（插入排序正确性证明）中测试Coq和Idris2两个定理证明器，对它们的性能进行定性评估，并比较社区和库支持，帮助用户做出明智选择


<details>
  <summary>Details</summary>
Motivation: 定理证明器在形式验证中很重要，但现有系统设计选择各异，影响可用性和适用领域。需要实际测试来评估不同证明器的性能和支持情况

Method: 通过证明插入排序的正确性来测试Coq和Idris2两个定理证明器，进行定性性能评估，并比较它们的社区和库支持

Result: 提供了两个定理证明器在实际应用中的性能表现评估结果，以及社区和库支持的对比分析

Conclusion: 这项工作帮助用户根据具体需求选择合适的定理证明系统，并为开发者提供了其他系统中可能有用的方法参考

Abstract: Theorem provers are important tools for people working in formal
verification. There are a myriad of interactive systems available today, with
varying features and approaches motivating their development. These design
choices impact their usability, alongside the problem domain in which they are
employed. We test-drive two such provers, Coq and Idris2, by proving the
correctness of insertion sort, before providing a qualitative evaluation of
their performance. We then compare their community and library support. This
work helps users to make an informed choice of system, and highlight approaches
in other systems that developers might find useful.

</details>


### [30] [The mechanization of science illustrated by the Lean formalization of the multi-graded Proj construction](https://arxiv.org/abs/2509.15116)
*Arnaud Mayeux,Jujian Zhang*

Main category: cs.LO

TL;DR: 在Lean4中形式化多级分次Proj构造


<details>
  <summary>Details</summary>
Motivation: 展示机械化数学和形式化验证的能力，为代数几何中的多级分次环理论提供形式化基础

Method: 使用Lean4定理证明器对多级分次Proj构造进行形式化定义和验证

Result: 成功实现了多级分次Proj构造的完整形式化，验证了相关数学定理的正确性

Conclusion: 这项工作证明了Lean4在复杂代数结构形式化方面的有效性，为后续代数几何的形式化研究奠定了基础

Abstract: We formalize the multi-graded Proj construction in Lean4, illustrating
mechanized mathematics and formalization.

</details>
