<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 46]
- [cs.LO](#cs.LO) [Total: 9]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters](https://arxiv.org/abs/2510.03415)
*Aditya Thimmaiah,Jiyang Zhang,Jayanth Srinivasa,Junyi Jessy Li,Milos Gligoric*

Main category: cs.PL

TL;DR: 研究大语言模型能否基于编程语言的形式语义执行程序，发现LLMs在标准语义下表现良好，但在非标准语义下性能显著下降，表明其语义理解缺乏鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs能否纯粹基于编程语言的形式语义来执行程序，从而支持新编程语言和语言特性的快速原型开发。

Method: 使用IMP语言的小步操作语义和K语义，构建三个难度可控的评估集，评估模型在最终状态预测、语义规则预测和执行轨迹预测三个任务上的表现，并通过系统变异标准规则来区分预训练记忆和语义能力。

Result: 强代码/推理LLMs在标准语义下表现良好，但在非标准语义下性能显著下降；推理模型在涉及高度复杂程序的粗粒度任务上表现优异；提供形式语义对简单程序有帮助但对复杂程序往往有害。

Conclusion: LLMs有潜力成为编程语言解释器，但其语义理解缺乏鲁棒性，需要进一步改进。

Abstract: As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.

</details>


### [2] [Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren](https://arxiv.org/abs/2510.04049)
*Xiangyu Guo,Ajay Bansal*

Main category: cs.PL

TL;DR: 本文展示了在stableKanren中使用完整性约束进行数值计算以解决问题的示例，并介绍了注入启发式知识以减少求解时间的多种方法。


<details>
  <summary>Details</summary>
Motivation: 为了在关系编程语言中平衡符号和数值计算，避免将所有数字转换为符号，同时提供比关系数字表示更直接的数值表示和更简单的语法。

Method: 使用stableKanren扩展miniKanren，支持稳定模型语义下的正常逻辑程序，通过构建约束存储来实现完整性约束的数值计算。

Result: 演示了在SEND+MORE=MONEY谜题中，不同的编程或查询方法会影响求解器性能，随着注入更多启发式知识，性能逐渐提升。

Conclusion: stableKanren在关系编程中有效平衡了符号和数值计算，提供了直接的数值表示和简化的语法，支持组合搜索问题的声明式生成与测试范式。

Abstract: This paper presents examples of using integrity constraints in stableKanren
to encode numeric computations for problem solving. Then, we use one of the
examples to introduce multiple ways to infuse heuristic knowledge and reduce
solving time. stableKanren is an extension of miniKanren that supports normal
logic programs under stable model semantics. stableKanren further supports
numeric computation by constructing a constraint store for integrity
constraints. There are three ways to extend a relational programming language
with numeric computations: relational number representation, grounding numbers
to symbols, and constraint store construction. We demonstrate that the numeric
computations in stableKanren have a straightforward numerical representation
compared to relational number representations. More importantly, stableKanren
balances symbolic and numeric computation in relational programming by avoiding
the grounding of all numbers to symbols. Lastly, it also has simpler syntax
compared to other constraint store construction approaches. stableKanren
supports combinatorial search problem solving under a declarative generate and
test paradigm. Such a paradigm generates all possible combinations of solutions
to the problem, then applies a set of constraints to prune out the unwanted
solutions. We demonstrate that different approaches to writing programs or
queries affect the solver's performance in the SEND+MORE=MONEY puzzle. The
performance gradually improves as more heuristic knowledge is infused through
the programs or queries. Additionally, we show how to use an external function
to achieve a hybrid solution.

</details>


### [3] [Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization](https://arxiv.org/abs/2510.04890)
*Shihan Fang,Wenxin Zheng*

Main category: cs.PL

TL;DR: 提出了一种新的向量化流水线，通过SIR和VIR两种专门的IR扩展来改进编译器向量化能力，相比LLVM和GCC分别实现了53%和58%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代处理器依赖SIMD指令集提升性能，但生产级编译器如LLVM和GCC由于向量化过程分散和可扩展性有限，无法充分利用向量化机会。

Method: 引入包含SIR和VIR两种IR扩展的向量化流水线：SIR编码高级结构信息，VIR通过数据依赖分析显式表示指令依赖关系，构建灵活可扩展的向量化框架。

Result: 实验评估显示，提出的向量化流水线相比LLVM和GCC分别实现了53%和58%的性能加速。

Conclusion: 基于详细依赖信息的向量化框架显著提高了向量化过程的可互操作性，扩展了同构指令的搜索空间，增强了自动向量化的范围和效率。

Abstract: Modern processors increasingly rely on SIMD instruction sets, such as AVX and
RVV, to significantly enhance parallelism and computational performance.
However, production-ready compilers like LLVM and GCC often fail to fully
exploit available vectorization opportunities due to disjoint vectorization
passes and limited extensibility. Although recent attempts in heuristics and
intermediate representation (IR) designs have attempted to address these
problems, efficiently simplifying control flow analysis and accurately
identifying vectorization opportunities remain challenging tasks.
  To address these issues, we introduce a novel vectorization pipeline
featuring two specialized IR extensions: SIR, which encodes high-level
structural information, and VIR, which explicitly represents instruction
dependencies through data dependency analysis. Leveraging the detailed
dependency information provided by VIR, we develop a flexible and extensible
vectorization framework. This approach substantially improves interoperability
across vectorization passes and expands the search space for identifying
isomorphic instructions, ultimately enhancing both the scope and efficiency of
automatic vectorization. Experimental evaluations demonstrate that our proposed
vectorization pipeline achieves significant performance improvements,
delivering speedups of up to 53% and 58% compared to LLVM and GCC,
respectively.

</details>


### [4] [concurrentKanren: miniKanren for parallel execution](https://arxiv.org/abs/2510.04994)
*Sjoerd Dost*

Main category: cs.PL

TL;DR: 在Go语言中实现了miniKanren的并行版本，展示了并行执行的可行性和性能提升潜力。


<details>
  <summary>Details</summary>
Motivation: 虽然并发逻辑编程早于miniKanren，但miniKanren的并发实现仍未被充分探索。

Method: 利用隐式并行性，允许遗留程序从并行执行中受益，并讨论了实现策略。

Result: 证明了并行miniKanren的可行性，并评估了并行性的影响。

Conclusion: 为未来语言无关的模型奠定了基础。

Abstract: Concurrent logic programming predates miniKanren, but concurrent
implementations of miniKanren have remained largely unexplored. In this work we
present a parallel implementation of miniKanren in Go, demonstrating its
feasibility and potential for performance improvements. Our approach leverages
implicit parallelism allowing legacy programs to benefit from parallel
execution. We discuss implementation strategies and evaluate the impact of
parallelism, laying groundwork for future language-agnostic models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Repairing Leaks in Resource Wrappers](https://arxiv.org/abs/2510.03461)
*Sanjay Malakar,Michael D. Ernst,Martin Kellogg,Manu Sridharan*

Main category: cs.SE

TL;DR: 本文提出了一种改进资源泄漏修复的方法，特别针对资源包装器的情况，通过集成资源管理规范推断、程序变换、字段包含分析和新的修复模式，显著提高了修复率。


<details>
  <summary>Details</summary>
Motivation: 现有工具只能修复硬编码库资源类型的泄漏，无法处理资源包装器（将资源存储在字段中且自身需要关闭的情况），限制了修复范围。

Method: 1) 将资源管理规范推断集成到修复流程中；2) 将程序转换为更易分析的变体；3) 使用字段包含分析推理资源生命周期；4) 引入新的修复模式处理非final字段中的资源。

Result: 在NJR基准测试套件中，将资源泄漏警告的修复率从41%提高到68%。

Conclusion: 该方法通过更全面的分析和新的修复技术，显著提升了资源泄漏修复能力，特别是在处理资源包装器方面表现突出。

Abstract: A resource leak occurs when a program fails to release a finite resource like
a socket, file descriptor or database connection. While sound static analysis
tools can detect all leaks, automatically repairing them remains challenging.
Prior work took the output of a detection tool and attempted to repair only
leaks from a hard-coded list of library resource types. That approach limits
the scope of repairable leaks: real-world code uses resource wrappers that
store a resource in a field and must themselves be closed. This paper makes
four key contributions to improve resource leak repair in the presence of
wrappers. (1) It integrates inference of resource management specifications
into the repair pipeline, enabling extant fixing approaches to reason about
wrappers. (2) It transforms programs into variants that are easier to analyze,
making inference, detection, and fixing tools more effective; for instance, it
makes detection tools report problems closer to the root cause, often in a
client of a resource wrapper rather than within the wrapper class itself. (3) A
novel field containment analysis reasons about resource lifetimes, enabling
repair of more leaks involving resources stored in fields. (4) It introduces a
new repair pattern and more precise reasoning to better handle resources stored
in non-final fields. Prior work fixed 41% of resource leak warnings in the NJR
benchmark suite; our implementation Arodnap fixes 68%.

</details>


### [6] [ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework](https://arxiv.org/abs/2510.03463)
*Vali Tawosi,Keshav Ramani,Salwa Alamir,Xiaomo Liu*

Main category: cs.SE

TL;DR: 提出了ALMAS框架，一个基于LLM的多智能体软件工程系统，能够端到端执行软件开发任务，与敏捷开发团队协作。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM系统主要关注代码实现，但软件开发是多阶段过程，需要覆盖整个软件开发生命周期。

Method: 设计ALMAS框架，将智能体与敏捷角色对齐，采用模块化方式与人类开发者和开发环境无缝集成。

Result: 通过已发表工作和用例展示，ALMAS能够无缝生成应用程序并添加新功能。

Conclusion: ALMAS框架展示了多智能体LLM系统在端到端软件工程中的潜力，能够有效支持敏捷开发团队。

Abstract: Multi-agent Large Language Model (LLM) systems have been leading the way in
applied LLM research across a number of fields. One notable area is software
development, where researchers have advanced the automation of code
implementation, code testing, code maintenance, inter alia, using LLM agents.
However, software development is a multifaceted environment that extends beyond
just code. As such, a successful LLM system must factor in multiple stages of
the software development life-cycle (SDLC). In this paper, we propose a vision
for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework,
which follows the above SDLC philosophy such that it may work within an agile
software development team to perform several tasks end-to-end. ALMAS aligns its
agents with agile roles, and can be used in a modular fashion to seamlessly
integrate with human developers and their development environment. We showcase
the progress towards ALMAS through our published works and a use case
demonstrating the framework, where ALMAS is able to seamlessly generate an
application and add a new feature.

</details>


### [7] [Relative Code Comprehensibility Prediction](https://arxiv.org/abs/2510.03474)
*Nadeeshan De Silva,Martin Kellogg,Oscar Chaparro*

Main category: cs.SE

TL;DR: 该论文提出使用相对可理解性预测模型替代绝对可理解性预测模型，通过比较两个代码片段的可理解性来缓解人类数据中的噪声问题，实验证明相对模型性能显著优于绝对模型。


<details>
  <summary>Details</summary>
Motivation: 现有代码可理解性度量指标和机器学习模型与人类实际可理解性测量相关性差，主要原因是人类可理解性数据存在固有噪声，这导致直接预测绝对可理解性的模型准确率有限。

Method: 提出训练模型预测两个代码片段的相对可理解性（哪个更容易理解），而不是单独预测每个片段的绝对可理解性。使用包含150个Java代码片段和12.5k个人类可理解性测量的数据集，比较绝对和相对预测模型与基线模型的性能。

Result: 绝对可理解性模型最多比基线提升33.4%，且经常表现不佳；相对可理解性模型显著更好，片段级和开发者级预测的平均改进分别为137.8%和74.7%。

Conclusion: 相对可理解性模型能更有效地从数据中学习，支持其在软件工程下游任务中的实际应用价值。

Abstract: Automatically predicting how difficult it is for humans to understand a code
snippet can assist developers in tasks like deciding when and where to
refactor. Despite many proposed code comprehensibility metrics, studies have
shown they often correlate poorly with actual measurements of human
comprehensibility. This has motivated the use of machine learning models to
predict human comprehensibility directly from code, but these models have also
shown limited accuracy.
  We argue that model inaccuracy stems from inherent noise in human
comprehensibility data, which confuses models trained to predict it directly.
To address this, we propose training models to predict the relative
comprehensibility of two code snippets - that is, predicting which snippet a
human would find easier to understand without predicting each snippet's
comprehensibility in isolation. This mitigates noise in predicting 'absolute'
comprehensibility measurements, but is still useful for downstream
software-engineering tasks like assessing whether refactoring improves or
hinders comprehensibility.
  We conducted a study to assess and compare the effectiveness of absolute and
relative code comprehensibility prediction via machine learning. We used a
dataset of 150 Java code snippets and 12.5k human comprehensibility
measurements from prior user studies, comparing the models' performance with
naive baselines (eg 'always predict the majority class'). Our findings indicate
that absolute comprehensibility models improve over the baselines by at most
33.4% and frequently underperform. In contrast, relative comprehensibility
models are substantially better, with average improvements of 137.8% and 74.7%
for snippet-wise and developer-wise prediction, respectively. These results
suggest that relative comprehensibility models learn more effectively from the
data, supporting their practical applicability for downstream SE tasks.

</details>


### [8] [LLM Agents for Automated Dependency Upgrades](https://arxiv.org/abs/2510.03480)
*Vali Tawosi,Salwa Alamir,Xiaomo Liu,Manuela Veloso*

Main category: cs.SE

TL;DR: 提出一个基于LLM代理的框架，结合迁移文档自动推荐和应用代码更新，确保与新版本库的兼容性。


<details>
  <summary>Details</summary>
Motivation: 随着代码库扩展，库依赖会过时需要更新，但手动更新可能引入破坏性变更，需要大量开发时间维护。

Method: 使用LLM代理框架，包括摘要代理、控制代理和代码代理，自动定位Java代码库中的过时库使用并实施推荐修复。

Result: 在工业用例测试中，该方法在所有情况下使用更少的token完成升级，达到71.4%的精确度。

Conclusion: 该方法相比现有技术更高效有效，能够自动处理库依赖更新问题。

Abstract: As a codebase expands over time, its library dependencies can become outdated
and require updates to maintain innovation and security. However, updating a
library can introduce breaking changes in the code, necessitating significant
developer time for maintenance. To address this, we introduce a framework of
LLM agents to be used in combination with migration documentation to
automatically recommend and apply code updates and ensure compatibility with
new versions. Our solution can automatically localize updated library usages in
live Java codebases and implement recommended fixes in a user-friendly manner.
The system architecture consists of multiple key components: a Summary Agent,
Control Agent, and Code Agent. To validate our approach, we apply the framework
on an industrial use case by which we create three synthetic code repositories
with major Upgrade changes and benchmark our approach against state-of-the-art
methods. Results show that our approach not only performs upgrades using fewer
tokens across all cases but also achieves a precision of 71.4%, highlighting
its efficiency and effectiveness compared to state-of-the-art methods.

</details>


### [9] [AgentHub: A Research Agenda for Agent Sharing Infrastructure](https://arxiv.org/abs/2510.03495)
*Erik Pautsch,Tanmay Singla,Wenxin Jiang,Huiyun Peng,Behnaz Hassanshahi,Konstantin Läufer,George K. Thiruvathukal,James C. Davis*

Main category: cs.SE

TL;DR: 提出了AgentHub研究议程，旨在解决LLM智能体生态系统中的基础设施碎片化问题，推动智能体共享、信任和组合的标准化发展。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体基础设施分散，缺乏像npm、Hugging Face等成熟生态系统的统一管理机制，现有研究仅关注分发、命名等狭窄领域，需要更全面的软件工程视角。

Method: 提出AgentHub研究议程框架，通过定义能力清晰度、生命周期透明度、互操作性、治理、安全性和工作流集成等关键挑战，为构建可靠可扩展的智能体生态系统制定社区路线图。

Result: 建立了系统化的研究议程，为智能体生态系统的标准化发展提供了理论框架和方向指引。

Conclusion: AgentHub愿景是让智能体能够像今天的软件库一样被无缝共享、信任和组合，推动智能体生态系统的成熟发展。

Abstract: LLM-based agents are rapidly proliferating, yet the infrastructure for
discovering, evaluating, and governing them remains fragmented compared to
mature ecosystems like software package registries (e.g., npm) and model hubs
(e.g., Hugging Face). Recent research and engineering works have begun to
consider the requisite infrastructure, but so far they focus narrowly -- on
distribution, naming, or protocol negotiation. However, considering broader
software engineering requirements would improve open-source distribution and
ease reuse. We therefore propose AgentHub, a research agenda for agent sharing.
By framing the key challenges of capability clarity, lifecycle transparency,
interoperability, governance, security, and workflow integration, AgentHub
charts a community-wide agenda for building reliable and scalable agent
ecosystems. Our vision is a future where agents can be shared, trusted, and
composed as seamlessly as today's software libraries.

</details>


### [10] [REFINE: Enhancing Program Repair Agents through Context-Aware Patch Refinement](https://arxiv.org/abs/2510.03588)
*Anvith Pabba,Simin Chen,Alex Mathai,Anindya Chakraborty,Baishakhi Ray*

Main category: cs.SE

TL;DR: 提出了Refine框架，通过系统化地将草稿补丁转化为正确补丁来解决LLM在程序修复中的局限性，显著提升了修复性能


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的程序修复技术由于对代码上下文理解有限和过度依赖不完整的测试套件，经常产生部分正确的草稿补丁，无法完全修复bug或过度拟合测试用例

Method: Refine框架通过三个关键步骤：消除模糊问题和代码上下文的歧义、通过测试时扩展多样化补丁候选、通过LLM驱动的代码审查过程聚合部分修复

Result: 在SWE-Bench Lite基准测试中达到工作流方法的最先进结果，将AutoCodeRover性能提升14.67%至51.67%；在SWE-Bench Verified上提升解决率12.2%；集成多个APR系统平均提升14%

Conclusion: 精炼是当前APR流程中缺失的关键组件，智能协作在缩小接近正确与完全正确补丁之间的差距方面具有巨大潜力

Abstract: Large Language Models (LLMs) have recently shown strong potential in
automatic program repair (APR), especially in repository-level settings where
the goal is to generate patches based on natural language issue descriptions,
large codebases, and regression tests. However, despite their promise, current
LLM-based APR techniques often struggle to produce correct fixes due to limited
understanding of code context and over-reliance on incomplete test suites. As a
result, they frequently generate Draft Patches-partially correct patches that
either incompletely address the bug or overfit to the test cases. In this work,
we propose a novel patch refinement framework, Refine, that systematically
transforms Draft Patches into correct ones. Refine addresses three key
challenges: disambiguating vague issue and code context, diversifying patch
candidates through test-time scaling, and aggregating partial fixes via an
LLM-powered code review process. We implement Refine as a general refinement
module that can be integrated into both open-agent-based and workflow-based APR
systems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine
achieves state-of-the-art results among workflow-based approaches and
approaches the best-known performance across all APR categories. Specifically,
Refine boosts AutoCodeRover's performance by 14.67%, achieving a score of
51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine
improves the resolution rate by 12.2%, and when integrated across multiple APR
systems, it yields an average improvement of 14%-demonstrating its broad
effectiveness and generalizability. These results highlight the effectiveness
of refinement as a missing component in current APR pipelines and the potential
of agentic collaboration in closing the gap between near-correct and correct
patches. We also open source our code.

</details>


### [11] [Generating High-Level Test Cases from Requirements using LLM: An Industry Study](https://arxiv.org/abs/2510.03641)
*Satoshi Masuda,Satoshi Kouzawa,Kyousuke Sezai,Hidetoshi Suhara,Yasuaki Hiruta,Kunihiro Kudou*

Main category: cs.SE

TL;DR: 提出了一种仅使用提示而不创建RAG的方法，从需求文档自动生成高层次测试用例，通过首先生成测试设计技术，然后为每个技术生成测试用例，在蓝牙和Mozilla数据集上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 工业界对从需求文档自动生成高层次测试用例有强烈需求，但现有基于RAG的方法需要为每个应用定制知识系统，工作量较大，且没有不依赖RAG的通用方法。

Method: 首先将需求文档输入LLM生成对应的测试设计技术，然后为每个生成的测试设计技术生成高层次测试用例，并基于语义相似度验证评估方法。

Result: 在蓝牙和Mozilla数据集上实验，宏召回率分别达到0.81和0.37，表明该方法在不使用RAG的情况下具有实际应用可行性。

Conclusion: 提出的方法能够在不创建RAG的情况下从需求文档生成高层次测试用例，为更广泛的需求文档提供了通用的自动化测试用例生成方案。

Abstract: Currently, generating high-level test cases described in natural language
from requirement documents is performed manually. In the industry, including
companies specializing in software testing, there is a significant demand for
the automatic generation of high-level test cases from requirement documents
using Large Language Models (LLMs). Efforts to utilize LLMs for requirement
analysis are underway. In some cases, retrieval-augmented generation (RAG) is
employed for generating high-level test cases using LLMs. However, in practical
applications, it is necessary to create a RAG tailored to the knowledge system
of each specific application, which is labor-intensive. Moreover, when applying
high-level test case generation as a prompt, there is no established method for
instructing the generation of high-level test cases at a level applicable to
other specifications without using RAG. It is required to establish a method
for the automatic generation of high-level test cases that can be generalized
across a wider range of requirement documents. In this paper, we propose a
method for generating high-level (GHL) test cases from requirement documents
using only prompts, without creating RAGs. In the proposed method, first, the
requirement document is input into the LLM to generate test design techniques
corresponding to the requirement document. Then, high-level test cases are
generated for each of the generated test design techniques. Furthermore, we
verify an evaluation method based on semantic similarity of the generated
high-level test cases. In the experiments, we confirmed the method using
datasets from Bluetooth and Mozilla, where requirement documents and high-level
test cases are available, achieving macro-recall measurement of 0.81 and 0.37,
respectively. We believe that the method is feasible for practical application
in generating high-level test cases without using RAG.

</details>


### [12] [Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems](https://arxiv.org/abs/2510.03712)
*Jahidul Arafat,Kh. M. Moniruzzaman,Shamim Hossain,Fariha Tasmin,Kamrujjaman,Ahsan Habib Tareq*

Main category: cs.SE

TL;DR: 提出首个系统性检测、预防和优化潜在风险的框架，通过集成数学建模、智能扰动测试和风险感知性能优化，将可靠性工程从被动事件管理转变为主动风险感知优化。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统采用激进的优化策略，这些策略会创造潜在风险——当优化失败时，卓越性能掩盖灾难性脆弱性。当前可靠性工程侧重于被动事件响应而非主动检测优化引发的漏洞。

Method: 集成三个系统：HYDRA使用六种优化感知扰动策略实现89.7%风险发现率；RAVEN提供持续生产监控，在1,748个场景中达到92.9%精度和93.8%召回率；APEX实现风险感知优化，保持96.6%基线性能同时减少59.2%潜在风险。

Result: 评估显示强统计验证（Cohen d>2.0）和卓越可重复性（r>0.92）。生产部署24周显示平均恢复时间减少69.1%，事件严重程度减少78.6%，预防81起事件，产生144万美元年均收益，投资回报期3.2个月。

Conclusion: 该方法将可靠性工程从被动事件管理转变为主动风险感知优化，通过潜在风险指数（LRI）实现预测性风险评估，与事件严重程度强相关（r=0.863, p<0.001）。

Abstract: Modern distributed systems employ aggressive optimization strategies that
create latent risks - hidden vulnerabilities where exceptional performance
masks catastrophic fragility when optimizations fail. Cache layers achieving
99% hit rates can obscure database bottlenecks until cache failures trigger
100x load amplification and cascading collapse. Current reliability engineering
focuses on reactive incident response rather than proactive detection of
optimization-induced vulnerabilities. This paper presents the first
comprehensive framework for systematic latent risk detection, prevention, and
optimization through integrated mathematical modeling, intelligent perturbation
testing, and risk-aware performance optimization. We introduce the Latent Risk
Index (LRI) that correlates strongly with incident severity (r=0.863, p<0.001),
enabling predictive risk assessment. Our framework integrates three systems:
HYDRA employing six optimization-aware perturbation strategies achieving 89.7%
risk discovery rates, RAVEN providing continuous production monitoring with
92.9% precision and 93.8% recall across 1,748 scenarios, and APEX enabling
risk-aware optimization maintaining 96.6% baseline performance while reducing
latent risks by 59.2%. Evaluation across three testbed environments
demonstrates strong statistical validation with large effect sizes (Cohen
d>2.0) and exceptional reproducibility (r>0.92). Production deployment over 24
weeks shows 69.1% mean time to recovery reduction, 78.6% incident severity
reduction, and 81 prevented incidents generating 1.44M USD average annual
benefits with 3.2-month ROI. Our approach transforms reliability engineering
from reactive incident management to proactive risk-aware optimization.

</details>


### [13] [APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents](https://arxiv.org/abs/2510.03743)
*Zachary Eberhart,Collin McMillan*

Main category: cs.SE

TL;DR: APIDA-Chat是一个开源管道，可将符号对话行为脚本转换为现实的API搜索对话，用于廉价训练数据生成，解决小众API对话数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型助手在解释流行API时表现良好，但在小众或专有库上表现不佳，因为用于微调的多轮对话数据稀缺。

Method: 采用两阶段方法：第一阶段使用传统对话规划器与教师LLM合成黄金对话集，然后微调较小的学生模型；第二阶段复用规划器与微调后的模型，实现低成本对话合成。

Result: 微调后的学生模型BLEU从0.38提升至0.50，BERTScore从0.88提升至0.91，且可在单个消费级GPU上运行。

Conclusion: APIDA-Chat提供了一个模块化、开源的解决方案，可作为未来工作的保守基准，有效解决小众API对话数据生成问题。

Abstract: Large-language-model assistants are suitable for explaining popular APIs, yet
they falter on niche or proprietary libraries because the multi-turn dialogue
data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source
pipeline that converts symbolic dialogue-act "scripts" into realistic,
domain-grounded API Search conversations using a lightweight model for
inexpensive training data generation. Phase I pairs a legacy dialogue planner
with a high-capability teacher LLM (o4-mini) to synthesize a "gold set" of
realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on
this corpus. Phase II drops the teacher and reuses the same planner with the
fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without
exposing source code to external services. The fine-tuned student improves BLEU
from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while
running entirely on a single consumer GPU. All components are modular and
publicly released to serve as a conservative baseline for future work.
APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a
video demo is available at https://youtu.be/YqmZBHyGbPs .

</details>


### [14] [Code4MeV2: a Research-oriented Code-completion Platform](https://arxiv.org/abs/2510.03755)
*Roham Koohestani,Parham Bateni,Aydin Ebrahimi,Behdad Etezadi,Kiarash Karimi,Maliheh Izadi*

Main category: cs.SE

TL;DR: Code4MeV2是一个面向研究的开源代码补全插件，采用客户端-服务器架构，提供内联代码补全和上下文感知聊天助手功能，核心贡献是模块化透明的数据收集框架。


<details>
  <summary>Details</summary>
Motivation: AI代码补全工具的用户交互数据通常被大公司私有化，阻碍了学术研究。研究人员需要开发专用平台来研究人机交互，使得可重复研究和大规模数据分析变得不切实际。

Method: 开发了基于JetBrains IDE的开源代码补全插件Code4MeV2，采用客户端-服务器架构，包含内联代码补全和上下文感知聊天助手，重点是模块化透明的数据收集框架。

Result: Code4MeV2在代码补全方面达到业界可比性能，平均延迟200ms。通过专家评估和8名参与者的用户研究验证了工具的有效性，获得了研究人员和日常用户的积极反馈。

Conclusion: Code4MeV2解决了AI代码补全工具数据私有化的问题，为学术研究提供了开放平台，邀请社区采用和贡献。

Abstract: The adoption of AI-powered code completion tools in software development has
increased substantially, yet the user interaction data produced by these
systems remain proprietary within large corporations. This creates a barrier
for the academic community, as researchers must often develop dedicated
platforms to conduct studies on human--AI interaction, making reproducible
research and large-scale data analysis impractical. In this work, we introduce
Code4MeV2, a research-oriented, open-source code completion plugin for
JetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a
client--server architecture and features inline code completion and a
context-aware chat assistant. Its core contribution is a modular and
transparent data collection framework that gives researchers fine-grained
control over telemetry and context gathering. Code4MeV2 achieves
industry-comparable performance in terms of code completion, with an average
latency of 200~ms. We assess our tool through a combination of an expert
evaluation and a user study with eight participants. Feedback from both
researchers and daily users highlights its informativeness and usefulness. We
invite the community to adopt and contribute to this tool. More information
about the tool can be found at https://app.code4me.me.

</details>


### [15] [A First Look at the Lifecycle of DL-Specific Self-Admitted Technical Debt](https://arxiv.org/abs/2510.03802)
*Gilberto Recupito,Vincenzo De Martino,Dario Di Nucci,Fabio Palomba*

Main category: cs.SE

TL;DR: 本研究分析了深度学习系统中自承认技术债务的生命周期模式，发现DL-specific SATD主要在项目早期和中期引入，训练和硬件阶段的技术债务持续时间最长。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统的快速发展带来了独特的软件质量挑战，特别是自承认技术债务对系统可维护性的影响。目前对DL-specific SATD的生命周期模式了解不足，需要研究开发者如何引入、承认和解决这些技术债务。

Method: 使用软件仓库挖掘技术，分析了40个机器学习项目中的185个DL-specific SATD实例，通过项目提交历史追踪技术债务的引入和持续性。

Result: DL-specific SATD主要在项目开发早期和中期引入；训练和硬件阶段的技术债务持续时间最长；开发者在功能实现和bug修复时更频繁地引入DL-specific SATD。

Conclusion: 需要针对深度学习系统制定专门的SATD管理策略，理解DL-specific SATD的时间特性和演化规律有助于在关键阶段优先干预，提升系统可维护性和质量。

Abstract: The rapid adoption of Deep Learning (DL)-enabled systems has revolutionized
software development, driving innovation across various domains. However, these
systems also introduce unique challenges, particularly in maintaining software
quality and performance. Among these challenges, Self-Admitted Technical Debt
(SATD) has emerged as a growing concern, significantly impacting the
maintainability and overall quality of ML and DL-enabled systems. Despite its
critical implications, the lifecycle of DL-specific SATD, how developers
introduce, acknowledge, and address it over time-remains underexplored. This
study presents a preliminary analysis of the persistence and lifecycle of
DL-specific SATD in DL-enabled systems. The purpose of this project is to
uncover the patterns of SATD introduction, recognition, and durability during
the development life cycle, providing information on how to manage these
issues. Using mining software repository techniques, we examined 40 ML
projects, focusing on 185 DL-specific SATD instances. The analysis tracked the
introduction and persistence of SATD instances through project commit histories
to assess their lifecycle and developer actions. The findings indicate that
DL-specific SATD is predominantly introduced during the early and middle stages
of project development. Training and Hardware phases showed the longest SATD
durations, highlighting critical areas where debt accumulates and persists.
Additionally, developers introduce DL-specific SATD more frequently during
feature implementation and bug fixes. This study emphasizes the need for
targeted DL-specific SATD management strategies in DL-enabled systems to
mitigate its impact. By understanding the temporal characteristics and
evolution of DL-specific SATD, developers can prioritize interventions at
critical stages to improve the maintainability and quality of the system.

</details>


### [16] [Smart Paste: Automatically Fixing Copy/Paste for Google Developers](https://arxiv.org/abs/2510.03843)
*Vincent Nguyen,Guilherme Herzog,José Cambronero,Marcus Revaj,Aditya Kini,Alexander Frömmgen,Maxim Tabachnyk*

Main category: cs.SE

TL;DR: 开发了Smart Paste IDE功能，通过深度学习预测粘贴代码后的编辑需求，在Google内部部署后获得45%接受率，占公司代码总量的1%以上


<details>
  <summary>Details</summary>
Motivation: 手动编辑粘贴代码是开发者长期痛点，Google内部数据显示代码粘贴频率是手动输入的4倍，且经常需要后续编辑

Method: 迭代开发和规模化Smart Paste IDE功能，涵盖用户体验、系统集成和模型能力，使用深度学习预测粘贴后的编辑需求

Result: 部署后获得压倒性积极反馈，45%的接受率，在Google企业规模下，这些接受的建议占公司所有代码的1%以上

Conclusion: Smart Paste成功展示了AI从业者如何从用户体验、系统集成和模型能力等方面全面开发功能的经验指南

Abstract: Manually editing pasted code is a long-standing developer pain point. In
internal software development at Google, we observe that code is pasted 4 times
more often than it is manually typed. These paste actions frequently require
follow-up edits, ranging from simple reformatting and renaming to more complex
style adjustments and cross-language translations. Prior work has shown deep
learning can be used to predict these edits. In this work, we show how to
iteratively develop and scale Smart Paste, an IDE feature for post-paste edit
suggestions, to Google's development environment. This experience can serve as
a guide for AI practitioners on a holistic approach to feature development,
covering user experience, system integration, and model capabilities. Since
deployment, Smart Paste has had overwhelmingly positive feedback with a 45%
acceptance rate. At Google's enterprise scale, these accepted suggestions
account substantially for over 1% of all code written company-wide.

</details>


### [17] [Designing Empirical Studies on LLM-Based Code Generation: Towards a Reference Framework](https://arxiv.org/abs/2510.03862)
*Nathalia Nascimento,Everton Guimaraes,Paulo Alencar*

Main category: cs.SE

TL;DR: 提出了一个用于设计和报告基于LLM代码生成实证研究的理论框架，旨在解决当前评估标准化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的代码生成实证评估缺乏标准化，不同研究在目标、任务和指标上差异很大，限制了可比性和可重复性。

Method: 基于作者先前经验和近期研究的比较分析，构建了一个围绕问题来源、质量属性和指标等核心组件组织的理论框架。

Result: 通过代表性案例映射展示了框架的适用性，并识别了改进机会。

Conclusion: 该框架为标准化LLM在软件工程背景下的评估提供了基础，未来计划将其发展为更成熟的标准化工具体系。

Abstract: The rise of large language models (LLMs) has introduced transformative
potential in automated code generation, addressing a wide range of software
engineering challenges. However, empirical evaluation of LLM-based code
generation lacks standardization, with studies varying widely in goals, tasks,
and metrics, which limits comparability and reproducibility. In this paper, we
propose a theoretical framework for designing and reporting empirical studies
on LLM-based code generation. The framework is grounded in both our prior
experience conducting such experiments and a comparative analysis of key
similarities and differences among recent studies. It organizes evaluation
around core components such as problem sources, quality attributes, and
metrics, supporting structured and systematic experimentation. We demonstrate
its applicability through representative case mappings and identify
opportunities for refinement. Looking forward, we plan to evolve the framework
into a more robust and mature tool for standardizing LLM evaluation across
software engineering contexts.

</details>


### [18] [Adversarial Agent Collaboration for C to Rust Translation](https://arxiv.org/abs/2510.03879)
*Tianyu Li,Ruishi Li,Bo Wang,Brandon Paulsen,Umang Mathur,Prateek Saxena*

Main category: cs.SE

TL;DR: ACToR是一个基于LLM代理的C到Rust翻译器，通过生成器和判别器代理的对抗协作，能够在零人工干预下成功翻译平均485行代码的63个真实世界命令行工具，测试通过率超过90%。


<details>
  <summary>Details</summary>
Motivation: 现有C到安全Rust的翻译方法（包括LLM辅助方法）无法处理大型（>500行）C代码库，因为它们依赖复杂的程序分析且经常失败。

Method: 受GANs启发，ACToR让生成器代理和判别器代理对抗协作：生成器代理合成并优化Rust翻译以通过现有测试套件，判别器代理则寻找新的失败测试，迭代改进翻译。

Result: ACToR成功翻译了所有63个真实世界命令行工具（平均485行代码），测试通过率超过90%，且比非对抗基线方法提高了18.9%的正确性。

Conclusion: ACToR是首个能够可靠翻译这种规模C程序的系统，为将遗留C代码迁移到内存安全语言提供了可行方案。

Abstract: Translating C to memory-safe languages, like Rust, prevents critical memory
safety vulnerabilities that are prevalent in legacy C software. Existing
approaches for C to safe Rust translation, including LLM-assisted ones, do not
generalize on larger (> 500 LoC) C codebases because they depend on complex
program analyses that frequently break. In this work, we present ACToR
(Adversarial C To Rust translator), a simple LLM agent-based approach. Inspired
by GANs, ACToR pits a generator agent against a discriminator agent, which
collaborate to iteratively generate a Rust translation. On each iteration, the
translator agent synthesizes and refines a Rust translation to pass an existing
suite of tests, and then the discriminator agent finds new failing tests. We
demonstrate that ACToR translates all of the 63 real-world command line
utilities considered in our benchmarks, which have an average size of 485 lines
of code, and it achieves over 90% test pass rate with zero human intervention.
To our knowledge, it is the first such system that reliably translates C
programs of this scale. Furthermore, ACToR improves translation correctness by
up to 18.9% compared to baseline, non-adversarial approaches.

</details>


### [19] [Rethinking Services in the Quantum Age: The SOQ Paradigm](https://arxiv.org/abs/2510.03890)
*Jose Garcia-Alonso,Enrique Moguel,Jaime Alvarado-Valiente,Javier Romero-Alvarez,Álvaro M. Aparicio-Morales,Juan M. Murillo,Francisco Javier Cavero,Adrián Romero-Flores,Alfonso E. Marquez-Chamorro,José Antonio Parejo,Antonio Ruiz-Cortés,Giuseppe Bisicchia,Alessandro Bocci,Antonio Brogi*

Main category: cs.SE

TL;DR: 本文提出面向服务的量子计算（SOQ）新范式，将量子服务重新构想为自主、可组合和可互操作的实体，通过经典面向服务计算的视角来构建量子软件系统。


<details>
  <summary>Details</summary>
Motivation: 量子计算从理论承诺向实际应用发展，但在集成到现实软件系统时面临硬件脆弱性、平台异构性和缺乏稳健软件工程实践的约束。

Method: 定义SOQ的基本原则，提出支持其实现的分层技术栈，识别需要解决的关键研究和工程挑战，包括互操作性、混合性、定价模型、服务抽象和劳动力发展。

Result: SOQ范式能够实现量子计算到现实软件系统的可扩展、模块化和可互操作集成，无需依赖专用经典环境来管理量子处理。

Conclusion: SOQ方法对于量子技术进步至关重要，因为它使量子计算能够独立且无需依赖专用经典环境地集成到现实软件系统中。

Abstract: Quantum computing is rapidly progressing from theoretical promise to
practical implementation, offering significant computational advantages for
tasks in optimization, simulation, cryptography, and machine learning. However,
its integration into real-world software systems remains constrained by
hardware fragility, platform heterogeneity, and the absence of robust software
engineering practices. This paper introduces Service-Oriented Quantum (SOQ), a
novel paradigm that reimagines quantum software systems through the lens of
classical service-oriented computing. Unlike prior approaches such as Quantum
Service-Oriented Computing (QSOC), which treat quantum capabilities as
auxiliary components within classical systems, SOQ positions quantum services
as autonomous, composable, and interoperable entities. We define the
foundational principles of SOQ, propose a layered technology stack to support
its realization, and identify the key research and engineering challenges that
must be addressed, including interoperability, hybridity, pricing models,
service abstractions, and workforce development. This approach is of vital
importance for the advancement of quantum technology because it enables the
scalable, modular, and interoperable integration of quantum computing into
real-world software systems independently and without relying on a dedicated
classical environment to manage quantum processing.

</details>


### [20] [A Brief History of the Waterfall Model: Past, Present, and Future](https://arxiv.org/abs/2510.03894)
*Antonios Saravanos*

Main category: cs.SE

TL;DR: 对瀑布模型的历史回顾和批判性分析，探讨其从独立框架到现代混合方法组件的演变，强调其持续相关性和适应性。


<details>
  <summary>Details</summary>
Motivation: 重新评估瀑布模型在当代软件开发中的价值，挑战其作为过时方法的刻板印象，展示其在特定领域和混合方法中的持续影响力。

Method: 基于学术文献的历史分析，追溯瀑布模型的概念起源、Royce的形式化定义，以及数十年行业采用和批判的演变过程。

Result: 瀑布模型已从独立框架转变为现代混合开发方法的重要组成部分，其原则继续影响结合传统和敏捷方法的当代框架。

Conclusion: 瀑布模型仍然具有相关性，不是作为过去的遗物，而是作为情境感知开发策略的一部分，其持久相关性在于其适应性。

Abstract: The waterfall model, one of the earliest software development methodologies,
has played a foundational role in shaping contemporary software engineering
practices. This paper provides a historical and critical overview of the model,
tracing its conceptual origins in software engineering, its formalization by
Royce, and its evolution through decades of industry adoption and critique.
Although often criticized for its rigidity, shortcomings, and high failure
rates, the waterfall model persists in specific domains. Its principles
continue to influence contemporary hybrid development frameworks that combine
traditional and agile methods. Drawing on a range of scholarly sources, this
study synthesizes key developments in the perception and application of the
waterfall model. The analysis highlights how the model has shifted from a
standalone framework to a component within modern hybrid methodologies. By
revisiting its origins, assessing its present utility, and examining its role
in contemporary development practices, this paper argues that the waterfall
model remains relevant, not as a relic of the past but as part of context-aware
development strategies. The paper contends that the model's enduring relevance
lies in its adaptability. By recognizing both its limitations and its
strengths, and by understanding its integration within hybrid approaches,
practitioners can make more informed decisions about methodology selection and
process design in diverse development environments.

</details>


### [21] [Multi-Agent Code-Orchestrated Generation for Reliable Infrastructure-as-Code](https://arxiv.org/abs/2510.03902)
*Rana Nameer Hussain Khan,Dawood Wasif,Jin-Hee Cho,Ali Butt*

Main category: cs.SE

TL;DR: MACOG是一个基于多智能体LLM的IaC生成架构，通过分解任务为模块化子任务，由专门智能体协作生成符合语法、策略和语义的Terraform配置。


<details>
  <summary>Details</summary>
Motivation: 传统LLM的单次生成方法在IaC生成中常导致语法错误、策略违规和不可扩展设计，需要更可靠的解决方案。

Method: 采用多智能体架构，包括架构师、提供商协调器、工程师、审查员、安全验证员、成本容量规划师、DevOps和记忆管理员，通过共享黑板和有限状态协调器进行交互。

Result: 在IaC-Eval基准测试中表现优异，GPT-5从54.90提升到74.02，Gemini-2.5 Pro从43.56提升到60.13，在BLEU、CodeBERTScore和LLM-judge指标上均有提升。

Conclusion: MACOG通过多智能体协作和约束解码、部署反馈等机制，显著提升了IaC生成的质量和可靠性。

Abstract: The increasing complexity of cloud-native infrastructure has made
Infrastructure-as-Code (IaC) essential for reproducible and scalable
deployments. While large language models (LLMs) have shown promise in
generating IaC snippets from natural language prompts, their monolithic,
single-pass generation approach often results in syntactic errors, policy
violations, and unscalable designs. In this paper, we propose MACOG
(Multi-Agent Code-Orchestrated Generation), a novel multi-agent LLM-based
architecture for IaC generation that decomposes the task into modular subtasks
handled by specialized agents: Architect, Provider Harmonizer, Engineer,
Reviewer, Security Prover, Cost and Capacity Planner, DevOps, and Memory
Curator. The agents interact via a shared-blackboard, finite-state orchestrator
layer, and collectively produce Terraform configurations that are not only
syntactically valid but also policy-compliant and semantically coherent. To
ensure infrastructure correctness and governance, we incorporate Terraform Plan
for execution validation and Open Policy Agent (OPA) for customizable policy
enforcement. We evaluate MACOG using the IaC-Eval benchmark, where MACOG is the
top enhancement across models, e.g., GPT-5 improves from 54.90 (RAG) to 74.02
and Gemini-2.5 Pro from 43.56 to 60.13, with concurrent gains on BLEU,
CodeBERTScore, and an LLM-judge metric. Ablations show constrained decoding and
deploy feedback are critical: removing them drops IaC-Eval to 64.89 and 56.93,
respectively.

</details>


### [22] [Refactoring with LLMs: Bridging Human Expertise and Machine Understanding](https://arxiv.org/abs/2510.03914)
*Yonnel Chen Kuang Piao,Jean Carlors Paul,Leuson Da Silva,Arghavan Moradi Dakhel,Mohammad Hamdaqa,Foutse Khomh*

Main category: cs.SE

TL;DR: 本研究探索基于人类最佳实践指南的指令策略能否增强大语言模型执行多样化代码重构任务的能力，结果表明基于Fowler指南的指令设计能让LLMs成功执行所有基准重构类型并在真实场景中保持程序语义。


<details>
  <summary>Details</summary>
Motivation: 代码重构是提高代码质量和可维护性的重要实践，但开发者常因时间、精力和资源投入大且缺乏即时功能回报而忽视重构。现有自动化重构工具对广泛重构类型的支持有限。

Method: 利用最先进LLMs的指令跟随和代码理解能力，基于Martin Fowler的重构指南设计多种指令策略，编码61种知名重构类型的动机、步骤和转换目标，并在基准示例和GitHub真实代码片段上评估。

Result: 基于Fowler指南的指令设计使LLMs能成功执行所有基准重构类型，并在真实环境中保持程序语义。规则化指令在特定场景表现更好，而允许模型关注重构整体目标而非固定转换类型能带来更大代码质量提升。

Conclusion: 基于人类最佳实践指南的指令策略能有效增强LLMs执行多样化代码重构任务的能力，为自动化代码重构提供了新途径。

Abstract: Code refactoring is a fundamental software engineering practice aimed at
improving code quality and maintainability. Despite its importance, developers
often neglect refactoring due to the significant time, effort, and resources it
requires, as well as the lack of immediate functional rewards. Although several
automated refactoring tools have been proposed, they remain limited in
supporting a broad spectrum of refactoring types. In this study, we explore
whether instruction strategies inspired by human best-practice guidelines can
enhance the ability of Large Language Models (LLMs) to perform diverse
refactoring tasks automatically. Leveraging the instruction-following and code
comprehension capabilities of state-of-the-art LLMs (e.g., GPT-mini and
DeepSeek-V3), we draw on Martin Fowler's refactoring guidelines to design
multiple instruction strategies that encode motivations, procedural steps, and
transformation objectives for 61 well-known refactoring types. We evaluate
these strategies on benchmark examples and real-world code snippets from GitHub
projects. Our results show that instruction designs grounded in Fowler's
guidelines enable LLMs to successfully perform all benchmark refactoring types
and preserve program semantics in real-world settings, an essential criterion
for effective refactoring. Moreover, while descriptive instructions are more
interpretable to humans, our results show that rule-based instructions often
lead to better performance in specific scenarios. Interestingly, allowing
models to focus on the overall goal of refactoring, rather than prescribing a
fixed transformation type, can yield even greater improvements in code quality.

</details>


### [23] [Why Does the Engineering Manager Still Exist in Agile Software Development?](https://arxiv.org/abs/2510.03920)
*Ravi Kalluri*

Main category: cs.SE

TL;DR: 尽管敏捷方法强调去中心化决策和团队自主，但工程经理在敏捷软件组织中仍然存在，这反映了传统管理职能在敏捷环境中的持续必要性。


<details>
  <summary>Details</summary>
Motivation: 探索敏捷组织中工程经理持续存在的现象，揭示敏捷理论与组织现实之间的张力，理解管理角色在敏捷环境中的演变。

Method: 采用系统性文献综述方法，辅以案例研究，构建包含历史背景、理论张力、组织现实、实证证据等多维度的分析框架。

Result: 发现工程经理在敏捷组织中持续发挥重要作用，提出了一个概念模型来调和敏捷原则与管理必要性。

Conclusion: 提出了一个调和敏捷原则与管理必要性的概念模型，为从业者、研究人员和工具设计者提供指导，并讨论了领导力发展、工具集成和未来研究的影响。

Abstract: Although Agile methodologies emphasize decentralized decision-making and team
autonomy, engineering managers continue to be employed in Agile software
organizations. This apparent paradox suggests that traditional managerial
functions persist despite the theoretical displacement of managerial hierarchy
in Agile. This paper explores the persistence of engineering managers through a
multidimensional framework encompassing historical context, theoretical
tensions, organizational realities, empirical evidence, evolving managerial
roles, and practical implications. A systematic literature review underpins our
multifaceted analysis, supplemented by illustrative case studies. We conclude
by proposing a conceptual model that reconciles Agile principles with
managerial necessity, offering guidance for practitioners, researchers, and
tool designers. Implications for leadership development, tool integration, and
future research are discussed.

</details>


### [24] [Bamboo: LLM-Driven Discovery of API-Permission Mappings in the Android Framework](https://arxiv.org/abs/2510.04078)
*Han Hu,Wei Minn,Yonghui Liu,Jiakun Liu,Ferdian Thung,Terry Yue Zhuo,Lwin Khin Shar,Debin Gao,David Lo*

Main category: cs.SE

TL;DR: 本文提出了一种使用大型语言模型(LLMs)来系统分析Android API权限映射的新方法，开发了相应工具，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: Android官方API文档存在不精确和不完整的问题，导致开发者难以准确识别必要权限，可能引发安全漏洞和应用故障。现有方法在适应Android更新、代码覆盖率和复杂代码库方面存在不足。

Method: 采用大型语言模型(LLMs)，结合双重角色提示策略和API驱动的代码生成方法，构建API权限映射发现流程。

Result: 在Android版本6、7和10中分别识别出2,234、3,552和4,576个API权限映射，显著优于现有基线方法。

Conclusion: 基于LLM的方法能够有效解决Android API权限映射识别问题，为开发者提供更准确的权限指导，提升应用安全性。

Abstract: The permission mechanism in the Android Framework is integral to safeguarding
the privacy of users by managing users' and processes' access to sensitive
resources and operations. As such, developers need to be equipped with an
in-depth understanding of API permissions to build robust Android apps.
Unfortunately, the official API documentation by Android chronically suffers
from imprecision and incompleteness, causing developers to spend significant
effort to accurately discern necessary permissions. This potentially leads to
incorrect permission declarations in Android app development, potentially
resulting in security violations and app failures. Recent efforts in improving
permission specification primarily leverage static and dynamic code analyses to
uncover API-permission mappings within the Android framework. Yet, these
methodologies encounter substantial shortcomings, including poor adaptability
to Android SDK and Framework updates, restricted code coverage, and a
propensity to overlook essential API-permission mappings in intricate
codebases. This paper introduces a pioneering approach utilizing large language
models (LLMs) for a systematic examination of API-permission mappings. In
addition to employing LLMs, we integrate a dual-role prompting strategy and an
API-driven code generation approach into our mapping discovery pipeline,
resulting in the development of the corresponding tool, \tool{}. We formulate
three research questions to evaluate the efficacy of \tool{} against
state-of-the-art baselines, assess the completeness of official SDK
documentation, and analyze the evolution of permission-required APIs across
different SDK releases. Our experimental results reveal that \tool{} identifies
2,234, 3,552, and 4,576 API-permission mappings in Android versions 6, 7, and
10 respectively, substantially outprforming existing baselines.

</details>


### [25] [GA4GC: Greener Agent for Greener Code via Multi-Objective Configuration Optimization](https://arxiv.org/abs/2510.04135)
*Jingzhi Gong,Yixin Bian,Luis de la Cal,Giovanni Pinna,Anisha Uteem,David Williams,Mar Zamorano,Karine Even-Mendoza,W. B. Langdon,Hector Menendez,Federica Sarro*

Main category: cs.SE

TL;DR: GA4GC框架通过发现帕累托最优的代理超参数和提示模板，系统优化编码代理的运行时间与代码性能之间的权衡，实现高达135倍的超体积改进，减少37.7%的代理运行时间同时提高正确性。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的编码代理在工业部署中面临可持续性和可扩展性挑战，单次运行消耗超过10万token，环境成本可能超过优化收益。

Method: 引入GA4GC框架，系统优化编码代理运行时间（更环保的代理）和代码性能（更环保的代码）的权衡，通过发现帕累托最优的代理超参数和提示模板。

Result: 在SWE-Perf基准测试中实现高达135倍的超体积改进，减少37.7%的代理运行时间同时提高正确性。温度被确定为最关键的超参数。

Conclusion: 研究结果为工业部署中平衡代理可持续性与代码优化效果提供了可行的策略，温度是最关键的超参数。

Abstract: Coding agents powered by LLMs face critical sustainability and scalability
challenges in industrial deployment, with single runs consuming over 100k
tokens and incurring environmental costs that may exceed optimization benefits.
This paper introduces GA4GC, the first framework to systematically optimize
coding agent runtime (greener agent) and code performance (greener code)
trade-offs by discovering Pareto-optimal agent hyperparameters and prompt
templates. Evaluation on the SWE-Perf benchmark demonstrates up to 135x
hypervolume improvement, reducing agent runtime by 37.7% while improving
correctness. Our findings establish temperature as the most critical
hyperparameter, and provide actionable strategies to balance agent
sustainability with code optimization effectiveness in industrial deployment.

</details>


### [26] [Detecting Semantic Clones of Unseen Functionality](https://arxiv.org/abs/2510.04143)
*Konstantinos Kitsios,Francesco Sovrano,Earl T. Barr,Alberto Bacchelli*

Main category: cs.SE

TL;DR: 该论文研究了语义代码克隆检测中模型对未见功能克隆的泛化能力问题，发现现有模型在检测未见功能克隆时性能显著下降，并提出使用对比学习方法来提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经模型在语义代码克隆检测任务上虽然表现优异，但主要依赖于训练数据中的相似克隆，对于未见功能的克隆检测能力较差。开发者需要检测所有类型的克隆，包括未见功能的克隆。

Method: 重新评估了6个最先进的模型（包括任务特定模型和生成式LLM）在未见功能克隆检测上的表现，并提出使用对比学习：对于任务特定模型替换最终分类器为对比分类器，对于LLM提出对比上下文学习。

Result: 任务特定模型在未见功能克隆检测上F1下降高达48%（平均31%），LLM表现与任务特定模型相当但泛化更好（F1下降最多5%，平均3%）。使用对比学习后，任务特定模型F1提升高达26%（平均9%），LLM提升高达5%（平均3%）。

Conclusion: 当前代码克隆检测模型对未见功能的泛化能力有限，对比学习能有效提升模型在未见功能克隆检测上的性能，特别是对于任务特定模型效果显著。

Abstract: Semantic code clone detection is the task of detecting whether two snippets
of code implement the same functionality (e.g., Sort Array). Recently, many
neural models achieved near-perfect performance on this task. These models seek
to make inferences based on their training data. Consequently, they better
detect clones similar to those they have seen during training and may struggle
to detect those they have not. Developers seeking clones are, of course,
interested in both types of clones. We confirm this claim through a literature
review, identifying three practical clone detection tasks in which the model's
goal is to detect clones of a functionality even if it was trained on clones of
different functionalities. In light of this finding, we re-evaluate six
state-of-the-art models, including both task-specific models and generative
LLMs, on the task of detecting clones of unseen functionality. Our experiments
reveal a drop in F1 of up to 48% (average 31%) for task-specific models. LLMs
perform on par with task-specific models without explicit training for clone
detection, but generalize better to unseen functionalities, where F1 drops up
to 5% (average 3%) instead. We propose and evaluate the use of contrastive
learning to improve the performance of existing models on clones of unseen
functionality. We draw inspiration from the computer vision and natural
language processing fields where contrastive learning excels at measuring
similarity between two objects, even if they come from classes unseen during
training. We replace the final classifier of the task-specific models with a
contrastive classifier, while for the generative LLMs we propose contrastive
in-context learning, guiding the LLMs to focus on the differences between
clones and non-clones. The F1 on clones of unseen functionality is improved by
up to 26% (average 9%) for task-specific models and up to 5% (average 3%) for
LLMs.

</details>


### [27] [Multi Language Models for On-the-Fly Syntax Highlighting](https://arxiv.org/abs/2510.04166)
*Marco Edoardo Palma,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: 提出了一种统一的语法高亮模型，可同时处理6种主流编程语言，通过新颖的归一化技术和少样本学习减少对暴力生成器的依赖，降低部署复杂度并提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习语法高亮模型存在单语言限制、依赖大型数据集和资源密集型训练的问题，在多语言环境中需要维护多个独立模型，增加了系统复杂性和运营成本。

Method: 采用统一模型架构支持多语言语法高亮，引入新颖的归一化技术增强模型泛化能力，通过少样本学习减少对暴力生成器大型数据集的依赖。

Result: 实现了支持6种主流编程语言的统一语法高亮模型，部署复杂度降低6倍，在未见语言上表现更好，少量样本即可替代大型数据集。

Conclusion: 该创新方法实现了跨多种编程语言的高效、可扩展且成本效益高的语法高亮，解决了现有模型的局限性。

Abstract: Syntax highlighting is a critical feature in modern software development
environments, enhancing code readability and developer productivity. However,
delivering accurate highlighting in real time remains challenging for online
and web-based development tools due to strict time and memory constraints on
backend services. These systems must serve highlights rapidly and frequently,
even when code is partially valid or invalid. This has led to on-the-fly syntax
highlighting, where visual annotations are generated just before content is
served, often at high request rates and under incomplete input conditions. To
meet these demands efficiently, state-of-the-art models use deep learning to
learn the behavior of brute-force syntax highlighting resolvers, tools that are
easy to implement but too slow for production. Through the Deep Abstraction
process, brute-force strategies are encoded into fast statistical models that
achieve both high accuracy and low-latency inference. Despite their success,
such models face key challenges: they support only one programming language per
model, require large datasets from slow brute-force generators, and involve
resource-intensive training. In multi-language environments, this means
maintaining multiple independent models, increasing system complexity and
operational cost. This work addresses these issues by introducing a unified
model capable of highlighting up to six mainstream programming languages,
reducing deployment complexity by a factor of six and improving performance on
unseen languages. A novel normalization technique significantly enhances model
generalization, while few-shot learning experiments show that a small number of
oracle samples can replace large datasets, minimizing dependence on brute-force
generators. Combined, these innovations enable efficient, scalable, and
cost-effective syntax highlighting across diverse programming languages.

</details>


### [28] [Selecting Cybersecurity Requirements: Effects of LLM Use and Professional Software Development Experience](https://arxiv.org/abs/2510.04274)
*Damjan Fujs,Damjan Vavpotič,Tomaž Hovelja,Marko Poženel*

Main category: cs.SE

TL;DR: 研究探讨了LLM访问权限和专业软件开发经验对网络安全需求优先级排序的影响，发现LLM使用无显著差异，但经验水平在成本、用户体验和风险评估方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型访问权限和不同专业软件开发经验水平如何影响网络安全需求的优先级排序决策。

Method: 23名研究生参与研究，使用MoSCoW方法对安全需求进行优先级排序，分为有LLM支持组和无LLM支持组，评估多个标准。

Result: LLM使用组间无显著差异，但经验组间在开发成本估算、用户体验影响感知和风险评估方面存在统计显著差异。有经验参与者倾向于给用户体验影响更高评分，风险估计更低。

Conclusion: LLM访问权限不影响网络安全解决方案评估，但专业经验在成本、用户体验和风险评估决策中起重要作用。

Abstract: This study investigates how access to Large Language Models (LLMs) and
varying levels of professional software development experience affect the
prioritization of cybersecurity requirements for web applications. Twenty-three
postgraduate students participated in a research study to prioritize security
requirements (SRs) using the MoSCoW method and subsequently rated their
proposed solutions against multiple evaluation criteria. We divided
participants into two groups (one with and the other without access to LLM
support during the task). Results showed no significant differences related to
LLM use, suggesting that access to LLMs did not noticeably influence how
participants evaluated cybersecurity solutions. However, statistically
significant differences emerged between experience groups for certain criteria,
such as estimated cost to develop a feature, perceived impact on user
experience, and risk assessment related to non-implementation of the proposed
feature. Participants with more professional experience tended to provide
higher ratings for user experience impact and lower risk estimates.

</details>


### [29] [Challenge on Optimization of Context Collection for Code Completion](https://arxiv.org/abs/2510.04349)
*Dmitry Ustalov,Egor Bogomolov,Alexander Bezzubov,Yaroslav Golubev,Evgeniy Glukhov,Georgii Levtsov,Vladimir Kovalenko*

Main category: cs.SE

TL;DR: 该论文介绍了JetBrains与Mistral AI在ASE 2025会议上组织的代码完成上下文收集优化挑战赛，参与者开发了从源代码仓库高效收集上下文的机制，以改进Python和Kotlin的填充式代码补全。


<details>
  <summary>Details</summary>
Motivation: 随着AI在软件工程中的工作流和方法快速发展，需要系统评估它们从整个项目中利用信息的能力，特别是在大型代码库中。

Method: 构建了基于许可开源项目的Python和Kotlin真实代码大型数据集，参与者开发上下文收集机制，使用chrF指标评估多个最先进神经模型的补全质量。

Result: 公开阶段有19个团队提交Python解决方案，8个团队提交Kotlin解决方案；私有阶段有6个团队竞争，其中5个团队向研讨会提交了论文。

Conclusion: 该挑战赛成功推动了代码补全上下文收集机制的研究，为优化大型代码库中的AI辅助代码完成提供了重要基准。

Abstract: The rapid advancement of workflows and methods for software engineering using
AI emphasizes the need for a systematic evaluation and analysis of their
ability to leverage information from entire projects, particularly in large
code bases. In this challenge on optimization of context collection for code
completion, organized by JetBrains in collaboration with Mistral AI as part of
the ASE 2025 conference, participants developed efficient mechanisms for
collecting context from source code repositories to improve fill-in-the-middle
code completions for Python and Kotlin. We constructed a large dataset of
real-world code in these two programming languages using permissively licensed
open-source projects. The submissions were evaluated based on their ability to
maximize completion quality for multiple state-of-the-art neural models using
the chrF metric. During the public phase of the competition, nineteen teams
submitted solutions to the Python track and eight teams submitted solutions to
the Kotlin track. In the private phase, six teams competed, of which five
submitted papers to the workshop.

</details>


### [30] [MacroBench: A Novel Testbed for Web Automation Scripts via Large Language Models](https://arxiv.org/abs/2510.04363)
*Hyunjun Kim,Sejong Kim*

Main category: cs.SE

TL;DR: MacroBench是一个评估LLM从自然语言目标生成可复用浏览器自动化程序能力的代码优先基准测试，包含7个自托管网站和681个任务，通过端到端验证协议测试模型性能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型能否通过阅读HTML/DOM并生成Python+Selenium代码来合成可复用的浏览器自动化程序，填补现有基准测试在web自动化宏合成评估方面的空白。

Method: 创建包含7个自托管网站的基准测试（Airbnb、TikTok、Reddit等类似平台），涵盖681个任务，通过静态检查、沙箱执行、DOM断言和数据库快照进行端到端验证，并包含安全测试套件。

Result: 在2636次模型-任务运行中，GPT-4o-Mini达到96.8%成功率，GPT-4.1达95.3%，Gemini-2.5-Pro达89.0%，DeepSeek-V3.1达83.4%。模型在简单任务上可靠（91.7%），但在复杂工作流上完全失败（0.0%）。

Conclusion: 虽然模型在功能完成度上表现良好，但都无法达到生产级编码标准，基准测试框架为web自动化宏合成的可重复评估提供了工具。

Abstract: We introduce MacroBench, a code-first benchmark that evaluates whether LLMs
can synthesize reusable browser automation programs from natural language goals
by reading HTML/DOM and emitting Python with Selenium. MacroBench instantiates
seven self-hosted sites: Airbnb-like, TikTok-like, Reddit-like, Instagram-like,
Facebook-like, Discord-like, and Threads-like, covering 681 tasks across
interaction complexity and targeting difficulty. Our end-to-end protocol
validates generated code via static checks, sandboxed execution, and outcome
verification including DOM assertions and database snapshots, and includes a
safety suite for scraping, spam/abuse, and credential/privacy prompts. Across
2636 model-task runs, we observe stratified success: GPT-4o-Mini achieves 96.8
percent, GPT-4.1 achieves 95.3 percent, Gemini-2.5-Pro achieves 89.0 percent,
and DeepSeek-V3.1 achieves 83.4 percent. Models handle simple tasks reliably at
91.7 percent but fail on complex workflows at 0.0 percent, and none meet
production-quality coding practices despite functional completion. We release
our complete benchmark pipeline, evaluation framework, and experimental results
to enable reproducible assessment of macro synthesis for web automation.

</details>


### [31] [Reconsidering Requirements Engineering: Human-AI Collaboration in AI-Native Software Development](https://arxiv.org/abs/2510.04380)
*Mateen Ahmed Abbasi,Petri Ihantola,Tommi Mikkonen,Niko Mäkitalo*

Main category: cs.SE

TL;DR: 本文探讨人工智能如何改进传统需求工程实践，通过自动化任务、支持需求优先级排序和促进人机协作，同时分析了AI带来的机遇与挑战，强调需要伦理实践和产学研合作。


<details>
  <summary>Details</summary>
Motivation: 需求工程是软件开发成功的基础，但面临模糊性、利益相关者需求冲突和管理复杂性等持续挑战。AI有潜力优化RE流程，但同时也带来伦理、偏见和透明度等新问题。

Method: 探索AI如何增强传统RE实践，包括自动化劳动密集型任务、支持需求优先级排序、促进利益相关者与AI系统之间的协作。

Result: AI能够提高RE过程的效率和准确性，但需要解决伦理问题和建立可信赖的AI解决方案。

Conclusion: 需要在AI应用中强调伦理实践，加强学术界与行业专业人士的合作，创建既强大又可信赖且实用的AI解决方案，以适应快速发展的软件开发世界。

Abstract: Requirement Engineering (RE) is the foundation of successful software
development. In RE, the goal is to ensure that implemented systems satisfy
stakeholder needs through rigorous requirements elicitation, validation, and
evaluation processes. Despite its critical role, RE continues to face
persistent challenges, such as ambiguity, conflicting stakeholder needs, and
the complexity of managing evolving requirements. A common view is that
Artificial Intelligence (AI) has the potential to streamline the RE process,
resulting in improved efficiency, accuracy, and management actions. However,
using AI also introduces new concerns, such as ethical issues, biases, and lack
of transparency. This paper explores how AI can enhance traditional RE
practices by automating labor-intensive tasks, supporting requirement
prioritization, and facilitating collaboration between stakeholders and AI
systems. The paper also describes the opportunities and challenges that AI
brings to RE. In particular, the vision calls for ethical practices in AI,
along with a much-enhanced collaboration between academia and industry
professionals. The focus should be on creating not only powerful but also
trustworthy and practical AI solutions ready to adapt to the fast-paced world
of software development.

</details>


### [32] [Smart Hiring Redefined: An Intelligent Recruitment Management Platform](https://arxiv.org/abs/2510.04437)
*Fangzhe Wu,Dongyang Lyu,Xiaoqi Li*

Main category: cs.SE

TL;DR: 智能招聘管理系统通过自动化和数据驱动方法，显著提升招聘效率和准确性，解决传统招聘模式效率低、成本高和信息不对称的问题。


<details>
  <summary>Details</summary>
Motivation: 传统招聘模式由于效率有限、成本高昂和信息不对称，难以满足企业对精准人才获取的日益增长需求。

Method: 采用自动化和数据驱动方法，实现简历批量快速解析、候选人职位智能匹配和面试流程自动化调度。

Result: 智能招聘系统显著提升了招聘流程的效率和准确性，能够处理海量简历并进行精准匹配。

Conclusion: 智能招聘管理系统是现代组织人才战略中不可或缺的组成部分，能够优化招聘流程、降低人力时间成本并增强核心竞争力。

Abstract: Against the backdrop of deepening digital and intelligent transformation in
human resource management, traditional recruitment models struggle to fully
meet enterprises' growing demand for precise talent acquisition due to limited
efficiency, high costs, and information asymmetry. As a vital tool for
optimizing recruitment processes, reducing labor and time costs, and enhancing
core competitiveness, intelligent recruitment management systems become an
indispensable component of modern organizational talent strategies.Compared
with the labor intensive tasks of resume screening, candidate position
matching, and interview coordination in traditional manual recruitment,
intelligent recruitment systems significantly enhance the efficiency and
accuracy of the hiring process through automation and data driven approaches.
These systems enable rapid parsing of massive resume volumes, intelligent
matching of candidates to positions, and automated scheduling of interview
processes.

</details>


### [33] [Improving IR-based Bug Localization with Semantics-Driven Query Reduction](https://arxiv.org/abs/2510.04468)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: IQLoc是一种结合信息检索和大型语言模型的软件缺陷定位方法，通过利用Transformer模型理解程序语义来改进缺陷定位效果


<details>
  <summary>Details</summary>
Motivation: 现有基于信息检索的缺陷定位方法忽略了源代码的上下文和语义，而大型语言模型虽然能理解文本和代码，但尚未很好地适应缺陷定位任务，且可能计算资源密集

Method: 提出IQLoc方法，结合IR和LLM的优势，利用基于Transformer的模型理解程序语义来推理代码的可疑性，并在缺陷定位过程中使用信息检索重新制定查询

Result: 在包含约7.5K缺陷报告的Bench4BL基准数据集上评估，IQLoc在MAP、MRR和HIT@K指标上显著优于四种基线技术，对于包含堆栈跟踪、代码元素或纯自然语言描述的缺陷报告都有显著改进

Conclusion: 通过将程序语义理解集成到信息检索中，IQLoc缓解了传统基于IR的缺陷定位方法面临的长期挑战

Abstract: Despite decades of research, software bug localization remains challenging
due to heterogeneous content and inherent ambiguities in bug reports. Existing
methods such as Information Retrieval (IR)-based approaches often attempt to
match source documents to bug reports, overlooking the context and semantics of
the source code. On the other hand, Large Language Models (LLM) (e.g.,
Transformer models) show promising results in understanding both texts and
code. However, they have not been yet adapted well to localize software bugs
against bug reports. They could be also data or resource-intensive. To bridge
this gap, we propose, IQLoc, a novel bug localization approach that capitalizes
on the strengths of both IR and LLM-based approaches. In particular, we
leverage the program semantics understanding of transformer-based models to
reason about the suspiciousness of code and reformulate queries during bug
localization using Information Retrieval. To evaluate IQLoc, we refine the
Bench4BL benchmark dataset and extend it by incorporating ~30% more recent bug
reports, resulting in a benchmark containing ~7.5K bug reports. We evaluated
IQLoc using three performance metrics and compare it against four baseline
techniques. Experimental results demonstrate its superiority, achieving up to
58.52% and 60.59% in MAP, 61.49% and 64.58% in MRR, and 69.88% and 100.90% in
HIT@K for the test bug reports with random and time-wise splits, respectively.
Moreover, IQLoc improves MAP by 91.67% for bug reports with stack traces,
72.73% for those that include code elements, and 65.38% for those containing
only descriptions in natural language. By integrating program semantic
understanding into Information Retrieval, IQLoc mitigates several longstanding
challenges of traditional IR-based approaches in bug localization.

</details>


### [34] [DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing](https://arxiv.org/abs/2510.04469)
*Wenqi Yan,Toby Murray,Benjamin Rubinstein,Van-Thuan Pham*

Main category: cs.SE

TL;DR: DynamiQ是一个基于AFLTeam优化的动态自适应并行模糊测试框架，通过程序调用图的结构信息定义任务，利用运行时反馈持续优化任务分配，显著减少冗余探索并提升大规模模糊测试效率。


<details>
  <summary>Details</summary>
Motivation: 现有并行模糊测试方法大多将单个种子视为任务，存在冗余探索问题。需要更智能的任务分配机制来提升大规模模糊测试的效率。

Method: 基于LibAFL框架构建，利用程序调用图的结构信息定义任务，通过运行时反馈持续优化任务分配，并在任务分配和任务感知模糊测试方面实施多项实践优化。

Result: 在12个真实世界目标上经过25,000 CPU小时评估，DynamiQ在代码覆盖率和漏洞发现方面均优于最先进的并行模糊测试工具，发现了9个先前未知的广泛使用且经过大量模糊测试的开源软件漏洞。

Conclusion: DynamiQ通过动态任务分配和结构感知的方法，显著提升了并行模糊测试的效率和效果，证明了基于程序结构信息进行智能任务分配的重要性。

Abstract: We present DynamiQ, a full-fledged and optimized successor to AFLTeam that
supports dynamic and adaptive parallel fuzzing. Unlike most existing approaches
that treat individual seeds as tasks, DynamiQ leverages structural information
from the program's call graph to define tasks and continuously refines task
allocation using runtime feedback. This design significantly reduces redundant
exploration and enhances fuzzing efficiency at scale. Built on top of the
state-of-the-art LibAFL framework, DynamiQ incorporates several practical
optimizations in both task allocation and task-aware fuzzing. Evaluated on 12
real-world targets from OSS-Fuzz and FuzzBench over 25,000 CPU hours, DynamiQ
outperforms state-of-the-art parallel fuzzers in both code coverage and
vulnerability discovery, uncovering 9 previously unknown bugs in widely used
and extensively fuzzed open-source software.

</details>


### [35] [Detecting and Characterizing Low and No Functionality Packages in the NPM Ecosystem](https://arxiv.org/abs/2510.04495)
*Napasorn Tevarut,Brittany Reid,Yutaro Kashiwa,Pattara Leelaprute,Arnon Rungsawang,Bundit Manaskasemsak,Hajimu Iida*

Main category: cs.SE

TL;DR: 该论文研究了npm生态系统中的琐碎包和数据包，开发了基于规则的静态分析方法来检测它们，发现17.92%的包是琐碎包，其漏洞水平与非琐碎包相当，数据包虽然罕见但也存在风险。


<details>
  <summary>Details</summary>
Motivation: 琐碎包（功能简单的小模块）在npm生态系统中很常见，尽管简单但可能带来安全风险。现有定义需要完善，特别是引入数据包（不含可执行逻辑的包）的概念。

Method: 开发基于规则的静态分析方法来检测琐碎包和数据包，并在2025年npm生态系统中评估其流行度和相关风险。

Result: 分析显示17.92%的包是琐碎包，其漏洞水平与非琐碎包相当；数据包虽然罕见但也包含风险。检测工具达到94%准确率（宏F1分数0.87）。

Conclusion: 琐碎包和数据包在依赖管理中值得更多关注，以减少潜在的技术债务和安全暴露。

Abstract: Trivial packages, small modules with low functionality, are common in the npm
ecosystem and can pose security risks despite their simplicity. This paper
refines existing definitions and introduce data-only packages that contain no
executable logic. A rule-based static analysis method is developed to detect
trivial and data-only packages and evaluate their prevalence and associated
risks in the 2025 npm ecosystem. The analysis shows that 17.92% of packages are
trivial, with vulnerability levels comparable to non-trivial ones, and
data-only packages, though rare, also contain risks. The proposed detection
tool achieves 94% accuracy (macro-F1 0.87), enabling effective large-scale
analysis to reduce security exposure. This findings suggest that trivial and
data-only packages warrant greater attention in dependency management to reduce
potential technical debt and security exposure.

</details>


### [36] [Spec2Control: Automating PLC/DCS Control-Logic Engineering from Natural Language Requirements with LLMs - A Multi-Plant Evaluation](https://arxiv.org/abs/2510.04519)
*Heiko Koziolek,Thilo Braun,Virendra Ashiwal,Sofia Linsbauer,Marthe Ahlgreen Hansen,Karoline Grotterud*

Main category: cs.SE

TL;DR: Spec2Control是一个高度自动化的LLM工作流，能够直接从自然语言用户需求生成图形化控制逻辑，在分布式控制系统编程中实现98.6%的正确控制策略连接，节省94-96%的人工劳动。


<details>
  <summary>Details</summary>
Motivation: 分布式控制系统(DCS)的软件编程过程仍然主要依靠手动操作，成本高昂且繁琐。现有基于LLM的商业辅助工具仅限于文本表示，自动化程度有限，且未在大型数据集上进行测试。

Method: 引入Spec2Control，一个高度自动化的LLM工作流，能够直接从自然语言用户需求生成图形化控制逻辑。

Result: 在包含10个控制叙述和65个复杂测试用例的开放数据集上的实验表明，Spec2Control能够成功识别控制策略，自主生成98.6%的正确控制策略连接，节省94-96%的人工劳动。

Conclusion: Spec2Control正在集成到商业ABB工程工具中，同时也提供开源版本供独立验证，为DCS控制逻辑生成提供了高度自动化的解决方案。

Abstract: Distributed control systems (DCS) manage the automation for many industrial
production processes (e.g., power plants, chemical refineries, steel mills).
Programming the software for such systems remains a largely manual and tedious
process, incurring costs of millions of dollars for extensive facilities. Large
language models (LLMs) have been found helpful in generating DCS control logic,
resulting in commercial copilot tools. Today, these tools are focused on
textual notations, they provide limited automation, and have not been tested on
large datasets with realistic test cases. We introduce Spec2Control, a highly
automated LLM workflow to generate graphical control logic directly from
natural language user requirements. Experiments using an open dataset with 10
control narratives and 65 complex test cases demonstrate that Spec2Control can
successfully identify control strategies, can generate 98.6% of correct control
strategy connections autonomously, and can save between 94-96% of human labor.
Spec2Control is being integrated into commercial ABB engineering tools, but is
also available as an open-source variant for independent validation.

</details>


### [37] [Advancing Digital Government: Integrating Open Source Software Enablement Indicators in Maturity Indexes](https://arxiv.org/abs/2510.04603)
*Johan Linåker,Sachiko Muto*

Main category: cs.SE

TL;DR: 本研究分析16个数字成熟国家的开源软件政策，为数字政府成熟度指数提出开源软件采用指标，发现开源软件政策普遍存在，主要通过中央公共部门组织管理，目标包括互操作性、数字主权等，实施由多级政府的开源项目办公室支持。


<details>
  <summary>Details</summary>
Motivation: 开源软件是现代软件栈的重要组成部分，对GDP和国家技术增长有显著影响，但政府开源软件采用的系统性测量仍然有限。

Method: 采用定性方法，结合政策文件的案头研究和政府代表的半结构化访谈，生成详细的国家报告并进行交叉分析。

Result: 促进开源软件重用的政策广泛存在，政策目标包括互操作性、数字主权、透明度和成本效率，实施由多级政府的开源项目办公室支持，提出了涵盖14个领域的指标。

Conclusion: 开源软件是公共部门数字化转型的战略推动者，明确的政策框架和机构支持至关重要，国际数字成熟度框架应扩展开源软件指标以更好地指导和评估政府采用和影响。

Abstract: Context: Open Source Software (OSS) is a vital public good, included across
most of modern software stacks, significantly impacting GDP and national tech
growth, while supporting interoperability, sovereignty, and transparency.
However, systematic measurement of governmental OSS adoption remain limited.
  Research Aim: This study contributes to digital government maturity indexes
by analyzing policies and support actions leveraging OSS for software reuse and
collaborative development across 16 digitally mature countries, and proposing
potential indicators for said indexes. It examines OSS policy formation, stated
goals, key actors, and support mechanisms.
  Methodology: A qualitative approach is used combining desk research of policy
documents with semi-structured interviews of government representatives,
producing detailed country reports. These are cross-analyzed, focusing on OSS
policy promotion, rationale, and implementation support.
  Results: Policies facilitating OSS reuse are widespread, targeting both
inbound acquisition and outbound sharing, and are predominantly governed by
central public sector organizations. Policy goals include interoperability,
digital sovereignty, transparency, and cost efficiency, with security framed
both as a risk and strength. Implementation is supported by diverse Open Source
Program Offices (OSPOs) at multiple government levels, which foster capacity
building, resource pooling, and sustainable project governance. Indicators are
synthesized and proposed across 14 areas covering policy incentives and design,
and implementation and support.
  Conclusions: OSS is a strategic enabler for public sector digital
transformation. Clear policy frameworks, coupled with institutional support
such as OSPOs, are essential. International digital maturity frameworks should
expand OSS indicators to better guide and assess government adoption and
impact.

</details>


### [38] [Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation](https://arxiv.org/abs/2510.04605)
*Jingyao Zhang,Tianlin Li,Xiaoyu Zhang,Qiang Hu,Bin Shi*

Main category: cs.SE

TL;DR: 扩散大语言模型(DLLMs)在软件工程任务中表现优于自回归大语言模型(AR-LLMs)，在52,937个任务的大规模基准测试中平均准确率提升30%，跨文件修复任务提升113%，同时保持更高的效率和更低的延迟。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型在软件工程中存在处理代码结构信息能力有限和推理延迟高的问题，扩散大语言模型提供了具有全局双向编码和解耦生成步骤的替代方案。

Method: 对扩散大语言模型在软件开发生命周期中的表现进行全面评估，包括代码生成、缺陷检测和程序修复任务。

Result: 在52,937个任务的大规模基准测试中，7B参数的DLLMs在平均准确率上比AR-LLMs提升30%，在跨文件修复任务上提升113%，同时保持更高的效率和更低的延迟。

Conclusion: 扩散大语言模型被确立为软件工程任务的优越范式。

Abstract: Autoregressive Large Language Models (AR-LLMs) are widely used in software
engineering (SE) but face limitations in processing code structure information
and suffer from high inference latency. Diffusion LLMs (DLLMs) offer a
promising alternative with global bidirectional encoding and decoupled
generation steps. This work presents the first comprehensive evaluation of
DLLMs across the software development lifecycle, including code generation,
defect detection, and program repair. On a large-scale benchmark of 52,937
tasks, 7Bparameter DLLMs outperform AR-LLMs with a 30% average accuracy
improvement achieving a 113% gain on cross-file repair, while maintaining
superior efficiency and reduced latency. Our results establish DLLMs as a
superior paradigm for SE tasks.

</details>


### [39] [A survey on the impact of emotions on the productivity among software developers](https://arxiv.org/abs/2510.04611)
*Pawel Weichbroth,Maciej Lotysz,Michal Wrobel*

Main category: cs.SE

TL;DR: 软件开发者情绪状态对感知生产力有显著正向影响（beta=0.893, p<0.001），情绪管理对提升开发效率至关重要。


<details>
  <summary>Details</summary>
Motivation: 软件开发的时间压力等因素常导致开发者情绪状态下降，但情绪是否影响生产力尚不清楚，本研究旨在探索两者关系。

Method: 采用两阶段方法：先通过9位专家验证测量模型，再对88名软件开发者进行调查，使用偏最小二乘法进行数据分析。

Result: 路径分析明确证实假设，开发者情绪状态对感知生产力有强烈正向且显著的影响。

Conclusion: 管理和改善开发者情绪健康对提升软件开发环境中的生产力至关重要，减少倦怠、压力等负面因素的干预措施能显著影响绩效结果。

Abstract: The time pressure associated with software development, among other factors,
often leads to a diminished emotional state among developers. However, whether
emotions affect perceived productivity remains an open question. This study
aims to determine the strength and direction of the relationship between
emotional state and perceived productivity among software developers. We
employed a two-stage approach. First, a survey was conducted with a pool of
nine experts to validate the measurement model. Second, a survey was
administered to a pool of 88 software developers to empirically test the
formulated hypothesis by using Partial Least Squares, as the data analysis
method. The results of the path analysis clearly confirm the formulated
hypothesis, showing that the emotional state of a software developer has a
strong positive, and significant impact (beta = 0.893, p < 0.001) on perceived
productivity among software developers. The findings highlight the importance
of managing and improving developers emotional well-being to enhance
productivity in software development environments. Additionally, interventions
aimed at reducing burnout, stress, and other negative factors could have a
considerable impact on their performance outcomes.

</details>


### [40] [Evolaris: A Roadmap to Self-Evolving Software Intelligence Management](https://arxiv.org/abs/2510.04689)
*Chengwei Liu,Wenbo Guo,Yuxin Zhang,Limin Wang,Sen Chen,Lei Bu,Yang Liu*

Main category: cs.SE

TL;DR: 提出了Evolaris，一个基于多智能体框架的自进化软件情报系统，用于从分散的非正式渠道及时捕获安全威胁信息。


<details>
  <summary>Details</summary>
Motivation: 软件威胁环境日益动态和分散，关键威胁信息越来越多地通过博客、社交媒体、开源仓库等非正式渠道出现，需要及时捕获这些情报以维持态势感知和快速安全响应。

Method: 构建基于多智能体框架的Evolaris系统，智能体独立运行但通过共享上下文协调，执行信息发现、推理、缺口补全、验证和风险检测等任务。

Result: 该架构使平台能够从新输入中学习，精炼内部知识，并随时间适应新兴威胁模式，持续提高软件威胁分析的精确性、及时性和可扩展性。

Conclusion: Evolaris为主动安全决策提供了可持续基础，并加强了安全威胁理解的更广泛生态系统。

Abstract: In recent years, the landscape of software threats has become significantly
more dynamic and distributed. Security vulnerabilities are no longer discovered
and shared only through formal channels such as public vulnerability databases
or vendor advisories. Increasingly, criti- cal threat information emerges
informally through blogs, social media, developer forums, open source
repositories, and even underground com- munities. To this end, capturing such
intelligence in a timely manner is essential for maintaining situational
awareness and enabling prompt security responses. However, this remains a
complex challenge due to the fragmented nature of data sources and the
technical difficulty of collecting, parsing, mapping, and validating
information at scale. To ad- dress this, we propose Evolaris, a self-evolving
software intelligence sys- tem built on a multi-agent framework. Evolaris is
designed to support a full-stack workflow, where agents operate independently
but coordinate through shared context to perform tasks such as information
discovery, reasoning, gap completion, validation, and risk detection. This
archi- tecture enables the platform to learn from new inputs, refine its
internal knowledge, and adapt to emerging threat patterns over time, which
could continuously improve the precision, timeliness, and scalability of
software threat analysis, and offers a sustainable foundation for proactive
secu- rity decision-making and strengthens the broader ecosystem of security
threat understanding.

</details>


### [41] [An Empirical Study of SOTA RCA Models: From Oversimplified Benchmarks to Realistic Failures](https://arxiv.org/abs/2510.04711)
*Aoyang Fang,Songhan Zhang,Yifan Yang,Haotong Wu,Junjielong Xu,Xuyang Wang,Rui Wang,Manyi Wang,Qisheng Lu,Pinjia He*

Main category: cs.SE

TL;DR: 现有云原生微服务根因分析(RCA)基准测试过于简化，导致SOTA模型性能被高估。作者开发了更真实的基准测试框架，重新评估11个SOTA模型发现准确率很低(平均0.21，最佳0.37)，并识别了三大常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 云原生微服务架构的复杂性使得根因分析至关重要，但现有基准测试过于简化，无法反映真实场景。初步研究表明简单规则方法在现有基准上能与SOTA模型匹敌甚至超越，表明存在性能高估问题。

Method: 系统分析流行RCA基准测试的局限性，开发自动化框架生成更真实的基准测试数据集，包含1,430个验证过的故障案例(来自9,152次注入)，涵盖25种故障类型，具有动态工作负载、分层真实标签和已验证的SLI影响。

Result: 在更真实的数据集上重新评估11个SOTA模型，结果显示Top@1准确率很低(平均0.21，最佳0.37)，且执行时间显著更长。识别出三大常见失败模式：可扩展性问题、可观测性盲点和建模瓶颈。

Conclusion: 现有RCA基准测试的简化导致模型性能被严重高估，需要更真实的基准测试来推动该领域发展。作者提出的框架为更准确的模型评估提供了基础。

Abstract: While cloud-native microservice architectures have transformed software
development, their complexity makes Root Cause Analysis (RCA) both crucial and
challenging. Although many data-driven RCA models have been proposed, we find
that existing benchmarks are often oversimplified and fail to capture
real-world conditions. Our preliminary study shows that simple rule-based
methods can match or even outperform state-of-the-art (SOTA) models on four
widely used benchmarks, suggesting performance overestimation due to benchmark
simplicity. To address this, we systematically analyze popular RCA benchmarks
and identify key limitations in fault injection, call graph design, and
telemetry patterns. Based on these insights, we develop an automated framework
to generate more realistic benchmarks, yielding a dataset of 1,430 validated
failure cases from 9,152 injections, covering 25 fault types under dynamic
workloads with hierarchical ground-truth labels and verified SLI impact.
Re-evaluation of 11 SOTA models on this dataset shows low Top@1 accuracy
(average 0.21, best 0.37) and significantly longer execution times. Our
analysis highlights three common failure patterns: scalability issues,
observability blind spots, and modeling bottlenecks.

</details>


### [42] [Agile Software Effort Estimation using Regression Techniques](https://arxiv.org/abs/2510.04760)
*Sisay Deresa Sima,Ayalew Belay Habtie*

Main category: cs.SE

TL;DR: 该研究开发了一个基于故事点的敏捷工作量估算模型，使用LASSO和Elastic Net回归技术，在21个软件项目上验证，LASSO回归表现最佳。


<details>
  <summary>Details</summary>
Motivation: 软件工作量估算是软件开发过程中最关键的方面之一，整个项目的成功与否取决于估算的准确性。研究人员仍在进行敏捷工作量估算的研究。

Method: 使用LASSO和Elastic Net回归技术开发故事点敏捷工作量估算模型，在21个软件项目上应用，采用默认参数和调优网格搜索结合5折交叉验证。

Result: LASSO回归取得了更好的预测性能：PRED(8%)和PRED(25%)结果均为100.0，MMRE为0.0491，MMER为0.0551，MdMRE为0.0593，MdMER为0.063，MSE为0.0007。

Conclusion: LASSO回归在敏捷工作量估算中表现出优越的预测性能，结果与其他相关文献相比具有竞争力。

Abstract: Software development effort estimation is one of the most critical aspect in
software development process, as the success or failure of the entire project
depends on the accuracy of estimations. Researchers are still conducting
studies on agile effort estimation. The aim of this research is to develop a
story point based agile effort estimation model using LASSO and Elastic Net
regression techniques. The experimental work is applied to the agile story
point approach using 21 software projects collected from six firms. The two
algorithms are trained using their default parameters and tuned grid search
with 5-fold cross-validation to get an enhanced model. The experiment result
shows LASSO regression achieved better predictive performance PRED (8%) and
PRED (25%) results of 100.0, MMRE of 0.0491, MMER of 0.0551, MdMRE of 0.0593,
MdMER of 0.063, and MSE of 0.0007. The results are also compared with other
related literature.

</details>


### [43] [GUISpector: An MLLM Agent Framework for Automated Verification of Natural Language Requirements in GUI Prototypes](https://arxiv.org/abs/2510.04791)
*Kristian Kolthoff,Felix Kretzer,Simone Paolo Ponzetto,Alexander Maedche,Christian Bartelt*

Main category: cs.SE

TL;DR: GUISpector是一个基于多模态大语言模型的GUI原型验证框架，能够自动验证自然语言需求，提供可操作的反馈，并与LLM驱动的开发工作流集成。


<details>
  <summary>Details</summary>
Motivation: 现有GUI测试方法难以处理现代界面的复杂性，缺乏可操作的反馈和与自动化开发代理的有效集成。随着LLM驱动的编程代理在开发工作流中日益普及，确保GUI实现满足自然语言需求变得至关重要。

Method: 使用多模态大语言模型代理解释和操作化自然语言需求，自主规划和执行GUI应用的验证轨迹，系统提取详细反馈，提供集成工具监督验证过程。

Result: 在150个基于900个验收标准注释的需求集上评估，有效检测需求满足和违规情况，展示了与自动化LLM驱动开发工作流的无缝集成潜力。

Conclusion: GUISpector框架能够有效验证GUI原型的自然语言需求，提供可操作的反馈，支持迭代改进和LLM驱动的代码生成，为自动化开发工作流提供了有价值的工具。

Abstract: GUIs are foundational to interactive systems and play a pivotal role in early
requirements elicitation through prototyping. Ensuring that GUI implementations
fulfill NL requirements is essential for robust software engineering,
especially as LLM-driven programming agents become increasingly integrated into
development workflows. Existing GUI testing approaches, whether traditional or
LLM-driven, often fall short in handling the complexity of modern interfaces,
and typically lack actionable feedback and effective integration with automated
development agents. In this paper, we introduce GUISpector, a novel framework
that leverages a multi-modal (M)LLM-based agent for the automated verification
of NL requirements in GUI prototypes. First, GUISpector adapts a MLLM agent to
interpret and operationalize NL requirements, enabling to autonomously plan and
execute verification trajectories across GUI applications. Second, GUISpector
systematically extracts detailed NL feedback from the agent's verification
process, providing developers with actionable insights that can be used to
iteratively refine the GUI artifact or directly inform LLM-based code
generation in a closed feedback loop. Third, we present an integrated tool that
unifies these capabilities, offering practitioners an accessible interface for
supervising verification runs, inspecting agent rationales and managing the
end-to-end requirements verification process. We evaluated GUISpector on a
comprehensive set of 150 requirements based on 900 acceptance criteria
annotations across diverse GUI applications, demonstrating effective detection
of requirement satisfaction and violations and highlighting its potential for
seamless integration of actionable feedback into automated LLM-driven
development workflows. The video presentation of GUISpector is available at:
https://youtu.be/JByYF6BNQeE, showcasing its main capabilities.

</details>


### [44] [RevMine: An LLM-Assisted Tool for Code Review Mining and Analysis Across Git Platforms](https://arxiv.org/abs/2510.04796)
*Samah Kansab,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: RevMine是一个基于大语言模型的概念工具，旨在简化代码审查挖掘流程，降低实证研究的门槛。


<details>
  <summary>Details</summary>
Motivation: 当前代码审查数据的收集和分析过程耗时且技术密集，研究人员需要编写大量临时脚本来处理GitHub、GitLab等平台的数据。

Method: 使用大语言模型指导用户完成认证、端点发现和自然语言驱动的数据收集，支持基于用户定义过滤器或LLM推断模式的定量和定性分析。

Result: 开发了RevMine工具架构，展示了其用例和研究潜力。

Conclusion: 通过降低入门门槛，RevMine旨在普及代码审查挖掘，支持更广泛的实证软件工程研究。

Abstract: Empirical research on code review processes is increasingly central to
understanding software quality and collaboration. However, collecting and
analyzing review data remains a time-consuming and technically intensive task.
Most researchers follow similar workflows - writing ad hoc scripts to extract,
filter, and analyze review data from platforms like GitHub and GitLab. This
paper introduces RevMine, a conceptual tool that streamlines the entire code
review mining pipeline using large language models (LLMs). RevMine guides users
through authentication, endpoint discovery, and natural language-driven data
collection, significantly reducing the need for manual scripting. After
retrieving review data, it supports both quantitative and qualitative analysis
based on user-defined filters or LLM-inferred patterns. This poster outlines
the tool's architecture, use cases, and research potential. By lowering the
barrier to entry, RevMine aims to democratize code review mining and enable a
broader range of empirical software engineering studies.

</details>


### [45] [InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface](https://arxiv.org/abs/2510.04835)
*Wentao Gao,Renata Borovica-Gajic,Sang Kil Cha,Tian Qiu,Van-Thuan Pham*

Main category: cs.SE

TL;DR: InsightQL是一个帮助开发者分析模糊测试阻塞问题的框架，通过统一数据库和参数化查询接口，有效解决覆盖率停滞问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模糊测试技术在面对覆盖率停滞问题时效果有限，需要人工介入分析，但这个过程劳动密集且效率低下。

Method: 构建统一数据库和直观的参数化查询接口，帮助开发者系统性地提取洞察信息并高效解决模糊测试阻塞问题。

Result: 在FuzzBench基准测试的14个流行真实库上验证，成功解除了多个模糊测试阻塞，代码覆盖率最高提升13.90%。

Conclusion: InsightQL框架能够有效辅助开发者分析模糊测试阻塞问题，显著提升代码覆盖率，为发现更深层漏洞提供支持。

Abstract: Fuzzing is a highly effective automated testing method for uncovering
software vulnerabilities. Despite advances in fuzzing techniques, such as
coverage-guided greybox fuzzing, many fuzzers struggle with coverage plateaus
caused by fuzz blockers, limiting their ability to find deeper vulnerabilities.
Human expertise can address these challenges, but analyzing fuzzing results to
guide this support remains labor-intensive. To tackle this, we introduce
InsightQL, the first human-assisting framework for fuzz blocker analysis.
Powered by a unified database and an intuitive parameterized query interface,
InsightQL aids developers in systematically extracting insights and efficiently
unblocking fuzz blockers. Our experiments on 14 popular real-world libraries
from the FuzzBench benchmark demonstrate the effectiveness of InsightQL,
leading to the unblocking of many fuzz blockers and considerable improvements
in code coverage (up to 13.90%).

</details>


### [46] [FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration](https://arxiv.org/abs/2510.04852)
*Victor May,Diganta Misra,Yanqi Luo,Anjali Sridhar,Justine Gehring,Silvio Soares Ribeiro Junior*

Main category: cs.SE

TL;DR: FreshBrew是一个用于评估AI代理在项目级Java迁移任务中的基准，重点关注程序语义保持和避免奖励黑客行为，使用高测试覆盖率的项目进行可靠评估。


<details>
  <summary>Details</summary>
Motivation: 传统代码迁移依赖基于规则的系统，而基于大语言模型的AI代理框架提供了有前景的替代方案，但其有效性尚未得到系统评估。

Method: 引入FreshBrew基准，在228个代码库上评估多个最先进的大语言模型，并与基于规则的工具进行比较。

Result: 表现最佳的Gemini 2.5 Flash模型能够成功将52.3%的项目迁移到JDK 17。

Conclusion: 研究揭示了当前AI代理在现实Java现代化任务中的失败模式，为评估可信赖的代码迁移系统提供了基础。

Abstract: AI coding assistants are rapidly becoming integral to modern software
development. A key challenge in this space is the continual need to migrate and
modernize codebases in response to evolving software ecosystems. Traditionally,
such migrations have relied on rule-based systems and human intervention. With
the advent of powerful large language models (LLMs), AI-driven agentic
frameworks offer a promising alternative-but their effectiveness has not been
systematically evaluated. In this paper, we introduce FreshBrew, a novel
benchmark for evaluating AI agents on project-level Java migrations, with a
specific focus on measuring an agent's ability to preserve program semantics
and avoid reward hacking, which we argue requires projects with high test
coverage for a rigorous and reliable evaluation. We benchmark several
state-of-the-art LLMs, and compare their performance against established
rule-based tools. Our evaluation of AI agents on this benchmark of 228
repositories shows that the top-performing model, Gemini 2.5 Flash, can
successfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis
reveals novel insights into the critical strengths and limitations of current
agentic approaches, offering actionable insights into their real-world
applicability. Our empirical study reveals failure modes of current AI agents
in realistic Java modernization tasks, providing a foundation for evaluating
trustworthy code-migration systems. By releasing FreshBrew, we aim to
facilitate rigorous, reproducible evaluation and catalyze progress in AI-driven
codebase modernization.

</details>


### [47] [Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches](https://arxiv.org/abs/2510.04905)
*Yicheng Tao,Yao Qin,Yepang Liu*

Main category: cs.SE

TL;DR: 本文综述了检索增强代码生成（RACG）领域的研究进展，特别关注仓库级代码生成（RLCG）任务，系统分类了现有工作并建立了统一分析框架。


<details>
  <summary>Details</summary>
Motivation: 现实软件开发需要跨整个代码仓库进行推理，而现有函数级和文件级代码生成方法难以处理仓库级代码生成中的长程依赖和全局语义一致性问题。

Method: 采用检索增强生成（RAG）范式，将外部检索机制与大型语言模型结合，提升上下文感知能力和可扩展性。

Result: 建立了多维度的分类框架，包括生成策略、检索模态、模型架构、训练范式和评估协议，总结了常用数据集和基准。

Conclusion: 为理解这一快速发展领域提供了统一分析框架，并为AI驱动的软件工程持续进步指明了关键挑战和机遇。

Abstract: Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.

</details>


### [48] [Why Software Signing (Still) Matters: Trust Boundaries in the Software Supply Chain](https://arxiv.org/abs/2510.04964)
*Kelechi G. Kalu,James C. Davis*

Main category: cs.SE

TL;DR: 软件签名提供了来源验证、完整性和问责制的核心保证，但在集中式注册表时代，需要重新评估其必要性。研究表明签名作为基础防御层，在跨越镜像、代理、重新托管和隔离传输等分发边界时仍然至关重要。


<details>
  <summary>Details</summary>
Motivation: 在PyPI、npm、Maven Central和Hugging Face等集中式注册表盛行的时代，研究注册表安全控制是否足以替代端到端软件签名，以及签名在跨越不同软件分发边界时的必要性。

Method: 综合历史实践，构建现代分发模式的信任模型，识别在哪些情况下签名对于扩展注册表控制之外的信任是必要的。

Result: 研究发现签名的核心保证（来源验证、完整性和问责制）不会自动跨越不同的软件分发边界，包括镜像、企业代理、重新托管和隔离传输等场景。

Conclusion: 将签名作为基础防御层可以加强软件供应链保证，即使在注册表安全的情况下，签名在跨越分发边界时仍然不可或缺。

Abstract: Software signing provides a formal mechanism for provenance by ensuring
artifact integrity and verifying producer identity. It also imposes tooling and
operational costs to implement in practice. In an era of centralized registries
such as PyPI, npm, Maven Central, and Hugging Face, it is reasonable to ask
whether hardening registry security controls obviates the need for end-to-end
artifact signing. In this work, we posit that the core guarantees of signing,
provenance, integrity, and accountability are not automatically carried across
different software distribution boundaries. These boundaries include mirrors,
corporate proxies, re-hosting, and air-gapped transfers, where registry
security controls alone cannot provide sufficient assurance. We synthesize
historical practice and present a trust model for modern distribution modes to
identify when signing is necessary to extend trust beyond registry control.
Treating signing as a baseline layer of defense strengthens software supply
chain assurance even when registries are secure.

</details>


### [49] [Quantum Computing as a Service - a Software Engineering Perspective](https://arxiv.org/abs/2510.04982)
*Aakash Ahmad,Muhammad Waseem,Bakheet Aljedaani,Mahdi Fahmideh,Peng Liang,Feras Awaysheh*

Main category: cs.SE

TL;DR: 本文提出了一种基于过程中心和架构驱动的方法，从软件工程视角研究量子计算即服务(QCaaS)，通过系统映射研究和架构开发，识别了量子服务开发生命周期的4个阶段，并构建了支持QCaaS的分层参考架构。


<details>
  <summary>Details</summary>
Motivation: 量子计算作为颠覆性技术正在兴起，量子计算即服务(QCaaS)被视为符合服务导向理念的解决方案，可以为没有量子计算机的个人和组织提供量子计算资源。本文旨在从软件工程角度研究如何实现QCaaS。

Method: 采用两阶段研究方法：(a) 系统映射研究，通过多步骤选择和定性评估筛选了41篇同行评审文献；(b) 基于架构的开发方法，将量子服务开发生命周期阶段整合到支持QCaaS的参考架构中。

Result: 识别了4阶段的量子服务开发生命周期，包括量子重要需求(QSRs)、各种建模符号、模式目录、编程语言和部署平台，这些可以集成到分层参考架构中以工程化QCaaS。

Conclusion: 研究提出了一个支持量子服务导向的参考架构，为量子计算即服务的工程化实现提供了软件工程视角和方法论支持。

Abstract: Quantum systems have started to emerge as a disruptive technology and
enabling platforms - exploiting the principles of quantum mechanics via
programmable quantum bits (QuBits) - to achieve quantum supremacy in computing.
Academic research, industrial projects (e.g., Amazon Braket, IBM Qiskit), and
consortiums like 'Quantum Flagship' are striving to develop practically capable
and commercially viable quantum computing (QC) systems and technologies.
Quantum Computing as a Service (QCaaS) is viewed as a solution attuned to the
philosophy of service-orientation that can offer QC resources and platforms, as
utility computing, to individuals and organisations who do not own quantum
computers. This research investigates a process-centric and architecture-driven
approach to offer a software engineering perspective on enabling QCaaS - a.k.a
quantum service-orientation. We employed a two-phase research method comprising
(a) a systematic mapping study and (b) an architecture-based development, first
to identify the phases of the quantum service development life cycle and
subsequently to integrate these phases into a reference architecture that
supports QCaaS. The SMS process retrieved a collection of potentially relevant
research literature and based on a multi-step selection and qualitative
assessment, we selected 41 peer-reviewed studies to answer three RQs. The RQs
investigate (i) demographic details in terms of frequency, types, and trends of
research, (ii) phases of quantum service development lifecycle to derive a
reference architecture for conception, modeling, assembly, and deployment of
services, and (iii) The results identify a 4-phased development lifecycle along
with quantum significant requirements (QSRs), various modeling notations,
catalogue of patterns, programming languages, and deployment platforms that can
be integrated in a layered reference architecture to engineer QCaaS.

</details>


### [50] [AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault Analysis](https://arxiv.org/abs/2510.04997)
*Jiongchi Yu,Weipeng Jiang,Xiaoyu Zhang,Qiang Hu,Xiaofei Xie,Chao Shen*

Main category: cs.SE

TL;DR: 本文探讨了使用大语言模型(LLMs)进行软件故障分析的可行性，通过将传统多步骤专家驱动的故障分析过程分解为三个关键阶段，并在3,829个软件故障上进行评估，结果显示LLMs能显著提高分析效率。


<details>
  <summary>Details</summary>
Motivation: 传统软件故障分析过程劳动密集且耗时，阻碍了大规模故障研究和迭代实证研究的进展，需要更高效的自动化方法。

Method: 将实证软件故障研究分解为三个关键阶段：研究目标定义、数据准备和故障分析，并使用LLMs对3,829个高质量实证研究中的软件故障进行分析评估。

Result: LLMs能显著提高故障分析效率，平均处理时间约2小时，而传统手动分析通常需要数周时间。

Conclusion: LLMs在推进实证故障研究方面具有巨大潜力，但需要解决开放挑战才能实现完全自动化的端到端软件故障分析。

Abstract: Understanding software faults is essential for empirical research in software
development and maintenance. However, traditional fault analysis, while
valuable, typically involves multiple expert-driven steps such as collecting
potential faults, filtering, and manual investigation. These processes are both
labor-intensive and time-consuming, creating bottlenecks that hinder
large-scale fault studies in complex yet critical software systems and slow the
pace of iterative empirical research.
  In this paper, we decompose the process of empirical software fault study
into three key phases: (1) research objective definition, (2) data preparation,
and (3) fault analysis, and we conduct an initial exploration study of applying
Large Language Models (LLMs) for fault analysis of open-source software.
Specifically, we perform the evaluation on 3,829 software faults drawn from a
high-quality empirical study. Our results show that LLMs can substantially
improve efficiency in fault analysis, with an average processing time of about
two hours, compared to the weeks of manual effort typically required. We
conclude by outlining a detailed research plan that highlights both the
potential of LLMs for advancing empirical fault studies and the open challenges
that required be addressed to achieve fully automated, end-to-end software
fault analysis.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [51] [Unreliability in Practical Subclasses of Communicating Systems](https://arxiv.org/abs/2510.03941)
*Amrita Suresh,Nobuko Yoshida*

Main category: cs.LO

TL;DR: 本文研究了通信自动机系统在故障模型下的弹性，特别是对RSC和k-MC两种可判定子类在干扰和崩溃停止故障下的适应性分析。


<details>
  <summary>Details</summary>
Motivation: 现有的RSC和k-MC验证方法依赖于完美通道假设，在现实故障场景下不具弹性，限制了其实际应用价值。

Method: 提出干扰模型下的松弛条件，证明松弛后的性质仍可判定；设计新的崩溃处理通信系统，将MPST与崩溃停止故障转化为该系统并集成RSC和k-MC性质。

Result: 松弛后的RSC和k-MC在干扰下保持可判定性且复杂度不变；新系统能捕获比现有MPST更广泛的行为；通过扩展工具验证代表性协议展示了系统的弹性。

Conclusion: 所提出的松弛方法和新通信系统有效增强了RSC和k-MC在故障模型下的弹性，为实际分布式系统验证提供了更实用的理论框架。

Abstract: Systems of communicating automata are prominent models for peer-to-peer
message-passing over unbounded channels, but in the general scenario, most
verification properties are undecidable. To address this issue, two decidable
subclasses, Realisable with Synchronous Communication (RSC) and k-Multiparty
Compatibility} (k-MC), were proposed in the literature, with corresponding
verification tools developed and applied in practice. Unfortunately, both RSC
and k-MC are not resilient under failures: (1) their decidability relies on the
assumption of perfect channels and (2) most standard protocols do not satisfy
RSC or k-MC under failures. To address these limitations, this paper studies
the resilience of RSC and k-MC under two distinct failure models: interference
and crash-stop failures. For interference, we relax the conditions of RSC and
k-MC and prove that the inclusions of these relaxed properties remain decidable
under interference, preserving their known complexity bounds. We then propose a
novel crash-handling communicating system that captures wider behaviours than
existing multiparty session types (MPST) with crash-stop failures. We study a
translation of MPST with crash-stop failures into this system integrating RSC
and k-MC properties, and establish their decidability results. Finally, by
verifying representative protocols from the literature using RSC and k-MC tools
extended to interferences, we evaluate the relaxed systems and demonstrate
their resilience.

</details>


### [52] [An Empirical Study of Rational Tree Unification for miniKanren](https://arxiv.org/abs/2510.03789)
*Eridan Domoratskiy,Dmitrii Kosarev,Dmitry Boulytchev*

Main category: cs.LO

TL;DR: 研究miniKanren中理性树的统一化，提出算法定义、证明性质，引入启发式优化并评估，讨论理性与传统统一算法的关系及在关系编程中的共存场景。


<details>
  <summary>Details</summary>
Motivation: 在关系编程环境miniKanren中研究理性树的统一化问题，探索更高效的统一算法及其优化方法。

Method: 定义理性树统一算法，证明算法性质，引入启发式优化策略，并通过基准测试进行评估。

Result: 开发了理性树统一算法，证明其正确性，优化策略在基准测试中表现良好。

Conclusion: 理性树统一算法在miniKanren中可行且有效，可与传统算法共存，为关系编程提供更灵活的统一机制。

Abstract: We present a study of unification for rational trees in the context of
miniKanren. We give the definition of rational trees, specify the unification
algorithm and prove some of its properties. We also introduce a number of
heuristic optimizations and evaluate them for a number of relevant benchmarks.
Finally we discuss the relations between rational and conventional unification
algorithms and possible scenarios of their coexistence in the context of
relational programming.

</details>


### [53] [Interpolation in First-Order Logic](https://arxiv.org/abs/2510.03822)
*Balder ten Cate,Jesse Comer*

Main category: cs.LO

TL;DR: 本文对一阶逻辑及其片段中的Craig插值定理进行了综述，涵盖了插值定理的细化、在逻辑和计算机科学中的应用、重要语法片段的插值结果以及插值计算问题。


<details>
  <summary>Details</summary>
Motivation: 为一阶逻辑及其片段的Craig插值定理相关文献提供一个入门指南，系统梳理该领域的研究成果和应用。

Method: 采用文献综述的方法，系统整理和分析已知的Craig插值定理相关研究成果。

Result: 全面覆盖了Craig插值定理的多种细化形式、在不同领域的应用案例、重要一阶逻辑片段的插值特性以及插值计算的技术方法。

Conclusion: 本章为研究一阶逻辑及其片段中Craig插值定理的学者提供了系统的知识框架和文献指引，展示了该理论在逻辑和计算机科学中的广泛应用价值。

Abstract: In this chapter we give a basic overview of known results regarding Craig
interpolation for first-order logic as well as for fragments of first-order
logic. Our aim is to provide an entry point into the literature on
interpolation theorems for first-order logic and fragments of first-order
logic, and their applications. In particular, we cover a range of known
refinements of the Craig interpolation theorem, we discuss several important
applications of interpolation in logic and computer science, we review known
results about interpolation for important syntactic fragments of first-order
logic, and we discuss the problem of computing interpolants.

</details>


### [54] [On Hyperproperty Verification, Quantifier Alternations, and Games under Partial Information](https://arxiv.org/abs/2510.03942)
*Raven Beutner,Bernd Finkbeiner*

Main category: cs.LO

TL;DR: 本文提出使用部分信息下的多人游戏来验证具有任意量词交替的超属性，解决了传统方法只能处理∀*∃*属性的限制。


<details>
  <summary>Details</summary>
Motivation: 传统超属性验证方法面临量词交替带来的挑战，完全验证方法需要系统补集操作，实际不可行。基于游戏的方法虽然更高效，但仅限于∀*∃*属性，无法处理重要的复杂超属性。

Method: 使用部分信息下的多人游戏来验证具有任意量词交替的HyperLTL公式。虽然部分信息游戏通常不可判定，但本文的游戏在层次化信息下进行，属于可判定类。

Result: 证明了该方法可以处理任意量词交替的超属性，且在层次化信息下是可判定的。讨论了游戏的完备性并研究了部分信息下的预言变量。

Conclusion: 通过部分信息下的多人游戏，成功扩展了基于游戏的超属性验证方法，使其能够处理具有任意量词交替的复杂超属性，同时保持了可判定性。

Abstract: Hyperproperties generalize traditional trace properties by relating multiple
execution traces rather than reasoning about individual runs in isolation. They
provide a unified way to express important requirements such as information
flow and robustness properties. Temporal logics like HyperLTL capture these
properties by explicitly quantifying over executions of a system. However, many
practically relevant hyperproperties involve quantifier alternations, a feature
that poses substantial challenges for automated verification. Complete
verification methods require a system complementation for each quantifier
alternation, making it infeasible in practice. A cheaper (but incomplete)
method interprets the verification of a HyperLTL formula as a two-player game
between universal and existential quantifiers. The game-based approach is
significantly cheaper, facilitates interactive proofs, and allows for
easy-to-check certificates of satisfaction. It is, however, limited to
$\forall^*\exists^*$ properties, leaving important properties out of reach. In
this paper, we show that we can use games to verify hyperproperties with
arbitrary quantifier alternations by utilizing multiplayer games under partial
information. While games under partial information are, in general,
undecidable, we show that our game is played under hierarchical information and
thus falls in a decidable class of games. We discuss the completeness of the
game and study prophecy variables in the setting of partial information.

</details>


### [55] [Strategy Logic, Imperfect Information, and Hyperproperties](https://arxiv.org/abs/2510.03952)
*Raven Beutner,Bernd Finkbeiner*

Main category: cs.LO

TL;DR: 本文研究了策略逻辑(SL)的两个变体：带不完全信息的策略逻辑(SL_ii)和超策略逻辑(HyperSL)，证明了它们在限制条件下是等价的，可以相互编码。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体系统中战略行为与超属性之间的关系，探索不完全信息与超属性之间的内在联系。

Method: 通过将不完全信息视为超属性，将SL_ii实例编码为HyperSL实例；通过构建多智能体系统的自组合，使用不完全信息模拟超属性，实现反向编码。

Result: 证明了SL_ii和HyperSL在限制条件下（状态公式不嵌套在路径公式内）是等价的，可以相互转换。

Conclusion: 不完全信息与超属性在多智能体系统的战略推理中存在深刻的等价关系，这为理解这两种重要概念提供了新的视角。

Abstract: Strategy logic (SL) is a powerful temporal logic that enables first-class
reasoning over strategic behavior in multi-agent systems (MAS). In many MASs,
the agents (and their strategies) cannot observe the global state of the
system, leading to many extensions of SL centered around imperfect information,
such as strategy logic with imperfect information (SL$_\mathit{ii}$). Along
orthogonal lines, researchers have studied the combination of strategic
behavior and hyperproperties. Hyperproperties are system properties that relate
multiple executions in a system and commonly arise when specifying security
policies. Hyper Strategy Logic (HyperSL) is a temporal logic that combines
quantification over strategies with the ability to express hyperproperties on
the executions of different strategy profiles. In this paper, we study the
relation between SL$_\mathit{ii}$ and HyperSL. Our main result is that both
logics (restricted to formulas where no state formulas are nested within path
formulas) are equivalent in the sense that we can encode SL$_\mathit{ii}$
instances into HyperSL instances and vice versa. For the former direction, we
build on the well-known observation that imperfect information is a
hyperproperty. For the latter direction, we construct a self-composition of
MASs and show how we can simulate hyperproperties using imperfect information.

</details>


### [56] [A Complete Diagrammatic Calculus for Conditional Gaussian Mixtures](https://arxiv.org/abs/2510.04649)
*Mateo Torres-Ruiz,Robin Piedeleu,Alexandra Silva,Fabio Zanasi*

Main category: cs.LO

TL;DR: 该论文引入了一种用于混合概率模型的图示演算，其中连续随机变量在离散变量条件下服从多元高斯分布，涵盖了高斯混合模型等重要类别。


<details>
  <summary>Details</summary>
Motivation: 扩展离散和高斯分类概率的合成理论，为混合概率模型开发一种图示演算方法，以推理连续随机变量在离散变量条件下的多元高斯分布。

Method: 开发了字符串图示语法来表达和组合这些模型，给出了组合语义，并配备了完备的等式理论来表征两个模型何时表示相同的分布。

Result: 建立了一个用于混合概率模型的图示演算系统，具有组合语义和完备的等式理论。

Conclusion: 该研究为混合概率模型提供了一种新的图示演算方法，能够有效推理高斯混合模型等重要的概率模型类别。

Abstract: We extend the synthetic theories of discrete and Gaussian categorical
probability by introducing a diagrammatic calculus for reasoning about hybrid
probabilistic models in which continuous random variables, conditioned on
discrete ones, follow a multivariate Gaussian distribution. This setting
includes important classes of models such as Gaussian mixture models, where
each Gaussian component is selected according to a discrete variable. We
develop a string diagrammatic syntax for expressing and combining these models,
give it a compositional semantics, and equip it with a sound and complete
equational theory that characterises when two models represent the same
distribution.

</details>


### [57] [Continuation Semantics for Fixpoint Modal Logic and Computation Tree Logics](https://arxiv.org/abs/2510.04653)
*Ryota Kojima,Corina Cirstea*

Main category: cs.LO

TL;DR: 本文提出了针对不动点模态逻辑(FML)和计算树逻辑*(CTL*)的延续语义学，证明了其与余代数语义学的等价性，并建立了通过单子态射传递执行映射的一般结果。


<details>
  <summary>Details</summary>
Motivation: 现有的余代数语义学需要模型具有无限迹/最大执行映射，这限制了应用范围。本文旨在开发更灵活的延续语义学，允许使用非最大不动点的执行映射。

Method: 在延续单子的余代数上定义延续语义学，将谓词和延续识别，通过评估延续来解释模态。建立了通过单子态射传递执行映射的一般结果。

Result: 证明了延续语义学与余代数语义学对于所有分支类型都是等价的，并识别了CTL可以在延续语义下编码到不动点模态逻辑的充分条件。

Conclusion: 延续语义学为FML和CTL*提供了与余代数语义学等价的替代语义，具有更灵活的模型要求，并建立了语义等价性的通用框架。

Abstract: We introduce continuation semantics for both fixpoint modal logic (FML) and
Computation Tree Logic* (CTL*), parameterised by a choice of branching type and
quantitative predicate lifting. Our main contribution is proving that they are
equivalent to coalgebraic semantics, for all branching types. Our continuation
semantics is defined over coalgebras of the continuation monad whose answer
type coincides with the domain of truth values of the formulas. By identifying
predicates and continuations, such a coalgebra has a canonical interpretation
of the modality by evaluation of continuations. We show that this continuation
semantics is equivalent to the coalgebraic semantics for fixpoint modal logic.
We then reformulate the current construction for coalgebraic models of CTL*.
These models are usually required to have an infinitary trace/maximal execution
map, characterized as the greatest fixpoint of a special operator. Instead, we
allow coalgebraic models of CTL* to employ non-maximal fixpoints, which we call
execution maps. Under this reformulation, we establish a general result on
transferring execution maps via monad morphisms. From this result, we obtain
that continuation semantics is equivalent to the coalgebraic semantics for
CTL*. We also identify a sufficient condition under which CTL can be encoded
into fixpoint modal logic under continuation semantics.

</details>


### [58] [Curved Boolean Logic: A Contextual Generalization of Propositional Logic with Algorithmic Consequences](https://arxiv.org/abs/2510.04716)
*Maximilian R. P. von Liechtenstein*

Main category: cs.LO

TL;DR: CBL扩展了命题逻辑，允许局部真值分配不扩展到单一全局赋值，类似于几何中的曲率概念。论文提供了等价语义和上下文感知证明演算，形式化了CBL-SAT及其复杂性，并提出了操作算子来在经典硬件上提前修剪矛盾。


<details>
  <summary>Details</summary>
Motivation: 将几何中的曲率概念引入逻辑系统，允许局部不一致性存在，从而更好地建模现实世界中的不确定性和噪声。

Method: 使用层理论和排他图语义，开发上下文感知证明演算，定义CBL-SAT问题，提出CBL-AC和CBL-CONS操作算子，并建模多种噪声类型。

Result: 证明了CBL-SAT在一般情况下是NP完全的，提供了操作算子来优化计算，并开发了统计显著性检验方法。

Conclusion: CBL为处理局部不一致性提供了新框架，与KCBS、CSW和层理论相关，在SAT/CSP和大型语言模型的鲁棒性方面有应用前景。

Abstract: Curved Boolean Logic (CBL) generalizes propositional logic by allowing local
truth assignments that do not extend to a single global valuation, analogous to
curvature in geometry. We give equivalent sheaf and exclusivity-graph semantics
and a context-aware proof calculus that is conservative in the flat limit. We
formalize CBL-SAT and basic complexity (NP-complete in general) and present
operational operators (CBL-AC and CBL-CONS) that prune contradictions earlier
on classical hardware. We model noise with iid, AR(1)-correlated, and
adversarial bounded perturbations and provide permutation-based significance
with Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files)
regenerates all figures and statistics. We position CBL relative to KCBS, CSW,
and sheaf frameworks and outline links to SAT/CSP and robustness/adapter
stability in large language models.

</details>


### [59] [One rig to control them all](https://arxiv.org/abs/2510.05032)
*Chris Heunen,Robin Kaarsgaard,Louis Lemonnier*

Main category: cs.LO

TL;DR: 提出了一个计算控制理论，包含7个可解释的方程，用于构建受控电路，适用于可逆布尔电路和量子电路。


<details>
  <summary>Details</summary>
Motivation: 为计算控制提供一个理论基础，通过可解释的方程来构建受控电路。

Method: 在基础电路prop中添加7个方程来构建受控电路，并证明其语义对应于在基础prop上取自由rig范畴。

Result: 成功构建了受控电路，并在可逆布尔电路和量子电路中得到验证。

Conclusion: 提出的理论为计算控制提供了坚实的数学基础，能够系统性地构建受控电路。

Abstract: We introduce a theory for computational control, consisting of seven
naturally interpretable equations. Adding these to a prop of base circuits
constructs controlled circuits, borne out in examples of reversible Boolean
circuits and quantum circuits. We prove that this syntactic construction
semantically corresponds to taking the free rig category on the base prop.

</details>
