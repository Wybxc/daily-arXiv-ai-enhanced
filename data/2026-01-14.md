<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 11]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [S4 modal sequent calculus as intermediate logic and intermediate language](https://arxiv.org/abs/2601.08071)
*Jean Caspar,Guillaume Munch-Maccagnoni*

Main category: cs.LO

TL;DR: 该论文提出基于延续的中间语言对应中间逻辑的观点，特别是CPS中间语言中的二阶延续对应带有模态类型限制的经典模态逻辑S4，这构成了一种中间逻辑。


<details>
  <summary>Details</summary>
Motivation: 论文旨在建立编译器中间表示的理论基础，将基于延续的中间语言与中间逻辑联系起来，以支持表达性程序转换同时保持可高效编译的特性（如延续的"可堆栈性"）。

Method: 引入三类别极化相继式演算用于S4逻辑，配合将堆与栈分离的操作机器模型，研究S4模态片段的可堆栈性特性。

Result: 证明了CPS中间语言中的二阶延续对应带有模态类型限制的经典模态逻辑S4，根据哥德尔-麦金西-塔斯基定理，这确实构成了一种中间逻辑。

Conclusion: 基于延续的中间语言与中间逻辑之间存在对应关系，这种理论联系为编译器中间表示提供了逻辑基础，有助于在保持编译效率的同时实现表达性程序转换。

Abstract: In this short paper, we advocate for the idea that continuation-based intermediate languages correspond to intermediate logics. The goal of intermediate languages is to serve as a basis for compiler intermediate representations, allowing to represent expressive program transformations for optimisation and compilation, while preserving the properties that make programs compilable efficiently in the first place, such as the "stackability" of continuations. Intermediate logics are logics between intuitionistic and classical logic in terms of provability. Second-class continuations used in CPS-based intermediate languages correspond to a classical modal logic S4 with the added restriction that implications may only return modal types. This indeed corresponds to an intermediate logic, owing to the Gödel-McKinsey-Tarski theorem which states the intuitionistic nature of the modal fragment of S4. We introduce a three-kinded polarised sequent calculus for S4, together with an operational machine model that separates a heap from a stack. With this model we study a stackability property for the modal fragment of S4.

</details>


### [2] [Forcing and Interpolation in First-Order Hybrid Logic with rigid symbols](https://arxiv.org/abs/2601.08432)
*Daniel Găină,Go Hashimoto*

Main category: cs.LO

TL;DR: 该论文为多类一阶混合逻辑建立了Craig插值性质的类似物，使用强制技术动态添加新常量，并推导出满足Robinson一致性和Craig插值性质的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究多类一阶混合逻辑的插值性质，特别是在可能包含空域的模型情况下，建立类似经典一阶逻辑的Craig插值定理。

Method: 开发了一种强制技术，动态地向底层签名添加新常量，同时保持一致性。该方法特别处理了可能包含空域的模型情况。

Result: 建立了多类一阶混合逻辑的Craig插值性质类似物，推导出满足Robinson一致性和Craig插值性质的签名方块的充分条件。

Conclusion: 通过强制技术成功扩展了Craig插值性质到多类一阶混合逻辑，为这类逻辑系统提供了重要的元逻辑性质。

Abstract: In this paper, we establish an analogue of Craig Interpolation Property for a many-sorted variant of first-order hybrid logic. We develop a forcing technique that dynamically adds new constants to the underlying signature in a way that preserves consistency, even in the presence of models with possibly empty domains. Using this forcing method, we derive general criteria that are sufficient for a signature square to satisfy both Robinson's consistency and Craig interpolation properties.

</details>


### [3] [Degree-preserving Godel logics with an involution: intermediate logics and (ideal) paraconsistency](https://arxiv.org/abs/2601.08474)
*M. E. Coniglio,F. Esteva,J. Gispert,L. Godo*

Main category: cs.LO

TL;DR: 研究介于带对合的Gödel模糊逻辑的度保持伴随与经典命题逻辑之间的中间逻辑，以及它们有限值对应物的中间逻辑。这些度保持Gödel逻辑虽然对Gödel否定是爆炸性的，但对对合否定是次协调的。引入了饱和次协调性概念，并完全刻画了理想和饱和次协调逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究模糊逻辑与经典逻辑之间的中间逻辑系统，特别是关注次协调性（paraconsistency）在这些逻辑中的表现。虽然度保持Gödel逻辑对Gödel否定是爆炸性的，但对对合否定表现出次协调性，这为研究次协调逻辑提供了新的视角。

Method: 引入饱和次协调性概念（比理想次协调性更弱），系统研究带对合的度保持Gödel模糊逻辑与经典逻辑之间的中间逻辑。分析有限值Gödel逻辑和Lukasiewicz逻辑的度保持版本，完全刻画理想和饱和次协调逻辑的特征。

Result: 完全刻画了介于带对合的度保持n值Gödel模糊逻辑与经典命题逻辑之间的理想和饱和次协调逻辑。在度保持有限值Lukasiewicz逻辑的中间逻辑家族中，识别出了大量饱和次协调逻辑。

Conclusion: 度保持Gödel逻辑虽然对Gödel否定是爆炸性的，但对对合否定表现出次协调性。饱和次协调性为研究次协调逻辑提供了有用的概念框架，在Gödel和Lukasiewicz逻辑的度保持版本中都发现了丰富的次协调逻辑结构。

Abstract: In this paper we study intermediate logics between the degree preserving companion of Godel fuzzy logic with an involution and classical propositional logic CPL, as well as the intermediate logics of their finite-valued counterparts. Although these degree-preserving Godel logics are explosive with respect to Godel negation, they are paraconsistent with respect to the involutive negation. We introduce the notion of saturated paraconsistency, a weaker notion than ideal paraconsistency, and we fully characterize the ideal and the saturated paraconsistent logics between the degree-preserving n-valued Godel fuzzy logic with an involution and CPL. We also identify a large family of saturated paraconsistent logics in the family of intermediate logics for degree-preserving finite-valued Lukasiewicz logics.

</details>


### [4] [On Deciding Constant Runtime of Linear Loops](https://arxiv.org/abs/2601.08492)
*Florian Frohn,Jürgen Giesl,Peter Giesl,Nils Lommen*

Main category: cs.LO

TL;DR: 本文研究线性单路径循环程序的常数运行时判定问题，针对具有实特征值的矩阵更新，证明了在实数或有理数域上可判定循环运行时是否对所有输入都有常数上界。


<details>
  <summary>Details</summary>
Motivation: 在自动程序验证中，如果所有循环都有常数运行时，则线性while程序的安全性是可判定的。该问题与多相线性排序函数的存在性密切相关，而后者常用于终止性和复杂度分析。因此，判定循环运行时是否常数上界是程序验证中的重要问题。

Method: 研究形式为while φ do x ← Ax + b end的线性单路径循环，其中A具有实特征值。针对变量取值于实数或有理数域的情况，开发判定循环运行时是否对所有输入都有常数上界的决策过程。

Result: 证明了对于具有实特征值的线性单路径循环，在实数或有理数域上可判定其运行时是否对所有输入都有常数上界。为实现实际应用，还提供了该决策过程的实现。

Conclusion: 本文解决了线性循环程序常数运行时判定的重要问题，为程序验证提供了理论基础和实用工具，特别是与多相线性排序函数和程序安全性判定的连接具有重要意义。

Abstract: We consider linear single-path loops of the form \[
  \textbf{while} \quad \varphi \quad \textbf{do} \quad \vec{x} \gets A \vec{x} + \vec{b} \quad \textbf{end} \] where $\vec{x}$ is a vector of variables, the loop guard $\varphi$ is a conjunction of linear inequations over the variables $\vec{x}$, and the update of the loop is represented by the matrix $A$ and the vector $\vec{b}$. It is already known that termination of such loops is decidable. In this work, we consider loops where $A$ has real eigenvalues, and prove that it is decidable whether the loop's runtime (for all inputs) is bounded by a constant if the variables range over $\mathbb R$ or $\mathbb Q$. This is an important problem in automatic program verification, since safety of linear while-programs is decidable if all loops have constant runtime, and it is closely connected to the existence of multiphase-linear ranking functions, which are often used for termination and complexity analysis. To evaluate its practical applicability, we also present an implementation of our decision procedure.

</details>


### [5] [The Unification Type of an Equational Theory May Depend on the Instantiation Preorder: From Results for Single Theories to Results for Classes of Theories](https://arxiv.org/abs/2601.08710)
*Franz Baader,Oliver Fernández Gil*

Main category: cs.LO

TL;DR: 论文研究了等式理论的统一化类型，发现其类型取决于使用受限还是不受限的实例化预序，并证明了多个理论在不受限预序下的统一化类型为无穷型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解等式理论的统一化类型如何随实例化预序（受限vs不受限）的变化而变化。已有研究表明ACUI理论在受限预序下是单一型，但在不受限预序下不是单一型，甚至不是有限型。本文旨在更全面地探索这一现象。

Method: 通过理论分析和证明，研究了多种等式理论在不受限实例化预序下的统一化类型。特别关注正则且有限、正则且局部有限、正则且幺半群并满足附加条件的理论类别，证明它们是诺特型的。

Result: 证明了ACUI理论在不受限实例化预序下是无穷型（排除零型）。ACU和AC理论在不受限预序下也是无穷型，尽管它们在受限情况下分别是单一型和有限型。还证明了某些理论从受限预序的零型提升到不受限预序的无穷型。

Conclusion: 等式理论的统一化类型确实依赖于使用的实例化预序。本文不仅确定了更多理论在不受限预序下的类型，还证明了正则且有限、正则且局部有限、正则且幺半群等理论类别是诺特型的，因此不能有不受限统一化类型零。

Abstract: The unification type of an equational theory is defined using a preorder on substitutions, called the instantiation preorder, whose scope is either restricted to the variables occurring in the unification problem, or unrestricted such that all variables are considered. It has been known for more than three decades that the unification type of an equational theory may vary, depending on which instantiation preorder is used. More precisely, it was shown in 1991 that the theory ACUI of an associative, commutative, and idempotent binary function symbol with a unit is unitary w.r.t. the restricted instantiation preorder, but not unitary w.r.t. the unrestricted one. In 2016 this result was strengthened by showing that the unrestricted type of this theory also cannot be finitary. In the conference version of this article, we considerably improved on this result by proving that ACUI is infinitary w.r.t. the unrestricted instantiation preorder, thus precluding type zero. We also showed that, w.r.t. this preorder, the unification type of ACU (where idempotency is removed from the axioms) and of AC (where additionally the unit is removed) is infinitary, though it is respectively unitary and finitary in the restricted case. In the other direction, we proved (using the example of unification in the description logic EL) that the unification type may actually improve from type zero to infinitary when switching from the restricted instantiation preorder to the unrestricted one. In the present article, we not only determine the unrestricted unification type of considerably more equational theories, but we also prove general results for whole classes of theories. In particular, we show that theories that are regular and finite, regular and locally finite, or regular, monoidal, and satisfy an additional condition are Noetherian, and thus cannot have unrestricted unification type zero.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Formalization and Implementation of Safe Destination Passing in Pure Functional Programming Settings](https://arxiv.org/abs/2601.08529)
*Thomas Bagrel*

Main category: cs.PL

TL;DR: 开发了带目的地的λ演算λ_d，通过模态类型系统结合线性类型和年龄系统实现安全的目的地传递，并在Haskell中实现原型，展示了在遍历大型数据结构时的应用潜力


<details>
  <summary>Details</summary>
Motivation: 目的地传递风格编程允许调用者控制内存管理，在纯函数式编程中能够实现传统不可变数据结构无法表达的程序。现有系统表达能力有限，需要更灵活且安全的目的地传递机制。

Method: 1. 开发核心λ演算λ_d，采用模态类型系统结合线性类型和年龄系统来管理作用域，确保目的地传递的安全性
2. 在Coq证明助手中形式化证明类型安全性
3. 将核心演算适配到Haskell中，通过类型系统限制保持安全性
4. 优化实现以恢复灵活性，但增加用户复杂度

Result: 1. λ_d演算比现有类似系统更具表达能力
2. 成功在Coq中形式化证明了类型安全性
3. 在Haskell中实现了原型，在遍历列表和数据树等大型数据结构时显示出有前景的结果
4. 通过优化实现恢复了大部分灵活性，但增加了用户复杂度

Conclusion: 目的地传递风格编程在纯函数式语言中具有实用价值，特别是在处理大型数据结构时。虽然类型系统限制需要在安全性和灵活性之间权衡，但通过适当的实现策略可以在Haskell等现有语言中有效应用目的地传递技术。

Abstract: Destination-passing style programming introduces destinations, which represent the address of a write-once memory cell. These destinations can be passed as function parameters, allowing the caller to control memory management: the callee simply fills the cell instead of allocating space for a return value. While typically used in systems programming, destination passing also has applications in pure functional programming, where it enables programs that were previously unexpressible using usual immutable data structures.
  In this thesis, we develop a core λ-calculus with destinations, {λ_d}. Our new calculus is more expressive than similar existing systems, with destination passing designed to be as flexible as possible. This is achieved through a modal type system combining linear types with a system of ages to manage scopes, in order to make destination-passing safe. Type safety of our core calculus was proved formally with the Coq proof assistant.
  Then, we see how this core calculus can be adapted into an existing pure functional language, Haskell, whose type system is less powerful than our custom theoretical one. Retaining safety comes at the cost of removing some flexibility in the handling of destinations. We later refine the implementation to recover much of this flexibility, at the cost of increased user complexity.
  The prototype implementation in Haskell shows encouraging results for adopting destination-passing style programming when traversing or mapping over large data structures such as lists or data trees.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [SECite: Analyzing and Summarizing Citations in Software Engineering Literature](https://arxiv.org/abs/2601.07939)
*Shireesh Reddy Pyreddy,Khaja Valli Pathan,Hasan Masum,Tarannum Shaila Zaman*

Main category: cs.SE

TL;DR: SECite：基于引文情感分析评估学术影响力的新方法，通过NLP技术分析引文情感并生成特定情感摘要


<details>
  <summary>Details</summary>
Motivation: 传统文献综述仅反映作者自我陈述的视角，而分析其他研究者如何讨论和引用论文能提供更深入、更实用的理解。需要一种方法来评估学术影响力，超越简单的引用计数，关注引文中的情感和评价内容。

Method: 开发半自动化流程提取九篇研究论文的引文，应用先进的NLP技术和无监督机器学习对引文语句进行正面/负面情感分类。除了情感分类，还使用生成式AI生成特定情感摘要，捕捉每篇目标论文的优势和局限，这些摘要既来自聚类的引文组，也来自全文分析。

Result: 研究揭示了学术社区对这些工作的认知模式，突出了外部引文反馈与作者自我陈述之间的契合与分歧。通过整合引文情感分析和基于LLM的摘要生成，为评估学术贡献提供了全面框架。

Conclusion: SECite方法通过分析引文情感和生成特定情感摘要，能够更全面地评估学术论文的实际影响和接受度，超越了传统引用计数和作者自我陈述的局限性，为文献综述和学术评价提供了新视角。

Abstract: Identifying the strengths and limitations of a research paper is a core component of any literature review. However, traditional summaries reflect only the authors' self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. In this research, we introduce SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. We develop a semi-automated pipeline to extract citations referencing nine research papers and apply advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Beyond sentiment classification, we use generative AI to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. Our findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors' own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions.

</details>


### [8] [Towards Verifiably Safe Tool Use for LLM Agents](https://arxiv.org/abs/2601.08012)
*Aarya Doshi,Yining Hong,Congying Xu,Eunsuk Kang,Alexandros Kapravelos,Christian Kästner*

Main category: cs.SE

TL;DR: 提出结合STPA安全分析与增强MCP框架的方法，为LLM智能体提供形式化安全保障，减少对人工确认的依赖


<details>
  <summary>Details</summary>
Motivation: LLM智能体通过工具调用能执行复杂任务，但可能引发敏感数据泄露、关键记录被覆盖等风险，现有方法无法保证系统安全，需要形式化安全保障

Method: 1) 应用系统理论过程分析(STPA)识别智能体工作流中的危险，推导安全需求，形式化为数据流和工具序列的可执行规范；2) 引入能力增强的模型上下文协议(MCP)框架，要求对能力、机密性和信任级别进行结构化标注

Result: 该方法将LLM智能体安全从临时可靠性修复转向具有形式化保证的主动防护，减少对用户确认的依赖，使自主性成为有意识的设计选择

Conclusion: 结合STPA安全分析和增强MCP框架的方法为LLM智能体提供了形式化安全保障，实现了从临时修复到主动防护的转变

Abstract: Large language model (LLM)-based AI agents extend LLM capabilities by enabling access to tools such as data sources, APIs, search engines, code sandboxes, and even other agents. While this empowers agents to perform complex tasks, LLMs may invoke unintended tool interactions and introduce risks, such as leaking sensitive data or overwriting critical records, which are unacceptable in enterprise contexts. Current approaches to mitigate these risks, such as model-based safeguards, enhance agents' reliability but cannot guarantee system safety. Methods like information flow control (IFC) and temporal constraints aim to provide guarantees but often require extensive human annotation. We propose a process that starts with applying System-Theoretic Process Analysis (STPA) to identify hazards in agent workflows, derive safety requirements, and formalize them as enforceable specifications on data flows and tool sequences. To enable this, we introduce a capability-enhanced Model Context Protocol (MCP) framework that requires structured labels on capabilities, confidentiality, and trust level. Together, these contributions aim to shift LLM-based agent safety from ad hoc reliability fixes to proactive guardrails with formal guarantees, while reducing dependence on user confirmation and making autonomy a deliberate design choice.

</details>


### [9] [Automating API Documentation from Crowdsourced Knowledge](https://arxiv.org/abs/2601.08036)
*Bonan Kou,Zijie Zhou,Muhao Chen,Tianyi Zhang*

Main category: cs.SE

TL;DR: AutoDoc：利用LLM从Stack Overflow讨论中提取API知识，自动生成更准确、更全面的API文档，解决官方文档过时和不完整的问题。


<details>
  <summary>Details</summary>
Motivation: 官方API文档经常存在过时和不完整的问题，而Stack Overflow等在线讨论平台包含大量实用的API知识，但缺乏系统化的整理。需要一种方法能够自动从这些讨论中提取知识并生成高质量的API文档。

Method: 1. 使用微调的密集检索模型从Stack Overflow帖子中识别7种类型的API知识；2. 利用GPT-4o总结提取的知识；3. 设计两个专门组件处理LLM幻觉和内容冗余问题。

Result: 在48个不同流行度的API上评估，AutoDoc生成的文档比基线方法准确度高77.7%，重复率低9.5%，包含34.4%官方文档未覆盖的知识。用户研究显示所有参与者都认为AutoDoc生成的文档更全面、简洁、有帮助。

Conclusion: 通过精心设计对抗LLM幻觉和信息冗余，利用LLM从在线讨论中生成API文档是可行的。AutoDoc不仅能让大型LLM生成高质量文档，还能让较小的开源模型达到可比效果。

Abstract: API documentation is crucial for developers to learn and use APIs. However, it is known that many official API documents are obsolete and incomplete. To address this challenge, we propose a new approach called AutoDoc that generates API documents with API knowledge extracted from online discussions on Stack Overflow (SO). AutoDoc leverages a fine-tuned dense retrieval model to identify seven types of API knowledge from SO posts. Then, it uses GPT-4o to summarize the API knowledge in these posts into concise text. Meanwhile, we designed two specific components to handle LLM hallucination and redundancy in generated content. We evaluated AutoDoc against five comparison baselines on 48 APIs of different popularity levels. Our results indicate that the API documents generated by AutoDoc are up to 77.7% more accurate, 9.5% less duplicated, and contain 34.4% knowledge uncovered by the official documents. We also measured the sensitivity of AutoDoc to the choice of different LLMs. We found that while larger LLMs produce higher-quality API documents, AutoDoc enables smaller open-source models (e.g., Mistral-7B-v0.3) to achieve comparable results. Finally, we conducted a user study to evaluate the usefulness of the API documents generated by AutoDoc. All participants found API documents generated by AutoDoc to be more comprehensive, concise, and helpful than the comparison baselines. This highlights the feasibility of utilizing LLMs for API documentation with careful design to counter LLM hallucination and information redundancy.

</details>


### [10] [Cognitive Biases in LLM-Assisted Software Development](https://arxiv.org/abs/2601.08045)
*Xinyi Zhou,Zeinadsadat Saghi,Sadra Sabouri,Rahul Pandita,Mollie McGuire,Souti Chattopadhyay*

Main category: cs.SE

TL;DR: 该研究首次全面探讨了LLM辅助开发中的认知偏见，发现48.8%的程序员行为存在偏见，其中56.4%与LLM交互相关，并提出了15个偏见分类和缓解建议。


<details>
  <summary>Details</summary>
Motivation: LLM在软件开发中的广泛应用正在将编程从解决方案生成转变为解决方案评估活动，这种转变可能放大现有决策偏见或产生全新偏见。需要研究认知偏见在AI协作开发中的表现和影响。

Method: 采用混合方法：对14名学生和专业开发者进行观察研究，随后对22名开发者进行问卷调查。定性比较传统非LLM工作流与LLM相关偏见类别，系统分析了90个特定于开发者-LLM交互的认知偏见。

Result: 研究发现48.8%的程序员行为存在偏见，其中56.4%的偏见行为与开发者-LLM交互相关。LLM相关行为更可能与新型偏见相关联。开发了由认知心理学家验证的15个偏见分类法。

Conclusion: LLM辅助开发中存在显著的认知偏见问题，需要为开发者提供工具和实践建议，并为LLM工具构建者提供缓解偏见的建议，以改善人-AI编程协作。

Abstract: The widespread adoption of Large Language Models (LLMs) in software development is transforming programming from a solution-generative to a solution-evaluative activity. This shift opens a pathway for new cognitive challenges that amplify existing decision-making biases or create entirely novel ones. One such type of challenge stems from cognitive biases, which are thinking patterns that lead people away from logical reasoning and result in sub-optimal decisions. How do cognitive biases manifest and impact decision-making in emerging AI-collaborative development? This paper presents the first comprehensive study of cognitive biases in LLM-assisted development. We employ a mixed-methods approach, combining observational studies with 14 student and professional developers, followed by surveys with 22 additional developers. We qualitatively compare categories of biases affecting developers against the traditional non-LLM workflows. Our findings suggest that LLM-related actions are more likely to be associated with novel biases. Through a systematic analysis of 90 cognitive biases specific to developer-LLM interactions, we develop a taxonomy of 15 bias categories validated by cognitive psychologists. We found that 48.8% of total programmer actions are biased, and developer-LLM interactions account for 56.4% of these biased actions. We discuss how these bias categories manifest, present tools and practices for developers, and recommendations for LLM tool builders to help mitigate cognitive biases in human-AI programming.

</details>


### [11] [Coverage-Guided Road Selection and Prioritization for Efficient Testing in Autonomous Driving Systems](https://arxiv.org/abs/2601.08609)
*Qurban Ali,Andrea Stocco,Leonardo Mariani,Oliviero Riganelli*

Main category: cs.SE

TL;DR: 提出基于几何和行为特征的ADAS测试优先级框架，减少冗余测试89%同时保留79%失败场景，早期故障检测提升95倍


<details>
  <summary>Details</summary>
Motivation: ADAS测试需要大量道路场景数据，但现有数据集存在冗余案例，降低了测试效率而不改善故障检测能力

Method: 基于ADAS驾驶行为的几何和动态特征对道路场景进行聚类，选择代表性案例保证覆盖率，然后根据几何复杂度、驾驶难度和历史故障对道路进行优先级排序

Result: 在OPENCAT数据集和Udacity自动驾驶模拟器上评估，平均减少测试套件规模89%，保留79%失败道路场景，优先级策略相比随机基线早期故障检测提升达95倍

Conclusion: 提出的测试优先级框架能有效减少ADAS测试冗余，提高测试效率，同时保持故障检测能力，显著加速早期故障发现

Abstract: Autonomous Driving Assistance Systems (ADAS) rely on extensive testing to ensure safety and reliability, yet road scenario datasets often contain redundant cases that slow down the testing process without improving fault detection. To address this issue, we present a novel test prioritization framework that reduces redundancy while preserving geometric and behavioral diversity. Road scenarios are clustered based on geometric and dynamic features of the ADAS driving behavior, from which representative cases are selected to guarantee coverage. Roads are finally prioritized based on geometric complexity, driving difficulty, and historical failures, ensuring that the most critical and challenging tests are executed first. We evaluate our framework on the OPENCAT dataset and the Udacity self-driving car simulator using two ADAS models. On average, our approach achieves an 89% reduction in test suite size while retaining an average of 79% of failed road scenarios. The prioritization strategy improves early failure detection by up to 95x compared to random baselines.

</details>


### [12] [LLMs in Code Vulnerability Analysis: A Proof of Concept](https://arxiv.org/abs/2601.08691)
*Shaznin Sultana,Sadia Afreen,Nasir U. Eisty*

Main category: cs.SE

TL;DR: 研究评估了代码专用和通用大语言模型在软件安全任务中的表现，发现微调方法优于零样本和少样本方法，代码专用模型在复杂任务上表现更好，但当前评估指标存在不足。


<details>
  <summary>Details</summary>
Motivation: 传统软件安全分析方法难以应对现代代码库的规模和复杂性，需要智能自动化来更高效、准确地检测、评估和修复漏洞。

Method: 评估了五对最新的大语言模型（包括代码专用和通用开源模型），在两个公认的C/C++漏洞数据集（Big-Vul和Vul-Repair）上进行测试，比较了微调和基于提示的方法。

Result: 微调方法在所有任务和模型上都优于零样本和少样本方法；代码专用模型在复杂任务的零样本和少样本设置中表现更佳，而通用模型效果接近；当前评估指标（CodeBLEU、CodeBERTScore、BLEU、ChrF）在衡量修复质量方面存在不足。

Conclusion: 本研究通过探索先进大语言模型在改进漏洞分析和修复方面的潜力，为软件安全社区做出了贡献。

Abstract: Context: Traditional software security analysis methods struggle to keep pace with the scale and complexity of modern codebases, requiring intelligent automation to detect, assess, and remediate vulnerabilities more efficiently and accurately. Objective: This paper explores the incorporation of code-specific and general-purpose Large Language Models (LLMs) to automate critical software security tasks, such as identifying vulnerabilities, predicting severity and access complexity, and generating fixes as a proof of concept. Method: We evaluate five pairs of recent LLMs, including both code-based and general-purpose open-source models, on two recognized C/C++ vulnerability datasets, namely Big-Vul and Vul-Repair. Additionally, we compare fine-tuning and prompt-based approaches. Results: The results show that fine-tuning uniformly outperforms both zero-shot and few-shot approaches across all tasks and models. Notably, code-specialized models excel in zero-shot and few-shot settings on complex tasks, while general-purpose models remain nearly as effective. Discrepancies among CodeBLEU, CodeBERTScore, BLEU, and ChrF highlight the inadequacy of current metrics for measuring repair quality. Conclusions: This study contributes to the software security community by investigating the potential of advanced LLMs to improve vulnerability analysis and remediation.

</details>


### [13] ["Where is My Troubleshooting Procedure?": Studying the Potential of RAG in Assisting Failure Resolution of Large Cyber-Physical System](https://arxiv.org/abs/2601.08706)
*Maria Teresa Rossi,Leonardo Mariani,Oliviero Riganelli,Giuseppe Filomento,Danilo Giannone,Paolo Gavazzo*

Main category: cs.SE

TL;DR: RAG技术能帮助操作员在复杂工业环境中快速检索故障排除程序，但需要交叉验证建议后才能执行


<details>
  <summary>Details</summary>
Motivation: 工业环境中操作员需要从大量技术手册中检索故障排除程序，但手册的复杂性和自然语言描述会显著降低关键事件中的检索效率

Method: 基于检索增强生成(RAG)技术开发对话式界面工具，分析Fincantieri公司的故障排除程序进行实验验证

Result: RAG能够帮助操作员对故障症状做出快速反应，但需要在执行建议前采取特定措施进行交叉验证

Conclusion: RAG技术可以有效辅助工业操作员检索故障排除程序，但实际应用中需要建立验证机制确保建议的可靠性

Abstract: In today's complex industrial environments, operators must often navigate through extensive technical manuals to identify troubleshooting procedures that may help react to some observed failure symptoms. These manuals, written in natural language, describe many steps in detail. Unfortunately, the number, magnitude, and articulation of these descriptions can significantly slow down and complicate the retrieval of the correct procedure during critical incidents. Interestingly, Retrieval Augmented Generation (RAG) enables the development of tools based on conversational interfaces that can assist operators in their retrieval tasks, improving their capability to respond to incidents. This paper presents the results of a set of experiments that derive from the analysis of the troubleshooting procedures available in Fincantieri, a large international company developing complex naval cyber-physical systems. Results show that RAG can assist operators in reacting promptly to failure symptoms, although specific measures have to be taken into consideration to cross-validate recommendations before actuating them.

</details>


### [14] [Revisiting "Revisiting Neuron Coverage for DNN Testing: A Layer-Wise and Distribution-Aware Criterion": A Critical Review and Implications on DNN Coverage Testing](https://arxiv.org/abs/2601.08729)
*Jinhan Kim,Nargiz Humbatova,Gunel Jahangirova,Shin Yoo,Paolo Tonella*

Main category: cs.SE

TL;DR: 对ICSE 2023提出的Neural Coverage（NLC）进行批判性审查，指出其在理论假设、设计原则和实证有效性方面的问题，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: NLC虽然提出了八个设计需求并展示了良好的实证性能，但作者质疑其理论和实证假设，认为NLC偏离了覆盖率准则的核心原则，且实证研究存在有效性威胁。

Method: 通过批判性分析NLC的理论基础，识别其在单调性、测试套件顺序独立性等核心原则上的偏差，以及对协方差矩阵关键属性的考虑不足。同时进行实证验证来支持这些主张。

Result: 实证验证证实了作者的质疑：NLC确实偏离了覆盖率准则的核心原则，其设计存在理论缺陷，且原始研究的实证有效性受到测试套件排序等问题的威胁。

Conclusion: 本文揭示了NLC在理论和实证方面的局限性，提出了未来DNN覆盖率指标的改进方向，并讨论了这些发现对深度学习测试领域的重要意义。

Abstract: We present a critical review of Neural Coverage (NLC), a state-of-the-art DNN coverage criterion by Yuan et al. at ICSE 2023. While NLC proposes to satisfy eight design requirements and demonstrates strong empirical performance, we question some of their theoretical and empirical assumptions. We observe that NLC deviates from core principles of coverage criteria, such as monotonicity and test suite order independence, and could more fully account for key properties of the covariance matrix. Additionally, we note threats to the validity of the empirical study, related to the ground truth ordering of test suites. Through our empirical validation, we substantiate our claims and propose improvements for future DNN coverage metrics. Finally, we conclude by discussing the implications of these insights.

</details>


### [15] [TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback](https://arxiv.org/abs/2601.08734)
*Prithwish Jana,Sam Davidson,Bhavana Bhasker,Andrey Kan,Anoop Deoras,Laurent Callot*

Main category: cs.SE

TL;DR: TerraFormer是一个神经符号框架，通过监督微调和验证器引导的强化学习，结合形式验证工具，显著提升IaC生成和变异的正确性，超越了许多更大的LLM模型。


<details>
  <summary>Details</summary>
Motivation: 自动化基础设施即代码(IaC)具有挑战性，大型语言模型(LLM)从自然语言生成配置时经常出错，需要提高IaC生成和变异的正确性。

Method: 提出TerraFormer神经符号框架，结合监督微调与验证器引导的强化学习，使用形式验证工具提供语法、可部署性和策略合规性反馈。创建了两个高质量NL-to-IaC数据集TF-Gen和TF-Mutn。

Result: TerraFormer相比基础LLM在IaC-Eval上提升15.94%正确性，在TF-Gen和TF-Mutn测试集上分别提升11.65%和19.60%。超越了许多更大的模型，在IaC-Eval排名第三，实现了最佳实践和安全性合规。

Conclusion: TerraFormer通过神经符号方法有效解决了IaC自动化的挑战，在正确性和合规性方面显著优于现有方法，包括更大的LLM模型。

Abstract: Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50x larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen (Test), and 19.60% on TF-Mutn (Test). It outperforms larger models on both TF-Gen (Test) and TF-Mutn (Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.

</details>


### [16] [Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs](https://arxiv.org/abs/2601.08773)
*Manideep Reddy Chinthareddy*

Main category: cs.SE

TL;DR: 比较三种RAG检索管道在Java代码库上的表现：向量检索、LLM生成知识图谱和AST确定性知识图谱，发现AST方法在覆盖率、成本和准确性方面最优。


<details>
  <summary>Details</summary>
Motivation: 传统基于向量相似度的RAG在软件工程中能捕获主题相似性，但在多跳架构推理（如控制器-服务-仓库链、接口驱动连接、继承关系）上存在不足，需要更好的检索方法。

Method: 在三个Java代码库（Shopizer、ThingsBoard、OpenMRS Core）上基准测试三种检索管道：A) 纯向量检索（No-Graph RAG）；B) LLM生成知识图谱RAG（LLM-KB）；C) 确定性AST派生知识图谱RAG（DKB），使用Tree-sitter和双向遍历构建。每个仓库使用15个架构和代码追踪查询，测量索引时间、查询延迟、语料覆盖率、成本和答案正确性。

Result: DKB在几秒内构建图谱，而LLM-KB需要更长时间；LLM-KB存在索引不完整问题（Shopizer中377个文件被跳过）；DKB端到端成本相对向量基线适中，而LLM-KB成本随仓库规模增加显著上升；查询延迟方面No-Graph和DKB相似，LLM-KB更慢且波动大；在Shopizer问题上，DKB正确率最高，LLM-KB次之，纯向量基线在架构查询上表现最差且幻觉风险最高。

Conclusion: 确定性AST派生图谱相比LLM提取图谱，在显著降低索引成本的同时，提供更可靠的覆盖率和多跳基础，是软件工程RAG中更优的检索方法。

Abstract: Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS Core): (A) vector-only No-Graph RAG, (B) an LLM-generated knowledge graph RAG (LLM-KB), and (C) a deterministic AST-derived knowledge graph RAG (DKB) built with Tree-sitter and bidirectional traversal.
  Using 15 architecture and code-tracing queries per repository, we measure indexing time, query latency, corpus coverage, cost, and answer correctness. DKB builds its graph in seconds, while LLM-KB requires much longer graph generation. LLM-KB also shows indexing incompleteness: on Shopizer, 377 files are skipped or missed, reducing embedded chunk coverage and graph size compared to DKB. End-to-end cost is modest for DKB relative to the vector-only baseline but much higher for LLM-KB, especially as repository scale increases. Query latency is similar for No-Graph and DKB, while LLM-KB is slower and more variable. On the Shopizer question suite, DKB achieves the highest correctness, LLM-KB is close behind, and the vector-only baseline performs worst on upstream architectural queries and has the highest hallucination risk. Overall, deterministic AST-derived graphs provide more reliable coverage and multi-hop grounding than LLM-extracted graphs at substantially lower indexing cost.

</details>


### [17] [APEX-SWE](https://arxiv.org/abs/2601.08806)
*Abhi Kottamasu,Akul Datta,Aakash Barthwal,Chirag Mahapatra,Ajay Arun,Adarsh Hiremath,Brendan Foody,Bertie Vidgen*

Main category: cs.SE

TL;DR: APEX-SWE是一个评估前沿AI模型能否执行有经济价值的软件工程工作的基准，包含集成任务和可观测性任务两类真实世界任务，Gemini 3 Pro表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注狭窄、定义明确的任务，无法反映真实世界的软件工程工作。需要一个新的基准来评估AI模型是否能执行有经济价值的软件工程任务。

Method: 提出APEX-SWE基准，包含两类任务：(1) 集成任务：在异构云原语、业务应用和基础设施即代码服务之间构建端到端系统；(2) 可观测性任务：使用日志、仪表板等遥测信号和非结构化上下文调试生产故障。评估了8个前沿模型。

Result: Gemini 3 Pro表现最佳，Pass@1得分为25%。分析显示，强大性能主要源于认知推理能力（区分假设与已验证事实的能力）与解决不确定性后再行动的能动性相结合。

Conclusion: APEX-SWE为评估AI模型在真实软件工程任务中的能力提供了新基准，开源了评估框架和开发集，强调认知推理和能动性对AI执行经济价值软件工程工作的重要性。

Abstract: We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks (n=100), which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models on APEX-SWE. Gemini 3 Pro (Thinking = High) performs best, with a Pass@1 score of 25\%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX-SWE evaluation harness and a dev set (n=50).

</details>
