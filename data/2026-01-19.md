<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.LO](#cs.LO) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [LogicLens: Leveraging Semantic Code Graph to explore Multi Repository large systems](https://arxiv.org/abs/2601.10773)
*Niko Usai,Dario Montagnini,Kristian Ilianov Iliev,Raffaele Camanzo*

Main category: cs.SE

TL;DR: LogicLens是一个基于语义多仓库图的对话式代理，帮助开发者探索复杂软件系统，结合代码分析和LLM语义增强，支持自然语言查询和动态子图检索。


<details>
  <summary>Details</summary>
Motivation: 理解大型软件系统具有挑战性，特别是当代码分布在多个仓库和微服务中时。开发者不仅需要理解代码结构，还需要理解隐含且分散的领域逻辑和运行时行为。

Method: 通过预处理构建语义多仓库图，结合AST解析和仓库遍历的语法代码分析，以及使用大型语言模型进行语义增强。该图捕获结构元素（文件、类、函数）和功能抽象（领域实体、操作、工作流）。然后通过自然语言交互动态检索相关子图并回答技术或功能查询。

Result: 在真实世界的多仓库场景中评估系统有效性，展示了包括影响分析和基于症状的调试在内的涌现能力，这些能力从语义图结构中自然产生。

Conclusion: LogicLens通过语义图表示和自然语言交互，为开发者探索复杂软件系统提供了有效工具，能够处理跨仓库的代码理解和推理问题。

Abstract: Understanding large software systems is a challenging task, especially when code is distributed across multiple repositories and microservices. Developers often need to reason not only about the structure of the code, but also about its domain logic and runtime behaviors, which are typically implicit and scattered. We introduce LogicLens, a reactive conversational agent that assists developers in exploring complex software systems through a semantic multi-repository graph. This graph is built in a preprocessing step by combining syntactic code analysis, via AST parsing and repository traversal, with semantic enrichment using Large Language Models (LLMs). The resulting graph captures both structural elements, such as files, classes, and functions, as well as functional abstractions like domain entities, operations, and workflows. Once the graph is constructed, LogicLens enables developers to interact with it via natural language, dynamically retrieving relevant subgraphs and answering technical or functional queries. We present the architecture of the system, discuss emergent behaviors, and evaluate its effectiveness on real-world multi-repository scenarios. We demonstrate emergent capabilities including impact analysis and symptom-based debugging that arise naturally from the semantic graph structure.

</details>


### [2] [Multi-Artifact Analysis of Self-Admitted Technical Debt in Scientific Software](https://arxiv.org/abs/2601.10850)
*Eric L. Melin,Nasir U. Eisty,Gregory Watson,Addi Malviya-Thakur*

Main category: cs.SE

TL;DR: 该研究首次对科学软件中的科学债务进行了系统分析，发现传统技术债务分类无法充分捕捉科学软件特有的技术债务，需要专门的检测方法。


<details>
  <summary>Details</summary>
Motivation: 科学软件中的技术债务对研究结果的效度和可复现性构成独特风险，但传统技术债务分类是否适用于科学软件领域尚不清楚。

Method: 对23个开源科学软件项目进行多工件分析，包括代码注释、提交信息、拉取请求和问题跟踪器。构建并验证科学债务数据集，开发多源技术债务分类器，并进行从业者验证。

Result: 分类器在23个项目的900,358个工件上表现优异。技术债务在拉取请求和问题跟踪器中最为普遍。传统技术债务模型常遗漏科学债务，从业者验证确认科学债务在实践中具有可识别性和实用性。

Conclusion: 科学债务是科学软件中独特的技术债务形式，需要专门的识别和管理方法。该研究提供了首个科学债务的多工件视角，强调了科学软件需要定制化的技术债务检测方法。

Abstract: Context: Self-admitted technical debt (SATD) occurs when developers acknowledge shortcuts in code. In scientific software (SSW), such debt poses unique risks to the validity and reproducibility of results. Objective: This study aims to identify, categorize, and evaluate scientific debt, a specialized form of SATD in SSW, and assess the extent to which traditional SATD categories capture these domain-specific issues. Method: We conduct a multi-artifact analysis across code comments, commit messages, pull requests, and issue trackers from 23 open-source SSW projects. We construct and validate a curated dataset of scientific debt, develop a multi-source SATD classifier, and conduct a practitioner validation to assess the practical relevance of scientific debt. Results: Our classifier performs strongly across 900,358 artifacts from 23 SSW projects. SATD is most prevalent in pull requests and issue trackers, underscoring the value of multi-artifact analysis. Models trained on traditional SATD often miss scientific debt, emphasizing the need for its explicit detection in SSW. Practitioner validation confirmed that scientific debt is both recognizable and useful in practice. Conclusions: Scientific debt represents a unique form of SATD in SSW that that is not adequately captured by traditional categories and requires specialized identification and management. Our dataset, classification analysis, and practitioner validation results provide the first formal multi-artifact perspective on scientific debt, highlighting the need for tailored SATD detection approaches in SSW.

</details>


### [3] [Struggling to Connect: A Researchers' Reflection on Networking in Software Engineering](https://arxiv.org/abs/2601.10907)
*Shalini Chakraborty*

Main category: cs.SE

TL;DR: 本文探讨影响软件工程研究人员建立专业网络的因素，分析国家、移民身份、语言、性别等障碍，并倡导社区驱动的"专家声音"倡议来解决不平等问题。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究人员的网络建设对职业发展和研究可见性至关重要，但网络建设机会和能力分布不均，且受到工作场所、文化环境等多种因素影响，存在许多隐形障碍需要被认识和解决。

Method: 采用反思性报告方法，结合现有文献和个人经验，分析国家居住地、移民身份、语言、性别和周围环境等因素如何影响研究人员建立专业联系的能力。

Result: 研究发现研究人员建立专业网络的能力受到多种系统性因素的影响，这些因素往往被忽视但显著影响研究人员的职业成功，揭示了全球研究生态系统中的不平等现象。

Conclusion: 需要社区驱动的"专家声音"倡议来认识和解决网络建设中的不平等问题，通过集体行动改善软件工程研究生态系统的包容性和公平性。

Abstract: Networking is central to the growth and visibility of software engineering research and researchers. However, opportunities and capacities to build such networks are not easily identified and often are unevenly distributed. While networking is often viewed as an individual skill, a researchers workplace, culture and environment significantly influence their motivation and, consequently, the networks they form. This paper explores how factors such as country of residence, immigration status, language, gender, and surrounding context affect researchers' ability to establish professional connections and succeed within the global research ecosystem. Drawing on existing literature and personal experience, this reflective report examines the often-invisible barriers to networking and advocates for a community-driven "expert voice" initiative to acknowledge and address these inequities.

</details>


### [4] [Change And Cover: Last-Mile, Pull Request-Based Regression Test Augmentation](https://arxiv.org/abs/2601.10942)
*Zitong Zhou,Matteo Paltenghi,Miryung Kim,Michael Pradel*

Main category: cs.SE

TL;DR: ChaCo是一个基于LLM的测试增强技术，专门针对PR中未覆盖的代码行生成测试，填补"最后一英里"回归测试空白。


<details>
  <summary>Details</summary>
Motivation: 在软件开发中，即使有大量测试套件，PR修改的代码行仍可能未被测试覆盖，形成"最后一英里"回归测试空白。现有测试生成器通常关注整体覆盖率，而非专门针对PR中未覆盖的代码行。

Method: ChaCo采用LLM生成测试，重点关注PR特定的补丁覆盖率。关键技术包括：1) 提取相关测试上下文（现有测试函数、fixtures、数据生成器）；2) 将生成的测试与现有测试套件集成，匹配结构和风格；3) 生成测试添加摘要供开发者审查。

Result: 在三个开源项目（SciPy、Qiskit、Pandas）的145个PR上评估，帮助30%的PR实现完全补丁覆盖，成本仅0.11美元。人工评审评分高：值得添加(4.53/5.0)、集成良好(4.2/5.0)、与PR相关(4.7/5.0)。提交的12个测试中8个已被合并，暴露并修复了两个未知bug。

Conclusion: ChaCo能有效填补PR测试覆盖的空白，具有实际应用价值。测试上下文对于上下文感知的测试生成至关重要。该方法可集成到CI工作流中，自动化最后一英里回归测试增强。

Abstract: Software is in constant evolution, with developers frequently submitting pull requests (PRs) to introduce new features or fix bugs. Testing PRs is critical to maintaining software quality. Yet, even in projects with extensive test suites, some PR-modified lines remain untested, leaving a "last-mile" regression test gap. Existing test generators typically aim to improve overall coverage, but do not specifically target the uncovered lines in PRs. We present Change And Cover (ChaCo), an LLM-based test augmentation technique that addresses this gap. It makes three contributions: (i) ChaCo considers the PR-specific patch coverage, offering developers augmented tests for code just when it is on the developers' mind. (ii) We identify providing suitable test context as a crucial challenge for an LLM to generate useful tests, and present two techniques to extract relevant test content, such as existing test functions, fixtures, and data generators. (iii) To make augmented tests acceptable for developers, ChaCo carefully integrates them into the existing test suite, e.g., by matching the test's structure and style with the existing tests, and generates a summary of the test addition for developer review. We evaluate ChaCo on 145 PRs from three popular and complex open-source projects - SciPy, Qiskit, and Pandas. The approach successfully helps 30% of PRs achieve full patch coverage, at the cost of $0.11, showing its effectiveness and practicality. Human reviewers find the tests to be worth adding (4.53/5.0), well integrated (4.2/5.0), and relevant to the PR (4.7/5.0). Ablations show test context is crucial for context-aware test generation, leading to 2x coverage. We submitted 12 tests, of which 8 have already been merged, and two previously unknown bugs were exposed and fixed. We envision our approach to be integrated into CI workflows, automating the last mile of regression test augmentation.

</details>


### [5] [ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development](https://arxiv.org/abs/2601.11077)
*Jie Yang,Honglin Guo,Li Ji,Jiazheng Zhou,Rui Zheng,Zhikai Lei,Shuo Zhang,Zhiheng Xi,Shichun Liu,Yuxin Wang,Bo Wang,Yining Zheng,Tao Gui,Xipeng Qiu*

Main category: cs.SE

TL;DR: ABC-Bench是一个专门评估智能体后端编码能力的基准测试，要求智能体在真实可执行的工作流中完成从仓库探索到容器化服务部署的完整开发生命周期，并通过端到端API测试。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要评估静态上下文中的代码逻辑，忽略了真实世界工程（特别是后端开发）所需的动态、全过程需求，包括环境配置和服务部署。需要填补这一评估空白。

Method: 使用可扩展的自动化流水线，从开源仓库中筛选了224个实际任务，涵盖8种编程语言和19个框架。要求智能体管理从仓库探索到实例化容器化服务的完整开发生命周期，并通过外部端到端API测试。

Result: 广泛评估显示，即使是当前最先进的模型在这些整体任务上也难以提供可靠性能，突显了当前模型能力与实际后端工程需求之间的显著差距。

Conclusion: ABC-Bench填补了评估智能体后端编码能力的空白，揭示了当前LLM在真实后端工程任务中的局限性，为未来研究提供了重要的评估框架。

Abstract: The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.

</details>


### [6] [Patterns of Bot Participation and Emotional Influence in Open-Source Development](https://arxiv.org/abs/2601.11138)
*Matteo Vaccargiu,Riccardo Lai,Maria Ilaria Lunesu,Andrea Pinna,Giuseppe Destefanis*

Main category: cs.SE

TL;DR: 研究以太坊生态系统中机器人如何参与开源讨论及其对开发者情绪的影响，发现少量机器人（0.28%）能改变开发者沟通的时间和情绪动态。


<details>
  <summary>Details</summary>
Motivation: 了解机器人在开源社区中的实际作用，特别是它们是否以及如何影响开发者之间的情绪互动和沟通动态。

Method: 分析10个仓库的36,875个账户，识别105个已验证机器人（0.28%）。使用27个情绪类别训练的模型分析人类和机器人的情绪表达，比较参与模式和响应时间。

Result: 人类参与呈U型模式，机器人参与模式不同（PR中均匀参与，issue中后期参与）。机器人PR响应更快，issue中扮演较慢维护角色。机器人更中立，但它们的干预导致人类评论中立性降低，情绪向感激、钦佩、乐观转变，困惑减少。

Conclusion: 即使少量机器人也能显著改变开发者沟通的时间和情绪动态，表明机器人在开源社区中具有超出简单自动化的社会影响。

Abstract: We study how bots contribute to open-source discussions in the Ethereum ecosystem and whether they influence developers' emotional tone. Our dataset covers 36,875 accounts across ten repositories with 105 validated bots (0.28%). Human participation follows a U-shaped pattern, while bots engage in uniform (pull requests) or late-stage (issues) activity. Bots respond faster than humans in pull requests but play slower maintenance roles in issues. Using a model trained on 27 emotion categories, we find bots are more neutral, yet their interventions are followed by reduced neutrality in human comments, with shifts toward gratitude, admiration, and optimism and away from confusion. These findings indicate that even a small number of bots are associated with changes in both timing and emotional dynamics of developer communication.

</details>


### [7] [Automation and Reuse Practices in GitHub Actions Workflows: A Practitioner's Perspective](https://arxiv.org/abs/2601.11299)
*Hassan Onsori Delicheh,Guillaume Cardoen,Alexandre Decan,Tom Mens*

Main category: cs.SE

TL;DR: 该研究调查了419名GitHub Actions使用者，发现开发者主要自动化CI/CD任务，较少关注安全分析和性能监控；虽然依赖可复用Actions，但可复用工作流采用率低；复制粘贴仍是常见做法以获得更多控制权；需要改进工具、支持更广泛的自动化任务以及更好的可复用组件管理机制。


<details>
  <summary>Details</summary>
Motivation: GitHub Actions原生支持工作流自动化，但工作流维护对开发者来说常常是负担，他们在编写、测试、调试和维护工作流时面临困难。目前对工作流实践者的自动化和复用实践了解甚少，因此需要调查以阐明好的和坏的工作流开发实践，并识别支持工作流维护的机会。

Method: 对419名工作流实践者进行问卷调查，调查内容包括：1) 开发者倾向于使用GitHub Actions自动化的任务类型；2) 他们偏好的工作流创建机制；3) 他们优先考虑的非功能特性；4) 与GitHub工作流复用机制相关的实践和挑战。

Result: 研究发现：1) 自动化工作主要集中在核心CI/CD任务，对安全分析和性能监控等关键领域关注较少；2) 实践者强烈依赖可复用Actions，但可复用工作流采用频率较低；3) 观察到Action版本控制和维护方面的挑战；4) 复制粘贴仍是常见做法，以获得更多控制权并避免依赖可复用组件的复杂性。

Conclusion: 这些发现表明需要：1) 改进工具支持；2) 增强对广泛自动化任务的支持；3) 更好的可复用工作流组件发现、管理和信任机制。研究为GitHub Actions生态系统的改进提供了重要见解。

Abstract: GitHub natively supports workflow automation through GitHub Actions. Yet, workflow maintenance is often considered a burden for software developers, who frequently face difficulties in writing, testing, debugging, and maintaining workflows. Little knowledge exists concerning the automation and reuse practices favoured by workflow practitioners. We therefore surveyed 419 practitioners to elucidate good and bad workflow development practices and to identify opportunities for supporting workflow maintenance. Specifically, we investigate the tasks that practitioners tend to automate using GitHub Actions, their preferred workflow creation mechanisms, and the non-functional characteristics they prioritise. We also examine the practices and challenges associated with GitHub's workflow reuse mechanisms. We observe a tendency to focus automation efforts on core CI/CD tasks, with less emphasis on crucial areas like security analysis and performance monitoring. Practitioners strongly rely on reusable Actions, but reusable workflows see less frequent adoption. Furthermore, we observed challenges with Action versioning and maintenance. Copy-pasting remains a common practice to have more control and avoid the complexity of depending on reusable components. These insights suggest the need for improved tooling, enhanced support for a wide range of automation tasks, and better mechanisms for discovering, managing, and trusting reusable workflow components.

</details>


### [8] [RITA: A Tool for Automated Requirements Classification and Specification from Online User Feedback](https://arxiv.org/abs/2601.11362)
*Manjeshwar Aniruddh Mallya,Alessio Ferrari,Mohammad Amin Zadenoori,Jacek Dąbrowski*

Main category: cs.SE

TL;DR: RITA是一个集成轻量级开源大语言模型的工具，通过统一工作流将在线用户反馈转化为需求制品，支持自动请求分类、非功能性需求识别和需求规范生成，并与Jira集成。


<details>
  <summary>Details</summary>
Motivation: 在线用户反馈是需求工程的重要资源，但海量和嘈杂的数据使得分析困难。现有工具虽然支持单个反馈分析任务，但缺乏端到端的集成，限制了实际应用和真实世界有用性的评估。

Method: 开发RITA工具，集成轻量级开源大语言模型，创建统一工作流。支持自动请求分类、非功能性需求识别、自然语言需求规范生成，提供用户友好界面，并与Jira集成实现需求规范到开发工具的无缝转移。

Result: RITA利用先前评估过的LLM-based RE技术，能够高效地将原始用户反馈转化为需求制品，帮助弥合研究与实践之间的差距。

Conclusion: RITA通过集成LLM技术提供端到端的反馈驱动需求工程支持，解决了现有工具缺乏集成的问题，促进了研究和实践的结合。

Abstract: Context and motivation. Online user feedback is a valuable resource for requirements engineering, but its volume and noise make analysis difficult. Existing tools support individual feedback analysis tasks, but their capabilities are rarely integrated into end-to-end support. Problem. The lack of end-to-end integration limits the practical adoption of existing RE tools and makes it difficult to assess their real-world usefulness. Solution. To address this challenge, we present RITA, a tool that integrates lightweight open-source large language models into a unified workflow for feedback-driven RE. RITA supports automated request classification, non-functional requirement identification, and natural-language requirements specification generation from online feedback via a user-friendly interface, and integrates with Jira for seamless transfer of requirements specifications to development tools. Results and conclusions. RITA exploits previously evaluated LLM-based RE techniques to efficiently transform raw user feedback into requirements artefacts, helping bridge the gap between research and practice. A demonstration is available at: https://youtu.be/8meCLpwQWV8.

</details>


### [9] [A Practical Guide to Establishing Technical Debt Management](https://arxiv.org/abs/2601.11430)
*Marion Wiese*

Main category: cs.SE

TL;DR: 该白皮书基于博士研究成果，为团队提供技术债务管理的实用指南，区分"最佳实践"和"锦上添花"，强调团队自主决策而非僵化框架。


<details>
  <summary>Details</summary>
Motivation: 将学术研究成果转化为团队可用的技术债务管理实践指导，解决理论与实践脱节的问题，帮助团队建立适合自身需求的技术债务管理系统。

Method: 与研究人员合作，支持三家不同公司的团队建立定制化的技术债务管理系统；基于实践经验，筛选实用研究成果，区分"最佳实践"（所有团队都采用）和"锦上添花"（至少一个团队采用）。

Result: 开发出团队技术债务管理指南，提供方向性指导而非刚性框架，强调团队共同决策，包含跨公司推广的建议但不覆盖全公司范围实施。

Conclusion: 技术债务管理需要团队定制化方案，指南应提供灵活指导而非强制框架，团队自主决策是关键，研究成果需经过实践筛选才能转化为有效指导。

Abstract: This white paper provides an overview of the topic of "technical debt" and presents an approach for managing technical debt in teams. The white paper is based on the results of my dissertation, which aimed to translate scientific findings into practical guidance. To this end, I collaborated with other researchers to support three teams from different companies in adapting and establishing a technical debt management system tailored to their specific needs. Research findings were supplemented with details or additional approaches. Research results that were less practical were discarded. The result is a guide on establishing technical debt management within a team. The guide is intended to provide orientation and not be a rigid framework. We distinguish between "best practices" and "nice-to-haves." "Best practices" are understood to be all approaches that were adopted by all three teams. "Nice-to-haves" were used by at least one team. In many places, it is explicitly mentioned that the team should decide together how to design the process. This also applies, of course, to all areas where this was not explicitly mentioned. This white paper explicitly does not cover the establishment of technical debt management across the entire company, but provides suggestions for this at the end.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Cutting Corners on Uncertainty: Zonotope Abstractions for Stream-based Runtime Monitoring](https://arxiv.org/abs/2601.11358)
*Bernd Finkbeiner,Martin Fränzle,Florian Kohn,Paul Kröger*

Main category: cs.PL

TL;DR: 该论文提出使用zonotopes作为在线监控RLola规范的抽象域，能够精确捕获监控器的仿射状态，并通过过近似实现有界内存监控。


<details>
  <summary>Details</summary>
Motivation: 流式监控评估安全关键系统的健康状况，但真实传感器存在校准和测量误差。这些误差通过监控器的计算传播并可能扭曲最终判决。仿射算术可以精确跟踪误差，但独立测量噪声会引入新的松弛变量，导致监控器状态表示随时间无限增长，因此需要设计有界内存监控算法。

Method: 引入zonotopes作为RLola规范在线监控的抽象域。zonotopes能够精确捕获监控器的仿射状态，并通过过近似产生有界内存监控器。论文比较了不同zonotope过近似策略在运行时监控中的性能。

Result: zonotopes能够精确捕获监控器的仿射状态，其过近似产生有界内存监控器。论文比较了不同zonotope过近似策略的性能和误报率。

Conclusion: zonotopes作为抽象域能够有效解决流式监控中的误差传播问题，通过过近似实现有界内存监控，为安全关键系统的运行时监控提供了可靠方法。

Abstract: Stream-based monitoring assesses the health of safety-critical systems by transforming input streams of sensor measurements into output streams that determine a verdict. These inputs are often treated as accurate representations of the physical state, although real sensors introduce calibration and measurement errors. Such errors propagate through the monitor's computations and can distort the final verdict. Affine arithmetic with symbolic slack variables can track these errors precisely, but independent measurement noise introduces a fresh slack variable upon each measurement event, causing the monitor's state representation to grow without bound over time. Therefore, any bounded-memory monitoring algorithm must unify slack variables at runtime in a way that generates a sound approximation.
  This paper introduces zonotopes as an abstract domain for online monitoring of RLola specifications. We demonstrate that zonotopes precisely capture the affine state of the monitor and that their over-approximation produces a sound bounded-memory monitor. We present a comparison of different zonotope over-approximation strategies in the context of runtime monitoring, evaluating their performance and false-positive rates.

</details>


### [11] [Qihe: A General-Purpose Static Analysis Framework for Verilog](https://arxiv.org/abs/2601.11408)
*Qinlin Chen,Nairen Zhang,Jinpeng Wang,Jiacai Cui,Tian Tan,Xiaoxing Ma,Chang Xu,Jian Lu,Yue Li*

Main category: cs.PL

TL;DR: Qihe是首个针对Verilog的通用静态分析框架，填补了硬件分析领域的空白，支持多种硬件特性分析，已在真实项目中发现了多个未知bug和漏洞。


<details>
  <summary>Details</summary>
Motivation: 软件领域已有成熟的静态分析框架支持bug检测、安全分析和程序理解，但硬件领域缺乏类似框架，阻碍了硬件静态分析的发展和应用。

Method: 设计分析导向的前端、Verilog专用中间表示（IR），以及一系列基础分析组件，支持位向量运算、寄存器同步、数字组件并发等硬件特性分析。

Result: 在真实硬件项目中发现了9个未知bug（已获开发者确认），识别了18个现有linter无法检测的bug，检测出16个真实硬件程序中的漏洞。

Conclusion: Qihe作为首个Verilog通用静态分析框架，填补了硬件分析空白，开源10万+行代码旨在激发硬件静态分析生态发展，达到软件分析类似的繁荣程度。

Abstract: In the past decades, static analysis has thrived in software, facilitating applications in bug detection, security, and program understanding. These advanced analyses are largely underpinned by general-purpose static analysis frameworks, which offer essential infrastructure to streamline their development. Conversely, hardware lacks such a framework, which overshadows the promising opportunities for sophisticated static analysis in hardware, hindering achievements akin to those witnessed in software. We thus introduce Qihe, the first general-purpose static analysis framework for Verilog -- a highly challenging endeavor given the absence of precedents in hardware. Qihe features an analysis-oriented front end, a Verilog-specific IR, and a suite of diverse fundamental analyses that capture essential hardware-specific characteristics -- such as bit-vector arithmetic, register synchronization, and digital component concurrency -- and enable the examination of intricate hardware data and control flows. These fundamental analyses are designed to support a wide array of hardware analysis clients. To validate Qihe's utility, we further developed a set of clients spanning bug detection, security, and program understanding. Our preliminary experimental results are highly promising; for example, Qihe uncovered 9 previously unknown bugs in popular real-world hardware projects (averaging 1.5K+ GitHub stars), all of which were confirmed by developers; moreover, Qihe successfully identified 18 bugs beyond the capabilities of existing static analyses for Verilog bug detection (i.e., linters), and detected 16 vulnerabilities in real-world hardware programs. By open-sourcing Qihe, which comprises over 100K lines of code, we aim to inspire further innovation and applications of sophisticated static analysis for hardware, aspiring to foster a similarly vibrant ecosystem that software analysis enjoys.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [Resource-Bounded Martin-Löf Type Theory: Compositional Cost Analysis for Dependent Types](https://arxiv.org/abs/2601.10772)
*Mirco A. Mannucci,Corey Thuro*

Main category: cs.LO

TL;DR: 扩展资源有界类型理论到带依赖类型的Martin-Lof类型理论，通过大小索引为归纳族程序提供成本边界分析


<details>
  <summary>Details</summary>
Motivation: 连接依赖类型理论和定量资源分析之间的差距，为大小依赖算法提供经过认证的成本边界

Method: 引入资源索引的宇宙层次U_r（r∈L跟踪类型形成的成本）和分级模态Box_r用于可行性认证；建立预层topos上的语义模型，扩展依赖预层和理解结构

Result: 证明成本健全性定理（合成边界过度逼近操作成本）、内涵片段的规范性、语法模型的初始性；通过长度索引向量操作（线性边界）和二分查找（对数边界）等案例验证框架

Conclusion: 成功将资源有界类型理论扩展到依赖类型系统，为大小依赖算法提供类型级别的成本边界认证，填补了依赖类型理论与定量资源分析之间的空白

Abstract: We extend resource-bounded type theory to Martin-Lof type theory (MLTT) with dependent types, enabling size-indexed cost bounds for programs over inductive families.
  We introduce a resource-indexed universe hierarchy U_r where r is an element of L and tracks the cost of type formation, and a graded modality Box_r for feasibility certification. Our main results are: (1) a cost soundness theorem showing that synthesized bounds over-approximate operational costs, with bounds expressed as functions of size indices; (2) a semantic model in the presheaf topos over L, extended with dependent presheaves and a comprehension structure; (3) canonicity for the intensional fragment; and (4) initiality of the syntactic model. We demonstrate the framework with case studies including length-indexed vector operations with linear bounds and binary search with logarithmic bounds, both expressed in the type.
  This work bridges the gap between dependent type theory and quantitative resource analysis, enabling certified cost bounds for size-dependent algorithms.

</details>


### [13] [Applying Formal Methods Tools to an Electronic Warfare Codebase (Experience report)](https://arxiv.org/abs/2601.11510)
*Letitia W. Li,Denley Lam,Vu Le,Daniel Mitchell,Mark J. Gerken,Robert B. Ross*

Main category: cs.LO

TL;DR: 本文探讨了在电子战系统中应用形式化方法的经验，分析了形式化方法工具在工业软件工程中的可用性挑战，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 形式化方法相比单元测试具有优势，但其陡峭的学习曲线阻碍了广泛采用。为了支持工业软件工程工作流的集成，工具需要提供有用信息且易于使用，特别是在具有严格安全要求的电子战系统中。

Method: 通过识别和应用形式化方法工具于电子战系统，收集缺乏形式化方法培训但精通开发的电子战软件工程师的视角，分析工具间的差异和可用性问题。

Result: 发现形式化方法与单元测试在思维方式上的差异，工具术语和注释与目标编程语言不一致，输入/输出契约、内存对象和循环不变量难以掌握。比较了不同工具检测到的漏洞，并提出了改进建议。

Conclusion: 形式化方法工具需要改进可用性，包括更好的能力文档、减少手动工作量、改进库代码处理，以促进在工业环境中的更广泛采用。

Abstract: While using formal methods offers advantages over unit testing, their steep learning curve can be daunting to developers and can be a major impediment to widespread adoption. To support integration into an industrial software engineering workflow, a tool must provide useful information and must be usable with relatively minimal user effort. In this paper, we discuss our experiences associated with identifying and applying formal methods tools on an electronic warfare (EW) system with stringent safety requirements and present perspectives on formal methods tools from EW software engineers who are proficient in development yet lack formal methods training. In addition to a difference in mindset between formal methods and unit testing approaches, some formal methods tools use terminology or annotations that differ from their target programming language, creating another barrier to adoption. Input/output contracts, objects in memory affected by a function, and loop invariants can be difficult to grasp and use. In addition to usability, our findings include a comparison of vulnerabilities detected by different tools. Finally, we present suggestions for improving formal methods usability including better documentation of capabilities, decreased manual effort, and improved handling of library code.

</details>
